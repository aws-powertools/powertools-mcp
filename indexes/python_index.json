{
    "config":
    {
        "lang":
        [
            "en"
        ],
        "separator": "[\\s\\-]+",
        "pipeline":
        [
            "stopWordFilter"
        ]
    },
    "docs":
    [
        {
            "location": "",
            "title": "Homepage",
            "text": "<p>Powertools for AWS Lambda (Python) is a developer toolkit to implement Serverless best practices and increase developer velocity.</p> <ul> <li> <p> Features</p> <p>Adopt one, a few, or all industry practices. Progressively.</p> <p> All features</p> </li> <li> <p> Support this project</p> <p>Become a public reference customer, share your work, contribute, use Lambda Layers, etc.</p> <p> Support</p> </li> <li> <p> Available languages</p> <p>Powertools for AWS Lambda is also available in other languages</p> <p> Java, TypeScript, and .NET</p> </li> </ul>"
        },
        {
            "location": "#install",
            "title": "Install",
            "text": "<p>You can install Powertools for AWS Lambda (Python) using your favorite dependency management, or Lambda Layers:</p> PipLambda LayerLambda Layer (GovCloud)Serverless Application Repository (SAR)Alpha releases <p>Most features use Python standard library and the AWS SDK (boto3) that are available in the AWS Lambda runtime.</p> <ul> <li>pip: <code>pip install \"aws-lambda-powertools\"</code></li> <li>poetry: <code>poetry add \"aws-lambda-powertools\"</code></li> <li>pdm: <code>pdm add \"aws-lambda-powertools\"</code></li> </ul> <p>Lambda Layer is a .zip file archive that can contain additional code, pre-packaged dependencies, data,  or configuration files. We compile and optimize all dependencies, and remove duplicate dependencies already available in the Lambda runtime to achieve the most optimal size.</p> <p>For the latter, make sure to replace <code>{region}</code> with your AWS region, e.g., <code>eu-west-1</code>, and the <code>{python_version}</code> without the period (.), e.g., <code>python313</code> for <code>Python 3.13</code>.</p> Architecture Layer ARN x86_64 arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-{python_version}-x86_64:7 ARM arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-{python_version}-arm64:7 AWS ConsoleAWS SSM Parameter StoreInfrastructure as Code (IaC)Inspect Lambda Layer contents <p>You can add our layer using the AWS Lambda Console (direct link):</p> <ul> <li>Under Layers, choose <code>AWS layers</code> or <code>Specify an ARN</code></li> <li>Click to copy the correct ARN value based on your AWS Lambda function architecture and region</li> </ul> <p>We offer Parameter Store aliases for releases too, allowing you to specify either specific versions or use the latest version on every deploy. To use these you can add these snippets to your AWS CloudFormation or Terraform projects:</p> <p>CloudFormation</p> <p>Sample Placeholders:</p> <ul> <li><code>{arch}</code> is either <code>arm64</code> (Graviton based functions) or <code>x86_64</code></li> <li><code>{python_version}</code> is the Python runtime version, e.g., <code>python3.13</code> for <code>Python 3.13</code>.</li> <li><code>{version}</code> is the semantic version number (e,g. 3.1.0) for a release or <code>latest</code></li> </ul> <pre><code>MyFunction:\n    Type: \"AWS::Lambda::Function\"\n    Properties:\n        ...\n        Layers:\n        - {{resolve:ssm:/aws/service/powertools/python/{arch}/{python_version}/{version}}}\n</code></pre> <p>Terraform</p> <p>Using the <code>aws_ssm_parameter</code> data provider from the AWS Terraform provider allows you to lookup the value of parameters to use later in your project.</p> <pre><code>data \"aws_ssm_parameter\" \"powertools_version\" {\n    name = \"/aws/service/powertools/python/{arch}/{python_version}/{version}\"\n}\n\nresource \"aws_lambda_function\" \"test_lambda\" {\n    ...\n\n    runtime = \"python3.13\"\n\n    layers = [data.aws_ssm_parameter.powertools_version.value]\n}\n</code></pre> <p>Are we missing a framework? please create a documentation request.</p> <p>Thanks to the community, we've covered most popular frameworks on how to add a Lambda Layer to an existing function.</p> x86_64arm64 SAMServerless frameworkCDKTerraformPulumiAmplify <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nResources:\n    MyLambdaFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n            Runtime: python3.12\n            Handler: app.lambda_handler\n            Layers:\n            - !Sub arn:aws:lambda:${AWS::Region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12\n</code></pre> <pre><code>service: powertools-lambda\n\nprovider:\n  name: aws\n  runtime: python3.12\n  region: us-east-1\n\nfunctions:\n  powertools:\n    handler: lambda_function.lambda_handler\n    architecture: arm64\n    layers:\n    - arn:aws:lambda:${aws:region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12\n</code></pre> <pre><code>from aws_cdk import Aws, Stack, aws_lambda\nfrom constructs import Construct\n\n\nclass SampleApp(Stack):\n\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -&gt; None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        powertools_layer = aws_lambda.LayerVersion.from_layer_version_arn(\n            self,\n            id=\"lambda-powertools\",\n            layer_version_arn=f\"arn:aws:lambda:{Aws.REGION}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12\",\n        )\n        aws_lambda.Function(\n            self,\n            \"sample-app-lambda\",\n            runtime=aws_lambda.Runtime.PYTHON_3_12,\n            layers=[powertools_layer],\n            code=aws_lambda.Code.from_asset(\"lambda\"),\n            handler=\"hello.handler\",\n        )\n</code></pre> <pre><code>terraform {\n  required_version = \"~&gt; 1.0.5\"\n  required_providers {\n    aws = \"~&gt; 3.50.0\"\n  }\n}\n\nprovider \"aws\" {\n  region = \"{region}\"\n}\n\nresource \"aws_iam_role\" \"iam_for_lambda\" {\n  name = \"iam_for_lambda\"\n\n  assume_role_policy = &lt;&lt;EOF\n    {\n        \"Version\": \"2012-10-17\",\n        \"Statement\": [\n        {\n            \"Action\": \"sts:AssumeRole\",\n            \"Principal\": {\n            \"Service\": \"lambda.amazonaws.com\"\n            },\n            \"Effect\": \"Allow\"\n        }\n        ]\n    }\n    EOF\n}\n\nresource \"aws_lambda_function\" \"test_lambda\" {\n  filename      = \"lambda_function_payload.zip\"\n  function_name = \"lambda_function_name\"\n  role          = aws_iam_role.iam_for_lambda.arn\n  handler       = \"index.test\"\n  runtime       = \"python3.12\"\n  layers        = [\"arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12\"]\n\n  source_code_hash = filebase64sha256(\"lambda_function_payload.zip\")\n}\n</code></pre> <pre><code>import json\n\nimport pulumi\nimport pulumi_aws as aws\n\nrole = aws.iam.Role(\n    \"role\",\n    assume_role_policy=json.dumps(\n        {\n            \"Version\": \"2012-10-17\",\n            \"Statement\": [\n                {\"Action\": \"sts:AssumeRole\", \"Principal\": {\"Service\": \"lambda.amazonaws.com\"}, \"Effect\": \"Allow\"},\n            ],\n        },\n    ),\n    managed_policy_arns=[aws.iam.ManagedPolicy.AWS_LAMBDA_BASIC_EXECUTION_ROLE],\n)\n\nlambda_function = aws.lambda_.Function(\n    \"function\",\n    layers=[\n        pulumi.Output.concat(\n            \"arn:aws:lambda:\",\n            aws.get_region_output().name,\n            \":017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12\",\n        ),\n    ],\n    tracing_config={\"mode\": \"Active\"},\n    runtime=aws.lambda_.Runtime.PYTHON3D12,\n    handler=\"index.handler\",\n    role=role.arn,\n    architectures=[\"x86_64\"],\n    code=pulumi.FileArchive(\"lambda_function_payload.zip\"),\n)\n</code></pre> <pre><code># Create a new one with the layer\n❯ amplify add function\n? Select which capability you want to add: Lambda function (serverless function)\n? Provide an AWS Lambda function name: &lt;NAME-OF-FUNCTION&gt;\n? Choose the runtime that you want to use: Python\n? Do you want to configure advanced settings? Yes\n...\n? Do you want to enable Lambda layers for this function? Yes\n? Enter up to 5 existing Lambda layer ARNs (comma-separated): arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12\n❯ amplify push -y\n\n\n# Updating an existing function and add the layer\n❯ amplify update function\n? Select the Lambda function you want to update test2\nGeneral information\n- Name: &lt;NAME-OF-FUNCTION&gt;\n? Which setting do you want to update? Lambda layers configuration\n? Do you want to enable Lambda layers for this function? Yes\n? Enter up to 5 existing Lambda layer ARNs (comma-separated): arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12\n? Do you want to edit the local lambda function now? No\n</code></pre> SAMServerless frameworkCDKTerraformPulumiAmplify <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nResources:\n  MyLambdaFunction:\n      Type: AWS::Serverless::Function\n      Properties:\n          Architectures: [arm64]\n          Runtime: python3.12\n          Handler: app.lambda_handler\n          Layers:\n          - !Sub arn:aws:lambda:${AWS::Region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12\n</code></pre> <pre><code>service: powertools-lambda\n\nprovider:\n  name: aws\n  runtime: python3.12\n  region: us-east-1\n\nfunctions:\n  powertools:\n    handler: lambda_function.lambda_handler\n    architecture: arm64\n    layers:\n    - arn:aws:lambda:${aws:region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12\n</code></pre> <pre><code>from aws_cdk import Aws, Stack, aws_lambda\nfrom constructs import Construct\n\n\nclass SampleApp(Stack):\n\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -&gt; None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        powertools_layer = aws_lambda.LayerVersion.from_layer_version_arn(\n            self,\n            id=\"lambda-powertools\",\n            layer_version_arn=f\"arn:aws:lambda:{Aws.REGION}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12\",\n        )\n        aws_lambda.Function(\n            self,\n            \"sample-app-lambda\",\n            runtime=aws_lambda.Runtime.PYTHON_3_12,\n            layers=[powertools_layer],\n            architecture=aws_lambda.Architecture.ARM_64,\n            code=aws_lambda.Code.from_asset(\"lambda\"),\n            handler=\"hello.handler\",\n        )\n</code></pre> <pre><code>terraform {\n  required_version = \"~&gt; 1.0.5\"\n  required_providers {\n    aws = \"~&gt; 3.50.0\"\n  }\n}\n\nprovider \"aws\" {\n  region = \"{region}\"\n}\n\nresource \"aws_iam_role\" \"iam_for_lambda\" {\n  name = \"iam_for_lambda\"\n\n  assume_role_policy = &lt;&lt;EOF\n    {\n      \"Version\": \"2012-10-17\",\n      \"Statement\": [\n        {\n          \"Action\": \"sts:AssumeRole\",\n          \"Principal\": {\n            \"Service\": \"lambda.amazonaws.com\"\n          },\n          \"Effect\": \"Allow\"\n        }\n      ]\n    }\n    EOF\n}\n\nresource \"aws_lambda_function\" \"test_lambda\" {\n  filename      = \"lambda_function_payload.zip\"\n  function_name = \"lambda_function_name\"\n  role          = aws_iam_role.iam_for_lambda.arn\n  handler       = \"index.test\"\n  runtime       = \"python3.12\"\n  layers        = [\"arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12\"]\n  architectures = [\"arm64\"]\n\n  source_code_hash = filebase64sha256(\"lambda_function_payload.zip\")\n}\n</code></pre> <pre><code>import json\n\nimport pulumi\nimport pulumi_aws as aws\n\nrole = aws.iam.Role(\n    \"role\",\n    assume_role_policy=json.dumps(\n        {\n            \"Version\": \"2012-10-17\",\n            \"Statement\": [\n                {\"Action\": \"sts:AssumeRole\", \"Principal\": {\"Service\": \"lambda.amazonaws.com\"}, \"Effect\": \"Allow\"},\n            ],\n        },\n    ),\n    managed_policy_arns=[aws.iam.ManagedPolicy.AWS_LAMBDA_BASIC_EXECUTION_ROLE],\n)\n\nlambda_function = aws.lambda_.Function(\n    \"function\",\n    layers=[\n        pulumi.Output.concat(\n            \"arn:aws:lambda:\",\n            aws.get_region_output().name,\n            \":017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12\",\n        ),\n    ],\n    tracing_config={\"mode\": \"Active\"},\n    runtime=aws.lambda_.Runtime.PYTHON3D12,\n    handler=\"index.handler\",\n    role=role.arn,\n    architectures=[\"arm64\"],\n    code=pulumi.FileArchive(\"lambda_function_payload.zip\"),\n)\n</code></pre> <pre><code># Create a new one with the layer\n❯ amplify add function\n? Select which capability you want to add: Lambda function (serverless function)\n? Provide an AWS Lambda function name: &lt;NAME-OF-FUNCTION&gt;\n? Choose the runtime that you want to use: Python\n? Do you want to configure advanced settings? Yes\n...\n? Do you want to enable Lambda layers for this function? Yes\n? Enter up to 5 existing Lambda layer ARNs (comma-separated): arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12\n❯ amplify push -y\n\n\n# Updating an existing function and add the layer\n❯ amplify update function\n? Select the Lambda function you want to update test2\nGeneral information\n- Name: &lt;NAME-OF-FUNCTION&gt;\n? Which setting do you want to update? Lambda layers configuration\n? Do you want to enable Lambda layers for this function? Yes\n? Enter up to 5 existing Lambda layer ARNs (comma-separated): arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12\n? Do you want to edit the local lambda function now? No\n</code></pre> <p>You can use AWS CLI to generate a pre-signed URL to download the contents of our Lambda Layer.</p> AWS CLI command to download Lambda Layer content<pre><code>aws lambda get-layer-version-by-arn --arn arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 --region eu-west-1\n</code></pre> <p>You'll find the pre-signed URL under <code>Location</code> key as part of the CLI command output.</p> <p>Lambda Layer is a .zip file archive that can contain additional code, pre-packaged dependencies, data,  or configuration files. We compile and optimize all dependencies, and remove duplicate dependencies already available in the Lambda runtime to achieve the most optimal size.</p> <p>For the latter, make sure to replace <code>{python_version}</code> without the period (.), e.g., <code>python313</code> for <code>Python 3.13</code>.</p> <p>AWS GovCloud (us-gov-east-1)</p> Architecture Layer ARN x86_64 arn:aws-us-gov:lambda:us-gov-east-1:165087284144:layer:AWSLambdaPowertoolsPythonV3-{python_version}-x86_64:7 ARM arn:aws-us-gov:lambda:us-gov-east-1:165087284144:layer:AWSLambdaPowertoolsPythonV3-{python_version}-arm64:7 <p>AWS GovCloud (us-gov-west-1)</p> Architecture Layer ARN x86_64 arn:aws-us-gov:lambda:us-gov-west-1:165093116878:layer:AWSLambdaPowertoolsPythonV3-{python_version}-x86_64:7 ARM arn:aws-us-gov:lambda:us-gov-west-1:165093116878:layer:AWSLambdaPowertoolsPythonV3-{python_version}-arm64:7 <p>We provide a SAR App that deploys a CloudFormation stack with a copy of our Lambda Layer in your AWS account and region.</p> <p>Compared with the public Layer ARN option, the advantage is being able to use a semantic version. Make sure to replace <code>{python_version}</code> without the period (.), e.g., <code>python313</code> for <code>Python 3.13</code>.</p> App ARN Architecture aws-lambda-powertools-python-layer-v3-{python_version}-x86-64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-{python_version}-x86-64 X86_64 aws-lambda-powertools-python-layer-v3-{python_version}-arm64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-{python_version}-arm64 ARM64 Don't have enough permissions? Expand for a least-privilege IAM policy example <p>Credits to mwarkentin for providing the scoped down IAM permissions.</p> Least-privileged IAM permissions SAM example<pre><code>  AWSTemplateFormatVersion: \"2010-09-09\"\n  Resources:\n      PowertoolsLayerIamRole:\n        Type: \"AWS::IAM::Role\"\n        Properties:\n            AssumeRolePolicyDocument:\n                Version: \"2012-10-17\"\n                Statement:\n                    - Effect: \"Allow\"\n                      Principal:\n                        Service:\n                          - \"cloudformation.amazonaws.com\"\n                        Action:\n                          - \"sts:AssumeRole\"\n                Path: \"/\"\n\n      PowertoolsLayerIamPolicy:\n        Type: \"AWS::IAM::Policy\"\n        Properties:\n            PolicyName: PowertoolsLambdaLayerPolicy\n            PolicyDocument:\n                Version: \"2012-10-17\"\n                Statement:\n                    - Sid: CloudFormationTransform\n                      Effect: Allow\n                      Action: cloudformation:CreateChangeSet\n                      Resource:\n                        - arn:aws:cloudformation:us-east-1:aws:transform/Serverless-2016-10-31\n                    - Sid: GetCfnTemplate\n                      Effect: Allow\n                      Action:\n                        - serverlessrepo:CreateCloudFormationTemplate\n                        - serverlessrepo:GetCloudFormationTemplate\n                      Resource:\n                        # this is arn of the Powertools for AWS Lambda (Python) SAR app\n                        - arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python313-x86-64\n                    - Sid: S3AccessLayer\n                      Effect: Allow\n                      Action:\n                        - s3:GetObject\n                      Resource:\n                        # AWS publishes to an external S3 bucket locked down to your account ID\n                        # The below example is us publishing Powertools for AWS Lambda (Python)\n                        # Bucket: awsserverlessrepo-changesets-plntc6bfnfj\n                        # Key: *****/arn:aws:serverlessrepo:eu-west-1:057560766410:applications-aws-lambda-powertools-python-layer-v3-python313-x86-64-3.0.9/aeeccf50-****-****-****-*********\n                        - arn:aws:s3:::awsserverlessrepo-changesets-*/*\n                    - Sid: GetLayerVersion\n                      Effect: Allow\n                      Action:\n                        - lambda:PublishLayerVersion\n                        - lambda:GetLayerVersion\n                      Resource:\n                        - !Sub arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:layer:aws-lambda-powertools-python-layer-v3*\n            Roles:\n            - Ref: \"PowertoolsLayerIamRole\"\n</code></pre> <p>If you're using Infrastructure as Code, here are some excerpts on how to use SAR:</p> SAMServerless frameworkCDKTerraform <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nResources:\n  AwsLambdaPowertoolsPythonLayer:\n      Type: AWS::Serverless::Application\n      Properties:\n          Location:\n              ApplicationId: arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python313-x86-64\n              SemanticVersion: 3.0.9 # change to latest semantic version available in SAR\n\n  MyLambdaFunction:\n      Type: AWS::Serverless::Function\n      Properties:\n        Runtime: python3.13\n        Handler: app.lambda_handler\n        Layers:\n            # fetch Layer ARN from SAR App stack output\n            - !GetAtt AwsLambdaPowertoolsPythonLayer.Outputs.LayerVersionArn\n</code></pre> <pre><code>service: powertools-lambda\n\nprovider:\n  name: aws\n  runtime: python3.13\n  region: us-east-1\n\nfunctions:\n    powertools:\n      handler: lambda_function.lambda_handler\n      layers:\n          - !GetAtt AwsLambdaPowertoolsPythonLayer.Outputs.LayerVersionArn\n\nresources:\n  - AwsLambdaPowertoolsPythonLayer:\n      Type: AWS::Serverless::Application\n      Properties:\n        Location:\n          ApplicationId:  arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python313-x86-64\n          SemanticVersion: 3.0.9\n</code></pre> <pre><code>from aws_cdk import Stack, aws_lambda, aws_sam\nfrom constructs import Construct\n\nPOWERTOOLS_BASE_NAME = \"AWSLambdaPowertools\"\n# Find latest from github.com/aws-powertools/powertools-lambda-python/releases\nPOWERTOOLS_VER = \"3.0.9\"\nPOWERTOOLS_ARN = (\n    \"arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python313-x86-64\"\n)\n\n\nclass SampleApp(Stack):\n\n    def __init__(self, scope: Construct, id_: str) -&gt; None:\n        super().__init__(scope, id_)\n\n        # Launches SAR App as CloudFormation nested stack and return Lambda Layer\n        powertools_app = aws_sam.CfnApplication(\n            self,\n            f\"{POWERTOOLS_BASE_NAME}Application\",\n            location={\"applicationId\": POWERTOOLS_ARN, \"semanticVersion\": POWERTOOLS_VER},\n        )\n\n        powertools_layer_arn = powertools_app.get_att(\"Outputs.LayerVersionArn\").to_string()\n        powertools_layer_version = aws_lambda.LayerVersion.from_layer_version_arn(\n            self,\n            f\"{POWERTOOLS_BASE_NAME}\",\n            powertools_layer_arn,\n        )\n\n        aws_lambda.Function(\n            self,\n            \"sample-app-lambda\",\n            runtime=aws_lambda.Runtime.PYTHON_3_13,\n            function_name=\"sample-lambda\",\n            code=aws_lambda.Code.from_asset(\"lambda\"),\n            handler=\"hello.handler\",\n            layers=[powertools_layer_version],\n        )\n</code></pre> <p>Credits to Dani Comnea for providing the Terraform equivalent.</p> <pre><code>terraform {\n  required_version = \"~&gt; 0.13\"\n  required_providers {\n    aws = \"~&gt; 3.50.0\"\n  }\n}\n\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nresource \"aws_serverlessapplicationrepository_cloudformation_stack\" \"deploy_sar_stack\" {\n  name = \"aws-lambda-powertools-python-layer\"\n\n  application_id   = data.aws_serverlessapplicationrepository_application.sar_app.application_id\n  semantic_version = data.aws_serverlessapplicationrepository_application.sar_app.semantic_version\n  capabilities = [\n    \"CAPABILITY_IAM\",\n    \"CAPABILITY_NAMED_IAM\"\n  ]\n}\n\ndata \"aws_serverlessapplicationrepository_application\" \"sar_app\" {\n  application_id   = \"arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python313-x86-64\"\n  semantic_version = var.aws_powertools_version\n}\n\nvariable \"aws_powertools_version\" {\n  type        = string\n  default     = \"3.0.9\"\n  description = \"The Powertools for AWS Lambda (Python) release version\"\n}\n\noutput \"deployed_powertools_sar_version\" {\n  value = data.aws_serverlessapplicationrepository_application.sar_app.semantic_version\n}\n\n# Fetch Powertools for AWS Lambda (Python) Layer ARN from deployed SAR App\noutput \"aws_lambda_powertools_layer_arn\" {\n  value = aws_serverlessapplicationrepository_cloudformation_stack.deploy_sar_stack.outputs.LayerVersionArn\n}\n</code></pre> <p>Every morning during business days (~8am UTC), we publish a <code>prerelease</code> to PyPi to accelerate customer feedback on unstable releases / bugfixes until they become production ready.</p> <p>Here's how you can use them:</p> <ul> <li>Pip: <code>pip install --pre \"aws-lambda-powertools\"</code></li> <li>Poetry: <code>poetry add --allow-prereleases \"aws-lambda-powertools\" --group dev</code></li> <li>Pdm: <code>pdm add -dG --prerelease \"aws-lambda-powertools\"</code></li> </ul>"
        },
        {
            "location": "#extra-dependencies",
            "title": "Extra dependencies",
            "text": "<p>However, you will need additional dependencies if you are using any of the features below:</p> Feature Install Default dependency Tracer <code>pip install \"aws-lambda-powertools[tracer]\"</code> <code>aws-xray-sdk</code> Validation <code>pip install \"aws-lambda-powertools[validation]\"</code> <code>fastjsonschema</code> Parser <code>pip install \"aws-lambda-powertools[parser]\"</code> <code>pydantic</code> (v2) Data Masking <code>pip install \"aws-lambda-powertools[datamasking]\"</code> <code>aws-encryption-sdk</code>, <code>jsonpath-ng</code> All extra dependencies at once <code>pip install \"aws-lambda-powertools[all]\"</code> Two or more extra dependencies only, not all <code>pip install \"aws-lambda-powertools[tracer,parser,datamasking]\"</code>"
        },
        {
            "location": "#local-development",
            "title": "Local development",
            "text": "<p>Using Lambda Layer? Simply add <code>\"aws-lambda-powertools[all]\"</code> as a development dependency.</p> <p>Powertools for AWS Lambda (Python) relies on the AWS SDK bundled in the Lambda runtime. This helps us achieve an optimal package size and initialization. However, when developing locally, you need to install AWS SDK as a development dependency to support IDE auto-completion and to run your tests locally:</p> <ul> <li>Pip: <code>pip install \"aws-lambda-powertools[aws-sdk]\"</code></li> <li>Poetry: <code>poetry add \"aws-lambda-powertools[aws-sdk]\" --group dev</code></li> <li>Pdm: <code>pdm add -dG \"aws-lambda-powertools[aws-sdk]\"</code></li> </ul> <p>A word about dependency resolution</p> <p>In this context, <code>[aws-sdk]</code> is an alias to the <code>boto3</code> package. Due to dependency resolution, it'll either install:</p> <ul> <li>(A) the SDK version available in Lambda runtime</li> <li>(B) a more up-to-date version if another package you use also depends on <code>boto3</code>, for example Powertools for AWS Lambda (Python) Tracer</li> </ul>"
        },
        {
            "location": "#lambda-layer",
            "title": "Lambda Layer",
            "text": "<p>Lambda Layer is a .zip file archive that can contain additional code, pre-packaged dependencies, data,  or configuration files. We compile and optimize all dependencies for Python versions from 3.9 to 3.13, as well as for both arm64 and x86_64 architectures, to ensure compatibility. We also remove duplicate dependencies already available in the Lambda runtime to achieve the most optimal size.</p> x86_64arm64 Click to expand and copy any regional Lambda Layer ARN Python 3.9Python 3.10Python 3.11Python 3.12Python 3.13 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ca-west-1</code> arn:aws:lambda:ca-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ca-west-1</code> arn:aws:lambda:ca-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ca-west-1</code> arn:aws:lambda:ca-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ca-west-1</code> arn:aws:lambda:ca-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ca-west-1</code> arn:aws:lambda:ca-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 Click to expand and copy any regional Lambda Layer ARN Python 3.9Python 3.10Python 3.11Python 3.12Python 3.13 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <p>Want to inspect the contents of the Layer?</p> <p>The pre-signed URL to download this Lambda Layer will be within <code>Location</code> key in the CLI output. The CLI output will also contain the Powertools for AWS Lambda version it contains.</p> AWS CLI command to download Lambda Layer content<pre><code>aws lambda get-layer-version-by-arn --arn arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 --region eu-west-1\n</code></pre>"
        },
        {
            "location": "#sar",
            "title": "SAR",
            "text": "<p>Serverless Application Repository (SAR) App deploys a CloudFormation stack with a copy of our Lambda Layer in your AWS account and region.</p> <p>Compared with the public Layer ARN option, SAR allows you to choose a semantic version and deploys a Layer in your target account.</p> App ARN Python version Architecture aws-lambda-powertools-python-layer-v3-python39-x86-64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python39-x86-64 Python 3.9 X86_64 aws-lambda-powertools-python-layer-v3-python310-x86-64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python310-x86-64 Python 3.10 X86_64 aws-lambda-powertools-python-layer-v3-python311-x86-64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python311-x86-64 Python 3.11 X86_64 aws-lambda-powertools-python-layer-v3-python312-x86-64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python312-x86-64 Python 3.12 X86_64 aws-lambda-powertools-python-layer-v3-python313-x86-64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python313-x86-64 Python 3.13 X86_64 aws-lambda-powertools-python-layer-v3-python39-arm64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python39-arm64 Python 3.9 ARM64 aws-lambda-powertools-python-layer-v3-python310-arm64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python310-arm64 Python 3.10 ARM64 aws-lambda-powertools-python-layer-v3-python311-arm64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python311-arm64 Python 3.11 ARM64 aws-lambda-powertools-python-layer-v3-python312-arm64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python312-arm64 Python 3.12 ARM64 aws-lambda-powertools-python-layer-v3-python313-arm64 arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python313-arm64 Python 3.13 ARM64 Click to expand and copy SAR code snippets for popular frameworks <p>You can create a shared Lambda Layers stack and make this along with other account level layers stack.</p> SAMServerless frameworkCDKTerraform <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\n\nResources:\n  AwsLambdaPowertoolsPythonLayer:\n      Type: AWS::Serverless::Application\n      Properties:\n          Location:\n              ApplicationId: arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python313-x86-64\n              SemanticVersion: 3.0.9 # change to latest semantic version available in SAR\n\n  MyLambdaFunction:\n      Type: AWS::Serverless::Function\n      Properties:\n        Runtime: python3.13\n        Handler: app.lambda_handler\n        Layers:\n            # fetch Layer ARN from SAR App stack output\n            - !GetAtt AwsLambdaPowertoolsPythonLayer.Outputs.LayerVersionArn\n</code></pre> <pre><code>service: powertools-lambda\n\nprovider:\n  name: aws\n  runtime: python3.13\n  region: us-east-1\n\nfunctions:\n    powertools:\n      handler: lambda_function.lambda_handler\n      layers:\n          - !GetAtt AwsLambdaPowertoolsPythonLayer.Outputs.LayerVersionArn\n\nresources:\n  - AwsLambdaPowertoolsPythonLayer:\n      Type: AWS::Serverless::Application\n      Properties:\n        Location:\n          ApplicationId:  arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python313-x86-64\n          SemanticVersion: 3.0.9\n</code></pre> <pre><code>from aws_cdk import Stack, aws_lambda, aws_sam\nfrom constructs import Construct\n\nPOWERTOOLS_BASE_NAME = \"AWSLambdaPowertools\"\n# Find latest from github.com/aws-powertools/powertools-lambda-python/releases\nPOWERTOOLS_VER = \"3.0.9\"\nPOWERTOOLS_ARN = (\n    \"arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python313-x86-64\"\n)\n\n\nclass SampleApp(Stack):\n\n    def __init__(self, scope: Construct, id_: str) -&gt; None:\n        super().__init__(scope, id_)\n\n        # Launches SAR App as CloudFormation nested stack and return Lambda Layer\n        powertools_app = aws_sam.CfnApplication(\n            self,\n            f\"{POWERTOOLS_BASE_NAME}Application\",\n            location={\"applicationId\": POWERTOOLS_ARN, \"semanticVersion\": POWERTOOLS_VER},\n        )\n\n        powertools_layer_arn = powertools_app.get_att(\"Outputs.LayerVersionArn\").to_string()\n        powertools_layer_version = aws_lambda.LayerVersion.from_layer_version_arn(\n            self,\n            f\"{POWERTOOLS_BASE_NAME}\",\n            powertools_layer_arn,\n        )\n\n        aws_lambda.Function(\n            self,\n            \"sample-app-lambda\",\n            runtime=aws_lambda.Runtime.PYTHON_3_13,\n            function_name=\"sample-lambda\",\n            code=aws_lambda.Code.from_asset(\"lambda\"),\n            handler=\"hello.handler\",\n            layers=[powertools_layer_version],\n        )\n</code></pre> <p>Credits to Dani Comnea for providing the Terraform equivalent.</p> <pre><code>terraform {\n  required_version = \"~&gt; 0.13\"\n  required_providers {\n    aws = \"~&gt; 3.50.0\"\n  }\n}\n\nprovider \"aws\" {\n  region = \"us-east-1\"\n}\n\nresource \"aws_serverlessapplicationrepository_cloudformation_stack\" \"deploy_sar_stack\" {\n  name = \"aws-lambda-powertools-python-layer\"\n\n  application_id   = data.aws_serverlessapplicationrepository_application.sar_app.application_id\n  semantic_version = data.aws_serverlessapplicationrepository_application.sar_app.semantic_version\n  capabilities = [\n    \"CAPABILITY_IAM\",\n    \"CAPABILITY_NAMED_IAM\"\n  ]\n}\n\ndata \"aws_serverlessapplicationrepository_application\" \"sar_app\" {\n  application_id   = \"arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python313-x86-64\"\n  semantic_version = var.aws_powertools_version\n}\n\nvariable \"aws_powertools_version\" {\n  type        = string\n  default     = \"3.0.9\"\n  description = \"The Powertools for AWS Lambda (Python) release version\"\n}\n\noutput \"deployed_powertools_sar_version\" {\n  value = data.aws_serverlessapplicationrepository_application.sar_app.semantic_version\n}\n\n# Fetch Powertools for AWS Lambda (Python) Layer ARN from deployed SAR App\noutput \"aws_lambda_powertools_layer_arn\" {\n  value = aws_serverlessapplicationrepository_cloudformation_stack.deploy_sar_stack.outputs.LayerVersionArn\n}\n</code></pre> <p>Credits to mwarkentin for providing the scoped down IAM permissions below.</p> Least-privileged IAM permissions SAM example<pre><code>  AWSTemplateFormatVersion: \"2010-09-09\"\n  Resources:\n      PowertoolsLayerIamRole:\n        Type: \"AWS::IAM::Role\"\n        Properties:\n            AssumeRolePolicyDocument:\n                Version: \"2012-10-17\"\n                Statement:\n                    - Effect: \"Allow\"\n                      Principal:\n                        Service:\n                          - \"cloudformation.amazonaws.com\"\n                        Action:\n                          - \"sts:AssumeRole\"\n                Path: \"/\"\n\n      PowertoolsLayerIamPolicy:\n        Type: \"AWS::IAM::Policy\"\n        Properties:\n            PolicyName: PowertoolsLambdaLayerPolicy\n            PolicyDocument:\n                Version: \"2012-10-17\"\n                Statement:\n                    - Sid: CloudFormationTransform\n                      Effect: Allow\n                      Action: cloudformation:CreateChangeSet\n                      Resource:\n                        - arn:aws:cloudformation:us-east-1:aws:transform/Serverless-2016-10-31\n                    - Sid: GetCfnTemplate\n                      Effect: Allow\n                      Action:\n                        - serverlessrepo:CreateCloudFormationTemplate\n                        - serverlessrepo:GetCloudFormationTemplate\n                      Resource:\n                        # this is arn of the Powertools for AWS Lambda (Python) SAR app\n                        - arn:aws:serverlessrepo:eu-west-1:057560766410:applications/aws-lambda-powertools-python-layer-v3-python313-x86-64\n                    - Sid: S3AccessLayer\n                      Effect: Allow\n                      Action:\n                        - s3:GetObject\n                      Resource:\n                        # AWS publishes to an external S3 bucket locked down to your account ID\n                        # The below example is us publishing Powertools for AWS Lambda (Python)\n                        # Bucket: awsserverlessrepo-changesets-plntc6bfnfj\n                        # Key: *****/arn:aws:serverlessrepo:eu-west-1:057560766410:applications-aws-lambda-powertools-python-layer-v3-python313-x86-64-3.0.9/aeeccf50-****-****-****-*********\n                        - arn:aws:s3:::awsserverlessrepo-changesets-*/*\n                    - Sid: GetLayerVersion\n                      Effect: Allow\n                      Action:\n                        - lambda:PublishLayerVersion\n                        - lambda:GetLayerVersion\n                      Resource:\n                        - !Sub arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:layer:aws-lambda-powertools-python-layer-v3*\n            Roles:\n            - Ref: \"PowertoolsLayerIamRole\"\n</code></pre>"
        },
        {
            "location": "#quick-getting-started",
            "title": "Quick getting started",
            "text": "Hello world example using SAM CLI<pre><code>sam init --app-template hello-world-powertools-python --name sam-app --package-type Zip --runtime python3.11 --no-tracing\n</code></pre>"
        },
        {
            "location": "#features",
            "title": "Features",
            "text": "<p>Core utilities such as Tracing, Logging, Metrics, and Event Handler will be available across all Powertools for AWS Lambda languages. Additional utilities are subjective to each language ecosystem and customer demand.</p> Utility Description Tracing Decorators and utilities to trace Lambda function handlers, and both synchronous and asynchronous functions Logger Structured logging made easier, and decorator to enrich structured logging with key Lambda context details Metrics Custom Metrics created asynchronously via CloudWatch Embedded Metric Format (EMF) Event handler: AppSync AppSync event handler for Lambda Direct Resolver and Amplify GraphQL Transformer function Event handler: API Gateway, ALB and Lambda Function URL Amazon API Gateway REST/HTTP API and ALB event handler for Lambda functions invoked using Proxy integration, and Lambda Function URL Middleware factory Decorator factory to create your own middleware to run logic before, and after each Lambda invocation Parameters Retrieve parameter values from AWS Systems Manager Parameter Store, AWS Secrets Manager, or Amazon DynamoDB, and cache them for a specific amount of time Batch processing Handle partial failures for AWS SQS batch processing Typing Static typing classes to speedup development in your IDE Validation JSON Schema validator for inbound events and responses Event source data classes Data classes describing the schema of common Lambda event triggers Parser Data parsing and deep validation using Pydantic Idempotency Idempotent Lambda handler Data Masking Protect confidential data with easy removal or encryption Feature Flags A simple rule engine to evaluate when one or multiple features should be enabled depending on the input Streaming Streams datasets larger than the available memory as streaming data."
        },
        {
            "location": "#environment-variables",
            "title": "Environment variables",
            "text": "Info <p>Explicit parameters take precedence over environment variables</p> Environment variable Description Utility Default POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging All <code>\"service_undefined\"</code> POWERTOOLS_METRICS_NAMESPACE Sets namespace used for metrics Metrics <code>None</code> POWERTOOLS_METRICS_FUNCTION_NAME Function name used as dimension for the ColdStart metric metrics Metrics <code>None</code> POWERTOOLS_METRICS_DISABLED Disables all metrics emitted by Powertools metrics Metrics <code>None</code> POWERTOOLS_TRACE_DISABLED Explicitly disables tracing Tracing <code>false</code> POWERTOOLS_TRACER_CAPTURE_RESPONSE Captures Lambda or method return as metadata. Tracing <code>true</code> POWERTOOLS_TRACER_CAPTURE_ERROR Captures Lambda or method exception as metadata. Tracing <code>true</code> POWERTOOLS_TRACE_MIDDLEWARES Creates sub-segment for each custom middleware Middleware factory <code>false</code> POWERTOOLS_LOGGER_LOG_EVENT Logs incoming event Logging <code>false</code> POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling Logging <code>0</code> POWERTOOLS_LOG_DEDUPLICATION_DISABLED Disables log deduplication filter protection to use Pytest Live Log feature Logging <code>false</code> POWERTOOLS_PARAMETERS_MAX_AGE Adjust how long values are kept in cache (in seconds) Parameters <code>5</code> POWERTOOLS_PARAMETERS_SSM_DECRYPT Sets whether to decrypt or not values retrieved from AWS SSM Parameters Store Parameters <code>false</code> POWERTOOLS_DEV Increases verbosity across utilities Multiple; see POWERTOOLS_DEV effect below <code>false</code> POWERTOOLS_LOG_LEVEL Sets logging level Logging <code>INFO</code>"
        },
        {
            "location": "#optimizing-for-non-production-environments",
            "title": "Optimizing for non-production environments",
            "text": "<p>We will emit a warning when this feature is used to help you detect misuse in production.</p> <p>Whether you're prototyping locally or against a non-production environment, you can use <code>POWERTOOLS_DEV</code> to increase verbosity across multiple utilities.</p> <p>When <code>POWERTOOLS_DEV</code> is set to a truthy value (<code>1</code>, <code>true</code>), it'll have the following effects:</p> Utility Effect Logger Increase JSON indentation to 4. This will ease local debugging when running functions locally under emulators or direct calls while not affecting unit tests.  However, Amazon CloudWatch Logs view will degrade as each new line is treated as a new message. Event Handler Enable full traceback errors in the response, indent request/responses, and CORS in dev mode (<code>*</code>). Tracer Future-proof safety to disables tracing operations in non-Lambda environments. This already happens automatically in the Tracer utility. Metrics Disables Powertools metrics emission by default.  However, this can be overridden by explicitly setting POWERTOOLS_METRICS_DISABLED=false, which takes precedence over the dev mode setting."
        },
        {
            "location": "#debug-mode",
            "title": "Debug mode",
            "text": "<p>As a best practice for libraries, Powertools module logging statements are suppressed.</p> <p>When necessary, you can use <code>POWERTOOLS_DEBUG</code> environment variable to enable debugging. This will provide additional information on every internal operation.</p>"
        },
        {
            "location": "#support-powertools-for-aws-lambda-python",
            "title": "Support Powertools for AWS Lambda (Python)",
            "text": "<p>There are many ways you can help us gain future investments to improve everyone's experience:</p> <ul> <li> <p> Become a public reference</p> <p>Add your company name and logo on our landing page.</p> <p> GitHub Issue template</p> </li> <li> <p> Share your work</p> <p>Blog posts, video, and sample projects about Powertools for AWS Lambda.</p> <p> GitHub Issue template</p> </li> <li> <p> Join the community</p> <p>Connect, ask questions, and share what features you use.</p> <p> Discord invite</p> </li> </ul>"
        },
        {
            "location": "#becoming-a-reference-customer",
            "title": "Becoming a reference customer",
            "text": "<p>Knowing which companies are using this library is important to help prioritize the project internally. The following companies, among others, use Powertools:</p> <p>Alma Media</p> <p>Banxware</p> <p>Brsk</p> <p>BusPatrol</p> <p>Capital One</p> <p>Caylent</p> <p>CHS Inc.</p> <p>CPQi (Exadel Financial Services)</p> <p>CloudZero</p> <p>CyberArk</p> <p>Flyweight</p> <p>globaldatanet</p> <p>Guild</p> <p>IMS</p> <p>Jit Security</p> <p>LocalStack</p> <p>Propellor.ai</p> <p>Pushpay</p> <p>Recast</p> <p>TopSport</p> <p>Transformity</p> <p>Trek10</p> <p>Vertex Pharmaceuticals</p>"
        },
        {
            "location": "#using-lambda-layers",
            "title": "Using Lambda Layers",
            "text": "<p>Layers help us understand who uses Powertools for AWS Lambda (Python) in a non-intrusive way.</p> <p>When using Layers, you can add Powertools for AWS Lambda (Python) as a dev dependency to not impact the development process. For Layers, we pre-package all dependencies, compile and optimize for storage and both x86_64 and ARM architecture.</p>"
        },
        {
            "location": "#tenets",
            "title": "Tenets",
            "text": "<p>These are our core principles to guide our decision making.</p> <ul> <li>AWS Lambda only. We optimise for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported.</li> <li>Eases the adoption of best practices. The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional.</li> <li>Keep it lean. Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time.</li> <li>We strive for backwards compatibility. New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined.</li> <li>We work backwards from the community. We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs)</li> <li>Progressive. Utilities are designed to be incrementally adoptable for customers at any stage of their Serverless journey. They follow language idioms and their community’s common practices.</li> </ul>"
        },
        {
            "location": "automation/",
            "title": "Automation",
            "text": ""
        },
        {
            "location": "automation/#continuous-integration-practices",
            "title": "Continuous integration practices",
            "text": "<p>We adhere to industry recommendations from the OSSF Scorecard project, among others.</p> <p>Since all code changes require a pull request (PR) along with one or more reviewers, we automate quality and security checks before, during, and after a PR is merged to trunk (<code>develop</code>).</p> <p>We use a combination of tools coupled with peer review to increase its compound effect in detecting issues early.</p> <p>This is a snapshot of our automated checks at a glance.</p> <p></p>"
        },
        {
            "location": "automation/#pre-commit-checks",
            "title": "Pre-commit checks",
            "text": "<p>Pre-commit configuration.</p> <p>Pre-commit checks are crucial for a fast feedback loop while ensuring security practices at the individual change level.</p> <p>To prevent scenarios where these checks are intentionally omitted at the client side, we run at CI level too.</p> <p>These run locally only for changed files</p> <ul> <li>Merge conflict check. Checks for merge strings in each individual change accidentally left unresolved to prevent breakage.</li> <li>Code linting. Linter checks for industry quality standards and known bad practices that could lead to abuse.</li> <li>CloudFormation linting. <code>cfn-lint</code> ensures best practices at our documentation examples.</li> <li>Markdown linting. Primarily industry markdown practices at this stage.</li> <li>GitHub Actions linting. <code>actionlint</code> ensures workflows follow GitHub Actions security practices. It  guards against numerous leading practices to prevent common configuration mistakes, insecure inline scripts, among many others.</li> <li>Terraform linting. As of now, largely formatting until we increase our Terraform coverage in documentation examples.</li> <li>Secrets linting. Detects industry credentials that might be accidentally leaked in source code.</li> </ul>"
        },
        {
            "location": "automation/#pre-pull-request-checks",
            "title": "Pre-Pull Request checks",
            "text": "<p>For an improved contributing experience, most of our checks can run locally. For maintainers, this also means increased focus on reviewing actual value instead of standards and security malpractices that can be caught earlier.</p> <p>These are in addition to pre-commit checks.</p> <ul> <li>Static typing analysis. <code>mypy</code> checks for static typing annotations to prevent common bugs in Python that may or may not lead to abuse.</li> <li>Tests. We run <code>unit</code>, <code>functional</code>, and <code>performance</code> tests (see our definition). Besides breaking changes, we are investing in mutation testing to find additional sources of bugs and potential abuse.</li> <li>Security baseline. <code>bandit</code> detects common security issues defined by Python Code Quality Authority (PyCQA).</li> <li>Complexity baseline. We run a series of maintainability and cyclomatic checks to reduce code and logic complexity. This aids reviewers' cognitive overhead and long-term maintainers revisiting legacy code at a later date.</li> </ul>"
        },
        {
            "location": "automation/#pull-request-checks",
            "title": "Pull Request checks",
            "text": "<p>While we trust contributors and maintainers do go through pre-commit and pre-pull request due diligence, we verify them at CI level.</p> <p>Checks described earlier are omitted to improve reading experience.</p> <ul> <li>Semantic PR title. We enforce PR titles follow semantic naming, for example <code>chore(category): change</code>. This benefits contributors with a lower entry bar, no need for semantic commits. It also benefits everyone looking for an useful changelog message on what changed and where.</li> <li>Related issue check. Every change require an issue describing its needs. This enforces a PR has a related issue by blocking merge operations if missing.</li> <li>Acknowledgment check. Ensures PR template is used and every contributor is aware of code redistribution.</li> <li>Code coverage diff. Educates contributors and maintainers about code coverage differences for a given change.</li> <li>Contribution size check. Suggests contributors and maintainers to break up large changes (100-499 LOC) in smaller PRs. It helps reduce overlooking security and other practices due to increased cognitive overhead.</li> <li>Dependency vulnerability check. Verifies any dependency changes for common vulnerability exposures (CVEs), in addition to our daily check on any dependencies used (e.g., Python, Docker, Go, etc.)</li> <li>GitHub Actions security check. Enforces use of immutable 3rd-party GitHub Actions (_e.g., <code>actions/checkout@&lt;git-SHA&gt;_</code>) to prevent abuse. Upgrades are handled by a separate automated process that includes a maintainer review to also prevent unexpected behavior changes.</li> </ul>"
        },
        {
            "location": "automation/#after-merge-checks",
            "title": "After merge checks",
            "text": "<p>Checks described earlier are omitted to improve reading experience.</p> <p>We strike a balance in security and contribution experience. These automated checks take several minutes to complete. Failures are reviewed by a maintainer on-call and before a release.</p> <ul> <li>End-to-end tests. We run E2E with a high degree of parallelization. While it is designed to also run locally, it may incur AWS charges to contributors. For additional security, all infrastructure is ephemeral per change and per Python version.</li> <li>SAST check. GitHub CodeQL runs ~30m static analysis in the entire codebase.</li> <li>Security posture check. OSSF Scorecard runs numerous automated checks upon changes, and raises security alerts if OSSF security practices are no longer followed.</li> <li>Rebuild Changelog. We rebuild our entire changelog upon changes and create a PR for maintainers. This has the added benefit in keeping a protected branch while keeping removing error-prone tasks from maintainers.</li> <li>Stage documentation. We rebuild and deploy changes to the documentation to a staged version. This gives us safety that our docs can always be rebuilt, and ready to release to production when needed.</li> <li>Update draft release. We use Release Drafter to generate a portion of our release notes and to always keep a fresh draft upon changes. You can read our thoughts on a good quality release notes here (human readable changes + automation).</li> </ul>"
        },
        {
            "location": "automation/#continuous-deployment-practices",
            "title": "Continuous deployment practices",
            "text": "<p>We adhere to industry recommendations from the OSSF Scorecard project, among others.</p> <p>Releases are triggered by maintainers along with a reviewer - detailed info here. In addition to checks that run for every code change, our pipeline requires a manual approval before releasing.</p> <p>We use a combination of provenance and signed attestation for our builds, source code sealing, SAST scanners, Python specific static code analysis, ephemeral credentials that last a given job step, and more.</p> <p>This is a snapshot of our automated checks at a glance.</p> <p></p>"
        },
        {
            "location": "automation/#lambda-layer-pipeline",
            "title": "Lambda layer pipeline",
            "text": "<p>Lambda Layer is a .zip file archive that can contain additional code, pre-packaged dependencies, data, or configuration files. It provides a way to efficiently include libraries and other resources in your Lambda functions, promoting code reusability and reducing deployment package sizes.</p> <p>To build and deploy the Lambda Layers, we run a pipeline with the following steps:</p> <ul> <li>We fetch the latest PyPi release and use it as the source for our layer.</li> <li>We build Python versions ranging from 3.9 to 3.13 for x86_64 and arm64 architectures. This is necessary because we use pre-compiled libraries like Pydantic and Cryptography, which require specific Python versions for each layer.</li> <li>We provide layer distributions for both the x86_64 and arm64 architectures.</li> <li>For each Python version, we create a single CDK package containing both x86_64 and arm64 assets to optimize deployment performance.</li> </ul> <p>Next, we deploy these CDK Assets to the beta account across all AWS regions. Once the beta deployment is complete, we run:</p> <ul> <li>Canary Tests: Run thorough canary tests to assess stability and functionality</li> <li>Successful?: Deploy previous CDK Asset to production across all regions</li> <li>Failure?: Halt pipeline to investigate and remediate issues before redeploying</li> </ul> <pre><code>graph LR\n    Fetch[Fetch PyPi release] --&gt; P39[&lt;strong&gt;Python 3.9&lt;/strong&gt;]\n    Fetch --&gt; P310[&lt;strong&gt;Python 3.10&lt;/strong&gt;]\n    Fetch --&gt; P311[&lt;strong&gt;Python 3.11&lt;/strong&gt;]\n    Fetch --&gt; P312[&lt;strong&gt;Python 3.12&lt;/strong&gt;]\n    Fetch --&gt; P313[&lt;strong&gt;Python 3.13&lt;/strong&gt;]\n\n    subgraph build [\"LAYER BUILD\"]\n      P39 --&gt; P39x86[build x86_64]\n      P39 --&gt; P39arm64[build arm64]\n      P310 --&gt; P310x86[build x86_64]\n      P310 --&gt; P310arm64[build arm64]\n      P311 --&gt; P311x86[build x86_64]\n      P311 --&gt; P311arm64[build arm64]\n      P312 --&gt; P312x86[build x86_64]\n      P312 --&gt; P312arm64[build arm64]\n      P313 --&gt; P313x86[build x86_64]\n      P313 --&gt; P313arm64[build arm64]\n      P39x86 --&gt; CDKP2[CDK Package]\n      P39arm64 --&gt; CDKP2[CDK Package]\n      P310x86 --&gt; CDKP3[CDK Package]\n      P310arm64 --&gt; CDKP3[CDK Package]\n      P311x86 --&gt; CDKP4[CDK Package]\n      P311arm64 --&gt; CDKP4[CDK Package]\n      P312x86 --&gt; CDKP5[CDK Package]\n      P312arm64 --&gt; CDKP5[CDK Package]\n      P313x86 --&gt; CDKP6[CDK Package]\n      P313arm64 --&gt; CDKP6[CDK Package]\n    end\n\n    subgraph beta [\"BETA (all regions)\"]\n      CDKP2 --&gt; DeployBeta\n      CDKP3 --&gt; DeployBeta\n      CDKP4 --&gt; DeployBeta\n      CDKP5 --&gt; DeployBeta\n      CDKP6 --&gt; DeployBeta\n      DeployBeta --&gt; RunBetaCanary[\"Beta canary tests&lt;br&gt; &lt;i&gt;(all packages)&lt;/i&gt;\"]\n    end\n    subgraph prod [\"PROD (all regions)\"]\n        RunBetaCanary---|&lt;strong&gt;If successful&lt;/strong&gt;|DeployProd[Deploy to Prod]\n        DeployProd --&gt; RunProdCanary[\"Prod canary tests&lt;br&gt; &lt;i&gt;(all packages)&lt;/i&gt;\"]\n    end</code></pre>"
        },
        {
            "location": "changelog/",
            "title": "Changelog",
            "text": ""
        },
        {
            "location": "changelog/#unreleased",
            "title": "Unreleased",
            "text": ""
        },
        {
            "location": "changelog/#v3100-2025-04-08",
            "title": "v3.10.0 - 2025-04-08",
            "text": ""
        },
        {
            "location": "changelog/#maintenance",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 3.9.1a9 (#6422)</li> </ul>"
        },
        {
            "location": "changelog/#v390-2025-03-25",
            "title": "v3.9.0 - 2025-03-25",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes",
            "title": "Bug Fixes",
            "text": "<ul> <li>idempotency: include sk in error msgs when using composite key (#6325)</li> <li>metrics: ensure proper type conversion for <code>DD_FLUSH_TO_LOG</code> env var (#6280)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring",
            "title": "Code Refactoring",
            "text": "<ul> <li>data_classes: Add base class with common code (#6297)</li> <li>data_classes: remove duplicated code (#6288)</li> <li>data_classes: simplify nested data classes (#6289)</li> <li>tests: add LambdaContext type in tests (#6214)</li> </ul>"
        },
        {
            "location": "changelog/#documentation",
            "title": "Documentation",
            "text": "<ul> <li>homepage: update layer instructions link (#6242)</li> <li>public_reference: add Guild as a public reference (#6342)</li> </ul>"
        },
        {
            "location": "changelog/#features",
            "title": "Features",
            "text": "<ul> <li>data_classes: add API Gateway Websocket event (#6287)</li> <li>event_handler: add custom method for OpenAPI configuration (#6204)</li> <li>event_handler: add custom response validation in OpenAPI utility (#6189)</li> <li>general: make logger, tracer and metrics utilities aware of provisioned concurrency (#6324)</li> <li>metrics: allow change ColdStart function_name dimension (#6315)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_1",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 3.8.1a8 (#6307)</li> <li>ci: new pre-release 3.8.1a11 (#6340)</li> <li>ci: new pre-release 3.8.1a0 (#6244)</li> <li>ci: new pre-release 3.8.1a10 (#6332)</li> <li>ci: new pre-release 3.8.1a1 (#6250)</li> <li>ci: new pre-release 3.8.1a2 (#6253)</li> <li>ci: new pre-release 3.8.1a9 (#6322)</li> <li>ci: new pre-release 3.8.1a3 (#6259)</li> <li>ci: new pre-release 3.8.1a4 (#6268)</li> <li>ci: Fix SAR pipeline (#6313)</li> <li>ci: new pre-release 3.8.1a5 (#6276)</li> <li>ci: new pre-release 3.8.1a6 (#6290)</li> <li>ci: new pre-release 3.8.1a7 (#6298)</li> <li>deps: bump actions/setup-go from 5.3.0 to 5.4.0 (#6304)</li> <li>deps: bump actions/upload-artifact from 4.6.1 to 4.6.2 (#6302)</li> <li>deps: bump squidfunk/mkdocs-material from <code>047452c</code> to <code>479a06a</code> in /docs (#6261)</li> <li>deps: bump squidfunk/mkdocs-material from <code>479a06a</code> to <code>f226a2d</code> in /docs (#6279)</li> <li>deps: bump actions/download-artifact from 4.1.9 to 4.2.0 (#6294)</li> <li>deps: bump actions/download-artifact from 4.2.0 to 4.2.1 (#6303)</li> <li>deps: bump actions/setup-node from 4.2.0 to 4.3.0 (#6278)</li> <li>deps-dev: bump mkdocs-material from 9.6.7 to 9.6.8 (#6264)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.296 to 0.1.297 (#6281)</li> <li>deps-dev: bump boto3-stubs from 1.37.12 to 1.37.14 (#6282)</li> <li>deps-dev: bump aws-cdk from 2.1004.0 to 2.1005.0 (#6301)</li> <li>deps-dev: bump boto3-stubs from 1.37.15 to 1.37.16 (#6305)</li> <li>deps-dev: bump mkdocs-material from 9.6.8 to 9.6.9 (#6285)</li> <li>deps-dev: bump cfn-lint from 1.31.0 to 1.31.3 (#6306)</li> <li>deps-dev: bump ruff from 0.9.10 to 0.11.0 (#6273)</li> <li>deps-dev: bump sentry-sdk from 2.24.0 to 2.24.1 (#6339)</li> <li>deps-dev: bump aws-cdk-lib from 2.183.0 to 2.184.1 (#6272)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.183.0a0 to 2.184.1a0 (#6271)</li> <li>deps-dev: bump filelock from 3.17.0 to 3.18.0 (#6270)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.184.1a0 to 2.185.0a0 (#6317)</li> <li>deps-dev: bump boto3-stubs from 1.37.11 to 1.37.12 (#6266)</li> <li>deps-dev: bump cfn-lint from 1.31.3 to 1.32.0 (#6316)</li> <li>deps-dev: bump cfn-lint from 1.30.0 to 1.31.0 (#6296)</li> <li>deps-dev: bump cfn-lint from 1.29.1 to 1.30.0 (#6263)</li> <li>deps-dev: bump aws-cdk from 2.1003.0 to 2.1004.0 (#6262)</li> <li>deps-dev: bump boto3-stubs from 1.37.14 to 1.37.15 (#6295)</li> <li>deps-dev: bump boto3-stubs from 1.37.8 to 1.37.10 (#6248)</li> <li>deps-dev: bump mkdocstrings-python from 1.16.6 to 1.16.7 (#6319)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.182.0a0 to 2.183.0a0 (#6258)</li> <li>deps-dev: bump aws-cdk-lib from 2.182.0 to 2.183.0 (#6257)</li> <li>deps-dev: bump ruff from 0.11.0 to 0.11.1 (#6320)</li> <li>deps-dev: bump ruff from 0.11.1 to 0.11.2 (#6326)</li> <li>deps-dev: bump boto3-stubs from 1.37.10 to 1.37.11 (#6252)</li> <li>deps-dev: bump coverage from 7.7.0 to 7.7.1 (#6328)</li> <li>deps-dev: bump cfn-lint from 1.28.0 to 1.29.1 (#6249)</li> <li>deps-dev: bump boto3-stubs from 1.37.16 to 1.37.18 (#6327)</li> <li>deps-dev: bump sentry-sdk from 2.23.1 to 2.24.0 (#6329)</li> <li>deps-dev: bump boto3-stubs from 1.37.18 to 1.37.19 (#6337)</li> <li>deps-dev: bump mkdocstrings-python from 1.16.7 to 1.16.8 (#6338)</li> <li>deps-dev: bump ruff from 0.9.9 to 0.9.10 (#6241)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.295 to 0.1.296 (#6240)</li> <li>deps-dev: bump boto3-stubs from 1.37.7 to 1.37.8 (#6239)</li> <li>deps-dev: bump coverage from 7.6.12 to 7.7.0 (#6284)</li> <li>documentation: v2 end of support (#6343)</li> <li>logger: clear prev request buffers in manual mode (#6314)</li> </ul>"
        },
        {
            "location": "changelog/#v380-2025-03-07",
            "title": "v3.8.0 - 2025-03-07",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_1",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: revert regression when validating response (#6234)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_1",
            "title": "Code Refactoring",
            "text": "<ul> <li>tracer: fix capture_lambda_handler return type annotation (#6197)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_1",
            "title": "Documentation",
            "text": "<ul> <li>layer: Fix SSM parameter name for looking up layer ARN (#6221)</li> </ul>"
        },
        {
            "location": "changelog/#features_1",
            "title": "Features",
            "text": "<ul> <li>logger: add logger buffer feature (#6060)</li> <li>logger: add new logic to sample debug logs (#6142)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_2",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 3.7.1a2 (#6186)</li> <li>ci: new pre-release 3.7.1a0 (#6166)</li> <li>ci: new pre-release 3.7.1a6 (#6229)</li> <li>ci: new pre-release 3.7.1a7 (#6233)</li> <li>ci: new pre-release 3.7.1a1 (#6178)</li> <li>ci: enable SAR deployment (#6104)</li> <li>ci: new pre-release 3.7.1a5 (#6219)</li> <li>ci: new pre-release 3.7.1a3 (#6201)</li> <li>ci: new pre-release 3.7.1a4 (#6211)</li> <li>deps: bump docker/setup-qemu-action from 3.5.0 to 3.6.0 (#6190)</li> <li>deps: bump actions/download-artifact from 4.1.8 to 4.1.9 (#6174)</li> <li>deps: bump squidfunk/mkdocs-material from <code>2615302</code> to <code>047452c</code> in /docs (#6210)</li> <li>deps: bump docker/setup-qemu-action from 3.4.0 to 3.5.0 (#6176)</li> <li>deps: bump docker/setup-buildx-action from 3.9.0 to 3.10.0 (#6175)</li> <li>deps: bump datadog-lambda from 6.105.0 to 6.106.0 (#6218)</li> <li>deps: bump codecov/codecov-action from 5.3.1 to 5.4.0 (#6180)</li> <li>deps: bump pydantic-settings from 2.8.0 to 2.8.1 (#6182)</li> <li>deps: bump jinja2 from 3.1.5 to 3.1.6 in /docs (#6223)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.294 to 0.1.295 (#6207)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.293 to 0.1.294 (#6193)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.181.0a0 to 2.181.1a0 (#6194)</li> <li>deps-dev: bump ruff from 0.9.8 to 0.9.9 (#6195)</li> <li>deps-dev: bump aws-cdk-lib from 2.181.1 to 2.182.0 (#6222)</li> <li>deps-dev: bump testcontainers from 4.9.1 to 4.9.2 (#6225)</li> <li>deps-dev: bump cfn-lint from 1.26.1 to 1.27.0 (#6192)</li> <li>deps-dev: bump boto3-stubs from 1.37.2 to 1.37.3 (#6181)</li> <li>deps-dev: bump isort from 6.0.0 to 6.0.1 (#6183)</li> <li>deps-dev: bump boto3-stubs from 1.37.5 to 1.37.6 (#6227)</li> <li>deps-dev: bump ruff from 0.9.7 to 0.9.8 (#6184)</li> <li>deps-dev: bump boto3-stubs from 1.37.4 to 1.37.5 (#6217)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.181.1a0 to 2.182.0a0 (#6226)</li> <li>deps-dev: bump cfn-lint from 1.27.0 to 1.28.0 (#6228)</li> <li>deps-dev: bump pytest from 8.3.4 to 8.3.5 (#6206)</li> <li>deps-dev: bump boto3-stubs from 1.37.0 to 1.37.1 (#6170)</li> <li>deps-dev: bump boto3-stubs from 1.37.3 to 1.37.4 (#6205)</li> <li>deps-dev: bump mkdocs-material from 9.6.5 to 9.6.7 (#6208)</li> <li>deps-dev: bump aws-cdk from 2.1000.3 to 2.1001.0 (#6173)</li> <li>deps-dev: bump cfn-lint from 1.26.0 to 1.26.1 (#6169)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.180.0a0 to 2.181.0a0 (#6172)</li> <li>deps-dev: bump jinja2 from 3.1.5 to 3.1.6 (#6224)</li> <li>deps-dev: bump aws-cdk from 2.1002.0 to 2.1003.0 (#6232)</li> <li>deps-dev: bump cfn-lint from 1.25.1 to 1.26.0 (#6164)</li> <li>deps-dev: bump boto3-stubs from 1.36.26 to 1.37.0 (#6165)</li> <li>deps-dev: bump mypy-boto3-appconfigdata from 1.36.0 to 1.37.0 in the boto-typing group (#6163)</li> <li>deps-dev: bump aws-cdk from 2.1000.2 to 2.1000.3 (#6162)</li> <li>deps-dev: bump boto3-stubs from 1.37.6 to 1.37.7 (#6231)</li> <li>deps-dev: bump aws-cdk from 2.1001.0 to 2.1002.0 (#6209)</li> </ul>"
        },
        {
            "location": "changelog/#v370-2025-02-25",
            "title": "v3.7.0 - 2025-02-25",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_2",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: correctly pick powertools or custom handler in custom environments (#6083)</li> <li>openapi: validate response serialization when falsy (#6119)</li> <li>parser: fix data types for <code>sourceIPAddress</code> and <code>sequencer</code> fields in S3RecordModel Model (#6154)</li> <li>parser: fix EventBridgeModel when working with scheduled events (#6134)</li> <li>security: fix encryption_context handling in data masking operations (#6074)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_2",
            "title": "Documentation",
            "text": "<ul> <li>roadmap: update roadmap (#6077)</li> </ul>"
        },
        {
            "location": "changelog/#features_2",
            "title": "Features",
            "text": "<ul> <li>batch: raise exception for invalid batch event (#6088)</li> <li>event_handler: add support for defining OpenAPI examples in parameters (#6086)</li> <li>layers: add new comercial region ap-southeast-7 and mx-central-1 (#6109)</li> <li>parser: Event source dataclasses for IoT Core Registry Events (#6123)</li> <li>parser: Add IoT registry events models (#5892)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_3",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 3.6.1a9 (#6157)</li> <li>ci: new pre-release 3.6.1a8 (#6152)</li> <li>ci: new pre-release 3.6.1a4 (#6120)</li> <li>ci: new pre-release 3.6.1a3 (#6107)</li> <li>ci: new pre-release 3.6.1a0 (#6084)</li> <li>ci: new pre-release 3.6.1a5 (#6124)</li> <li>ci: new pre-release 3.6.1a7 (#6139)</li> <li>ci: new pre-release 3.6.1a1 (#6090)</li> <li>ci: new pre-release 3.6.1a6 (#6132)</li> <li>ci: new pre-release 3.6.1a2 (#6098)</li> <li>ci: remove python3.8 runtime when bootstrapping a new region (#6101)</li> <li>deps: bump squidfunk/mkdocs-material from <code>f5bcec4</code> to <code>2615302</code> in /docs (#6135)</li> <li>deps: bump squidfunk/mkdocs-material from <code>c62453b</code> to <code>f5bcec4</code> in /docs (#6087)</li> <li>deps: bump actions/upload-artifact from 4.6.0 to 4.6.1 (#6144)</li> <li>deps: bump aws-actions/configure-aws-credentials from 4.0.3 to 4.1.0 (#6082)</li> <li>deps: bump pydantic-settings from 2.7.1 to 2.8.0 (#6147)</li> <li>deps: bump ossf/scorecard-action from 2.4.0 to 2.4.1 (#6143)</li> <li>deps: bump slsa-framework/slsa-github-generator from 2.0.0 to 2.1.0 (#6155)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.21 to 3.0.22 (#6113)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.292 to 0.1.293 (#6129)</li> <li>deps-dev: bump sentry-sdk from 2.21.0 to 2.22.0 (#6114)</li> <li>deps-dev: bump bandit from 1.8.2 to 1.8.3 (#6117)</li> <li>deps-dev: bump mkdocstrings-python from 1.15.0 to 1.16.0 (#6118)</li> <li>deps-dev: bump boto3-stubs from 1.36.19 to 1.36.22 (#6116)</li> <li>deps-dev: bump cfn-lint from 1.24.0 to 1.25.1 (#6115)</li> <li>deps-dev: bump mkdocstrings-python from 1.16.0 to 1.16.1 (#6128)</li> <li>deps-dev: bump boto3-stubs from 1.36.22 to 1.36.24 (#6131)</li> <li>deps-dev: bump aws-cdk from 2.178.2 to 2.1000.2 (#6126)</li> <li>deps-dev: bump sentry-sdk from 2.20.0 to 2.21.0 (#6096)</li> <li>deps-dev: bump mkdocs-material from 9.6.3 to 9.6.4 (#6097)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.178.2a0 to 2.179.0a0 (#6127)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.178.1a0 to 2.178.2a0 (#6095)</li> <li>deps-dev: bump boto3-stubs from 1.36.17 to 1.36.19 (#6093)</li> <li>deps-dev: bump aws-cdk-lib from 2.178.2 to 2.179.0 (#6130)</li> <li>deps-dev: bump ruff from 0.9.6 to 0.9.7 (#6138)</li> <li>deps-dev: bump aws-cdk from 2.178.1 to 2.178.2 (#6089)</li> <li>deps-dev: bump mkdocs-material from 9.6.4 to 9.6.5 (#6136)</li> <li>deps-dev: bump boto3-stubs from 1.36.24 to 1.36.25 (#6137)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.179.0a0 to 2.180.0a0 (#6145)</li> <li>deps-dev: bump aws-cdk-lib from 2.179.0 to 2.180.0 (#6148)</li> <li>deps-dev: bump coverage from 7.6.11 to 7.6.12 (#6080)</li> <li>deps-dev: bump mkdocstrings-python from 1.14.6 to 1.15.0 (#6079)</li> <li>deps-dev: bump boto3-stubs from 1.36.16 to 1.36.17 (#6078)</li> <li>deps-dev: bump boto3-stubs from 1.36.25 to 1.36.26 (#6146)</li> <li>docs: enable sitemap generation (#6103)</li> </ul>"
        },
        {
            "location": "changelog/#v360-2025-02-11",
            "title": "v3.6.0 - 2025-02-11",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_3",
            "title": "Bug Fixes",
            "text": "<ul> <li>docs: typo in a service name in Event Handler (#5944)</li> <li>logger: child logger must respect log level (#5950)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_2",
            "title": "Code Refactoring",
            "text": "<ul> <li>metrics: Improve type annotations for metrics decorator (#6000)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_3",
            "title": "Documentation",
            "text": "<ul> <li>api: migrating the event handler utility to mkdocstrings (#6023)</li> <li>api: migrating the metrics utility to mkdocstrings (#6022)</li> <li>api: migrating the logger utility to mkdocstrings (#6021)</li> <li>api: migrating the Middleware Factory utility to mkdocstrings (#6019)</li> <li>api: migrating the tracer utility to mkdocstrings (#6017)</li> <li>api: migrating the batch utility to mkdocstrings (#6016)</li> <li>api: migrating the event source data classes utility to mkdocstrings (#6015)</li> <li>api: migrating the data masking utility to mkdocstrings (#6013)</li> <li>api: migrating the AppConfig utility to mkdocstrings (#6008)</li> <li>api: migrating the idempotency utility to mkdocstrings (#6007)</li> <li>api: migrating the jmespath utility to mkdocstrings (#6006)</li> <li>api: migrating the parameters utility to mkdocstrings (#6005)</li> <li>api: migrating the parser utility to mkdocstrings (#6004)</li> <li>api: migrating the streaming utility to mkdocstrings (#6003)</li> <li>api: migrating the typing utility to mkdocstrings (#5996)</li> <li>api: migrating the validation utility to mkdocstrings (#5972)</li> <li>layer: update layer version number - v3.5.0 (#5952)</li> </ul>"
        },
        {
            "location": "changelog/#features_3",
            "title": "Features",
            "text": "<ul> <li>data-masking: add custom mask functionalities (#5837)</li> <li>event_source: add class APIGatewayAuthorizerResponseWebSocket (#6058)</li> <li>logger: add clear_state method (#5956)</li> <li>metrics: disable metrics flush via environment variables (#6046)</li> <li>openapi: enhance support for tuple return type validation (#5997)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_4",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 3.5.1a9 (#6069)</li> <li>ci: new pre-release 3.5.1a0 (#5945)</li> <li>ci: new pre-release 3.5.1a1 (#5954)</li> <li>ci: new pre-release 3.5.1a8 (#6061)</li> <li>ci: install &amp; configure mkdocstrings plugin (#5959)</li> <li>ci: new pre-release 3.5.1a2 (#5970)</li> <li>ci: new pre-release 3.5.1a3 (#5998)</li> <li>ci: new pre-release 3.5.1a7 (#6044)</li> <li>ci: new pre-release 3.5.1a4 (#6018)</li> <li>ci: remove pdoc3 library (#6024)</li> <li>ci: new pre-release 3.5.1a5 (#6026)</li> <li>ci: add new script to bump Lambda layer version (#6001)</li> <li>ci: new pre-release 3.5.1a6 (#6033)</li> <li>deps: bump squidfunk/mkdocs-material from <code>471695f</code> to <code>7e841df</code> in /docs (#6012)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.20 to 3.0.21 (#6064)</li> <li>deps: bump actions/setup-python from 5.3.0 to 5.4.0 (#5960)</li> <li>deps: bump docker/setup-qemu-action from 3.2.0 to 3.3.0 (#5961)</li> <li>deps: bump codecov/codecov-action from 5.1.2 to 5.3.1 (#5964)</li> <li>deps: bump squidfunk/mkdocs-material from <code>7e841df</code> to <code>c62453b</code> in /docs (#6052)</li> <li>deps: bump actions/setup-node from 4.1.0 to 4.2.0 (#5963)</li> <li>deps: bump actions/upload-artifact from 4.5.0 to 4.6.0 (#5962)</li> <li>deps: bump release-drafter/release-drafter from 6.0.0 to 6.1.0 (#5976)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.18 to 3.0.20 (#5977)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.12.3 to 1.12.4 (#5980)</li> <li>deps: bump docker/setup-buildx-action from 3.8.0 to 3.9.0 (#6042)</li> <li>deps: bump docker/setup-qemu-action from 3.3.0 to 3.4.0 (#6043)</li> <li>deps: bump aws-actions/configure-aws-credentials from 4.0.2 to 4.0.3 (#5975)</li> <li>deps: bump squidfunk/mkdocs-material from <code>41942f7</code> to <code>471695f</code> in /docs (#5979)</li> <li>deps: bump actions/setup-go from 5.2.0 to 5.3.0 (#5978)</li> <li>deps-dev: bump aws-cdk from 2.178.0 to 2.178.1 (#6053)</li> <li>deps-dev: bump mkdocstrings-python from 1.13.0 to 1.14.2 (#6011)</li> <li>deps-dev: bump mkdocs-material from 9.6.1 to 9.6.2 (#6009)</li> <li>deps-dev: bump aws-cdk-lib from 2.178.0 to 2.178.1 (#6047)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.178.0a0 to 2.178.1a0 (#6048)</li> <li>deps-dev: bump boto3-stubs from 1.36.14 to 1.36.15 (#6049)</li> <li>deps-dev: bump boto3-stubs from 1.36.10 to 1.36.11 (#6010)</li> <li>deps-dev: bump boto3-stubs from 1.36.10 to 1.36.12 (#6014)</li> <li>deps-dev: bump ruff from 0.9.5 to 0.9.6 (#6066)</li> <li>deps-dev: bump mkdocstrings-python from 1.14.2 to 1.14.4 (#6025)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.177.0a0 to 2.178.0a0 (#6041)</li> <li>deps-dev: bump mkdocs-material from 9.5.50 to 9.6.1 (#5966)</li> <li>deps-dev: bump black from 24.10.0 to 25.1.0 (#5968)</li> <li>deps-dev: bump ruff from 0.9.3 to 0.9.4 (#5969)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.291 to 0.1.292 (#6051)</li> <li>deps-dev: bump cfn-lint from 1.22.7 to 1.23.1 (#5967)</li> <li>deps-dev: bump mkdocstrings-python from 1.14.5 to 1.14.6 (#6050)</li> <li>deps-dev: bump isort from 5.13.2 to 6.0.0 (#5965)</li> <li>deps-dev: bump ruff from 0.9.4 to 0.9.5 (#6039)</li> <li>deps-dev: bump aws-cdk-lib from 2.177.0 to 2.178.0 (#6038)</li> <li>deps-dev: bump mypy from 1.14.1 to 1.15.0 (#6028)</li> <li>deps-dev: bump mkdocstrings-python from 1.14.4 to 1.14.5 (#6032)</li> <li>deps-dev: bump cfn-lint from 1.23.1 to 1.24.0 (#6030)</li> <li>deps-dev: bump boto3-stubs from 1.36.14 to 1.36.16 (#6057)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.290 to 0.1.291 (#6031)</li> <li>deps-dev: bump boto3-stubs from 1.36.12 to 1.36.14 (#6029)</li> <li>deps-dev: bump mkdocs-material from 9.6.2 to 9.6.3 (#6065)</li> <li>deps-dev: bump coverage from 7.6.10 to 7.6.11 (#6067)</li> <li>deps-dev: bump aws-cdk from 2.177.0 to 2.178.0 (#6040)</li> <li>docs: enable privacy plugin in docs (#6036)</li> </ul>"
        },
        {
            "location": "changelog/#v350-2025-01-28",
            "title": "v3.5.0 - 2025-01-28",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_4",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: fixes typo in variable name <code>fronzen_openapi_extensions</code> (#5929)</li> <li>event_handler: add tests for PEP 563 compatibility with OpenAPI (#5886)</li> <li>event_handler: fix forward references resolution in OpenAPI (#5885)</li> <li>parser: make identitySource optional for ApiGatewayAuthorizerRequestV2 model (#5880)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_4",
            "title": "Documentation",
            "text": "<ul> <li>data_classes: improve Event Source Data Classes documentation (#5916)</li> <li>event_handler: demonstrate handling optional security routes (#5895)</li> <li>layer: update layer version number - v3.4.1 (#5869)</li> <li>parser: improve documentation with Pydantic best practices (#5925)</li> </ul>"
        },
        {
            "location": "changelog/#features_4",
            "title": "Features",
            "text": "<ul> <li>event_source: add AWS Transfer Family classes (#5912)</li> <li>idempotency: add support for custom Idempotency key prefix (#5898)</li> <li>logger: add context manager for logger keys (#5883)</li> <li>parser: add AWS Transfer Family model (#5906)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_5",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: adding poetry export plugin to support v2 (#5941)</li> <li>ci: adding poetry export plugin to support v2 (#5938)</li> <li>ci: adjust token permission (#5867)</li> <li>ci: new pre-release 3.4.2a0 (#5873)</li> <li>ci: make <code>pyproject.toml</code> fully compatible with Poetryv2 (#5902)</li> <li>ci: drop support for Python 3.8 (#5896)</li> <li>ci: update poetry version to v2 (#5936)</li> <li>ci: fix permissions for gh pages (#5866)</li> <li>deps: bump pydantic from 2.10.5 to 2.10.6 (#5918)</li> <li>deps: bump squidfunk/mkdocs-material from <code>ba73db5</code> to <code>41942f7</code> in /docs (#5890)</li> <li>deps-dev: bump boto3-stubs from 1.36.4 to 1.36.5 (#5919)</li> <li>deps-dev: bump boto3-stubs from 1.36.4 to 1.36.6 (#5923)</li> <li>deps-dev: bump cfn-lint from 1.22.6 to 1.22.7 (#5910)</li> <li>deps-dev: bump testcontainers from 3.7.1 to 4.9.1 (#5907)</li> <li>deps-dev: bump pytest-benchmark from 4.0.0 to 5.1.0 (#5909)</li> <li>deps-dev: bump aws-cdk from 2.176.0 to 2.177.0 (#5930)</li> <li>deps-dev: bump pytest-cov from 5.0.0 to 6.0.0 (#5908)</li> <li>deps-dev: bump aws-cdk-lib from 2.176.0 to 2.177.0 (#5931)</li> <li>deps-dev: bump cfn-lint from 1.22.5 to 1.22.6 (#5900)</li> <li>deps-dev: bump boto3-stubs from 1.36.6 to 1.36.7 (#5932)</li> <li>deps-dev: bump boto3-stubs from 1.36.2 to 1.36.3 (#5894)</li> <li>deps-dev: bump pytest-asyncio from 0.24.0 to 0.25.2 (#5920)</li> <li>deps-dev: bump mkdocs-material from 9.5.49 to 9.5.50 (#5889)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.175.1a0 to 2.176.0a0 (#5882)</li> <li>deps-dev: bump boto3-stubs from 1.36.1 to 1.36.2 (#5881)</li> <li>deps-dev: bump aws-cdk from 2.175.1 to 2.176.0 (#5878)</li> <li>deps-dev: bump ruff from 0.9.1 to 0.9.2 (#5877)</li> <li>deps-dev: bump aws-cdk-lib from 2.175.1 to 2.176.0 (#5876)</li> <li>deps-dev: bump mypy-boto3-appconfigdata from 1.35.93 to 1.36.0 in the boto-typing group (#5875)</li> <li>deps-dev: bump sentry-sdk from 2.19.2 to 2.20.0 (#5870)</li> <li>deps-dev: bump boto3-stubs from 1.35.97 to 1.35.99 (#5874)</li> <li>deps-dev: bump cfn-lint from 1.22.4 to 1.22.5 (#5872)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.176.0a0 to 2.177.0a0 (#5933)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.289 to 0.1.290 (#5917)</li> <li>deps-dev: bump ruff from 0.9.2 to 0.9.3 (#5911)</li> </ul>"
        },
        {
            "location": "changelog/#v341-2025-01-14",
            "title": "v3.4.1 - 2025-01-14",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_5",
            "title": "Bug Fixes",
            "text": "<ul> <li>appsync: enhance consistency for custom resolver field naming in AppSync (#5801)</li> <li>idempotency: add support for Optional type when serializing output (#5590)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_5",
            "title": "Documentation",
            "text": "<ul> <li>community: data masking blog post (#5831)</li> <li>home: fix date typo and shorten message. (#5798)</li> <li>layer: update layer version number - v3.4.0 (#5785)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_6",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 3.4.1a7 (#5816)</li> <li>ci: new pre-release 3.4.1a0 (#5783)</li> <li>ci: change token permissions (#5862)</li> <li>ci: change token permissions / update aws-credentials action (#5861)</li> <li>ci: fix dependency resolution (#5859)</li> <li>ci: fix dependency resolution (#5858)</li> <li>ci: change token permissions (#5865)</li> <li>ci: new pre-release 3.4.1a1 (#5789)</li> <li>ci: new pre-release 3.4.1a2 (#5791)</li> <li>ci: new pre-release 3.4.1a3 (#5794)</li> <li>ci: new pre-release 3.4.1a10 (#5845)</li> <li>ci: new pre-release 3.4.1a4 (#5796)</li> <li>ci: new pre-release 3.4.1a5 (#5807)</li> <li>ci: new pre-release 3.4.1a8 (#5818)</li> <li>ci: new pre-release 3.4.1a6 (#5813)</li> <li>ci: new pre-release 3.4.1a9 (#5822)</li> <li>deps: bump pydantic from 2.10.4 to 2.10.5 (#5848)</li> <li>deps: bump jinja2 from 3.1.4 to 3.1.5 in /docs (#5787)</li> <li>deps: bump pydantic-settings from 2.7.0 to 2.7.1 (#5815)</li> <li>deps-dev: bump ruff from 0.8.4 to 0.8.6 (#5833)</li> <li>deps-dev: bump boto3-stubs from 1.35.90 to 1.35.92 (#5827)</li> <li>deps-dev: bump aws-cdk from 2.173.4 to 2.174.0 (#5832)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.173.2a0 to 2.173.4a0 (#5811)</li> <li>deps-dev: bump cfn-lint from 1.22.2 to 1.22.3 (#5810)</li> <li>deps-dev: bump boto3-stubs from 1.35.89 to 1.35.90 (#5809)</li> <li>deps-dev: bump mypy from 1.14.0 to 1.14.1 (#5812)</li> <li>deps-dev: bump boto3-stubs from 1.35.92 to 1.35.93 (#5835)</li> <li>deps-dev: bump aws-cdk-lib from 2.173.4 to 2.174.1 (#5838)</li> <li>deps-dev: bump mypy-boto3-appconfigdata from 1.35.0 to 1.35.93 in the boto-typing group (#5840)</li> <li>deps-dev: bump aws-cdk-lib from 2.173.2 to 2.173.4 (#5803)</li> <li>deps-dev: bump aws-cdk from 2.173.2 to 2.173.4 (#5802)</li> <li>deps-dev: bump boto3-stubs from 1.35.87 to 1.35.89 (#5804)</li> <li>deps-dev: bump jinja2 from 3.1.4 to 3.1.5 (#5788)</li> <li>deps-dev: bump aws-cdk from 2.174.0 to 2.174.1 (#5841)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.173.4a0 to 2.174.1a0 (#5842)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.287 to 0.1.288 (#5793)</li> <li>deps-dev: bump boto3-stubs from 1.35.93 to 1.35.94 (#5844)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.288 to 0.1.289 (#5843)</li> <li>deps-dev: bump boto3-stubs from 1.35.94 to 1.35.95 (#5847)</li> <li>deps-dev: bump cfn-lint from 1.22.3 to 1.22.4 (#5849)</li> <li>deps-dev: bump boto3-stubs from 1.35.95 to 1.35.96 (#5850)</li> <li>deps-dev: bump boto3-stubs from 1.35.96 to 1.35.97 (#5852)</li> <li>deps-dev: bump boto3-stubs from 1.35.86 to 1.35.87 (#5786)</li> <li>deps-dev: bump aws-cdk from 2.174.1 to 2.175.0 (#5854)</li> <li>deps-dev: bump aws-cdk from 2.175.0 to 2.175.1 (#5863)</li> <li>deps-dev: bump boto3-stubs from 1.35.85 to 1.35.86 (#5780)</li> <li>deps-dev: bump mypy from 1.13.0 to 1.14.0 (#5779)</li> <li>deps-dev: bump ruff from 0.8.6 to 0.9.1 (#5853)</li> <li>deps-dev: bump aws-cdk-lib from 2.174.1 to 2.175.1 (#5856)</li> </ul>"
        },
        {
            "location": "changelog/#v340-2024-12-20",
            "title": "v3.4.0 - 2024-12-20",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_6",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: add overwrite to SSM workflow (#5775)</li> <li>docs: typo in homepage extra dependencies command (#5681)</li> <li>openapi: Allow values of any type in the examples of the Schema Object. (#5575)</li> <li>parser: remove AttributeError validation from event_parser function (#5742)</li> <li>parser: remove 'aws:' prefix from SelfManagedKafka model (#5584)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_3",
            "title": "Code Refactoring",
            "text": "<ul> <li>event_handler: add type annotations for router decorators (#5601)</li> <li>event_handler: add type annotations for <code>resolve</code> function (#5602)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_6",
            "title": "Documentation",
            "text": "<ul> <li>layer: update layer version number - v3.3.0 (#5562)</li> </ul>"
        },
        {
            "location": "changelog/#features_5",
            "title": "Features",
            "text": "<ul> <li>event_handler: mark API operation as deprecated for OpenAPI documentation (#5732)</li> <li>event_handler: add exception handling mechanism for AppSyncResolver (#5588)</li> <li>event_source: Extend CodePipeline Artifact Capabilities (#5448)</li> <li>layer: add new ap-southeast-5 region (#5769)</li> <li>metrics: warn when overwriting dimension (#5653)</li> <li>parser: add models for API GW Websockets events (#5597)</li> <li>ssm: Parameters for resolving to versioned layers (#5754)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_7",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 3.3.1a14 (#5713)</li> <li>ci: new pre-release 3.3.1a21 (#5773)</li> <li>ci: new pre-release 3.3.1a0 (#5565)</li> <li>ci: new pre-release 3.3.1a1 (#5577)</li> <li>ci: disable dry run in layer balancing workflow (#5768)</li> <li>ci: new pre-release 3.3.1a20 (#5766)</li> <li>ci: new pre-release 3.3.1a10 (#5679)</li> <li>ci: add workflow to balance layers per region (#5752)</li> <li>ci: new pre-release 3.3.1a9 (#5668)</li> <li>ci: new pre-release 3.3.1a19 (#5757)</li> <li>ci: new pre-release 3.3.1a8 (#5663)</li> <li>ci: adding missing region in matrix (#5777)</li> <li>ci: new pre-release 3.3.1a2 (#5585)</li> <li>ci: new pre-release 3.3.1a11 (#5688)</li> <li>ci: new pre-release 3.3.1a3 (#5598)</li> <li>ci: new pre-release 3.3.1a7 (#5656)</li> <li>ci: new pre-release 3.3.1a6 (#5650)</li> <li>ci: new pre-release 3.3.1a12 (#5697)</li> <li>ci: new pre-release 3.3.1a18 (#5739)</li> <li>ci: replace closed-issue-message action with powertools action (#5641)</li> <li>ci: new pre-release 3.3.1a17 (#5733)</li> <li>ci: new pre-release 3.3.1a4 (#5612)</li> <li>ci: new pre-release 3.3.1a13 (#5707)</li> <li>ci: new pre-release 3.3.1a16 (#5725)</li> <li>ci: remove poetry cache in quality check pipeline (#5626)</li> <li>ci: revert closed issue action update (#5637)</li> <li>ci: new pre-release 3.3.1a15 (#5720)</li> <li>ci: new pre-release 3.3.1a5 (#5639)</li> <li>deps: bump squidfunk/mkdocs-material from <code>ef0b45e</code> to <code>d063d84</code> in /docs (#5649)</li> <li>deps: bump pydantic from 2.10.0 to 2.10.1 (#5632)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.12.2 to 1.12.3 (#5709)</li> <li>deps: bump codecov/codecov-action from 5.0.3 to 5.0.7 (#5617)</li> <li>deps: bump actions/dependency-review-action from 4.4.0 to 4.5.0 (#5616)</li> <li>deps: bump squidfunk/mkdocs-material from <code>ce587cb</code> to <code>ef0b45e</code> in /docs (#5603)</li> <li>deps: bump squidfunk/mkdocs-material from <code>d063d84</code> to <code>3f571e7</code> in /docs (#5678)</li> <li>deps: bump redis from 5.2.0 to 5.2.1 (#5701)</li> <li>deps: bump pydantic-settings from 2.6.1 to 2.7.0 (#5735)</li> <li>deps: bump aws-actions/closed-issue-message from 80edfc24bdf1283400eb04d20a8a605ae8bf7d48 to 37548691e7cc75ba58f85c9f873f9eee43590449 (#5606)</li> <li>deps: bump pydantic from 2.9.2 to 2.10.0 (#5611)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.17 to 3.0.18 (#5743)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.16 to 3.0.17 (#5643)</li> <li>deps: bump squidfunk/mkdocs-material from <code>3f571e7</code> to <code>d485eb6</code> in /docs (#5710)</li> <li>deps: bump codecov/codecov-action from 5.0.7 to 5.1.0 (#5692)</li> <li>deps: bump pydantic from 2.10.1 to 2.10.2 (#5654)</li> <li>deps: bump squidfunk/mkdocs-material from <code>d485eb6</code> to <code>ba73db5</code> in /docs (#5746)</li> <li>deps: bump docker/setup-buildx-action from 3.7.1 to 3.8.0 (#5744)</li> <li>deps: bump datadog-lambda from 6.101.0 to 6.102.0 (#5570)</li> <li>deps: bump pydantic from 2.10.2 to 2.10.3 (#5682)</li> <li>deps: bump aws-encryption-sdk from 3.3.0 to 4.0.0 (#5564)</li> <li>deps: bump pydantic from 2.10.3 to 2.10.4 (#5760)</li> <li>deps: bump actions/upload-artifact from 4.4.3 to 4.5.0 (#5763)</li> <li>deps: bump codecov/codecov-action from 5.1.1 to 5.1.2 (#5764)</li> <li>deps: bump codecov/codecov-action from 4.6.0 to 5.0.2 (#5567)</li> <li>deps: bump fastjsonschema from 2.20.0 to 2.21.1 (#5676)</li> <li>deps: bump datadog-lambda from 6.102.0 to 6.104.0 (#5631)</li> <li>deps: bump codecov/codecov-action from 5.1.0 to 5.1.1 (#5703)</li> <li>deps: bump codecov/codecov-action from 5.0.2 to 5.0.3 (#5592)</li> <li>deps-dev: bump httpx from 0.27.2 to 0.28.0 (#5665)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.171.0a0 to 2.171.1a0 (#5666)</li> <li>deps-dev: bump aws-cdk from 2.171.0 to 2.171.1 (#5662)</li> <li>deps-dev: bump aws-cdk-lib from 2.171.0 to 2.171.1 (#5661)</li> <li>deps-dev: bump boto3-stubs from 1.35.69 to 1.35.71 (#5660)</li> <li>deps-dev: bump cfn-lint from 1.20.0 to 1.20.1 (#5659)</li> <li>deps-dev: bump mkdocs-material from 9.5.46 to 9.5.47 (#5677)</li> <li>deps-dev: bump cfn-lint from 1.20.1 to 1.20.2 (#5686)</li> <li>deps-dev: bump boto3-stubs from 1.35.71 to 1.35.74 (#5691)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.284 to 0.1.285 (#5642)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.170.0a0 to 2.171.0a0 (#5655)</li> <li>deps-dev: bump ruff from 0.8.1 to 0.8.2 (#5693)</li> <li>deps-dev: bump pytest from 8.3.3 to 8.3.4 (#5695)</li> <li>deps-dev: bump mkdocs-material from 9.5.45 to 9.5.46 (#5645)</li> <li>deps-dev: bump sentry-sdk from 2.19.0 to 2.19.1 (#5694)</li> <li>deps-dev: bump aws-cdk-lib from 2.170.0 to 2.171.0 (#5647)</li> <li>deps-dev: bump aws-cdk from 2.170.0 to 2.171.0 (#5648)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.285 to 0.1.287 (#5685)</li> <li>deps-dev: bump boto3-stubs from 1.35.67 to 1.35.69 (#5652)</li> <li>deps-dev: bump sentry-sdk from 2.19.1 to 2.19.2 (#5699)</li> <li>deps-dev: bump ruff from 0.7.4 to 0.8.0 (#5630)</li> <li>deps-dev: bump types-python-dateutil from 2.9.0.20241003 to 2.9.0.20241206 (#5700)</li> <li>deps-dev: bump httpx from 0.28.0 to 0.28.1 (#5702)</li> <li>deps-dev: bump aws-cdk from 2.171.1 to 2.172.0 (#5712)</li> <li>deps-dev: bump cfn-lint from 1.20.2 to 1.21.0 (#5711)</li> <li>deps-dev: bump boto3-stubs from 1.35.76 to 1.35.77 (#5716)</li> <li>deps-dev: bump aws-cdk-lib from 2.171.1 to 2.172.0 (#5719)</li> <li>deps-dev: bump cfn-lint from 1.21.0 to 1.22.0 (#5718)</li> <li>deps-dev: bump aws-cdk from 2.169.0 to 2.170.0 (#5628)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.167.2a0 to 2.170.0a0 (#5629)</li> <li>deps-dev: bump boto3-stubs from 1.35.77 to 1.35.78 (#5723)</li> <li>deps-dev: bump sentry-sdk from 2.18.0 to 2.19.0 (#5633)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.171.1a0 to 2.172.0a0 (#5724)</li> <li>deps-dev: bump aws-cdk from 2.172.0 to 2.173.0 (#5727)</li> <li>deps-dev: bump mkdocs-material from 9.5.44 to 9.5.45 (#5610)</li> <li>deps-dev: bump ruff from 0.8.2 to 0.8.3 (#5728)</li> <li>deps-dev: bump boto3-stubs from 1.35.64 to 1.35.67 (#5621)</li> <li>deps-dev: bump aws-cdk-lib from 2.167.2 to 2.170.0 (#5622)</li> <li>deps-dev: bump cfn-lint from 1.22.0 to 1.22.1 (#5729)</li> <li>deps-dev: bump aws-cdk from 2.167.2 to 2.169.0 (#5618)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.282 to 0.1.284 (#5607)</li> <li>deps-dev: bump boto3-stubs from 1.35.78 to 1.35.80 (#5730)</li> <li>deps-dev: bump aws-cdk-lib from 2.172.0 to 2.173.0 (#5731)</li> <li>deps-dev: bump mkdocs-material from 9.5.47 to 9.5.48 (#5717)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.172.0a0 to 2.173.0a0 (#5736)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.167.1a0 to 2.167.2a0 (#5619)</li> <li>deps-dev: bump boto3-stubs from 1.35.80 to 1.35.81 (#5750)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.281 to 0.1.282 (#5594)</li> <li>deps-dev: bump cfn-lint from 1.19.0 to 1.20.0 (#5595)</li> <li>deps-dev: bump aws-cdk from 2.167.1 to 2.167.2 (#5593)</li> <li>deps-dev: bump cfn-lint from 1.22.1 to 1.22.2 (#5749)</li> <li>deps-dev: bump aws-cdk-lib from 2.167.1 to 2.167.2 (#5596)</li> <li>deps-dev: bump aws-cdk from 2.173.0 to 2.173.1 (#5745)</li> <li>deps-dev: bump boto3-stubs from 1.35.63 to 1.35.64 (#5582)</li> <li>deps-dev: bump mkdocs-material from 9.5.48 to 9.5.49 (#5748)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.167.0a0 to 2.167.1a0 (#5583)</li> <li>deps-dev: bump aws-cdk-lib from 2.173.0 to 2.173.1 (#5747)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.173.0a0 to 2.173.1a0 (#5755)</li> <li>deps-dev: bump aws-cdk from 2.173.1 to 2.173.2 (#5762)</li> <li>deps-dev: bump boto3-stubs from 1.35.81 to 1.35.84 (#5765)</li> <li>deps-dev: bump boto3-stubs from 1.35.60 to 1.35.63 (#5581)</li> <li>deps-dev: bump ruff from 0.8.0 to 0.8.1 (#5671)</li> <li>deps-dev: bump aws-cdk from 2.167.0 to 2.167.1 (#5572)</li> <li>deps-dev: bump boto3-stubs from 1.35.84 to 1.35.85 (#5770)</li> <li>deps-dev: bump ruff from 0.7.3 to 0.7.4 (#5569)</li> <li>deps-dev: bump aws-cdk-lib from 2.167.0 to 2.167.1 (#5568)</li> <li>deps-dev: bump ruff from 0.8.3 to 0.8.4 (#5772)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.173.1a0 to 2.173.2a0 (#5771)</li> <li>deps-dev: bump aws-cdk-lib from 2.173.1 to 2.173.2 (#5759)</li> <li>layers: balance Python 3.13 layers in GovCloud partition (#5579)</li> </ul>"
        },
        {
            "location": "changelog/#v330-2024-11-14",
            "title": "v3.3.0 - 2024-11-14",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_7",
            "title": "Bug Fixes",
            "text": "<ul> <li>appsync: make contextual data accessible for async functions (#5317)</li> <li>ci: Update output to something easily copy/pasteable (#5435)</li> <li>ci: remove space (#5433)</li> <li>metrics: add warning for invalid dimension values; prevent their addition to EMF blobs (#5542)</li> <li>parameters: fix force_fetch feature when working with get_parameters (#5515)</li> <li>parser: support TypeAdapter instances as models (#5535)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_7",
            "title": "Documentation",
            "text": "<ul> <li>layer: update layer version number - v3.2.0 (#5426)</li> <li>parser: change parser documentation (#5262)</li> </ul>"
        },
        {
            "location": "changelog/#features_6",
            "title": "Features",
            "text": "<ul> <li>event_handler: mutualTLS Security Scheme for OpenAPI (#5484)</li> <li>layers: introduce new CDK Python constructor for Powertools Lambda Layer (#5320)</li> <li>runtime: add Python 3.13 support (#5527)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_8",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: Bump CDK version to build layers and fix imports (#5555)</li> <li>ci: new pre-release 3.2.1a0 (#5434)</li> <li>ci: new pre-release 3.2.1a15 (#5551)</li> <li>ci: new pre-release 3.2.1a14 (#5545)</li> <li>ci: fix imports to build Lambda layer (#5557)</li> <li>ci: new pre-release 3.2.1a1 (#5443)</li> <li>ci: bump minimum required pydantic version (#5446)</li> <li>ci: new pre-release 3.2.1a2 (#5456)</li> <li>ci: new pre-release 3.2.1a12 (#5524)</li> <li>ci: new pre-release 3.2.1a3 (#5465)</li> <li>ci: new pre-release 3.2.1a4 (#5470)</li> <li>ci: new pre-release 3.2.1a5 (#5473)</li> <li>ci: new pre-release 3.2.1a11 (#5517)</li> <li>ci: new pre-release 3.2.1a6 (#5480)</li> <li>ci: new pre-release 3.2.1a7 (#5488)</li> <li>ci: new pre-release 3.2.1a10 (#5509)</li> <li>ci: new pre-release 3.2.1a8 (#5497)</li> <li>ci: new pre-release 3.2.1a9 (#5504)</li> <li>ci: new pre-release 3.2.1a13 (#5537)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.10.3 to 1.11.0 (#5477)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.15 to 3.0.16 (#5499)</li> <li>deps: bump actions/dependency-review-action from 4.3.4 to 4.3.5 (#5431)</li> <li>deps: bump actions/setup-python from 5.2.0 to 5.3.0 (#5529)</li> <li>deps: bump datadog-lambda from 6.99.0 to 6.100.0 (#5491)</li> <li>deps: bump actions/checkout from 4.2.1 to 4.2.2 (#5438)</li> <li>deps: bump actions/checkout from 4.2.0 to 4.2.2 (#5531)</li> <li>deps: bump actions/setup-node from 4.0.4 to 4.1.0 (#5450)</li> <li>deps: bump squidfunk/mkdocs-material from <code>2c2802b</code> to <code>ce587cb</code> in /docs (#5507)</li> <li>deps: bump actions/setup-python from 5.2.0 to 5.3.0 (#5449)</li> <li>deps: bump redis from 5.1.1 to 5.2.0 (#5454)</li> <li>deps: bump docker/setup-buildx-action from 2.4.1 to 3.7.1 (#5530)</li> <li>deps: bump squidfunk/mkdocs-material from <code>31eb7f7</code> to <code>2c2802b</code> in /docs (#5487)</li> <li>deps: bump docker/setup-qemu-action from 2.1.0 to 3.2.0 (#5528)</li> <li>deps: bump actions/dependency-review-action from 4.3.5 to 4.4.0 (#5469)</li> <li>deps: bump datadog-lambda from 6.100.0 to 6.101.0 (#5513)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.11.0 to 1.12.1 (#5514)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.12.1 to 1.12.2 (#5519)</li> <li>deps-dev: bump sentry-sdk from 2.17.0 to 2.18.0 (#5502)</li> <li>deps-dev: bump boto3-stubs from 1.35.51 to 1.35.52 (#5478)</li> <li>deps-dev: bump mkdocs-material from 9.5.43 to 9.5.44 (#5506)</li> <li>deps-dev: bump cfn-lint from 1.18.2 to 1.18.3 (#5479)</li> <li>deps-dev: bump boto3-stubs from 1.35.49 to 1.35.51 (#5472)</li> <li>deps-dev: bump aws-cdk from 2.165.0 to 2.166.0 (#5520)</li> <li>deps-dev: bump aws-cdk-lib from 2.165.0 to 2.166.0 (#5522)</li> <li>deps-dev: bump boto3-stubs from 1.35.52 to 1.35.53 (#5485)</li> <li>deps-dev: bump cfn-lint from 1.18.1 to 1.18.2 (#5468)</li> <li>deps-dev: bump boto3-stubs from 1.35.54 to 1.35.56 (#5523)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.163.1a0 to 2.164.1a0 (#5467)</li> <li>deps-dev: bump mkdocs-material from 9.5.42 to 9.5.43 (#5486)</li> <li>deps-dev: bump aws-cdk from 2.164.0 to 2.164.1 (#5462)</li> <li>deps-dev: bump boto3-stubs from 1.35.46 to 1.35.49 (#5460)</li> <li>deps-dev: bump aws-cdk-lib from 2.164.0 to 2.164.1 (#5459)</li> <li>deps-dev: bump ruff from 0.7.0 to 0.7.1 (#5451)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.278 to 0.1.279 (#5512)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.165.0a0 to 2.166.0a0 (#5533)</li> <li>deps-dev: bump aws-cdk-lib from 2.163.1 to 2.164.0 (#5453)</li> <li>deps-dev: bump aws-cdk from 2.163.1 to 2.164.0 (#5452)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.279 to 0.1.281 (#5548)</li> <li>deps-dev: bump aws-cdk-lib from 2.164.1 to 2.165.0 (#5490)</li> <li>deps-dev: bump boto3-stubs from 1.35.53 to 1.35.54 (#5493)</li> <li>deps-dev: bump aws-cdk from 2.164.1 to 2.165.0 (#5494)</li> <li>deps-dev: bump mypy from 1.11.2 to 1.13.0 (#5440)</li> <li>deps-dev: bump ruff from 0.7.2 to 0.7.3 (#5532)</li> <li>deps-dev: bump boto3-stubs from 1.35.56 to 1.35.58 (#5540)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.162.1a0 to 2.163.1a0 (#5441)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.277 to 0.1.278 (#5439)</li> <li>deps-dev: bump cfn-lint from 1.18.3 to 1.18.4 (#5501)</li> <li>deps-dev: bump cfn-lint from 1.18.4 to 1.19.0 (#5544)</li> <li>deps-dev: bump ruff from 0.7.1 to 0.7.2 (#5492)</li> <li>deps-dev: bump aws-cdk-lib from 2.162.1 to 2.163.1 (#5429)</li> <li>deps-dev: bump boto3-stubs from 1.35.45 to 1.35.46 (#5430)</li> <li>deps-dev: bump aws-cdk from 2.162.1 to 2.163.1 (#5432)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.164.1a0 to 2.165.0a0 (#5500)</li> <li>deps-dev: bump xenon from 0.9.1 to 0.9.3 (#5428)</li> <li>deps-dev: bump boto3-stubs from 1.35.58 to 1.35.59 (#5549)</li> <li>layers: add pydantic-settings package to v3 Layer (#5516)</li> </ul>"
        },
        {
            "location": "changelog/#v320-2024-10-22",
            "title": "v3.2.0 - 2024-10-22",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_8",
            "title": "Bug Fixes",
            "text": "<ul> <li>test command in verify step (#5381)</li> <li>ci: Tables are nicer (#5416)</li> <li>ci: GovCloud layer verification (#5382)</li> <li>ci: Update partition name (#5380)</li> <li>layer: update partition name in the GovCloud workflow (#5379)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_8",
            "title": "Documentation",
            "text": "<ul> <li>Add GovCloud layer info (#5414)</li> <li>event_handler: add Terraform payload info for API Gateway HTTP API (#5351)</li> <li>examples: temporarily fix SAR version to v2.x (#5360)</li> <li>layer: update layer version number (#5344)</li> <li>upgrade_guide: update Lambda layer name (#5347)</li> </ul>"
        },
        {
            "location": "changelog/#features_7",
            "title": "Features",
            "text": "<ul> <li>ci: GovCloud Layer Workflow (#5261)</li> <li>logger: add thread safe logging keys (#5141)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_9",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 3.1.1a0 (#5353)</li> <li>ci: Add dump of govcloud layer info in verify step (#5415)</li> <li>deps: bump squidfunk/mkdocs-material from <code>f9cb76d</code> to <code>0d4e687</code> in /docs (#5395)</li> <li>deps: bump actions/upload-artifact from 4.4.1 to 4.4.3 (#5357)</li> <li>deps: bump squidfunk/mkdocs-material from <code>8e8b333</code> to <code>f9cb76d</code> in /docs (#5366)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.14 to 3.0.15 (#5418)</li> <li>deps: bump jsonpath-ng from 1.6.1 to 1.7.0 (#5369)</li> <li>deps: bump squidfunk/mkdocs-material from <code>0d4e687</code> to <code>31eb7f7</code> in /docs (#5417)</li> <li>deps: bump actions/upload-artifact from 4.4.0 to 4.4.3 (#5373)</li> <li>deps-dev: bump boto3-stubs from 1.35.38 to 1.35.39 (#5370)</li> <li>deps-dev: bump boto3-stubs from 1.35.39 to 1.35.41 (#5392)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.161.1a0 to 2.162.1a0 (#5386)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.274 to 0.1.275 (#5406)</li> <li>deps-dev: bump boto3-stubs from 1.35.43 to 1.35.44 (#5407)</li> <li>deps-dev: bump cfn-lint from 1.17.2 to 1.18.1 (#5423)</li> <li>deps-dev: bump cfn-lint from 1.17.1 to 1.17.2 (#5408)</li> <li>deps-dev: bump aws-cdk-lib from 2.161.1 to 2.162.1 (#5371)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.273 to 0.1.274 (#5394)</li> <li>deps-dev: bump aws-cdk from 2.161.1 to 2.162.1 (#5372)</li> <li>deps-dev: bump boto3-stubs from 1.35.41 to 1.35.42 (#5397)</li> <li>deps-dev: bump cfn-lint from 1.16.1 to 1.17.1 (#5404)</li> <li>deps-dev: bump mkdocs-material from 9.5.40 to 9.5.41 (#5393)</li> <li>deps-dev: bump cfn-lint from 1.16.0 to 1.16.1 (#5363)</li> <li>deps-dev: bump boto3-stubs from 1.35.37 to 1.35.38 (#5364)</li> <li>deps-dev: bump mkdocs-material from 9.5.39 to 9.5.40 (#5365)</li> <li>deps-dev: bump ruff from 0.6.9 to 0.7.0 (#5403)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.275 to 0.1.277 (#5419)</li> <li>deps-dev: bump boto3-stubs from 1.35.42 to 1.35.43 (#5402)</li> <li>deps-dev: bump boto3-stubs from 1.35.36 to 1.35.37 (#5356)</li> <li>deps-dev: bump nox from 2024.4.15 to 2024.10.9 (#5355)</li> <li>deps-dev: bump mkdocs-material from 9.5.41 to 9.5.42 (#5420)</li> <li>deps-dev: bump boto3-stubs from 1.35.44 to 1.35.45 (#5421)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.161.0a0 to 2.161.1a0 (#5349)</li> <li>deps-dev: bump boto3-stubs from 1.35.35 to 1.35.36 (#5350)</li> <li>deps-dev: bump sentry-sdk from 2.15.0 to 2.16.0 (#5348)</li> <li>deps-dev: bump sentry-sdk from 2.16.0 to 2.17.0 (#5400)</li> <li>docs: remove layer callout from data masking docs (#5377)</li> </ul>"
        },
        {
            "location": "changelog/#v310-2024-10-08",
            "title": "v3.1.0 - 2024-10-08",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_9",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: Layer Rename Fix (#5291)</li> <li>ci: layer rename (#5283)</li> <li>idempotency: fix response hook invocation when function returns None (#5251)</li> <li>layer: reverting SSM parameter name (#5340)</li> <li>layers: rename Lambda layer name from x86 to x86_64 (#5226)</li> <li>parser: fallback to <code>validate_python</code> when using <code>type[Model]</code> and nested models (#5313)</li> <li>parser: revert a regression in v3 when raising ValidationError (#5259)</li> <li>parser: make size and etag optional for LifecycleExpiration events in S3 (#5250)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_4",
            "title": "Code Refactoring",
            "text": "<ul> <li>examples: fix issues reported by SonarCloud and Scorecard (#5315)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_9",
            "title": "Documentation",
            "text": "<ul> <li>idempotency: fix description in <code>Advanced</code> table (#5191)</li> <li>metrics: fix test references (#5265)</li> <li>public_reference: add Flyweight as a public reference (#5322)</li> <li>upgrade_guide: update upgrade guide with Pydantic information (#5316)</li> <li>v3: fix small things in the documentation (#5224)</li> <li>versioning: add v2 maintainance mode banner (#5240)</li> </ul>"
        },
        {
            "location": "changelog/#features_8",
            "title": "Features",
            "text": "<ul> <li>event_source: add CodeDeploy Lifecycle Hook event (#5219)</li> <li>openapi: enable direct list input in Examples model (#5318)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_10",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 3.0.1a7 (#5299)</li> <li>ci: new pre-release 3.0.1a3 (#5270)</li> <li>ci: new pre-release 3.0.1a4 (#5277)</li> <li>ci: new pre-release 3.0.1a2 (#5258)</li> <li>ci: new pre-release 3.0.1a5 (#5288)</li> <li>ci: new pre-release 3.0.1a9 (#5337)</li> <li>ci: new pre-release 3.0.1a8 (#5323)</li> <li>ci: new pre-release 3.0.1a0 (#5220)</li> <li>ci: new pre-release 3.0.1a1 (#5247)</li> <li>ci: new pre-release 3.0.1a6 (#5293)</li> <li>deps: bump actions/download-artifact from 4.1.7 to 4.1.8 (#5203)</li> <li>deps: bump squidfunk/mkdocs-material from <code>22a429f</code> to <code>08fbf58</code> in /docs (#5243)</li> <li>deps: bump docker/setup-buildx-action from 3.6.1 to 3.7.0 (#5298)</li> <li>deps: bump actions/checkout from 4.1.7 to 4.2.0 (#5244)</li> <li>deps: bump actions/setup-node from 4.0.3 to 4.0.4 (#5186)</li> <li>deps: bump docker/setup-buildx-action from 3.7.0 to 3.7.1 (#5310)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.10.2 to 1.10.3 (#5311)</li> <li>deps: bump squidfunk/mkdocs-material from <code>a2e3a31</code> to <code>22a429f</code> in /docs (#5201)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.10.1 to 1.10.2 (#5202)</li> <li>deps: bump actions/checkout from 4.2.0 to 4.2.1 (#5329)</li> <li>deps: bump squidfunk/mkdocs-material from <code>08fbf58</code> to <code>7aea359</code> in /docs (#5253)</li> <li>deps: bump actions/setup-python from 5.1.0 to 5.2.0 (#5204)</li> <li>deps: bump codecov/codecov-action from 4.5.0 to 4.6.0 (#5287)</li> <li>deps: bump redis from 5.1.0 to 5.1.1 (#5331)</li> <li>deps: bump actions/checkout from 4.1.6 to 4.1.7 (#5206)</li> <li>deps: bump actions/upload-artifact from 4.4.0 to 4.4.1 (#5328)</li> <li>deps: bump actions/upload-artifact from 4.3.3 to 4.4.0 (#5217)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.12 to 3.0.13 (#5276)</li> <li>deps: bump redis from 5.0.8 to 5.1.0 (#5264)</li> <li>deps: bump datadog-lambda from 6.98.0 to 6.99.0 (#5333)</li> <li>deps: bump squidfunk/mkdocs-material from <code>7aea359</code> to <code>8e8b333</code> in /docs (#5272)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.13 to 3.0.14 (#5330)</li> <li>deps: bump docker/setup-qemu-action from 3.0.0 to 3.2.0 (#5205)</li> <li>deps-dev: bump mkdocs-material from 9.5.38 to 9.5.39 (#5273)</li> <li>deps-dev: bump cfn-lint from 1.15.1 to 1.15.2 (#5274)</li> <li>deps-dev: bump boto3-stubs from 1.35.28 to 1.35.29 (#5263)</li> <li>deps-dev: bump boto3-stubs from 1.35.34 to 1.35.35 (#5334)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.270 to 0.1.271 (#5284)</li> <li>deps-dev: bump mkdocs-material from 9.5.37 to 9.5.38 (#5255)</li> <li>deps-dev: bump ruff from 0.6.7 to 0.6.8 (#5254)</li> <li>deps-dev: bump boto3-stubs from 1.35.27 to 1.35.28 (#5256)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.269 to 0.1.270 (#5257)</li> <li>deps-dev: bump sentry-sdk from 2.14.0 to 2.15.0 (#5285)</li> <li>deps-dev: bump boto3-stubs from 1.35.29 to 1.35.31 (#5286)</li> <li>deps-dev: bump boto3-stubs from 1.35.31 to 1.35.32 (#5292)</li> <li>deps-dev: bump aws-cdk-lib from 2.161.0 to 2.161.1 (#5335)</li> <li>deps-dev: bump boto3-stubs from 1.35.32 to 1.35.33 (#5295)</li> <li>deps-dev: bump types-python-dateutil from 2.9.0.20240906 to 2.9.0.20241003 (#5296)</li> <li>deps-dev: bump boto3-stubs from 1.35.26 to 1.35.27 (#5242)</li> <li>deps-dev: bump mkdocs-material from 9.5.36 to 9.5.37 (#5241)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.271 to 0.1.272 (#5297)</li> <li>deps-dev: bump boto3-stubs from 1.35.25 to 1.35.26 (#5234)</li> <li>deps-dev: bump aws-cdk from 2.159.1 to 2.160.0 (#5233)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.159.1a0 to 2.160.0a0 (#5235)</li> <li>deps-dev: bump aws-cdk-lib from 2.159.1 to 2.160.0 (#5230)</li> <li>deps-dev: bump cfn-lint from 1.15.0 to 1.15.1 (#5232)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.158.0a0 to 2.159.1a0 (#5231)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.268 to 0.1.269 (#5229)</li> <li>deps-dev: bump aws-cdk-lib from 2.160.0 to 2.161.0 (#5304)</li> <li>deps-dev: bump boto3-stubs from 1.35.33 to 1.35.34 (#5306)</li> <li>deps-dev: bump types-redis from 4.6.0.20240903 to 4.6.0.20241004 (#5307)</li> <li>deps-dev: bump aws-cdk-lib from 2.158.0 to 2.159.1 (#5208)</li> <li>deps-dev: bump ruff from 0.6.4 to 0.6.7 (#5207)</li> <li>deps-dev: bump aws-cdk from 2.157.0 to 2.159.1 (#5194)</li> <li>deps-dev: bump aws-cdk from 2.160.0 to 2.161.0 (#5309)</li> <li>deps-dev: bump ruff from 0.6.8 to 0.6.9 (#5308)</li> <li>deps-dev: bump cfn-lint from 1.15.2 to 1.16.0 (#5305)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.160.0a0 to 2.161.0a0 (#5332)</li> <li>deps-dev: bump aws-cdk from 2.161.0 to 2.161.1 (#5327)</li> <li>deps-dev: bump mkdocs-material from 9.5.34 to 9.5.36 (#5210)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.272 to 0.1.273 (#5336)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.264 to 0.1.268 (#5216)</li> <li>deps-dev: bump multiprocess from 0.70.16 to 0.70.17 (#5275)</li> <li>deps-dev: bump boto3-stubs from 1.35.17 to 1.35.25 (#5218)</li> <li>deps-dev: bump bandit from 1.7.9 to 1.7.10 (#5214)</li> <li>deps-dev: bump cfn-lint from 1.12.4 to 1.15.0 (#5215)</li> <li>docs: recreate requirements.txt file for mkdocs container (#5246)</li> <li>tests: fix e2e tests in Idempotency utility (#5280)</li> </ul>"
        },
        {
            "location": "changelog/#v300-2024-09-23",
            "title": "v3.0.0 - 2024-09-23",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_10",
            "title": "Bug Fixes",
            "text": "<ul> <li>v3: revert unnecessary changes that impacts v3 (#5087)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_5",
            "title": "Code Refactoring",
            "text": "<ul> <li>batch: add from future import annotations (#4993)</li> <li>batch_processing: mark batch_processor and async_batch_processor as deprecated  (#4910)</li> <li>data_classes: add from future import annotations (#4939)</li> <li>data_masking: add from future import annotations (#4945)</li> <li>event_handler: add from future import annotations (#4992)</li> <li>event_handler: add from future import annotations in the Middlewares (#4975)</li> <li>feature_flags: add from future import annotations (#4960)</li> <li>general: drop pydantic v1 (#4305)</li> <li>idempotency: add from future import annotations (#4961)</li> <li>jmespath_utils: deprecate extract_data_from_envelope in favor of query (#4907)</li> <li>jmespath_utils: add from future import annotations (#4962)</li> <li>logging: add from future import annotations (#4940)</li> <li>metrics: add from future import annotations (#4944)</li> <li>middleware_factory: add from future import annotations (#4941)</li> <li>openapi: add from future import annotations (#4990)</li> <li>parameters: deprecate the config parameter in favor of boto_config (#4893)</li> <li>parameters: add top-level get_multiple method in SSMProvider class (#4785)</li> <li>parameters: add from future import annotations (#4976)</li> <li>parameters: increase default max_age (cache) to 5 minutes (#4279)</li> <li>parser: add from future import annotations (#4977)</li> <li>parser: add from future import annotations (#4983)</li> <li>shared: add from future import annotations (#4942)</li> <li>streaming: add from future import annotations (#4987)</li> <li>tracing: add from future import annotations (#4943)</li> <li>typing: add from future import annotations (#4985)</li> <li>typing: enable TCH, UP and FA100 ruff rules (#5017)</li> <li>typing: reduce aws_lambda_powertools.shared.types usage (#4896)</li> <li>typing: enable boto3 implicit type annotations (#4692)</li> <li>typing: move more types into TYPE_CHECKING (#5088)</li> <li>validation: add from future import annotations (#4984)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_10",
            "title": "Documentation",
            "text": "<ul> <li>upgrade_guide: create upgrade guide from v2 to v3 (#5028)</li> </ul>"
        },
        {
            "location": "changelog/#features_9",
            "title": "Features",
            "text": "<ul> <li>data_classes: return empty dict or list instead of None (#4606)</li> <li>event_handler: Ensure Bedrock Agents resolver works with Pydantic v2 (#5156)</li> <li>idempotency: simplify access to expiration time in <code>DataRecord</code> class (#5082)</li> <li>lambda-layer: add pipeline to build Lambda layer in v3 (#4826)</li> <li>parser: Adds DDB deserialization to DynamoDBStreamChangedRecordModel (#4401)</li> <li>parser: Allow primitive data types to be parsed using TypeAdapter (#4502)</li> <li>v3: merging develop into v3 (#5160)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_11",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: fix bump poetry version (#5211)</li> <li>ci: fix working-directory in v3 layer pipeline (#5199)</li> <li>ci: fix Redis e2e tests in v3 branch (#4852)</li> <li>ci: fix e2e tests in v3 branch (#4848)</li> <li>ci: add the aws-encryption-sdk dependency in the Lambda layer (#4630)</li> <li>ci: bump pydantic library to 2.0+ and boto3 to 1.34.32 (#4235)</li> <li>v3: merging develop into v3 - 15/05/2024 (#4335)</li> <li>v3: merging develop into v3 (#4267)</li> </ul>"
        },
        {
            "location": "changelog/#v2431-2024-08-12",
            "title": "v2.43.1 - 2024-08-12",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_11",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_source: fix regression when working with zero numbers in DynamoDBStreamEvent (#4932)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_12",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 2.43.1a0 (#4920)</li> <li>ci: new pre-release 2.43.1a1 (#4926)</li> <li>ci: new pre-release 2.42.1a9 (#4912)</li> <li>deps-dev: bump ruff from 0.5.6 to 0.5.7 (#4918)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.234 to 0.1.238 (#4917)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.34.132 to 1.34.158 in the boto-typing group (#4921)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.238 to 0.1.242 (#4922)</li> <li>deps-dev: bump cfn-lint from 1.9.6 to 1.9.7 (#4923)</li> <li>deps-dev: bump cfn-lint from 1.9.5 to 1.9.6 (#4916)</li> </ul>"
        },
        {
            "location": "changelog/#v2430-2024-08-08",
            "title": "v2.43.0 - 2024-08-08",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_12",
            "title": "Bug Fixes",
            "text": "<ul> <li>data_class: ensure DynamoDBStreamEvent conforms to decimal limits (#4863)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_6",
            "title": "Code Refactoring",
            "text": "<ul> <li>test: make CORS test consistent with expected behavior (#4882)</li> <li>tracer: make capture_lambda_handler type more generic (#4796)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_11",
            "title": "Documentation",
            "text": "<ul> <li>fix type vs. field in comment (#4832)</li> <li>public_reference: add CHS Inc. as a public reference (#4885)</li> <li>public_reference: add LocalStack as a public reference (#4858)</li> <li>public_reference: add Caylent as a public reference (#4822)</li> </ul>"
        },
        {
            "location": "changelog/#features_10",
            "title": "Features",
            "text": "<ul> <li>metrics: add unit None for CloudWatch EMF Metrics (#4904)</li> <li>validation: returns output from validate function (#4839)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_13",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 2.42.1a5 (#4868)</li> <li>ci: new pre-release 2.42.1a8 (#4903)</li> <li>ci: new pre-release 2.42.1a0 (#4827)</li> <li>ci: new pre-release 2.42.1a7 (#4894)</li> <li>ci: new pre-release 2.42.1a1 (#4837)</li> <li>ci: new pre-release 2.42.1a3 (#4856)</li> <li>ci: new pre-release 2.42.1a4 (#4864)</li> <li>ci: new pre-release 2.42.1a6 (#4884)</li> <li>ci: new pre-release 2.42.1a2 (#4847)</li> <li>deps: bump golang.org/x/sync from 0.7.0 to 0.8.0 in /layer/scripts/layer-balancer in the layer-balancer group (#4892)</li> <li>deps: bump actions/upload-artifact from 4.3.5 to 4.3.6 (#4901)</li> <li>deps: bump actions/upload-artifact from 4.3.4 to 4.3.5 (#4871)</li> <li>deps: bump ossf/scorecard-action from 2.3.3 to 2.4.0 (#4829)</li> <li>deps: bump squidfunk/mkdocs-material from <code>257eca8</code> to <code>9919d6e</code> in /docs (#4878)</li> <li>deps: bump docker/setup-buildx-action from 3.5.0 to 3.6.1 (#4844)</li> <li>deps: bump redis from 5.0.7 to 5.0.8 (#4854)</li> <li>deps-dev: bump ruff from 0.5.5 to 0.5.6 (#4874)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.34.83 to 1.34.153 in the boto-typing group (#4887)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.224 to 0.1.228 (#4867)</li> <li>deps-dev: bump cfn-lint from 1.9.1 to 1.9.3 (#4866)</li> <li>deps-dev: bump sentry-sdk from 2.11.0 to 2.12.0 (#4861)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.228 to 0.1.230 (#4876)</li> <li>deps-dev: bump black from 24.4.2 to 24.8.0 (#4873)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.223 to 0.1.224 (#4855)</li> <li>deps-dev: bump mypy-boto3-logs from 1.34.66 to 1.34.151 in the boto-typing group (#4853)</li> <li>deps-dev: bump coverage from 7.6.0 to 7.6.1 (#4888)</li> <li>deps-dev: bump cfn-lint from 1.8.2 to 1.9.1 (#4851)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.150.0a0 to 2.151.0a0 (#4889)</li> <li>deps-dev: bump aws-cdk from 2.150.0 to 2.151.0 (#4872)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.219 to 0.1.222 (#4836)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.222 to 0.1.223 (#4843)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.233 to 0.1.234 (#4909)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.230 to 0.1.231 (#4891)</li> <li>deps-dev: bump cfn-lint from 1.9.3 to 1.9.5 (#4890)</li> <li>deps-dev: bump pytest from 8.3.1 to 8.3.2 (#4824)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.231 to 0.1.233 (#4900)</li> <li>deps-dev: bump mkdocs-material from 9.5.30 to 9.5.31 (#4877)</li> <li>deps-dev: bump types-redis from 4.6.0.20240425 to 4.6.0.20240726 (#4831)</li> <li>deps-dev: bump ruff from 0.5.4 to 0.5.5 (#4823)</li> <li>deps-dev: bump aws-cdk-lib from 2.150.0 to 2.151.0 (#4875)</li> <li>deps-dev: bump types-redis from 4.6.0.20240726 to 4.6.0.20240806 (#4899)</li> <li>maintenance: add Banxware customer refernece (#4841)</li> </ul>"
        },
        {
            "location": "changelog/#v2420-2024-07-25",
            "title": "v2.42.0 - 2024-07-25",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_13",
            "title": "Bug Fixes",
            "text": "<ul> <li>idempotency: ensure in_progress_expiration field is set on Lambda timeout. (#4773)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_12",
            "title": "Documentation",
            "text": "<ul> <li>idempotency: improve navigation, wording, and new section on guarantees (#4613)</li> </ul>"
        },
        {
            "location": "changelog/#features_11",
            "title": "Features",
            "text": "<ul> <li>event_handler: add OpenAPI extensions (#4703)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_14",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 2.41.1a4 (#4772)</li> <li>ci: new pre-release 2.41.1a0 (#4749)</li> <li>ci: new pre-release 2.41.1a1 (#4756)</li> <li>ci: new pre-release 2.41.1a2 (#4758)</li> <li>ci: new pre-release 2.41.1a9 (#4808)</li> <li>ci: new pre-release 2.41.1a3 (#4766)</li> <li>ci: new pre-release 2.41.1a8 (#4802)</li> <li>ci: new pre-release 2.41.1a5 (#4777)</li> <li>ci: new pre-release 2.41.1a6 (#4783)</li> <li>ci: new pre-release 2.41.1a7 (#4792)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/config from 1.27.26 to 1.27.27 in /layer/scripts/layer-balancer in the layer-balancer group (#4779)</li> <li>deps: bump aws-actions/closed-issue-message from 8b6324312193476beecf11f8e8539d73a3553bf4 to 80edfc24bdf1283400eb04d20a8a605ae8bf7d48 (#4786)</li> <li>deps: bump actions/dependency-review-action from 4.3.3 to 4.3.4 (#4753)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#4745)</li> <li>deps: bump datadog-lambda from 6.96.0 to 6.97.0 (#4770)</li> <li>deps: bump docker/setup-buildx-action from 3.4.0 to 3.5.0 (#4801)</li> <li>deps: bump docker/setup-qemu-action from 3.1.0 to 3.2.0 (#4800)</li> <li>deps-dev: bump cfn-lint from 1.8.1 to 1.8.2 (#4788)</li> <li>deps-dev: bump pytest-asyncio from 0.23.7 to 0.23.8 (#4776)</li> <li>deps-dev: bump pytest from 8.2.2 to 8.3.1 (#4799)</li> <li>deps-dev: bump aws-cdk-lib from 2.148.1 to 2.150.0 (#4806)</li> <li>deps-dev: bump ruff from 0.5.3 to 0.5.4 (#4798)</li> <li>deps-dev: bump cfn-lint from 1.6.1 to 1.8.1 (#4780)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.211 to 0.1.212 (#4769)</li> <li>deps-dev: bump ruff from 0.5.2 to 0.5.3 (#4781)</li> <li>deps-dev: bump mkdocs-material from 9.5.28 to 9.5.29 (#4764)</li> <li>deps-dev: bump aws-cdk from 2.148.0 to 2.149.0 (#4765)</li> <li>deps-dev: bump ruff from 0.5.1 to 0.5.2 (#4762)</li> <li>deps-dev: bump sentry-sdk from 2.9.0 to 2.10.0 (#4763)</li> <li>deps-dev: bump aws-cdk from 2.149.0 to 2.150.0 (#4805)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.207 to 0.1.211 (#4760)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.34.131 to 1.34.148 in the boto-typing group (#4812)</li> <li>deps-dev: bump sentry-sdk from 2.10.0 to 2.11.0 (#4815)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.212 to 0.1.219 (#4817)</li> <li>deps-dev: bump cfn-lint from 1.6.0 to 1.6.1 (#4751)</li> <li>deps-dev: bump mkdocs-material from 9.5.29 to 9.5.30 (#4807)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.148.1a0 to 2.150.0a0 (#4813)</li> <li>deps-dev: bump cfn-lint from 1.5.3 to 1.6.0 (#4747)</li> <li>deps-dev: bump coverage from 7.5.4 to 7.6.0 (#4746)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.206 to 0.1.207 (#4748)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.34.128 to 1.34.145 in the boto-typing group (#4787)</li> <li>docs: Add lambda layer policy to versioning docs (#4811)</li> <li>logger: use package logger over source logger to reduce noise (#4793)</li> </ul>"
        },
        {
            "location": "changelog/#v2410-2024-07-11",
            "title": "v2.41.0 - 2024-07-11",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_14",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: make the max_age attribute comply with RFC specification (#4731)</li> <li>event_handler: disable allow-credentials header when origin allow_origin is * (#4638)</li> <li>event_handler: convert null body to empty string in ALBResolver to avoid HTTP 502 (#4683)</li> <li>event_handler: custom serializer recursive values when using data validation (#4664)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_13",
            "title": "Documentation",
            "text": "<ul> <li>i-made-this: Bedrock agents with Powertools for AWS Lambda (#4705)</li> <li>public_reference: add BusPatrol as a public reference (#4713)</li> </ul>"
        },
        {
            "location": "changelog/#features_12",
            "title": "Features",
            "text": "<ul> <li>batch: add option to not raise <code>BatchProcessingError</code> exception when the entire batch fails (#4719)</li> <li>feature_flags: allow customers to bring their own boto3 client and session (#4717)</li> <li>parser: add support for API Gateway Lambda authorizer events (#4718)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_15",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>Add token to codecov action (#4682)</li> <li>ci: new pre-release 2.40.2a5 (#4706)</li> <li>ci: new pre-release 2.40.2a0 (#4665)</li> <li>ci: new pre-release 2.40.2a8 (#4737)</li> <li>ci: new pre-release 2.40.2a7 (#4726)</li> <li>ci: new pre-release 2.40.2a1 (#4669)</li> <li>ci: new pre-release 2.40.2a2 (#4679)</li> <li>ci: new pre-release 2.40.2a3 (#4688)</li> <li>ci: new pre-release 2.40.2a6 (#4715)</li> <li>ci: new pre-release 2.40.2a4 (#4694)</li> <li>deps: bump docker/setup-qemu-action from 3.0.0 to 3.1.0 (#4685)</li> <li>deps: bump actions/setup-python from 5.1.0 to 5.1.1 (#4732)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#4733)</li> <li>deps: bump actions/upload-artifact from 4.3.3 to 4.3.4 (#4698)</li> <li>deps: bump actions/download-artifact from 4.1.7 to 4.1.8 (#4699)</li> <li>deps: bump actions/setup-node from 4.0.2 to 4.0.3 (#4725)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.9 to 3.0.10 (#4678)</li> <li>deps: bump docker/setup-buildx-action from 3.3.0 to 3.4.0 (#4693)</li> <li>deps: bump zipp from 3.17.0 to 3.19.1 in /docs (#4720)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#4659)</li> <li>deps: bump certifi from 2024.6.2 to 2024.7.4 (#4700)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/config from 1.27.23 to 1.27.24 in /layer/scripts/layer-balancer in the layer-balancer group (#4684)</li> <li>deps-dev: bump mkdocs-material from 9.5.27 to 9.5.28 (#4676)</li> <li>deps-dev: bump cfn-lint from 1.4.2 to 1.5.0 (#4675)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.147.3a0 to 2.148.0a0 (#4722)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.200 to 0.1.201 (#4687)</li> <li>deps-dev: bump aws-cdk-lib from 2.147.2 to 2.147.3 (#4674)</li> <li>deps-dev: bump zipp from 3.17.0 to 3.19.1 in /layer (#4721)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.202 to 0.1.205 (#4723)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.147.2a0 to 2.147.3a0 (#4686)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.199 to 0.1.200 (#4677)</li> <li>deps-dev: bump aws-cdk-lib from 2.147.3 to 2.148.0 (#4710)</li> <li>deps-dev: bump aws-cdk from 2.147.2 to 2.147.3 (#4672)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.34.120 to 1.34.138 in the boto-typing group (#4673)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.201 to 0.1.202 (#4696)</li> <li>deps-dev: bump cfn-lint from 1.5.1 to 1.5.2 (#4724)</li> <li>deps-dev: bump ruff from 0.5.0 to 0.5.1 (#4697)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.198 to 0.1.199 (#4668)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.147.1a0 to 2.147.2a0 (#4667)</li> <li>deps-dev: bump aws-cdk from 2.147.3 to 2.148.0 (#4708)</li> <li>deps-dev: bump cfn-lint from 1.5.2 to 1.5.3 (#4734)</li> <li>deps-dev: bump sentry-sdk from 2.8.0 to 2.9.0 (#4735)</li> <li>deps-dev: bump cfn-lint from 1.4.1 to 1.4.2 (#4660)</li> <li>deps-dev: bump aws-cdk-lib from 2.147.1 to 2.147.2 (#4661)</li> <li>deps-dev: bump cfn-lint from 1.5.0 to 1.5.1 (#4711)</li> <li>deps-dev: bump aws-cdk from 2.147.1 to 2.147.2 (#4657)</li> <li>deps-dev: bump ruff from 0.4.10 to 0.5.0 (#4644)</li> <li>deps-dev: bump sentry-sdk from 2.7.1 to 2.8.0 (#4712)</li> <li>layers: downgrade aws cdk to 2.145.0 (#4739)</li> </ul>"
        },
        {
            "location": "changelog/#v2401-2024-06-28",
            "title": "v2.40.1 - 2024-06-28",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_15",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: current_event regression AppSyncResolver Router (#4652)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_16",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: new pre-release 2.40.1a1 (#4653)</li> <li>ci: new pre-release 2.40.1a0 (#4648)</li> <li>deps-dev: bump cfn-lint from 1.3.7 to 1.4.1 (#4646)</li> <li>deps-dev: bump sentry-sdk from 2.7.0 to 2.7.1 (#4645)</li> </ul>"
        },
        {
            "location": "changelog/#v2400-2024-06-27",
            "title": "v2.40.0 - 2024-06-27",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_16",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_sources: change partition and offset field types in KafkaEventRecord (#4515)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_14",
            "title": "Documentation",
            "text": "<ul> <li>homepage: Fix homepage link (#4587)</li> <li>i-made-this: add new article about best practices for accelerating serverless development (#4518)</li> <li>public reference: add Brsk as a public reference (#4597)</li> </ul>"
        },
        {
            "location": "changelog/#features_13",
            "title": "Features",
            "text": "<ul> <li>event-handler: add appsync batch resolvers (#1998)</li> <li>validation: support JSON Schema referencing in validation utils (#4508)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_17",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: add the Metrics feature to nox tests (#4552)</li> <li>ci: new pre-release 2.39.2a5 (#4636)</li> <li>ci: add the Streaming feature to nox tests (#4575)</li> <li>ci: new pre-release 2.39.2a4 (#4629)</li> <li>ci: new pre-release 2.39.2a3 (#4620)</li> <li>ci: add the Event Handler feature to nox tests (#4581)</li> <li>ci: add the Data Class feature to nox tests (#4583)</li> <li>ci: add the Parser feature to nox tests (#4584)</li> <li>ci: add the Idempotency feature to nox tests (#4585)</li> <li>ci: new pre-release 2.39.2a2 (#4610)</li> <li>ci: introduce tests with Nox (#4537)</li> <li>ci: new pre-release 2.39.2a1 (#4598)</li> <li>ci: add the Tracer feature to nox tests (#4567)</li> <li>ci: add the Middleware Factory feature to nox tests (#4568)</li> <li>ci: add the Parameters feature to nox tests (#4569)</li> <li>ci: add the Batch Processor feature to nox tests (#4586)</li> <li>ci: add the Feature Flags feature to nox tests (#4570)</li> <li>ci: add the Validation feature to nox tests (#4571)</li> <li>ci: introduce daily pre-releases (#4535)</li> <li>ci: new pre-release 2.39.2a0 (#4590)</li> <li>ci: add the Data Masking feature to nox tests (#4574)</li> <li>ci: add the Typing feature to nox tests (#4572)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.8.14 to 1.9.0 (#4592)</li> <li>deps: bump pydantic from 1.10.16 to 1.10.17 (#4595)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#4565)</li> <li>deps: bump squidfunk/mkdocs-material from <code>96abcbb</code> to <code>257eca8</code> in /docs (#4540)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.7 to 3.0.9 (#4539)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#4546)</li> <li>deps: bump redis from 5.0.5 to 5.0.6 (#4527)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#4580)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 2 updates (#4635)</li> <li>deps: bump codecov/codecov-action from 4.4.1 to 4.5.0 (#4514)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.8.14 to 1.9.0 (#4538)</li> <li>deps: bump fastjsonschema from 2.19.1 to 2.20.0 (#4543)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.189 to 0.1.192 (#4578)</li> <li>deps-dev: bump sentry-sdk from 2.5.1 to 2.6.0 (#4579)</li> <li>deps-dev: bump cfn-lint from 0.87.7 to 1.3.0 (#4577)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.192 to 0.1.193 (#4596)</li> <li>deps-dev: bump ruff from 0.4.9 to 0.4.10 (#4594)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.193 to 0.1.194 (#4601)</li> <li>deps-dev: bump aws-cdk from 2.146.0 to 2.147.0 (#4604)</li> <li>deps-dev: bump aws-cdk-lib from 2.146.0 to 2.147.0 (#4603)</li> <li>deps-dev: bump filelock from 3.15.1 to 3.15.3 (#4576)</li> <li>deps-dev: bump hvac from 2.2.0 to 2.3.0 (#4563)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.188 to 0.1.189 (#4564)</li> <li>deps-dev: bump cfn-lint from 1.3.0 to 1.3.3 (#4602)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.194 to 0.1.198 (#4627)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.146.0a0 to 2.147.0a0 (#4619)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.184 to 0.1.188 (#4550)</li> <li>deps-dev: bump mkdocs-material from 9.5.26 to 9.5.27 (#4544)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.145.0a0 to 2.146.0a0 (#4542)</li> <li>deps-dev: bump urllib3 from 1.26.18 to 1.26.19 in /layer (#4547)</li> <li>deps-dev: bump aws-cdk-lib from 2.145.0 to 2.146.0 (#4526)</li> <li>deps-dev: bump aws-cdk from 2.147.0 to 2.147.1 (#4614)</li> <li>deps-dev: bump coverage from 7.5.3 to 7.5.4 (#4617)</li> <li>deps-dev: bump aws-cdk-lib from 2.147.0 to 2.147.1 (#4615)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.34.125 to 1.34.128 in the boto-typing group (#4541)</li> <li>deps-dev: bump pdoc3 from 0.10.0 to 0.11.0 (#4618)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.34.109 to 1.34.125 in the boto-typing group (#4509)</li> <li>deps-dev: bump mike from 2.1.1 to 2.1.2 (#4616)</li> <li>deps-dev: bump mypy from 1.10.0 to 1.10.1 (#4624)</li> <li>deps-dev: bump filelock from 3.15.3 to 3.15.4 (#4626)</li> <li>deps-dev: bump ruff from 0.4.8 to 0.4.9 (#4528)</li> <li>deps-dev: bump cfn-lint from 1.3.3 to 1.3.5 (#4628)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.34.91 to 1.34.132 in the boto-typing group (#4623)</li> <li>deps-dev: bump aws-cdk from 2.145.0 to 2.146.0 (#4525)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.182 to 0.1.184 (#4529)</li> <li>deps-dev: bump bandit from 1.7.8 to 1.7.9 (#4511)</li> <li>deps-dev: bump cfn-lint from 0.87.6 to 0.87.7 (#4513)</li> <li>deps-dev: bump filelock from 3.14.0 to 3.15.1 (#4512)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.179 to 0.1.182 (#4510)</li> <li>deps-dev: bump cfn-lint from 1.3.5 to 1.3.7 (#4634)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.34.114 to 1.34.131 in the boto-typing group (#4593)</li> <li>governance: fix errors when creating Gitpod environment (#4532)</li> <li>layers: downgrade aws cdk to 2.145.0 (#4640)</li> </ul>"
        },
        {
            "location": "changelog/#v2391-2024-06-13",
            "title": "v2.39.1 - 2024-06-13",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_17",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: regression making pydantic required (it should not) (#4500)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_18",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> </ul>"
        },
        {
            "location": "changelog/#v2390-2024-06-13",
            "title": "v2.39.0 - 2024-06-13",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_18",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: do not skip middleware and exception handlers on 404 error (#4492)</li> <li>event_handler: raise more specific SerializationError exception for unsupported types in data validation (#4415)</li> <li>event_handler: security scheme unhashable list when working with router (#4421)</li> <li>event_handler: CORS Origin for ALBResolver multi-headers  (#4385)</li> <li>idempotency: POWERTOOLS_IDEMPOTENCY_DISABLED should respect truthy values (#4391)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_15",
            "title": "Documentation",
            "text": "<ul> <li>homepage: Change installation to CDK v2 (#4351)</li> <li>public reference: add Recast as a public reference (#4491)</li> </ul>"
        },
        {
            "location": "changelog/#features_14",
            "title": "Features",
            "text": "<ul> <li>event_source: add CloudFormationCustomResourceEvent data class. (#4342)</li> <li>events: Update and Add Cognito User Pool Events (#4423)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_19",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#4369)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#4468)</li> <li>deps: bump datadog-lambda from 5.94.0 to 6.95.0 (#4471)</li> <li>deps: bump redis from 5.0.4 to 5.0.5 (#4464)</li> <li>deps: bump aws-encryption-sdk from 3.2.0 to 3.3.0 (#4393)</li> <li>deps: bump codecov/codecov-action from 4.4.0 to 4.4.1 (#4376)</li> <li>deps: bump squidfunk/mkdocs-material from <code>8a87f05</code> to <code>96abcbb</code> in /docs (#4461)</li> <li>deps: bump typing-extensions from 4.12.1 to 4.12.2 (#4470)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 2 updates (#4396)</li> <li>deps: bump aws-xray-sdk from 2.13.0 to 2.13.1 (#4379)</li> <li>deps: bump actions/dependency-review-action from 4.3.2 to 4.3.3 (#4456)</li> <li>deps: bump aws-xray-sdk from 2.13.1 to 2.14.0 (#4453)</li> <li>deps: bump typing-extensions from 4.11.0 to 4.12.0 (#4404)</li> <li>deps: bump squidfunk/mkdocs-material from <code>5358893</code> to <code>8a87f05</code> in /docs (#4408)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.6 to 3.0.7 (#4478)</li> <li>deps: bump squidfunk/mkdocs-material from <code>48d1914</code> to <code>5358893</code> in /docs (#4377)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#4444)</li> <li>deps: bump pydantic from 1.10.15 to 1.10.16 (#4485)</li> <li>deps: bump datadog-lambda from 6.95.0 to 6.96.0 (#4489)</li> <li>deps: bump actions/checkout from 4.1.6 to 4.1.7 (#4493)</li> <li>deps: bump typing-extensions from 4.12.0 to 4.12.1 (#4440)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.5 to 3.0.6 (#4445)</li> <li>deps: bump requests from 2.31.0 to 2.32.0 (#4383)</li> <li>deps-dev: bump aws-cdk from 2.143.1 to 2.144.0 (#4443)</li> <li>deps-dev: bump aws-cdk-lib from 2.143.1 to 2.144.0 (#4441)</li> <li>deps-dev: bump ruff from 0.4.6 to 0.4.7 (#4435)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.143.0a0 to 2.143.1a0 (#4433)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.164 to 0.1.169 (#4442)</li> <li>deps-dev: bump pytest from 8.2.1 to 8.2.2 (#4450)</li> <li>deps-dev: bump aws-cdk from 2.143.0 to 2.143.1 (#4430)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.163 to 0.1.164 (#4428)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.161 to 0.1.163 (#4425)</li> <li>deps-dev: bump cfn-lint from 0.87.5 to 0.87.6 (#4486)</li> <li>deps-dev: bump sentry-sdk from 2.3.1 to 2.4.0 (#4449)</li> <li>deps-dev: bump ruff from 0.4.5 to 0.4.6 (#4417)</li> <li>deps-dev: bump cfn-lint from 0.87.3 to 0.87.4 (#4419)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.159 to 0.1.161 (#4420)</li> <li>deps-dev: bump coverage from 7.5.2 to 7.5.3 (#4418)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.34.113 to 1.34.114 in the boto-typing group (#4416)</li> <li>deps-dev: bump mkdocs-material from 9.5.24 to 9.5.25 (#4411)</li> <li>deps-dev: bump aws-cdk-lib from 2.143.0 to 2.143.1 (#4429)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.142.1a0 to 2.143.0a0 (#4410)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.34.97 to 1.34.113 in the boto-typing group (#4409)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.158 to 0.1.159 (#4412)</li> <li>deps-dev: bump coverage from 7.5.1 to 7.5.2 (#4413)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.143.1a0 to 2.144.0a0 (#4448)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.34.105 to 1.34.120 in the boto-typing group (#4452)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.169 to 0.1.173 (#4459)</li> <li>deps-dev: bump aws-cdk-lib from 2.142.1 to 2.143.0 (#4403)</li> <li>deps-dev: bump aws-cdk from 2.142.1 to 2.143.0 (#4402)</li> <li>deps-dev: bump ruff from 0.4.4 to 0.4.5 (#4399)</li> <li>deps-dev: bump sentry-sdk from 2.2.1 to 2.3.1 (#4398)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.157 to 0.1.158 (#4397)</li> <li>deps-dev: bump ruff from 0.4.7 to 0.4.8 (#4455)</li> <li>deps-dev: bump sentry-sdk from 2.4.0 to 2.5.0 (#4462)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.155 to 0.1.157 (#4394)</li> <li>deps-dev: bump mkdocs-material from 9.5.25 to 9.5.26 (#4463)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.34.84 to 1.34.111 in the boto-typing group (#4392)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.154 to 0.1.155 (#4386)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.173 to 0.1.174 (#4466)</li> <li>deps-dev: bump pytest-asyncio from 0.23.6 to 0.23.7 (#4387)</li> <li>deps-dev: bump sentry-sdk from 2.2.0 to 2.2.1 (#4388)</li> <li>deps-dev: bump ijson from 3.2.3 to 3.3.0 (#4465)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.152 to 0.1.154 (#4382)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.174 to 0.1.175 (#4472)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.34.107 to 1.34.109 in the boto-typing group (#4378)</li> <li>deps-dev: bump sentry-sdk from 2.5.0 to 2.5.1 (#4469)</li> <li>deps-dev: bump cfn-lint from 0.87.4 to 0.87.5 (#4479)</li> <li>deps-dev: bump mkdocs-material from 9.5.23 to 9.5.24 (#4380)</li> <li>deps-dev: bump pytest from 8.2.0 to 8.2.1 (#4381)</li> <li>deps-dev: bump aws-cdk from 2.144.0 to 2.145.0 (#4482)</li> <li>deps-dev: bump aws-cdk-lib from 2.144.0 to 2.145.0 (#4481)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.141.0a0 to 2.142.1a0 (#4367)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.144.0a0 to 2.145.0a0 (#4487)</li> <li>deps-dev: bump aws-cdk from 2.142.0 to 2.142.1 (#4366)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.150 to 0.1.152 (#4368)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.176 to 0.1.179 (#4488)</li> <li>deps-dev: bump cfn-lint from 0.87.2 to 0.87.3 (#4370)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.175 to 0.1.176 (#4480)</li> <li>libraries: add jmespath as a required dependency (#4422)</li> </ul>"
        },
        {
            "location": "changelog/#v2381-2024-05-17",
            "title": "v2.38.1 - 2024-05-17",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_19",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: reverting logger child modification (#4363)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_20",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> </ul>"
        },
        {
            "location": "changelog/#v2380-2024-05-17",
            "title": "v2.38.0 - 2024-05-17",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_20",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: apply lessons learned to monthly roadmap reminder cross-repo (#4078)</li> <li>event-sources: sane defaults for authorizer v1 and v2 (#4298)</li> <li>logger: correctly pick powertools or custom handler in custom environments (#4295)</li> <li>parser: make etag optional field on S3 notification events (#4173)</li> <li>typing: resolved_headers_field is not Optional (#4148)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_7",
            "title": "Code Refactoring",
            "text": "<ul> <li>data-masking: remove Non-GA comments (#4334)</li> <li>parser: only infer type hints when necessary (#4183)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_16",
            "title": "Documentation",
            "text": "<ul> <li>general: update documentation to add info about v3 (#4234)</li> <li>homepage: add link to new and official workshop (#4292)</li> <li>idempotency: fix highlight and import path (#4154)</li> <li>roadmap: april updates (#4181)</li> </ul>"
        },
        {
            "location": "changelog/#features_15",
            "title": "Features",
            "text": "<ul> <li>event_handler: add support for persisting authorization session in OpenAPI (#4312)</li> <li>event_handler: add decorator for HTTP HEAD verb (#4275)</li> <li>logger-utils: preserve log level for discovered third-party top-level loggers (#4299)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_21",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: bump upload artifact action to v4 (#4355)</li> <li>ci: add branch v3 to quality check and e2e actions (#4232)</li> <li>ci: bump download artifact action to v4 (#4358)</li> <li>deps: bump actions/download-artifact from 4.1.4 to 4.1.5 (#4161)</li> <li>deps: bump actions/checkout from 4.1.3 to 4.1.4 (#4206)</li> <li>deps: bump ossf/scorecard-action from 2.3.1 to 2.3.3 (#4315)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/config from 1.27.12 to 1.27.13 in /layer/scripts/layer-balancer in the layer-balancer group (#4319)</li> <li>deps: bump actions/download-artifact from 4.1.6 to 4.1.7 (#4205)</li> <li>deps: bump squidfunk/mkdocs-material from <code>521644b</code> to <code>e309089</code> in /docs (#4216)</li> <li>deps: bump squidfunk/mkdocs-material from <code>11d7ec0</code> to <code>8ef47d7</code> in /docs (#4323)</li> <li>deps: bump datadog-lambda from 5.92.0 to 5.93.0 (#4211)</li> <li>deps: bump redis from 5.0.3 to 5.0.4 (#4187)</li> <li>deps: bump actions/upload-artifact from 4.3.2 to 4.3.3 (#4177)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 2 updates (#4302)</li> <li>deps: bump squidfunk/mkdocs-material from <code>8ef47d7</code> to <code>48d1914</code> in /docs (#4336)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#4337)</li> <li>deps: bump squidfunk/mkdocs-material from <code>e309089</code> to <code>98c9809</code> in /docs (#4236)</li> <li>deps: bump actions/dependency-review-action from 4.3.1 to 4.3.2 (#4244)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.4 to 3.0.5 (#4281)</li> <li>deps: bump actions/checkout from 4.1.4 to 4.1.5 (#4282)</li> <li>deps: bump jinja2 from 3.1.3 to 3.1.4 in /docs (#4284)</li> <li>deps: bump codecov/codecov-action from 4.3.0 to 4.3.1 (#4252)</li> <li>deps: bump datadog-lambda from 5.93.0 to 5.94.0 (#4253)</li> <li>deps: bump actions/checkout from 4.1.2 to 4.1.3 (#4168)</li> <li>deps: bump actions/dependency-review-action from 4.2.5 to 4.3.1 (#4240)</li> <li>deps: bump actions/checkout from 4.1.5 to 4.1.6 (#4344)</li> <li>deps: bump squidfunk/mkdocs-material from <code>98c9809</code> to <code>11d7ec0</code> in /docs (#4269)</li> <li>deps: bump actions/upload-artifact from 4.3.1 to 4.3.2 (#4162)</li> <li>deps: bump codecov/codecov-action from 4.3.1 to 4.4.0 (#4328)</li> <li>deps: bump slsa-framework/slsa-github-generator from 1.10.0 to 2.0.0 (#4179)</li> <li>deps: bump actions/download-artifact from 4.1.5 to 4.1.6 (#4178)</li> <li>deps-dev: bump mkdocs-material from 9.5.20 to 9.5.21 (#4271)</li> <li>deps-dev: bump mike from 2.1.0 to 2.1.1 (#4268)</li> <li>deps-dev: bump cfn-lint from 0.87.0 to 0.87.1 (#4272)</li> <li>deps-dev: bump mike from 1.1.2 to 2.1.0 (#4258)</li> <li>deps-dev: bump aws-cdk-lib from 2.139.1 to 2.140.0 (#4259)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.139.1a0 to 2.140.0a0 (#4270)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.139.0a0 to 2.139.1a0 (#4261)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.133 to 0.1.134 (#4260)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.134 to 0.1.135 (#4273)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.34.91 to 1.34.97 in the boto-typing group (#4257)</li> <li>deps-dev: bump sentry-sdk from 2.0.1 to 2.1.1 (#4287)</li> <li>deps-dev: bump aws-cdk-lib from 2.139.0 to 2.139.1 (#4248)</li> <li>deps-dev: bump cfn-lint from 0.86.4 to 0.87.0 (#4249)</li> <li>deps-dev: bump pytest-xdist from 3.5.0 to 3.6.1 (#4247)</li> <li>deps-dev: bump ruff from 0.4.2 to 0.4.3 (#4286)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.132 to 0.1.133 (#4246)</li> <li>deps-dev: bump jinja2 from 3.1.3 to 3.1.4 (#4283)</li> <li>deps-dev: bump aws-cdk from 2.139.0 to 2.139.1 (#4245)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.135 to 0.1.136 (#4285)</li> <li>deps-dev: bump filelock from 3.13.4 to 3.14.0 (#4241)</li> <li>deps-dev: bump hvac from 2.1.0 to 2.2.0 (#4238)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.131 to 0.1.132 (#4239)</li> <li>deps-dev: bump mkdocs-material from 9.5.19 to 9.5.20 (#4242)</li> <li>deps-dev: bump aws-cdk from 2.139.1 to 2.140.0 (#4256)</li> <li>deps-dev: bump pytest from 8.1.1 to 8.2.0 (#4237)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.136 to 0.1.139 (#4293)</li> <li>deps-dev: bump aws-cdk-lib from 2.141.0 to 2.142.1 (#4352)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.139 to 0.1.140 (#4301)</li> <li>deps-dev: bump sentry-sdk from 1.45.0 to 2.0.1 (#4223)</li> <li>deps-dev: bump mkdocs-material from 9.5.18 to 9.5.19 (#4224)</li> <li>deps-dev: bump black from 24.4.1 to 24.4.2 (#4222)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.138.0a0 to 2.139.0a0 (#4225)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.130 to 0.1.131 (#4221)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.140 to 0.1.142 (#4307)</li> <li>deps-dev: bump ruff from 0.4.1 to 0.4.2 (#4212)</li> <li>deps-dev: bump aws-cdk-lib from 2.138.0 to 2.139.0 (#4213)</li> <li>deps-dev: bump aws-cdk from 2.138.0 to 2.139.0 (#4215)</li> <li>deps-dev: bump aws-cdk from 2.140.0 to 2.141.0 (#4306)</li> <li>deps-dev: bump types-redis from 4.6.0.20240423 to 4.6.0.20240425 (#4214)</li> <li>deps-dev: bump aws-cdk-lib from 2.140.0 to 2.141.0 (#4308)</li> <li>deps-dev: bump the boto-typing group with 2 updates (#4210)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.126 to 0.1.130 (#4209)</li> <li>deps-dev: bump ruff from 0.4.3 to 0.4.4 (#4309)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.140.0a0 to 2.141.0a0 (#4318)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.142 to 0.1.144 (#4316)</li> <li>deps-dev: bump black from 24.4.0 to 24.4.1 (#4203)</li> <li>deps-dev: bump mypy from 1.9.0 to 1.10.0 (#4202)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.34.61 to 1.34.91 in the boto-typing group (#4201)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.123 to 0.1.126 (#4188)</li> <li>deps-dev: bump cfn-lint from 0.87.1 to 0.87.2 (#4317)</li> <li>deps-dev: bump coverage from 7.4.4 to 7.5.0 (#4186)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.144 to 0.1.145 (#4325)</li> <li>deps-dev: bump types-redis from 4.6.0.20240417 to 4.6.0.20240423 (#4185)</li> <li>deps-dev: bump mkdocs-material from 9.5.21 to 9.5.22 (#4324)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.34.91 to 1.34.105 in the boto-typing group (#4329)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.145 to 0.1.146 (#4330)</li> <li>deps-dev: bump cfn-lint from 0.86.3 to 0.86.4 (#4180)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.121 to 0.1.123 (#4176)</li> <li>deps-dev: bump mkdocs-material from 9.5.22 to 9.5.23 (#4338)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.137.0a0 to 2.138.0a0 (#4169)</li> <li>deps-dev: bump aws-cdk from 2.141.0 to 2.142.0 (#4343)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.119 to 0.1.121 (#4167)</li> <li>deps-dev: bump ruff from 0.3.7 to 0.4.1 (#4166)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.34.72 to 1.34.107 in the boto-typing group (#4345)</li> <li>deps-dev: bump aws-cdk from 2.137.0 to 2.138.0 (#4157)</li> <li>deps-dev: bump aws-cdk-lib from 2.137.0 to 2.138.0 (#4160)</li> <li>deps-dev: bump sentry-sdk from 2.1.1 to 2.2.0 (#4348)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.146 to 0.1.150 (#4346)</li> <li>deps-dev: bump coverage from 7.5.0 to 7.5.1 (#4288)</li> <li>governance: add FastAPI third party license attribution (#4297)</li> </ul>"
        },
        {
            "location": "changelog/#v2370-2024-04-18",
            "title": "v2.37.0 - 2024-04-18",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_21",
            "title": "Bug Fixes",
            "text": "<ul> <li>docs: clarified usage of validation with fine grained responses (#4101)</li> <li>event_source: fix typo in physicalname attribute for AmazonMQ events (#4053)</li> <li>typing: make the case_sensitive field a boolean only (#4128)</li> <li>typing: improve overloads to ensure the return type follows the default_value type (#4114)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_17",
            "title": "Documentation",
            "text": "<ul> <li>we-made-this: new article on how to stream data with AWS Lambda &amp; Powertools for AWS Lambda (#4068)</li> </ul>"
        },
        {
            "location": "changelog/#features_16",
            "title": "Features",
            "text": "<ul> <li>Idempotency: add feature for manipulating idempotent responses (#4037)</li> <li>event_handler: add support for OpenAPI security schemes (#4103)</li> <li>logger: add method to return currently configured keys (#4033)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_22",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: add monthly roadmap reminder workflow (#4075)</li> <li>ci: prevent deprecated custom runner from being used (#4061)</li> <li>deps: bump squidfunk/mkdocs-material from <code>065f3af</code> to <code>6b124e1</code> in /docs (#4055)</li> <li>deps: bump squidfunk/mkdocs-material from <code>3307665</code> to <code>065f3af</code> in /docs (#4052)</li> <li>deps: bump idna from 3.6 to 3.7 (#4121)</li> <li>deps: bump sqlparse from 0.4.4 to 0.5.0 (#4138)</li> <li>deps: bump squidfunk/mkdocs-material from <code>6b124e1</code> to <code>521644b</code> in /docs (#4141)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#4066)</li> <li>deps: bump pydantic from 1.10.14 to 1.10.15 (#4064)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#4042)</li> <li>deps: bump golang.org/x/sync from 0.6.0 to 0.7.0 in /layer/scripts/layer-balancer in the layer-balancer group (#4071)</li> <li>deps: bump codecov/codecov-action from 4.1.1 to 4.2.0 (#4072)</li> <li>deps: bump datadog-lambda from 5.91.0 to 5.92.0 (#4038)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/config from 1.27.10 to 1.27.11 in /layer/scripts/layer-balancer in the layer-balancer group (#4079)</li> <li>deps: bump typing-extensions from 4.10.0 to 4.11.0 (#4080)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.3 to 3.0.4 (#4099)</li> <li>deps: bump codecov/codecov-action from 4.2.0 to 4.3.0 (#4098)</li> <li>deps: bump docker/setup-buildx-action from 3.2.0 to 3.3.0 (#4091)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.112 to 0.1.113 (#4136)</li> <li>deps-dev: bump aws-cdk from 2.135.0 to 2.136.0 (#4090)</li> <li>deps-dev: bump types-redis from 4.6.0.20240311 to 4.6.0.20240409 (#4094)</li> <li>deps-dev: bump aws-cdk-lib from 2.135.0 to 2.136.0 (#4092)</li> <li>deps-dev: bump cfn-lint from 0.86.1 to 0.86.2 (#4081)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.135.0a0 to 2.136.0a0 (#4095)</li> <li>deps-dev: bump filelock from 3.13.3 to 3.13.4 (#4096)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.106 to 0.1.107 (#4082)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.107 to 0.1.110 (#4097)</li> <li>deps-dev: bump aws-cdk from 2.136.0 to 2.136.1 (#4106)</li> <li>deps-dev: bump aws-cdk-lib from 2.136.0 to 2.136.1 (#4107)</li> <li>deps-dev: bump sentry-sdk from 1.44.1 to 1.45.0 (#4108)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.110 to 0.1.112 (#4109)</li> <li>deps-dev: bump sentry-sdk from 1.44.0 to 1.44.1 (#4065)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.134.0a0 to 2.135.0a0 (#4063)</li> <li>deps-dev: bump aws-cdk from 2.136.1 to 2.137.0 (#4115)</li> <li>deps-dev: bump the boto-typing group with 2 updates (#4062)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.34.75 to 1.34.83 in the boto-typing group (#4116)</li> <li>deps-dev: bump ruff from 0.3.5 to 0.3.7 (#4123)</li> <li>deps-dev: bump aws-cdk-lib from 2.136.1 to 2.137.0 (#4119)</li> <li>deps-dev: bump aws-cdk from 2.134.0 to 2.135.0 (#4058)</li> <li>deps-dev: bump aws-cdk-lib from 2.134.0 to 2.135.0 (#4057)</li> <li>deps-dev: bump mkdocs-material from 9.5.16 to 9.5.17 (#4056)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.136.0a0 to 2.137.0a0 (#4124)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.34.77 to 1.34.84 in the boto-typing group (#4126)</li> <li>deps-dev: bump ruff from 0.3.4 to 0.3.5 (#4049)</li> <li>deps-dev: bump mkdocs-material from 9.5.15 to 9.5.16 (#4050)</li> <li>deps-dev: bump the boto-typing group with 1 update (#4047)</li> <li>deps-dev: bump black from 24.3.0 to 24.4.0 (#4135)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.105 to 0.1.106 (#4048)</li> <li>deps-dev: bump cfn-lint from 0.86.2 to 0.86.3 (#4137)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.113 to 0.1.115 (#4142)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.133.0a0 to 2.134.0a0 (#4039)</li> <li>deps-dev: bump mkdocs-material from 9.5.17 to 9.5.18 (#4143)</li> <li>deps-dev: bump types-redis from 4.6.0.20240409 to 4.6.0.20240417 (#4145)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.115 to 0.1.119 (#4150)</li> <li>deps-dev: bump aws-cdk-lib from 2.133.0 to 2.134.0 (#4031)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.104 to 0.1.105 (#4030)</li> <li>deps-dev: bump aws-cdk from 2.133.0 to 2.134.0 (#4032)</li> <li>deps-dev: bump the boto-typing group with 1 update (#4029)</li> <li>deps-dev: bump sentry-sdk from 1.43.0 to 1.44.0 (#4040)</li> <li>docs: update highlighted lines on the Typing examples (#4131)</li> </ul>"
        },
        {
            "location": "changelog/#v2360-2024-03-27",
            "title": "v2.36.0 - 2024-03-27",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_22",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: always add 422 response to the schema (#3995)</li> <li>event_handler: make decoded_body field optional in ApiGateway resolver (#3937)</li> <li>tracer: add name sanitization for X-Ray subsegments (#4005)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_8",
            "title": "Code Refactoring",
            "text": "<ul> <li>logger: add type annotation for append_keys method (#3988)</li> <li>parameters: improve typing for get_secret method (#3910)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_18",
            "title": "Documentation",
            "text": "<ul> <li>batch: improved the example demonstrating how to create a custom partial processor. (#4024)</li> <li>bedrock-agents: fix type in Bedrock operation example (#3948)</li> <li>tutorial: fix \"Simplifying with Tracer\" section in the tutorial  (#3962)</li> </ul>"
        },
        {
            "location": "changelog/#features_17",
            "title": "Features",
            "text": "<ul> <li>batch: add flag in SqsFifoProcessor to enable continuous message processing (#3954)</li> <li>data_classes: Add CloudWatchAlarmEvent data class (#3868)</li> <li>event-handler: add compress option when serving Swagger HTML (#3946)</li> <li>event_handler:  define exception_handler directly from the router (#3979)</li> <li>metrics: allow custom timestamps for metrics (#4006)</li> <li>parameters: add feature for creating and updating Parameters and Secrets (#2858)</li> <li>tracer: auto-disable tracer when for AWS SAM and Chalice environments (#3949)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_23",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump squidfunk/mkdocs-material from <code>3678304</code> to <code>6c81a89</code> in /docs (#3973)</li> <li>deps: bump datadog-lambda from 5.89.0 to 5.90.0 (#3941)</li> <li>deps: bump actions/checkout from 4.1.1 to 4.1.2 (#3939)</li> <li>deps: bump redis from 5.0.2 to 5.0.3 (#3929)</li> <li>deps: bump slsa-framework/slsa-github-generator from 1.9.0 to 1.10.0 (#3997)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#4001)</li> <li>deps: bump actions/dependency-review-action from 4.2.3 to 4.2.4 (#4012)</li> <li>deps: bump docker/setup-buildx-action from 3.1.0 to 3.2.0 (#3955)</li> <li>deps: bump actions/dependency-review-action from 4.1.3 to 4.2.3 (#3993)</li> <li>deps: bump datadog-lambda from 5.90.0 to 5.91.0 (#3958)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.8.12 to 1.8.14 (#3918)</li> <li>deps: bump squidfunk/mkdocs-material from <code>6c81a89</code> to <code>3307665</code> in /docs (#4017)</li> <li>deps: bump actions/dependency-review-action from 4.2.4 to 4.2.5 (#4023)</li> <li>deps: bump aws-encryption-sdk from 3.1.1 to 3.2.0 (#3983)</li> <li>deps: bump actions/setup-python from 5.0.0 to 5.1.0 (#4022)</li> <li>deps: bump codecov/codecov-action from 4.1.0 to 4.1.1 (#4021)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3972)</li> <li>deps-dev: bump filelock from 3.13.1 to 3.13.3 (#4014)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.90 to 0.1.91 (#3975)</li> <li>deps-dev: bump types-python-dateutil from 2.9.0.20240315 to 2.9.0.20240316 (#3977)</li> <li>deps-dev: bump mkdocs-material from 9.5.13 to 9.5.14 (#3978)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.132.1a0 to 2.133.0a0 (#3976)</li> <li>deps-dev: bump the boto-typing group with 2 updates (#3974)</li> <li>deps-dev: bump the boto-typing group with 2 updates (#3982)</li> <li>deps-dev: bump ruff from 0.3.2 to 0.3.3 (#3967)</li> <li>deps-dev: bump aws-cdk-lib from 2.132.1 to 2.133.0 (#3965)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.91 to 0.1.94 (#3985)</li> <li>deps-dev: bump black from 24.2.0 to 24.3.0 (#3968)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.20240311 to 2.9.0.20240315 (#3966)</li> <li>deps-dev: bump aws-cdk from 2.132.1 to 2.133.0 (#3963)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3964)</li> <li>deps-dev: bump pytest-asyncio from 0.23.5.post1 to 0.23.6 (#3984)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3991)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.89 to 0.1.90 (#3957)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3956)</li> <li>deps-dev: bump sentry-sdk from 1.42.0 to 1.43.0 (#3992)</li> <li>deps-dev: bump coverage from 7.4.3 to 7.4.4 (#3959)</li> <li>deps-dev: bump ruff from 0.3.3 to 0.3.4 (#3996)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.88 to 0.1.89 (#3952)</li> <li>deps-dev: bump sentry-sdk from 1.41.0 to 1.42.0 (#3951)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3950)</li> <li>deps-dev: bump pytest-mock from 3.12.0 to 3.13.0 (#3999)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.94 to 0.1.96 (#4002)</li> <li>deps-dev: bump the boto-typing group with 2 updates (#3940)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.87 to 0.1.88 (#3942)</li> <li>deps-dev: bump pytest from 8.0.2 to 8.1.1 (#3943)</li> <li>deps-dev: bump aws-cdk-aws-lambda-python-alpha from 2.131.0a0 to 2.132.1a0 (#3944)</li> <li>deps-dev: bump cfn-lint from 0.86.0 to 0.86.1 (#3998)</li> <li>deps-dev: bump aws-cdk from 2.132.0 to 2.132.1 (#3938)</li> <li>deps-dev: bump aws-cdk-lib from 2.131.0 to 2.132.1 (#3936)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.96 to 0.1.99 (#4008)</li> <li>deps-dev: bump aws-cdk from 2.131.0 to 2.132.0 (#3928)</li> <li>deps-dev: bump types-redis from 4.6.0.20240218 to 4.6.0.20240311 (#3931)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.20240106 to 2.8.19.20240311 (#3932)</li> <li>deps-dev: bump pytest-mock from 3.13.0 to 3.14.0 (#4007)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.99 to 0.1.101 (#4015)</li> <li>deps-dev: bump ruff from 0.3.0 to 0.3.2 (#3925)</li> <li>deps-dev: bump mypy from 1.8.0 to 1.9.0 (#3921)</li> <li>deps-dev: bump bandit from 1.7.7 to 1.7.8 (#3920)</li> <li>deps-dev: bump pytest-cov from 4.1.0 to 5.0.0 (#4013)</li> <li>deps-dev: bump pytest-asyncio from 0.23.5 to 0.23.5.post1 (#3923)</li> <li>deps-dev: bump mkdocs-material from 9.5.14 to 9.5.15 (#4016)</li> <li>deps-dev: bump the boto-typing group with 2 updates (#3919)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.101 to 0.1.104 (#4020)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.83 to 0.1.87 (#3930)</li> </ul>"
        },
        {
            "location": "changelog/#v2351-2024-03-08",
            "title": "v2.35.1 - 2024-03-08",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_23",
            "title": "Bug Fixes",
            "text": "<ul> <li>data_sources: ensure correct types on SQSMessageAttributes (#3898)</li> <li>event_handler: validate POST bodies on BedrockAgentResolver (#3903)</li> <li>internal: call ruff with correct args (#3901)</li> </ul>"
        },
        {
            "location": "changelog/#features_18",
            "title": "Features",
            "text": "<ul> <li>event_handler: use custom serializer during openapi serialization (#3900)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_24",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump aws-xray-sdk from 2.12.1 to 2.13.0 (#3906)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3911)</li> <li>deps: bump squidfunk/mkdocs-material from <code>7be068b</code> to <code>3678304</code> in /docs (#3894)</li> <li>deps: bump datadog-lambda from 5.88.0 to 5.89.0 (#3907)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.81 to 0.1.82 (#3896)</li> <li>deps-dev: bump sentry-sdk from 1.40.6 to 1.41.0 (#3905)</li> <li>deps-dev: bump mkdocs-material from 9.5.12 to 9.5.13 (#3895)</li> <li>deps-dev: bump cdklabs-generative-ai-cdk-constructs from 0.1.82 to 0.1.83 (#3908)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3904)</li> </ul>"
        },
        {
            "location": "changelog/#v2350-2024-03-06",
            "title": "v2.35.0 - 2024-03-06",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_24",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: OpenAPI schema version respects Pydantic version (#3860)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_9",
            "title": "Code Refactoring",
            "text": "<ul> <li>logger: improve typing (#3869)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_19",
            "title": "Documentation",
            "text": "<ul> <li>event_handler: add bedrock agent resolver documentation (#3602)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_25",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump docker/setup-buildx-action from 3.0.0 to 3.1.0 (#3864)</li> <li>deps: bump actions/download-artifact from 4.1.3 to 4.1.4 (#3875)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3884)</li> <li>deps: bump squidfunk/mkdocs-material from <code>49d1bfd</code> to <code>7be068b</code> in /docs (#3872)</li> <li>deps: bump squidfunk/mkdocs-material from <code>43b898a</code> to <code>49d1bfd</code> in /docs (#3857)</li> <li>deps: bump codecov/codecov-action from 4.0.2 to 4.1.0 (#3856)</li> <li>deps: bump redis from 5.0.1 to 5.0.2 (#3867)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3887)</li> <li>deps: bump actions/download-artifact from 4.1.2 to 4.1.3 (#3862)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.8.11 to 1.8.12 (#3863)</li> <li>deps-dev: bump aws-cdk-lib from 2.130.0 to 2.131.0 (#3881)</li> <li>deps-dev: bump cfn-lint from 0.85.3 to 0.86.0 (#3882)</li> <li>deps-dev: bump black from 24.1.1 to 24.2.0 (#3760)</li> <li>deps-dev: bump cfn-lint from 0.85.2 to 0.85.3 (#3861)</li> <li>deps-dev: bump aws-cdk from 2.130.0 to 2.131.0 (#3883)</li> <li>deps-dev: bump mkdocs-material from 9.5.11 to 9.5.12 (#3870)</li> <li>deps-dev: bump ruff from 0.2.2 to 0.3.0 (#3871)</li> <li>docs: add Bedrock Agents to feature list (#3889)</li> </ul>"
        },
        {
            "location": "changelog/#v2342-2024-02-26",
            "title": "v2.34.2 - 2024-02-26",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_25",
            "title": "Bug Fixes",
            "text": "<ul> <li>typing: ensure return type is a str when default_value is set (#3840)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_20",
            "title": "Documentation",
            "text": "<ul> <li>install: make minimum install the default option then extra (#3834)</li> </ul>"
        },
        {
            "location": "changelog/#features_19",
            "title": "Features",
            "text": "<ul> <li>event-source: add function to get multi-value query string params by name (#3846)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_26",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: remove aws-encryption-sdk from Lambda layer due to cffi being tied to python version (#3853)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3844)</li> <li>deps: bump cryptography from 42.0.2 to 42.0.4 (#3827)</li> <li>deps: bump codecov/codecov-action from 4.0.1 to 4.0.2 (#3842)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3835)</li> <li>deps-dev: bump httpx from 0.26.0 to 0.27.0 (#3828)</li> <li>deps-dev: bump aws-cdk from 2.128.0 to 2.129.0 (#3831)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3836)</li> <li>deps-dev: bump aws-cdk from 2.129.0 to 2.130.0 (#3843)</li> <li>deps-dev: bump aws-cdk-lib from 2.128.0 to 2.130.0 (#3838)</li> </ul>"
        },
        {
            "location": "changelog/#v2341-2024-02-21",
            "title": "v2.34.1 - 2024-02-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_26",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: inject PR_LABELS env for PR Label automation (#3819)</li> <li>ci: revert layer version bump write-only back to append  (#3818)</li> <li>event-handler: return dict on missing multi_value_headers (#3824)</li> <li>idempotency: validate before saving to cache (#3822)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_27",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps-dev: bump ruff from 0.2.1 to 0.2.2 (#3802)</li> <li>deps-dev: bump the boto-typing group with 2 updates (#3810)</li> </ul>"
        },
        {
            "location": "changelog/#v2340-2024-02-21",
            "title": "v2.34.0 - 2024-02-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_27",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: create one layer artifact per region &amp; merge (#3808)</li> <li>event-handler: multi-value query string and validation of scalar parameters (#3795)</li> <li>event-handler: swagger schema respects api stage (#3796)</li> <li>event-handler: handle aliased parameters e.g., Query(alias=\"categoryType\") (#3766)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_10",
            "title": "Code Refactoring",
            "text": "<ul> <li>feature-flags: add intersection tests; structure refinement (#3775)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_21",
            "title": "Documentation",
            "text": "<ul> <li>feature_flags: fix incorrect line markers and envelope name (#3792)</li> <li>home: update layer version to 62 for package version 2.33.1 (#3778)</li> <li>home: add note about POWERTOOLS_DEV side effects in CloudWatch Logs (#3770)</li> <li>homepage: discord flat badge style; remove former devax email (#3768)</li> <li>homepage: remove leftover announcement banner (#3783)</li> <li>roadmap: latest roadmap update; use new grid to de-clutter homepage (#3755)</li> <li>we-made-this: add swagger post (#3799)</li> <li>we-made-this: add reinvent 2023 session (#3790)</li> </ul>"
        },
        {
            "location": "changelog/#features_20",
            "title": "Features",
            "text": "<ul> <li>feature_flags: add intersect actions for conditions (#3692)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_28",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump actions/dependency-review-action from 4.1.2 to 4.1.3 (#3813)</li> <li>deps: bump actions/dependency-review-action from 4.1.0 to 4.1.2 (#3800)</li> <li>deps: bump actions/dependency-review-action from 4.0.0 to 4.1.0 (#3771)</li> <li>deps: bump squidfunk/mkdocs-material from <code>62d3668</code> to <code>43b898a</code> in /docs (#3801)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3764)</li> <li>deps: bump squidfunk/mkdocs-material from <code>6a72238</code> to <code>62d3668</code> in /docs (#3756)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 2 updates (#3814)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3784)</li> <li>deps-dev: bump pytest from 8.0.0 to 8.0.1 (#3812)</li> <li>deps-dev: bump aws-cdk from 2.127.0 to 2.128.0 (#3776)</li> <li>deps-dev: bump the boto-typing group with 2 updates (#3797)</li> <li>deps-dev: bump cfn-lint from 0.85.1 to 0.85.2 (#3786)</li> <li>deps-dev: bump pytest-asyncio from 0.21.1 to 0.23.5 (#3773)</li> <li>deps-dev: bump aws-cdk-lib from 2.127.0 to 2.128.0 (#3777)</li> <li>deps-dev: bump sentry-sdk from 1.40.3 to 1.40.4 (#3765)</li> <li>deps-dev: bump sentry-sdk from 1.40.4 to 1.40.5 (#3805)</li> <li>deps-dev: bump mkdocs-material from 9.5.9 to 9.5.10 (#3803)</li> <li>deps-dev: bump types-redis from 4.6.0.20240106 to 4.6.0.20240218 (#3804)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3757)</li> <li>deps-dev: bump aws-cdk-lib from 2.126.0 to 2.127.0 (#3758)</li> <li>deps-dev: bump aws-cdk from 2.126.0 to 2.127.0 (#3761)</li> <li>deps-dev: bump mkdocs-material from 9.5.8 to 9.5.9 (#3759)</li> <li>deps-dev: bump sentry-sdk from 1.40.2 to 1.40.3 (#3750)</li> <li>deps-dev: bump cfn-lint from 0.85.0 to 0.85.1 (#3749)</li> <li>deps-dev: bump coverage from 7.4.1 to 7.4.2 (#3811)</li> <li>tests: increase idempotency coverage with nested payload tampering tests (#3809)</li> </ul>"
        },
        {
            "location": "changelog/#v2331-2024-02-09",
            "title": "v2.33.1 - 2024-02-09",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_28",
            "title": "Bug Fixes",
            "text": "<ul> <li>typing: make Response headers covariant (#3745)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_22",
            "title": "Documentation",
            "text": "<ul> <li>Add nathan hanks post community (#3727)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_29",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: drop support for Python 3.7 (#3638)</li> <li>ci: enable Redis e2e tests (#3718)</li> <li>deps: bump actions/setup-node from 4.0.1 to 4.0.2 (#3737)</li> <li>deps: bump squidfunk/mkdocs-material from <code>e0d6c67</code> to <code>6a72238</code> in /docs (#3735)</li> <li>deps: bump actions/dependency-review-action from 3.1.5 to 4.0.0 (#3646)</li> <li>deps: bump release-drafter/release-drafter from 5.25.0 to 6.0.0 (#3699)</li> <li>deps: bump actions/download-artifact from 4.1.1 to 4.1.2 (#3725)</li> <li>deps: bump squidfunk/mkdocs-material from <code>a4a2029</code> to <code>e0d6c67</code> in /docs (#3708)</li> <li>deps: bump codecov/codecov-action from 3.1.6 to 4.0.1 (#3700)</li> <li>deps: bump actions/download-artifact from 3.0.2 to 4.1.1 (#3612)</li> <li>deps: revert aws-cdk-lib as a runtime dep (#3730)</li> <li>deps: bump actions/upload-artifact from 3.1.3 to 4.3.1 (#3714)</li> <li>deps-dev: bump cfn-lint from 0.83.8 to 0.85.0 (#3724)</li> <li>deps-dev: bump httpx from 0.24.1 to 0.26.0 (#3712)</li> <li>deps-dev: bump pytest from 7.4.4 to 8.0.0 (#3711)</li> <li>deps-dev: bump sentry-sdk from 1.40.1 to 1.40.2 (#3740)</li> <li>deps-dev: bump coverage from 7.2.7 to 7.4.1 (#3713)</li> <li>deps-dev: bump the boto-typing group with 7 updates (#3709)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.14 to 2.8.19.20240106 (#3720)</li> <li>deps-dev: bump mypy from 1.4.1 to 1.8.0 (#3710)</li> <li>deps-dev: bump ruff from 0.2.0 to 0.2.1 (#3742)</li> <li>deps-dev: bump isort from 5.11.5 to 5.13.2 (#3723)</li> <li>deps-dev: bump pytest-socket from 0.6.0 to 0.7.0 (#3721)</li> <li>deps-dev: bump ruff from 0.1.15 to 0.2.0 (#3702)</li> <li>deps-dev: bump aws-cdk from 2.125.0 to 2.126.0 (#3701)</li> <li>deps-dev: bump hvac from 1.2.1 to 2.1.0 (#3738)</li> <li>deps-dev: bump black from 23.12.1 to 24.1.1 (#3739)</li> </ul>"
        },
        {
            "location": "changelog/#v2330-2024-02-02",
            "title": "v2.33.0 - 2024-02-02",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_29",
            "title": "Bug Fixes",
            "text": "<ul> <li>data-masking: fix and improve e2e tests for DataMasking (#3695)</li> <li>event-handler: strip whitespace from Content-Type headers during OpenAPI schema validation (#3677)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_23",
            "title": "Documentation",
            "text": "<ul> <li>data-masking: add docs for data masking utility (#3186)</li> <li>metrics: fix empty metric warning filter (#3660)</li> <li>proccess: add versioning and maintenance policy (#3682)</li> </ul>"
        },
        {
            "location": "changelog/#features_21",
            "title": "Features",
            "text": "<ul> <li>event_handler: support Header parameter validation in OpenAPI schema (#3687)</li> <li>event_handler: add support for multiValueQueryStringParameters in OpenAPI schema (#3667)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_30",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump codecov/codecov-action from 3.1.5 to 3.1.6 (#3683)</li> <li>deps: bump codecov/codecov-action from 3.1.4 to 3.1.5 (#3674)</li> <li>deps: bump pydantic from 1.10.13 to 1.10.14 (#3655)</li> <li>deps: bump squidfunk/mkdocs-material from <code>58eef6c</code> to <code>9aad7af</code> in /docs (#3670)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3665)</li> <li>deps: bump squidfunk/mkdocs-material from <code>9aad7af</code> to <code>a4a2029</code> in /docs (#3679)</li> <li>deps-dev: bump sentry-sdk from 1.39.2 to 1.40.0 (#3684)</li> <li>deps-dev: bump ruff from 0.1.14 to 0.1.15 (#3685)</li> <li>deps-dev: bump ruff from 0.1.13 to 0.1.14 (#3656)</li> <li>deps-dev: bump aws-cdk from 2.122.0 to 2.123.0 (#3673)</li> <li>deps-dev: bump aws-cdk from 2.124.0 to 2.125.0 (#3693)</li> <li>deps-dev: bump aws-cdk from 2.123.0 to 2.124.0 (#3678)</li> </ul>"
        },
        {
            "location": "changelog/#v2320-2024-01-19",
            "title": "v2.32.0 - 2024-01-19",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_30",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: escape OpenAPI schema on Swagger UI (#3606)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_11",
            "title": "Code Refactoring",
            "text": "<ul> <li>event-handler: Inject CSS and JS files into SwaggerUI route when no custom CDN is used. (#3562)</li> <li>event_handler: fix BedrockAgentResolver docstring (#3645)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_24",
            "title": "Documentation",
            "text": "<ul> <li>homepage: add banner about Python 3.7 deprecation (#3618)</li> <li>i-made-this: added new article on how to create a serverless API with CDK and Powertools (#3605)</li> </ul>"
        },
        {
            "location": "changelog/#features_22",
            "title": "Features",
            "text": "<ul> <li>event_handler: add support for additional response models (#3591)</li> <li>event_handler: add support to download OpenAPI spec file (#3571)</li> <li>event_source: Add support for S3 batch operations (#3572)</li> <li>event_source: Add support for policyLevel field in CloudWatch Logs event and parser (#3624)</li> <li>idempotency: leverage new DynamoDB Failed conditional writes behavior with ReturnValuesOnConditionCheckFailure (#3446)</li> <li>idempotency: adding redis as idempotency backend (#2567)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_31",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: Disable Redis e2e until we drop Python 3.7 (#3652)</li> <li>ci: update boto3 library version to 1.26.164+ (#3632)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3649)</li> <li>deps: bump jinja2 from 3.1.2 to 3.1.3 in /docs (#3620)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3639)</li> <li>deps: bump gitpython from 3.1.37 to 3.1.41 in /docs (#3610)</li> <li>deps: bump squidfunk/mkdocs-material from <code>2f29d71</code> to <code>58eef6c</code> in /docs (#3633)</li> <li>deps: bump redis from 4.6.0 to 5.0.1 (#3613)</li> <li>deps-dev: bump gitpython from 3.1.40 to 3.1.41 (#3611)</li> <li>deps-dev: bump sentry-sdk from 1.39.1 to 1.39.2 (#3614)</li> <li>deps-dev: bump aws-cdk from 2.120.0 to 2.121.1 (#3634)</li> <li>deps-dev: bump jinja2 from 3.1.2 to 3.1.3 (#3619)</li> <li>deps-dev: bump cfn-lint from 0.83.7 to 0.83.8 (#3603)</li> <li>deps-dev: bump aws-cdk from 2.121.1 to 2.122.0 (#3648)</li> <li>deps-dev: bump ruff from 0.1.11 to 0.1.13 (#3625)</li> <li>deps-dev: bump aws-cdk from 2.118.0 to 2.120.0 (#3627)</li> </ul>"
        },
        {
            "location": "changelog/#v2310-2024-01-05",
            "title": "v2.31.0 - 2024-01-05",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_31",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: fail dispatch analytics job when Lambda call fails (#3579)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_12",
            "title": "Code Refactoring",
            "text": "<ul> <li>parameters: add overload signatures for get_parameter and get_parameters (#3534)</li> <li>parser: Improve error message when parsing models and envelopes (#3587)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_25",
            "title": "Documentation",
            "text": "<ul> <li>middleware-factory: Fix and improve typing (#3569)</li> </ul>"
        },
        {
            "location": "changelog/#features_23",
            "title": "Features",
            "text": "<ul> <li>event-handler: add description to request body in OpenAPI schema (#3548)</li> <li>event_handler: support richer top level Tags (#3543)</li> <li>layers: add new comercial region Canada - ca-west-1 (#3549)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_32",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: Remove dev dependencies locked to Pydantic v1 within the Pydantic v2 workflow. (#3582)</li> <li>deps: bump squidfunk/mkdocs-material from <code>9af3b7e</code> to <code>2f29d71</code> in /docs (#3559)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 4 updates (#3593)</li> <li>deps: bump actions/setup-node from 4.0.0 to 4.0.1 (#3535)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.2 to 3.0.3 (#3536)</li> <li>deps: bump actions/dependency-review-action from 3.1.4 to 3.1.5 (#3592)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 2 updates (#3544)</li> <li>deps: bump fastjsonschema from 2.19.0 to 2.19.1 (#3567)</li> <li>deps-dev: bump ruff from 0.1.8 to 0.1.9 (#3550)</li> <li>deps-dev: bump aws-cdk from 2.115.0 to 2.116.1 (#3553)</li> <li>deps-dev: bump aws-cdk from 2.117.0 to 2.118.0 (#3589)</li> <li>deps-dev: bump cfn-lint from 0.83.6 to 0.83.7 (#3554)</li> <li>deps-dev: bump ruff from 0.1.9 to 0.1.10 (#3583)</li> <li>deps-dev: bump pytest from 7.4.3 to 7.4.4 (#3576)</li> <li>deps-dev: bump aws-cdk from 2.116.1 to 2.117.0 (#3565)</li> <li>deps-dev: bump ruff from 0.1.10 to 0.1.11 (#3588)</li> </ul>"
        },
        {
            "location": "changelog/#v2302-2023-12-18",
            "title": "v2.30.2 - 2023-12-18",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_32",
            "title": "Bug Fixes",
            "text": "<ul> <li>event-handler: fix operation tags schema generation (#3528)</li> <li>event-handler: set default OpenAPI version to 3.0.0 (#3527)</li> <li>event-handler: upgrade Swagger UI to fix regressions (#3526)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_33",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps-dev: bump cfn-lint from 0.83.5 to 0.83.6 (#3521)</li> </ul>"
        },
        {
            "location": "changelog/#v2301-2023-12-15",
            "title": "v2.30.1 - 2023-12-15",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_33",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: allow responses and metadata when using Router (#3514)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_34",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps-dev: bump aws-cdk from 2.114.1 to 2.115.0 (#3508)</li> <li>deps-dev: bump the boto-typing group with 11 updates (#3509)</li> <li>deps-dev: bump sentry-sdk from 1.39.0 to 1.39.1 (#3512)</li> </ul>"
        },
        {
            "location": "changelog/#v2300-2023-12-14",
            "title": "v2.30.0 - 2023-12-14",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_34",
            "title": "Bug Fixes",
            "text": "<ul> <li>docs: make the Lambda Layer version consistent (#3498)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_26",
            "title": "Documentation",
            "text": "<ul> <li>customer-reference: add Transformity as a customer reference (#3497)</li> </ul>"
        },
        {
            "location": "changelog/#features_24",
            "title": "Features",
            "text": "<ul> <li>general: add support for Python 3.12 (#3304)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_35",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump squidfunk/mkdocs-material from <code>876b39c</code> to <code>9af3b7e</code> in /docs (#3486)</li> <li>deps-dev: bump sentry-sdk from 1.38.0 to 1.39.0 (#3495)</li> <li>deps-dev: bump cfn-lint from 0.83.4 to 0.83.5 (#3487)</li> <li>deps-dev: bump ruff from 0.1.7 to 0.1.8 (#3501)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3500)</li> <li>tests: temporarily disable E2E parallelism  (#3484)</li> </ul>"
        },
        {
            "location": "changelog/#v2291-2023-12-11",
            "title": "v2.29.1 - 2023-12-11",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_35",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: log non-ascii characters as is when JSON stringifying (#3475)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_36",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump squidfunk/mkdocs-material from <code>8c72011</code> to <code>20241c6</code> in /docs (#3470)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 2 updates (#3476)</li> <li>deps: bump actions/setup-python from 4.8.0 to 5.0.0 (#3465)</li> <li>deps: bump squidfunk/mkdocs-material from <code>20241c6</code> to <code>876b39c</code> in /docs (#3477)</li> <li>deps: bump datadog-lambda from 5.84.0 to 5.85.0 (#3466)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 2 updates (#3467)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3469)</li> <li>deps-dev: bump aws-cdk from 2.113.0 to 2.114.1 (#3464)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3478)</li> </ul>"
        },
        {
            "location": "changelog/#v2290-2023-12-06",
            "title": "v2.29.0 - 2023-12-06",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_36",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: serialize pydantic/dataclasses in exception handler (#3455)</li> <li>metrics: lambda_handler typing, and **kwargs preservation all middlewares (#3460)</li> </ul>"
        },
        {
            "location": "changelog/#features_25",
            "title": "Features",
            "text": "<ul> <li>event_sources: add get_context() to standardize API Gateway Lambda Authorizer context in v1 and v2 (#3454)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_37",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3441)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.1 to 3.0.2 (#3449)</li> <li>deps: bump datadog-lambda from 5.83.0 to 5.84.0 (#3438)</li> <li>deps: bump cryptography from 41.0.4 to 41.0.6 (#3431)</li> <li>deps: bump squidfunk/mkdocs-material from <code>fc42bac</code> to <code>8c72011</code> in /docs (#3416)</li> <li>deps: bump actions/dependency-review-action from 3.1.3 to 3.1.4 (#3426)</li> <li>deps: bump actions/setup-python from 4.7.1 to 4.8.0 (#3456)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.8.10 to 1.8.11 (#3433)</li> <li>deps-dev: bump cfn-lint from 0.83.3 to 0.83.4 (#3450)</li> <li>deps-dev: bump ruff from 0.1.6 to 0.1.7 (#3458)</li> <li>deps-dev: bump sentry-sdk from 1.36.0 to 1.38.0 (#3435)</li> <li>deps-dev: bump aws-cdk-lib from 2.110.1 to 2.111.0 (#3428)</li> <li>deps-dev: bump aws-cdk from 2.112.0 to 2.113.0 (#3448)</li> <li>deps-dev: bump aws-cdk from 2.110.1 to 2.111.0 (#3418)</li> <li>deps-dev: bump the boto-typing group with 11 updates (#3427)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3457)</li> <li>deps-dev: bump aws-cdk from 2.111.0 to 2.112.0 (#3440)</li> <li>layers: Update log retention to 10 years (#3424)</li> </ul>"
        },
        {
            "location": "changelog/#v2281-2023-11-28",
            "title": "v2.28.1 - 2023-11-28",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_37",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: fix compress handling (#3420)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_38",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> </ul>"
        },
        {
            "location": "changelog/#v2280-2023-11-23",
            "title": "v2.28.0 - 2023-11-23",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_38",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: hide error details by default (#3406)</li> <li>event_handler: fix format for OpenAPI path templating (#3399)</li> <li>event_handler: lazy load Pydantic to improve cold start (#3397)</li> <li>event_handler: allow fine grained Response with data validation (#3394)</li> <li>event_handler: apply serialization as the last operation for middlewares (#3392)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_27",
            "title": "Documentation",
            "text": "<ul> <li>event_handlers: new data validation and OpenAPI feature (#3386)</li> </ul>"
        },
        {
            "location": "changelog/#features_26",
            "title": "Features",
            "text": "<ul> <li>event_handler: allow customers to catch request validation errors (#3396)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_39",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3389)</li> <li>deps: bump datadog-lambda from 4.82.0 to 5.83.0 (#3401)</li> <li>deps-dev: bump aws-cdk-lib from 2.110.0 to 2.110.1 (#3402)</li> <li>deps-dev: bump pytest-xdist from 3.4.0 to 3.5.0 (#3387)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3400)</li> <li>deps-dev: bump sentry-sdk from 1.35.0 to 1.36.0 (#3388)</li> <li>deps-dev: bump aws-cdk from 2.110.0 to 2.110.1 (#3403)</li> </ul>"
        },
        {
            "location": "changelog/#v2271-2023-11-21",
            "title": "v2.27.1 - 2023-11-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_39",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: allow custom JMESPath functions to extract correlation ID (#3382)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_28",
            "title": "Documentation",
            "text": "<ul> <li>event_handlers: note that CORS and / binary mime type don't work in API Gateway (#3383)</li> <li>logger: improve ALC messaging in the PT context (#3359)</li> <li>logger: Fix ALC link (#3352)</li> </ul>"
        },
        {
            "location": "changelog/#features_27",
            "title": "Features",
            "text": "<ul> <li>logger: implement addFilter/removeFilter to address static typing errors (#3380)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_40",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: lint and type checking removal in Pydantic v2 quality check (#3360)</li> <li>deps: bump actions/github-script from 7.0.0 to 7.0.1 (#3377)</li> <li>deps: bump squidfunk/mkdocs-material from <code>2c57e4d</code> to <code>fc42bac</code> in /docs (#3375)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 2 updates (#3353)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3374)</li> <li>deps: bump squidfunk/mkdocs-material from <code>f486dc9</code> to <code>2c57e4d</code> in /docs (#3366)</li> <li>deps-dev: bump cfn-lint from 0.83.2 to 0.83.3 (#3363)</li> <li>deps-dev: bump the boto-typing group with 11 updates (#3362)</li> <li>deps-dev: bump aws-cdk-lib from 2.108.1 to 2.110.0 (#3365)</li> <li>deps-dev: bump aws-cdk from 2.108.1 to 2.109.0 (#3354)</li> <li>deps-dev: bump aws-cdk from 2.109.0 to 2.110.0 (#3361)</li> <li>deps-dev: bump the boto-typing group with 2 updates (#3376)</li> <li>deps-dev: bump ruff from 0.1.5 to 0.1.6 (#3364)</li> </ul>"
        },
        {
            "location": "changelog/#v2270-2023-11-16",
            "title": "v2.27.0 - 2023-11-16",
            "text": ""
        },
        {
            "location": "changelog/#features_28",
            "title": "Features",
            "text": "<ul> <li>logger: Adding support to new env variables (#3348)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_41",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump actions/github-script from 6.4.1 to 7.0.0 (#3330)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 2 updates (#3340)</li> <li>deps: bump fastjsonschema from 2.18.1 to 2.19.0 (#3337)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3345)</li> <li>deps: bump actions/dependency-review-action from 3.1.2 to 3.1.3 (#3331)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3329)</li> <li>deps: bump datadog-lambda from 4.81.0 to 4.82.0 (#3338)</li> <li>deps-dev: bump cfn-lint from 0.83.1 to 0.83.2 (#3335)</li> <li>deps-dev: bump aws-cdk from 2.108.0 to 2.108.1 (#3344)</li> <li>deps-dev: bump sentry-sdk from 1.34.0 to 1.35.0 (#3334)</li> <li>deps-dev: bump pytest-xdist from 3.3.1 to 3.4.0 (#3332)</li> <li>deps-dev: bump aws-cdk-lib from 2.107.0 to 2.108.1 (#3343)</li> <li>deps-dev: bump aws-cdk from 2.106.0 to 2.106.1 (#3328)</li> <li>deps-dev: bump aws-cdk-lib from 2.105.0 to 2.106.0 (#3319)</li> <li>deps-dev: bump aws-cdk from 2.105.0 to 2.106.0 (#3320)</li> <li>deps-dev: bump aws-cdk from 2.106.1 to 2.108.0 (#3341)</li> <li>deps-dev: bump aws-cdk-lib from 2.106.0 to 2.107.0 (#3333)</li> </ul>"
        },
        {
            "location": "changelog/#v2261-2023-11-10",
            "title": "v2.26.1 - 2023-11-10",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_40",
            "title": "Bug Fixes",
            "text": "<ul> <li>event-handler: enable path parameters on Bedrock handler (#3312)</li> <li>event_handler: Router prefix mismatch regression after Middleware feat (#3302)</li> <li>event_source: kinesis subsequenceNumber str type to int (#3275)</li> <li>parameters: Respect POWERTOOLS_PARAMETERS_SSM_DECRYPT environment variable when getting multiple ssm parameters. (#3241)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_29",
            "title": "Documentation",
            "text": "<ul> <li>customer-reference: add Vertex Pharmaceuticals as a customer reference (#3210)</li> <li>event-handler: fixed SchemaValidationMiddleware link (#3247)</li> </ul>"
        },
        {
            "location": "changelog/#features_29",
            "title": "Features",
            "text": "<ul> <li>data_classes: add support for Bedrock Agents event (#3262)</li> <li>event_handler: add Bedrock Agent event handler (#3285)</li> <li>event_handler: add ability to expose a Swagger UI (#3254)</li> <li>event_handler: generate OpenAPI specifications and validate input/output (#3109)</li> <li>parser: add BedrockEventModel parser and envelope (#3286)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_42",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.1.5 to 3.0.0 (#3289)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3287)</li> <li>deps: bump actions/checkout from 4.1.0 to 4.1.1 (#3220)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3282)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.1.4 to 2.1.5 (#3281)</li> <li>deps: bump release-drafter/release-drafter from 5.24.0 to 5.25.0 (#3219)</li> <li>deps: bump squidfunk/mkdocs-material from <code>cb38dc2</code> to <code>df9409b</code> in /docs (#3216)</li> <li>deps: bump urllib3 from 1.26.17 to 1.26.18 (#3222)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 2 updates (#3298)</li> <li>deps: bump squidfunk/mkdocs-material from <code>772e14e</code> to <code>f486dc9</code> in /docs (#3299)</li> <li>deps: bump datadog-lambda from 4.80.0 to 4.81.0 (#3228)</li> <li>deps: bump actions/setup-node from 3.8.1 to 4.0.0 (#3244)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 3.0.0 to 3.0.1 (#3300)</li> <li>deps: bump actions/dependency-review-action from 3.1.0 to 3.1.1 (#3301)</li> <li>deps: bump squidfunk/mkdocs-material from <code>df9409b</code> to <code>772e14e</code> in /docs (#3265)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3305)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 2 updates (#3248)</li> <li>deps: bump actions/dependency-review-action from 3.1.1 to 3.1.2 (#3308)</li> <li>deps: bump ossf/scorecard-action from 2.3.0 to 2.3.1 (#3245)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3310)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3215)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3313)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3278)</li> <li>deps-dev: bump pytest from 7.4.2 to 7.4.3 (#3249)</li> <li>deps-dev: bump ruff from 0.1.1 to 0.1.2 (#3250)</li> <li>deps-dev: bump the boto-typing group with 2 updates (#3242)</li> <li>deps-dev: bump aws-cdk-lib from 2.102.0 to 2.103.0 (#3258)</li> <li>deps-dev: bump cfn-lint from 0.82.2 to 0.83.0 (#3243)</li> <li>deps-dev: bump ruff from 0.1.2 to 0.1.3 (#3257)</li> <li>deps-dev: bump aws-cdk from 2.102.0 to 2.103.0 (#3259)</li> <li>deps-dev: bump ruff from 0.1.0 to 0.1.1 (#3235)</li> <li>deps-dev: bump aws-cdk-lib from 2.103.0 to 2.103.1 (#3263)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3231)</li> <li>deps-dev: bump aws-cdk from 2.101.1 to 2.102.0 (#3232)</li> <li>deps-dev: bump aws-cdk from 2.103.0 to 2.103.1 (#3264)</li> <li>deps-dev: bump cfn-lint from 0.82.0 to 0.82.2 (#3229)</li> <li>deps-dev: bump cfn-lint from 0.83.0 to 0.83.1 (#3274)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3273)</li> <li>deps-dev: bump cfn-lint from 0.81.0 to 0.82.0 (#3224)</li> <li>deps-dev: bump aws-cdk from 2.101.0 to 2.101.1 (#3223)</li> <li>deps-dev: bump sentry-sdk from 1.32.0 to 1.33.1 (#3277)</li> <li>deps-dev: bump urllib3 from 1.26.17 to 1.26.18 in /layer (#3221)</li> <li>deps-dev: bump aws-cdk from 2.103.1 to 2.104.0 (#3288)</li> <li>deps-dev: bump sentry-sdk from 1.33.1 to 1.34.0 (#3290)</li> <li>deps-dev: bump aws-cdk-lib from 2.103.1 to 2.104.0 (#3291)</li> <li>deps-dev: bump aws-cdk-lib from 2.100.0 to 2.101.1 (#3217)</li> <li>deps-dev: bump aws-cdk from 2.100.0 to 2.101.0 (#3214)</li> <li>deps-dev: bump aws-cdk from 2.104.0 to 2.105.0 (#3307)</li> <li>deps-dev: bump ruff from 0.1.3 to 0.1.4 (#3297)</li> <li>deps-dev: bump aws-cdk-lib from 2.104.0 to 2.105.0 (#3309)</li> <li>deps-dev: bump the boto-typing group with 2 updates (#3211)</li> <li>deps-dev: bump the boto-typing group with 3 updates (#3314)</li> <li>deps-dev: bump ruff from 0.1.4 to 0.1.5 (#3315)</li> <li>deps-dev: bump ruff from 0.0.292 to 0.1.0 (#3213)</li> </ul>"
        },
        {
            "location": "changelog/#v2260-2023-10-13",
            "title": "v2.26.0 - 2023-10-13",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_41",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: force Logger to use local timezone when UTC flag is not set (#3168)</li> <li>parameter: improve AppConfig cached configuration retrieval (#3195)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_13",
            "title": "Code Refactoring",
            "text": "<ul> <li>data-masking: disable e2e tests. (#3204)</li> <li>data_masking: move Data Masking utility to a private folder (#3202)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_30",
            "title": "Documentation",
            "text": "<ul> <li>contributing: initial structure for revamped contributing guide (#3133)</li> <li>event_handler: add information about case-insensitive header lookup function (#3183)</li> </ul>"
        },
        {
            "location": "changelog/#features_30",
            "title": "Features",
            "text": "<ul> <li>data_masking: add new sensitive data masking utility (#2197)</li> <li>event_handler: add support to VPC Lattice payload v2 (#3153)</li> <li>layers: add arm64 support in more regions (#3151)</li> <li>logger: new stack_trace field with rich exception details (#3147)</li> <li>parser: infer model from type hint (#3181)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_43",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump squidfunk/mkdocs-material from <code>cbfecae</code> to <code>a4cfa88</code> in /docs (#3175)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3174)</li> <li>deps: bump squidfunk/mkdocs-material from <code>b41ba6d</code> to <code>06673a1</code> in /docs (#3124)</li> <li>deps: bump ossf/scorecard-action from 2.2.0 to 2.3.0 (#3178)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3198)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#3177)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3127)</li> <li>deps: bump urllib3 from 1.26.16 to 1.26.17 (#3162)</li> <li>deps: bump aws-xray-sdk from 2.12.0 to 2.12.1 (#3197)</li> <li>deps: bump fastjsonschema from 2.18.0 to 2.18.1 (#3159)</li> <li>deps: bump actions/setup-python from 4.7.0 to 4.7.1 (#3158)</li> <li>deps: bump actions/checkout from 4.0.0 to 4.1.0 (#3128)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3156)</li> <li>deps: bump squidfunk/mkdocs-material from <code>e5f28aa</code> to <code>cbfecae</code> in /docs (#3157)</li> <li>deps: bump squidfunk/mkdocs-material from <code>06673a1</code> to <code>e5f28aa</code> in /docs (#3134)</li> <li>deps: bump squidfunk/mkdocs-material from <code>a4cfa88</code> to <code>cb38dc2</code> in /docs (#3189)</li> <li>deps: bump pydantic from 1.10.12 to 1.10.13 (#3144)</li> <li>deps: bump gitpython from 3.1.35 to 3.1.37 in /docs (#3188)</li> <li>deps-dev: bump types-requests from 2.31.0.5 to 2.31.0.6 (#3145)</li> <li>deps-dev: bump aws-cdk from 2.98.0 to 2.99.0 (#3148)</li> <li>deps-dev: bump the boto-typing group with 2 updates (#3143)</li> <li>deps-dev: bump aws-cdk from 2.99.1 to 2.100.0 (#3185)</li> <li>deps-dev: bump aws-cdk from 2.97.0 to 2.98.0 (#3139)</li> <li>deps-dev: bump aws-cdk from 2.96.2 to 2.97.0 (#3129)</li> <li>deps-dev: bump types-requests from 2.31.0.3 to 2.31.0.5 (#3136)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3135)</li> <li>deps-dev: bump ruff from 0.0.291 to 0.0.292 (#3161)</li> <li>deps-dev: bump ruff from 0.0.290 to 0.0.291 (#3126)</li> <li>deps-dev: bump aws-cdk from 2.99.0 to 2.99.1 (#3155)</li> <li>deps-dev: bump sentry-sdk from 1.31.0 to 1.32.0 (#3192)</li> <li>deps-dev: bump urllib3 from 1.26.16 to 1.26.17 in /layer (#3163)</li> <li>deps-dev: bump cfn-lint from 0.80.3 to 0.80.4 (#3166)</li> <li>deps-dev: bump cfn-lint from 0.80.2 to 0.80.3 (#3125)</li> <li>deps-dev: bump cfn-lint from 0.80.4 to 0.81.0 (#3179)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3196)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3170)</li> </ul>"
        },
        {
            "location": "changelog/#v2251-2023-09-22",
            "title": "v2.25.1 - 2023-09-22",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_42",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: add explicit None return type annotations (#3113)</li> <li>metrics: support additional arguments in functions wrapped with log_metrics decorator (#3120)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_44",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3108)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3115)</li> <li>deps: bump squidfunk/mkdocs-material from <code>4ff781e</code> to <code>b41ba6d</code> in /docs (#3117)</li> <li>deps: bump squidfunk/mkdocs-material from <code>c4890ab</code> to <code>4ff781e</code> in /docs (#3110)</li> <li>deps-dev: bump ruff from 0.0.289 to 0.0.290 (#3105)</li> <li>deps-dev: bump aws-cdk from 2.96.1 to 2.96.2 (#3102)</li> <li>deps-dev: bump the boto-typing group with 3 updates (#3118)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3101)</li> <li>deps-dev: bump cfn-lint from 0.79.11 to 0.80.2 (#3107)</li> <li>deps-dev: bump types-requests from 2.31.0.2 to 2.31.0.3 (#3114)</li> </ul>"
        },
        {
            "location": "changelog/#v2250-2023-09-15",
            "title": "v2.25.0 - 2023-09-15",
            "text": ""
        },
        {
            "location": "changelog/#code-refactoring_14",
            "title": "Code Refactoring",
            "text": "<ul> <li>parameters: BaseProvider._get to also support Dict (#3090)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_31",
            "title": "Documentation",
            "text": "<ul> <li>event_handler: fix typing in micro function example (#3098)</li> <li>event_handler: add micro function examples (#3056)</li> <li>we-made-this: fix broken Twitch video embeds (#3096)</li> </ul>"
        },
        {
            "location": "changelog/#features_31",
            "title": "Features",
            "text": "<ul> <li>event_source: add Kinesis Firehose Data Transformation data class (#3029)</li> <li>event_sources: add Secrets Manager secret rotation event (#3061)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_45",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>automation: remove previous labels when PR is updated (#3066)</li> <li>deps: bump actions/dependency-review-action from 3.0.8 to 3.1.0 (#3071)</li> <li>deps: bump docker/setup-qemu-action from 2.2.0 to 3.0.0 (#3081)</li> <li>deps: bump docker/setup-buildx-action from 2.10.0 to 3.0.0 (#3083)</li> <li>deps: bump squidfunk/mkdocs-material from <code>dd1770c</code> to <code>c4890ab</code> in /docs (#3078)</li> <li>deps-dev: bump cfn-lint from 0.79.9 to 0.79.10 (#3077)</li> <li>deps-dev: bump hvac from 1.2.0 to 1.2.1 (#3075)</li> <li>deps-dev: bump ruff from 0.0.288 to 0.0.289 (#3080)</li> <li>deps-dev: bump ruff from 0.0.287 to 0.0.288 (#3076)</li> <li>deps-dev: bump aws-cdk from 2.95.0 to 2.95.1 (#3074)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3085)</li> <li>deps-dev: bump aws-cdk from 2.95.1 to 2.96.0 (#3087)</li> <li>deps-dev: bump sentry-sdk from 1.30.0 to 1.31.0 (#3086)</li> <li>deps-dev: bump aws-cdk from 2.94.0 to 2.95.0 (#3070)</li> <li>deps-dev: bump cfn-lint from 0.79.10 to 0.79.11 (#3088)</li> <li>deps-dev: bump aws-cdk from 2.96.0 to 2.96.1 (#3093)</li> <li>typing: move backwards compat types to shared types (#3092)</li> </ul>"
        },
        {
            "location": "changelog/#v2240-2023-09-08",
            "title": "v2.24.0 - 2023-09-08",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_43",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: expanding safe URI characters to include +$&amp; (#3026)</li> <li>parser: change ApproximateCreationDateTime field to datetime in DynamoDBStreamChangedRecordModel (#3049)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_15",
            "title": "Code Refactoring",
            "text": "<ul> <li>batch: type response() method (#3023)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_32",
            "title": "Documentation",
            "text": "<ul> <li>event_handler: demonstrate how to combine logger correlation ID and middleware (#3064)</li> <li>event_handler: use correct correlation_id for logger in middleware example (#3063)</li> <li>idempotency: use tab navigation, improves custom serializer example, and additional explanations (#3067)</li> </ul>"
        },
        {
            "location": "changelog/#features_32",
            "title": "Features",
            "text": "<ul> <li>event_handler: add Middleware support for REST Event Handler (#2917)</li> <li>idempotency: add support to custom serialization/deserialization on idempotency decorator (#2951)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_46",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump squidfunk/mkdocs-material from <code>b1f7f94</code> to <code>f4764d1</code> in /docs (#3031)</li> <li>deps: bump gitpython from 3.1.32 to 3.1.35 in /docs (#3059)</li> <li>deps: bump squidfunk/mkdocs-material from <code>f4764d1</code> to <code>dd1770c</code> in /docs (#3044)</li> <li>deps: bump actions/checkout from 3.6.0 to 4.0.0 (#3041)</li> <li>deps: bump squidfunk/mkdocs-material from <code>97da15b</code> to <code>b1f7f94</code> in /docs (#3021)</li> <li>deps: bump docker/setup-buildx-action from 2.9.1 to 2.10.0 (#3022)</li> <li>deps: bump actions/upload-artifact from 3.1.2 to 3.1.3 (#3053)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 1 update (#3052)</li> <li>deps-dev: bump mkdocs-material from 9.2.6 to 9.2.7 (#3043)</li> <li>deps-dev: bump cfn-lint from 0.79.7 to 0.79.8 (#3033)</li> <li>deps-dev: bump mkdocs-material from 9.2.5 to 9.2.6 (#3032)</li> <li>deps-dev: bump ruff from 0.0.286 to 0.0.287 (#3035)</li> <li>deps-dev: bump sentry-sdk from 1.29.2 to 1.30.0 (#3028)</li> <li>deps-dev: bump the boto-typing group with 11 updates (#3027)</li> <li>deps-dev: bump pytest from 7.4.1 to 7.4.2 (#3057)</li> <li>deps-dev: bump hvac from 1.1.1 to 1.2.0  (#3054)</li> <li>deps-dev: bump cfn-lint from 0.79.8 to 0.79.9 (#3046)</li> <li>deps-dev: bump the boto-typing group with 1 update (#3013)</li> <li>deps-dev: bump pytest from 7.4.0 to 7.4.1 (#3042)</li> <li>deps-dev: bump ruff from 0.0.285 to 0.0.286 (#3014)</li> <li>deps-dev: bump gitpython from 3.1.32 to 3.1.35 (#3060)</li> <li>deps-dev: bump aws-cdk from 2.93.0 to 2.94.0 (#3036)</li> </ul>"
        },
        {
            "location": "changelog/#v2231-2023-08-25",
            "title": "v2.23.1 - 2023-08-25",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_44",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: revert aws credentials action (#3010)</li> <li>ci: change SAR assume role options (#3005)</li> <li>event_handler: make invalid chars a raw str to fix DeprecationWarning (#2982)</li> <li>metrics: preserve default_tags when metric-specific tag is set in Datadog provider (#2997)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_47",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump squidfunk/mkdocs-material from <code>cd3a522</code> to <code>97da15b</code> in /docs (#2987)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#2978)</li> <li>deps: bump aws-actions/configure-aws-credentials from 2.2.0 to 3.0.0 (#3000)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#2983)</li> <li>deps: bump slsa-framework/slsa-github-generator from 1.8.0 to 1.9.0 (#2992)</li> <li>deps: bump actions/checkout from 3.5.3 to 3.6.0 (#2999)</li> <li>deps-dev: bump ruff from 0.0.284 to 0.0.285 (#2977)</li> <li>deps-dev: bump aws-cdk from 2.92.0 to 2.93.0 (#2993)</li> <li>deps-dev: bump mkdocs-material from 9.1.21 to 9.2.0 (#2984)</li> <li>deps-dev: bump mkdocs-material from 9.2.0 to 9.2.3 (#2988)</li> </ul>"
        },
        {
            "location": "changelog/#v2230-2023-08-18",
            "title": "v2.23.0 - 2023-08-18",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_45",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: strip xray_trace_id when explicitly disabled (#2852)</li> <li>metrics: proxy service and namespace attrs to provider (#2910)</li> <li>parser: API Gateway V2 request context scope field should be optional (#2961)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_16",
            "title": "Code Refactoring",
            "text": "<ul> <li>e2e: support fail fast in get_lambda_response (#2912)</li> <li>metrics: move from protocol to ABC; split provider tests (#2934)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_33",
            "title": "Documentation",
            "text": "<ul> <li>batch: new visuals and error handling section (#2857)</li> <li>batch: explain record type discrepancy in failure and success handler (#2868)</li> <li>metrics: update Datadog integration diagram (#2954)</li> <li>navigation: remove nofollow attribute for internal links (#2867)</li> <li>navigation: add nofollow attribute (#2842)</li> <li>roadmap: update roadmap themes (#2915)</li> <li>roadmap: add GovCloud and China region item (#2960)</li> <li>tutorial: add support for Python 3.11 (#2860)</li> </ul>"
        },
        {
            "location": "changelog/#features_33",
            "title": "Features",
            "text": "<ul> <li>event_handler: allow stripping route prefixes using regexes (#2521)</li> <li>layers: add new comercial region Israel(Tel Aviv) (#2907)</li> <li>metrics: add Datadog observability provider (#2906)</li> <li>metrics: support to bring your own metrics provider (#2194)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_48",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: enable protected branch auditing (#2913)</li> <li>ci: group dependabot updates (#2896)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2 from 1.19.0 to 1.19.1 in /layer/scripts/layer-balancer (#2877)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.8.8 to 1.8.9 (#2943)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/service/lambda from 1.38.0 to 1.38.1 in /layer/scripts/layer-balancer (#2876)</li> <li>deps: bump actions/dependency-review-action from 3.0.6 to 3.0.7 (#2941)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/config from 1.18.29 to 1.18.30 in /layer/scripts/layer-balancer (#2875)</li> <li>deps: bump actions/dependency-review-action from 3.0.7 to 3.0.8 (#2963)</li> <li>deps: bump gitpython from 3.1.31 to 3.1.32 in /docs (#2948)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 2 updates (#2904)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#2933)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.8.9 to 1.8.10 (#2946)</li> <li>deps: bump actions/setup-node from 3.7.0 to 3.8.0 (#2957)</li> <li>deps: bump slsa-framework/slsa-github-generator from 1.7.0 to 1.8.0 (#2927)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/config from 1.18.28 to 1.18.29 in /layer/scripts/layer-balancer (#2844)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/service/lambda from 1.37.1 to 1.38.0 in /layer/scripts/layer-balancer (#2843)</li> <li>deps: bump pydantic from 1.10.11 to 1.10.12 (#2846)</li> <li>deps: bump the layer-balancer group in /layer/scripts/layer-balancer with 3 updates (#2971)</li> <li>deps: bump actions/setup-node from 3.8.0 to 3.8.1 (#2970)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/config from 1.18.30 to 1.18.31 in /layer/scripts/layer-balancer (#2889)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/service/lambda from 1.38.1 to 1.39.0 in /layer/scripts/layer-balancer (#2890)</li> <li>deps: bump squidfunk/mkdocs-material from <code>33e28bd</code> to <code>cd3a522</code> in /docs (#2859)</li> <li>deps-dev: bump ruff from 0.0.283 to 0.0.284 (#2940)</li> <li>deps-dev: bump cfn-lint from 0.79.5 to 0.79.6 (#2899)</li> <li>deps-dev: bump the boto-typing group with 11 updates (#2901)</li> <li>deps-dev: bump ruff from 0.0.281 to 0.0.282 (#2905)</li> <li>deps-dev: bump aws-cdk from 2.88.0 to 2.89.0 (#2887)</li> <li>deps-dev: bump aws-cdk from 2.89.0 to 2.90.0 (#2932)</li> <li>deps-dev: bump mkdocs-material from 9.1.19 to 9.1.21 (#2894)</li> <li>deps-dev: bump the boto-typing group with 3 updates (#2967)</li> <li>deps-dev: bump radon from 5.1.0 to 6.0.1 (#2964)</li> <li>deps-dev: bump the boto-typing group with 4 updates (#2928)</li> <li>deps-dev: bump mypy-boto3-logs from 1.28.1 to 1.28.15 (#2880)</li> <li>deps-dev: bump mypy-boto3-appconfigdata from 1.28.0 to 1.28.15 (#2879)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.28.11 to 1.28.15 (#2878)</li> <li>deps-dev: bump mypy-boto3-xray from 1.28.0 to 1.28.15 (#2881)</li> <li>deps-dev: bump ruff from 0.0.282 to 0.0.283 (#2937)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.28.0 to 1.28.11 (#2847)</li> <li>deps-dev: bump sentry-sdk from 1.28.1 to 1.29.0 (#2900)</li> <li>deps-dev: bump cfn-lint from 0.79.4 to 0.79.5 (#2870)</li> <li>deps-dev: bump the boto-typing group with 1 update (#2944)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.28.10 to 1.28.12 (#2864)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.28.0 to 1.28.12 (#2865)</li> <li>deps-dev: bump cfn-lint from 0.79.3 to 0.79.4 (#2862)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.28.0 to 1.28.12 (#2861)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.28.0 to 1.28.12 (#2863)</li> <li>deps-dev: bump aws-cdk from 2.90.0 to 2.91.0 (#2947)</li> <li>deps-dev: bump xenon from 0.9.0 to 0.9.1 (#2955)</li> <li>deps-dev: bump cfn-lint from 0.78.2 to 0.79.3 (#2854)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.28.0 to 1.28.11 (#2845)</li> <li>deps-dev: bump cfn-lint from 0.79.6 to 0.79.7 (#2956)</li> <li>deps-dev: bump aws-cdk from 2.91.0 to 2.92.0 (#2965)</li> <li>deps-dev: bump ruff from 0.0.280 to 0.0.281 (#2891)</li> <li>docs: include the environment variables section in the utilities documentation (#2925)</li> <li>docs: disable line length rule using older syntax (#2920)</li> <li>maintenance: enables publishing docs and changelog, running e2e tests only in the main repository (#2924)</li> </ul>"
        },
        {
            "location": "changelog/#v2220-2023-07-25",
            "title": "v2.22.0 - 2023-07-25",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_46",
            "title": "Bug Fixes",
            "text": "<ul> <li>parameters: distinct cache key for single vs path with same name (#2839)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_34",
            "title": "Documentation",
            "text": "<ul> <li>community: new batch processing article (#2828)</li> <li>parameters: improve readability on error handling get_parameter… (#2833)</li> </ul>"
        },
        {
            "location": "changelog/#features_34",
            "title": "Features",
            "text": "<ul> <li>general: add support for Python 3.11 (#2820)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_49",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: add baking time for layer build (#2834)</li> <li>ci: build changelog on a schedule only (#2832)</li> <li>deps: bump actions/setup-python from 4.6.1 to 4.7.0 (#2821)</li> <li>deps-dev: bump ruff from 0.0.278 to 0.0.279 (#2822)</li> <li>deps-dev: bump cfn-lint from 0.78.1 to 0.78.2 (#2823)</li> <li>deps-dev: bump ruff from 0.0.279 to 0.0.280 (#2836)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.28.0 to 1.28.10 (#2837)</li> </ul>"
        },
        {
            "location": "changelog/#v2210-2023-07-21",
            "title": "v2.21.0 - 2023-07-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_47",
            "title": "Bug Fixes",
            "text": "<ul> <li>docs: remove redundant code (#2796)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_35",
            "title": "Documentation",
            "text": "<ul> <li>customer-reference: add Jit Security as a customer reference (#2801)</li> </ul>"
        },
        {
            "location": "changelog/#features_35",
            "title": "Features",
            "text": "<ul> <li>parser: add support for Pydantic v2 (#2733)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_50",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps: bump squidfunk/mkdocs-material from <code>a28ed81</code> to <code>33e28bd</code> in /docs (#2797)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.28.3.post2 to 1.28.8 (#2808)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.13 to 2.8.19.14 (#2807)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.28.3.post1 to 1.28.3.post2 (#2794)</li> <li>deps-dev: bump types-requests from 2.31.0.1 to 2.31.0.2 (#2806)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.28.3.post1 to 1.28.3.post2 (#2793)</li> <li>deps-dev: bump aws-cdk from 2.87.0 to 2.88.0 (#2812)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.28.3 to 1.28.3.post1 (#2785)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.28.3 to 1.28.3.post1 (#2786)</li> <li>deps-dev: bump mkdocs-material from 9.1.18 to 9.1.19 (#2798)</li> <li>security: improve debugging for provenance script (#2784)</li> </ul>"
        },
        {
            "location": "changelog/#v2200-2023-07-14",
            "title": "v2.20.0 - 2023-07-14",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_48",
            "title": "Bug Fixes",
            "text": "<ul> <li>docs: ensure alias is applied to versioned releases (#2644)</li> <li>docs: ensure version alias is in an array to prevent \"you're not viewing the latest version\" incorrect message (#2629)</li> <li>logger: ensure logs stream to stdout by default, not stderr (#2736)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_17",
            "title": "Code Refactoring",
            "text": "<ul> <li>parser: convert functional tests to unit tests (#2656)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_36",
            "title": "Documentation",
            "text": "<ul> <li>batch: fix custom batch processor example (#2714)</li> <li>contributing: add code integration journey graph (#2685)</li> <li>maintainers: add cicd pipeline diagram (#2692)</li> <li>process: explain our integration automated checks; revamp navigation (#2764)</li> </ul>"
        },
        {
            "location": "changelog/#features_36",
            "title": "Features",
            "text": "<ul> <li>metrics: support to set default dimension in EphemeralMetrics (#2748)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_51",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: enforce pip --require-hashes to maybe satistify scorecard (#2679)</li> <li>ci: prevent merging PRs that do not meet minimum requirements (#2639)</li> <li>ci: enforce top-level permission to minimum fail-safe permission as per openssf (#2638)</li> <li>ci: propagate checkout permission to nested workflows (#2642)</li> <li>ci: improves dependabot based on ossf scorecard recommendations (#2647)</li> <li>ci: use deps sha for docs and gitpod images based on ossf findings (#2662)</li> <li>ci: use sast on every commit on any supported language (#2646)</li> <li>ci: add gitleaks in pre-commit hooks as an extra safety measure (#2677)</li> <li>ci: address ossf scorecard findings on npm, pip, and top-level permission leftover (#2694)</li> <li>ci: prevent sast codeql to run in forks (#2711)</li> <li>ci: introduce provenance and attestation in release (#2746)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.8.7 to 1.8.8 (#2754)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/service/lambda from 1.37.0 to 1.37.1 in /layer/scripts/layer-balancer (#2769)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.1.3 to 2.1.4 (#2738)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/config from 1.18.27 to 1.18.28 in /layer/scripts/layer-balancer (#2770)</li> <li>deps: bump actions/setup-python from 4.6.1 to 4.7.0 (#2768)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2 from 1.16.16 to 1.18.1 in /layer/scripts/layer-balancer (#2654)</li> <li>deps: bump golang.org/x/sync from 0.1.0 to 0.3.0 in /layer/scripts/layer-balancer (#2649)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/service/lambda from 1.24.6 to 1.37.0 in /layer/scripts/layer-balancer (#2653)</li> <li>deps: bump docker/setup-buildx-action from 2.8.0 to 2.9.0 (#2718)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2/config from 1.17.8 to 1.18.27 in /layer/scripts/layer-balancer (#2651)</li> <li>deps: bump github.com/aws/aws-sdk-go-v2 from 1.18.1 to 1.19.0 in /layer/scripts/layer-balancer (#2771)</li> <li>deps: migrate from retry to retry2 to address CVE-2022-42969 (#2665)</li> <li>deps: bump pydantic from 1.10.9 to 1.10.10 (#2624)</li> <li>deps: bump squidfunk/mkdocs-material from <code>3837c0f</code> to <code>a28ed81</code> in /docs (#2669)</li> <li>deps: bump pydantic from 1.10.10 to 1.10.11 (#2671)</li> <li>deps: bump docker/setup-buildx-action from 2.9.0 to 2.9.1 (#2755)</li> <li>deps: bump actions/dependency-review-action from 2.5.1 to 3.0.6 (#2650)</li> <li>deps: bump actions/setup-node from 3.6.0 to 3.7.0 (#2689)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.27.0 to 1.28.0 (#2698)</li> <li>deps-dev: bump sentry-sdk from 1.27.0 to 1.27.1 (#2701)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.27.0 to 1.28.0 (#2700)</li> <li>deps-dev: bump mypy-boto3-appconfigdata from 1.27.0 to 1.28.0 (#2699)</li> <li>deps-dev: bump ruff from 0.0.276 to 0.0.277 (#2682)</li> <li>deps-dev: bump pytest-asyncio from 0.21.0 to 0.21.1 (#2756)</li> <li>deps-dev: bump cfn-lint from 0.77.10 to 0.78.1 (#2757)</li> <li>deps-dev: bump aws-cdk from 2.86.0 to 2.87.0 (#2696)</li> <li>deps-dev: bump typed-ast from 1.5.4 to 1.5.5 (#2670)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.27.0 to 1.28.0 (#2697)</li> <li>deps-dev: bump ruff from 0.0.275 to 0.0.276 (#2655)</li> <li>deps-dev: bump sentry-sdk from 1.26.0 to 1.27.0 (#2652)</li> <li>deps-dev: bump ruff from 0.0.277 to 0.0.278 (#2758)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.28.0 to 1.28.3 (#2774)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.158 to 1.26.164 (#2622)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.28.0 to 1.28.3 (#2773)</li> <li>deps-dev: bump sentry-sdk from 1.27.1 to 1.28.0 (#2741)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.27.0 to 1.28.0 (#2721)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.27.0 to 1.28.0 (#2722)</li> <li>deps-dev: bump mypy-boto3-logs from 1.27.0 to 1.28.1 (#2723)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.27.0 to 1.28.0 (#2724)</li> <li>deps-dev: bump mypy-boto3-xray from 1.27.0 to 1.28.0 (#2720)</li> <li>deps-dev: bump sentry-sdk from 1.28.0 to 1.28.1 (#2772)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.27.0 to 1.28.0 (#2740)</li> <li>deps-dev: bump mypy-boto3-appconfigdata from 1.26.70 to 1.27.0 (#2636)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.27.0 to 1.28.0 (#2739)</li> <li>governance: update active maintainers list (#2715)</li> <li>streaming: replace deprecated Version classes from distutils (#2752)</li> <li>user-agent: support patching botocore session (#2614)</li> </ul>"
        },
        {
            "location": "changelog/#v2190-2023-06-30",
            "title": "v2.19.0 - 2023-06-30",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_49",
            "title": "Bug Fixes",
            "text": "<ul> <li>e2e: fix idempotency tests (#2576)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_18",
            "title": "Code Refactoring",
            "text": "<ul> <li>event_source: convert functional tests to unit tests (#2506)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_37",
            "title": "Documentation",
            "text": "<ul> <li>i-made-this: added new article on idempotency (#2582)</li> <li>i-made-this: article on idempotency w/ CDK and Powertools (#2569)</li> <li>idempotency: split snippets, improve wording and lint examples (#2492)</li> </ul>"
        },
        {
            "location": "changelog/#features_37",
            "title": "Features",
            "text": "<ul> <li>event_handler: add VPCLatticeResolver (#2601)</li> <li>event_source: decode nested messages on SQS events (#2349)</li> <li>parser: add support to VpcLatticeModel (#2584)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_52",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>analytics: update docs base origin url (#2560)</li> <li>ci: replace flake8 with Ruff as a linter (#2495)</li> <li>ci: enable Ruff rule E501 and fix errors (#2587)</li> <li>ci: enable Ruff rule COM812 and fix the errors (#2595)</li> <li>ci: enable Ruff rules PLW, PLR, PLC and PLE and fix the errors (#2593)</li> <li>ci: enable Ruff autofix rules (#2599)</li> <li>ci: enable Ruff rules ISC, I001, B018 and fix the errors (#2597)</li> <li>ci: enable Ruff rule ERA001 and fix errors (#2591)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.8.6 to 1.8.7 (#2573)</li> <li>deps: bump docker/setup-buildx-action from 2.7.0 to 2.8.0 (#2604)</li> <li>deps: bump ossf/scorecard-action from 2.1.3 to 2.2.0 (#2563)</li> <li>deps: bump release-drafter/release-drafter from 5.23.0 to 5.24.0 (#2603)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.155 to 1.26.163 (#2608)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.157 to 1.26.163 (#2607)</li> <li>deps-dev: bump mkdocs-material from 9.1.16 to 9.1.17 (#2564)</li> <li>deps-dev: bump ruff from 0.0.272 to 0.0.275 (#2586)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.26.97 to 1.26.162 (#2606)</li> <li>deps-dev: bump pytest from 7.3.2 to 7.4.0 (#2557)</li> <li>deps-dev: bump aws-cdk from 2.85.0 to 2.86.0 (#2613)</li> <li>deps-dev: bump mypy from 1.4.0 to 1.4.1 (#2574)</li> </ul>"
        },
        {
            "location": "changelog/#v2180-2023-06-23",
            "title": "v2.18.0 - 2023-06-23",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_50",
            "title": "Bug Fixes",
            "text": "<ul> <li>docs: ensure versions.json is updated (#2505)</li> <li>event_source: centralizing helper functions for query, header and base64 (#2496)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_38",
            "title": "Documentation",
            "text": "<ul> <li>homepage: fix .NET repository link (#2549)</li> <li>homepage: add Open Source Security Foundation badge; update links to new url (#2545)</li> <li>navigation: make Key Feature the first section (#2517)</li> </ul>"
        },
        {
            "location": "changelog/#features_38",
            "title": "Features",
            "text": "<ul> <li>event_handler: support to enable or disable compression in custom responses (#2544)</li> <li>feature_flags: add modulo range condition for segmented experimentation support (#2331)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_53",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: fix changelog build permissions (#2519)</li> <li>ci: remove GH pages action (#2501)</li> <li>ci: updates runner names in workflows (#2510)</li> <li>ci: introduces OSSF Scorecard (#2512)</li> <li>ci: fix codeowners team name (#2516)</li> <li>deps: bump actions/upload-artifact from 3.1.0 to 3.1.2 (#2522)</li> <li>deps: bump actions/checkout from 3.1.0 to 3.5.3 (#2523)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.153 to 1.26.155 (#2498)</li> <li>deps-dev: bump aws-cdk from 2.84.0 to 2.85.0 (#2524)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.147 to 1.26.157 (#2507)</li> <li>deps-dev: bump cfn-lint from 0.77.9 to 0.77.10 (#2508)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.149 to 1.26.156 (#2503)</li> <li>deps-dev: bump sentry-sdk from 1.25.1 to 1.26.0 (#2527)</li> <li>deps-dev: bump hvac from 1.1.0 to 1.1.1 (#2497)</li> <li>deps-dev: bump flake8-variables-names from 0.0.5 to 0.0.6 (#2525)</li> <li>deps-dev: bump ijson from 3.2.1 to 3.2.2 (#2526)</li> <li>deps-dev: bump pytest-mock from 3.10.0 to 3.11.1 (#2485)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.152 to 1.26.158 (#2528)</li> <li>deps-dev: bump mypy from 1.3.0 to 1.4.0 (#2509)</li> <li>documentation: updating repository URL and name to the new location (#2499)</li> </ul>"
        },
        {
            "location": "changelog/#v2170-2023-06-16",
            "title": "v2.17.0 - 2023-06-16",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_51",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: prioritize static over dynamic route to prevent order of route registration mismatch (#2458)</li> <li>idempotency: treat missing idempotency key as non-idempotent transaction (no-op) when raise_on_no_idempotency_key is False (#2477)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_39",
            "title": "Documentation",
            "text": "<ul> <li>event_handler: improve compress example using Response class (#2426)</li> <li>event_sources: fix DynamoDB stream event docstring (#2468)</li> <li>idempotency: new sequence flow when idempotency key is optional (#2480)</li> <li>idempotency: add CDK example (#2434)</li> <li>maintainers: visual representation of release process (#2399)</li> <li>navigation: standardize link targets to enhance customer experience (#2420)</li> <li>we-made-this: new article about idempotency design (#2425)</li> </ul>"
        },
        {
            "location": "changelog/#features_39",
            "title": "Features",
            "text": "<ul> <li>event_sources: add AWS Config Rule event data class (#2175)</li> <li>event_sources: add support for VPC Lattice events (#2358)</li> <li>logger: type log record in LambdaPowertoolsFormatter with TypedDict (#2419)</li> <li>parser: support for CloudFormation Custom Resources (#2335)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_54",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: document all github action workflows and enforce least-privilege (#2395)</li> <li>ci: fix PR labeling permission scope (#2396)</li> <li>deps: bump aws-actions/configure-aws-credentials from 2.1.0 to 2.2.0 (#2469)</li> <li>deps: bump docker/setup-buildx-action from 2.5.0 to 2.6.0 (#2403)</li> <li>deps: bump docker/setup-qemu-action from 2.1.0 to 2.2.0 (#2404)</li> <li>deps: bump docker/setup-buildx-action from 2.6.0 to 2.7.0 (#2450)</li> <li>deps: bump pydantic from 1.10.8 to 1.10.9 (#2405)</li> <li>deps: bump actions/checkout from 3.5.2 to 3.5.3 (#2431)</li> <li>deps-dev: bump ijson from 3.2.0.post0 to 3.2.1 (#2441)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.115 to 1.26.152 (#2444)</li> <li>deps-dev: bump filelock from 3.12.0 to 3.12.2 (#2446)</li> <li>deps-dev: bump aws-cdk from 2.83.0 to 2.83.1 (#2432)</li> <li>deps-dev: bump cfn-lint from 0.77.6 to 0.77.7 (#2414)</li> <li>deps-dev: bump pytest from 7.3.1 to 7.3.2 (#2443)</li> <li>deps-dev: bump sentry-sdk from 1.25.0 to 1.25.1 (#2408)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.147 to 1.26.149 (#2410)</li> <li>deps-dev: bump aws-cdk from 2.82.0 to 2.83.0 (#2406)</li> <li>deps-dev: bump mypy-boto3-logs from 1.26.53 to 1.26.149 (#2409)</li> <li>deps-dev: bump cfn-lint from 0.77.7 to 0.77.8 (#2451)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.127 to 1.26.153 (#2452)</li> <li>deps-dev: bump cfn-lint from 0.77.8 to 0.77.9 (#2472)</li> <li>deps-dev: bump flake8-comprehensions from 3.12.0 to 3.13.0 (#2471)</li> <li>deps-dev: bump mkdocs-material from 9.1.15 to 9.1.16 (#2470)</li> <li>deps-dev: bump aws-cdk from 2.83.1 to 2.84.0 (#2460)</li> </ul>"
        },
        {
            "location": "changelog/#v2162-2023-06-06",
            "title": "v2.16.2 - 2023-06-06",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_52",
            "title": "Bug Fixes",
            "text": "<ul> <li>parameters: AppConfigProvider when retrieving multiple unique configuration names (#2378)</li> <li>shared: move to static version bumping to prevent issues with customers custom builds (#2386)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_55",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.108 to 1.26.147 (#2383)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.122 to 1.26.147 (#2382)</li> <li>deps-dev: bump sentry-sdk from 1.24.0 to 1.25.0 (#2374)</li> <li>deps-dev: bump aws-cdk from 2.81.0 to 2.82.0 (#2373)</li> <li>typing: add setLevel and addHandler to Logger for mypy/pyright (#2388)</li> </ul>"
        },
        {
            "location": "changelog/#v2161-2023-06-02",
            "title": "v2.16.1 - 2023-06-02",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_53",
            "title": "Bug Fixes",
            "text": "<ul> <li>shared: skip user agent on much older botocore versions (#2366)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_56",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> </ul>"
        },
        {
            "location": "changelog/#v2160-2023-06-02",
            "title": "v2.16.0 - 2023-06-02",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_54",
            "title": "Bug Fixes",
            "text": "<ul> <li>docs: use concrete secrets from settings (#2322)</li> <li>event_source: change the import location of boto3 in CodePipelineJobEvent data class (#2353)</li> <li>logger: add setLevel function to set level programmatically (#2320)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_19",
            "title": "Code Refactoring",
            "text": "<ul> <li>logger: remove subclassing and move unnecessary APIs (#2334)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_40",
            "title": "Documentation",
            "text": "<ul> <li>batch: add encryption at rest for SQS (#2290)</li> <li>batch_processing: snippets split, improved, and lint (#2231)</li> <li>feature_flags: snippets split, improved, and lint (#2222)</li> <li>project: rename project to Powertools for AWS Lambda (Python) (#2313)</li> </ul>"
        },
        {
            "location": "changelog/#features_40",
            "title": "Features",
            "text": "<ul> <li>docs: Move docs to S3 (#2277)</li> <li>event_source: allow multiple CORS origins (#2279)</li> <li>parser: add support for parsing SQS events wrapped in Kinesis Firehose (#2294)</li> <li>user-agent: add custom header User-Agent to AWS SDK requests (#2267)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_57",
            "title": "Maintenance",
            "text": "<ul> <li>version bump</li> <li>ci: remove auto-merge workflow (#2214)</li> <li>ci: schedule changelog to rebuild daily at 8am, and on release only (#2216)</li> <li>ci: create pull request on changelog update (#2224)</li> <li>ci: skip analytics on forks (#2225)</li> <li>ci: enforce zero trust for third party workflows (#2215)</li> <li>ci: convert create-pr steps into composite action (#2238)</li> <li>ci: bump package version after release via pull request (#2239)</li> <li>ci: update layer ARN docs and create PR during release (#2240)</li> <li>ci: fail create-pr when branch cannot be created or behind tip</li> <li>ci: filter out bot commits from CHANGELOG</li> <li>ci: add more permissions to analytics</li> <li>ci: source code tampering protection for release (#2301)</li> <li>deps: bump fastjsonschema from 2.16.3 to 2.17.1 (#2307)</li> <li>deps: bump aws-actions/configure-aws-credentials from 2.0.0 to 2.1.0 (#2350)</li> <li>deps: bump typing-extensions from 4.5.0 to 4.6.2 (#2345)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.1.2 to 2.1.3 (#2227)</li> <li>deps: bump actions/setup-python from 4.6.0 to 4.6.1 (#2325)</li> <li>deps: update mkdocs configuration to support pymdown-extensions 10.0 (#2271)</li> <li>deps: bump pymdown-extensions from 9.11 to 10.0 (#2262)</li> <li>deps: bump pydantic from 1.10.7 to 1.10.8 (#2316)</li> <li>deps: bump codecov/codecov-action from 3.1.3 to 3.1.4 (#2263)</li> <li>deps: bump requests from 2.28.2 to 2.31.0 (#2308)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.26.116 to 1.26.135 (#2282)</li> <li>deps-dev: bump pytest-xdist from 3.2.1 to 3.3.0 (#2251)</li> <li>deps-dev: bump aws-cdk from 2.79.0 to 2.79.1 (#2252)</li> <li>deps-dev: bump mkdocs-material from 9.1.11 to 9.1.12 (#2253)</li> <li>deps-dev: bump aws-cdk from 2.79.1 to 2.80.0 (#2305)</li> <li>deps-dev: bump mkdocs-material from 9.1.13 to 9.1.14 (#2304)</li> <li>deps-dev: bump mkdocs-material from 9.1.12 to 9.1.13 (#2280)</li> <li>deps-dev: bump aws-cdk from 2.80.0 to 2.81.0 (#2332)</li> <li>deps-dev: bump sentry-sdk from 1.22.2 to 1.23.0 (#2264)</li> <li>deps-dev: bump sentry-sdk from 1.23.1 to 1.24.0 (#2314)</li> <li>deps-dev: bump types-requests from 2.30.0.0 to 2.31.0.0 (#2315)</li> <li>deps-dev: bump httpx from 0.24.0 to 0.24.1 (#2298)</li> <li>deps-dev: bump aws-cdk from 2.78.0 to 2.79.0 (#2235)</li> <li>deps-dev: bump mypy from 1.2.0 to 1.3.0 (#2233)</li> <li>deps-dev: bump pytest-cov from 4.0.0 to 4.1.0 (#2327)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.12 to 2.8.19.13 (#2234)</li> <li>deps-dev: bump coverage from 7.2.5 to 7.2.6 (#2326)</li> <li>deps-dev: bump mkdocs-material from 9.1.14 to 9.1.15 (#2337)</li> <li>deps-dev: bump mkdocs-material from 9.1.9 to 9.1.11 (#2229)</li> <li>deps-dev: bump cfn-lint from 0.77.4 to 0.77.5 (#2228)</li> <li>deps-dev: bump cfn-lint from 0.77.5 to 0.77.6 (#2360)</li> <li>deps-dev: bump coverage from 7.2.6 to 7.2.7 (#2338)</li> <li>deps-dev: bump types-requests from 2.31.0.0 to 2.31.0.1 (#2339)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.26.99 to 1.26.127 (#2219)</li> <li>deps-dev: bump types-requests from 2.29.0.0 to 2.30.0.0 (#2220)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.116 to 1.26.127 (#2218)</li> <li>deps-dev: bump pytest-xdist from 3.3.0 to 3.3.1 (#2297)</li> <li>deps-dev: bump sentry-sdk from 1.23.0 to 1.23.1 (#2283)</li> <li>deps-dev: bump aws-cdk from 2.77.0 to 2.78.0 (#2202)</li> <li>governance: Fix python version in issue templates (#2275)</li> </ul>"
        },
        {
            "location": "changelog/#v2150-2023-05-04",
            "title": "v2.15.0 - 2023-05-04",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_55",
            "title": "Bug Fixes",
            "text": "<ul> <li>typo</li> <li>ci: pypi publishing was targetting test endpoint</li> </ul>"
        },
        {
            "location": "changelog/#documentation_41",
            "title": "Documentation",
            "text": "<ul> <li>batch: fixed typo in DynamoDB Streams section (#2189)</li> <li>examples: standardize lambda handler function name (#2192)</li> <li>homepage: add customer references section (#2159)</li> <li>jmespath: fix MD037/no-space-in-emphasis</li> <li>tutorial: use newer sam cli template; update to py3.10 (#2167)</li> <li>we-made-this: add serverless transactional message app (#2182)</li> </ul>"
        },
        {
            "location": "changelog/#features_41",
            "title": "Features",
            "text": "<ul> <li>ci: dispatch GitHub analytics action (#2161)</li> <li>event_source: support custom json_deserializer; add json_body in SQSEvent (#2200)</li> <li>event_source: add support for dynamic partitions in the Api Gateway Authorizer event (#2176)</li> <li>event_sources: Add str to Data Classes base DictWrapper (#2129)</li> <li>jmespath: new built-in envelopes to unwrap S3 events (#2169)</li> <li>logger: add DatadogLogFormatter and observability provider (#2183)</li> <li>metrics: add flush_metrics() method to allow manual flushing of metrics (#2171)</li> <li>parser: add support for SQS-wrapped S3 event notifications (#2108)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_58",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>add dummy reusable dispatch analytics job</li> <li>ci: remove build step from release env; no more secrets need</li> <li>ci: use new pypi trusted publisher for increase security (#2198)</li> <li>deps: bump pypa/gh-action-pypi-publish from 1.8.5 to 1.8.6 (#2201)</li> <li>deps-dev: bump cfn-lint from 0.77.3 to 0.77.4 (#2178)</li> <li>deps-dev: bump types-requests from 2.28.11.17 to 2.29.0.0 (#2187)</li> <li>deps-dev: bump coverage from 7.2.4 to 7.2.5 (#2186)</li> <li>deps-dev: bump mkdocs-material from 9.1.8 to 9.1.9 (#2190)</li> <li>deps-dev: bump importlib-metadata from 6.5.0 to 6.6.0 (#2163)</li> <li>deps-dev: bump mypy-boto3-xray from 1.26.11.post1 to 1.26.122 (#2173)</li> <li>deps-dev: bump aws-cdk from 2.76.0 to 2.77.0 (#2174)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.115 to 1.26.122 (#2172)</li> <li>deps-dev: bump cfn-lint from 0.77.2 to 0.77.3 (#2165)</li> <li>deps-dev: bump mkdocs-material from 9.1.6 to 9.1.8 (#2162)</li> <li>deps-dev: bump coverage from 7.2.3 to 7.2.4 (#2179)</li> <li>governance: add Lambda Powertools for .NET in issue templates (#2196)</li> </ul>"
        },
        {
            "location": "changelog/#v2141-2023-04-21",
            "title": "v2.14.1 - 2023-04-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_56",
            "title": "Bug Fixes",
            "text": "<ul> <li>batch: resolve use of ValidationError in batch (#2157)</li> <li>e2e: fix test brittleness (#2152)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_42",
            "title": "Documentation",
            "text": "<ul> <li>readme: update python version badge to 3.10</li> </ul>"
        },
        {
            "location": "changelog/#features_42",
            "title": "Features",
            "text": "<ul> <li>event_sources: add queue_url field in SQS EventSource DataClass (#2146)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_59",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>add Python 3.10 PyPi language classifier (#2144)</li> <li>update v2 layer ARN on documentation</li> <li>batch: safeguard custom use of BatchProcessingError exception (#2155)</li> <li>deps: bump codecov/codecov-action from 3.1.2 to 3.1.3 (#2153)</li> <li>deps: bump dependabot/fetch-metadata from 1.3.6 to 1.4.0 (#2140)</li> <li>deps-dev: bump aws-cdk from 2.75.0 to 2.75.1 (#2150)</li> <li>deps-dev: bump aws-cdk from 2.75.1 to 2.76.0 (#2154)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.26.89 to 1.26.116 (#2147)</li> <li>deps-dev: bump importlib-metadata from 6.4.1 to 6.5.0 (#2141)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.104 to 1.26.116 (#2149)</li> <li>deps-dev: bump filelock from 3.11.0 to 3.12.0 (#2142)</li> <li>deps-dev: bump cfn-lint from 0.77.1 to 0.77.2 (#2148)</li> </ul>"
        },
        {
            "location": "changelog/#v2140-2023-04-18",
            "title": "v2.14.0 - 2023-04-18",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_57",
            "title": "Bug Fixes",
            "text": "<ul> <li>enable python 3.10 on SAR template</li> <li>ci: fix layer version in tracer, logger and metrics</li> <li>ci: typo</li> <li>docs: add Layer ARN for new 5 regions</li> <li>layers: add debug to update layer arn script</li> </ul>"
        },
        {
            "location": "changelog/#features_43",
            "title": "Features",
            "text": "<ul> <li>runtime: add support for python 3.10 (#2137)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_60",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>update v2 layer ARN on documentation</li> <li>update v2 layer ARN on documentation</li> <li>ci: add support for x86-64 regions only (#2122)</li> <li>deps-dev: bump importlib-metadata from 6.3.0 to 6.4.1 (#2134)</li> <li>deps-dev: bump cfn-lint from 0.77.0 to 0.77.1 (#2133)</li> <li>deps-dev: bump pytest from 7.3.0 to 7.3.1 (#2127)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.109 to 1.26.114 (#2126)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.114 to 1.26.115 (#2135)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.97.post1 to 1.26.115 (#2132)</li> <li>github: new tech debt issue form (#2131)</li> <li>layer: change layer-balance script to support new regions</li> </ul>"
        },
        {
            "location": "changelog/#reverts",
            "title": "Reverts",
            "text": "<ul> <li>chore: update v2 layer ARN on documentation</li> </ul>"
        },
        {
            "location": "changelog/#v2130-2023-04-14",
            "title": "v2.13.0 - 2023-04-14",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_58",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: replace the correct files for Layer ARN</li> <li>ci: fix working directory</li> <li>ci: add debug log to NPM install</li> <li>ci: use project's CDK version when building layers</li> <li>ci: add the rest of the changed docs</li> <li>ci: update layer version on logger, tracer and metrics docs (#2120)</li> <li>event_sources: Update CodePipeline event source to include optional encryption_key field and make user_parameters field optional (#2113)</li> </ul>"
        },
        {
            "location": "changelog/#features_44",
            "title": "Features",
            "text": "<ul> <li>parameters: Configure max_age and decrypt parameters via environment variables (#2088)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_61",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>ci: bump the cdk-aws-lambda-powertools-layer version (#2121)</li> <li>deps: bump codecov/codecov-action from 3.1.1 to 3.1.2 (#2110)</li> <li>deps-dev: bump httpx from 0.23.3 to 0.24.0 (#2111)</li> <li>deps-dev: bump aws-cdk-lib from 2.73.0 to 2.74.0 (#2123)</li> <li>deps-dev: bump mkdocs-material from 9.1.5 to 9.1.6 (#2104)</li> <li>deps-dev: bump aws-cdk from 2.73.0 to 2.74.0 (#2125)</li> <li>deps-dev: bump flake8-comprehensions from 3.11.1 to 3.12.0 (#2124)</li> <li>deps-dev: bump mypy from 1.1.1 to 1.2.0 (#2096)</li> <li>deps-dev: bump cfn-lint from 0.76.2 to 0.77.0 (#2107)</li> <li>deps-dev: bump pytest from 7.2.2 to 7.3.0 (#2106)</li> <li>deps-dev: bump importlib-metadata from 6.1.0 to 6.3.0 (#2105)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.80 to 1.26.109 (#2103)</li> <li>maintenance: validate acknowledgement section is present (#2112)</li> </ul>"
        },
        {
            "location": "changelog/#v2120-2023-04-07",
            "title": "v2.12.0 - 2023-04-07",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_59",
            "title": "Bug Fixes",
            "text": "<ul> <li>batch: handle early validation errors for pydantic models (poison pill) #2091 (#2099)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_43",
            "title": "Documentation",
            "text": "<ul> <li>batch: use newly supported Json model (#2100)</li> <li>homepage: remove banner for end-of-support v1 (#2098)</li> <li>idempotency: fixes to testing your code section (#2073)</li> <li>idempotency: new sequence diagrams, fix idempotency record vs DynamoDB TTL confusion (#2074)</li> <li>parser: fix highlighted line (#2064)</li> </ul>"
        },
        {
            "location": "changelog/#features_45",
            "title": "Features",
            "text": "<ul> <li>batch: reduce boilerplate with process_partial_response (#2090)</li> <li>idempotency: allow custom sdk clients in DynamoDBPersistenceLayer (#2087)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_62",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump peaceiris/actions-gh-pages from 3.9.2 to 3.9.3 (#2069)</li> <li>deps: bump aws-xray-sdk from 2.11.0 to 2.12.0 (#2080)</li> <li>deps-dev: bump coverage from 7.2.2 to 7.2.3 (#2092)</li> <li>deps-dev: bump aws-cdk from 2.72.1 to 2.73.0 (#2093)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.60 to 1.26.108 (#2095)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.11 to 2.8.19.12 (#2085)</li> <li>deps-dev: bump cfn-lint from 0.76.1 to 0.76.2 (#2084)</li> <li>deps-dev: bump aws-cdk from 2.72.0 to 2.72.1 (#2081)</li> <li>deps-dev: bump filelock from 3.10.7 to 3.11.0 (#2094)</li> <li>deps-dev: bump mkdocs-material from 9.1.4 to 9.1.5 (#2077)</li> <li>deps-dev: bump aws-cdk-lib from 2.72.0 to 2.72.1 (#2076)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.99 to 1.26.104 (#2075)</li> <li>deps-dev: bump aws-cdk from 2.71.0 to 2.72.0 (#2071)</li> <li>deps-dev: bump aws-cdk-lib from 2.72.1 to 2.73.0 (#2097)</li> <li>deps-dev: bump aws-cdk-lib from 2.71.0 to 2.72.0 (#2070)</li> <li>deps-dev: bump black from 23.1.0 to 23.3.0 (#2066)</li> <li>deps-dev: bump aws-cdk from 2.70.0 to 2.71.0 (#2067)</li> <li>deps-dev: bump aws-cdk-lib from 2.70.0 to 2.71.0 (#2065)</li> </ul>"
        },
        {
            "location": "changelog/#v2110-2023-03-29",
            "title": "v2.11.0 - 2023-03-29",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_60",
            "title": "Bug Fixes",
            "text": "<ul> <li>feature_flags: make test conditions deterministic (#2059)</li> <li>feature_flags: handle expected falsy values in conditions (#2052)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_44",
            "title": "Documentation",
            "text": "<ul> <li>logger: warn append_keys on not being thread-safe (#2046)</li> </ul>"
        },
        {
            "location": "changelog/#features_46",
            "title": "Features",
            "text": "<ul> <li>event_sources: support for S3 Event Notifications through EventBridge (#2024)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_63",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump pydantic from 1.10.6 to 1.10.7 (#2034)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.97 to 1.26.97.post2 (#2043)</li> <li>deps-dev: bump cfn-lint from 0.75.1 to 0.76.1 (#2056)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.10 to 2.8.19.11 (#2057)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.97.post2 to 1.26.99 (#2054)</li> <li>deps-dev: bump mkdocs-material from 9.1.3 to 9.1.4 (#2050)</li> <li>deps-dev: bump filelock from 3.10.2 to 3.10.4 (#2048)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.26.52 to 1.26.99 (#2049)</li> <li>deps-dev: bump filelock from 3.10.1 to 3.10.2 (#2045)</li> <li>deps-dev: bump types-requests from 2.28.11.15 to 2.28.11.16 (#2044)</li> <li>deps-dev: bump filelock from 3.10.4 to 3.10.7 (#2055)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.97 to 1.26.97.post1 (#2042)</li> <li>deps-dev: bump filelock from 3.10.0 to 3.10.1 (#2036)</li> <li>deps-dev: bump aws-cdk from 2.69.0 to 2.70.0 (#2039)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.87 to 1.26.97 (#2035)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.62 to 1.26.97 (#2037)</li> <li>deps-dev: bump aws-cdk-lib from 2.69.0 to 2.70.0 (#2038)</li> <li>deps-dev: bump types-requests from 2.28.11.16 to 2.28.11.17 (#2061)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.26.77 to 1.26.97 (#2033)</li> <li>deps-dev: bump flake8-comprehensions from 3.11.0 to 3.11.1 (#2029)</li> <li>deps-dev: bump cfn-lint from 0.75.0 to 0.75.1 (#2027)</li> <li>deps-dev: bump pytest-asyncio from 0.20.3 to 0.21.0 (#2026)</li> </ul>"
        },
        {
            "location": "changelog/#v2100-2023-03-17",
            "title": "v2.10.0 - 2023-03-17",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_61",
            "title": "Bug Fixes",
            "text": "<ul> <li>only allow one e2e test at a time</li> <li>build: auto-generate setup.py for legacy build tools (#2013)</li> <li>ci: bump CDK version</li> <li>typing: swap NoReturn with None for methods with no return value (#2004)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_45",
            "title": "Documentation",
            "text": "<ul> <li>homepage: revamp install UX &amp; share how we build Lambda Layer (#1978)</li> <li>metrics: fix high-resolution metrics announcement link (#2017)</li> </ul>"
        },
        {
            "location": "changelog/#features_47",
            "title": "Features",
            "text": "<ul> <li>event_sources: support for custom properties in ActiveMQEvent (#1999)</li> <li>parser: support for S3 Event Notifications via EventBridge (#1982)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_64",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>ci: allow dependabot to upgrade CDK for JS</li> <li>deps: bump docker/setup-buildx-action from 2.4.1 to 2.5.0 (#1995)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.1.1 to 2.1.2 (#1979)</li> <li>deps: bump aws-actions/configure-aws-credentials from 1 to 2 (#1987)</li> <li>deps: bump pydantic from 1.10.5 to 1.10.6 (#1991)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.26.49 to 1.26.89 (#1996)</li> <li>deps-dev: bump cfn-lint from 0.74.2 to 0.74.3 (#2008)</li> <li>deps-dev: bump filelock from 3.9.0 to 3.9.1 (#2006)</li> <li>deps-dev: bump aws-cdk-lib from 2.68.0 to 2.69.0 (#2007)</li> <li>deps-dev: bump cfn-lint from 0.74.1 to 0.74.2 (#2005)</li> <li>deps-dev: bump mypy from 0.982 to 1.1.1 (#1985)</li> <li>deps-dev: bump pytest-xdist from 3.2.0 to 3.2.1 (#2000)</li> <li>deps-dev: bump flake8-bugbear from 23.2.13 to 23.3.12 (#2001)</li> <li>deps-dev: bump bandit from 1.7.4 to 1.7.5 (#1997)</li> <li>deps-dev: bump mkdocs-material from 9.1.2 to 9.1.3 (#2009)</li> <li>deps-dev: bump aws-cdk from 2.67.0 to 2.69.0 (#2010)</li> <li>deps-dev: bump mkdocs-material from 9.1.1 to 9.1.2 (#1994)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.84 to 1.26.87 (#1993)</li> <li>deps-dev: bump filelock from 3.9.1 to 3.10.0 (#2019)</li> <li>deps-dev: bump aws-cdk-lib from 2.67.0 to 2.68.0 (#1992)</li> <li>deps-dev: bump cfn-lint from 0.74.0 to 0.74.1 (#1988)</li> <li>deps-dev: bump coverage from 7.2.1 to 7.2.2 (#2021)</li> <li>deps-dev: bump pytest from 7.2.1 to 7.2.2 (#1980)</li> <li>deps-dev: bump cfn-lint from 0.74.3 to 0.75.0 (#2020)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.9 to 2.8.19.10 (#1973)</li> <li>deps-dev: bump hvac from 1.0.2 to 1.1.0 (#1983)</li> <li>deps-dev: bump mkdocs-material from 9.1.0 to 9.1.1 (#1984)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.24 to 1.26.84 (#1981)</li> <li>deps-dev: bump mkdocs-material from 9.0.15 to 9.1.0 (#1976)</li> <li>deps-dev: bump cfn-lint from 0.67.0 to 0.74.0 (#1974)</li> <li>deps-dev: bump aws-cdk-lib from 2.66.1 to 2.67.0 (#1977)</li> </ul>"
        },
        {
            "location": "changelog/#v291-2023-03-01",
            "title": "v2.9.1 - 2023-03-01",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_62",
            "title": "Bug Fixes",
            "text": "<ul> <li>idempotency: revert dict mutation that impacted static_pk_value feature (#1970)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_46",
            "title": "Documentation",
            "text": "<ul> <li>appsync: add mutation example and infrastructure fix (#1964)</li> <li>parameters: fix typos and inconsistencies (#1966)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_65",
            "title": "Maintenance",
            "text": "<ul> <li>update project description</li> <li>update v2 layer ARN on documentation</li> <li>ci: disable pypi test due to maintenance mode</li> <li>ci: replace deprecated set-output commands (#1957)</li> <li>deps: bump fastjsonschema from 2.16.2 to 2.16.3 (#1961)</li> <li>deps: bump release-drafter/release-drafter from 5.22.0 to 5.23.0 (#1947)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.1.0 to 2.1.1 (#1958)</li> <li>deps-dev: bump coverage from 7.2.0 to 7.2.1 (#1963)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.8 to 2.8.19.9 (#1960)</li> <li>deps-dev: bump mkdocs-material from 9.0.14 to 9.0.15 (#1959)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.55 to 1.26.80 (#1967)</li> <li>deps-dev: bump types-requests from 2.28.11.14 to 2.28.11.15 (#1962)</li> <li>deps-dev: bump aws-cdk-lib from 2.66.0 to 2.66.1 (#1954)</li> <li>deps-dev: bump coverage from 7.1.0 to 7.2.0 (#1951)</li> <li>deps-dev: bump mkdocs-material from 9.0.13 to 9.0.14 (#1952)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.26.43 to 1.26.77 (#1949)</li> <li>deps-dev: bump types-requests from 2.28.11.13 to 2.28.11.14 (#1946)</li> <li>deps-dev: bump aws-cdk-lib from 2.65.0 to 2.66.0 (#1948)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.7 to 2.8.19.8 (#1945)</li> <li>parser: add workaround to make API GW test button work (#1971)</li> </ul>"
        },
        {
            "location": "changelog/#v290-2023-02-21",
            "title": "v2.9.0 - 2023-02-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_63",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: upgraded cdk to match the version used on e2e tests</li> <li>feature-flags: revert RuleAction Enum inheritance on str (#1910)</li> <li>logger: support exception and exception_name fields at any log level (#1930)</li> <li>metrics: clarify no-metrics user warning (#1935)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_47",
            "title": "Documentation",
            "text": "<ul> <li>event_handlers: Fix REST API - HTTP Methods documentation (#1936)</li> <li>home: update powertools definition</li> <li>we-made-this: add CI/CD using Feature Flags video   (#1940)</li> <li>we-made-this: add Feature Flags post (#1939)</li> </ul>"
        },
        {
            "location": "changelog/#features_48",
            "title": "Features",
            "text": "<ul> <li>batch: add support to SQS FIFO queues (SqsFifoPartialProcessor) (#1934)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_66",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.0.5 to 2.1.0 (#1943)</li> <li>deps: bump pydantic from 1.10.4 to 1.10.5 (#1931)</li> <li>deps-dev: bump mkdocs-material from 9.0.12 to 9.0.13 (#1944)</li> <li>deps-dev: bump aws-cdk-lib from 2.64.0 to 2.65.0 (#1938)</li> <li>deps-dev: bump types-python-dateutil from 2.8.19.6 to 2.8.19.7 (#1932)</li> <li>deps-dev: bump types-requests from 2.28.11.12 to 2.28.11.13 (#1933)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.26.63 to 1.26.71 (#1928)</li> <li>deps-dev: bump flake8-bugbear from 23.1.20 to 23.2.13 (#1924)</li> <li>deps-dev: bump mypy-boto3-appconfigdata from 1.26.0.post1 to 1.26.70 (#1925)</li> </ul>"
        },
        {
            "location": "changelog/#v280-2023-02-10",
            "title": "v2.8.0 - 2023-02-10",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_64",
            "title": "Bug Fixes",
            "text": "<ul> <li>idempotency: make idempotent_function decorator thread safe (#1899)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_48",
            "title": "Documentation",
            "text": "<ul> <li>engine: re-enable clipboard button for code snippets</li> <li>homepage: Replace poetry command to add group parameter (#1917)</li> <li>homepage: set url for end-of-support in announce block (#1893)</li> <li>idempotency: add IAM permissions section (#1902)</li> <li>metrics: remove reduntant wording before release</li> <li>metrics: fix syntax highlighting for new default_dimensions</li> </ul>"
        },
        {
            "location": "changelog/#features_49",
            "title": "Features",
            "text": "<ul> <li>batch: add async_batch_processor for concurrent processing (#1724)</li> <li>metrics: add default_dimensions to single_metric (#1880)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_67",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump docker/setup-buildx-action from 2.4.0 to 2.4.1 (#1903)</li> <li>deps-dev: bump aws-cdk-lib from 2.63.0 to 2.63.2 (#1904)</li> <li>deps-dev: bump black from 22.12.0 to 23.1.0 (#1886)</li> <li>deps-dev: bump types-requests from 2.28.11.8 to 2.28.11.12 (#1906)</li> <li>deps-dev: bump pytest-xdist from 3.1.0 to 3.2.0 (#1905)</li> <li>deps-dev: bump aws-cdk-lib from 2.63.2 to 2.64.0 (#1918)</li> <li>deps-dev: bump mkdocs-material from 9.0.11 to 9.0.12 (#1919)</li> <li>deps-dev: bump mkdocs-material from 9.0.10 to 9.0.11 (#1896)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.26.0.post1 to 1.26.63 (#1895)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.58 to 1.26.62 (#1889)</li> <li>deps-dev: bump mkdocs-material from 9.0.9 to 9.0.10 (#1888)</li> <li>deps-dev: bump aws-cdk-lib from 2.62.2 to 2.63.0 (#1887)</li> <li>maintainers: fix release workflow rename</li> <li>pypi: add new links to Pypi package homepage (#1912)</li> </ul>"
        },
        {
            "location": "changelog/#v271-2023-02-01",
            "title": "v2.7.1 - 2023-02-01",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_65",
            "title": "Bug Fixes",
            "text": "<ul> <li>parallel_run should fail when e2e tests fail</li> <li>bump aws-cdk version</li> <li>ci: scope e2e tests by python version</li> <li>ci: add auth to API HTTP Gateway and Lambda Function Url (#1882)</li> <li>license: correction to MIT + MIT-0 (no proprietary anymore) (#1883)</li> <li>license: add MIT-0 license header (#1871)</li> <li>tests: make logs fetching more robust (#1878)</li> <li>tests: remove custom workers</li> <li>tests: make sure multiple e2e tests run concurrently (#1861)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_49",
            "title": "Documentation",
            "text": "<ul> <li>event-source:  fix incorrect method in example CloudWatch Logs (#1857)</li> <li>homepage: add banner for end-of-support v1 (#1879)</li> <li>parameters: snippets split, improved, and lint (#1564)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_68",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump docker/setup-buildx-action from 2.0.0 to 2.4.0 (#1873)</li> <li>deps: bump dependabot/fetch-metadata from 1.3.5 to 1.3.6 (#1855)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.26.0.post1 to 1.26.58 (#1868)</li> <li>deps-dev: bump isort from 5.11.4 to 5.11.5 (#1875)</li> <li>deps-dev: bump aws-cdk-lib from 2.62.1 to 2.62.2 (#1869)</li> <li>deps-dev: bump mkdocs-material from 9.0.6 to 9.0.8 (#1874)</li> <li>deps-dev: bump aws-cdk-lib from 2.62.0 to 2.62.1 (#1866)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.35.post1 to 1.26.57 (#1865)</li> <li>deps-dev: bump coverage from 7.0.5 to 7.1.0 (#1862)</li> <li>deps-dev: bump aws-cdk-lib from 2.61.1 to 2.62.0 (#1863)</li> <li>deps-dev: bump flake8-bugbear from 22.12.6 to 23.1.20 (#1854)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.49 to 1.26.55 (#1856)</li> </ul>"
        },
        {
            "location": "changelog/#reverts_1",
            "title": "Reverts",
            "text": "<ul> <li>fix(tests): remove custom workers</li> </ul>"
        },
        {
            "location": "changelog/#v270-2023-01-24",
            "title": "v2.7.0 - 2023-01-24",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_66",
            "title": "Bug Fixes",
            "text": "<ul> <li>git-chlg docker image is broken</li> </ul>"
        },
        {
            "location": "changelog/#features_50",
            "title": "Features",
            "text": "<ul> <li>feature_flags: Add Time based feature flags actions (#1846)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_69",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump peaceiris/actions-gh-pages from 3.9.1 to 3.9.2 (#1841)</li> <li>deps: bump future from 0.18.2 to 0.18.3 (#1836)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.0.4 to 2.0.5 (#1837)</li> <li>deps-dev: bump mkdocs-material from 9.0.4 to 9.0.5 (#1840)</li> <li>deps-dev: bump types-requests from 2.28.11.7 to 2.28.11.8 (#1843)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.26.30 to 1.26.52 (#1847)</li> <li>deps-dev: bump pytest from 7.2.0 to 7.2.1 (#1838)</li> <li>deps-dev: bump aws-cdk-lib from 2.60.0 to 2.61.1 (#1849)</li> <li>deps-dev: bump mypy-boto3-logs from 1.26.49 to 1.26.53 (#1850)</li> <li>deps-dev: bump mkdocs-material from 9.0.5 to 9.0.6 (#1851)</li> <li>deps-dev: bump mkdocs-material from 9.0.3 to 9.0.4 (#1833)</li> <li>deps-dev: bump mypy-boto3-logs from 1.26.43 to 1.26.49 (#1834)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.26.40 to 1.26.49 (#1835)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.18 to 1.26.49 (#1832)</li> <li>deps-dev: bump aws-cdk-lib from 2.59.0 to 2.60.0 (#1831)</li> </ul>"
        },
        {
            "location": "changelog/#v260-2023-01-12",
            "title": "v2.6.0 - 2023-01-12",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_67",
            "title": "Bug Fixes",
            "text": "<ul> <li>api_gateway: fixed custom metrics issue when using debug mode (#1827)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_50",
            "title": "Documentation",
            "text": "<ul> <li>logger: fix incorrect field names in example structured logs (#1830)</li> <li>logger: Add warning of uncaught exceptions (#1826)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_70",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump pydantic from 1.10.2 to 1.10.4 (#1817)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.0.1 to 2.0.3 (#1801)</li> <li>deps: bump release-drafter/release-drafter from 5.21.1 to 5.22.0 (#1802)</li> <li>deps: bump gitpython from 3.1.29 to 3.1.30 (#1812)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 2.0.3 to 2.0.4 (#1821)</li> <li>deps: bump peaceiris/actions-gh-pages from 3.9.0 to 3.9.1 (#1814)</li> <li>deps-dev: bump mkdocs-material from 8.5.11 to 9.0.2 (#1808)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.26.11.post1 to 1.26.43 (#1819)</li> <li>deps-dev: bump mypy-boto3-logs from 1.26.27 to 1.26.43 (#1820)</li> <li>deps-dev: bump filelock from 3.8.2 to 3.9.0 (#1816)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.11.post1 to 1.26.35.post1 (#1818)</li> <li>deps-dev: bump ijson from 3.1.4 to 3.2.0.post0 (#1815)</li> <li>deps-dev: bump coverage from 6.5.0 to 7.0.3 (#1806)</li> <li>deps-dev: bump flake8-builtins from 2.0.1 to 2.1.0 (#1799)</li> <li>deps-dev: bump coverage from 7.0.3 to 7.0.4 (#1822)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.26.12 to 1.26.40 (#1811)</li> <li>deps-dev: bump isort from 5.11.3 to 5.11.4 (#1809)</li> <li>deps-dev: bump aws-cdk-lib from 2.55.1 to 2.59.0 (#1810)</li> <li>deps-dev: bump importlib-metadata from 5.1.0 to 6.0.0 (#1804)</li> <li>deps-dev: bump mkdocs-material from 9.0.2 to 9.0.3 (#1823)</li> <li>deps-dev: bump black from 22.10.0 to 22.12.0 (#1770)</li> <li>deps-dev: bump flake8-black from 0.3.5 to 0.3.6 (#1792)</li> <li>deps-dev: bump coverage from 7.0.4 to 7.0.5 (#1829)</li> <li>deps-dev: bump types-requests from 2.28.11.5 to 2.28.11.7 (#1795)</li> </ul>"
        },
        {
            "location": "changelog/#v250-2022-12-21",
            "title": "v2.5.0 - 2022-12-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_68",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handlers: omit explicit None HTTP header values (#1793)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_51",
            "title": "Documentation",
            "text": "<ul> <li>idempotency: fix, improve, and increase visibility for batch integration (#1776)</li> <li>validation: fix broken link; enrich built-in jmespath links (#1777)</li> </ul>"
        },
        {
            "location": "changelog/#features_51",
            "title": "Features",
            "text": "<ul> <li>logger: unwrap event from common models if asked to log (#1778)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_71",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>common: reusable function to extract event from models</li> <li>deps: bump certifi from 2022.9.24 to 2022.12.7 (#1768)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 1.4.0 to 2.0.1 (#1752)</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions from 1.3.0 to 1.4.0 (#1749)</li> <li>deps-dev: bump pytest-asyncio from 0.20.2 to 0.20.3 (#1767)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.26.0.post1 to 1.26.17 (#1753)</li> <li>deps-dev: bump isort from 5.10.1 to 5.11.2 (#1782)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.26.17 to 1.26.30 (#1785)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.13.post16 to 1.26.24 (#1765)</li> <li>deps-dev: bump aws-cdk-lib from 2.54.0 to 2.55.1 (#1787)</li> <li>deps-dev: bump aws-cdk-lib from 2.53.0 to 2.54.0 (#1764)</li> <li>deps-dev: bump flake8-bugbear from 22.10.27 to 22.12.6 (#1760)</li> <li>deps-dev: bump filelock from 3.8.0 to 3.8.2 (#1759)</li> <li>deps-dev: bump pytest-xdist from 3.0.2 to 3.1.0 (#1758)</li> <li>deps-dev: bump mkdocs-material from 8.5.10 to 8.5.11 (#1756)</li> <li>deps-dev: bump importlib-metadata from 4.13.0 to 5.1.0 (#1750)</li> <li>deps-dev: bump isort from 5.11.2 to 5.11.3 (#1788)</li> <li>deps-dev: bump flake8-black from 0.3.3 to 0.3.5 (#1738)</li> <li>deps-dev: bump mypy-boto3-logs from 1.26.17 to 1.26.27 (#1775)</li> <li>tests: move shared_functions to unit tests</li> </ul>"
        },
        {
            "location": "changelog/#v240-2022-11-24",
            "title": "v2.4.0 - 2022-11-24",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_69",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: use gh-pages env as official docs are wrong</li> <li>ci: api docs path</li> </ul>"
        },
        {
            "location": "changelog/#documentation_52",
            "title": "Documentation",
            "text": "<ul> <li>idempotency: fix register_lambda_context order (#1747)</li> <li>streaming: fix leftover newline</li> </ul>"
        },
        {
            "location": "changelog/#features_52",
            "title": "Features",
            "text": "<ul> <li>streaming: add new s3 streaming utility (#1719)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_72",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>ci: re-create versioned API docs for new pages deployment</li> <li>ci: re-create versioned API docs for new pages deployment</li> <li>ci: increase permission in parent job for docs publishing</li> <li>ci: attempt gh-pages deployment via beta route</li> <li>deps: bump aws-xray-sdk from 2.10.0 to 2.11.0 (#1730)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.26.0.post1 to 1.26.12 (#1742)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.26.0.post1 to 1.26.11.post1 (#1746)</li> <li>deps-dev: bump aws-cdk-lib from 2.50.0 to 2.51.1 (#1741)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.26.0.post1 to 1.26.13.post16 (#1743)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.26.0.post1 to 1.26.12 (#1744)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.26.4 to 1.26.11.post1 (#1740)</li> <li>deps-dev: bump types-requests from 2.28.11.4 to 2.28.11.5 (#1729)</li> <li>deps-dev: bump mkdocs-material from 8.5.9 to 8.5.10 (#1731)</li> <li>governance: remove markdown rendering from docs issue template</li> </ul>"
        },
        {
            "location": "changelog/#regression",
            "title": "Regression",
            "text": "<ul> <li>ci: new gh-pages beta doesn't work either; reverting as gh-pages is disrupted</li> </ul>"
        },
        {
            "location": "changelog/#v231-2022-11-21",
            "title": "v2.3.1 - 2022-11-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_70",
            "title": "Bug Fixes",
            "text": "<ul> <li>apigateway: support dynamic routes with equal sign (RFC3986) (#1737)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_73",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>test build layer hardware to 8 core</li> <li>deps-dev: bump mypy-boto3-xray from 1.26.9 to 1.26.11.post1 (#1734)</li> </ul>"
        },
        {
            "location": "changelog/#v230-2022-11-17",
            "title": "v2.3.0 - 2022-11-17",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_71",
            "title": "Bug Fixes",
            "text": "<ul> <li>apigateway: support nested router decorators (#1709)</li> <li>ci: increase permission to allow version sync back to repo</li> <li>ci: disable pre-commit hook download from version bump</li> <li>ci: setup git client earlier to prevent dirty stash error</li> <li>parameters: get_secret correctly return SecretBinary value (#1717)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_53",
            "title": "Documentation",
            "text": "<ul> <li>project name consistency</li> <li>apigateway: add all resolvers in testing your code section for accuracy (#1688)</li> <li>examples: linting unnecessary whitespace</li> <li>homepage: update default value for <code>POWERTOOLS_DEV</code> (#1695)</li> <li>idempotency: add missing Lambda Context; note on thread-safe (#1732)</li> <li>logger: update uncaught exception message value</li> </ul>"
        },
        {
            "location": "changelog/#features_53",
            "title": "Features",
            "text": "<ul> <li>apigateway: multiple exceptions in exception_handler (#1707)</li> <li>event_sources: extract CloudWatch Logs in Kinesis streams (#1710)</li> <li>logger: log uncaught exceptions via system's exception hook (#1727)</li> <li>parser: export Pydantic.errors through escape hatch (#1728)</li> <li>parser: extract CloudWatch Logs in Kinesis streams (#1726)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_74",
            "title": "Maintenance",
            "text": "<ul> <li>apigw test event wrongly set with base64</li> <li>update v2 layer ARN on documentation</li> <li>ci: revert custom hw for E2E due to lack of hw</li> <li>ci: try bigger hardware for e2e test</li> <li>ci: uncomment test pypi, fix version bump sync</li> <li>ci: limit to src only to prevent dependabot failures</li> <li>ci: use new custom hw for E2E</li> <li>ci: prevent dependabot updates to trigger E2E</li> <li>ci: bump hardware for build steps</li> <li>deps: bump dependabot/fetch-metadata from 1.3.4 to 1.3.5 (#1689)</li> <li>deps-dev: bump types-requests from 2.28.11.3 to 2.28.11.4 (#1701)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.25.0 to 1.26.0.post1 (#1716)</li> <li>deps-dev: bump mypy-boto3-appconfigdata from 1.25.0 to 1.26.0.post1 (#1704)</li> <li>deps-dev: bump mypy-boto3-xray from 1.25.0 to 1.26.0.post1 (#1703)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.25.0 to 1.26.0.post1 (#1714)</li> <li>deps-dev: bump flake8-bugbear from 22.10.25 to 22.10.27 (#1665)</li> <li>deps-dev: bump mypy-boto3-lambda from 1.25.0 to 1.26.0.post1 (#1705)</li> <li>deps-dev: bump mypy-boto3-xray from 1.26.0.post1 to 1.26.9 (#1720)</li> <li>deps-dev: bump mypy-boto3-logs from 1.25.0 to 1.26.3 (#1702)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.26.0.post1 to 1.26.4 (#1721)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.25.0 to 1.26.0.post1 (#1722)</li> <li>deps-dev: bump pytest-asyncio from 0.20.1 to 0.20.2 (#1723)</li> <li>deps-dev: bump flake8-builtins from 2.0.0 to 2.0.1 (#1715)</li> <li>deps-dev: bump pytest-xdist from 2.5.0 to 3.0.2 (#1655)</li> <li>deps-dev: bump mkdocs-material from 8.5.7 to 8.5.9 (#1697)</li> <li>deps-dev: bump flake8-comprehensions from 3.10.0 to 3.10.1 (#1699)</li> <li>deps-dev: bump types-requests from 2.28.11.2 to 2.28.11.3 (#1698)</li> <li>deps-dev: bump pytest-benchmark from 3.4.1 to 4.0.0 (#1659)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.25.0 to 1.26.0.post1 (#1691)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.25.0 to 1.26.0.post1 (#1690)</li> <li>logger: uncaught exception to use exception value as message</li> <li>logger: overload inject_lambda_context with generics (#1583)</li> </ul>"
        },
        {
            "location": "changelog/#v220-2022-11-07",
            "title": "v2.2.0 - 2022-11-07",
            "text": ""
        },
        {
            "location": "changelog/#documentation_54",
            "title": "Documentation",
            "text": "<ul> <li>homepage: remove v1 layer limitation on pydantic not being included</li> <li>tracer: add note on why X-Ray SDK over ADOT closes #1675</li> </ul>"
        },
        {
            "location": "changelog/#features_54",
            "title": "Features",
            "text": "<ul> <li>metrics: add EphemeralMetrics as a non-singleton option (#1676)</li> <li>parameters: add get_parameters_by_name for SSM params in distinct paths (#1678)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_75",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>deps: bump package to 2.2.0</li> <li>deps-dev: bump aws-cdk-lib from 2.49.0 to 2.50.0 (#1683)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.25.0 to 1.26.0.post1 (#1682)</li> <li>deps-dev: bump mypy-boto3-cloudformation from 1.25.0 to 1.26.0.post1 (#1679)</li> <li>package: correct pyproject version manually</li> </ul>"
        },
        {
            "location": "changelog/#v210-2022-10-31",
            "title": "v2.1.0 - 2022-10-31",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_72",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: linting issues after flake8-blackbear,mypy upgrades</li> <li>deps: update build system to poetry-core (#1651)</li> <li>idempotency: idempotent_function should support standalone falsy values (#1669)</li> <li>logger: fix unknown attributes being ignored by mypy (#1670)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_55",
            "title": "Documentation",
            "text": "<ul> <li>community: fix social handlers for Ran (#1654)</li> <li>community: fix twitch parent domain for embedded video</li> <li>homepage: remove 3.6 and add hero image</li> <li>homepage: add Pulumi code example (#1652)</li> <li>index: fold support us banner</li> <li>index: add quotes to pip for zsh customers</li> <li>install: address early v2 feedback on installation and project support</li> <li>we-made-this: new community content section (#1650)</li> </ul>"
        },
        {
            "location": "changelog/#features_55",
            "title": "Features",
            "text": "<ul> <li>layers: add layer balancer script (#1643)</li> <li>logger: add use_rfc3339 and auto-complete formatter opts in Logger (#1662)</li> <li>logger: accept arbitrary keyword=value for ephemeral metadata (#1658)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_76",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>ci: fix typo on version description</li> <li>deps: bump peaceiris/actions-gh-pages from 3.8.0 to 3.9.0 (#1649)</li> <li>deps: bump docker/setup-qemu-action from 2.0.0 to 2.1.0 (#1627)</li> <li>deps-dev: bump aws-cdk-lib from 2.47.0 to 2.48.0 (#1664)</li> <li>deps-dev: bump flake8-variables-names from 0.0.4 to 0.0.5 (#1628)</li> <li>deps-dev: bump pytest-asyncio from 0.16.0 to 0.20.1 (#1635)</li> <li>deps-dev: bump aws-cdk-lib from 2.48.0 to 2.49.0 (#1671)</li> <li>docs: remove v2 banner on top of the docs</li> <li>governance: remove 'area/' from PR labels</li> </ul>"
        },
        {
            "location": "changelog/#v200-2022-10-24",
            "title": "v2.0.0 - 2022-10-24",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_73",
            "title": "Bug Fixes",
            "text": "<ul> <li>lock dependencies</li> <li>mypy errors</li> <li>lint files</li> <li>ci: temporarly remove pypi test deployment</li> <li>ci: use docker driver on buildx</li> <li>ci: new artifact path, sed gnu/linux syntax, and pypi test</li> <li>ci: secret and OIDC inheritance in nested children workflow</li> <li>ci: build without buildkit</li> <li>ci: fix arm64 layer builds</li> <li>ci: remove v2 suffix from SAR apps (#1633)</li> <li>ci: workflow should use npx for CDK CLI</li> <li>parser: S3Model Object Deleted omits size and eTag attr (#1638)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_20",
            "title": "Code Refactoring",
            "text": "<ul> <li>apigateway: remove POWERTOOLS_EVENT_HANDLER_DEBUG env var (#1620)</li> <li>batch: remove legacy sqs_batch_processor (#1492)</li> <li>e2e: make table name dynamic</li> <li>e2e: fix idempotency typing</li> </ul>"
        },
        {
            "location": "changelog/#documentation_56",
            "title": "Documentation",
            "text": "<ul> <li>batch: remove legacy reference to sqs processor</li> <li>homepage: note about v2 version</li> <li>homepage: auto-update Layer ARN on every release (#1610)</li> <li>roadmap: refresh roadmap post-v2 launch</li> <li>roadmap: include observability provider and lambda layer themes before v2</li> <li>upgrade_guide: add latest changes and quick summary (#1623)</li> <li>v2: document optional dependencies and local dev (#1574)</li> </ul>"
        },
        {
            "location": "changelog/#features_56",
            "title": "Features",
            "text": "<ul> <li>apigateway: ignore trailing slashes in routes (APIGatewayRestResolver) (#1609)</li> <li>ci: release docs as alpha when doing a pre-release (#1624)</li> <li>data-classes: replace AttributeValue in DynamoDBStreamEvent with deserialized Python values (#1619)</li> <li>data_classes: add KinesisFirehoseEvent (#1540)</li> <li>event_handler: improved support for headers and cookies in v2 (#1455)</li> <li>event_handler: add cookies as 1st class citizen in v2 (#1487)</li> <li>idempotency: support methods with the same name (ABCs) by including fully qualified name in v2 (#1535)</li> <li>layer: publish SAR v2 via Github actions (#1585)</li> <li>layers: add support for publishing v2 layer (#1558)</li> <li>parameters: migrate AppConfig to new APIs due to API deprecation (#1553)</li> <li>tracer: support methods with the same name (ABCs) by including fully qualified name in v2 (#1486)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_77",
            "title": "Maintenance",
            "text": "<ul> <li>update v2 layer ARN on documentation</li> <li>update v2 layer ARN on documentation</li> <li>update v2 layer ARN on documentation</li> <li>update v2 layer ARN on documentation</li> <li>merge v2 branch</li> <li>bump pyproject version to 2.0</li> <li>ci: make release process manual</li> <li>ci: migrate E2E tests to CDK CLI and off Docker (#1501)</li> <li>ci: remove v1 workflows (#1617)</li> <li>core: expose modules in the Top-level package (#1517)</li> <li>dep: add cfn-lint as a dev dependency; pre-commit (#1612)</li> <li>deps: remove email-validator; use Str over EmailStr in SES model (#1608)</li> <li>deps: bump release-drafter/release-drafter from 5.21.0 to 5.21.1 (#1611)</li> <li>deps: lock importlib to 4.x</li> <li>deps-dev: bump mypy-boto3-s3 from 1.24.76 to 1.24.94 (#1622)</li> <li>deps-dev: bump aws-cdk-lib from 2.46.0 to 2.47.0 (#1629)</li> <li>layer: bump to 1.31.1 (v39)</li> </ul>"
        },
        {
            "location": "changelog/#v1311-2022-10-14",
            "title": "v1.31.1 - 2022-10-14",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_74",
            "title": "Bug Fixes",
            "text": "<ul> <li>parser: loose validation on SNS fields to support FIFO (#1606)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_57",
            "title": "Documentation",
            "text": "<ul> <li>governance: allow community to suggest feature content (#1593)</li> <li>governance: new form to allow customers self-nominate as public reference (#1589)</li> <li>homepage: include .NET powertools</li> <li>idempotency: \"persisntence\" typo (#1596)</li> <li>logger: fix typo. (#1587)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_78",
            "title": "Maintenance",
            "text": "<ul> <li>add dummy v2 sar deploy job</li> <li>bump layer version to 38</li> <li>deps-dev: bump mypy-boto3-ssm from 1.24.81 to 1.24.90 (#1594)</li> <li>deps-dev: bump flake8-builtins from 1.5.3 to 2.0.0 (#1582)</li> </ul>"
        },
        {
            "location": "changelog/#v1310-2022-10-10",
            "title": "v1.31.0 - 2022-10-10",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_75",
            "title": "Bug Fixes",
            "text": "<ul> <li>metrics: ensure dimension_set is reused across instances (pointer) (#1581)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_58",
            "title": "Documentation",
            "text": "<ul> <li>readme: add lambda layer latest version badge</li> </ul>"
        },
        {
            "location": "changelog/#features_57",
            "title": "Features",
            "text": "<ul> <li>parser: add KinesisFirehoseModel (#1556)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_79",
            "title": "Maintenance",
            "text": "<ul> <li>deps-dev: bump types-requests from 2.28.11.1 to 2.28.11.2 (#1576)</li> <li>deps-dev: bump typing-extensions from 4.3.0 to 4.4.0 (#1575)</li> <li>layer: remove unsused GetFunction permission for the canary</li> <li>layer: bump to latest version 37</li> </ul>"
        },
        {
            "location": "changelog/#v1300-2022-10-05",
            "title": "v1.30.0 - 2022-10-05",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_76",
            "title": "Bug Fixes",
            "text": "<ul> <li>apigateway: update Response class to require status_code only (#1560)</li> <li>ci: integrate isort 5.0 with black to resolve conflicts</li> <li>event_sources: implement Mapping protocol on DictWrapper for better interop with existing middlewares (#1516)</li> <li>typing: fix mypy error</li> <li>typing: level arg in copy_config_to_registered_loggers (#1534)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_59",
            "title": "Documentation",
            "text": "<ul> <li>batch: document the new lambda context feature</li> <li>homepage: introduce POWERTOOLS_DEV env var (#1569)</li> <li>multiple: fix highlighting after new isort/black integration</li> <li>parser: add JSON string field extension example (#1526)</li> </ul>"
        },
        {
            "location": "changelog/#features_58",
            "title": "Features",
            "text": "<ul> <li>batch: inject lambda_context if record handler signature accepts it (#1561)</li> <li>event-handler: context support to share data between routers (#1567)</li> <li>logger: introduce POWERTOOLS_DEBUG for internal debugging (#1572)</li> <li>logger: include logger name attribute when copy_config_to_registered_logger is used (#1568)</li> <li>logger: pretty-print JSON when POWERTOOLS_DEV is set (#1548)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_80",
            "title": "Maintenance",
            "text": "<ul> <li>dep: bump pyproject to pypi sync</li> <li>deps: bump fastjsonschema from 2.16.1 to 2.16.2 (#1530)</li> <li>deps: bump actions/setup-python from 3 to 4 (#1528)</li> <li>deps: bump codecov/codecov-action from 3.1.0 to 3.1.1 (#1529)</li> <li>deps: bump dependabot/fetch-metadata from 1.3.3 to 1.3.4 (#1565)</li> <li>deps: bump email-validator from 1.2.1 to 1.3.0 (#1533)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.24.54 to 1.24.83 (#1557)</li> <li>deps-dev: bump mkdocs-material from 8.5.3 to 8.5.4 (#1563)</li> <li>deps-dev: bump pytest-cov from 3.0.0 to 4.0.0 (#1551)</li> <li>deps-dev: bump flake8-bugbear from 22.9.11 to 22.9.23 (#1541)</li> <li>deps-dev: bump types-requests from 2.28.11 to 2.28.11.1 (#1571)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.24.69 to 1.24.80 (#1542)</li> <li>deps-dev: bump mako from 1.2.2 to 1.2.3 (#1537)</li> <li>deps-dev: bump types-requests from 2.28.10 to 2.28.11 (#1538)</li> <li>deps-dev: bump mkdocs-material from 8.5.1 to 8.5.3 (#1532)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.24.80 to 1.24.81 (#1544)</li> <li>deps-dev: bump mypy-boto3-s3 from 1.24.36.post1 to 1.24.76 (#1531)</li> <li>docs: bump layer version to 36 (1.29.2)</li> <li>layers: add dummy v2 layer automation</li> <li>lint: use new isort black integration</li> <li>multiple: localize powertools_dev env logic and warning (#1570)</li> </ul>"
        },
        {
            "location": "changelog/#v1292-2022-09-19",
            "title": "v1.29.2 - 2022-09-19",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_77",
            "title": "Bug Fixes",
            "text": "<ul> <li>deps: bump dev dep mako version to address CVE-2022-40023 (#1524)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_81",
            "title": "Maintenance",
            "text": "<ul> <li>deps: bump release-drafter/release-drafter from 5.20.1 to 5.21.0 (#1520)</li> <li>deps-dev: bump mkdocs-material from 8.5.0 to 8.5.1 (#1521)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.24.60 to 1.24.74 (#1522)</li> </ul>"
        },
        {
            "location": "changelog/#v1291-2022-09-13",
            "title": "v1.29.1 - 2022-09-13",
            "text": ""
        },
        {
            "location": "changelog/#v1290-2022-09-13",
            "title": "v1.29.0 - 2022-09-13",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_78",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: ignore v2 action for now</li> <li>ci: only run e2e tests on py 3.7</li> <li>ci: pass core fns to large pr workflow script</li> <li>ci: on_label permissioning model &amp; workflow execution</li> <li>ci: ensure PR_AUTHOR is present for large_pr_split workflow</li> <li>ci: gracefully and successful exit changelog upon no changes</li> <li>ci: event resolution for on_label_added workflow</li> <li>core: fixes leftovers from rebase</li> </ul>"
        },
        {
            "location": "changelog/#documentation_60",
            "title": "Documentation",
            "text": "<ul> <li>layer: upgrade to 1.28.0 (v33)</li> </ul>"
        },
        {
            "location": "changelog/#features_59",
            "title": "Features",
            "text": "<ul> <li>ci: add actionlint in pre-commit hook</li> <li>data-classes: add KafkaEvent and KafkaEventRecord (#1485)</li> <li>event_sources: add CloudWatch dashboard custom widget event (#1474)</li> <li>parser: add KafkaMskEventModel and KafkaSelfManagedEventModel (#1499)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_82",
            "title": "Maintenance",
            "text": "<ul> <li>ci: add workflow to suggest splitting large PRs (#1480)</li> <li>ci: remove unused and undeclared OS matrix env</li> <li>ci: disable v2 docs</li> <li>ci: limit E2E workflow run for source code change</li> <li>ci: add missing description fields</li> <li>ci: sync package version with pypi</li> <li>ci: fix invalid dependency leftover</li> <li>ci: create adhoc docs workflow for v2</li> <li>ci: create adhoc docs workflow for v2</li> <li>ci: remove dangling debug step</li> <li>ci: create docs workflow for v2</li> <li>ci: create reusable docs publishing workflow (#1482)</li> <li>ci: format comment  on comment_large_pr script</li> <li>ci: add note for state persistence on comment_large_pr</li> <li>ci: destructure assignment on comment_large_pr</li> <li>ci: record pr details upon labeling</li> <li>ci: add linter for GitHub Actions as pre-commit hook (#1479)</li> <li>ci: enable ci checks for v2</li> <li>deps-dev: bump black from 21.12b0 to 22.8.0 (#1515)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.24.55.post1 to 1.24.60 (#1481)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.24.55.post1 to 1.24.60 (#306)</li> <li>deps-dev: bump mkdocs-material from 8.4.1 to 8.4.2 (#1483)</li> <li>deps-dev: revert to v1.28.0 dependencies</li> <li>deps-dev: bump mkdocs-material from 8.4.4 to 8.5.0 (#1514)</li> <li>maintainers: update release workflow link</li> <li>maintenance: add discord link to first PR and first issue (#1493)</li> </ul>"
        },
        {
            "location": "changelog/#v1280-2022-08-25",
            "title": "v1.28.0 - 2022-08-25",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_79",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: calculate parallel jobs based on infrastructure needs (#1475)</li> <li>ci: del flake8 direct dep over py3.6 conflicts and docs failure</li> <li>ci: move from pip-tools to poetry on layers reusable workflow</li> <li>ci: move from pip-tools to poetry on layers to fix conflicts</li> <li>ci: typo and bust gh actions cache</li> <li>ci: use poetry to resolve layer deps; pip for CDK</li> <li>ci: disable poetry venv for layer workflow as cdk ignores venv</li> <li>ci: add cdk v2 dep for layers workflow</li> <li>ci: move from pip-tools to poetry on layers</li> <li>ci: temporarily disable changelog upon release</li> <li>ci: add explicit origin to fix release detached head</li> <li>jmespath_util: snappy as dev dep and typing example (#1446)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_61",
            "title": "Documentation",
            "text": "<ul> <li>apigateway: removes duplicate admonition (#1426)</li> <li>home: fix discord syntax and add Discord badge</li> <li>home: add discord invitation link (#1471)</li> <li>jmespath_util: snippets split, improved, and lint (#1419)</li> <li>layer: upgrade to 1.27.0</li> <li>layer: upgrade to 1.27.0</li> <li>middleware-factory: snippets split, improved, and lint (#1451)</li> <li>parser: minor grammar fix (#1427)</li> <li>typing: snippets split, improved, and lint (#1465)</li> <li>validation: snippets split, improved, and lint (#1449)</li> </ul>"
        },
        {
            "location": "changelog/#features_60",
            "title": "Features",
            "text": "<ul> <li>parser: add support for Lambda Function URL (#1442)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_83",
            "title": "Maintenance",
            "text": "<ul> <li>batch: deprecate sqs_batch_processor (#1463)</li> <li>ci: prevent concurrent git update in critical workflows (#1478)</li> <li>ci: disable e2e py version matrix due to concurrent locking</li> <li>ci: revert e2e py version matrix</li> <li>ci: temp disable e2e matrix</li> <li>ci: update changelog with latest changes</li> <li>ci: update changelog with latest changes</li> <li>ci: reduce payload and only send prod notification</li> <li>ci: remove area/utilities conflicting label</li> <li>ci: include py version in stack and cache lock</li> <li>ci: remove conventional changelog commit to reduce noise</li> <li>ci: update changelog with latest changes</li> <li>deps: bump release-drafter/release-drafter from 5.20.0 to 5.20.1 (#1458)</li> <li>deps: bump pydantic from 1.9.1 to 1.9.2 (#1448)</li> <li>deps-dev: bump flake8-bugbear from 22.8.22 to 22.8.23 (#1473)</li> <li>deps-dev: bump types-requests from 2.28.7 to 2.28.8 (#1423)</li> <li>maintainer: add Leandro as maintainer (#1468)</li> <li>tests: build and deploy Lambda Layer stack once (#1466)</li> <li>tests: refactor E2E test mechanics to ease maintenance, writing tests and parallelization (#1444)</li> <li>tests: enable end-to-end test workflow (#1470)</li> <li>tests: refactor E2E logger to ease maintenance, writing tests and parallelization (#1460)</li> <li>tests: refactor E2E tracer to ease maintenance, writing tests and parallelization (#1457)</li> </ul>"
        },
        {
            "location": "changelog/#reverts_2",
            "title": "Reverts",
            "text": "<ul> <li>fix(ci): add explicit origin to fix release detached head</li> </ul>"
        },
        {
            "location": "changelog/#v1270-2022-08-05",
            "title": "v1.27.0 - 2022-08-05",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_80",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: changelog workflow must receive git tags too</li> <li>ci: add additional input to accurately describe intent on skip</li> <li>ci: job permissions</li> <li>event_sources: add test for Function URL AuthZ (#1421)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_62",
            "title": "Documentation",
            "text": "<ul> <li>layer: upgrade to 1.26.7</li> </ul>"
        },
        {
            "location": "changelog/#features_61",
            "title": "Features",
            "text": "<ul> <li>ci: create reusable changelog generation (#1418)</li> <li>ci: include changelog generation on docs build</li> <li>ci: create reusable changelog generation</li> <li>event_handlers: Add support for Lambda Function URLs (#1408)</li> <li>metrics: update max user-defined dimensions from 9 to 29 (#1417)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_84",
            "title": "Maintenance",
            "text": "<ul> <li>ci: sync area labels to prevent dedup</li> <li>ci: update changelog with latest changes</li> <li>ci: update changelog with latest changes</li> <li>ci: add manual trigger for docs</li> <li>ci: update changelog with latest changes</li> <li>ci: temporarily disable changelog push on release</li> <li>ci: update changelog with latest changes</li> <li>ci: move changelog generation to rebuild_latest_doc workflow</li> <li>ci: update project with version</li> <li>ci: update release automated activities</li> <li>ci: readd changelog step on release</li> <li>ci: move changelog generation to rebuild_latest_doc workflow</li> <li>ci: drop 3.6 from workflows</li> <li>deps: bump constructs from 10.1.1 to 10.1.60 (#1399)</li> <li>deps: bump constructs from 10.1.1 to 10.1.66 (#1414)</li> <li>deps: bump jsii from 1.57.0 to 1.63.2 (#1400)</li> <li>deps: bump constructs from 10.1.1 to 10.1.64 (#1405)</li> <li>deps: bump attrs from 21.4.0 to 22.1.0 (#1397)</li> <li>deps: bump constructs from 10.1.1 to 10.1.63 (#1402)</li> <li>deps: bump constructs from 10.1.1 to 10.1.65 (#1407)</li> <li>deps-dev: bump types-requests from 2.28.5 to 2.28.6 (#1401)</li> <li>deps-dev: bump types-requests from 2.28.6 to 2.28.7 (#1406)</li> <li>docs: remove pause sentence from roadmap (#1409)</li> <li>docs: update site name to test ci changelog</li> <li>docs: update CHANGELOG for v1.26.7</li> <li>docs: update description to trigger changelog generation</li> <li>governance: remove devcontainer in favour of gitpod.io (#1411)</li> <li>governance: add pre-configured dev environment with GitPod.io to ease contributions (#1403)</li> <li>layers: upgrade cdk dep hashes to prevent ci fail</li> </ul>"
        },
        {
            "location": "changelog/#v1267-2022-07-29",
            "title": "v1.26.7 - 2022-07-29",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_81",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: add missing oidc token generation permission</li> <li>event_handlers: ImportError when importing Response from top-level event_handler (#1388)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_63",
            "title": "Documentation",
            "text": "<ul> <li>examples: enforce and fix all mypy errors (#1393)</li> </ul>"
        },
        {
            "location": "changelog/#features_62",
            "title": "Features",
            "text": "<ul> <li>idempotency: handle lambda timeout scenarios for INPROGRESS records (#1387)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_85",
            "title": "Maintenance",
            "text": "<ul> <li>ci: increase skip_pypi logic to cover tests/changelog on re-run failures</li> <li>ci: update project with version 1.26.6</li> <li>ci: drop 3.6 from workflows (#1395)</li> <li>ci: add conditional to skip pypi release (#1366)</li> <li>ci: remove leftover logic from on_merged_pr workflow</li> <li>ci: update project with version 1.26.6</li> <li>ci: update project with version 1.26.6</li> <li>deps: bump jsii from 1.57.0 to 1.63.1 (#1390)</li> <li>deps: bump constructs from 10.1.1 to 10.1.59 (#1396)</li> <li>deps-dev: bump flake8-isort from 4.1.1 to 4.1.2.post0 (#1384)</li> <li>layers: bump to 1.26.6 using layer v26</li> <li>maintainers: add Ruben as a maintainer (#1392)</li> </ul>"
        },
        {
            "location": "changelog/#v1266-2022-07-25",
            "title": "v1.26.6 - 2022-07-25",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_82",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: remove unsupported env in workflow_call</li> <li>ci: allow inherit secrets for reusable workflow</li> <li>ci: remove unused secret</li> <li>ci: label_related_issue unresolved var from history mixup</li> <li>ci: cond doesnt support two expr w/ env</li> <li>ci: only event is resolved in cond</li> <li>ci: unexpected symbol due to double quotes...</li> <li>event_handlers: handle lack of headers when using auto-compression feature (#1325)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_86",
            "title": "Maintenance",
            "text": "<ul> <li>dummy for PR test</li> <li>print full event depth</li> <li>print full workflow event depth</li> <li>debug full event</li> <li>remove leftover from fork one more time</li> <li>ci: test env expr</li> <li>ci: test upstream job skip</li> <li>ci: lockdown workflow_run by origin (#1350)</li> <li>ci: test default env</li> <li>ci: experiment hardening origin</li> <li>ci: experiment hardening origin</li> <li>ci: introduce codeowners (#1352)</li> <li>ci: use OIDC and encrypt release secrets (#1355)</li> <li>ci: remove core group from codeowners (#1358)</li> <li>ci: confirm workflow_run event</li> <li>ci: use gh environment for beta and prod layer deploy (#1356)</li> <li>ci: update project with version 1.26.5</li> <li>deps: bump constructs from 10.1.1 to 10.1.52 (#1343)</li> <li>deps-dev: bump mypy-boto3-cloudwatch from 1.24.0 to 1.24.35 (#1342)</li> <li>governance: update wording tech debt to summary in maintenance template</li> <li>governance: add new maintenance issue template for tech debt (#1326)</li> <li>layers: layer canary stack should not hardcode resource name</li> <li>layers: replace layers account secret (#1329)</li> <li>layers: expand to all aws commercial regions (#1324)</li> <li>layers: bump to 1.26.5</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #285 from heitorlessa/chore/skip-dep-workflow</li> <li>Merge pull request #284 from heitorlessa/chore/dummy</li> </ul>"
        },
        {
            "location": "changelog/#v1265-2022-07-20",
            "title": "v1.26.5 - 2022-07-20",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_83",
            "title": "Bug Fixes",
            "text": "<ul> <li>mathc the name of the cdk synth from the build phase</li> <li>typo in input for layer workflow</li> <li>no need to cache npm since we only install cdk cli and don't have .lock files</li> <li>add entire ARN role instead of account and role name</li> <li>path to artefact</li> <li>unzip the right artifact name</li> <li>download artefact into the layer dir</li> <li>sight, yes a whitespace character breaks the build</li> <li>ci: checkout project before validating related issue workflow</li> <li>ci: install poetry before calling setup/python with cache (#1315)</li> <li>ci: remove additional quotes in PR action (#1317)</li> <li>ci: lambda layer workflow release version and conditionals (#1316)</li> <li>ci: fetch all git info so we can check tags</li> <li>ci: lambda layer workflow release version and conditionals (#1316)</li> <li>ci: keep layer version permission (#1318)</li> <li>ci: regex to catch combination of related issues workflow</li> <li>deps: correct mypy types as dev dependency (#1322)</li> <li>logger: preserve std keys when using custom formatters (#1264)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_64",
            "title": "Documentation",
            "text": "<ul> <li>event-handler: snippets split, improved, and lint (#1279)</li> <li>governance: typos on PR template fixes #1314</li> <li>governance: add security doc to the root</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_87",
            "title": "Maintenance",
            "text": "<ul> <li>ci: limits concurrency for docs workflow</li> <li>ci: adds caching when installing python dependencies (#1311)</li> <li>ci: update project with version 1.26.4</li> <li>ci: fix reference error in related_issue</li> <li>deps: bump constructs from 10.1.1 to 10.1.51 (#1323)</li> <li>deps-dev: bump mypy from 0.961 to 0.971 (#1320)</li> <li>governance: fix typo on semantic commit link introduced in #1aef4</li> <li>layers: add release pipeline in GitHub Actions (#1278)</li> <li>layers: bump to 22 for 1.26.3</li> </ul>"
        },
        {
            "location": "changelog/#v1264-2022-07-18",
            "title": "v1.26.4 - 2022-07-18",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_84",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: checkout project before validating related issue workflow</li> <li>ci: fixes typos and small issues on github scripts (#1302)</li> <li>ci: address conditional type on_merge</li> <li>ci: address pr title semantic not found logic</li> <li>ci: address gh-actions additional quotes; remove debug</li> <li>ci: regex group name for on_merge workflow</li> <li>ci: escape outputs as certain PRs can break GH Actions expressions</li> <li>ci: move conditionals from yaml to code; leftover</li> <li>ci: move conditionals from yaml to code</li> <li>ci: accept core arg in label related issue workflow</li> <li>ci: match the name of the cdk synth from the build phase</li> <li>ci: regex to catch combination of related issues workflow</li> <li>logger: preserve std keys when using custom formatters (#1264)</li> <li>parser: raise ValidationError when SNS-&gt;SQS keys are intentionally missing (#1299)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_65",
            "title": "Documentation",
            "text": "<ul> <li>event-handler: snippets split, improved, and lint (#1279)</li> <li>graphql: snippets split, improved, and lint (#1287)</li> <li>homepage: emphasize additional powertools languages (#1292)</li> <li>metrics: snippets split, improved, and lint</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_88",
            "title": "Maintenance",
            "text": "<ul> <li>ci: increase release automation and limit to one manual step (#1297)</li> <li>ci: make export PR reusable</li> <li>ci: auto-merge cdk lib and lambda layer construct</li> <li>ci: convert inline gh-script to file</li> <li>ci: lockdown 3rd party workflows to pin sha (#1301)</li> <li>ci: automatically add area label based on title (#1300)</li> <li>ci: disable output debugging as pr body isnt accepted</li> <li>ci: experiment with conditional on outputs</li> <li>ci: improve error handling for non-issue numbers</li> <li>ci: add end to end testing mechanism (#1247)</li> <li>ci: limits concurrency for docs workflow</li> <li>ci: fix reference error in related_issue</li> <li>ci: move error prone env to code as constants</li> <li>ci: move all scripts under .github/scripts</li> <li>deps: bump cdk-lambda-powertools-python-layer (#1284)</li> <li>deps: bump jsii from 1.61.0 to 1.62.0 (#1294)</li> <li>deps: bump constructs from 10.1.1 to 10.1.46 (#1306)</li> <li>deps: bump actions/setup-node from 2 to 3 (#1281)</li> <li>deps: bump fastjsonschema from 2.15.3 to 2.16.1 (#1309)</li> <li>deps: bump constructs from 10.1.1 to 10.1.49 (#1308)</li> <li>deps: bump attrs from 21.2.0 to 21.4.0 (#1282)</li> <li>deps: bump aws-cdk-lib from 2.29.0 to 2.31.1 (#1290)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.24.12 to 1.24.27 (#1293)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.24.0 to 1.24.29 (#1295)</li> <li>governance: remove any step relying on master branch</li> <li>governance: update emeritus affiliation</li> <li>layers: add release pipeline in GitHub Actions (#1278)</li> <li>layers: bump to 22 for 1.26.3</li> </ul>"
        },
        {
            "location": "changelog/#v1263-2022-07-04",
            "title": "v1.26.3 - 2022-07-04",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_85",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: remove utf-8 body in octokit body req</li> <li>ci: improve msg visibility on closed issues</li> <li>ci: disable merged_pr workflow</li> <li>ci: merged_pr add issues write access</li> <li>ci: quote prBody GH expr on_opened_pr</li> <li>ci: reusable workflow secrets param</li> <li>logger: support additional args for handlers when injecting lambda context (#1276)</li> <li>logger: preserve std keys when using custom formatters (#1264)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_66",
            "title": "Documentation",
            "text": "<ul> <li>lint: add markdownlint rules and automation (#1256)</li> <li>logger: document enriching logs with logrecord attributes (#1271)</li> <li>logger: snippets split, improved, and lint (#1262)</li> <li>metrics: snippets split, improved, and lint (#1272)</li> <li>tracer: snippets split, improved, and lint (#1261)</li> <li>tracer: split and lint code snippets (#1260)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_89",
            "title": "Maintenance",
            "text": "<ul> <li>move to approach B for multiple IaC</li> <li>add sam build gitignore</li> <li>bump to version 1.26.3</li> <li>ci: reactivate on_merged_pr workflow</li> <li>ci: improve wording on closed issues action</li> <li>ci: deactivate on_merged_pr workflow</li> <li>deps: bump aws-xray-sdk from 2.9.0 to 2.10.0 (#1270)</li> <li>deps: bump dependabot/fetch-metadata from 1.1.1 to 1.3.2 (#1269)</li> <li>deps: bump dependabot/fetch-metadata from 1.3.2 to 1.3.3 (#1273)</li> <li>deps-dev: bump flake8-bugbear from 22.6.22 to 22.7.1 (#1274)</li> <li>deps-dev: bump flake8-bugbear from 22.4.25 to 22.6.22 (#1258)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.24.0 to 1.24.12 (#1255)</li> <li>deps-dev: bump mypy-boto3-secretsmanager (#1252)</li> <li>governance: fix on_merged_pr workflow syntax</li> <li>governance: warn message on closed issues</li> <li>layers: bump to 21 for 1.26.2</li> <li>test-perf: use pytest-benchmark to improve reliability (#1250)</li> </ul>"
        },
        {
            "location": "changelog/#v1262-2022-06-16",
            "title": "v1.26.2 - 2022-06-16",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_86",
            "title": "Bug Fixes",
            "text": "<ul> <li>event-handler: body to empty string in CORS preflight (ALB non-compliant) (#1249)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_21",
            "title": "Code Refactoring",
            "text": "<ul> <li>rename to clear_state</li> <li>rename to remove_custom_keys</li> </ul>"
        },
        {
            "location": "changelog/#documentation_67",
            "title": "Documentation",
            "text": "<ul> <li>fix anchor</li> </ul>"
        },
        {
            "location": "changelog/#features_63",
            "title": "Features",
            "text": "<ul> <li>logger: add option to clear state per invocation</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_90",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.26.2</li> <li>deps: bump actions/setup-python from 3 to 4 (#1244)</li> <li>deps-dev: bump mypy from 0.960 to 0.961 (#1241)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.23.0.post1 to 1.24.0 (#1231)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.23.8 to 1.24.0 (#1232)</li> <li>deps-dev: bump mypy-boto3-dynamodb from 1.23.0.post1 to 1.24.0 (#1234)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.23.0.post1 to 1.24.0 (#1233)</li> <li>governance: auto-merge on all PR events</li> <li>governance: add release label on pr merge</li> <li>governance: enforce safe scope on pr merge labelling</li> <li>governance: limit build workflow to code changes only</li> <li>governance: auto-merge workflow_dispatch off</li> <li>governance: auto-merge to use squash</li> <li>governance: check for related issue in new PRs</li> <li>governance: auto-merge mypy-stub dependabot</li> <li>governance: address gh reusable workflow limitation</li> <li>governance: fix workflow action requirements &amp; syntax</li> <li>governance: warn message on closed issues</li> <li>metrics: revert dimensions test before splitting (#1243)</li> </ul>"
        },
        {
            "location": "changelog/#v1261-2022-06-07",
            "title": "v1.26.1 - 2022-06-07",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_87",
            "title": "Bug Fixes",
            "text": "<ul> <li>metrics: raise SchemaValidationError for &gt;8 metric dimensions (#1240)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_68",
            "title": "Documentation",
            "text": "<ul> <li>governance: link roadmap and maintainers doc</li> <li>maintainers: initial maintainers playbook (#1222)</li> <li>roadmap: use pinned pause issue instead</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_91",
            "title": "Maintenance",
            "text": "<ul> <li>bump version 1.26.1</li> <li>deps-dev: bump mypy from 0.950 to 0.960 (#1224)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.23.0.post1 to 1.23.8 (#1225)</li> </ul>"
        },
        {
            "location": "changelog/#v1260-2022-05-20",
            "title": "v1.26.0 - 2022-05-20",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_88",
            "title": "Bug Fixes",
            "text": "<ul> <li>batch: missing space in BatchProcessingError message (#1201)</li> <li>batch: docstring fix for success_handler() record parameter (#1202)</li> <li>docs: remove Slack link (#1210)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_69",
            "title": "Documentation",
            "text": "<ul> <li>layer: upgrade to 1.25.10</li> <li>roadmap: add new roadmap section (#1204)</li> </ul>"
        },
        {
            "location": "changelog/#features_64",
            "title": "Features",
            "text": "<ul> <li>parameters: accept boto3_client to support private endpoints and ease testing (#1096)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_92",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.26.0</li> <li>deps: bump pydantic from 1.9.0 to 1.9.1 (#1221)</li> <li>deps: bump email-validator from 1.1.3 to 1.2.1 (#1199)</li> <li>deps-dev: bump mypy-boto3-secretsmanager from 1.21.34 to 1.23.0.post1 (#1218)</li> <li>deps-dev: bump mypy-boto3-appconfig from 1.21.34 to 1.23.0.post1 (#1219)</li> <li>deps-dev: bump mypy-boto3-ssm from 1.21.34 to 1.23.0.post1 (#1220)</li> </ul>"
        },
        {
            "location": "changelog/#v12510-2022-04-29",
            "title": "v1.25.10 - 2022-04-29",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_89",
            "title": "Bug Fixes",
            "text": "<ul> <li>data-classes: Add missing SES fields and (#1045)</li> <li>deps: Ignore boto3 changes until needed (#1151)</li> <li>deps-dev: remove jmespath due to dev deps conflict  (#1148)</li> <li>event_handler: exception_handler to handle ServiceError exceptions (#1160)</li> <li>event_handler: Allow for event_source support (#1159)</li> <li>parser: Add missing fields for SESEvent (#1027)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_70",
            "title": "Documentation",
            "text": "<ul> <li>layer: upgrade to 1.25.9</li> </ul>"
        },
        {
            "location": "changelog/#features_65",
            "title": "Features",
            "text": "<ul> <li>parameters: add clear_cache method for providers (#1194)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_93",
            "title": "Maintenance",
            "text": "<ul> <li>include regression in changelog</li> <li>bump to 1.25.10</li> <li>ci: changelog pre-generation to fetch tags from origin</li> <li>ci: disable mergify configuration after breaking changes (#1188)</li> <li>ci: post release on tagged issues too</li> <li>deps: bump codecov/codecov-action from 3.0.0 to 3.1.0 (#1143)</li> <li>deps: bump github/codeql-action from 1 to 2 (#1154)</li> <li>deps-dev: bump flake8-eradicate from 1.2.0 to 1.2.1 (#1158)</li> <li>deps-dev: bump mypy from 0.942 to 0.950 (#1162)</li> <li>deps-dev: bump mkdocs-git-revision-date-plugin (#1146)</li> <li>deps-dev: bump flake8-bugbear from 22.1.11 to 22.4.25 (#1156)</li> <li>deps-dev: bump xenon from 0.8.0 to 0.9.0 (#1145)</li> <li>deps-dev: bump mypy from 0.931 to 0.942 (#1133)</li> </ul>"
        },
        {
            "location": "changelog/#regression_1",
            "title": "Regression",
            "text": "<ul> <li>parser: Add missing fields for SESEvent (#1027) (#1190)</li> </ul>"
        },
        {
            "location": "changelog/#v1259-2022-04-21",
            "title": "v1.25.9 - 2022-04-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_90",
            "title": "Bug Fixes",
            "text": "<ul> <li>deps: correct py36 marker for jmespath</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_94",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.25.9</li> </ul>"
        },
        {
            "location": "changelog/#v1258-2022-04-21",
            "title": "v1.25.8 - 2022-04-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_91",
            "title": "Bug Fixes",
            "text": "<ul> <li>removed ambiguous quotes from labels.</li> <li>deps: update jmespath marker to support 1.0 and py3.6 (#1139)</li> <li>governance: update label in names in issues</li> </ul>"
        },
        {
            "location": "changelog/#documentation_71",
            "title": "Documentation",
            "text": "<ul> <li>install: instructions to reduce pydantic package size (#1077)</li> <li>layer: remove link from clipboard button (#1135)</li> <li>layer: update to 1.25.7</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_95",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.25.8</li> <li>deps: bump codecov/codecov-action from 2.1.0 to 3.0.0 (#1102)</li> <li>deps: bump actions/upload-artifact from 2 to 3 (#1103)</li> <li>deps-dev: bump mkdocs-material from 8.2.4 to 8.2.7 (#1131)</li> <li>deps-dev: bump pytest from 6.2.5 to 7.0.1 (#1063)</li> </ul>"
        },
        {
            "location": "changelog/#v1257-2022-04-08",
            "title": "v1.25.7 - 2022-04-08",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_92",
            "title": "Bug Fixes",
            "text": "<ul> <li>api_gateway: allow whitespace in routes' path parameter (#1099)</li> <li>api_gateway: allow whitespace in routes' path parameter (#1099)</li> <li>idempotency: pass by value on idem key to guard inadvert mutations (#1090)</li> <li>logger: clear_state should keep custom key formats (#1095)</li> <li>middleware_factory: ret type annotation for handler dec (#1066)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_72",
            "title": "Documentation",
            "text": "<ul> <li>layer: update to 1.25.6; cosmetic changes</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_96",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.25.7</li> <li>governance: refresh pull request template sections</li> <li>governance: update external non-triage effort disclaimer</li> <li>governance: update static typing to a form</li> <li>governance: update rfc to a form</li> <li>governance: update feat request to a form</li> <li>governance: bug report form typo</li> <li>governance: update docs report to a form</li> <li>governance: update bug report to a form</li> <li>governance: new ask a question</li> <li>governance: new static typing report</li> </ul>"
        },
        {
            "location": "changelog/#v1256-2022-04-01",
            "title": "v1.25.6 - 2022-04-01",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_93",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: clear_state regression on absent standard keys (#1088)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_73",
            "title": "Documentation",
            "text": "<ul> <li>layer: bump to 1.25.5</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_97",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.25.6</li> </ul>"
        },
        {
            "location": "changelog/#v1255-2022-03-18",
            "title": "v1.25.5 - 2022-03-18",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_94",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger-utils: regression on exclude set leading to no formatter (#1080)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_98",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.25.5</li> </ul>"
        },
        {
            "location": "changelog/#v1254-2022-03-17",
            "title": "v1.25.4 - 2022-03-17",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_95",
            "title": "Bug Fixes",
            "text": "<ul> <li>package_logger as const over logger instance</li> <li>repurpose test to cover parent loggers case</li> <li>use addHandler over monkeypatch</li> </ul>"
        },
        {
            "location": "changelog/#documentation_74",
            "title": "Documentation",
            "text": "<ul> <li>appsync: fix typo</li> <li>contributing: operational excellence pause</li> <li>layer: update to 1.25.3</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_99",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.25.4</li> <li>remove duplicate test</li> <li>comment reason for change</li> <li>remove unnecessary test</li> <li>lint unused import</li> </ul>"
        },
        {
            "location": "changelog/#regression_2",
            "title": "Regression",
            "text": "<ul> <li>service_name fixture</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_1",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #1075 from mploski/fix/existing-loggers-duplicated-logs</li> </ul>"
        },
        {
            "location": "changelog/#v1253-2022-03-09",
            "title": "v1.25.3 - 2022-03-09",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_96",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: ensure state is cleared for custom formatters (#1072)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_75",
            "title": "Documentation",
            "text": "<ul> <li>plugin: add mermaid to create diagram as code (#1070)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_100",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.25.3</li> </ul>"
        },
        {
            "location": "changelog/#v1252-2022-03-07",
            "title": "v1.25.2 - 2022-03-07",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_97",
            "title": "Bug Fixes",
            "text": "<ul> <li>event_handler: docs snippets, high-level import CorsConfig (#1019)</li> <li>lambda-authorizer: allow proxy resources path in arn (#1051)</li> <li>metrics: flush upon a single metric 100th data point (#1046)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_76",
            "title": "Documentation",
            "text": "<ul> <li>layer: update to 1.25.1</li> <li>parser: APIGatewayProxyEvent to APIGatewayProxyEventModel (#1061)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_101",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.25.2</li> <li>deps: bump actions/setup-python from 2.3.1 to 3 (#1048)</li> <li>deps: bump actions/checkout from 2 to 3 (#1052)</li> <li>deps: bump actions/github-script from 5 to 6 (#1023)</li> <li>deps: bump fastjsonschema from 2.15.2 to 2.15.3 (#949)</li> <li>deps-dev: bump mkdocs-material from 8.1.9 to 8.2.4 (#1054)</li> </ul>"
        },
        {
            "location": "changelog/#v1251-2022-02-14",
            "title": "v1.25.1 - 2022-02-14",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_98",
            "title": "Bug Fixes",
            "text": "<ul> <li>batch: bugfix to clear exceptions between executions (#1022)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_102",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.25.1</li> <li>layers: bump to 10 for 1.25.0</li> </ul>"
        },
        {
            "location": "changelog/#v1250-2022-02-09",
            "title": "v1.25.0 - 2022-02-09",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_99",
            "title": "Bug Fixes",
            "text": "<ul> <li>apigateway: remove indentation in debug_mode (#987)</li> <li>batch: delete &gt;10 messages in legacy sqs processor (#818)</li> <li>ci: pr label regex for special chars in title</li> <li>logger: exclude source_logger in copy_config_to_registered_loggers (#1001)</li> <li>logger: test generates logfile</li> </ul>"
        },
        {
            "location": "changelog/#documentation_77",
            "title": "Documentation",
            "text": "<ul> <li>fix syntax errors and line highlights (#1004)</li> <li>add better BDD coments</li> <li>event-handler: improve testing section for graphql (#996)</li> <li>layer: update to 1.24.2</li> <li>parameters: add testing your code section (#1017)</li> <li>theme: upgrade mkdocs-material to 8.x (#1002)</li> <li>tutorial: fix broken internal links (#1000)</li> </ul>"
        },
        {
            "location": "changelog/#features_66",
            "title": "Features",
            "text": "<ul> <li>event-handler: new resolvers to fix current_event typing (#978)</li> <li>logger: log_event support event data classes (e.g. S3Event) (#984)</li> <li>mypy: complete mypy support for the entire codebase (#943)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_103",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.25.0</li> <li>correct docs</li> <li>correct docs</li> <li>use isinstance over type</li> <li>deps-dev: bump flake8-bugbear from 21.11.29 to 22.1.11 (#955)</li> <li>metrics: fix tests when warnings are disabled (#994)</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_2",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #971 from gyft/fix-logger-util-tests</li> </ul>"
        },
        {
            "location": "changelog/#v1242-2022-01-21",
            "title": "v1.24.2 - 2022-01-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_100",
            "title": "Bug Fixes",
            "text": "<ul> <li>data-classes: underscore support in api gateway authorizer resource name (#969)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_78",
            "title": "Documentation",
            "text": "<ul> <li>layer: update to 1.24.1</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_104",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.24.2</li> </ul>"
        },
        {
            "location": "changelog/#v1241-2022-01-20",
            "title": "v1.24.1 - 2022-01-20",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_101",
            "title": "Bug Fixes",
            "text": "<ul> <li>remove unused json import</li> <li>remove apigw contract when using event-handler, apigw tracing</li> <li>use decorators, split cold start to ease reading</li> <li>incorrect log keys, indentation, snippet consistency</li> <li>remove f-strings that doesn't evaluate expr</li> <li>batch: report multiple failures (#967)</li> <li>data-classes: docstring typos and clean up (#937)</li> <li>parameters: appconfig internal _get docstrings (#934)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_79",
            "title": "Documentation",
            "text": "<ul> <li>rename quickstart to tutorial in readme</li> <li>rename to tutorial given the size</li> <li>add final consideration section</li> <li>batch: snippet typo on batch processed messages iteration (#951)</li> <li>batch: fix typo in context manager keyword (#938)</li> <li>homepage: link to typescript version (#950)</li> <li>install: new lambda layer for 1.24.0 release</li> <li>metrics: keep it consistent with other sections, update metric names</li> <li>nav: make REST and GraphQL event handlers more explicit (#959)</li> <li>quickstart: expand on intro line</li> <li>quickstart: tidy requirements up</li> <li>quickstart: make section agnostic to json lib</li> <li>quickstart: same process for Logger</li> <li>quickstart: add sub-sections, fix highlight &amp; code</li> <li>quickstart: sentence fragmentation, tidy up</li> <li>tenets: make core, non-core more explicit</li> <li>tracer: warning to note on local traces</li> <li>tracer: add initial image, requirements</li> <li>tracer: add annotation, metadata, and image</li> <li>tracer: update ServiceLens image w/ API GW, copywriting</li> <li>tutorial: fix path to images (#963)</li> </ul>"
        },
        {
            "location": "changelog/#features_67",
            "title": "Features",
            "text": "<ul> <li>ci: auto-notify &amp; close issues on release</li> <li>logger: clone powertools logger config to any Python logger (#927)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_105",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.24.1</li> <li>bump to 1.24.1</li> <li>ci: run codeql analysis on push only</li> <li>ci: fix mergify dependabot queue</li> <li>ci: add queue name in mergify</li> <li>ci: remove mergify legacy key</li> <li>ci: update mergify bot breaking change</li> <li>ci: safely label PR based on title</li> <li>deps: bump pydantic from 1.8.2 to 1.9.0 (#933)</li> <li>deps-dev: bump mypy from 0.930 to 0.931 (#941)</li> </ul>"
        },
        {
            "location": "changelog/#regression_3",
            "title": "Regression",
            "text": "<ul> <li>order to APP logger/service name due to screenshots</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_3",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #769 from mploski/docs/quick-start</li> </ul>"
        },
        {
            "location": "changelog/#v1240-2021-12-31",
            "title": "v1.24.0 - 2021-12-31",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_102",
            "title": "Bug Fixes",
            "text": "<ul> <li>apigateway: support @app.not_found() syntax &amp; housekeeping (#926)</li> <li>event-sources: handle dynamodb null type as none, not bool (#929)</li> <li>warning: future distutils deprecation (#921)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_80",
            "title": "Documentation",
            "text": "<ul> <li>consistency around admonitions and snippets (#919)</li> <li>Added GraphQL Sample API to Examples section of README.md (#930)</li> <li>batch: remove leftover from legacy</li> <li>layer: bump Lambda Layer to version 6</li> <li>tracer: new ignore_endpoint feature (#931)</li> </ul>"
        },
        {
            "location": "changelog/#features_68",
            "title": "Features",
            "text": "<ul> <li>event-sources: cache parsed json in data class (#909)</li> <li>feature_flags: support beyond boolean values (JSON values) (#804)</li> <li>idempotency: support dataclasses &amp; pydantic models payloads (#908)</li> <li>logger: support use_datetime_directive for timestamps (#920)</li> <li>tracer: ignore tracing for certain hostname(s) or url(s) (#910)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_106",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.24.0</li> <li>deps-dev: bump mypy from 0.920 to 0.930 (#925)</li> </ul>"
        },
        {
            "location": "changelog/#v1230-2021-12-20",
            "title": "v1.23.0 - 2021-12-20",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_103",
            "title": "Bug Fixes",
            "text": "<ul> <li>apigateway: allow list of HTTP methods in route method (#838)</li> <li>event-sources: Pass authorizer data to APIGatewayEventAuthorizer (#897)</li> <li>event-sources: handle claimsOverrideDetails set to null (#878)</li> <li>idempotency: include decorated fn name in hash (#869)</li> <li>metrics: explicit type to single_metric ctx manager (#865)</li> <li>parameters: appconfig transform and return types (#877)</li> <li>parser: overload parse when using envelope (#885)</li> <li>parser: kinesis sequence number is str, not int (#907)</li> <li>parser: mypy support for payload type override as models (#883)</li> <li>tracer: add warm start annotation (ColdStart=False) (#851)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_81",
            "title": "Documentation",
            "text": "<ul> <li>external reference to cloudformation custom resource helper (#914)</li> <li>add new public Slack invite</li> <li>disable search blur in non-prod env</li> <li>update Lambda Layers version</li> <li>apigateway: add new not_found feature (#915)</li> <li>apigateway: fix sample layout provided (#864)</li> <li>appsync: fix users.py typo to locations #830</li> <li>lambda_layer: fix CDK layer syntax</li> </ul>"
        },
        {
            "location": "changelog/#features_69",
            "title": "Features",
            "text": "<ul> <li>apigateway: add exception_handler support (#898)</li> <li>apigateway: access parent api resolver from router (#842)</li> <li>batch: new BatchProcessor for SQS, DynamoDB, Kinesis (#886)</li> <li>logger: allow handler with custom kwargs signature (#913)</li> <li>tracer: add service annotation when service is set (#861)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_107",
            "title": "Maintenance",
            "text": "<ul> <li>correct pr label order</li> <li>minor housekeeping before release (#912)</li> <li>bump to 1.23.0</li> <li>ci: split latest docs workflow</li> <li>deps: bump fastjsonschema from 2.15.1 to 2.15.2 (#891)</li> <li>deps: bump actions/setup-python from 2.2.2 to 2.3.0 (#831)</li> <li>deps: bump aws-xray-sdk from 2.8.0 to 2.9.0 (#876)</li> <li>deps: support arm64 when developing locally (#862)</li> <li>deps: bump actions/setup-python from 2.3.0 to 2.3.1 (#852)</li> <li>deps-dev: bump flake8 from 3.9.2 to 4.0.1 (#789)</li> <li>deps-dev: bump black from 21.10b0 to 21.11b1 (#839)</li> <li>deps-dev: bump black from 21.11b1 to 21.12b0 (#872)</li> <li>deps-dev: bump mypy from 0.910 to 0.920 (#903)</li> </ul>"
        },
        {
            "location": "changelog/#v1220-2021-11-17",
            "title": "v1.22.0 - 2021-11-17",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_104",
            "title": "Bug Fixes",
            "text": "<ul> <li>change supported python version from 3.6.1 to 3.6.2, bump black (#807)</li> <li>ci: comment custom publish version checker</li> <li>ci: skip sync master on docs hotfix</li> <li>parser: body/QS can be null or omitted in apigw v1/v2 (#820)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_22",
            "title": "Code Refactoring",
            "text": "<ul> <li>apigateway: Add BaseRouter and duplicate route check (#757)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_82",
            "title": "Documentation",
            "text": "<ul> <li>updated Lambda Layers definition &amp; limitations. (#775)</li> <li>Idiomatic tenet updated to Progressive</li> <li>use higher contrast font (#822)</li> <li>use higher contrast font</li> <li>fix indentation of SAM snippets in install section (#778)</li> <li>improve public lambda layer wording, clipboard buttons (#762)</li> <li>add amplify-cli instructions for public layer (#754)</li> <li>api-gateway: add support for new router feature (#767)</li> <li>apigateway: re-add sample layout, add considerations (#826)</li> <li>appsync: add new router feature (#821)</li> <li>idempotency: add support for DynamoDB composite keys (#808)</li> <li>tenets: update Idiomatic tenet to Progressive (#823)</li> </ul>"
        },
        {
            "location": "changelog/#features_70",
            "title": "Features",
            "text": "<ul> <li>apigateway: add Router to allow large routing composition (#645)</li> <li>appsync: add Router to allow large resolver composition (#776)</li> <li>data-classes: ActiveMQ and RabbitMQ support (#770)</li> <li>logger: add ALB correlation ID support (#816)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_108",
            "title": "Maintenance",
            "text": "<ul> <li>fix var expr</li> <li>remove Lambda Layer version tag</li> <li>bump to 1.22.0</li> <li>conditional to publish docs only attempt 3</li> <li>conditional to publish docs only attempt 2</li> <li>conditional to publish docs only</li> <li>deps: bump boto3 from 1.18.58 to 1.18.59 (#760)</li> <li>deps: bump boto3 from 1.18.56 to 1.18.58 (#755)</li> <li>deps: bump urllib3 from 1.26.4 to 1.26.5 (#787)</li> <li>deps: bump boto3 from 1.19.6 to 1.20.3 (#809)</li> <li>deps: bump boto3 from 1.18.61 to 1.19.6 (#783)</li> <li>deps: bump boto3 from 1.20.3 to 1.20.5 (#817)</li> <li>deps: bump boto3 from 1.18.59 to 1.18.61 (#766)</li> <li>deps-dev: bump coverage from 6.0.1 to 6.0.2 (#764)</li> <li>deps-dev: bump pytest-asyncio from 0.15.1 to 0.16.0 (#782)</li> <li>deps-dev: bump flake8-eradicate from 1.1.0 to 1.2.0 (#784)</li> <li>deps-dev: bump flake8-isort from 4.0.0 to 4.1.1 (#785)</li> <li>deps-dev: bump mkdocs-material from 7.3.2 to 7.3.3 (#758)</li> <li>deps-dev: bump flake8-comprehensions from 3.6.1 to 3.7.0 (#759)</li> <li>deps-dev: bump mkdocs-material from 7.3.3 to 7.3.5 (#781)</li> <li>deps-dev: bump coverage from 6.0 to 6.0.1 (#751)</li> <li>deps-dev: bump mkdocs-material from 7.3.5 to 7.3.6 (#791)</li> <li>deps-dev: bump coverage from 6.0.2 to 6.1.2 (#810)</li> <li>deps-dev: bump isort from 5.9.3 to 5.10.1 (#811)</li> </ul>"
        },
        {
            "location": "changelog/#v1211-2021-10-07",
            "title": "v1.21.1 - 2021-10-07",
            "text": ""
        },
        {
            "location": "changelog/#documentation_83",
            "title": "Documentation",
            "text": "<ul> <li>add new public layer ARNs (#746)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_109",
            "title": "Maintenance",
            "text": "<ul> <li>include public layers changelog</li> <li>bump to 1.21.1</li> <li>include regression in changelog</li> <li>ignore constants in test cov (#745)</li> <li>ignore constants in tests cov</li> <li>add support for publishing fallback</li> <li>deps: bump boto3 from 1.18.54 to 1.18.56 (#742)</li> <li>deps-dev: bump mkdocs-material from 7.3.1 to 7.3.2 (#741)</li> </ul>"
        },
        {
            "location": "changelog/#regression_4",
            "title": "Regression",
            "text": "<ul> <li>metrics: typing regression on log_metrics callable (#744)</li> </ul>"
        },
        {
            "location": "changelog/#v1210-2021-10-05",
            "title": "v1.21.0 - 2021-10-05",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_105",
            "title": "Bug Fixes",
            "text": "<ul> <li>data-classes: use correct asdict funciton (#666)</li> <li>feature-flags: rules should evaluate with an AND op (#724)</li> <li>idempotency: sorting keys before hashing (#722)</li> <li>idempotency: sorting keys before hashing</li> <li>logger: push extra keys to the end (#722)</li> <li>mypy: a few return types, type signatures, and untyped areas (#718)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_23",
            "title": "Code Refactoring",
            "text": "<ul> <li>data-classes: clean up internal logic for APIGatewayAuthorizerResponse (#643)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_84",
            "title": "Documentation",
            "text": "<ul> <li>Terraform reference for SAR Lambda Layer (#716)</li> <li>add team behind it and email</li> <li>event-handler: document catch-all routes (#705)</li> <li>idempotency: fix misleading idempotent examples (#661)</li> <li>jmespath: clarify envelope terminology</li> <li>parser: fix incorrect import in root_validator example (#735)</li> </ul>"
        },
        {
            "location": "changelog/#features_71",
            "title": "Features",
            "text": "<ul> <li>expose jmespath powertools functions (#736)</li> <li>add get_raw_configuration property in store; expose store</li> <li>boto3 sessions in batch, parameters &amp; idempotency (#717)</li> <li>feature-flags: Bring your own logger for debug (#709)</li> <li>feature-flags: improve \"IN/NOT_IN\"; new rule actions (#710)</li> <li>feature-flags: get_raw_configuration property in Store (#720)</li> <li>feature_flags: Added inequality conditions (#721)</li> <li>idempotency: makes customers unit testing easier (#719)</li> <li>validator: include missing data elements from a validation error (#686)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_110",
            "title": "Maintenance",
            "text": "<ul> <li>add python 3.9 support</li> <li>bump to 1.21.0</li> <li>deps: bump boto3 from 1.18.41 to 1.18.49 (#703)</li> <li>deps: bump boto3 from 1.18.32 to 1.18.38 (#671)</li> <li>deps: bump boto3 from 1.18.38 to 1.18.41 (#677)</li> <li>deps: bump boto3 from 1.18.51 to 1.18.54 (#733)</li> <li>deps: bump boto3 from 1.18.49 to 1.18.51 (#713)</li> <li>deps: bump codecov/codecov-action from 2.0.2 to 2.1.0 (#675)</li> <li>deps-dev: bump flake8-bugbear from 21.9.1 to 21.9.2 (#712)</li> <li>deps-dev: bump mkdocs-material from 7.3.0 to 7.3.1 (#731)</li> <li>deps-dev: bump mkdocs-material from 7.2.8 to 7.3.0 (#695)</li> <li>deps-dev: bump mkdocs-material from 7.2.6 to 7.2.8 (#682)</li> <li>deps-dev: bump flake8-bugbear from 21.4.3 to 21.9.1 (#676)</li> <li>deps-dev: bump coverage from 5.5 to 6.0 (#732)</li> <li>deps-dev: bump radon from 4.5.2 to 5.1.0 (#673)</li> <li>deps-dev: bump pytest-cov from 2.12.1 to 3.0.0 (#730)</li> <li>deps-dev: bump xenon from 0.7.3 to 0.8.0 (#669)</li> </ul>"
        },
        {
            "location": "changelog/#v1202-2021-09-02",
            "title": "v1.20.2 - 2021-09-02",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_106",
            "title": "Bug Fixes",
            "text": "<ul> <li>Fix issue with strip_prefixes (#647)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_111",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.20.2</li> <li>deps: bump boto3 from 1.18.26 to 1.18.32 (#663)</li> <li>deps-dev: bump mkdocs-material from 7.2.4 to 7.2.6 (#665)</li> <li>deps-dev: bump pytest from 6.2.4 to 6.2.5 (#662)</li> <li>license: Add THIRD-PARTY-LICENSES (#641)</li> </ul>"
        },
        {
            "location": "changelog/#v1201-2021-08-22",
            "title": "v1.20.1 - 2021-08-22",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_107",
            "title": "Bug Fixes",
            "text": "<ul> <li>idempotency: sorting keys before hashing (#639)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_112",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.20.1</li> <li>markdown linter fixes (#636)</li> <li>setup codespaces (#637)</li> <li>license: add third party license (#635)</li> </ul>"
        },
        {
            "location": "changelog/#v1200-2021-08-21",
            "title": "v1.20.0 - 2021-08-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_108",
            "title": "Bug Fixes",
            "text": "<ul> <li>api-gateway: HTTP API strip stage name from request path (#622)</li> <li>docs: correct feature_flags link and json exmaples (#605)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_24",
            "title": "Code Refactoring",
            "text": "<ul> <li>event_handler: match to match_results; 3.10 new keyword (#616)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_85",
            "title": "Documentation",
            "text": "<ul> <li>api-gateway: add new API mapping support</li> <li>data-class: fix invalid syntax in new AppSync Authorizer</li> <li>data-classes: make authorizer concise; use enum (#630)</li> </ul>"
        },
        {
            "location": "changelog/#features_72",
            "title": "Features",
            "text": "<ul> <li>data-classes: authorizer for http api and rest api (#620)</li> <li>data-classes: data_as_bytes prop KinesisStreamRecordPayload (#628)</li> <li>data-classes: AppSync Lambda authorizer event (#610)</li> <li>event-handler: prefixes to strip for custom mappings (#579)</li> <li>general: support for Python 3.9 (#626)</li> <li>idempotency: support for any synchronous function (#625)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_113",
            "title": "Maintenance",
            "text": "<ul> <li>update changelog to reflect out-of-band commits</li> <li>bump to 1.20.0</li> <li>update new changelog version tag</li> <li>actions: include new labels</li> <li>api-docs: enable allow_reuse to fix the docs (#612)</li> <li>deps: bump boto3 from 1.18.25 to 1.18.26 (#627)</li> <li>deps: bump boto3 from 1.18.24 to 1.18.25 (#623)</li> <li>deps: bump boto3 from 1.18.22 to 1.18.24 (#619)</li> <li>deps: bump boto3 from 1.18.21 to 1.18.22 (#614)</li> <li>deps: bump boto3 from 1.18.17 to 1.18.21 (#608)</li> <li>deps-dev: bump flake8-comprehensions from 3.6.0 to 3.6.1 (#615)</li> <li>deps-dev: bump flake8-comprehensions from 3.5.0 to 3.6.0 (#609)</li> <li>deps-dev: bump mkdocs-material from 7.2.3 to 7.2.4 (#607)</li> <li>docs: correct markdown based on markdown lint (#603)</li> <li>shared: fix cyclic import &amp; refactor data extraction fn (#613)</li> </ul>"
        },
        {
            "location": "changelog/#v1190-2021-08-11",
            "title": "v1.19.0 - 2021-08-11",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_109",
            "title": "Bug Fixes",
            "text": "<ul> <li>deps: bump poetry to latest (#592)</li> <li>feature-flags:  bug handling multiple conditions (#599)</li> <li>feature-toggles: correct cdk example (#601)</li> <li>parser: apigw wss validation check_message_id; housekeeping (#553)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_25",
            "title": "Code Refactoring",
            "text": "<ul> <li>feature-flags: add debug for all features evaluation\" (#590)</li> <li>feature_flags: optimize UX and maintenance (#563)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_86",
            "title": "Documentation",
            "text": "<ul> <li>event-handler: new custom serializer option</li> <li>feature-flags: add guidance when to use vs env vars vs parameters</li> <li>feature-flags: fix sample feature name in evaluate</li> <li>feature-flags: create concrete documentation (#594)</li> <li>feature-toggles: correct docs and typing (#588)</li> <li>feature_flags: fix SAM infra, convert CDK to Python</li> <li>parameters: auto-transforming values based on suffix (#573)</li> <li>readme: add code coverage badge (#577)</li> <li>tracer: update wording that it auto-disables on non-Lambda env</li> </ul>"
        },
        {
            "location": "changelog/#features_73",
            "title": "Features",
            "text": "<ul> <li>api-gateway: add support for custom serializer (#568)</li> <li>data-classes: decode json_body if based64 encoded (#560)</li> <li>feature flags: Add not_in action and rename contains to in (#589)</li> <li>params: expose high level max_age, raise_on_transform_error (#567)</li> <li>tracer: disable tracer when for non-Lambda envs (#598)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_114",
            "title": "Maintenance",
            "text": "<ul> <li>only build docs on docs path</li> <li>update pypi description, keywords</li> <li>bump to 1.19.0</li> <li>enable autolabel based on PR title</li> <li>include feature-flags docs hotfix</li> <li>deps: bump boto3 from 1.18.15 to 1.18.17 (#597)</li> <li>deps: bump boto3 from 1.18.1 to 1.18.15 (#591)</li> <li>deps: bump codecov/codecov-action from 2.0.1 to 2.0.2 (#558)</li> <li>deps-dev: bump mkdocs-material from 7.2.1 to 7.2.2 (#582)</li> <li>deps-dev: bump mkdocs-material from 7.2.2 to 7.2.3 (#596)</li> <li>deps-dev: bump pdoc3 from 0.9.2 to 0.10.0 (#584)</li> <li>deps-dev: bump isort from 5.9.2 to 5.9.3 (#574)</li> <li>deps-dev: bump mkdocs-material from 7.2.0 to 7.2.1 (#566)</li> <li>deps-dev: bump mkdocs-material from 7.1.11 to 7.2.0 (#551)</li> <li>deps-dev: bump flake8-black from 0.2.1 to 0.2.3 (#541)</li> </ul>"
        },
        {
            "location": "changelog/#v1181-2021-07-23",
            "title": "v1.18.1 - 2021-07-23",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_110",
            "title": "Bug Fixes",
            "text": "<ul> <li>api-gateway: route regression non-word and unsafe URI chars (#556)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_115",
            "title": "Maintenance",
            "text": "<ul> <li>bump 1.18.1</li> </ul>"
        },
        {
            "location": "changelog/#v1180-2021-07-20",
            "title": "v1.18.0 - 2021-07-20",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_111",
            "title": "Bug Fixes",
            "text": "<ul> <li>api-gateway: non-greedy route pattern regex (#533)</li> <li>api-gateway: incorrect plain text mimetype #506</li> <li>data-classes: include milliseconds in scalar types (#504)</li> <li>mypy: fixes to resolve no implicit optional errors (#521)</li> <li>parser: Make ApiGateway version, authorizer fields optional (#532)</li> <li>tracer: mypy generic to preserve decorated method signature (#529)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_26",
            "title": "Code Refactoring",
            "text": "<ul> <li>feature-toggles: Code coverage and housekeeping (#530)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_87",
            "title": "Documentation",
            "text": "<ul> <li>api-gateway: document new HTTP service error exceptions (#546)</li> <li>logger: document new get_correlation_id method (#545)</li> </ul>"
        },
        {
            "location": "changelog/#features_74",
            "title": "Features",
            "text": "<ul> <li>api-gateway: add debug mode (#507)</li> <li>api-gateway: add common service errors (#506)</li> <li>event-handler: Support AppSyncResolverEvent subclassing (#526)</li> <li>feat-toggle: New simple feature toggles rule engine (WIP) (#494)</li> <li>logger: add get_correlation_id method (#516)</li> <li>mypy: add mypy support to makefile (#508)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_116",
            "title": "Maintenance",
            "text": "<ul> <li>bump 1.18.0 (#547)</li> <li>deps: bump codecov/codecov-action from 1 to 2.0.1 (#539)</li> <li>deps: bump boto3 from 1.18.0 to 1.18.1 (#528)</li> <li>deps: bump boto3 from 1.17.110 to 1.18.0 (#527)</li> <li>deps: bump boto3 from 1.17.102 to 1.17.110 (#523)</li> <li>deps-dev: bump mkdocs-material from 7.1.10 to 7.1.11 (#542)</li> <li>deps-dev: bump mkdocs-material from 7.1.9 to 7.1.10 (#522)</li> <li>deps-dev: bump isort from 5.9.1 to 5.9.2 (#514)</li> <li>event-handler: adjusts exception docstrings to not confuse AppSync customers</li> </ul>"
        },
        {
            "location": "changelog/#v1171-2021-07-02",
            "title": "v1.17.1 - 2021-07-02",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_112",
            "title": "Bug Fixes",
            "text": "<ul> <li>validator: handle built-in custom formats correctly (#498)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_88",
            "title": "Documentation",
            "text": "<ul> <li>add Layers example for Serverless framework &amp; CDK (#500)</li> <li>enable dark mode switch (#471)</li> <li>logger: add FAQ for cross-account searches (#501)</li> <li>tracer: additional scenario when to disable auto-capture (#499)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_117",
            "title": "Maintenance",
            "text": "<ul> <li>bump 1.17.1 (#502)</li> <li>deps: bump boto3 from 1.17.101 to 1.17.102 (#493)</li> <li>deps: bump boto3 from 1.17.91 to 1.17.101 (#490)</li> <li>deps: bump email-validator from 1.1.2 to 1.1.3 (#478)</li> <li>deps: bump boto3 from 1.17.89 to 1.17.91 (#473)</li> <li>deps-dev: bump flake8-eradicate from 1.0.0 to 1.1.0 (#492)</li> <li>deps-dev: bump isort from 5.8.0 to 5.9.1 (#487)</li> <li>deps-dev: bump mkdocs-material from 7.1.7 to 7.1.9 (#491)</li> </ul>"
        },
        {
            "location": "changelog/#v1170-2021-06-08",
            "title": "v1.17.0 - 2021-06-08",
            "text": ""
        },
        {
            "location": "changelog/#documentation_89",
            "title": "Documentation",
            "text": "<ul> <li>include new public roadmap (#452)</li> <li>data_classes: fix missing dynamodb stream get_type/value</li> <li>idempotency: remove old todo</li> </ul>"
        },
        {
            "location": "changelog/#features_75",
            "title": "Features",
            "text": "<ul> <li>data-classes: add AttributeValueType to DynamoDBStreamEvent (#462)</li> <li>data-classes: decorator to instantiate data_classes and docs updates (#442)</li> <li>logger: add option to clear state per invocation (#467)</li> <li>parser: add support for API Gateway HTTP API #434 (#441)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_118",
            "title": "Maintenance",
            "text": "<ul> <li>bump xenon from 0.7.1 to 0.7.3 (#446)</li> <li>fix changelog file redirection</li> <li>include dependencies label under maintenance</li> <li>ignore codecov upload</li> <li>reintroduce codecov token</li> <li>fix path for PR auto-labelling</li> <li>assited changelog pre-generation, auto-label PR (#443)</li> <li>enable dependabot for dep upgrades (#444)</li> <li>enable mergify (#450)</li> <li>dependabot/mergify guardrail for major versions</li> <li>fix dependabot commit messages prefix</li> <li>fix dependabot unique set config</li> <li>bump mkdocs-material from 7.1.5 to 7.1.6 (#451)</li> <li>bump boto3 from 1.17.78 to 1.17.84 (#449)</li> <li>update mergify to require approval on dependabot (#456)</li> <li>bump actions/setup-python from 1 to 2.2.2 (#445)</li> <li>trial boring cyborg automation</li> <li>deps: bump boto3 from 1.17.87 to 1.17.88 (#463)</li> <li>deps: bump boto3 from 1.17.88 to 1.17.89 (#466)</li> <li>deps: bump boto3 from 1.17.84 to 1.17.85 (#455)</li> <li>deps: bump boto3 from 1.17.85 to 1.17.86 (#458)</li> <li>deps: bump boto3 from 1.17.86 to 1.17.87 (#459)</li> <li>deps-dev: bump mkdocs-material from 7.1.6 to 7.1.7 (#464)</li> <li>deps-dev: bump pytest-cov from 2.12.0 to 2.12.1 (#454)</li> <li>mergify: use job name to match GH Actions</li> <li>mergify: disable check for matrix jobs</li> </ul>"
        },
        {
            "location": "changelog/#v1161-2021-05-23",
            "title": "v1.16.1 - 2021-05-23",
            "text": ""
        },
        {
            "location": "changelog/#features_76",
            "title": "Features",
            "text": "<ul> <li>parser: security issue in Pydantic #436 (#437)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_119",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.16.1</li> </ul>"
        },
        {
            "location": "changelog/#v1160-2021-05-17",
            "title": "v1.16.0 - 2021-05-17",
            "text": ""
        },
        {
            "location": "changelog/#features_77",
            "title": "Features",
            "text": "<ul> <li>data-classes: decode base64 encoded body (#425)</li> <li>data-classes: support for code pipeline job event (#416)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_120",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.16.0</li> </ul>"
        },
        {
            "location": "changelog/#v1151-2021-05-13",
            "title": "v1.15.1 - 2021-05-13",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_113",
            "title": "Bug Fixes",
            "text": "<ul> <li>docs: Use updated names for ProxyEventType (#424)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_90",
            "title": "Documentation",
            "text": "<ul> <li>update list of features</li> <li>event_handler: add missing note on trimmed responses</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_121",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.15.1</li> </ul>"
        },
        {
            "location": "changelog/#v1150-2021-05-06",
            "title": "v1.15.0 - 2021-05-06",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_114",
            "title": "Bug Fixes",
            "text": "<ul> <li>deps: Bump aws-xray-sdk from 2.6.0 to 2.8.0 (#413)</li> <li>docs: workflow to include api ref in latest alias (#408)</li> <li>parser: Improve types for parser.py (#419)</li> <li>validator: event type annotation as any in validate fn (#405)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_27",
            "title": "Code Refactoring",
            "text": "<ul> <li>simplify custom formatter for minor changes (#417)</li> <li>event-handler: api gateway handler review changes (#420)</li> <li>event-handler: Add ResponseBuilder and more docs (#412)</li> <li>logger: BYOFormatter and Handler, UTC support, and more (#404)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_91",
            "title": "Documentation",
            "text": "<ul> <li>api_gateway: new event handler for API Gateway and ALB (#418)</li> <li>event_handler: fix closing brackets in CORS sample</li> <li>event_handler: remove beta flag from new HTTP utility</li> <li>idempotency: remove beta flag</li> <li>logger: improvements extensibility &amp; new features (#415)</li> <li>parser: fix table and heading syntax</li> <li>tracer: Fix line highlighting (#395)</li> </ul>"
        },
        {
            "location": "changelog/#features_78",
            "title": "Features",
            "text": "<ul> <li>add support to persist default dimensions (#410)</li> <li>event-handle: allow for cors=None setting (#421)</li> <li>event-handler: add http ProxyEvent handler (#369)</li> <li>parser: Support for API GW v1 proxy schema &amp; envelope (#403)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_122",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.15.0 (#422)</li> </ul>"
        },
        {
            "location": "changelog/#v1140-2021-04-09",
            "title": "v1.14.0 - 2021-04-09",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_115",
            "title": "Bug Fixes",
            "text": "<ul> <li>perf tests for Logger and fail str msgs</li> <li>downgrade poetry to 1.1.4 (#385)</li> <li>lock X-Ray SDK to 2.6.0 (#384)</li> <li>data-classes: Add missing operationName (#373)</li> <li>idempotent: Correctly raise IdempotencyKeyError (#378)</li> <li>metrics: AttributeError raised by MediaManager and Typing and docs (#357)</li> <li>parser: S3Model support empty keys (#375)</li> <li>tracer: Correct type hint for MyPy (#365)</li> <li>workflow: github actions depends on for release</li> </ul>"
        },
        {
            "location": "changelog/#documentation_92",
            "title": "Documentation",
            "text": "<ul> <li>Fix doc links and line highlights (#380)</li> <li>fix extra key for versioning</li> <li>update mkdocs-material to 7.1.0</li> <li>Correct link targets and line highlights (#390)</li> <li>introduce event handlers utility section (#388)</li> <li>enable versioning feature (#374)</li> <li>idempotency: add default configuration for those not using CFN (#391)</li> <li>index: fix link to event handler</li> <li>logger: add example on how to set UTC timestamp (#392)</li> <li>validator: include more complete examples &amp; intro to JSON Schema (#389)</li> </ul>"
        },
        {
            "location": "changelog/#features_79",
            "title": "Features",
            "text": "<ul> <li>event-handler: Add AppSync handler decorator (#363)</li> <li>parameter: add dynamodb_endpoint_url for local_testing (#376)</li> <li>parser: Add S3 Object Lambda Event (#362)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_123",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.14.0</li> <li>add approved by field in RFC template</li> <li>make RFC proposal more explicit</li> <li>update automated steps in release process</li> </ul>"
        },
        {
            "location": "changelog/#v1130-2021-03-23",
            "title": "v1.13.0 - 2021-03-23",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_116",
            "title": "Bug Fixes",
            "text": "<ul> <li>deps: Bump dependencies and fix some of the dev tooling (#354)</li> <li>lint: Move <code>tests/THIRD-PARTY-LICENSES</code> to root (#352)</li> </ul>"
        },
        {
            "location": "changelog/#features_80",
            "title": "Features",
            "text": "<ul> <li>data-classes: Add S3 Object Lambda Event (#353)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_124",
            "title": "Maintenance",
            "text": "<ul> <li>include internals in release template</li> <li>bump to 1.13.0</li> <li>correct 3rd party license</li> </ul>"
        },
        {
            "location": "changelog/#v1120-2021-03-17",
            "title": "v1.12.0 - 2021-03-17",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_117",
            "title": "Bug Fixes",
            "text": "<ul> <li>idempotency: TypeError when calling is_missing_idempotency_key with an int (#315)</li> <li>idempotency: Correctly handle save_inprogress errors (#313)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_28",
            "title": "Code Refactoring",
            "text": "<ul> <li>parameters: Consistently reference env (#319)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_93",
            "title": "Documentation",
            "text": "<ul> <li>surface new 1.12.0 features and enhancements  (#344)</li> <li>Correct code examples (#317)</li> <li>data-classes: Add more cognito code examples (#340)</li> <li>idempotency: Correct examples and line highlights (#312)</li> <li>metrics: Corrections to the code examples (#314)</li> <li>metrics: remove minimum dimensions</li> <li>metrics: Correct code examples in markdown (#316)</li> <li>tracer: Fix Tracer typing hinting for Pycharm (#345)</li> </ul>"
        },
        {
            "location": "changelog/#features_81",
            "title": "Features",
            "text": "<ul> <li>data-classes: Add appsync scalar_types_utils (#339)</li> <li>data-classes: AppSync Resolver Event (#323)</li> <li>idempotent: Include function name in the idempotent key (#326)</li> <li>logging: Add correlation_id support (#321)</li> <li>logging: Include exception_name (#320)</li> <li>parameters: Add force_fetch option (#341)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_125",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.12.0</li> <li>remove auto-label as restrictions prevent it from working</li> <li>increase perf SLA due to slow GitHub Actions machine</li> <li>add PR size labelling action # 2</li> <li>add PR size labelling action</li> <li>add PR auto-label action</li> <li>remove gatsby mention as migrated completed</li> </ul>"
        },
        {
            "location": "changelog/#v1110-2021-03-05",
            "title": "v1.11.0 - 2021-03-05",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_118",
            "title": "Bug Fixes",
            "text": "<ul> <li>import time latency by lazily loading high level modules (#301)</li> <li>correct behaviour to avoid caching \"INPROGRESS\" records (#295)</li> <li>idempotency: PR feedback on config and kwargs</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_29",
            "title": "Code Refactoring",
            "text": "<ul> <li>idempotent: Change UX to use a config class for non-persistence related features (#306)</li> <li>metrics: optimize validation and serialization (#307)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_94",
            "title": "Documentation",
            "text": "<ul> <li>batch: add example on how to integrate with sentry.io (#308)</li> <li>data-classes: Correct import for DynamoDBRecordEventName (#299)</li> <li>dataclasses: new Connect Contact Flow (#310)</li> <li>idempotency: tidy up doc before release (#309)</li> <li>idempotent: Fix typos and code formatting (#305)</li> </ul>"
        },
        {
            "location": "changelog/#features_82",
            "title": "Features",
            "text": "<ul> <li>Idempotency helper utility (#245)</li> <li>data-classes: Add connect contact flow event (#304)</li> <li>idempotency: Add raise_on_no_idempotency_key flag (#297)</li> <li>idempotency: Fix KeyError when local_cache is True and an error is raised in the lambda handler (#300)</li> <li>idempotent: Add support for jmespath_options (#302)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_126",
            "title": "Maintenance",
            "text": "<ul> <li>update changelog (#311)</li> <li>adjusts Metrics SLA for slow py36 interpreters</li> <li>remove unsuccessful labeler bot</li> <li>update labeler bot to sync upon PR changes</li> <li>attempt 1 to fix PR labeler</li> </ul>"
        },
        {
            "location": "changelog/#v1105-2021-02-17",
            "title": "v1.10.5 - 2021-02-17",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_127",
            "title": "Maintenance",
            "text": "<ul> <li>version bump to 1.10.5 (#292)</li> </ul>"
        },
        {
            "location": "changelog/#v1104-2021-02-17",
            "title": "v1.10.4 - 2021-02-17",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_119",
            "title": "Bug Fixes",
            "text": "<ul> <li>sync features in main page</li> <li>meta tags, and ext link to open in new tab</li> </ul>"
        },
        {
            "location": "changelog/#documentation_95",
            "title": "Documentation",
            "text": "<ul> <li>data-classes: Fix anchor tags to be lower case (#288)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_128",
            "title": "Maintenance",
            "text": "<ul> <li>version bump to 1.10.4 (#291)</li> <li>add default runtime key</li> <li>Correct the docs location (#289)</li> <li>enable PR labeler workflow</li> <li>add auto-label for known files</li> </ul>"
        },
        {
            "location": "changelog/#regression_5",
            "title": "Regression",
            "text": "<ul> <li>search input size</li> </ul>"
        },
        {
            "location": "changelog/#v1103-2021-02-12",
            "title": "v1.10.3 - 2021-02-12",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_120",
            "title": "Bug Fixes",
            "text": "<ul> <li>sfix typing hit for envelope parse model (#286)</li> <li>disable batching of X-Ray subsegments (#284)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_96",
            "title": "Documentation",
            "text": "<ul> <li>migrate documentation from Gatsby to MkDocs material (#279)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_129",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.10.3 (#287)</li> </ul>"
        },
        {
            "location": "changelog/#v1102-2021-02-04",
            "title": "v1.10.2 - 2021-02-04",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_121",
            "title": "Bug Fixes",
            "text": "<ul> <li>remove unnecessary typing-extensions for py3.8 (#281)</li> <li>batch processing exceptions (#276)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_97",
            "title": "Documentation",
            "text": "<ul> <li>appconfig: Use correct import for docstring (#271)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_130",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.10.2 (#282)</li> <li>fix immer and socket.io CVEs (#278)</li> <li>typo in parser docs</li> </ul>"
        },
        {
            "location": "changelog/#v1101-2021-01-19",
            "title": "v1.10.1 - 2021-01-19",
            "text": ""
        },
        {
            "location": "changelog/#features_83",
            "title": "Features",
            "text": "<ul> <li>add support for SNS-&gt;SQS protocol (#272)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_131",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.10.1 (#273)</li> </ul>"
        },
        {
            "location": "changelog/#v1100-2021-01-18",
            "title": "v1.10.0 - 2021-01-18",
            "text": ""
        },
        {
            "location": "changelog/#documentation_98",
            "title": "Documentation",
            "text": "<ul> <li>fix import (#267)</li> <li>add info about extras layer (#260)</li> <li>fix note whitespace</li> <li>add missing parser models (#254)</li> </ul>"
        },
        {
            "location": "changelog/#features_84",
            "title": "Features",
            "text": "<ul> <li>toggle to disable log deduplication locally for pytest live log #262 (#268)</li> <li>Add AppConfig parameter provider (#236)</li> <li>support extra parameter in Logger messages (#257)</li> <li>support custom formats in JSON Schema validation (#247)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_132",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.10.0 (#270)</li> <li>move env names to constant file (#264)</li> <li>update stale bot</li> <li>general simplifications and cleanup (#255)</li> <li>hardcode axios transitive resolution (#256)</li> </ul>"
        },
        {
            "location": "changelog/#v191-2020-12-21",
            "title": "v1.9.1 - 2020-12-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_122",
            "title": "Bug Fixes",
            "text": "<ul> <li>ensures all Loggers have unique service names</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_30",
            "title": "Code Refactoring",
            "text": "<ul> <li>convert dict into a literal dict object and re-use it</li> </ul>"
        },
        {
            "location": "changelog/#documentation_99",
            "title": "Documentation",
            "text": "<ul> <li>add clarification to Tracer docs for how <code>capture_method</code> decorator can cause function responses to be read and serialized.</li> </ul>"
        },
        {
            "location": "changelog/#features_85",
            "title": "Features",
            "text": "<ul> <li>pep-561: Create py.typed file and include into pyproject.</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_133",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.9.1 (#252)</li> <li>add changelog</li> <li>implement phony targets correctly</li> <li>deps: bump ini from 1.3.5 to 1.3.8 in /docs</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_4",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #250 from heitorlessa/fix/#249</li> <li>Merge pull request #235 from Nr18/phony</li> <li>Merge pull request #244 from awslabs/docs/capture_method_clarification</li> <li>Merge pull request #241 from awslabs/dependabot/npm_and_yarn/docs/ini-1.3.8</li> <li>Merge pull request #237 from gmcrocetti/pep-561</li> <li>Merge pull request #234 from Nr18/test-equal</li> <li>Merge pull request #233 from GroovyDan/improv/add_equality_check_to_dict_wrapper</li> <li>Merge pull request #232 from gyft/add-missing-tests</li> </ul>"
        },
        {
            "location": "changelog/#v190-2020-12-04",
            "title": "v1.9.0 - 2020-12-04",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_123",
            "title": "Bug Fixes",
            "text": "<ul> <li>s3 model import</li> <li>cloudwatch logs envelope typo</li> </ul>"
        },
        {
            "location": "changelog/#documentation_100",
            "title": "Documentation",
            "text": "<ul> <li>add Kinesis Streams as a supported model &amp; envelope</li> <li>add S3 as a supported model</li> <li>add CW Logs as a supported envelope</li> <li>add CW Logs as a supported model</li> <li>add Alb as a supported model</li> <li>shadow sidebar to remain expanded</li> <li>add source code link in nav bar</li> <li>fix broken link for github</li> </ul>"
        },
        {
            "location": "changelog/#features_86",
            "title": "Features",
            "text": "<ul> <li>Add Kinesis lambda event support to Parser utility</li> <li>Add cloudwatch lambda event support to Parser utility</li> <li>Add alb lambda event support to Parser utility #228</li> <li>Add Kinesis lambda event support to Parser utility</li> <li>Add S3 lambda event support to Parser utility #224</li> <li>Add Ses lambda event support to Parser utility #213</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_134",
            "title": "Maintenance",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_5",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #227 from risenberg-cyberark/kinesis</li> <li>Merge pull request #225 from risenberg-cyberark/s3</li> <li>Merge pull request #231 from risenberg-cyberark/cloudwatch</li> <li>Merge pull request #229 from risenberg-cyberark/alb</li> <li>Merge pull request #223 from heitorlessa/docs/add-source-code-link</li> <li>Merge pull request #222 from awslabs/docs-fix-broken-link</li> <li>Merge pull request #219 from igorlg/docs/logger-supress-clarify</li> <li>Merge pull request #214 from risenberg-cyberark/ses</li> </ul>"
        },
        {
            "location": "changelog/#v180-2020-11-20",
            "title": "v1.8.0 - 2020-11-20",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_124",
            "title": "Bug Fixes",
            "text": "<ul> <li>replace now deprecated set-env with new GitHub Env file</li> <li>remove dummy heading to prevent htmlAst bug</li> </ul>"
        },
        {
            "location": "changelog/#documentation_101",
            "title": "Documentation",
            "text": "<ul> <li>correct example usage of SES data class</li> <li>add faq section</li> <li>add minimal permission set for using layer</li> </ul>"
        },
        {
            "location": "changelog/#features_87",
            "title": "Features",
            "text": "<ul> <li>include new replay-name field in parser and data_classes</li> <li>data_classes: API Gateway V2 IAM and Lambda</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_135",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.8.0</li> <li>bump dependencies</li> <li>docs: Add some of the missing docstrings</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_6",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #212 from heitorlessa/chore/bump-1.8.0</li> <li>Merge pull request #211 from heitorlessa/feat/eventbridge-replay-support</li> <li>Merge pull request #209 from awslabs/docs/correct_ses_dataclass_example</li> <li>Merge pull request #207 from risenberg-cyberark/sns</li> <li>Merge pull request #205 from heitorlessa/chore/update-docs-dep</li> <li>Merge pull request #202 from Nr18/logger-faq</li> <li>Merge pull request #204 from am29d/docs/add-iam-permissions-for-layer</li> <li>Merge pull request #201 from gyft/feat-data-classes-event-updates</li> </ul>"
        },
        {
            "location": "changelog/#v170-2020-10-26",
            "title": "v1.7.0 - 2020-10-26",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_125",
            "title": "Bug Fixes",
            "text": "<ul> <li>_parse return type</li> <li>high and security peer dependency vulnerabilities</li> <li>change to Yarn to support manual resolutions</li> <li>generic type to match ABC bound class</li> <li>debug logging in envelopes before each parsing</li> <li>remove malformed 3.1. sentence</li> <li>ensures parser can take json strings as input</li> <li>parse high level import</li> <li>code inspect issues</li> <li>unnecessary return; better error handling</li> <li>snake_case</li> <li>comment out validators #118</li> <li>CR fixes Merge branch 'develop' of https://github.com/awslabs/aws-lambda-powertools-python into pydantic</li> <li>reduce complexity of dynamo envelope</li> <li>poetry update + pydantic, typing_extensions as optional</li> <li>add only pydantic (+1 squashed commit) Squashed commits: [804f251] fix poetry.lock, revert changes</li> <li>Correct typo</li> <li>remove only dev extras</li> <li>remove jmespath extras in Make</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_31",
            "title": "Code Refactoring",
            "text": "<ul> <li>pydantic as optional dependancy, remove lambdaContext</li> <li>change to advanced parser</li> </ul>"
        },
        {
            "location": "changelog/#documentation_102",
            "title": "Documentation",
            "text": "<ul> <li>reorder parser's payload sample position</li> <li>add more info on conditional keys #195</li> <li>add a note that decorator will replace the event</li> <li>address Ran's feedback</li> <li>reorder data validation; improve envelopes section</li> <li>reorder extending models as parse fn wasn't introduced</li> <li>use yarn's resolution to fix incompatible dependency</li> <li>add cold start data</li> <li>add a FAQ section</li> <li>ensure examples can be copied/pasted as-is</li> <li>add extending built-in models</li> <li>add envelope section</li> <li>add data model validation section</li> <li>use non-hello world model to better exemplify parsing</li> <li>add 101 parsing events content</li> <li>initial structure for parser docs</li> <li>initial sketch of parser docs</li> <li>update examples in README</li> </ul>"
        },
        {
            "location": "changelog/#features_88",
            "title": "Features",
            "text": "<ul> <li>experiment with codeQL over LGTM</li> <li>add standalone parse function</li> <li>Advanced parser utility (pydantic)</li> <li>RFC: Validate incoming and outgoing events utility #95</li> <li>data_classes: case insensitive header lookup</li> <li>data_classes: Cognito custom auth triggers</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_136",
            "title": "Maintenance",
            "text": "<ul> <li>fix repository URL</li> <li>spacing</li> <li>typo in list</li> <li>typo on code generation tool</li> <li>remove flake8 polyfill as explicit dep</li> <li>explicit DynamoDB Stream schema naming</li> <li>lint</li> <li>kwarg over arg to ease refactoring</li> <li>remove test for commented code</li> <li>fix make build syntax for internal build whl</li> <li>upgrade docs dep</li> <li>remove dev deps from example project</li> <li>remove kitchen sink example</li> <li>upgrade gatsby</li> <li>upgrade amplify, antd, and gatsby plugins</li> <li>upgrade apollo-docs theme</li> <li>remove dev deps from example project</li> <li>remove kitchen sink example</li> </ul>"
        },
        {
            "location": "changelog/#reverts_3",
            "title": "Reverts",
            "text": "<ul> <li>fix: remove jmespath extras in Make</li> <li>fix: remove jmespath extras in Make</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_7",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #200 from heitorlessa/chore/bump-1.7.0</li> <li>Merge pull request #199 from heitorlessa/docs/clarify-dynamic-log-keys</li> <li>Merge pull request #198 from awslabs/improv/suppress-logger-propagation</li> <li>Merge pull request #192 from heitorlessa/docs/parser</li> <li>Merge pull request #196 from awslabs/dependabot/npm_and_yarn/docs/object-path-0.11.5</li> <li>Merge pull request #189 from heitorlessa/improv/parser#118</li> <li>Merge pull request #186 from gyft/feat-case-insensitive-dict</li> <li>Merge pull request #188 from gyft/tests-pydantic</li> <li>Merge pull request #178 from gyft/cognito-custom-auth</li> <li>Merge pull request #118 from risenberg-cyberark/pydantic</li> <li>Merge pull request #181 from awslabs/fix/docs-sec-vuln</li> <li>Merge pull request #180 from heitorlessa/chore/remove-example</li> </ul>"
        },
        {
            "location": "changelog/#v161-2020-09-23",
            "title": "v1.6.1 - 2020-09-23",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_137",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.6.1 (#177)</li> </ul>"
        },
        {
            "location": "changelog/#v160-2020-09-22",
            "title": "v1.6.0 - 2020-09-22",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_126",
            "title": "Bug Fixes",
            "text": "<ul> <li>apply Tom's suggestion</li> <li>branding</li> <li>Correct description for data classes util</li> <li>duplicate features content</li> <li>navigation, branding</li> <li>remove DeleteMessageBatch call to SQS api if there are no messages to delete (#170)</li> <li>correct type hint Dict instead of dict</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_32",
            "title": "Code Refactoring",
            "text": "<ul> <li>correct type hint</li> </ul>"
        },
        {
            "location": "changelog/#documentation_103",
            "title": "Documentation",
            "text": "<ul> <li>fixed more typos, correct index reference to new util</li> <li>fix typo in DynamoDB example</li> <li>add docs for data classes utility</li> <li>improve wording on jmespath fns</li> <li>document validator utility</li> </ul>"
        },
        {
            "location": "changelog/#features_89",
            "title": "Features",
            "text": "<ul> <li>add custom jmespath functions support</li> <li>emf multiple metric values (#167)</li> <li>add initial validator tests</li> <li>add cloudwatch_logs based on Bryan's feedback</li> <li>add powertools_base64 custom fn</li> <li>add built-in envelopes</li> <li>add jmespath as optional dependency</li> <li>add initial draft simple validator</li> <li>trigger: data class and helper functions for lambda trigger events (#159)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_138",
            "title": "Maintenance",
            "text": "<ul> <li>typo</li> <li>bump to 1.6.0</li> <li>better type hinting</li> <li>update changelog</li> <li>fix docstring; import order</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_8",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #175 from heitorlessa/chore/bump-1.6.0</li> <li>Merge pull request #171 from awslabs/docs/data_classes</li> <li>Merge pull request #174 from heitorlessa/improv/docs-logger-metrics-testing</li> <li>Merge pull request #168 from gyft/tests-missing</li> <li>Merge pull request #153 from heitorlessa/feat/validator-utility</li> </ul>"
        },
        {
            "location": "changelog/#v150-2020-09-04",
            "title": "v1.5.0 - 2020-09-04",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_127",
            "title": "Bug Fixes",
            "text": "<ul> <li>throw exception by default if messages processing fails</li> <li>add sqs_batch_processor as its own method</li> <li>ensure debug log event has latest ctx</li> <li>update image with correct sample</li> <li>ensures xray_trace_id is refreshed</li> <li>typo in example</li> <li>include proposed suggestions</li> <li>base-partial: append record instead of entry</li> <li>logging: Don't include <code>json_default</code> in logs (#132)</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_33",
            "title": "Code Refactoring",
            "text": "<ul> <li>changes partial_sqs middleware in favor of a generic interface always expecting a BatchProcessor</li> <li>replace LambdaEvent with Dict[str, Any]</li> <li>remove initial reference</li> <li>fix import issues and provide context in docblocks</li> <li>split properties and add docblocks</li> <li>split the objects into seperate files</li> <li>make requested changes</li> <li>use None instead of</li> <li>batch middleware</li> <li>remove references to BaseProcessor. Left BasePartialProcessor</li> <li>change return for failure/success handlers</li> <li>sqs: add module middlewares</li> <li>sqs: change methods to protected</li> <li>tests: update tests to new batch processor middleware</li> <li>tests: processor using default config</li> </ul>"
        },
        {
            "location": "changelog/#documentation_104",
            "title": "Documentation",
            "text": "<ul> <li>address readability feedbacks</li> <li>add detail to batch processing</li> <li>simplify documentation more SQS specific focus Update for sqs_batch_processor interface</li> <li>rephrase the wording to make it more clear</li> <li>refactor example; improve docs about creating your own processor</li> <li>add newly created Slack Channel</li> <li>describe the typing utility</li> <li>add troubleshooting section</li> <li>add xray_trace_id key</li> <li>fix suggestions made by @heitorlessa</li> <li>add description where to find the layer arn (#145)</li> <li>new section \"Migrating from other Loggers\" (#148)</li> <li>minor edit to letter case part 2</li> <li>user specific documentation</li> <li>Fix doc for log sampling (#135)</li> <li>partial-processor: add simple docstrings to success/failure handlers</li> <li>sqs: docstrings for PartialSQS</li> <li>sqs-base: docstring for base class</li> </ul>"
        },
        {
            "location": "changelog/#features_90",
            "title": "Features",
            "text": "<ul> <li>add xray_trace_id key when tracing is active #137</li> <li>initial implementation as the proposed gist is</li> <li>add sqs failure processors</li> <li>include base processors</li> <li>add batch module</li> <li>add package level import for batch utility</li> <li>logger: readable log_dict seq</li> <li>logging: suppress some log keys</li> <li>logging: allow for custom json order</li> <li>parameters: transform = \"auto\" (#133)</li> <li>sqs: add optional config parameter</li> <li>sqs: improve validation for queue_url</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_139",
            "title": "Maintenance",
            "text": "<ul> <li>tiny changes for readability</li> <li>add debug logging for sqs batch processing</li> <li>remove middlewares module, moving decorator functionality to base and sqs</li> <li>add test for sqs_batch_processor interface</li> <li>add sqs_batch_processor decorator to simplify interface</li> <li>fix typos, docstrings and type hints (#154)</li> <li>doc typo</li> <li>batch: Housekeeping for recent changes (#157)</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_9",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #149 from Nr18/static-types</li> <li>Merge pull request #155 from awslabs/docs/batch_processing_util</li> <li>Merge pull request #100 from gmcrocetti/partial-sqs-batch</li> <li>Merge pull request #151 from Nr18/troubleshooting</li> <li>Merge pull request #150 from heitorlessa/feat/logger-add-xray-trace-id</li> <li>Merge pull request #140 from gyft/fix-log-key-order</li> <li>Merge pull request #142 from gyft/fix-letter-case</li> </ul>"
        },
        {
            "location": "changelog/#v140-2020-08-25",
            "title": "v1.4.0 - 2020-08-25",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_128",
            "title": "Bug Fixes",
            "text": "<ul> <li>upgrade dot-prop, serialize-javascript</li> <li>remove actual response from debug logs</li> <li>naming and staticmethod consistency</li> <li>correct in_subsegment assertion</li> <li>update cold_start doc to reflect #125</li> <li>split ColdStart metric to its own EMF blob #125</li> <li>ssm: Make decrypt an explicit option and refactoring (#123)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_105",
            "title": "Documentation",
            "text": "<ul> <li>add Lambda Layer SAR App url and ARN</li> <li>move tenets; remove extra space</li> <li>use table for clarity</li> <li>add blog post, and quick example</li> <li>subtle rewording for better clarity</li> <li>fix typos, log_event &amp; sampling wording</li> <li>make sensitive info more explicit with an example</li> <li>create Patching modules section; cleanup response wording</li> <li>move concurrent asynchronous under escape hatch</li> <li>grammar</li> <li>bring new feature upfront when returning sensitive info</li> </ul>"
        },
        {
            "location": "changelog/#features_91",
            "title": "Features",
            "text": "<ul> <li>capture_response as metadata option #127</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_140",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.4.0</li> <li>update internal docstrings for consistency</li> <li>update changelog to reflect new feature</li> <li>clarify changelog bugfix vs breaking change</li> <li>remove/correct unnecessary debug logs</li> <li>fix debug log adding unused obj</li> <li>grammar</li> <li>add metrics fix description</li> <li>correct typos</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_10",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #129 from am29d/feat/lambda-layers</li> <li>Merge pull request #130 from heitorlessa/docs/readability-improvements</li> <li>Merge pull request #128 from heitorlessa/feat/tracer-disallow-response-metadata</li> <li>Merge pull request #126 from heitorlessa/fix/metrics-cold-start-split</li> </ul>"
        },
        {
            "location": "changelog/#v131-2020-08-22",
            "title": "v1.3.1 - 2020-08-22",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_129",
            "title": "Bug Fixes",
            "text": "<ul> <li>capture_method: should yield inside with (#124)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_141",
            "title": "Maintenance",
            "text": "<ul> <li>version bump to 1.3.1</li> <li>deps: bump prismjs from 1.20.0 to 1.21.0 in /docs</li> <li>deps: bump elliptic from 6.5.2 to 6.5.3 in /docs</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_11",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #120 from awslabs/dependabot/npm_and_yarn/docs/elliptic-6.5.3</li> <li>Merge pull request #121 from awslabs/dependabot/npm_and_yarn/docs/prismjs-1.21.0</li> </ul>"
        },
        {
            "location": "changelog/#v130-2020-08-21",
            "title": "v1.3.0 - 2020-08-21",
            "text": ""
        },
        {
            "location": "changelog/#features_92",
            "title": "Features",
            "text": "<ul> <li>add parameter utility (#96)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_142",
            "title": "Maintenance",
            "text": ""
        },
        {
            "location": "changelog/#v120-2020-08-20",
            "title": "v1.2.0 - 2020-08-20",
            "text": ""
        },
        {
            "location": "changelog/#features_93",
            "title": "Features",
            "text": "<ul> <li>add support for tracing of generators using capture_method decorator (#113)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_143",
            "title": "Maintenance",
            "text": ""
        },
        {
            "location": "changelog/#v113-2020-08-18",
            "title": "v1.1.3 - 2020-08-18",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_130",
            "title": "Bug Fixes",
            "text": "<ul> <li>remove root logger handler set by Lambda #115</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_144",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.1.3</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_12",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #117 from heitorlessa/chore/bump-1.1.3</li> <li>Merge pull request #116 from heitorlessa/fix/remove-root-logger-handler</li> </ul>"
        },
        {
            "location": "changelog/#v112-2020-08-16",
            "title": "v1.1.2 - 2020-08-16",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_131",
            "title": "Bug Fixes",
            "text": "<ul> <li>return subclass #107</li> </ul>"
        },
        {
            "location": "changelog/#documentation_106",
            "title": "Documentation",
            "text": "<ul> <li>clarify auto_patch as per #108</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_145",
            "title": "Maintenance",
            "text": "<ul> <li>suppress LGTM alert</li> <li>add autocomplete as unreleased</li> <li>remove unused stdout fixture</li> <li>update Tracer docs as per #108</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_13",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #111 from heitorlessa/chore/bump-1.1.2</li> <li>Merge pull request #110 from heitorlessa/improv/logger-auto-complete</li> <li>Merge pull request #109 from heitorlessa/docs/tracer-reuse</li> </ul>"
        },
        {
            "location": "changelog/#v111-2020-08-14",
            "title": "v1.1.1 - 2020-08-14",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_132",
            "title": "Bug Fixes",
            "text": "<ul> <li>regression 104 (#105)</li> <li>return log level int immediately</li> <li>add test covering logging constant</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_146",
            "title": "Maintenance",
            "text": "<ul> <li>bump patch version</li> <li>fix unused fixture</li> <li>fix docstring on level [str,int] consistency</li> <li>fix test level typo</li> <li>trigger docs on new release (#102) (#103)</li> <li>trigger docs on new release (#102)</li> <li>trigger docs on new release</li> </ul>"
        },
        {
            "location": "changelog/#regression_6",
            "title": "Regression",
            "text": "<ul> <li>log level docstring as str</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_14",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #106 from heitorlessa/fix/regression-104</li> </ul>"
        },
        {
            "location": "changelog/#v110-2020-08-14",
            "title": "v1.1.0 - 2020-08-14",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_133",
            "title": "Bug Fixes",
            "text": "<ul> <li>auto-assigner filename as per docs</li> </ul>"
        },
        {
            "location": "changelog/#features_94",
            "title": "Features",
            "text": "<ul> <li>add support for logger inheritance (#99)</li> <li>enable issue auto-assigner to core team</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_147",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.1.0 (#101)</li> <li>deps: bump lodash from 4.17.15 to 4.17.19 in /docs (#93)</li> </ul>"
        },
        {
            "location": "changelog/#v102-2020-07-16",
            "title": "v1.0.2 - 2020-07-16",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_148",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.0.2 (#90)</li> <li>support aws-xray-sdk &gt;=2.5.0 till &lt;3.0.0 (#89)</li> </ul>"
        },
        {
            "location": "changelog/#v101-2020-07-05",
            "title": "v1.0.1 - 2020-07-05",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_134",
            "title": "Bug Fixes",
            "text": "<ul> <li>append structured logs when injecting lambda context  (#86)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_107",
            "title": "Documentation",
            "text": "<ul> <li>add blog post in the readme</li> </ul>"
        },
        {
            "location": "changelog/#v100-2020-06-18",
            "title": "v1.0.0 - 2020-06-18",
            "text": ""
        },
        {
            "location": "changelog/#documentation_108",
            "title": "Documentation",
            "text": "<ul> <li>customize contributing guide (#77)</li> </ul>"
        },
        {
            "location": "changelog/#features_95",
            "title": "Features",
            "text": "<ul> <li>docs anonymized page view (#82)</li> <li>add metrics metadata (#81)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_149",
            "title": "Maintenance",
            "text": "<ul> <li>bump to 1.0.0 GA (#83)</li> <li>add missing ':' and identation in examples</li> <li>cleanup tests (#79)</li> <li>remove deprecated code before GA (#78)</li> <li>move blockquotes as hidden comments</li> </ul>"
        },
        {
            "location": "changelog/#v0110-2020-06-10",
            "title": "v0.11.0 - 2020-06-10",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_135",
            "title": "Bug Fixes",
            "text": "<ul> <li>default dimension creation now happens when metrics are serialized instead of on metrics constructor (#74)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_150",
            "title": "Maintenance",
            "text": "<ul> <li>update CHANGELOG</li> </ul>"
        },
        {
            "location": "changelog/#v0101-2020-06-10",
            "title": "v0.10.1 - 2020-06-10",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_136",
            "title": "Bug Fixes",
            "text": "<ul> <li>default dimension creation now happens when metrics are serialized instead of on metrics constructor (#74)</li> </ul>"
        },
        {
            "location": "changelog/#documentation_109",
            "title": "Documentation",
            "text": "<ul> <li>fix contrast on highlighted code text (#73)</li> </ul>"
        },
        {
            "location": "changelog/#features_96",
            "title": "Features",
            "text": "<ul> <li>improve error handling for log_metrics decorator (#71)</li> <li>add high level imports (#70)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_151",
            "title": "Maintenance",
            "text": "<ul> <li>version bump 0.10.1</li> <li>deps: bump graphql-playground-html from 1.6.19 to 1.6.25 in /docs</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_15",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #72 from awslabs/dependabot/npm_and_yarn/docs/graphql-playground-html-1.6.25</li> </ul>"
        },
        {
            "location": "changelog/#v0100-2020-06-08",
            "title": "v0.10.0 - 2020-06-08",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_137",
            "title": "Bug Fixes",
            "text": "<ul> <li>correct env var name for publish to pypi test (#69)</li> <li>release-drafter action syntax</li> <li>release-drafter label for new feature/major non-breaking changes</li> <li>cast dimension value to str to avoid issue where EMF silently fails (#52)</li> <li>ignore path that might seem a broken link #49</li> <li>open api ref in a new tab #48</li> <li>metrics not being flushed on every invocation (#45)</li> <li>#35 duplicate changelog to project root</li> <li>#24 correct example test and docs</li> <li>CI attempt 4</li> <li>CI attempt 3</li> <li>CI attempt 3</li> <li>CI attempt 2</li> <li>add missing single_metric example; test var name</li> <li>fix import of aws_lambda_logging to relative import</li> <li>Makefile: format before linting</li> <li>make: add twine as a dev dep</li> <li>setup: correct invalid license classifier</li> <li>setup: correct license to MIT-0 in meta</li> </ul>"
        },
        {
            "location": "changelog/#documentation_110",
            "title": "Documentation",
            "text": "<ul> <li>build on master only</li> <li>clarify logger debug sampling message</li> <li>clean up readme in favour of docs website</li> <li>add install in main docs website</li> <li>add pypi badge</li> </ul>"
        },
        {
            "location": "changelog/#features_97",
            "title": "Features",
            "text": "<ul> <li>add capture_cold_start_metric for log_metrics (#67)</li> <li>automate publishing to pypi (#58)</li> <li>add pre-commit hooks (#64)</li> <li>update Metrics interface to resemble tracer &amp; logger: use \"service\" as its namespace.</li> <li>add codecov service (#59)</li> <li>add security and complexity baseline #33 (#57)</li> <li>add pull request template #33</li> <li>add RFC template for proposals</li> <li>create issue templates</li> <li>readd release drafter action #33</li> <li>add release drafter (#56)</li> <li>add stale issues config #33 (#55)</li> <li>enforce semantic PR titles (#54)</li> <li>add algolia search for docs and api ref (#39)</li> <li>add documentation website (#37)</li> <li>add docs to CI</li> <li>Add Python3.8 support</li> <li>logger: add log sampling</li> <li>pypi: add bumpversion, public release pypi</li> <li>pyproject.toml: move to poetry</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_152",
            "title": "Maintenance",
            "text": "<ul> <li>version bump (#68)</li> <li>public beta version</li> <li>rename Makefile target docs-dev to docs-local (#65)</li> <li>correct docstring for log_metrics</li> <li>fix typo in metrics doc</li> <li>Correct test comment</li> <li>remove unused import</li> <li>formatting</li> <li>plat wheels are not needed</li> <li>reformat changelog to follow KeepAChangelog standard (#50)</li> <li>bump to release candidate</li> <li>renamed history to changelog dependabot</li> <li>grammar issues</li> <li>bump example to use 0.8.0 features</li> <li>clean up CI workflows</li> <li>fix github badge typo</li> <li>pypi monthly download badge</li> <li>lint</li> <li>bump 0.3.1 with logging patch</li> <li>bump history</li> <li>lint</li> <li>add Python 3.8 in badge as it's supported</li> <li>CI badge</li> <li>public beta version</li> <li>deps: bump bleach from 3.1.0 to 3.1.1 in /python</li> <li>deps: bump websocket-extensions from 0.1.3 to 0.1.4 in /docs (#66)</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_16",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #60 from awslabs/improv/metrics_interface</li> <li>Merge pull request #8 from awslabs/dependabot/pip/python/bleach-3.1.1</li> <li>Merge pull request #7 from danilohgds/sampling_feature</li> <li>Merge pull request #5 from jfuss/feat/python38</li> </ul>"
        },
        {
            "location": "maintainers/",
            "title": "Maintainers playbook",
            "text": ""
        },
        {
            "location": "maintainers/#overview",
            "title": "Overview",
            "text": "<p>Please treat this content as a living document.</p> <p>This is document explains who the maintainers are, their responsibilities, and how they should be doing it. If you're interested in contributing, see CONTRIBUTING.</p>"
        },
        {
            "location": "maintainers/#current-maintainers",
            "title": "Current Maintainers",
            "text": "Maintainer GitHub ID Affiliation Ana Falcão anafalcao Amazon Leandro Damascena leandrodamascena Amazon Simon Thulbourn sthulb Amazon"
        },
        {
            "location": "maintainers/#emeritus",
            "title": "Emeritus",
            "text": "<p>Previous active maintainers who contributed to this project.</p> Maintainer GitHub ID Affiliation Alexander Schueren am29d Amazon Heitor Lessa heitorlessa Adyen Michal Ploski mploski Splunk Nicolas Moutschen nmoutschen Apollo Ruben Fonseca rubenfonseca N/A Tom McCarthy cakepietoast MongoDB"
        },
        {
            "location": "maintainers/#labels",
            "title": "Labels",
            "text": "<p>These are the most common labels used by maintainers to triage issues, pull requests (PR), and for project management:</p> Label Usage Notes triage New issues that require maintainers review Issue template bug Unexpected, reproducible and unintended software behavior PR/Release automation; Doc snippets are excluded; not-a-bug New and existing bug reports incorrectly submitted as bug Analytics documentation Documentation improvements PR/Release automation; Doc additions, fixes, etc.; feature-request New or enhancements to existing features Issue template typing New or enhancements to static typing Issue template RFC Technical design documents related to a feature request Issue template bug-upstream Bug caused by upstream dependency help wanted Tasks you want help from anyone to move forward Bandwidth, complex topics, etc. need-customer-feedback Tasks that need more feedback before proceeding 80/20% rule, uncertain, etc. need-more-information Missing information before making any calls need-documentation PR is missing or has incomplete documentation need-issue PR is missing a related issue for tracking change PR automation need-rfc Feature request requires a RFC to improve discussion pending-release Merged changes that will be available soon Release automation auto-closes/notifies it revisit-in-3-months Blocked issues/PRs that need to be revisited Often related to <code>need-customer-feedback</code>, prioritization, etc. breaking-change Changes that will cause customer impact and need careful triage do-not-merge PRs that are blocked for varying reasons Timeline is uncertain size/XS PRs between 0-9 LOC PR automation size/S PRs between 10-29 LOC PR automation size/M PRs between 30-99 LOC PR automation size/L PRs between 100-499 LOC PR automation size/XL PRs between 500-999 LOC, often PRs that grown with feedback PR automation size/XXL PRs with 1K+ LOC, largely documentation related PR automation tests PRs that add or change tests PR automation <code>&lt;utility&gt;</code> PRs related to a Powertools for AWS Lambda (Python) utility, e.g. <code>parameters</code>, <code>tracer</code> PR automation feature New features or minor changes PR/Release automation dependencies Changes that touch dependencies, e.g. Dependabot, etc. PR/ automation github-actions Changes in GitHub workflows PR automation github-templates Changes in GitHub issue/PR templates PR automation internal Changes in governance and chores (linting setup, baseline, etc.) PR automation tech-debt Changes in tech debt customer-reference Authorization to use company name in our documentation Public Relations community-content Suggested content to feature in our documentation Public Relations"
        },
        {
            "location": "maintainers/#maintainer-responsibilities",
            "title": "Maintainer Responsibilities",
            "text": "<p>Maintainers are active and visible members of the community, and have maintain-level permissions on a repository. Use those privileges to serve the community and evolve code as follows.</p> <p>Be aware of recurring ambiguous situations and document them to help your fellow maintainers.</p>"
        },
        {
            "location": "maintainers/#uphold-code-of-conduct",
            "title": "Uphold Code of Conduct",
            "text": "<p>Model the behavior set forward by the Code of Conduct and raise any violations to other maintainers and admins. There could be unusual circumstances where inappropriate behavior does not immediately fall within the Code of Conduct.</p> <p>These might be nuanced and should be handled with extra care - when in doubt, do not engage and reach out to other maintainers and admins.</p>"
        },
        {
            "location": "maintainers/#prioritize-security",
            "title": "Prioritize Security",
            "text": "<p>Security is your number one priority. Maintainer's Github keys must be password protected securely and any reported security vulnerabilities are addressed before features or bugs.</p> <p>Note that this repository is monitored and supported 24/7 by Amazon Security, see Reporting a Vulnerability for details.</p>"
        },
        {
            "location": "maintainers/#review-pull-requests",
            "title": "Review Pull Requests",
            "text": "<p>Review pull requests regularly, comment, suggest, reject, merge and close. Accept only high quality pull-requests. Provide code reviews and guidance on incoming pull requests.</p> <p>PRs are labeled based on file changes and semantic title. Pay attention to whether labels reflect the current state of the PR and correct accordingly.</p> <p>Use and enforce semantic versioning pull request titles, as these will be used for CHANGELOG and Release notes - make sure they communicate their intent at the human level.</p> <p>TODO: This is an area we want to automate using the new GitHub GraphQL API.</p> <p>For issues linked to a PR, make sure <code>pending release</code> label is applied to them when merging. Upon release, these issues will be notified which release version contains their change.</p> <p>See Common scenarios section for additional guidance.</p>"
        },
        {
            "location": "maintainers/#triage-new-issues",
            "title": "Triage New Issues",
            "text": "<p>Manage labels, review issues regularly, and create new labels as needed by the project. Remove <code>triage</code> label when you're able to confirm the validity of a request, a bug can be reproduced, etc. Give priority to the original author for implementation, unless it is a sensitive task that is best handled by maintainers.</p> <p>TODO: This is an area we want to automate using the new GitHub GraphQL API.</p> <p>Make sure issues are assigned to our board of activities and have the right status.</p> <p>Use our labels to signal good first issues to new community members, and to set expectation that this might need additional feedback from the author, other customers, experienced community members and/or maintainers.</p> <p>Be aware of casual contributors and recurring contributors. Provide the experience and attention you wish you had if you were starting in open source.</p> <p>See Common scenarios section for additional guidance.</p>"
        },
        {
            "location": "maintainers/#triage-bug-reports",
            "title": "Triage Bug Reports",
            "text": "<p>Be familiar with our definition of bug. If it's not a bug, you can close it or adjust its title and labels - always communicate the reason accordingly.</p> <p>For bugs caused by upstream dependencies, replace <code>bug</code> with <code>bug-upstream</code> label. Ask the author whether they'd like to raise the issue upstream or if they prefer us to do so.</p> <p>Assess the impact and make the call on whether we need an emergency release. Contact other maintainers when in doubt.</p> <p>See Common scenarios section for additional guidance.</p>"
        },
        {
            "location": "maintainers/#triage-rfcs",
            "title": "Triage RFCs",
            "text": "<p>RFC is a collaborative process to help us get to the most optimal solution given the context. Their purpose is to ensure everyone understands what this context is, their trade-offs, and alternative solutions that were part of the research before implementation begins.</p> <p>Make sure you ask these questions in mind when reviewing:</p> <ul> <li>Does it use our RFC template?</li> <li>Does the match our Tenets?</li> <li>Does the proposal address the use case? If so, is the recommended usage explicit?</li> <li>Does it focus on the mechanics to solve the use case over fine-grained implementation details?</li> <li>Can anyone familiar with the code base implement it?</li> <li>If approved, are they interested in contributing? Do they need any guidance?</li> <li>Does this significantly increase the overall project maintenance? Do we have the skills to maintain it?</li> <li>If we can't take this use case, are there alternative projects we could recommend? Or does it call for a new project altogether?</li> </ul> <p>When necessary, be upfront that the time to review, approve, and implement a RFC can vary - see Contribution is stuck. Some RFCs may be further updated after implementation, as certain areas become clearer.</p> <p>Some examples using our initial and new RFC templates: #92, #94, #95, #991, #1226</p>"
        },
        {
            "location": "maintainers/#releasing-a-new-version",
            "title": "Releasing a new version",
            "text": "<p>Firstly, make sure the commit history in the <code>develop</code> branch (1) it's up to date, (2) commit messages are semantic, and (3) commit messages have their respective area, for example <code>feat(logger): &lt;change&gt;</code>, <code>chore(ci): ...</code>).</p> <p>Looks good, what's next?</p> <p>Kickoff the <code>Release</code> workflow with the intended version - this might take around 25m-30m to complete.</p> <p>Once complete, you can start drafting the release notes to let customers know what changed and what's in it for them (a.k.a why they should care). We have guidelines in the release notes section so you know what good looks like.</p> <p>NOTE: Documentation might take a few minutes to reflect the latest version due to caching and CDN invalidations.</p>"
        },
        {
            "location": "maintainers/#release-process-visualized",
            "title": "Release process visualized",
            "text": "<p>Every release makes hundreds of checks, security scans, canaries and deployments - all of these are automated.</p> <p>This is a close visual representation of the main steps (GitHub Actions UI should be the source of truth), along with the approximate time it takes for each key step to complete.</p> <pre><code>gantt\n\ntitle      Release process\ndateFormat HH:mm\naxisFormat %H:%M\n\nRelease commit   : milestone, m1, 10:00,2m\n\nsection Seal\n    Bump release version        : active, 8s\n    Prevent source tampering    : active, 43s\nsection QA\n    Quality checks              : active, 2.2m\nsection Build\n    Checksum                    : active, 8s\n    Build release artifact      : active, 39s\n    Seal                        : active, 8s\nsection Provenance\n    Attest build                : active, 8s\n    Sign attestation            : active, attestation, 10:06, 8s\n\nsection Release\n    Checksum                    : active, 8s\n    PyPi temp credentials       : active, 8s\n    Publish PyPi                : active, pypi, 10:07, 29s\n\nPyPi release : milestone, m2, 10:07,1s\n\nsection Git release\n    Checksum                    : active, after pypi, 8s\n    Git Tag                     : active, 8s\n    Bump package version        : active, 8s\n    Create PR                   : active, 8s\n    Upload attestation          : active, 8s\n\nsection Layer release\n    Build (x86_64+ARM)             : active, layer_build, 10:08, 6m\n    Deploy Beta                 : active, layer_beta, after layer_build, 6.3m\n    Deploy Prod                 : active, layer_prod, after layer_beta, 6.3m\n\nLayer release : milestone, m3, 10:26,1s\n\nsection SAR release\n    Deploy Beta                 : active, sar_beta, after layer_beta, 2.2m\n    Deploy Prod                 : active, sar_prod, after sar_beta, 2.2m\n\nSAR release : milestone, m4, 10:25,1s\n\nsection Docs\n    Create PR (Layer ARN)       : active, after layer_prod, 8s\n    Release versioned docs      : active, 2.2m\n\nDocumentation release : milestone, m4, 10:28,1m\n\nsection Post-release\n    Close pending issues        : active, 8s\n\nRelease complete : milestone, m6, 10:31,2m</code></pre>"
        },
        {
            "location": "maintainers/#drafting-release-notes",
            "title": "Drafting release notes",
            "text": "<p>Make sure the release workflow completed before you edit release notes.</p> <p>Visit the Releases page and choose the edit pencil button.</p> <p>Make sure the <code>tag</code> field reflects the new version you're releasing, the target branch field is set to <code>develop</code>, and <code>release title</code> matches your tag e.g., <code>v1.26.0</code>.</p> <p>You'll notice we group all changes based on their labels like <code>feature</code>, <code>bug</code>, <code>documentation</code>, etc.</p> <p>Spotted a typo?</p> <p>Edit the respective PR title/labels and run the Release Drafter workflow.</p> <p>All good, what's next?</p> <p>The best part comes now!</p> <p>Replace the placeholder <code>[Human readable summary of changes]</code> with what you'd like to communicate to customers what this release is all about.</p> <p>Always put yourself in the customers shoes. Most read the first sentence only to know whether this is for them.</p> <p>These are some questions to keep in mind when drafting your first or future release notes:</p> <ul> <li>Can customers briefly understand the main changes in less than 30s?<ul> <li>tip: first paragraph is punchy and optimizes for dependabot-like notifications.</li> </ul> </li> <li>Are we calling out key contributor(s) to this release?</li> <li>Is it clear what each change enables/unlocks and before?<ul> <li>tip: use present and active voice; lead with the answer.</li> </ul> </li> <li>Does it include a link to the documentation for each main change?<ul> <li>tip: release explains what a change unblocks/enables (before/after), docs go in details</li> </ul> </li> <li>Is code snippet better in text or graphic?</li> <li>Does code snippet focus on the change only?<ul> <li>tip: release snippets highlight functionality, no need to be functional (that's docs)</li> </ul> </li> </ul> <p>Once you're happy, hit <code>Publish release</code> 🎉🎉🎉.</p>"
        },
        {
            "location": "maintainers/#releasing-an-alpha-release",
            "title": "Releasing an alpha release",
            "text": "<p>We publish alpha releases (<code>prerelease</code>) every morning during business days (~8am UTC). You can also manually trigger <code>pre-release</code> workflow when needed.</p>"
        },
        {
            "location": "maintainers/#run-end-to-end-tests",
            "title": "Run end to end tests",
            "text": "<p>E2E tests are run on every push to <code>develop</code> or manually via run-e2e-tests workflow.</p> <p>To run locally, you need AWS CDK CLI and an account bootstrapped (<code>cdk bootstrap</code>). With a default AWS CLI profile configured, or <code>AWS_PROFILE</code> environment variable set, run <code>make e2e tests</code>.</p>"
        },
        {
            "location": "maintainers/#releasing-a-documentation-hotfix",
            "title": "Releasing a documentation hotfix",
            "text": "<p>You can rebuild the latest documentation without a full release via this GitHub Actions Workflow. Choose <code>Run workflow</code>, keep <code>develop</code> as the branch, and input the latest Powertools for AWS Lambda (Python) version available.</p> <p>This workflow will update both user guide and API documentation.</p>"
        },
        {
            "location": "maintainers/#maintain-overall-health-of-the-repo",
            "title": "Maintain Overall Health of the Repo",
            "text": "<p>TODO: Coordinate renaming <code>develop</code> to <code>main</code></p> <p>Keep the <code>develop</code> branch at production quality at all times. Backport features as needed. Cut release branches and tags to enable future patches.</p>"
        },
        {
            "location": "maintainers/#manage-roadmap",
            "title": "Manage Roadmap",
            "text": "<p>See Roadmap section</p> <p>Ensure the repo highlights features that should be elevated to the project roadmap. Be clear about the feature’s status, priority, target version, and whether or not it should be elevated to the roadmap.</p>"
        },
        {
            "location": "maintainers/#add-continuous-integration-checks",
            "title": "Add Continuous Integration Checks",
            "text": "<p>Add integration checks that validate pull requests and pushes to ease the burden on Pull Request reviewers. Continuously revisit areas of improvement to reduce operational burden in all parties involved.</p>"
        },
        {
            "location": "maintainers/#negative-impact-on-the-project",
            "title": "Negative Impact on the Project",
            "text": "<p>Actions that negatively impact the project will be handled by the admins, in coordination with other maintainers, in balance with the urgency of the issue. Examples would be Code of Conduct violations, deliberate harmful or malicious actions, spam, monopolization, and security risks.</p>"
        },
        {
            "location": "maintainers/#becoming-a-maintainer",
            "title": "Becoming a maintainer",
            "text": "<p>In 2023, we will revisit this. We need to improve our understanding of how other projects are doing, their mechanisms to promote key contributors, and how they interact daily.</p> <p>We suspect this process might look similar to the OpenSearch project.</p>"
        },
        {
            "location": "maintainers/#common-scenarios",
            "title": "Common scenarios",
            "text": "<p>These are recurring ambiguous situations that new and existing maintainers may encounter. They serve as guidance. It is up to each maintainer to follow, adjust, or handle in a different manner as long as our conduct is consistent</p>"
        },
        {
            "location": "maintainers/#contribution-is-stuck",
            "title": "Contribution is stuck",
            "text": "<p>A contribution can get stuck often due to lack of bandwidth and language barrier. For bandwidth issues, check whether the author needs help. Make sure you get their permission before pushing code into their existing PR - do not create a new PR unless strictly necessary.</p> <p>For language barrier and others, offer a 1:1 chat to get them unblocked. Often times, English might not be their primary language, and writing in public might put them off, or come across not the way they intended to be.</p> <p>In other cases, you may have constrained capacity. Use <code>help wanted</code> label when you want to signal other maintainers and external contributors that you could use a hand to move it forward.</p>"
        },
        {
            "location": "maintainers/#insufficient-feedback-or-information",
            "title": "Insufficient feedback or information",
            "text": "<p>When in doubt, use <code>need-more-information</code> or <code>need-customer-feedback</code> labels to signal more context and feedback are necessary before proceeding. You can also use <code>revisit-in-3-months</code> label when you expect it might take a while to gather enough information before you can decide.</p>"
        },
        {
            "location": "maintainers/#crediting-contributions",
            "title": "Crediting contributions",
            "text": "<p>We credit all contributions as part of each release note as an automated process. If you find  contributors are missing from the release note you're producing, please add them manually.</p>"
        },
        {
            "location": "maintainers/#is-that-a-bug",
            "title": "Is that a bug?",
            "text": "<p>A bug produces incorrect or unexpected results at runtime that differ from its intended behavior. Bugs must be reproducible. They directly affect customers experience at runtime despite following its recommended usage.</p> <p>Documentation snippets, use of internal components, or unadvertised functionalities are not considered bugs.</p>"
        },
        {
            "location": "maintainers/#mentoring-contributions",
            "title": "Mentoring contributions",
            "text": "<p>Always favor mentoring issue authors to contribute, unless they're not interested or the implementation is sensitive (e.g., complexity, time to release, etc.).</p> <p>Make use of <code>help wanted</code> and <code>good first issue</code> to signal additional contributions the community can help.</p>"
        },
        {
            "location": "maintainers/#long-running-issues-or-prs",
            "title": "Long running issues or PRs",
            "text": "<p>Try offering a 1:1 call in the attempt to get to a mutual understanding and clarify areas that maintainers could help.</p> <p>In the rare cases where both parties don't have the bandwidth or expertise to continue, it's best to use the <code>revisit-in-3-months</code> label. By then, see if it's possible to break the PR or issue in smaller chunks, and eventually close if there is no progress.</p>"
        },
        {
            "location": "maintainers/#e2e-framework",
            "title": "E2E framework",
            "text": ""
        },
        {
            "location": "maintainers/#structure",
            "title": "Structure",
            "text": "<p>Our E2E framework relies on Pytest fixtures to coordinate infrastructure and test parallelization - see Test Parallelization and CDK CLI Parallelization.</p> <p>tests/e2e structure</p> <pre><code>.\n├── __init__.py\n├── conftest.py # builds Lambda Layer once\n├── logger\n│   ├── __init__.py\n│   ├── conftest.py  # deploys LoggerStack\n│   ├── handlers\n│   │   └── basic_handler.py\n│   ├── infrastructure.py # LoggerStack definition\n│   └── test_logger.py\n├── metrics\n│   ├── __init__.py\n│   ├── conftest.py  # deploys MetricsStack\n│   ├── handlers\n│   │   ├── basic_handler.py\n│   │   └── cold_start.py\n│   ├── infrastructure.py # MetricsStack definition\n│   └── test_metrics.py\n├── tracer\n│   ├── __init__.py\n│   ├── conftest.py  # deploys TracerStack\n│   ├── handlers\n│   │   ├── async_capture.py\n│   │   └── basic_handler.py\n│   ├── infrastructure.py  # TracerStack definition\n│   └── test_tracer.py\n└── utils\n    ├── __init__.py\n    ├── data_builder  # build_service_name(), build_add_dimensions_input, etc.\n    ├── data_fetcher  # get_traces(), get_logs(), get_lambda_response(), etc.\n    ├── infrastructure.py # base infrastructure like deploy logic, etc.\n</code></pre> <p>Where:</p> <ul> <li><code>&lt;feature&gt;/infrastructure.py</code>. Uses CDK to define the infrastructure a given feature needs.</li> <li><code>&lt;feature&gt;/handlers/</code>. Lambda function handlers to build, deploy, and exposed as stack output in PascalCase (e.g., <code>BasicHandler</code>).</li> <li><code>utils/</code>. Test utilities to build data and fetch AWS data to ease assertion</li> <li><code>conftest.py</code>. Deploys and deletes a given feature infrastructure. Hierarchy matters:<ul> <li>Top-level (<code>e2e/conftest</code>). Builds Lambda Layer only once and blocks I/O across all CPU workers.</li> <li>Feature-level (<code>e2e/&lt;feature&gt;/conftest</code>). Deploys stacks in parallel and make them independent of each other.</li> </ul> </li> </ul>"
        },
        {
            "location": "maintainers/#mechanics",
            "title": "Mechanics",
            "text": "<p>Under <code>BaseInfrastructure</code>, we hide the complexity of deployment and delete coordination under <code>deploy</code>, <code>delete</code>, and <code>create_lambda_functions</code> methods.</p> <p>This allows us to benefit from test and deployment parallelization, use IDE step-through debugging for a single test, run one, subset, or all tests and only deploy their related infrastructure, without any custom configuration.</p> <p>Class diagram to understand abstraction built when defining a new stack (<code>LoggerStack</code>)</p> <pre><code>classDiagram\n    class InfrastructureProvider {\n        &lt;&lt;interface&gt;&gt;\n        +deploy() Dict\n        +delete()\n        +create_resources()\n        +create_lambda_functions() Dict~Functions~\n    }\n\n    class BaseInfrastructure {\n        +deploy() Dict\n        +delete()\n        +create_lambda_functions() Dict~Functions~\n        +add_cfn_output()\n    }\n\n    class TracerStack {\n        +create_resources()\n    }\n\n    class LoggerStack {\n        +create_resources()\n    }\n\n    class MetricsStack {\n        +create_resources()\n    }\n\n    class EventHandlerStack {\n        +create_resources()\n    }\n\n    InfrastructureProvider &lt;|-- BaseInfrastructure : implement\n    BaseInfrastructure &lt;|-- TracerStack : inherit\n    BaseInfrastructure &lt;|-- LoggerStack : inherit\n    BaseInfrastructure &lt;|-- MetricsStack : inherit\n    BaseInfrastructure &lt;|-- EventHandlerStack : inherit</code></pre>"
        },
        {
            "location": "maintainers/#authoring-a-new-feature-e2e-test",
            "title": "Authoring a new feature E2E test",
            "text": "<p>Imagine you're going to create E2E for Event Handler feature for the first time. Keep the following mental model when reading:</p> <pre><code>graph LR\n    A[\"1. Define infrastructure\"]--&gt;B[\"2. Deploy/Delete infrastructure\"]--&gt;C[\"3.Access Stack outputs\" ]</code></pre>"
        },
        {
            "location": "maintainers/#1-define-infrastructure",
            "title": "1. Define infrastructure",
            "text": "<p>We use CDK as our Infrastructure as Code tool of choice. Before you start using CDK, you'd take the following steps:</p> <ol> <li>Create <code>tests/e2e/event_handler/infrastructure.py</code> file</li> <li>Create a new class <code>EventHandlerStack</code> and inherit from <code>BaseInfrastructure</code></li> <li>Override <code>create_resources</code> method and define your infrastructure using CDK</li> <li>(Optional) Create a Lambda function under <code>handlers/alb_handler.py</code></li> </ol> <p>Excerpt <code>tests/e2e/event_handler/infrastructure.py</code></p> <pre><code>class EventHandlerStack(BaseInfrastructure):\n    def create_resources(self):\n        functions = self.create_lambda_functions()\n\n        self._create_alb(function=functions[\"AlbHandler\"])\n        ...\n\n    def _create_alb(self, function: Function):\n        vpc = ec2.Vpc.from_lookup(\n            self.stack,\n            \"VPC\",\n            is_default=True,\n            region=self.region,\n        )\n\n        alb = elbv2.ApplicationLoadBalancer(self.stack, \"ALB\", vpc=vpc, internet_facing=True)\n        CfnOutput(self.stack, \"ALBDnsName\", value=alb.load_balancer_dns_name)\n        ...\n</code></pre> <p>Excerpt <code>tests/e2e/event_handler/handlers/alb_handler.py</code></p> <pre><code>from aws_lambda_powertools.event_handler import ALBResolver, Response, content_types\n\napp = ALBResolver()\n\n\n@app.get(\"/todos\")\ndef hello():\n    return Response(\n        status_code=200,\n        content_type=content_types.TEXT_PLAIN,\n        body=\"Hello world\",\n        cookies=[\"CookieMonster\", \"MonsterCookie\"],\n        headers={\"Foo\": [\"bar\", \"zbr\"]},\n    )\n\n\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "maintainers/#2-deploydelete-infrastructure-when-tests-run",
            "title": "2. Deploy/Delete infrastructure when tests run",
            "text": "<p>We need to create a Pytest fixture for our new feature under <code>tests/e2e/event_handler/conftest.py</code>.</p> <p>This will instruct Pytest to deploy our infrastructure when our tests start, and delete it when they complete whether tests are successful or not. Note that this file will not need any modification in the future.</p> <p>Excerpt <code>conftest.py</code> for Event Handler</p> <pre><code>import pytest\n\nfrom tests.e2e.event_handler.infrastructure import EventHandlerStack\n\n\n@pytest.fixture(autouse=True, scope=\"module\")\ndef infrastructure():\n    \"\"\"Setup and teardown logic for E2E test infrastructure\n\n    Yields\n    ------\n    Dict[str, str]\n        CloudFormation Outputs from deployed infrastructure\n    \"\"\"\n    stack = EventHandlerStack()\n    try:\n        yield stack.deploy()\n    finally:\n        stack.delete()\n</code></pre>"
        },
        {
            "location": "maintainers/#3-access-stack-outputs-for-e2e-tests",
            "title": "3. Access stack outputs for E2E tests",
            "text": "<p>Within our tests, we should now have access to the <code>infrastructure</code> fixture we defined earlier in <code>tests/e2e/event_handler/conftest.py</code>.</p> <p>We can access any Stack Output using pytest dependency injection.</p> <p>Excerpt <code>tests/e2e/event_handler/test_header_serializer.py</code></p> <pre><code>@pytest.fixture\ndef alb_basic_listener_endpoint(infrastructure: dict) -&gt; str:\n    dns_name = infrastructure.get(\"ALBDnsName\")\n    port = infrastructure.get(\"ALBBasicListenerPort\", \"\")\n    return f\"http://{dns_name}:{port}\"\n\n\ndef test_alb_headers_serializer(alb_basic_listener_endpoint):\n    # GIVEN\n    url = f\"{alb_basic_listener_endpoint}/todos\"\n    ...\n</code></pre>"
        },
        {
            "location": "maintainers/#internals",
            "title": "Internals",
            "text": ""
        },
        {
            "location": "maintainers/#test-runner-parallelization",
            "title": "Test runner parallelization",
            "text": "<p>Besides speed, we parallelize our end-to-end tests to ease asserting async side-effects may take a while per test too, e.g., traces to become available.</p> <p>The following diagram demonstrates the process we take every time you use <code>make e2e</code> locally or at CI:</p> <pre><code>graph TD\n    A[make e2e test] --&gt;Spawn{\"Split and group tests &lt;br&gt;by feature and CPU\"}\n\n    Spawn --&gt;|Worker0| Worker0_Start[\"Load tests\"]\n    Spawn --&gt;|Worker1| Worker1_Start[\"Load tests\"]\n    Spawn --&gt;|WorkerN| WorkerN_Start[\"Load tests\"]\n\n    Worker0_Start --&gt;|Wait| LambdaLayer[\"Lambda Layer build\"]\n    Worker1_Start --&gt;|Wait| LambdaLayer[\"Lambda Layer build\"]\n    WorkerN_Start --&gt;|Wait| LambdaLayer[\"Lambda Layer build\"]\n\n    LambdaLayer --&gt;|Worker0| Worker0_Deploy[\"Launch feature stack\"]\n    LambdaLayer --&gt;|Worker1| Worker1_Deploy[\"Launch feature stack\"]\n    LambdaLayer --&gt;|WorkerN| WorkerN_Deploy[\"Launch feature stack\"]\n\n    Worker0_Deploy --&gt;|Worker0| Worker0_Tests[\"Run tests\"]\n    Worker1_Deploy --&gt;|Worker1| Worker1_Tests[\"Run tests\"]\n    WorkerN_Deploy --&gt;|WorkerN| WorkerN_Tests[\"Run tests\"]\n\n    Worker0_Tests --&gt; ResultCollection\n    Worker1_Tests --&gt; ResultCollection\n    WorkerN_Tests --&gt; ResultCollection\n\n    ResultCollection{\"Wait for workers&lt;br/&gt;Collect test results\"}\n    ResultCollection --&gt; TestEnd[\"Report results\"]\n    ResultCollection --&gt; DeployEnd[\"Delete Stacks\"]</code></pre>"
        },
        {
            "location": "maintainers/#cdk-cli-parallelization",
            "title": "CDK CLI parallelization",
            "text": "<p>For CDK CLI to work with independent CDK Apps, we specify an output directory when synthesizing our stack and deploy from said output directory.</p> <pre><code>flowchart TD\n    subgraph \"Deploying distinct CDK Apps\"\n        EventHandlerInfra[\"Event Handler CDK App\"] --&gt; EventHandlerSynth\n        TracerInfra[\"Tracer CDK App\"] --&gt; TracerSynth\n       EventHandlerSynth[\"cdk synth --out cdk.out/event_handler\"] --&gt; EventHandlerDeploy[\"cdk deploy --app cdk.out/event_handler\"]\n\n       TracerSynth[\"cdk synth --out cdk.out/tracer\"] --&gt; TracerDeploy[\"cdk deploy --app cdk.out/tracer\"]\n    end</code></pre> <p>We create the typical CDK <code>app.py</code> at runtime when tests run, since we know which feature and Python version we're dealing with (locally or at CI).</p> <p>Excerpt <code>cdk_app_V39.py</code> for Event Handler created at deploy phase</p> <pre><code>from tests.e2e.event_handler.infrastructure import EventHandlerStack\nstack = EventHandlerStack()\nstack.create_resources()\nstack.app.synth()\n</code></pre> <p>When we run E2E tests for a single feature or all of them, our <code>cdk.out</code> looks like this:</p> <pre><code>total 8\ndrwxr-xr-x  18 lessa  staff   576B Sep  6 15:38 event-handler\ndrwxr-xr-x   3 lessa  staff    96B Sep  6 15:08 layer_build\n-rw-r--r--   1 lessa  staff    32B Sep  6 15:08 layer_build.diff\ndrwxr-xr-x  18 lessa  staff   576B Sep  6 15:38 logger\ndrwxr-xr-x  18 lessa  staff   576B Sep  6 15:38 metrics\ndrwxr-xr-x  22 lessa  staff   704B Sep  9 10:52 tracer\n</code></pre> <pre><code>classDiagram\n    class CdkOutDirectory {\n        feature_name/\n        layer_build/\n        layer_build.diff\n    }\n\n    class EventHandler {\n        manifest.json\n        stack_outputs.json\n        cdk_app_V39.py\n        asset.uuid/\n        ...\n    }\n\n    class StackOutputsJson {\n        BasicHandlerArn: str\n        ALBDnsName: str\n        ...\n    }\n\n    CdkOutDirectory &lt;|-- EventHandler : feature_name/\n    StackOutputsJson &lt;|-- EventHandler</code></pre> <p>Where:</p> <ul> <li><code>&lt;feature&gt;</code>. Contains CDK Assets, CDK <code>manifest.json</code>, our <code>cdk_app_&lt;PyVersion&gt;.py</code> and <code>stack_outputs.json</code></li> <li><code>layer_build</code>. Contains our Lambda Layer source code built once, used by all stacks independently</li> <li><code>layer_build.diff</code>. Contains a hash on whether our source code has changed to speed up further deployments and E2E tests</li> </ul> <p>Together, all of this allows us to use Pytest like we would for any project, use CDK CLI and its context methods (<code>from_lookup</code>), and use step-through debugging for a single E2E test without any extra configuration.</p> <p>NOTE: VSCode doesn't support debugging processes spawning sub-processes (like CDK CLI does w/ shell and CDK App). Maybe this works. PyCharm works just fine.</p>"
        },
        {
            "location": "roadmap/",
            "title": "Roadmap",
            "text": ""
        },
        {
            "location": "roadmap/#overview",
            "title": "Overview",
            "text": "<p>Our public roadmap outlines the high level direction we are working towards. We update this document when our priorities change: security and stability are our top priority.</p> <p>For most up-to-date information, see our board of activities.</p>"
        },
        {
            "location": "roadmap/#key-areas",
            "title": "Key areas",
            "text": "<p>Security and operational excellence take precedence above all else. This means bug fixing, stability, customer's support, and internal compliance may delay one or more key areas below.</p> <p>Missing something or want us to prioritize an existing area?</p> <p>You can help us prioritize by upvoting existing feature requests, leaving a comment on what use cases it could unblock for you, and by joining our discussions on Discord.</p>"
        },
        {
            "location": "roadmap/#new-features-and-utilities-p0",
            "title": "New features and utilities (p0)",
            "text": "<p>We will create new features and utilities to solve practical problems developers face when building serverless applications.</p> <ul> <li> Ability to buffer logs</li> <li> Async event handlers to streamline complex event-driven workflows across SQS, EventBridge</li> </ul>"
        },
        {
            "location": "roadmap/#powertools-toolchain-p1",
            "title": "Powertools toolchain (p1)",
            "text": "<p>To improve Lambda development workflows and tooling capabilities, we aim to demonstrate how to simplify complex packaging methods, enable OpenAPI code generation for multiple Lambda functions, and introduce profiling tools to evaluate Powertools for AWS Lambda (Python) code implementation, tracking memory consumption and computational performance.</p> <ul> <li> Create a comprehensive \"Recipes\" section with Lambda packaging tutorials for tools like uv, poetry, pants, providing clear, practical build strategies.</li> <li> Enable OpenAPI generation capabilities to create specifications across multiple Lambda functions, eliminating LambdaLith architectural constraints.</li> </ul>"
        },
        {
            "location": "roadmap/#support-for-async-p2",
            "title": "Support for async (p2)",
            "text": "<p>Python's serverless ecosystem is increasingly adopting asynchronous programming to deliver more efficient, non-blocking applications.</p> <ul> <li> Add support for aioboto3 or other tool, enabling efficient, non-blocking AWS service interactions in Lambda functions.</li> <li> Write a PoC with Event Handler support for async.</li> </ul>"
        },
        {
            "location": "roadmap/#roadmap-status-definition",
            "title": "Roadmap status definition",
            "text": "<p> <pre><code>graph LR\n    Ideas --&gt; Backlog --&gt; Work[\"Working on it\"] --&gt; Merged[\"Coming soon\"] --&gt; Shipped</code></pre> Visual representation </p> <p>Within our public board, you'll see the following values in the <code>Status</code> column:</p> <ul> <li>Ideas. Incoming and existing feature requests that are not being actively considered yet. These will be reviewed when bandwidth permits.</li> <li>Backlog. Accepted feature requests or enhancements that we want to work on.</li> <li>Working on it. Features or enhancements we're currently either researching or implementing it.</li> <li>Coming soon. Any feature, enhancement, or bug fixes that have been merged and are coming in the next release.</li> <li>Shipped. Features or enhancements that are now available in the most recent release.</li> </ul> <p>Tasks or issues with empty <code>Status</code> will be categorized in upcoming review cycles.</p>"
        },
        {
            "location": "roadmap/#process",
            "title": "Process",
            "text": "<p> <pre><code>graph LR\n    PFR[Feature request] --&gt; Triage{Need RFC?}\n    Triage --&gt; |Complex/major change or new utility?| RFC[Ask or write RFC] --&gt; Approval{Approved?}\n    Triage --&gt; |Minor feature or enhancement?| NoRFC[No RFC required] --&gt; Approval\n    Approval --&gt; |Yes| Backlog\n    Approval --&gt; |No | Reject[\"Inform next steps\"]\n    Backlog --&gt; |Prioritized| Implementation\n    Backlog --&gt; |Defer| WelcomeContributions[\"help-wanted label\"]</code></pre> Visual representation </p> <p>Our end-to-end mechanism follows four major steps:</p> <ul> <li>Feature Request. Ideas start with a feature request to outline their use case at a high level. For complex use cases, maintainers might ask for/write a RFC.<ul> <li>Maintainers review requests based on project tenets, customers reaction (👍), and use cases.</li> </ul> </li> <li>Request-for-comments (RFC). Design proposals use our RFC issue template to describe its implementation, challenges, developer experience, dependencies, and alternative solutions.<ul> <li>This helps refine the initial idea with community feedback before a decision is made.</li> </ul> </li> <li>Decision. After carefully reviewing and discussing them, maintainers make a final decision on whether to start implementation, defer or reject it, and update everyone with the next steps.</li> <li>Implementation. For approved features, maintainers give priority to the original authors for implementation unless it is a sensitive task that is best handled by maintainers.</li> </ul> See Maintainers document to understand how we triage issues and pull requests, labels and governance."
        },
        {
            "location": "roadmap/#disclaimer",
            "title": "Disclaimer",
            "text": "<p>The Powertools for AWS Lambda (Python) team values feedback and guidance from its community of users, although final decisions on inclusion into the project will be made by AWS.</p> <p>We determine the high-level direction for our open roadmap based on customer feedback and popularity (👍🏽 and comments), security and operational impacts, and business value. Where features don’t meet our goals and longer-term strategy, we will communicate that clearly and openly as quickly as possible with an explanation of why the decision was made.</p>"
        },
        {
            "location": "roadmap/#faqs",
            "title": "FAQs",
            "text": "<p>Q: Why did you build this?</p> <p>A: We know that our customers are making decisions and plans based on what we are developing, and we want to provide our customers the insights they need to plan.</p> <p>Q: Why are there no dates on your roadmap?</p> <p>A: Because job zero is security and operational stability, we can't provide specific target dates for features. The roadmap is subject to change at any time, and roadmap issues in this repository do not guarantee a feature will be launched as proposed.</p> <p>Q: How can I provide feedback or ask for more information?</p> <p>A: For existing features, you can directly comment on issues. For anything else, please open an issue.</p>"
        },
        {
            "location": "security/",
            "title": "Security",
            "text": ""
        },
        {
            "location": "security/#overview",
            "title": "Overview",
            "text": "<p>This page describes our security processes and supply chain practices.</p> <p>We continuously check and evolve our practices, therefore it is possible some diagrams may be eventually consistent.</p>"
        },
        {
            "location": "security/#reporting-a-vulnerability",
            "title": "Reporting a vulnerability",
            "text": "<p>If you discover a potential security issue in this project, we ask that you notify AWS/Amazon Security via our vulnerability reporting page or directly via email to aws-security@amazon.com.</p> <p>Please do not create a public GitHub issue.</p>"
        },
        {
            "location": "security/#supply-chain",
            "title": "Supply chain",
            "text": ""
        },
        {
            "location": "security/#verifying-signed-builds",
            "title": "Verifying signed builds",
            "text": "<p>Starting from v2.20.0 releases, builds are reproducible and signed publicly.</p> <p> <p>Supply Chain Threats visualized by SLSA </p>"
        },
        {
            "location": "security/#terminology",
            "title": "Terminology",
            "text": "<p>We use SLSA to ensure our builds are reproducible and to adhere to supply chain security practices.</p> <p>Within our releases page, you will notice a new metadata file: <code>multiple.intoto.jsonl</code>. It's metadata to describe where, when, and how our build artifacts were produced - or simply, attestation in SLSA terminology.</p> <p>For this to be useful, we need a verification tool - SLSA Verifier. SLSA Verifier decodes attestation to confirm the authenticity, identity, and the steps we took in our release pipeline (e.g., inputs, git commit/branch, GitHub org/repo, build SHA256, etc.).</p>"
        },
        {
            "location": "security/#howto",
            "title": "HOWTO",
            "text": "<p>You can do this manually or automated via a shell script. We maintain the latter to ease adoption in CI systems (feel free to modify to your needs).</p> ManuallyAutomated <ul> <li>Download SLSA Verifier binary</li> <li>Download the latest release artifact from PyPi (either wheel or tar.gz )</li> <li>Download <code>multiple.intoto.jsonl</code> attestation from the latest release under Assets</li> </ul> <p>Next steps assume macOS as the operating system, and release v2.20.0</p> <p>You should have the following files in the current directory:</p> <ul> <li>SLSA Verifier tool: <code>slsa-verifier-darwin-arm64</code></li> <li>Powertools Release artifact: <code>aws_lambda_powertools-2.20.0-py3-none-any.whl</code></li> <li>Powertools attestation: <code>multiple.intoto.jsonl</code></li> </ul> <p>You can now run SLSA Verifier with the following options:</p> <pre><code>./slsa-verifier-darwin-arm64 verify-artifact \\\n    --provenance-path \"multiple.intoto.jsonl\" \\\n    --source-uri github.com/aws-powertools/powertools-lambda-python \\\n    aws_lambda_powertools-2.20.0-py3-none-any.whl\n</code></pre> Verifying a release with verify_provenance.sh script<pre><code>bash verify_provenance.sh 2.20.0\n</code></pre> <p>Wait, what does this script do?</p> <p>I'm glad you asked! It takes the following actions:</p> <ol> <li>Downloads SLSA Verifier using the pinned version (_e.g., 2.3.0)</li> <li>Verifies the integrity of our newly downloaded SLSA Verifier tool</li> <li>Downloads attestation file for the given release version</li> <li>Downloads <code>aws-lambda-powertools</code> release artifact from PyPi for the given release version</li> <li>Runs SLSA Verifier against attestation, GitHub Source, and release binary</li> <li>Cleanup by removing downloaded files to keep your current directory tidy</li> </ol> Expand or click here to see the script source code .github/actions/verify-provenance/verify_provenance.sh<pre><code>#!/bin/bash\nset -uo pipefail # prevent accessing unset env vars, prevent masking pipeline errors to the next command\n\n#docs\n#title              :verify_provenance.sh\n#description        :This script will download and verify a signed Powertools for AWS Lambda (Python) release build with SLSA Verifier\n#author           :@heitorlessa\n#date               :July 1st 2023\n#version            :0.1\n#usage            :bash verify_provenance.sh {release version}\n#notes              :Meant to use in GitHub Actions or locally (MacOS, Linux, WSL).\n#os_version         :Ubuntu 22.04.2 LTS\n#==============================================================================\n\n# Check if RELEASE_VERSION is provided as a command line argument\nif [[ $# -eq 1 ]]; then\n    export readonly RELEASE_VERSION=\"$1\"\nelse\n    echo \"ERROR: Please provider Powertools release version as a command line argument.\"\n    echo \"Example: bash verify_provenance.sh 2.20.0\"\n    exit 1\nfi\n\nexport readonly ARCHITECTURE=$(uname -m | sed 's/x86_64/amd64/g') # arm64, x86_64 -&gt;amd64\nexport readonly OS_NAME=$(uname -s | tr '[:upper:]' '[:lower:]')  # darwin, linux\nexport readonly SLSA_VERIFIER_VERSION=\"2.3.0\"\nexport readonly SLSA_VERIFIER_CHECKSUM_FILE=\"SHA256SUM.md\"\nexport readonly SLSA_VERIFIER_BINARY=\"./slsa-verifier-${OS_NAME}-${ARCHITECTURE}\"\n\nexport readonly RELEASE_BINARY=\"aws_lambda_powertools-${RELEASE_VERSION}-py3-none-any.whl\"\nexport readonly ORG=\"aws-powertools\"\nexport readonly REPO=\"powertools-lambda-python\"\nexport readonly PROVENANCE_FILE=\"multiple.intoto.jsonl\"\n\nexport readonly FILES=(\"${SLSA_VERIFIER_BINARY}\" \"${SLSA_VERIFIER_CHECKSUM_FILE}\" \"${PROVENANCE_FILE}\" \"${RELEASE_BINARY}\")\n\nfunction debug() {\n    TIMESTAMP=$(date -u \"+%FT%TZ\") # 2023-05-10T07:53:59Z\n    echo \"\"${TIMESTAMP}\" DEBUG - [*] $1\"\n}\n\nfunction error() {\n    cleanup\n    TIMESTAMP=$(date -u \"+%FT%TZ\") # 2023-05-10T07:53:59Z\n    echo \"\"${TIMESTAMP}\" ERROR - [!] $1\"\n    echo \"\"${TIMESTAMP}\" ERROR - [!] exiting\"\n    exit 1\n}\n\nfunction download_slsa_verifier() {\n    readonly SLSA_URL=\"https://github.com/slsa-framework/slsa-verifier/releases/download/v${SLSA_VERIFIER_VERSION}/slsa-verifier-${OS_NAME}-${ARCHITECTURE}\"\n    # debug \"Downloading SLSA Verifier for - Binary: slsa-verifier-${OS_NAME}-${ARCHITECTURE}\"\n    debug \"Downloading SLSA Verifier binary: ${SLSA_URL}\"\n    curl \\\n        --location \\\n        --fail \\\n        --silent \\\n        -O \"${SLSA_URL}\" || error \"Failed to download SLSA Verifier binary\"\n\n    readonly SLSA_CHECKSUM_URL=\"https://raw.githubusercontent.com/slsa-framework/slsa-verifier/f59b55ef2190581d40fc1a5f3b7a51cab2f4a652/${SLSA_VERIFIER_CHECKSUM_FILE}\"\n    debug \"Downloading SLSA Verifier checksums\"\n    curl \\\n        --location \\\n        --fail \\\n        --silent \\\n        -O \"${SLSA_CHECKSUM_URL}\" || error \"Failed to download SLSA Verifier binary checksum file\"\n\n    debug \"Verifying SLSA Verifier binary integrity\"\n    CURRENT_HASH=$(sha256sum \"${SLSA_VERIFIER_BINARY}\" | awk '{print $1}')\n    if [[ $(grep \"${CURRENT_HASH}\" \"${SLSA_VERIFIER_CHECKSUM_FILE}\") ]]; then\n        debug \"SLSA Verifier binary integrity confirmed\"\n        chmod +x \"${SLSA_VERIFIER_BINARY}\"\n    else\n        error \"Failed integrity check for SLSA Verifier binary: ${SLSA_VERIFIER_BINARY}\"\n    fi\n}\n\nfunction download_provenance() {\n    readonly PROVENANCE_URL=\"https://github.com/${ORG}/${REPO}/releases/download/v${RELEASE_VERSION}/${PROVENANCE_FILE}\"\n    debug \"Downloading attestation: ${PROVENANCE_URL}\"\n\n    curl \\\n        --location \\\n        --fail \\\n        --silent \\\n        -O ${PROVENANCE_URL} || error \"Failed to download provenance. Does the release already exist?\"\n}\n\nfunction download_release_artifact() {\n    debug \"Downloading ${RELEASE_VERSION} release from PyPi\"\n    python -m pip download \\\n        --only-binary=:all: \\\n        --no-deps \\\n        --quiet \\\n        aws-lambda-powertools==\"${RELEASE_VERSION}\"\n}\n\nfunction verify_provenance() {\n    debug \"Verifying attestation with slsa-verifier\"\n    \"${SLSA_VERIFIER_BINARY}\" verify-artifact \\\n        --provenance-path \"${PROVENANCE_FILE}\" \\\n        --source-uri github.com/${ORG}/${REPO} \\\n        ${RELEASE_BINARY}\n}\n\nfunction cleanup() {\n    debug \"Cleaning up previously downloaded files\"\n    rm -f \"${SLSA_VERIFIER_BINARY}\"\n    rm -f \"${SLSA_VERIFIER_CHECKSUM_FILE}\"\n    rm -f \"${PROVENANCE_FILE}\"\n    rm -f \"${RELEASE_BINARY}\"\n    echo \"${FILES[@]}\" | xargs -n1 echo \"Removed file: \"\n}\n\nfunction main() {\n    download_slsa_verifier\n    download_provenance\n    download_release_artifact\n    verify_provenance\n    cleanup\n}\n\nmain\n\n# Lessons learned\n#\n# 1. If source doesn't match provenance\n#\n# FAILED: SLSA verification failed: source used to generate the binary does not match provenance: expected source 'awslabs/aws-lambda-powertools-python', got 'heitorlessa/aws-lambda-powertools-test'\n#\n# 2. Avoid building deps during download in Test registry endpoints\n#\n# FAILED: Could not find a version that satisfies the requirement poetry-core&gt;=1.3.2 (from versions: 1.2.0)\n#\n</code></pre>"
        },
        {
            "location": "upgrade/",
            "title": "Upgrade guide",
            "text": ""
        },
        {
            "location": "upgrade/#end-of-support-v2",
            "title": "End of support v2",
            "text": "<p>On March 25st, 2025, Powertools for AWS Lambda (Python) v2 reached end of support and will no longer receive updates or releases. If you are still using v2, we strongly recommend you to read our upgrade guide and update to the latest version.</p> <p>Given our commitment to all of our customers using Powertools for AWS Lambda (Python), we will keep Pypi v2 releases and documentation 2.x versions to prevent any disruption.</p>"
        },
        {
            "location": "upgrade/#migrate-to-v3-from-v2",
            "title": "Migrate to v3 from v2",
            "text": "<p>We strongly encourage you to migrate to v3. However, if you still need to upgrade from v1 to v2, you can find the upgrade guide.</p> <p>We've made minimal breaking changes to make your transition to v3 as smooth as possible.</p>"
        },
        {
            "location": "upgrade/#quick-summary",
            "title": "Quick summary",
            "text": "Area Change Code change required Pydantic We have removed support for Pydantic v1 No Parser We have replaced DynamoDBStreamModel <code>AttributeValue</code> with native Python types Yes Parser We no longer export Pydantic objects from <code>parser.pydantic</code>. Yes Lambda layer Lambda layers are now compiled according to the specific Python version and architecture No Event Handler We have deprecated the <code>get_header_value</code> function. Yes Batch Processor <code>@batch_processor</code> and <code>@async_batch_processor</code> decorators are now deprecated Yes Event Source Data Classes We have updated default values for optional fields. Yes Parameters The default cache TTL is now set to 5 minutes No Parameters The <code>config</code> parameter is deprecated in favor of <code>boto_config</code> Yes JMESPath Functions The <code>extract_data_from_envelope</code> function is deprecated in favor of <code>query</code> Yes Types file We have removed the type imports from the <code>shared/types.py</code> file Yes"
        },
        {
            "location": "upgrade/#first-steps",
            "title": "First Steps",
            "text": "<p>Before you start, we suggest making a copy of your current working project or create a new branch with git.</p> <ol> <li>Upgrade Python to at least v3.9.</li> <li>Ensure you have the latest version via Lambda Layer or PyPi.</li> <li>Review the following sections to confirm if you need to make changes to your code.</li> </ol>"
        },
        {
            "location": "upgrade/#drop-support-for-pydantic-v1",
            "title": "Drop support for Pydantic v1",
            "text": "<p>No code changes required</p> <p>As of June 30, 2024, Pydantic v1 has reached its end-of-life, and we have discontinued support for this version. We now exclusively support Pydantic v2.</p> <p>Use Pydantic v2 Migration Guide to migrate your custom Pydantic models to v2.</p>"
        },
        {
            "location": "upgrade/#dynamodbstreammodel-in-parser",
            "title": "DynamoDBStreamModel in parser",
            "text": "<p>This also applies if you're using DynamoDB BatchProcessor.</p> <p><code>DynamoDBStreamModel</code> now returns native Python types when you access DynamoDB records through <code>Keys</code>, <code>NewImage</code>, and <code>OldImage</code> attributes.</p> <p>Previously, you'd receive a raw JSON and need to deserialize each item to the type you'd want for convenience, or to the type DynamoDB stored via <code>get</code> method.</p> <p>With this change, you can access data deserialized as stored in DynamoDB, and no longer need to recursively deserialize nested objects (Maps) if you had them.</p> Note <p>For a lossless conversion of DynamoDB <code>Number</code> type, we follow AWS Python SDK (boto3) approach and convert to <code>Decimal</code>.</p> <pre><code>from __future__ import annotations\n\nimport json\nfrom typing import Any\n\nfrom aws_lambda_powertools.utilities.parser import event_parser\nfrom aws_lambda_powertools.utilities.parser.models import DynamoDBStreamModel\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef send_to_sqs(data: dict):\n    body = json.dumps(data)\n    ...\n\n@event_parser\ndef lambda_handler(event: DynamoDBStreamModel, context: LambdaContext):\n\n    for record in event.Records:\n\n-        # BEFORE - v2\n-        new_image: dict[str, Any] = record.dynamodb.NewImage\n-        event_type = new_image[\"eventType\"][\"S\"]\n-        if event_type == \"PENDING\":\n-            # deserialize attribute value into Python native type\n-            # NOTE: nested objects would need additional logic\n-            data = dict(new_image)\n-            send_to_sqs(data)\n\n+        # NOW - v3\n+        new_image: dict[str, Any] = record.dynamodb.NewImage\n+        if new_image.get(\"eventType\") == \"PENDING\":\n+            send_to_sqs(new_image)  # Here new_image is just a Python Dict type\n</code></pre>"
        },
        {
            "location": "upgrade/#importing-pydantic-objects",
            "title": "Importing Pydantic objects",
            "text": "<p>We have stopped exporting Pydantic objects directly from <code>aws_lambda_powertools.utilities.parser.pydantic</code>. This change prevents customers from accidentally importing all of Pydantic, which could significantly slow down function startup times.</p> <pre><code>- #BEFORE - v2\n- from aws_lambda_powertools.utilities.parser.pydantic import EmailStr\n\n+ # NOW - v3\n+ from pydantic import EmailStr\n</code></pre>"
        },
        {
            "location": "upgrade/#new-aws-lambda-layer-arns",
            "title": "New AWS Lambda Layer ARNs",
            "text": "<p>No code changes required</p> <p>To give you better a better experience, we're now building Powertools for AWS Lambda (Python)'s Lambda layers for specific Python versions (<code>3.9-3.13</code>) and architectures (<code>x86_64</code> &amp; <code>arm64</code>).</p> <p>This also allows us to include architecture-specific versions of both Pydantic v2 and AWS Encryption SDK and give you a more streamlined setup.</p> <p>To take advantage of the new layers, you need to update your functions or deployment setup to include one of the new Lambda layer ARN from the table below:</p> Architecture Python version Layer ARN x86_64 3.9 arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:{version} x86_64 3.10 arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:{version} x86_64 3.11 arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:{version} x86_64 3.12 arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:{version} x86_64 3.13 arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:{version} arm64 3.9 arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:{version} arm64 3.10 arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:{version} arm64 3.11 arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:{version} arm64 3.12 arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:{version} arm64 3.13 arn:aws:lambda:{region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:{version}"
        },
        {
            "location": "upgrade/#event-handler-headers-are-case-insensitive",
            "title": "Event Handler: headers are case-insensitive",
            "text": "<p>According to the HTTP RFC, HTTP headers are case-insensitive. As a result, we have deprecated the <code>get_header_value</code> function to align with this standard. Instead, we recommend using <code>app.current_event.headers.get</code> to access header values directly</p> <p>Consequently, the <code>case_sensitive</code> parameter in this function no longer has any effect, as we now ensure consistent casing by normalizing headers for you. This function will be removed in a future release, and we encourage users to adopt the new method to access header values.</p> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    endpoint = \"https://jsonplaceholder.typicode.com/todos\"\n\n    # BEFORE - v2\n-   api_key: str = app.current_event.get_header_value(name=\"X-Api-Key\", case_sensitive=True, default_value=\"\")\n\n    # NOW - v3\n+   api_key: str = app.current_event.headers.get(\"X-Api-Key\", \"\")\n\n    todos: Response = requests.get(endpoint, headers={\"X-Api-Key\": api_key})\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "upgrade/#deprecated-batch-processing-decorators",
            "title": "Deprecated Batch Processing decorators",
            "text": "<p>In v2, we designated <code>@batch_processor</code> and <code>@async_batch_processor</code> as legacy modes for using the Batch Processing utility.</p> <p>In v3, these have been marked as deprecated. Continuing to use them will result in warnings in your IDE and during Lambda execution.</p> <pre><code>import json\n\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor, process_partial_response\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n-# BEFORE - v2\n-@batch_processor(record_handler=record_handler, processor=processor)\n-def lambda_handler(event, context: LambdaContext):\n-    return processor.response()\n\n+ # NOW - v3\n+def lambda_handler(event, context: LambdaContext):\n+ return process_partial_response(\n+      event=event,\n+      record_handler=record_handler,\n+      processor=processor,\n+      context=context,\n+   )\n</code></pre>"
        },
        {
            "location": "upgrade/#event-source-default-values",
            "title": "Event source default values",
            "text": "<p>We've modified the Event Source Data classes so that optional dictionaries and lists now return empty strings, dictionaries or lists instead of <code>None</code>. This improvement simplifies your code by eliminating the need for conditional checks when accessing these fields, while maintaining backward compatibility with previous implementations.</p> <p>We've applied this change broadly across various event source data classes, ensuring a more consistent and streamlined coding experience for you.</p> <pre><code>from aws_lambda_powertools.utilities.data_classes import DynamoDBStreamEvent, event_source\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@event_source(data_class=DynamoDBStreamEvent)\ndef lambda_handler(event: DynamoDBStreamEvent, context: LambdaContext):\n    for record in event.records:\n\n-        # BEFORE - v2\n-        old_image_type_return_v2 = type(record.dynamodb.old_image)\n-        # Output is &lt;class 'NoneType'&gt;\n\n+        # NOW - v3\n+        old_image_type_return_v3 = type(record.dynamodb.old_image)\n+        # Output is &lt;class 'dict'&gt;\n</code></pre>"
        },
        {
            "location": "upgrade/#parameters-default-cache-ttl-updated-to-5-minutes",
            "title": "Parameters: default cache TTL updated to 5 minutes",
            "text": "<p>No code changes required</p> <p>We have updated the cache TTL from 5 seconds to 5 minutes to reduce the number of API calls to AWS, leading to improved performance and lower costs.</p> <p>No code changes are necessary for this update; however, if you prefer the previous behavior, you can set the <code>max_age</code> parameter back to 5 seconds.</p>"
        },
        {
            "location": "upgrade/#parameters-using-the-new-boto_config-parameter",
            "title": "Parameters: using the new boto_config parameter",
            "text": "<p>In v2, you could use the <code>config</code> parameter to modify the botocore Config session settings.</p> <p>In v3, we renamed this parameter to <code>boto_config</code> to standardize the name with other features, such as Idempotency, and introduced deprecation warnings for users still using <code>config</code>.</p> <pre><code>from botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\n\n-# BEFORE - v2\n-ssm_provider = parameters.SSMProvider(config=Config(region_name=\"us-west-1\"))\n\n+# NOW - v3\n+ssm_provider = parameters.SSMProvider(boto_config=Config(region_name=\"us-west-1\"))\n\ndef handler(event, context):\n    value = ssm_provider.get(\"/my/parameter\")\n    return {\"message\": value}\n</code></pre>"
        },
        {
            "location": "upgrade/#utilizing-the-new-query-function-in-jmespath-functions",
            "title": "Utilizing the new query function in JMESPath Functions",
            "text": "<p>In v2, you could use the <code>extract_data_from_envelope</code> function to search and extract data from dictionaries with JMESPath. This name was too generic and customers told us it was confusing.</p> <p>In v3, we renamed this function to <code>query</code> to align with similar frameworks in the ecosystem, and introduced deprecation warnings for users still using <code>extract_data_from_envelope</code>.</p> <pre><code>from aws_lambda_powertools.utilities.jmespath_utils import extract_data_from_envelope, query\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef handler(event: dict, context: LambdaContext) -&gt; dict:\n-   # BEFORE - v2\n-   some_data = extract_data_from_envelope(data=event, envelope=\"powertools_json(body)\")\n\n+   # NOW - v3\n+   some_data = query(data=event, envelope=\"powertools_json(body)\")\n\n    return {\"data\": some_data}\n</code></pre>"
        },
        {
            "location": "upgrade/#importing-types-from-typing-and-typing_annotations",
            "title": "Importing types from typing and typing_annotations",
            "text": "<p>We refactored our codebase to align with Python guidelines and eliminated the use of <code>aws_lambda_powertools.shared.types</code> imports.</p> <p>Instead, we now utilize types from the standard <code>typing</code> library, which are compatible with Python versions 3.9 and above, or from <code>typing_extensions</code> (included as a required dependency) for additional type support.</p> <pre><code>-# BEFORE - v2\n-from aws_lambda_powertools.shared.types import Annotated\n\n+# NOW - v3\n+from typing_extensions import Annotated\n\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef handler(event: dict, context: LambdaContext) -&gt; dict:\n    ...\n</code></pre>"
        },
        {
            "location": "versioning/",
            "title": "Versioning and maintenance policy",
            "text": ""
        },
        {
            "location": "versioning/#overview",
            "title": "Overview",
            "text": "<p>This document outlines the maintenance policy for Powertools for AWS Lambda and their underlying dependencies. AWS regularly provides Powertools for AWS Lambda with updates that may contain new features, enhancements, bug fixes, security patches, or documentation updates. Updates may also address changes with dependencies, language runtimes, and operating systems. Powertools for AWS Lambda is published to package managers (e.g. PyPi, NPM, Maven, NuGet), and are available as source code on GitHub.</p> <p>We recommend users to stay up-to-date with Powertools for AWS Lambda releases to keep up with the latest features, security updates, and underlying dependencies. Continued use of an unsupported Powertools for AWS Lambda version is not recommended and is done at the user’s discretion.</p> <p>For brevity, we will interchangeably refer to Powertools for AWS Lambda as \"SDK\" (Software Development Toolkit).</p>"
        },
        {
            "location": "versioning/#versioning",
            "title": "Versioning",
            "text": "<p>Powertools for AWS Lambda release versions are in the form of X.Y.Z where X represents the major version. Increasing the major version of an SDK indicates that this SDK underwent significant and substantial changes to support new idioms and patterns in the language. Major versions are introduced when public interfaces (e.g. classes, methods, types, etc.), behaviors, or semantics have changed. Applications need to be updated in order for them to work with the newest SDK version. It is important to update major versions carefully and in accordance with the upgrade guidelines provided by AWS.</p>"
        },
        {
            "location": "versioning/#sdk-major-version-lifecycle",
            "title": "SDK major version lifecycle",
            "text": "<p>The lifecycle for major Powertools for AWS Lambda versions consists of 5 phases, which are outlined below.</p> <ul> <li>Developer Preview (Phase 0) - During this phase, SDKs are not supported, should not be used in production environments, and are meant for early access and feedback purposes only. It is possible for future releases to introduce breaking changes. Once AWS identifies a release to be a stable product, it may mark it as a Release Candidate. Release Candidates are ready for GA release unless significant bugs emerge, and will receive full AWS support.</li> <li>General Availability (GA) (Phase 1) - During this phase, SDKs are fully supported. AWS will provide regular SDK releases that include support for new features, enhancements, as well as bug and security fixes. AWS will support the GA version of an SDK for at least 24 months, unless otherwise specified.</li> <li>Maintenance Announcement (Phase 2) - AWS will make a public announcement at least 6 months before an SDK enters maintenance mode. During this period, the SDK will continue to be fully supported. Typically, maintenance mode is announced at the same time as the next major version is transitioned to GA.</li> <li>Maintenance (Phase 3) - During the maintenance mode, AWS limits SDK releases to address critical bug fixes and security issues only. An SDK will not receive API updates for new or existing services, or be updated to support new regions. Maintenance mode has a default duration of 6 months, unless otherwise specified.</li> <li>End-of-Support (Phase 4) - When an SDK reaches end-of support, it will no longer receive updates or releases. Previously published releases will continue to be available via public package managers and the code will remain on GitHub. The GitHub repository may be archived. Use of an SDK which has reached end-of-support is done at the user’s discretion. We recommend users upgrade to the new major version.</li> </ul> <p>Please note that the timelines shown below are illustrative and not binding</p> <p></p>"
        },
        {
            "location": "versioning/#dependency-lifecycle",
            "title": "Dependency lifecycle",
            "text": "<p>Most AWS SDKs have underlying dependencies, such as language runtimes, AWS Lambda runtime, or third party libraries and frameworks. These dependencies are typically tied to the language community or the vendor who owns that particular component. Each community or vendor publishes their own end-of-support schedule for their product.</p> <p>The following terms are used to classify underlying third party dependencies:</p> <ul> <li>AWS Lambda Runtime: Examples include <code>nodejs20.x</code>, <code>python3.13</code>, etc.</li> <li>Language Runtime: Examples include Python 3.13, NodeJS 20, Java 17, .NET Core, etc.</li> <li>Third party Library: Examples include Pydantic, AWS X-Ray SDK, AWS Encryption SDK, Middy.js, etc.</li> </ul> <p>Powertools for AWS Lambda follows the AWS Lambda Runtime deprecation policy cycle, when it comes to Language Runtime. This means we will stop supporting their respective deprecated Language Runtime (e.g., <code>python37</code>) without increasing the major SDK version.</p> <p>AWS reserves the right to stop support for an underlying dependency without increasing the major SDK version</p>"
        },
        {
            "location": "versioning/#lambda-layer-lifecycle",
            "title": "Lambda layer lifecycle",
            "text": "<p>Powertools for AWS Lambda provides public Lambda layers as an alternative method for including the Powertools SDK into your Lambda functions.</p> <p>Unlike package indexers such as PyPi and NPMJS, which use semantic versioning (e.g., v1.2.3, v1.3.0), Lambda layers employs incrementing sequential versions (e.g., 1, 2, 3, 4). With each new release of the SDK, Powertools for AWS Lambda publishes an updated layer, including the SDK version in the layer description.</p> <p>Powertools for AWS Lambda layers are immutable and remain available beyond their end-of-life dates.</p> <p>Each Powertools for AWS Lambda layer adheres to the versioning policy outlined above.</p>"
        },
        {
            "location": "versioning/#communication-methods",
            "title": "Communication methods",
            "text": "<p>Maintenance announcements are communicated in several ways:</p> <ul> <li>A pinned GitHub Request For Comments (RFC) issue indicating the campaign for the next major version. The RFC will outline the path to end-of-support, specify campaign timelines, and upgrade guidance.</li> <li>AWS SDK documentation, such as API reference documentation, user guides, SDK product marketing pages, and GitHub readme(s) are updated to indicate the campaign timeline and provide guidance on upgrading affected applications.</li> <li>Deprecation warnings are added to the SDKs, outlining the path to end-of-support and linking to the upgrade guide.</li> </ul> <p>To see the list of available major versions of Powertools for AWS Lambda and where they are in their maintenance lifecycle, see version support matrix</p>"
        },
        {
            "location": "versioning/#version-support-matrix",
            "title": "Version support matrix",
            "text": "SDK Major version Current Phase General Availability Date Notes Powertools for AWS Lambda (Python) 2.x End of Support 09/23/2024 See upgrade guide Powertools for AWS Lambda (Python) 2.x Maintenance Announcement 09/25/2024 See announcement Powertools for AWS Lambda (Python) 3.x General Availability 09/23/2024 See Release notes Powertools for AWS Lambda (Python) 3.x Developer Preview See RFC Powertools for AWS Lambda (Python) 2.x General Availability 10/24/2022 See Release Notes Powertools for AWS Lambda (Python) 1.x End of Support 06/18/2020 See RFC and upgrade guide"
        },
        {
            "location": "we_made_this/",
            "title": "We Made This (Community)",
            "text": "<p>This space is dedicated to highlight our awesome community content featuring Powertools for AWS Lambda (Python) 🙏!</p> <p>Get your content featured here!</p>"
        },
        {
            "location": "we_made_this/#connect",
            "title": "Connect",
            "text": "<p>Join us on Discord to connect with the Powertools for AWS Lambda (Python) community 👋. Ask questions, learn from each other, contribute, hang out with key contributors, and more!</p>"
        },
        {
            "location": "we_made_this/#blog-posts",
            "title": "Blog posts",
            "text": ""
        },
        {
            "location": "we_made_this/#aws-lambda-cookbook-following-best-practices-with-powertools-for-aws-lambda",
            "title": "AWS Lambda Cookbook — Following best practices with Powertools for AWS Lambda",
            "text": "<p>Author: Ran Isenberg </p> <p>A collection of articles explaining in detail how Powertools for AWS Lambda helps with a Serverless adoption strategy and its challenges.</p> <ul> <li> <p>Part 1 - Logging</p> </li> <li> <p>Part 2 - Observability: monitoring and tracing</p> </li> <li> <p>Part 3 - Business Domain Observability</p> </li> <li> <p>Part 4 - Environment Variables</p> </li> <li> <p>Part 5 - Input Validation</p> </li> <li> <p>Part 6 - Configuration &amp; Feature Flags</p> </li> <li> <p>Serverless API Idempotency with AWS Powertools for AWS Lambda and CDK</p> </li> <li> <p>Effective Amazon SQS Batch Handling with Powertools for AWS Lambda (Python)</p> </li> <li> <p>Serverless API Documentation with Powertools for AWS Lambda</p> </li> <li> <p>Best practices for accelerating development with serverless blueprints</p> </li> <li> <p>Build a Chatbot with Amazon Bedrock: Automate API Calls Using Powertools for AWS Lambda and CDK</p> </li> </ul>"
        },
        {
            "location": "we_made_this/#making-all-your-apis-idempotent",
            "title": "Making all your APIs idempotent",
            "text": "<p>Author: Michael Walmsley </p> <p>This article dives into what idempotency means for APIs, their use cases, and how to implement them.</p> <ul> <li>blog.walmsles.io/making-all-your-apis-idempotent</li> </ul>"
        },
        {
            "location": "we_made_this/#deep-dive-on-powertools-for-aws-lambda-idempotency-feature",
            "title": "Deep dive on Powertools for AWS Lambda Idempotency feature",
            "text": "<p>Author: Michael Walmsley </p> <p>This article describes how to best calculate your idempotency token, implementation details, and how to handle idempotency in RESTful APIs.</p> <ul> <li>blog.walmsles.io/aws-lambda-powertools-idempotency-a-deeper-dive</li> </ul>"
        },
        {
            "location": "we_made_this/#developing-aws-lambda-functions-with-powertools-for-aws-lambda",
            "title": "Developing AWS Lambda functions with Powertools for AWS Lambda",
            "text": "<p>Author: Stephan Huber </p> <p>This article walks through how to add Powertools to an existing project, covers Tracer, Logger, Metrics, and JSON Schema Validation.</p> <ul> <li>globaldatanet.com/tech-blog/develop-lambda-functions-with-aws-lambda-powertools</li> </ul>"
        },
        {
            "location": "we_made_this/#speed-up-event-driven-projects",
            "title": "Speed-up event-driven projects",
            "text": "<p>Author: Joris Conijn </p> <p>This article walks through a sample AWS EventBridge cookiecutter template presented at the AWS Community Day Netherlands 2022.</p> <ul> <li>binx.io/2022/10/11/speedup-event-driven-projects/</li> <li>Slides</li> </ul>"
        },
        {
            "location": "we_made_this/#implementing-feature-flags-with-aws-appconfig-and-powertools-for-aws-lambda",
            "title": "Implementing Feature Flags with AWS AppConfig and Powertools for AWS Lambda",
            "text": "<p>Author: Ran Isenberg </p> <p>This article walks through how CyberArk uses Powertools to implement Feature Flags with AWS AppConfig</p> <ul> <li>aws.amazon.com/blogs/mt/how-cyberark-implements-feature-flags-with-aws-appconfig</li> </ul>"
        },
        {
            "location": "we_made_this/#designing-for-idempotency",
            "title": "Designing for Idempotency",
            "text": "<p>Author: Valentin Dreismann </p> <p>This article outlines the importance of idempotency, key considerations and trade-offs when implementing in your systems.</p> <ul> <li>Idempotency the right way</li> </ul>"
        },
        {
            "location": "we_made_this/#implementing-idempotency-in-serverless-architectures",
            "title": "Implementing Idempotency in Serverless Architectures",
            "text": "<p>Author: Seongwoo Choi </p> <p>This blog post focuses on the importance of idempotency in distributed services and explores streamlined idempotent request flows. It provides guidance on idempotency tests using duplicate requests.</p> <ul> <li>Implementing Idempotency in Serverless Architectures</li> </ul>"
        },
        {
            "location": "we_made_this/#creating-a-serverless-api-using-powertools-for-aws-lambda-and-aws-cdk",
            "title": "Creating a serverless API using Powertools for AWS Lambda and AWS CDK",
            "text": "<p>This blog post showcases how to use AWS CDK and Powertools for AWS Lambda, along with Amazon API Gateway and AWS Lambda, to effortlessly deploy scalable infrastructure with just a few lines of code.</p> <p>Author: Thomas Taylor </p> <p>Creating a serverless API using Powertools for AWS Lambda and CDK</p>"
        },
        {
            "location": "we_made_this/#boost-app-engagement-with-aws-cloudwatch-metrics-powertools-for-aws",
            "title": "Boost App Engagement with AWS CloudWatch Metrics &amp; Powertools for AWS",
            "text": "<p>This article will guide you through personalizing observability by integrating CloudWatch metrics with Powertools for AWS Lambda into mobile push notifications, a strategy that significantly enhances mobile app engagement</p> <p>Author: Nathan Hanks </p> <p>Creating a serverless API using Powertools for AWS Lambda and CDK</p>"
        },
        {
            "location": "we_made_this/#streaming-data-with-aws-lambda-powertools-for-aws-lambda",
            "title": "Streaming data with AWS Lambda &amp; Powertools for AWS Lambda",
            "text": "<p>This article will walk you through using Powertools for AWS Lambda to optimize your Lambda function when streaming large files from S3.</p> <p>Author: Tom Reid </p> <p>Streaming data with AWS Lambda &amp; Powertools for AWS Lambda</p>"
        },
        {
            "location": "we_made_this/#simplified-data-masking-in-aws-lambda-with-powertools",
            "title": "Simplified Data Masking in AWS Lambda with Powertools",
            "text": "<p>Learn to implement data masking in AWS Lambda with Powertools, protecting sensitive data in healthcare and finance while ensuring compliance with HIPAA and PCI-DSS regulations.</p> <p>Author: Avinash Dalvi </p> <p>Simplified Data Masking in AWS Lambda with Powertools</p>"
        },
        {
            "location": "we_made_this/#videos",
            "title": "Videos",
            "text": ""
        },
        {
            "location": "we_made_this/#building-a-resilient-input-handling-with-parser",
            "title": "Building a resilient input handling with Parser",
            "text": "<p>Author: Ran Isenberg </p> <p>When building applications with AWS Lambda it is critical to verify the data structure and validate the input due to the multiple different sources that can trigger them. In this session Ran Isenberg (CyberArk) will present one of the interesting features of Powertools for AWS Lambda for python: the parser.</p> <p>In this session you will learn how to increase code quality, extensibility and testability, boost you productivity and ship rock solid apps to production.</p>"
        },
        {
            "location": "we_made_this/#talk-dev-to-me-feature-flags-with-powertools-for-aws-lambda",
            "title": "Talk DEV to me | Feature Flags with Powertools for AWS Lambda",
            "text": "<p>Author: Ran Isenberg </p> <p>A deep dive in the Feature Flags feature along with tips and tricks.</p>"
        },
        {
            "location": "we_made_this/#level-up-your-cicd-with-smart-aws-feature-flags",
            "title": "Level Up Your CI/CD With Smart AWS Feature Flags",
            "text": "<p>Author: Ran Isenberg </p> <p>Feature flags can improve your CI/CD process by enabling capabilities otherwise not possible, thus making them an enabler of DevOps and a crucial part of continuous integration. Partial rollouts, A/B testing, and the ability to quickly change a configuration without redeploying code are advantages you gain by using features flags.</p> <p>In this talk, you will learn the added value of using feature flags as part of your CI/CD process and how Powertools for AWS Lambda can help with that.</p>"
        },
        {
            "location": "we_made_this/#aws-reinvent-2023-opn305-the-pragmatic-serverless-python-developer",
            "title": "AWS re:invent 2023 - OPN305 - The Pragmatic Serverless Python Developer",
            "text": "<p>Author: Heitor Lessa &amp; Ran Isenberg</p> <p>Are you developing AWS Lambda functions with Python? Always looking for tools to make you more productive? What if you could hear directly from practitioners?</p> <p>This session covers an opinionated approach to Python project setup, testing, profiling, deployments, and operations. Learn about many open source tools, including Powertools for AWS Lambda—a toolkit that can help you implement serverless best practices and increase developer velocity.</p> <p>Join to discover tools and patterns for effective serverless development with Python. To maximize your learning experience, the session includes a sample application that implements what’s described.</p>"
        },
        {
            "location": "we_made_this/#workshops",
            "title": "Workshops",
            "text": ""
        },
        {
            "location": "we_made_this/#introduction-to-powertools-for-aws-lambda",
            "title": "Introduction to Powertools for AWS Lambda",
            "text": "<p>Author: Michael Walmsley </p> <p>This repo contains documentation for a live coding workshop for the AWS Programming and Tools Meetup in Melbourne. The workshop will start with the SAM Cli \"Hello World\" example API project.</p> <p>Throughout the labs we will introduce each of the Powertools for AWS Lambda Core utilities to showcase how simple they are to use and adopt for all your projects, and how powerful they are at bringing you closer to the Well Architected Serverless Lens.</p> <ul> <li> github.com/walmsles/lambda-powertools-coding-workshop</li> </ul> <p>Walk-through video</p>"
        },
        {
            "location": "we_made_this/#sample-projects",
            "title": "Sample projects",
            "text": ""
        },
        {
            "location": "we_made_this/#complete-lambda-handler-cookbook",
            "title": "Complete Lambda Handler Cookbook",
            "text": "<p>Author: Ran Isenberg </p> <p>This repository provides a working, deployable, open source based, AWS Lambda handler and AWS CDK Python code.</p> <p>This handler embodies Serverless best practices and has all the bells and whistles for a proper production ready handler. It uses many of the Powertools for AWS Lambda utilities for Python.</p> <p> github.com/ran-isenberg/aws-lambda-handler-cookbook</p> <p>Author: Ran Isenberg &amp; Heitor Lessa </p> <p>This project covers an opinionated approach to Python project setup, testing, profiling, deployments, and operations. Learn about many open source tools, including Powertools for AWS Lambda—a toolkit that can help you implement serverless best practices and increase developer velocity.</p> <p>It is based on the AWS Lambda handler cookbook project and served as the examples for the AWS re:invent 2023 session: OPN305 - The pragmatic serverless python developer.</p> <p> https://github.com/ran-isenberg/serverless-python-demo</p>"
        },
        {
            "location": "we_made_this/#serverless-transactional-message-app",
            "title": "Serverless Transactional Message App",
            "text": "<p>Author: Santiago Garcia Arango </p> <p>This repository contains a well documented example of a Transactional Messages App that illustrates how to use Powertools for AWS Lambda to process SQS  messages in batches (with IaC on top of CDK).</p> <p>It uses Powertools for AWS Lambda Logger, Tracing, DataClasses and includes unit tests.</p> <p> github.com/san99tiago/aws-cdk-transactional-messages</p>"
        },
        {
            "location": "api_doc/data_classes/",
            "title": "Event Source Data Classes",
            "text": "<p>Base class for Event Source Data Classes</p> <p>Usage Documentation</p> <p><code>Data classes</code></p> CLASS DESCRIPTION <code>APIGatewayEventIdentity</code> <code>BaseProxyEvent</code> <code>BaseRequestContext</code> <code>BaseRequestContextV2</code> <code>CaseInsensitiveDict</code> <p>Case insensitive dict implementation. Assumes string keys only.</p> <code>DictWrapper</code> <p>Provides a single read only access to a wrapper dict</p> <code>RequestContextClientCert</code> <code>RequestContextV2Http</code>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity",
            "title": "APIGatewayEventIdentity",
            "text": "<pre><code>APIGatewayEventIdentity(\n    data: dict[str, Any],\n    json_deserializer: Callable | None = None,\n)\n</code></pre> <p>               Bases: <code>DictWrapper</code></p> ATTRIBUTE DESCRIPTION <code>account_id</code> <p>The AWS account ID associated with the request.</p> <p> TYPE: <code>str | None</code> </p> <code>api_key</code> <p>For API methods that require an API key, this variable is the API key associated with the method request.</p> <p> TYPE: <code>str | None</code> </p> <code>api_key_id</code> <p>The API key ID associated with an API request that requires an API key.</p> <p> TYPE: <code>str | None</code> </p> <code>caller</code> <p>The principal identifier of the caller making the request.</p> <p> TYPE: <code>str | None</code> </p> <code>cognito_authentication_provider</code> <p>A comma-separated list of the Amazon Cognito authentication providers used by the caller</p> <p> TYPE: <code>str | None</code> </p> <code>cognito_authentication_type</code> <p>The Amazon Cognito authentication type of the caller making the request.</p> <p> TYPE: <code>str | None</code> </p> <code>cognito_identity_id</code> <p>The Amazon Cognito identity ID of the caller making the request.</p> <p> TYPE: <code>str | None</code> </p> <code>cognito_identity_pool_id</code> <p>The Amazon Cognito identity pool ID of the caller making the request.</p> <p> TYPE: <code>str | None</code> </p> <code>principal_org_id</code> <p>The AWS organization ID.</p> <p> TYPE: <code>str | None</code> </p> <code>source_ip</code> <p>The source IP address of the TCP connection making the request to API Gateway.</p> <p> TYPE: <code>str</code> </p> <code>user</code> <p>The principal identifier of the user making the request.</p> <p> TYPE: <code>str | None</code> </p> <code>user_agent</code> <p>The User Agent of the API caller.</p> <p> TYPE: <code>str | None</code> </p> <code>user_arn</code> <p>The Amazon Resource Name (ARN) of the effective user identified after authentication.</p> <p> TYPE: <code>str | None</code> </p> Source code in <code>aws_lambda_powertools/utilities/data_classes/common.py</code> <pre><code>def __init__(self, data: dict[str, Any], json_deserializer: Callable | None = None):\n    \"\"\"\n    Parameters\n    ----------\n    data : dict[str, Any]\n        Lambda Event Source Event payload\n    json_deserializer : Callable, optional\n        function to deserialize `str`, `bytes`, `bytearray` containing a JSON document to a Python `obj`,\n        by default json.loads\n    \"\"\"\n    self._data = data\n    self._json_deserializer = json_deserializer or json.loads\n</code></pre>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.account_id",
            "title": "account_id  <code>property</code>",
            "text": "<pre><code>account_id: str | None\n</code></pre> <p>The AWS account ID associated with the request.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.api_key",
            "title": "api_key  <code>property</code>",
            "text": "<pre><code>api_key: str | None\n</code></pre> <p>For API methods that require an API key, this variable is the API key associated with the method request. For methods that don't require an API key, this variable is null.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.api_key_id",
            "title": "api_key_id  <code>property</code>",
            "text": "<pre><code>api_key_id: str | None\n</code></pre> <p>The API key ID associated with an API request that requires an API key.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.caller",
            "title": "caller  <code>property</code>",
            "text": "<pre><code>caller: str | None\n</code></pre> <p>The principal identifier of the caller making the request.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.cognito_authentication_provider",
            "title": "cognito_authentication_provider  <code>property</code>",
            "text": "<pre><code>cognito_authentication_provider: str | None\n</code></pre> <p>A comma-separated list of the Amazon Cognito authentication providers used by the caller making the request. Available only if the request was signed with Amazon Cognito credentials.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.cognito_authentication_type",
            "title": "cognito_authentication_type  <code>property</code>",
            "text": "<pre><code>cognito_authentication_type: str | None\n</code></pre> <p>The Amazon Cognito authentication type of the caller making the request. Available only if the request was signed with Amazon Cognito credentials.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.cognito_identity_id",
            "title": "cognito_identity_id  <code>property</code>",
            "text": "<pre><code>cognito_identity_id: str | None\n</code></pre> <p>The Amazon Cognito identity ID of the caller making the request. Available only if the request was signed with Amazon Cognito credentials.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.cognito_identity_pool_id",
            "title": "cognito_identity_pool_id  <code>property</code>",
            "text": "<pre><code>cognito_identity_pool_id: str | None\n</code></pre> <p>The Amazon Cognito identity pool ID of the caller making the request. Available only if the request was signed with Amazon Cognito credentials.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.principal_org_id",
            "title": "principal_org_id  <code>property</code>",
            "text": "<pre><code>principal_org_id: str | None\n</code></pre> <p>The AWS organization ID.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.source_ip",
            "title": "source_ip  <code>property</code>",
            "text": "<pre><code>source_ip: str\n</code></pre> <p>The source IP address of the TCP connection making the request to API Gateway.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.user",
            "title": "user  <code>property</code>",
            "text": "<pre><code>user: str | None\n</code></pre> <p>The principal identifier of the user making the request.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.user_agent",
            "title": "user_agent  <code>property</code>",
            "text": "<pre><code>user_agent: str | None\n</code></pre> <p>The User Agent of the API caller.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.APIGatewayEventIdentity.user_arn",
            "title": "user_arn  <code>property</code>",
            "text": "<pre><code>user_arn: str | None\n</code></pre> <p>The Amazon Resource Name (ARN) of the effective user identified after authentication.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseProxyEvent",
            "title": "BaseProxyEvent",
            "text": "<pre><code>BaseProxyEvent(\n    data: dict[str, Any],\n    json_deserializer: Callable | None = None,\n)\n</code></pre> <p>               Bases: <code>DictWrapper</code></p> METHOD DESCRIPTION <code>get_header_value</code> <p>Get header value by name</p> <code>get_multi_value_query_string_values</code> <p>Get multi-value query string parameter values by name</p> <code>get_query_string_value</code> <p>Get query string value by name</p> ATTRIBUTE DESCRIPTION <code>body</code> <p>Submitted body of the request as a string</p> <p> TYPE: <code>str | None</code> </p> <code>decoded_body</code> <p>Decode the body from base64 if encoded, otherwise return it as is.</p> <p> TYPE: <code>str | None</code> </p> <code>http_method</code> <p>The HTTP method used. Valid values include: DELETE, GET, HEAD, OPTIONS, PATCH, POST, and PUT.</p> <p> TYPE: <code>str</code> </p> <code>json_body</code> <p>Parses the submitted body as json</p> <p> TYPE: <code>Any</code> </p> <code>resolved_headers_field</code> <p>This property determines the appropriate header to be used</p> <p> TYPE: <code>dict[str, str]</code> </p> <code>resolved_query_string_parameters</code> <p>This property determines the appropriate query string parameter to be used</p> <p> TYPE: <code>dict[str, list[str]]</code> </p> Source code in <code>aws_lambda_powertools/utilities/data_classes/common.py</code> <pre><code>def __init__(self, data: dict[str, Any], json_deserializer: Callable | None = None):\n    \"\"\"\n    Parameters\n    ----------\n    data : dict[str, Any]\n        Lambda Event Source Event payload\n    json_deserializer : Callable, optional\n        function to deserialize `str`, `bytes`, `bytearray` containing a JSON document to a Python `obj`,\n        by default json.loads\n    \"\"\"\n    self._data = data\n    self._json_deserializer = json_deserializer or json.loads\n</code></pre>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseProxyEvent.body",
            "title": "body  <code>property</code>",
            "text": "<pre><code>body: str | None\n</code></pre> <p>Submitted body of the request as a string</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseProxyEvent.decoded_body",
            "title": "decoded_body  <code>cached</code> <code>property</code>",
            "text": "<pre><code>decoded_body: str | None\n</code></pre> <p>Decode the body from base64 if encoded, otherwise return it as is.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseProxyEvent.http_method",
            "title": "http_method  <code>property</code>",
            "text": "<pre><code>http_method: str\n</code></pre> <p>The HTTP method used. Valid values include: DELETE, GET, HEAD, OPTIONS, PATCH, POST, and PUT.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseProxyEvent.json_body",
            "title": "json_body  <code>cached</code> <code>property</code>",
            "text": "<pre><code>json_body: Any\n</code></pre> <p>Parses the submitted body as json</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseProxyEvent.resolved_headers_field",
            "title": "resolved_headers_field  <code>property</code>",
            "text": "<pre><code>resolved_headers_field: dict[str, str]\n</code></pre> <p>This property determines the appropriate header to be used as a trusted source for validating OpenAPI.</p> <p>This is necessary because different resolvers use different formats to encode headers parameters.</p> <p>Headers are case-insensitive according to RFC 7540 (HTTP/2), so we lower the header name This ensures that customers can access headers with any casing, as per the RFC guidelines. Reference: https://www.rfc-editor.org/rfc/rfc7540#section-8.1.2</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseProxyEvent.resolved_query_string_parameters",
            "title": "resolved_query_string_parameters  <code>cached</code> <code>property</code>",
            "text": "<pre><code>resolved_query_string_parameters: dict[str, list[str]]\n</code></pre> <p>This property determines the appropriate query string parameter to be used as a trusted source for validating OpenAPI.</p> <p>This is necessary because different resolvers use different formats to encode multi query string parameters.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseProxyEvent.get_header_value",
            "title": "get_header_value",
            "text": "<pre><code>get_header_value(\n    name: str,\n    default_value: str,\n    case_sensitive: bool = False,\n) -&gt; str\n</code></pre><pre><code>get_header_value(\n    name: str,\n    default_value: str | None = None,\n    case_sensitive: bool = False,\n) -&gt; str | None\n</code></pre> <pre><code>get_header_value(\n    name: str,\n    default_value: str | None = None,\n    case_sensitive: bool = False,\n) -&gt; str | None\n</code></pre> <p>Get header value by name</p> PARAMETER DESCRIPTION <code>name</code> <p>Header name</p> <p> TYPE: <code>str</code> </p> <code>default_value</code> <p>Default value if no value was found by name</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>case_sensitive</code> <p>Whether to use a case-sensitive look up. By default we make a case-insensitive lookup.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>(str, optional)</code> <p>Header value</p> Source code in <code>aws_lambda_powertools/utilities/data_classes/common.py</code> <pre><code>@deprecated(\n    \"`get_header_value` function is deprecated; Access headers directly using event.headers.get('HeaderName')\",\n    category=None,\n)\ndef get_header_value(\n    self,\n    name: str,\n    default_value: str | None = None,\n    case_sensitive: bool = False,\n) -&gt; str | None:\n    \"\"\"Get header value by name\n    Parameters\n    ----------\n    name: str\n        Header name\n    default_value: str, optional\n        Default value if no value was found by name\n    case_sensitive: bool\n        Whether to use a case-sensitive look up. By default we make a case-insensitive lookup.\n    Returns\n    -------\n    str, optional\n        Header value\n    \"\"\"\n    warnings.warn(\n        \"The `get_header_value` function is deprecated in V3 and the `case_sensitive` parameter \"\n        \"no longer has any effect. This function will be removed in the next major version. \"\n        \"Instead, access headers directly using event.headers.get('HeaderName'), which is case insensitive.\",\n        category=PowertoolsDeprecationWarning,\n        stacklevel=2,\n    )\n    return get_header_value(\n        headers=self.headers,\n        name=name,\n        default_value=default_value,\n        case_sensitive=case_sensitive,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseProxyEvent.get_multi_value_query_string_values",
            "title": "get_multi_value_query_string_values",
            "text": "<pre><code>get_multi_value_query_string_values(\n    name: str, default_values: list[str] | None = None\n) -&gt; list[str]\n</code></pre> <p>Get multi-value query string parameter values by name</p> PARAMETER DESCRIPTION <code>name</code> <p>Multi-Value query string parameter name</p> <p> TYPE: <code>str</code> </p> <code>default_values</code> <p>Default values is no values are found by name</p> <p> TYPE: <code>list[str] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>(List[str], optional)</code> <p>List of query string values</p> Source code in <code>aws_lambda_powertools/utilities/data_classes/common.py</code> <pre><code>def get_multi_value_query_string_values(\n    self,\n    name: str,\n    default_values: list[str] | None = None,\n) -&gt; list[str]:\n    \"\"\"Get multi-value query string parameter values by name\n    Parameters\n    ----------\n    name: str\n        Multi-Value query string parameter name\n    default_values: List[str], optional\n        Default values is no values are found by name\n    Returns\n    -------\n    List[str], optional\n        List of query string values\n    \"\"\"\n    return get_multi_value_query_string_values(\n        multi_value_query_string_parameters=self.multi_value_query_string_parameters,\n        name=name,\n        default_values=default_values,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseProxyEvent.get_query_string_value",
            "title": "get_query_string_value",
            "text": "<pre><code>get_query_string_value(\n    name: str, default_value: str\n) -&gt; str\n</code></pre><pre><code>get_query_string_value(\n    name: str, default_value: str | None = None\n) -&gt; str | None\n</code></pre> <pre><code>get_query_string_value(\n    name: str, default_value: str | None = None\n) -&gt; str | None\n</code></pre> <p>Get query string value by name</p> PARAMETER DESCRIPTION <code>name</code> <p>Query string parameter name</p> <p> TYPE: <code>str</code> </p> <code>default_value</code> <p>Default value if no value was found by name</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>(str, optional)</code> <p>Query string parameter value</p> Source code in <code>aws_lambda_powertools/utilities/data_classes/common.py</code> <pre><code>def get_query_string_value(self, name: str, default_value: str | None = None) -&gt; str | None:\n    \"\"\"Get query string value by name\n    Parameters\n    ----------\n    name: str\n        Query string parameter name\n    default_value: str, optional\n        Default value if no value was found by name\n    Returns\n    -------\n    str, optional\n        Query string parameter value\n    \"\"\"\n    return get_query_string_value(\n        query_string_parameters=self.query_string_parameters,\n        name=name,\n        default_value=default_value,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContext",
            "title": "BaseRequestContext",
            "text": "<pre><code>BaseRequestContext(\n    data: dict[str, Any],\n    json_deserializer: Callable | None = None,\n)\n</code></pre> <p>               Bases: <code>DictWrapper</code></p> ATTRIBUTE DESCRIPTION <code>account_id</code> <p>The AWS account ID associated with the request.</p> <p> TYPE: <code>str</code> </p> <code>api_id</code> <p>The identifier API Gateway assigns to your API.</p> <p> TYPE: <code>str</code> </p> <code>domain_name</code> <p>A domain name</p> <p> TYPE: <code>str | None</code> </p> <code>extended_request_id</code> <p>An automatically generated ID for the API call, which contains more useful information</p> <p> TYPE: <code>str | None</code> </p> <code>http_method</code> <p>The HTTP method used. Valid values include: DELETE, GET, HEAD, OPTIONS, PATCH, POST, and PUT.</p> <p> TYPE: <code>str</code> </p> <code>protocol</code> <p>The request protocol, for example, HTTP/1.1.</p> <p> TYPE: <code>str</code> </p> <code>request_id</code> <p>The ID that API Gateway assigns to the API request.</p> <p> TYPE: <code>str</code> </p> <code>request_time</code> <p>The CLF-formatted request time (dd/MMM/yyyy:HH:mm:ss +-hhmm)</p> <p> TYPE: <code>str | None</code> </p> <code>request_time_epoch</code> <p>The Epoch-formatted request time.</p> <p> TYPE: <code>int</code> </p> <code>stage</code> <p>The deployment stage of the API request</p> <p> TYPE: <code>str</code> </p> Source code in <code>aws_lambda_powertools/utilities/data_classes/common.py</code> <pre><code>def __init__(self, data: dict[str, Any], json_deserializer: Callable | None = None):\n    \"\"\"\n    Parameters\n    ----------\n    data : dict[str, Any]\n        Lambda Event Source Event payload\n    json_deserializer : Callable, optional\n        function to deserialize `str`, `bytes`, `bytearray` containing a JSON document to a Python `obj`,\n        by default json.loads\n    \"\"\"\n    self._data = data\n    self._json_deserializer = json_deserializer or json.loads\n</code></pre>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContext.account_id",
            "title": "account_id  <code>property</code>",
            "text": "<pre><code>account_id: str\n</code></pre> <p>The AWS account ID associated with the request.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContext.api_id",
            "title": "api_id  <code>property</code>",
            "text": "<pre><code>api_id: str\n</code></pre> <p>The identifier API Gateway assigns to your API.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContext.domain_name",
            "title": "domain_name  <code>property</code>",
            "text": "<pre><code>domain_name: str | None\n</code></pre> <p>A domain name</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContext.extended_request_id",
            "title": "extended_request_id  <code>property</code>",
            "text": "<pre><code>extended_request_id: str | None\n</code></pre> <p>An automatically generated ID for the API call, which contains more useful information for debugging/troubleshooting.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContext.http_method",
            "title": "http_method  <code>property</code>",
            "text": "<pre><code>http_method: str\n</code></pre> <p>The HTTP method used. Valid values include: DELETE, GET, HEAD, OPTIONS, PATCH, POST, and PUT.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContext.protocol",
            "title": "protocol  <code>property</code>",
            "text": "<pre><code>protocol: str\n</code></pre> <p>The request protocol, for example, HTTP/1.1.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContext.request_id",
            "title": "request_id  <code>property</code>",
            "text": "<pre><code>request_id: str\n</code></pre> <p>The ID that API Gateway assigns to the API request.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContext.request_time",
            "title": "request_time  <code>property</code>",
            "text": "<pre><code>request_time: str | None\n</code></pre> <p>The CLF-formatted request time (dd/MMM/yyyy:HH:mm:ss +-hhmm)</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContext.request_time_epoch",
            "title": "request_time_epoch  <code>property</code>",
            "text": "<pre><code>request_time_epoch: int\n</code></pre> <p>The Epoch-formatted request time.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContext.stage",
            "title": "stage  <code>property</code>",
            "text": "<pre><code>stage: str\n</code></pre> <p>The deployment stage of the API request</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContextV2",
            "title": "BaseRequestContextV2",
            "text": "<pre><code>BaseRequestContextV2(\n    data: dict[str, Any],\n    json_deserializer: Callable | None = None,\n)\n</code></pre> <p>               Bases: <code>DictWrapper</code></p> ATTRIBUTE DESCRIPTION <code>account_id</code> <p>The AWS account ID associated with the request.</p> <p> TYPE: <code>str</code> </p> <code>api_id</code> <p>The identifier API Gateway assigns to your API.</p> <p> TYPE: <code>str</code> </p> <code>authentication</code> <p>Optional when using mutual TLS authentication</p> <p> TYPE: <code>RequestContextClientCert | None</code> </p> <code>domain_name</code> <p>A domain name</p> <p> TYPE: <code>str</code> </p> <code>request_id</code> <p>The ID that API Gateway assigns to the API request.</p> <p> TYPE: <code>str</code> </p> <code>route_key</code> <p>The selected route key.</p> <p> TYPE: <code>str</code> </p> <code>stage</code> <p>The deployment stage of the API request</p> <p> TYPE: <code>str</code> </p> <code>time</code> <p>The CLF-formatted request time (dd/MMM/yyyy:HH:mm:ss +-hhmm).</p> <p> TYPE: <code>str</code> </p> <code>time_epoch</code> <p>The Epoch-formatted request time.</p> <p> TYPE: <code>int</code> </p> Source code in <code>aws_lambda_powertools/utilities/data_classes/common.py</code> <pre><code>def __init__(self, data: dict[str, Any], json_deserializer: Callable | None = None):\n    \"\"\"\n    Parameters\n    ----------\n    data : dict[str, Any]\n        Lambda Event Source Event payload\n    json_deserializer : Callable, optional\n        function to deserialize `str`, `bytes`, `bytearray` containing a JSON document to a Python `obj`,\n        by default json.loads\n    \"\"\"\n    self._data = data\n    self._json_deserializer = json_deserializer or json.loads\n</code></pre>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContextV2.account_id",
            "title": "account_id  <code>property</code>",
            "text": "<pre><code>account_id: str\n</code></pre> <p>The AWS account ID associated with the request.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContextV2.api_id",
            "title": "api_id  <code>property</code>",
            "text": "<pre><code>api_id: str\n</code></pre> <p>The identifier API Gateway assigns to your API.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContextV2.authentication",
            "title": "authentication  <code>property</code>",
            "text": "<pre><code>authentication: RequestContextClientCert | None\n</code></pre> <p>Optional when using mutual TLS authentication</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContextV2.domain_name",
            "title": "domain_name  <code>property</code>",
            "text": "<pre><code>domain_name: str\n</code></pre> <p>A domain name</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContextV2.request_id",
            "title": "request_id  <code>property</code>",
            "text": "<pre><code>request_id: str\n</code></pre> <p>The ID that API Gateway assigns to the API request.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContextV2.route_key",
            "title": "route_key  <code>property</code>",
            "text": "<pre><code>route_key: str\n</code></pre> <p>The selected route key.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContextV2.stage",
            "title": "stage  <code>property</code>",
            "text": "<pre><code>stage: str\n</code></pre> <p>The deployment stage of the API request</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContextV2.time",
            "title": "time  <code>property</code>",
            "text": "<pre><code>time: str\n</code></pre> <p>The CLF-formatted request time (dd/MMM/yyyy:HH:mm:ss +-hhmm).</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.BaseRequestContextV2.time_epoch",
            "title": "time_epoch  <code>property</code>",
            "text": "<pre><code>time_epoch: int\n</code></pre> <p>The Epoch-formatted request time.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.CaseInsensitiveDict",
            "title": "CaseInsensitiveDict",
            "text": "<pre><code>CaseInsensitiveDict(data=None, **kwargs)\n</code></pre> <p>               Bases: <code>dict</code></p> <p>Case insensitive dict implementation. Assumes string keys only.</p> Source code in <code>aws_lambda_powertools/utilities/data_classes/common.py</code> <pre><code>def __init__(self, data=None, **kwargs):\n    super().__init__()\n    self.update(data, **kwargs)\n</code></pre>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.DictWrapper",
            "title": "DictWrapper",
            "text": "<pre><code>DictWrapper(\n    data: dict[str, Any],\n    json_deserializer: Callable | None = None,\n)\n</code></pre> <p>               Bases: <code>Mapping</code></p> <p>Provides a single read only access to a wrapper dict</p> <p>data : dict[str, Any]     Lambda Event Source Event payload json_deserializer : Callable, optional     function to deserialize <code>str</code>, <code>bytes</code>, <code>bytearray</code> containing a JSON document to a Python <code>obj</code>,     by default json.loads</p> ATTRIBUTE DESCRIPTION <code>raw_event</code> <p>The original raw event dict</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>aws_lambda_powertools/utilities/data_classes/common.py</code> <pre><code>def __init__(self, data: dict[str, Any], json_deserializer: Callable | None = None):\n    \"\"\"\n    Parameters\n    ----------\n    data : dict[str, Any]\n        Lambda Event Source Event payload\n    json_deserializer : Callable, optional\n        function to deserialize `str`, `bytes`, `bytearray` containing a JSON document to a Python `obj`,\n        by default json.loads\n    \"\"\"\n    self._data = data\n    self._json_deserializer = json_deserializer or json.loads\n</code></pre>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.DictWrapper.raw_event",
            "title": "raw_event  <code>property</code>",
            "text": "<pre><code>raw_event: dict[str, Any]\n</code></pre> <p>The original raw event dict</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.RequestContextClientCert",
            "title": "RequestContextClientCert",
            "text": "<pre><code>RequestContextClientCert(\n    data: dict[str, Any],\n    json_deserializer: Callable | None = None,\n)\n</code></pre> <p>               Bases: <code>DictWrapper</code></p> ATTRIBUTE DESCRIPTION <code>client_cert_pem</code> <p>Client certificate pem</p> <p> TYPE: <code>str</code> </p> <code>issuer_dn</code> <p>Issuer Distinguished Name</p> <p> TYPE: <code>str</code> </p> <code>serial_number</code> <p>Unique serial number for client cert</p> <p> TYPE: <code>str</code> </p> <code>subject_dn</code> <p>Subject Distinguished Name</p> <p> TYPE: <code>str</code> </p> <code>validity_not_after</code> <p>Date when the cert is no longer valid</p> <p> TYPE: <code>str</code> </p> <code>validity_not_before</code> <p>Cert is not valid before this date</p> <p> TYPE: <code>str</code> </p> Source code in <code>aws_lambda_powertools/utilities/data_classes/common.py</code> <pre><code>def __init__(self, data: dict[str, Any], json_deserializer: Callable | None = None):\n    \"\"\"\n    Parameters\n    ----------\n    data : dict[str, Any]\n        Lambda Event Source Event payload\n    json_deserializer : Callable, optional\n        function to deserialize `str`, `bytes`, `bytearray` containing a JSON document to a Python `obj`,\n        by default json.loads\n    \"\"\"\n    self._data = data\n    self._json_deserializer = json_deserializer or json.loads\n</code></pre>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.RequestContextClientCert.client_cert_pem",
            "title": "client_cert_pem  <code>property</code>",
            "text": "<pre><code>client_cert_pem: str\n</code></pre> <p>Client certificate pem</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.RequestContextClientCert.issuer_dn",
            "title": "issuer_dn  <code>property</code>",
            "text": "<pre><code>issuer_dn: str\n</code></pre> <p>Issuer Distinguished Name</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.RequestContextClientCert.serial_number",
            "title": "serial_number  <code>property</code>",
            "text": "<pre><code>serial_number: str\n</code></pre> <p>Unique serial number for client cert</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.RequestContextClientCert.subject_dn",
            "title": "subject_dn  <code>property</code>",
            "text": "<pre><code>subject_dn: str\n</code></pre> <p>Subject Distinguished Name</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.RequestContextClientCert.validity_not_after",
            "title": "validity_not_after  <code>property</code>",
            "text": "<pre><code>validity_not_after: str\n</code></pre> <p>Date when the cert is no longer valid</p> <p>eg: Aug  5 00:28:21 2120 GMT</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.RequestContextClientCert.validity_not_before",
            "title": "validity_not_before  <code>property</code>",
            "text": "<pre><code>validity_not_before: str\n</code></pre> <p>Cert is not valid before this date</p> <p>eg: Aug 29 00:28:21 2020 GMT</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.RequestContextV2Http",
            "title": "RequestContextV2Http",
            "text": "<pre><code>RequestContextV2Http(\n    data: dict[str, Any],\n    json_deserializer: Callable | None = None,\n)\n</code></pre> <p>               Bases: <code>DictWrapper</code></p> ATTRIBUTE DESCRIPTION <code>protocol</code> <p>The request protocol, for example, HTTP/1.1.</p> <p> TYPE: <code>str</code> </p> <code>source_ip</code> <p>The source IP address of the TCP connection making the request to API Gateway.</p> <p> TYPE: <code>str</code> </p> <code>user_agent</code> <p>The User Agent of the API caller.</p> <p> TYPE: <code>str</code> </p> Source code in <code>aws_lambda_powertools/utilities/data_classes/common.py</code> <pre><code>def __init__(self, data: dict[str, Any], json_deserializer: Callable | None = None):\n    \"\"\"\n    Parameters\n    ----------\n    data : dict[str, Any]\n        Lambda Event Source Event payload\n    json_deserializer : Callable, optional\n        function to deserialize `str`, `bytes`, `bytearray` containing a JSON document to a Python `obj`,\n        by default json.loads\n    \"\"\"\n    self._data = data\n    self._json_deserializer = json_deserializer or json.loads\n</code></pre>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.RequestContextV2Http.protocol",
            "title": "protocol  <code>property</code>",
            "text": "<pre><code>protocol: str\n</code></pre> <p>The request protocol, for example, HTTP/1.1.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.RequestContextV2Http.source_ip",
            "title": "source_ip  <code>property</code>",
            "text": "<pre><code>source_ip: str\n</code></pre> <p>The source IP address of the TCP connection making the request to API Gateway.</p>"
        },
        {
            "location": "api_doc/data_classes/#aws_lambda_powertools.utilities.data_classes.common.RequestContextV2Http.user_agent",
            "title": "user_agent  <code>property</code>",
            "text": "<pre><code>user_agent: str\n</code></pre> <p>The User Agent of the API caller.</p>"
        },
        {
            "location": "api_doc/jmespath_functions/",
            "title": "JMESPath Functions",
            "text": "<p>Built-in JMESPath Functions to easily deserialize common encoded JSON payloads in Lambda functions.</p> <p>Usage Documentation</p> <p><code>JMESPath Functions</code></p> FUNCTION DESCRIPTION <code>extract_data_from_envelope</code> <p>Searches and extracts data using JMESPath</p> <code>query</code> <p>Searches and extracts data using JMESPath</p>"
        },
        {
            "location": "api_doc/jmespath_functions/#aws_lambda_powertools.utilities.jmespath_utils.extract_data_from_envelope",
            "title": "extract_data_from_envelope",
            "text": "<pre><code>extract_data_from_envelope(\n    data: dict | str,\n    envelope: str,\n    jmespath_options: dict | None = None,\n) -&gt; Any\n</code></pre> <p>Searches and extracts data using JMESPath</p> <p>Deprecated: Use query instead</p> Source code in <code>aws_lambda_powertools/utilities/jmespath_utils/__init__.py</code> <pre><code>@deprecated(\"`extract_data_from_envelope` is deprecated; use `query` instead.\", category=None)\ndef extract_data_from_envelope(data: dict | str, envelope: str, jmespath_options: dict | None = None) -&gt; Any:\n    \"\"\"Searches and extracts data using JMESPath\n\n    *Deprecated*: Use query instead\n    \"\"\"\n    warnings.warn(\n        \"The extract_data_from_envelope method is deprecated in V3 \"\n        \"and will be removed in the next major version. Use query instead.\",\n        category=PowertoolsDeprecationWarning,\n        stacklevel=2,\n    )\n\n    return query(data=data, envelope=envelope, jmespath_options=jmespath_options)\n</code></pre>"
        },
        {
            "location": "api_doc/jmespath_functions/#aws_lambda_powertools.utilities.jmespath_utils.query",
            "title": "query",
            "text": "<pre><code>query(\n    data: dict | str,\n    envelope: str,\n    jmespath_options: dict | None = None,\n) -&gt; Any\n</code></pre> <p>Searches and extracts data using JMESPath</p> <p>Envelope being the JMESPath expression to extract the data you're after</p> <p>Built-in JMESPath functions include: powertools_json, powertools_base64, powertools_base64_gzip</p> Example <p>Deserialize JSON string and extracts data from body key</p> <pre><code>from aws_lambda_powertools.utilities.jmespath_utils import query\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef handler(event: dict, context: LambdaContext):\n    # event = {\"body\": \"{\"customerId\":\"dd4649e6-2484-4993-acb8-0f9123103394\"}\"}  # noqa: ERA001\n    payload = query(data=event, envelope=\"powertools_json(body)\")\n    customer = payload.get(\"customerId\")  # now deserialized\n    ...\n</code></pre> PARAMETER DESCRIPTION <code>data</code> <p>Data set to be filtered</p> <p> TYPE: <code>dict | str</code> </p> <code>envelope</code> <p>JMESPath expression to filter data against</p> <p> TYPE: <code>str</code> </p> <code>jmespath_options</code> <p>Alternative JMESPath options to be included when filtering expr</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>Data found using JMESPath expression given in envelope</p> Source code in <code>aws_lambda_powertools/utilities/jmespath_utils/__init__.py</code> <pre><code>def query(data: dict | str, envelope: str, jmespath_options: dict | None = None) -&gt; Any:\n    \"\"\"Searches and extracts data using JMESPath\n\n    Envelope being the JMESPath expression to extract the data you're after\n\n    Built-in JMESPath functions include: powertools_json, powertools_base64, powertools_base64_gzip\n\n    Example\n    --------\n\n    **Deserialize JSON string and extracts data from body key**\n\n        from aws_lambda_powertools.utilities.jmespath_utils import query\n        from aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n        def handler(event: dict, context: LambdaContext):\n            # event = {\"body\": \"{\\\"customerId\\\":\\\"dd4649e6-2484-4993-acb8-0f9123103394\\\"}\"}  # noqa: ERA001\n            payload = query(data=event, envelope=\"powertools_json(body)\")\n            customer = payload.get(\"customerId\")  # now deserialized\n            ...\n\n    Parameters\n    ----------\n    data : dict | str\n        Data set to be filtered\n    envelope : str\n        JMESPath expression to filter data against\n    jmespath_options : dict | None\n        Alternative JMESPath options to be included when filtering expr\n\n\n    Returns\n    -------\n    Any\n        Data found using JMESPath expression given in envelope\n    \"\"\"\n    if not jmespath_options:\n        jmespath_options = {\"custom_functions\": PowertoolsFunctions()}\n\n    try:\n        logger.debug(f\"Envelope detected: {envelope}. JMESPath options: {jmespath_options}\")\n        return jmespath.search(envelope, data, options=jmespath.Options(**jmespath_options))\n    except (LexerError, TypeError, UnicodeError) as e:\n        message = f\"Failed to unwrap event from envelope using expression. Error: {e} Exp: {envelope}, Data: {data}\"  # noqa: B306, E501\n        raise InvalidEnvelopeExpressionError(message)\n</code></pre>"
        },
        {
            "location": "api_doc/middleware_factory/",
            "title": "Middleware Factory",
            "text": "<p>Utilities to enhance middleware</p> <p>Usage Documentation</p> <p><code>Middleware Factory</code></p> MODULE DESCRIPTION <code>exceptions</code> <code>factory</code> FUNCTION DESCRIPTION <code>lambda_handler_decorator</code> <p>Decorator factory for decorating Lambda handlers.</p>"
        },
        {
            "location": "api_doc/middleware_factory/#aws_lambda_powertools.middleware_factory.lambda_handler_decorator",
            "title": "lambda_handler_decorator",
            "text": "<pre><code>lambda_handler_decorator(\n    decorator: Callable | None = None,\n    trace_execution: bool | None = None,\n) -&gt; Callable\n</code></pre> <p>Decorator factory for decorating Lambda handlers.</p> <p>You can use lambda_handler_decorator to create your own middlewares, where your function signature follows: <code>fn(handler, event, context)</code></p> <p>Custom keyword arguments are also supported e.g. <code>fn(handler, event, context, option=value)</code></p> <p>Middlewares created by this factory supports tracing to help you quickly troubleshoot any overhead that custom middlewares may cause - They will appear as custom subsegments.</p> <p>Non-key value params are not supported e.g. <code>fn(handler, event, context, option)</code></p> Environment variables <p>POWERTOOLS_TRACE_MIDDLEWARES : str     uses <code>aws_lambda_powertools.tracing.Tracer</code>     to create sub-segments per middleware (e.g. <code>\"true\", \"True\", \"TRUE\"</code>)</p> PARAMETER DESCRIPTION <code>decorator</code> <p>Middleware to be wrapped by this factory</p> <p> TYPE: <code>Callable | None</code> DEFAULT: <code>None</code> </p> <code>trace_execution</code> <p>Flag to explicitly enable trace execution for middlewares.</p> <p><code>Env POWERTOOLS_TRACE_MIDDLEWARES=\"true\"</code></p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> Example <p>Create a middleware no params</p> <pre><code>from aws_lambda_powertools.middleware_factory import lambda_handler_decorator\n\n@lambda_handler_decorator\ndef log_response(handler, event, context):\n    any_code_to_execute_before_lambda_handler()\n    response = handler(event, context)\n    any_code_to_execute_after_lambda_handler()\n    print(f\"Lambda handler response: {response}\")\n\n@log_response\ndef lambda_handler(event, context):\n    return True\n</code></pre> <p>Create a middleware with params</p> <pre><code>from aws_lambda_powertools.middleware_factory import lambda_handler_decorator\n\n@lambda_handler_decorator\ndef obfuscate_sensitive_data(handler, event, context, fields=None):\n    # Obfuscate email before calling Lambda handler\n    if fields:\n        for field in fields:\n            field = event.get(field, \"\")\n            event[field] = obfuscate_pii(field)\n\n    response = handler(event, context)\n    print(f\"Lambda handler response: {response}\")\n\n@obfuscate_sensitive_data(fields=[\"email\"])\ndef lambda_handler(event, context):\n    return True\n</code></pre> <p>Trace execution of custom middleware</p> <pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\n\ntracer = Tracer(service=\"payment\") # or via env var\n...\n@lambda_handler_decorator(trace_execution=True)\ndef log_response(handler, event, context):\n    ...\n\n@tracer.capture_lambda_handler\n@log_response\ndef lambda_handler(event, context):\n    return True\n</code></pre> Limitations <ul> <li>Async middlewares not supported</li> <li>Classes, class methods middlewares not supported</li> </ul> RAISES DESCRIPTION <code>MiddlewareInvalidArgumentError</code> <p>When middleware receives non keyword=arguments</p> Source code in <code>aws_lambda_powertools/middleware_factory/factory.py</code> <pre><code>def lambda_handler_decorator(decorator: Callable | None = None, trace_execution: bool | None = None) -&gt; Callable:\n    \"\"\"Decorator factory for decorating Lambda handlers.\n\n    You can use lambda_handler_decorator to create your own middlewares,\n    where your function signature follows: `fn(handler, event, context)`\n\n    Custom keyword arguments are also supported e.g. `fn(handler, event, context, option=value)`\n\n    Middlewares created by this factory supports tracing to help you quickly troubleshoot\n    any overhead that custom middlewares may cause - They will appear as custom subsegments.\n\n    **Non-key value params are not supported** e.g. `fn(handler, event, context, option)`\n\n    Environment variables\n    ---------------------\n    POWERTOOLS_TRACE_MIDDLEWARES : str\n        uses `aws_lambda_powertools.tracing.Tracer`\n        to create sub-segments per middleware (e.g. `\"true\", \"True\", \"TRUE\"`)\n\n    Parameters\n    ----------\n    decorator: Callable\n        Middleware to be wrapped by this factory\n    trace_execution: bool\n        Flag to explicitly enable trace execution for middlewares.\\n\n        `Env POWERTOOLS_TRACE_MIDDLEWARES=\"true\"`\n\n    Example\n    -------\n    **Create a middleware no params**\n\n        from aws_lambda_powertools.middleware_factory import lambda_handler_decorator\n\n        @lambda_handler_decorator\n        def log_response(handler, event, context):\n            any_code_to_execute_before_lambda_handler()\n            response = handler(event, context)\n            any_code_to_execute_after_lambda_handler()\n            print(f\"Lambda handler response: {response}\")\n\n        @log_response\n        def lambda_handler(event, context):\n            return True\n\n    **Create a middleware with params**\n\n        from aws_lambda_powertools.middleware_factory import lambda_handler_decorator\n\n        @lambda_handler_decorator\n        def obfuscate_sensitive_data(handler, event, context, fields=None):\n            # Obfuscate email before calling Lambda handler\n            if fields:\n                for field in fields:\n                    field = event.get(field, \"\")\n                    event[field] = obfuscate_pii(field)\n\n            response = handler(event, context)\n            print(f\"Lambda handler response: {response}\")\n\n        @obfuscate_sensitive_data(fields=[\"email\"])\n        def lambda_handler(event, context):\n            return True\n\n    **Trace execution of custom middleware**\n\n        from aws_lambda_powertools import Tracer\n        from aws_lambda_powertools.middleware_factory import lambda_handler_decorator\n\n        tracer = Tracer(service=\"payment\") # or via env var\n        ...\n        @lambda_handler_decorator(trace_execution=True)\n        def log_response(handler, event, context):\n            ...\n\n        @tracer.capture_lambda_handler\n        @log_response\n        def lambda_handler(event, context):\n            return True\n\n    Limitations\n    -----------\n    * Async middlewares not supported\n    * Classes, class methods middlewares not supported\n\n    Raises\n    ------\n    MiddlewareInvalidArgumentError\n        When middleware receives non keyword=arguments\n    \"\"\"\n\n    if decorator is None:\n        return functools.partial(lambda_handler_decorator, trace_execution=trace_execution)\n\n    trace_execution = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.MIDDLEWARE_FACTORY_TRACE_ENV, \"false\"),\n        choice=trace_execution,\n    )\n\n    @functools.wraps(decorator)\n    def final_decorator(func: Callable | None = None, **kwargs: Any):\n        # If called with kwargs return new func with kwargs\n        if func is None:\n            return functools.partial(final_decorator, **kwargs)\n\n        if not inspect.isfunction(func):\n            # @custom_middleware(True) vs @custom_middleware(log_event=True)\n            raise MiddlewareInvalidArgumentError(\n                f\"Only keyword arguments is supported for middlewares: {decorator.__qualname__} received {func}\",  # type: ignore # noqa: E501\n            )\n\n        @functools.wraps(func)\n        def wrapper(event, context, **handler_kwargs):\n            try:\n                middleware = functools.partial(decorator, func, event, context, **kwargs, **handler_kwargs)\n                if trace_execution:\n                    tracer = Tracer(auto_patch=False)\n                    with tracer.provider.in_subsegment(name=f\"## {decorator.__qualname__}\"):\n                        response = middleware()\n                else:\n                    response = middleware()\n                return response\n            except Exception:\n                logger.exception(f\"Caught exception in {decorator.__qualname__}\")\n                raise\n\n        return wrapper\n\n    return final_decorator\n</code></pre>"
        },
        {
            "location": "api_doc/middleware_factory/#aws_lambda_powertools.middleware_factory.exceptions",
            "title": "exceptions",
            "text": "CLASS DESCRIPTION <code>MiddlewareInvalidArgumentError</code> <p>When middleware receives non keyword=arguments</p>"
        },
        {
            "location": "api_doc/middleware_factory/#aws_lambda_powertools.middleware_factory.exceptions.MiddlewareInvalidArgumentError",
            "title": "MiddlewareInvalidArgumentError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>When middleware receives non keyword=arguments</p>"
        },
        {
            "location": "api_doc/middleware_factory/#aws_lambda_powertools.middleware_factory.factory",
            "title": "factory",
            "text": "FUNCTION DESCRIPTION <code>lambda_handler_decorator</code> <p>Decorator factory for decorating Lambda handlers.</p>"
        },
        {
            "location": "api_doc/middleware_factory/#aws_lambda_powertools.middleware_factory.factory.lambda_handler_decorator",
            "title": "lambda_handler_decorator",
            "text": "<pre><code>lambda_handler_decorator(\n    decorator: Callable | None = None,\n    trace_execution: bool | None = None,\n) -&gt; Callable\n</code></pre> <p>Decorator factory for decorating Lambda handlers.</p> <p>You can use lambda_handler_decorator to create your own middlewares, where your function signature follows: <code>fn(handler, event, context)</code></p> <p>Custom keyword arguments are also supported e.g. <code>fn(handler, event, context, option=value)</code></p> <p>Middlewares created by this factory supports tracing to help you quickly troubleshoot any overhead that custom middlewares may cause - They will appear as custom subsegments.</p> <p>Non-key value params are not supported e.g. <code>fn(handler, event, context, option)</code></p> Environment variables <p>POWERTOOLS_TRACE_MIDDLEWARES : str     uses <code>aws_lambda_powertools.tracing.Tracer</code>     to create sub-segments per middleware (e.g. <code>\"true\", \"True\", \"TRUE\"</code>)</p> PARAMETER DESCRIPTION <code>decorator</code> <p>Middleware to be wrapped by this factory</p> <p> TYPE: <code>Callable | None</code> DEFAULT: <code>None</code> </p> <code>trace_execution</code> <p>Flag to explicitly enable trace execution for middlewares.</p> <p><code>Env POWERTOOLS_TRACE_MIDDLEWARES=\"true\"</code></p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> Example <p>Create a middleware no params</p> <pre><code>from aws_lambda_powertools.middleware_factory import lambda_handler_decorator\n\n@lambda_handler_decorator\ndef log_response(handler, event, context):\n    any_code_to_execute_before_lambda_handler()\n    response = handler(event, context)\n    any_code_to_execute_after_lambda_handler()\n    print(f\"Lambda handler response: {response}\")\n\n@log_response\ndef lambda_handler(event, context):\n    return True\n</code></pre> <p>Create a middleware with params</p> <pre><code>from aws_lambda_powertools.middleware_factory import lambda_handler_decorator\n\n@lambda_handler_decorator\ndef obfuscate_sensitive_data(handler, event, context, fields=None):\n    # Obfuscate email before calling Lambda handler\n    if fields:\n        for field in fields:\n            field = event.get(field, \"\")\n            event[field] = obfuscate_pii(field)\n\n    response = handler(event, context)\n    print(f\"Lambda handler response: {response}\")\n\n@obfuscate_sensitive_data(fields=[\"email\"])\ndef lambda_handler(event, context):\n    return True\n</code></pre> <p>Trace execution of custom middleware</p> <pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\n\ntracer = Tracer(service=\"payment\") # or via env var\n...\n@lambda_handler_decorator(trace_execution=True)\ndef log_response(handler, event, context):\n    ...\n\n@tracer.capture_lambda_handler\n@log_response\ndef lambda_handler(event, context):\n    return True\n</code></pre> Limitations <ul> <li>Async middlewares not supported</li> <li>Classes, class methods middlewares not supported</li> </ul> RAISES DESCRIPTION <code>MiddlewareInvalidArgumentError</code> <p>When middleware receives non keyword=arguments</p> Source code in <code>aws_lambda_powertools/middleware_factory/factory.py</code> <pre><code>def lambda_handler_decorator(decorator: Callable | None = None, trace_execution: bool | None = None) -&gt; Callable:\n    \"\"\"Decorator factory for decorating Lambda handlers.\n\n    You can use lambda_handler_decorator to create your own middlewares,\n    where your function signature follows: `fn(handler, event, context)`\n\n    Custom keyword arguments are also supported e.g. `fn(handler, event, context, option=value)`\n\n    Middlewares created by this factory supports tracing to help you quickly troubleshoot\n    any overhead that custom middlewares may cause - They will appear as custom subsegments.\n\n    **Non-key value params are not supported** e.g. `fn(handler, event, context, option)`\n\n    Environment variables\n    ---------------------\n    POWERTOOLS_TRACE_MIDDLEWARES : str\n        uses `aws_lambda_powertools.tracing.Tracer`\n        to create sub-segments per middleware (e.g. `\"true\", \"True\", \"TRUE\"`)\n\n    Parameters\n    ----------\n    decorator: Callable\n        Middleware to be wrapped by this factory\n    trace_execution: bool\n        Flag to explicitly enable trace execution for middlewares.\\n\n        `Env POWERTOOLS_TRACE_MIDDLEWARES=\"true\"`\n\n    Example\n    -------\n    **Create a middleware no params**\n\n        from aws_lambda_powertools.middleware_factory import lambda_handler_decorator\n\n        @lambda_handler_decorator\n        def log_response(handler, event, context):\n            any_code_to_execute_before_lambda_handler()\n            response = handler(event, context)\n            any_code_to_execute_after_lambda_handler()\n            print(f\"Lambda handler response: {response}\")\n\n        @log_response\n        def lambda_handler(event, context):\n            return True\n\n    **Create a middleware with params**\n\n        from aws_lambda_powertools.middleware_factory import lambda_handler_decorator\n\n        @lambda_handler_decorator\n        def obfuscate_sensitive_data(handler, event, context, fields=None):\n            # Obfuscate email before calling Lambda handler\n            if fields:\n                for field in fields:\n                    field = event.get(field, \"\")\n                    event[field] = obfuscate_pii(field)\n\n            response = handler(event, context)\n            print(f\"Lambda handler response: {response}\")\n\n        @obfuscate_sensitive_data(fields=[\"email\"])\n        def lambda_handler(event, context):\n            return True\n\n    **Trace execution of custom middleware**\n\n        from aws_lambda_powertools import Tracer\n        from aws_lambda_powertools.middleware_factory import lambda_handler_decorator\n\n        tracer = Tracer(service=\"payment\") # or via env var\n        ...\n        @lambda_handler_decorator(trace_execution=True)\n        def log_response(handler, event, context):\n            ...\n\n        @tracer.capture_lambda_handler\n        @log_response\n        def lambda_handler(event, context):\n            return True\n\n    Limitations\n    -----------\n    * Async middlewares not supported\n    * Classes, class methods middlewares not supported\n\n    Raises\n    ------\n    MiddlewareInvalidArgumentError\n        When middleware receives non keyword=arguments\n    \"\"\"\n\n    if decorator is None:\n        return functools.partial(lambda_handler_decorator, trace_execution=trace_execution)\n\n    trace_execution = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.MIDDLEWARE_FACTORY_TRACE_ENV, \"false\"),\n        choice=trace_execution,\n    )\n\n    @functools.wraps(decorator)\n    def final_decorator(func: Callable | None = None, **kwargs: Any):\n        # If called with kwargs return new func with kwargs\n        if func is None:\n            return functools.partial(final_decorator, **kwargs)\n\n        if not inspect.isfunction(func):\n            # @custom_middleware(True) vs @custom_middleware(log_event=True)\n            raise MiddlewareInvalidArgumentError(\n                f\"Only keyword arguments is supported for middlewares: {decorator.__qualname__} received {func}\",  # type: ignore # noqa: E501\n            )\n\n        @functools.wraps(func)\n        def wrapper(event, context, **handler_kwargs):\n            try:\n                middleware = functools.partial(decorator, func, event, context, **kwargs, **handler_kwargs)\n                if trace_execution:\n                    tracer = Tracer(auto_patch=False)\n                    with tracer.provider.in_subsegment(name=f\"## {decorator.__qualname__}\"):\n                        response = middleware()\n                else:\n                    response = middleware()\n                return response\n            except Exception:\n                logger.exception(f\"Caught exception in {decorator.__qualname__}\")\n                raise\n\n        return wrapper\n\n    return final_decorator\n</code></pre>"
        },
        {
            "location": "api_doc/parser/",
            "title": "Parser",
            "text": "<p>The Parser utility simplifies data parsing and validation using Pydantic. It allows you to define data models in pure Python classes, parse and validate incoming events, and extract only the data you need.</p> <p>Usage Documentation</p> <p><code>Parser</code></p> FUNCTION DESCRIPTION <code>event_parser</code> <p>Lambda handler decorator to parse &amp; validate events using Pydantic models</p> <code>parse</code> <p>Standalone function to parse &amp; validate events using Pydantic models</p>"
        },
        {
            "location": "api_doc/parser/#aws_lambda_powertools.utilities.parser.parser.event_parser",
            "title": "event_parser",
            "text": "<pre><code>event_parser(\n    handler: Callable[..., EventParserReturnType],\n    event: dict[str, Any],\n    context: LambdaContext,\n    model: type[T] | None = None,\n    envelope: type[Envelope] | None = None,\n    **kwargs: Any\n) -&gt; EventParserReturnType\n</code></pre> <p>Lambda handler decorator to parse &amp; validate events using Pydantic models</p> <p>It requires a model that implements Pydantic BaseModel to parse &amp; validate the event.</p> <p>When an envelope is given, it'll use the following logic:</p> <ol> <li>Parse the event against the envelope model first e.g. EnvelopeModel(**event)</li> <li>Envelope will extract a given key to be parsed against the model e.g. event.detail</li> </ol> <p>This is useful when you need to confirm event wrapper structure, and b) selectively extract a portion of your payload for parsing &amp; validation.</p> <p>NOTE: If envelope is omitted, the complete event is parsed to match the model parameter definition.</p> Example <p>Lambda handler decorator to parse &amp; validate event</p> <pre><code>class Order(BaseModel):\n    id: int\n    description: str\n    ...\n\n@event_parser(model=Order)\ndef handler(event: Order, context: LambdaContext):\n    ...\n</code></pre> <p>Lambda handler decorator to parse &amp; validate event - using built-in envelope</p> <pre><code>class Order(BaseModel):\n    id: int\n    description: str\n    ...\n\n@event_parser(model=Order, envelope=envelopes.EVENTBRIDGE)\ndef handler(event: Order, context: LambdaContext):\n    ...\n</code></pre> PARAMETER DESCRIPTION <code>handler</code> <p>Method to annotate on</p> <p> TYPE: <code>Callable[..., EventParserReturnType]</code> </p> <code>event</code> <p>Lambda event to be parsed &amp; validated</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>context</code> <p>Lambda context object</p> <p> TYPE: <code>LambdaContext</code> </p> <code>model</code> <p>Your data model that will replace the event.</p> <p> TYPE: <code>type[T] | None</code> DEFAULT: <code>None</code> </p> <code>envelope</code> <p>Optional envelope to extract the model from</p> <p> TYPE: <code>type[Envelope] | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValidationError</code> <p>When input event does not conform with the provided model</p> <code>InvalidModelTypeError</code> <p>When the model given does not implement BaseModel, is not provided</p> <code>InvalidEnvelopeError</code> <p>When envelope given does not implement BaseEnvelope</p> Source code in <code>aws_lambda_powertools/utilities/parser/parser.py</code> <pre><code>@lambda_handler_decorator\ndef event_parser(\n    handler: Callable[..., EventParserReturnType],\n    event: dict[str, Any],\n    context: LambdaContext,\n    model: type[T] | None = None,\n    envelope: type[Envelope] | None = None,\n    **kwargs: Any,\n) -&gt; EventParserReturnType:\n    \"\"\"Lambda handler decorator to parse &amp; validate events using Pydantic models\n\n    It requires a model that implements Pydantic BaseModel to parse &amp; validate the event.\n\n    When an envelope is given, it'll use the following logic:\n\n    1. Parse the event against the envelope model first e.g. EnvelopeModel(**event)\n    2. Envelope will extract a given key to be parsed against the model e.g. event.detail\n\n    This is useful when you need to confirm event wrapper structure, and\n    b) selectively extract a portion of your payload for parsing &amp; validation.\n\n    NOTE: If envelope is omitted, the complete event is parsed to match the model parameter definition.\n\n    Example\n    -------\n    **Lambda handler decorator to parse &amp; validate event**\n\n        class Order(BaseModel):\n            id: int\n            description: str\n            ...\n\n        @event_parser(model=Order)\n        def handler(event: Order, context: LambdaContext):\n            ...\n\n    **Lambda handler decorator to parse &amp; validate event - using built-in envelope**\n\n        class Order(BaseModel):\n            id: int\n            description: str\n            ...\n\n        @event_parser(model=Order, envelope=envelopes.EVENTBRIDGE)\n        def handler(event: Order, context: LambdaContext):\n            ...\n\n    Parameters\n    ----------\n    handler:  Callable\n        Method to annotate on\n    event:    dict\n        Lambda event to be parsed &amp; validated\n    context:  LambdaContext\n        Lambda context object\n    model:   type[T] | None\n        Your data model that will replace the event.\n    envelope: Envelope\n        Optional envelope to extract the model from\n\n    Raises\n    ------\n    ValidationError\n        When input event does not conform with the provided model\n    InvalidModelTypeError\n        When the model given does not implement BaseModel, is not provided\n    InvalidEnvelopeError\n        When envelope given does not implement BaseEnvelope\n    \"\"\"\n\n    if model is None:\n        # The first parameter of a Lambda function is always the event.\n        # Get the first parameter's type by using typing.get_type_hints.\n        type_hints = typing.get_type_hints(handler)\n        if type_hints:\n            model = list(type_hints.values())[0]\n        if model is None:\n            raise InvalidModelTypeError(\n                \"The model must be provided either as the `model` argument to `event_parser`\"\n                \"or as the type hint of `event` in the handler that it wraps\",\n            )\n\n    if envelope:\n        parsed_event = parse(event=event, model=model, envelope=envelope)\n    else:\n        parsed_event = parse(event=event, model=model)\n\n    logger.debug(f\"Calling handler {handler.__name__}\")\n    return handler(parsed_event, context, **kwargs)\n</code></pre>"
        },
        {
            "location": "api_doc/parser/#aws_lambda_powertools.utilities.parser.parser.parse",
            "title": "parse",
            "text": "<pre><code>parse(event: dict[str, Any], model: type[T]) -&gt; T\n</code></pre><pre><code>parse(\n    event: dict[str, Any],\n    model: type[T],\n    envelope: type[Envelope],\n) -&gt; T\n</code></pre> <pre><code>parse(\n    event: dict[str, Any],\n    model: type[T],\n    envelope: type[Envelope] | None = None,\n)\n</code></pre> <p>Standalone function to parse &amp; validate events using Pydantic models</p> <p>Typically used when you need fine-grained control over error handling compared to event_parser decorator.</p> Example <p>Lambda handler decorator to parse &amp; validate event</p> <pre><code>from aws_lambda_powertools.utilities.parser import ValidationError\n\nclass Order(BaseModel):\n    id: int\n    description: str\n    ...\n\ndef handler(event: Order, context: LambdaContext):\n    try:\n        parse(model=Order)\n    except ValidationError:\n        ...\n</code></pre> <p>Lambda handler decorator to parse &amp; validate event - using built-in envelope</p> <pre><code>class Order(BaseModel):\n    id: int\n    description: str\n    ...\n\ndef handler(event: Order, context: LambdaContext):\n    try:\n        parse(model=Order, envelope=envelopes.EVENTBRIDGE)\n    except ValidationError:\n        ...\n</code></pre> PARAMETER DESCRIPTION <code>event</code> <p>Lambda event to be parsed &amp; validated</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>model</code> <p>Your data model that will replace the event</p> <p> TYPE: <code>type[T]</code> </p> <code>envelope</code> <p>Optional envelope to extract the model from</p> <p> TYPE: <code>type[Envelope] | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>ValidationError</code> <p>When input event does not conform with model provided</p> <code>InvalidModelTypeError</code> <p>When model given does not implement BaseModel</p> <code>InvalidEnvelopeError</code> <p>When envelope given does not implement BaseEnvelope</p> Source code in <code>aws_lambda_powertools/utilities/parser/parser.py</code> <pre><code>def parse(event: dict[str, Any], model: type[T], envelope: type[Envelope] | None = None):\n    \"\"\"Standalone function to parse &amp; validate events using Pydantic models\n\n    Typically used when you need fine-grained control over error handling compared to event_parser decorator.\n\n    Example\n    -------\n\n    **Lambda handler decorator to parse &amp; validate event**\n\n        from aws_lambda_powertools.utilities.parser import ValidationError\n\n        class Order(BaseModel):\n            id: int\n            description: str\n            ...\n\n        def handler(event: Order, context: LambdaContext):\n            try:\n                parse(model=Order)\n            except ValidationError:\n                ...\n\n    **Lambda handler decorator to parse &amp; validate event - using built-in envelope**\n\n        class Order(BaseModel):\n            id: int\n            description: str\n            ...\n\n        def handler(event: Order, context: LambdaContext):\n            try:\n                parse(model=Order, envelope=envelopes.EVENTBRIDGE)\n            except ValidationError:\n                ...\n\n    Parameters\n    ----------\n    event:    dict\n        Lambda event to be parsed &amp; validated\n    model:   Model\n        Your data model that will replace the event\n    envelope: Envelope\n        Optional envelope to extract the model from\n\n    Raises\n    ------\n    ValidationError\n        When input event does not conform with model provided\n    InvalidModelTypeError\n        When model given does not implement BaseModel\n    InvalidEnvelopeError\n        When envelope given does not implement BaseEnvelope\n    \"\"\"\n    if envelope and callable(envelope):\n        try:\n            logger.debug(f\"Parsing and validating event model with envelope={envelope}\")\n            return envelope().parse(data=event, model=model)\n        except AttributeError as exc:\n            raise InvalidEnvelopeError(\n                f\"Error: {str(exc)}. Please ensure that both the Input model and the Envelope inherits from BaseModel,\\n\"  # noqa E501\n                \"and your payload adheres to the specified Input model structure.\\n\"\n                f\"Envelope={envelope}\\nModel={model}\",\n            ) from exc\n\n    try:\n        adapter = _retrieve_or_set_model_from_cache(model=model)\n\n        logger.debug(\"Parsing and validating event model; no envelope used\")\n\n        return _parse_and_validate_event(data=event, adapter=adapter)\n\n    # Pydantic raises PydanticSchemaGenerationError when the model is not a Pydantic model\n    # This is seen in the tests where we pass a non-Pydantic model type to the parser or\n    # when we pass a data structure that does not match the model (trying to parse a true/false/etc into a model)\n    except PydanticSchemaGenerationError as exc:\n        raise InvalidModelTypeError(f\"The event supplied is unable to be validated into {type(model)}\") from exc\n    except AttributeError as exc:\n        raise InvalidModelTypeError(\n            f\"Error: {str(exc)}. Please ensure the Input model inherits from BaseModel,\\n\"\n            \"and your payload adheres to the specified Input model structure.\\n\"\n            f\"Model={model}\",\n        ) from exc\n</code></pre>"
        },
        {
            "location": "api_doc/streaming/",
            "title": "Streaming",
            "text": "CLASS DESCRIPTION <code>S3Object</code> <p>Seekable and streamable S3 Object reader.</p> CLASS DESCRIPTION <code>CsvTransform</code> <p>CSV data transform.</p> CLASS DESCRIPTION <code>GzipTransform</code> <p>Gzip data transform.</p> CLASS DESCRIPTION <code>ZipTransform</code> <p>Zip data transform.</p>"
        },
        {
            "location": "api_doc/streaming/#aws_lambda_powertools.utilities.streaming.s3_object.S3Object",
            "title": "S3Object",
            "text": "<pre><code>S3Object(\n    bucket: str,\n    key: str,\n    version_id: str | None = None,\n    boto3_client: S3Client | None = None,\n    is_gzip: bool | None = False,\n    is_csv: bool | None = False,\n    **sdk_options\n)\n</code></pre> <p>               Bases: <code>IO[bytes]</code></p> <p>Seekable and streamable S3 Object reader.</p> <p>S3Object implements the IO[bytes], backed by a seekable S3 streaming.</p> PARAMETER DESCRIPTION <code>bucket</code> <p>The S3 bucket</p> <p> TYPE: <code>str</code> </p> <code>key</code> <p>The S3 key</p> <p> TYPE: <code>str</code> </p> <code>version_id</code> <p>A version ID of the object, when the S3 bucket is versioned</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>boto3_client</code> <p>An optional boto3 S3 client. If missing, a new one will be created.</p> <p> TYPE: <code>S3Client | None</code> DEFAULT: <code>None</code> </p> <code>is_gzip</code> <p>Enables the Gunzip data transformation</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>False</code> </p> <code>is_csv</code> <p>Enables the CSV data transformation</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>False</code> </p> <code>sdk_options</code> <p>Dictionary of options that will be passed to the S3 Client get_object API call</p> <p> DEFAULT: <code>{}</code> </p> Example <p>Reads a line from an S3, loading as little data as necessary:</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming import S3Object\n&gt;&gt;&gt;\n&gt;&gt;&gt; line: bytes = S3Object(bucket=\"bucket\", key=\"key\").readline()\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(line)\n</code></pre> METHOD DESCRIPTION <code>transform</code> <p>Applies one or more data transformations to the stream.</p> ATTRIBUTE DESCRIPTION <code>size</code> <p>Retrieves the size of the underlying S3 object</p> <p> TYPE: <code>int</code> </p> <code>transformed_stream</code> <p>Returns a IO[bytes] stream with all the data transformations applied in order</p> <p> TYPE: <code>IO[bytes]</code> </p> Source code in <code>aws_lambda_powertools/utilities/streaming/s3_object.py</code> <pre><code>def __init__(\n    self,\n    bucket: str,\n    key: str,\n    version_id: str | None = None,\n    boto3_client: S3Client | None = None,\n    is_gzip: bool | None = False,\n    is_csv: bool | None = False,\n    **sdk_options,\n):\n    self.bucket = bucket\n    self.key = key\n    self.version_id = version_id\n\n    # The underlying seekable IO, where all the magic happens\n    self.raw_stream = _S3SeekableIO(\n        bucket=bucket,\n        key=key,\n        version_id=version_id,\n        boto3_client=boto3_client,\n        **sdk_options,\n    )\n\n    # Stores the list of data transformations\n    self._data_transformations: list[BaseTransform] = []\n    if is_gzip:\n        self._data_transformations.append(GzipTransform())\n    if is_csv:\n        self._data_transformations.append(CsvTransform())\n\n    # Stores the cached transformed stream\n    self._transformed_stream: IO[bytes] | None = None\n</code></pre>"
        },
        {
            "location": "api_doc/streaming/#aws_lambda_powertools.utilities.streaming.s3_object.S3Object.size",
            "title": "size  <code>property</code>",
            "text": "<pre><code>size: int\n</code></pre> <p>Retrieves the size of the underlying S3 object</p>"
        },
        {
            "location": "api_doc/streaming/#aws_lambda_powertools.utilities.streaming.s3_object.S3Object.transformed_stream",
            "title": "transformed_stream  <code>property</code>",
            "text": "<pre><code>transformed_stream: IO[bytes]\n</code></pre> <p>Returns a IO[bytes] stream with all the data transformations applied in order</p>"
        },
        {
            "location": "api_doc/streaming/#aws_lambda_powertools.utilities.streaming.s3_object.S3Object.transform",
            "title": "transform",
            "text": "<pre><code>transform(\n    transformations: (\n        BaseTransform[T] | Sequence[BaseTransform[T]]\n    ),\n    in_place: Literal[True],\n) -&gt; T\n</code></pre><pre><code>transform(\n    transformations: (\n        BaseTransform[T] | Sequence[BaseTransform[T]]\n    ),\n    in_place: Literal[False],\n) -&gt; None\n</code></pre><pre><code>transform(\n    transformations: (\n        BaseTransform[T] | Sequence[BaseTransform[T]]\n    ),\n) -&gt; T\n</code></pre> <pre><code>transform(\n    transformations: (\n        BaseTransform[T] | Sequence[BaseTransform[T]]\n    ),\n    in_place: bool | None = False,\n) -&gt; T | None\n</code></pre> <p>Applies one or more data transformations to the stream.</p> PARAMETER DESCRIPTION <code>transformations</code> <p>One or more transformations to apply. Transformations are applied in the same order as they are declared.</p> <p> TYPE: <code>BaseTransform[T] | Sequence[BaseTransform[T]]</code> </p> <code>in_place</code> <p>Transforms the stream in place, instead of returning a new stream object. Defaults to false.</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>False</code> </p> RETURNS DESCRIPTION <code>T[bound=IO[bytes]], optional</code> <p>If in_place is False, returns an IO[bytes] object representing the transformed stream</p> Source code in <code>aws_lambda_powertools/utilities/streaming/s3_object.py</code> <pre><code>def transform(\n    self,\n    transformations: BaseTransform[T] | Sequence[BaseTransform[T]],\n    in_place: bool | None = False,\n) -&gt; T | None:\n    \"\"\"\n    Applies one or more data transformations to the stream.\n\n    Parameters\n    ----------\n    transformations: BaseTransform[T] | Sequence[BaseTransform[T]]\n        One or more transformations to apply. Transformations are applied in the same order as they are declared.\n    in_place: bool, optional\n        Transforms the stream in place, instead of returning a new stream object. Defaults to false.\n\n    Returns\n    -------\n    T[bound=IO[bytes]], optional\n        If in_place is False, returns an IO[bytes] object representing the transformed stream\n    \"\"\"\n    # Make transformations always be a sequence to make mypy happy\n    if not isinstance(transformations, Sequence):\n        transformations = [transformations]\n\n    # Scenario 1: user wants to transform the stream in place.\n    # In this case, we store the transformations and invalidate any existing transformed stream.\n    # This way, the transformed_stream is re-created on the next IO operation.\n    # This can happen when the user calls .transform multiple times before they start reading data\n    #\n    #   &gt;&gt;&gt; s3object.transform(GzipTransform(), in_place=True)\n    #   &gt;&gt;&gt; s3object.seek(0, io.SEEK_SET) &lt;- this creates a transformed stream\n    #   &gt;&gt;&gt; s3object.transform(CsvTransform(), in_place=True) &lt;- need to re-create transformed stream\n    #   &gt;&gt;&gt; s3object.read...\n    if in_place:\n        self._data_transformations.extend(transformations)\n\n        # Invalidate any existing transformed stream.\n        # It will be created again next time it's accessed.\n        self._transformed_stream = None\n        return None\n    else:\n        # Tell mypy that raw_stream actually implements T (bound to IO[bytes])\n        stream = cast(T, self.raw_stream)\n        for transformation in transformations:\n            stream = transformation.transform(stream)\n        return stream\n</code></pre>"
        },
        {
            "location": "api_doc/streaming/#aws_lambda_powertools.utilities.streaming.transformations.csv.CsvTransform",
            "title": "CsvTransform",
            "text": "<pre><code>CsvTransform(**transform_options)\n</code></pre> <p>               Bases: <code>BaseTransform</code></p> <p>CSV data transform.</p> <p>Returns a csv.DictReader that reads data from the input stream: https://docs.python.org/3/library/csv.html#csv.DictReader</p> Example <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming import S3Object\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming.transformations import CsvTransform\n&gt;&gt;&gt;\n&gt;&gt;&gt; s3object = S3Object(bucket=\"bucket\", key=\"key\")\n&gt;&gt;&gt; csv_reader = s3object.transform(CsvTransform())\n&gt;&gt;&gt; for row in csv_reader:\n&gt;&gt;&gt;   print(row)\n</code></pre> <p>Since the underlying stream of bytes needs to be converted into a stream of characters (Iterator[str]), we wrap the input into an io.TextIOWrapper. This means you have control over the text encoding and line termination options.</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming import S3Object\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming.transformations import CsvTransform\n&gt;&gt;&gt;\n&gt;&gt;&gt; s3object = S3Object(bucket=\"bucket\", key=\"key\")\n&gt;&gt;&gt; csv_reader = s3object.transform(CsvTransform(encoding=\"utf-8\", newline=\"\\r\\n\"))\n&gt;&gt;&gt; for row in csv_reader:\n&gt;&gt;&gt;   print(row)\n</code></pre> <p>Additional options passed on the constructor, will be pased to the csv.DictReader constructor.</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming import S3Object\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming.transformations import CsvTransform\n&gt;&gt;&gt;\n&gt;&gt;&gt; s3object = S3Object(bucket=\"bucket\", key=\"key\")\n&gt;&gt;&gt; csv_reader = s3object.transform(CsvTransform(dialect=\"excel\"))\n&gt;&gt;&gt; for row in csv_reader:\n&gt;&gt;&gt;   print(row)\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/streaming/transformations/base.py</code> <pre><code>def __init__(self, **transform_options):\n    self.transform_options = transform_options\n</code></pre>"
        },
        {
            "location": "api_doc/streaming/#aws_lambda_powertools.utilities.streaming.transformations.gzip.GzipTransform",
            "title": "GzipTransform",
            "text": "<pre><code>GzipTransform(**transform_options)\n</code></pre> <p>               Bases: <code>BaseTransform</code></p> <p>Gzip data transform.</p> <p>Returns a gzip.GzipFile instead that reads data from the input stream: https://docs.python.org/3/library/gzip.html#gzip.GzipFile</p> Example <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming import S3Object\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming.transformations import GzipTransform\n&gt;&gt;&gt;\n&gt;&gt;&gt; s3object = S3Object(bucket=\"bucket\", key=\"key\")\n&gt;&gt;&gt; reader = s3object.transform(GzipTransform())\n&gt;&gt;&gt; for line in reader:\n&gt;&gt;&gt;   print(line)\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/streaming/transformations/base.py</code> <pre><code>def __init__(self, **transform_options):\n    self.transform_options = transform_options\n</code></pre>"
        },
        {
            "location": "api_doc/streaming/#aws_lambda_powertools.utilities.streaming.transformations.zip.ZipTransform",
            "title": "ZipTransform",
            "text": "<pre><code>ZipTransform(**transform_options)\n</code></pre> <p>               Bases: <code>BaseTransform</code></p> <p>Zip data transform.</p> <p>Returns a zip.ZipFile that reads data from the input stream: https://docs.python.org/3/library/zipfile.html#zipfile.ZipFile</p> Example <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming import S3Object\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming.transformations import ZipTransform\n&gt;&gt;&gt;\n&gt;&gt;&gt; s3object = S3Object(bucket=\"bucket\", key=\"key\")\n&gt;&gt;&gt; zip_reader = s3object.transform(ZipTransform())\n&gt;&gt;&gt; for file in zip_reader.namelist():\n&gt;&gt;&gt;   print(file)\n&gt;&gt;&gt;   zip_reader.extract(file)\n</code></pre> <p>Additional options passed on the constructor, will be pased to the is_csv.DictReader constructor.</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming import S3Object\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming.transformations import ZipTransform\n&gt;&gt;&gt; import zipfile\n&gt;&gt;&gt;\n&gt;&gt;&gt; s3object = S3Object(bucket=\"bucket\", key=\"key\")\n&gt;&gt;&gt; zip_reader = s3object.transform(ZipTransform(compression=zipfile.ZIP_LZMA))\n&gt;&gt;&gt; for file in zip_reader.namelist():\n&gt;&gt;&gt;   print(file)\n&gt;&gt;&gt;   zip_reader.extract(file)\n</code></pre> <p>Currently, it's not possible to pipe the Zip file stream into another data transformation, since a Zip file contains multiple files, and not a single stream. However, you can still open a specific file as a stream, reading only the necessary bytes to extract it:</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming import S3Object\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.streaming.transformations import ZipTransform\n&gt;&gt;&gt; import zipfile\n&gt;&gt;&gt;\n&gt;&gt;&gt; s3object = S3Object(bucket=\"bucket\", key=\"key\")\n&gt;&gt;&gt; zip_reader = s3object.transform(ZipTransform())\n&gt;&gt;&gt; with zip_reader.open(\"filename.txt\") as f:\n&gt;&gt;&gt;   for line in f:\n&gt;&gt;&gt;      print(line)\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/streaming/transformations/base.py</code> <pre><code>def __init__(self, **transform_options):\n    self.transform_options = transform_options\n</code></pre>"
        },
        {
            "location": "api_doc/typing/",
            "title": "Typing",
            "text": "<p>Typing for developer ease in the IDE</p> <p>Usage Documentation</p> <p><code>Typing</code></p> MODULE DESCRIPTION <code>lambda_client_context</code> <code>lambda_client_context_mobile_client</code> <code>lambda_cognito_identity</code> <code>lambda_context</code> CLASS DESCRIPTION <code>LambdaContext</code> <p>The LambdaContext static object can be used to ease the development by providing the IDE type hints.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.LambdaContext",
            "title": "LambdaContext",
            "text": "<p>The LambdaContext static object can be used to ease the development by providing the IDE type hints.</p> Example <p>A Lambda function using LambdaContext</p> <pre><code>&gt;&gt;&gt; from typing import Any\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.typing import LambdaContext\n&gt;&gt;&gt;\n&gt;&gt;&gt; def handler(event: dict[str, Any], context: LambdaContext) -&gt; dict[str, Any]:\n&gt;&gt;&gt;     # Insert business logic\n&gt;&gt;&gt;     return event\n</code></pre> METHOD DESCRIPTION <code>get_remaining_time_in_millis</code> <p>Returns the number of milliseconds left before the execution times out.</p> ATTRIBUTE DESCRIPTION <code>aws_request_id</code> <p>The identifier of the invocation request.</p> <p> TYPE: <code>str</code> </p> <code>client_context</code> <p>(mobile apps) Client context that's provided to Lambda by the client application.</p> <p> TYPE: <code>LambdaClientContext</code> </p> <code>function_name</code> <p>The name of the Lambda function.</p> <p> TYPE: <code>str</code> </p> <code>function_version</code> <p>The version of the function.</p> <p> TYPE: <code>str</code> </p> <code>identity</code> <p>(mobile apps) Information about the Amazon Cognito identity that authorized the request.</p> <p> TYPE: <code>LambdaCognitoIdentity</code> </p> <code>invoked_function_arn</code> <p>The Amazon Resource Name (ARN) that's used to invoke the function. Indicates if the invoker specified a</p> <p> TYPE: <code>str</code> </p> <code>log_group_name</code> <p>The log group for the function.</p> <p> TYPE: <code>str</code> </p> <code>log_stream_name</code> <p>The log stream for the function instance.</p> <p> TYPE: <code>str</code> </p> <code>memory_limit_in_mb</code> <p>The amount of memory that's allocated for the function.</p> <p> TYPE: <code>int</code> </p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.LambdaContext.aws_request_id",
            "title": "aws_request_id  <code>property</code>",
            "text": "<pre><code>aws_request_id: str\n</code></pre> <p>The identifier of the invocation request.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.LambdaContext.client_context",
            "title": "client_context  <code>property</code>",
            "text": "<pre><code>client_context: LambdaClientContext\n</code></pre> <p>(mobile apps) Client context that's provided to Lambda by the client application.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.LambdaContext.function_name",
            "title": "function_name  <code>property</code>",
            "text": "<pre><code>function_name: str\n</code></pre> <p>The name of the Lambda function.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.LambdaContext.function_version",
            "title": "function_version  <code>property</code>",
            "text": "<pre><code>function_version: str\n</code></pre> <p>The version of the function.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.LambdaContext.identity",
            "title": "identity  <code>property</code>",
            "text": "<pre><code>identity: LambdaCognitoIdentity\n</code></pre> <p>(mobile apps) Information about the Amazon Cognito identity that authorized the request.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.LambdaContext.invoked_function_arn",
            "title": "invoked_function_arn  <code>property</code>",
            "text": "<pre><code>invoked_function_arn: str\n</code></pre> <p>The Amazon Resource Name (ARN) that's used to invoke the function. Indicates if the invoker specified a version number or alias.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.LambdaContext.log_group_name",
            "title": "log_group_name  <code>property</code>",
            "text": "<pre><code>log_group_name: str\n</code></pre> <p>The log group for the function.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.LambdaContext.log_stream_name",
            "title": "log_stream_name  <code>property</code>",
            "text": "<pre><code>log_stream_name: str\n</code></pre> <p>The log stream for the function instance.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.LambdaContext.memory_limit_in_mb",
            "title": "memory_limit_in_mb  <code>property</code>",
            "text": "<pre><code>memory_limit_in_mb: int\n</code></pre> <p>The amount of memory that's allocated for the function.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.LambdaContext.get_remaining_time_in_millis",
            "title": "get_remaining_time_in_millis  <code>staticmethod</code>",
            "text": "<pre><code>get_remaining_time_in_millis() -&gt; int\n</code></pre> <p>Returns the number of milliseconds left before the execution times out.</p> Source code in <code>aws_lambda_powertools/utilities/typing/lambda_context.py</code> <pre><code>@staticmethod\ndef get_remaining_time_in_millis() -&gt; int:\n    \"\"\"Returns the number of milliseconds left before the execution times out.\"\"\"\n    return 0\n</code></pre>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_client_context",
            "title": "lambda_client_context",
            "text": "CLASS DESCRIPTION <code>LambdaClientContext</code>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_client_context.LambdaClientContext",
            "title": "LambdaClientContext",
            "text": "ATTRIBUTE DESCRIPTION <code>client</code> <p>Client context that's provided to Lambda by the client application.</p> <p> TYPE: <code>LambdaClientContextMobileClient</code> </p> <code>custom</code> <p>A dict of custom values set by the mobile client application.</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>env</code> <p>A dict of environment information provided by the AWS SDK.</p> <p> TYPE: <code>dict[str, Any]</code> </p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_client_context.LambdaClientContext.client",
            "title": "client  <code>property</code>",
            "text": "<pre><code>client: LambdaClientContextMobileClient\n</code></pre> <p>Client context that's provided to Lambda by the client application.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_client_context.LambdaClientContext.custom",
            "title": "custom  <code>property</code>",
            "text": "<pre><code>custom: dict[str, Any]\n</code></pre> <p>A dict of custom values set by the mobile client application.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_client_context.LambdaClientContext.env",
            "title": "env  <code>property</code>",
            "text": "<pre><code>env: dict[str, Any]\n</code></pre> <p>A dict of environment information provided by the AWS SDK.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_client_context_mobile_client",
            "title": "lambda_client_context_mobile_client",
            "text": "CLASS DESCRIPTION <code>LambdaClientContextMobileClient</code> <p>Mobile Client context that's provided to Lambda by the client application.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_client_context_mobile_client.LambdaClientContextMobileClient",
            "title": "LambdaClientContextMobileClient",
            "text": "<p>Mobile Client context that's provided to Lambda by the client application.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_cognito_identity",
            "title": "lambda_cognito_identity",
            "text": "CLASS DESCRIPTION <code>LambdaCognitoIdentity</code> <p>Information about the Amazon Cognito identity that authorized the request.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_cognito_identity.LambdaCognitoIdentity",
            "title": "LambdaCognitoIdentity",
            "text": "<p>Information about the Amazon Cognito identity that authorized the request.</p> ATTRIBUTE DESCRIPTION <code>cognito_identity_id</code> <p>The authenticated Amazon Cognito identity.</p> <p> TYPE: <code>str</code> </p> <code>cognito_identity_pool_id</code> <p>The Amazon Cognito identity pool that authorized the invocation.</p> <p> TYPE: <code>str</code> </p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_cognito_identity.LambdaCognitoIdentity.cognito_identity_id",
            "title": "cognito_identity_id  <code>property</code>",
            "text": "<pre><code>cognito_identity_id: str\n</code></pre> <p>The authenticated Amazon Cognito identity.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_cognito_identity.LambdaCognitoIdentity.cognito_identity_pool_id",
            "title": "cognito_identity_pool_id  <code>property</code>",
            "text": "<pre><code>cognito_identity_pool_id: str\n</code></pre> <p>The Amazon Cognito identity pool that authorized the invocation.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_context",
            "title": "lambda_context",
            "text": "CLASS DESCRIPTION <code>LambdaContext</code> <p>The LambdaContext static object can be used to ease the development by providing the IDE type hints.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext",
            "title": "LambdaContext",
            "text": "<p>The LambdaContext static object can be used to ease the development by providing the IDE type hints.</p> Example <p>A Lambda function using LambdaContext</p> <pre><code>&gt;&gt;&gt; from typing import Any\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.typing import LambdaContext\n&gt;&gt;&gt;\n&gt;&gt;&gt; def handler(event: dict[str, Any], context: LambdaContext) -&gt; dict[str, Any]:\n&gt;&gt;&gt;     # Insert business logic\n&gt;&gt;&gt;     return event\n</code></pre> METHOD DESCRIPTION <code>get_remaining_time_in_millis</code> <p>Returns the number of milliseconds left before the execution times out.</p> ATTRIBUTE DESCRIPTION <code>aws_request_id</code> <p>The identifier of the invocation request.</p> <p> TYPE: <code>str</code> </p> <code>client_context</code> <p>(mobile apps) Client context that's provided to Lambda by the client application.</p> <p> TYPE: <code>LambdaClientContext</code> </p> <code>function_name</code> <p>The name of the Lambda function.</p> <p> TYPE: <code>str</code> </p> <code>function_version</code> <p>The version of the function.</p> <p> TYPE: <code>str</code> </p> <code>identity</code> <p>(mobile apps) Information about the Amazon Cognito identity that authorized the request.</p> <p> TYPE: <code>LambdaCognitoIdentity</code> </p> <code>invoked_function_arn</code> <p>The Amazon Resource Name (ARN) that's used to invoke the function. Indicates if the invoker specified a</p> <p> TYPE: <code>str</code> </p> <code>log_group_name</code> <p>The log group for the function.</p> <p> TYPE: <code>str</code> </p> <code>log_stream_name</code> <p>The log stream for the function instance.</p> <p> TYPE: <code>str</code> </p> <code>memory_limit_in_mb</code> <p>The amount of memory that's allocated for the function.</p> <p> TYPE: <code>int</code> </p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext.aws_request_id",
            "title": "aws_request_id  <code>property</code>",
            "text": "<pre><code>aws_request_id: str\n</code></pre> <p>The identifier of the invocation request.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext.client_context",
            "title": "client_context  <code>property</code>",
            "text": "<pre><code>client_context: LambdaClientContext\n</code></pre> <p>(mobile apps) Client context that's provided to Lambda by the client application.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext.function_name",
            "title": "function_name  <code>property</code>",
            "text": "<pre><code>function_name: str\n</code></pre> <p>The name of the Lambda function.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext.function_version",
            "title": "function_version  <code>property</code>",
            "text": "<pre><code>function_version: str\n</code></pre> <p>The version of the function.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext.identity",
            "title": "identity  <code>property</code>",
            "text": "<pre><code>identity: LambdaCognitoIdentity\n</code></pre> <p>(mobile apps) Information about the Amazon Cognito identity that authorized the request.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext.invoked_function_arn",
            "title": "invoked_function_arn  <code>property</code>",
            "text": "<pre><code>invoked_function_arn: str\n</code></pre> <p>The Amazon Resource Name (ARN) that's used to invoke the function. Indicates if the invoker specified a version number or alias.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext.log_group_name",
            "title": "log_group_name  <code>property</code>",
            "text": "<pre><code>log_group_name: str\n</code></pre> <p>The log group for the function.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext.log_stream_name",
            "title": "log_stream_name  <code>property</code>",
            "text": "<pre><code>log_stream_name: str\n</code></pre> <p>The log stream for the function instance.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext.memory_limit_in_mb",
            "title": "memory_limit_in_mb  <code>property</code>",
            "text": "<pre><code>memory_limit_in_mb: int\n</code></pre> <p>The amount of memory that's allocated for the function.</p>"
        },
        {
            "location": "api_doc/typing/#aws_lambda_powertools.utilities.typing.lambda_context.LambdaContext.get_remaining_time_in_millis",
            "title": "get_remaining_time_in_millis  <code>staticmethod</code>",
            "text": "<pre><code>get_remaining_time_in_millis() -&gt; int\n</code></pre> <p>Returns the number of milliseconds left before the execution times out.</p> Source code in <code>aws_lambda_powertools/utilities/typing/lambda_context.py</code> <pre><code>@staticmethod\ndef get_remaining_time_in_millis() -&gt; int:\n    \"\"\"Returns the number of milliseconds left before the execution times out.\"\"\"\n    return 0\n</code></pre>"
        },
        {
            "location": "api_doc/validation/",
            "title": "Validation",
            "text": "<p>Simple validator to enforce incoming/outgoing event conforms with JSON Schema</p> <p>Usage Documentation</p> <p><code>Validation</code></p> MODULE DESCRIPTION <code>base</code> <code>envelopes</code> <p>Built-in envelopes</p> <code>exceptions</code> <code>validator</code> CLASS DESCRIPTION <code>InvalidEnvelopeExpressionError</code> <p>When JMESPath fails to parse expression</p> <code>InvalidSchemaFormatError</code> <p>When JSON Schema is in invalid format</p> <code>SchemaValidationError</code> <p>When serialization fail schema validation</p> FUNCTION DESCRIPTION <code>validate</code> <p>Standalone function to validate event data using a JSON Schema</p>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.InvalidEnvelopeExpressionError",
            "title": "InvalidEnvelopeExpressionError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>When JMESPath fails to parse expression</p>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.InvalidSchemaFormatError",
            "title": "InvalidSchemaFormatError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>When JSON Schema is in invalid format</p>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.SchemaValidationError",
            "title": "SchemaValidationError",
            "text": "<pre><code>SchemaValidationError(\n    message: str | None = None,\n    validation_message: str | None = None,\n    name: str | None = None,\n    path: list | None = None,\n    value: Any | None = None,\n    definition: Any | None = None,\n    rule: str | None = None,\n    rule_definition: Any | None = None,\n)\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>When serialization fail schema validation</p> PARAMETER DESCRIPTION <code>message</code> <p>Powertools for AWS Lambda (Python) formatted error message</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>validation_message</code> <p>Containing human-readable information what is wrong (e.g. <code>data.property[index] must be smaller than or equal to 42</code>)</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>name of a path in the data structure (e.g. <code>data.property[index]</code>)</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>path</code> <p><code>path</code> as an array in the data structure (e.g. <code>['data', 'property', 'index']</code>),</p> <p> TYPE: <code>list | None</code> DEFAULT: <code>None</code> </p> <code>value</code> <p>The invalid value</p> <p> TYPE: <code>Any</code> DEFAULT: <code>None</code> </p> <code>definition</code> <p>The full rule <code>definition</code> (e.g. <code>42</code>)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>None</code> </p> <code>rule</code> <p><code>rule</code> which the <code>data</code> is breaking (e.g. <code>maximum</code>)</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>rule_definition</code> <p>The specific rule <code>definition</code> (e.g. <code>42</code>)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/utilities/validation/exceptions.py</code> <pre><code>def __init__(\n    self,\n    message: str | None = None,\n    validation_message: str | None = None,\n    name: str | None = None,\n    path: list | None = None,\n    value: Any | None = None,\n    definition: Any | None = None,\n    rule: str | None = None,\n    rule_definition: Any | None = None,\n):\n    \"\"\"When serialization fail schema validation\n\n    Parameters\n    ----------\n    message : str, optional\n        Powertools for AWS Lambda (Python) formatted error message\n    validation_message : str, optional\n        Containing human-readable information what is wrong\n        (e.g. `data.property[index] must be smaller than or equal to 42`)\n    name : str, optional\n        name of a path in the data structure\n        (e.g. `data.property[index]`)\n    path: list, optional\n        `path` as an array in the data structure\n        (e.g. `['data', 'property', 'index']`),\n    value : Any, optional\n        The invalid value\n    definition : Any, optional\n        The full rule `definition`\n        (e.g. `42`)\n    rule : str, optional\n        `rule` which the `data` is breaking\n        (e.g. `maximum`)\n    rule_definition : Any, optional\n        The specific rule `definition`\n        (e.g. `42`)\n    \"\"\"\n    super().__init__(message)\n    self.message = message\n    self.validation_message = validation_message\n    self.name = name\n    self.path = path\n    self.value = value\n    self.definition = definition\n    self.rule = rule\n    self.rule_definition = rule_definition\n</code></pre>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.validate",
            "title": "validate",
            "text": "<pre><code>validate(\n    event: Any,\n    schema: dict,\n    formats: dict | None = None,\n    handlers: dict | None = None,\n    provider_options: dict | None = None,\n    envelope: str | None = None,\n    jmespath_options: dict | None = None,\n) -&gt; Any\n</code></pre> <p>Standalone function to validate event data using a JSON Schema</p> <p>Typically used when you need more control over the validation process.</p> PARAMETER DESCRIPTION <code>event</code> <p>Lambda event to be validated</p> <p> TYPE: <code>dict</code> </p> <code>schema</code> <p>JSON Schema to validate incoming event</p> <p> TYPE: <code>dict</code> </p> <code>envelope</code> <p>JMESPath expression to filter data against</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>jmespath_options</code> <p>Alternative JMESPath options to be included when filtering expr</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>formats</code> <p>Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>handlers</code> <p>Custom methods to retrieve remote schemes, keyed off of URI scheme</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>provider_options</code> <p>Arguments that will be passed directly to the underlying validate call</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> Example <p>Validate event</p> <pre><code>from aws_lambda_powertools.utilities.validation import validate\n\ndef handler(event, context):\n    validate(event=event, schema=json_schema_dict)\n    return event\n</code></pre> <p>Unwrap event before validating against actual payload - using built-in envelopes</p> <pre><code>from aws_lambda_powertools.utilities.validation import validate, envelopes\n\ndef handler(event, context):\n    validate(event=event, schema=json_schema_dict, envelope=envelopes.API_GATEWAY_REST)\n    return event\n</code></pre> <p>Unwrap event before validating against actual payload - using custom JMESPath expression</p> <pre><code>from aws_lambda_powertools.utilities.validation import validate\n\ndef handler(event, context):\n    validate(event=event, schema=json_schema_dict, envelope=\"payload[*].my_data\")\n    return event\n</code></pre> <p>Unwrap and deserialize JSON string event before validating against actual payload - using built-in functions</p> <pre><code>from aws_lambda_powertools.utilities.validation import validate\n\ndef handler(event, context):\n    validate(event=event, schema=json_schema_dict, envelope=\"Records[*].powertools_json(body)\")\n    return event\n</code></pre> <p>Unwrap, decode base64 and deserialize JSON string event before validating against actual payload - using built-in functions</p> <pre><code>from aws_lambda_powertools.utilities.validation import validate\n\ndef handler(event, context):\n    validate(event=event, schema=json_schema_dict, envelope=\"Records[*].kinesis.powertools_json(powertools_base64(data))\")\n    return event\n</code></pre> <p>Unwrap, decompress ZIP archive and deserialize JSON string event before validating against actual payload - using built-in functions</p> <pre><code>from aws_lambda_powertools.utilities.validation import validate\n\ndef handler(event, context):\n    validate(event=event, schema=json_schema_dict, envelope=\"awslogs.powertools_base64_gzip(data) | powertools_json(@).logEvents[*]\")\n    return event\n</code></pre> RETURNS DESCRIPTION <code>Dict</code> <p>The validated event. If the schema specifies a <code>default</code> value for fields that are omitted, those default values will be included in the response.</p> RAISES DESCRIPTION <code>SchemaValidationError</code> <p>When schema validation fails against data set</p> <code>InvalidSchemaFormatError</code> <p>When JSON schema provided is invalid</p> <code>InvalidEnvelopeExpressionError</code> <p>When JMESPath expression to unwrap event is invalid</p> Source code in <code>aws_lambda_powertools/utilities/validation/validator.py</code> <pre><code>def validate(\n    event: Any,\n    schema: dict,\n    formats: dict | None = None,\n    handlers: dict | None = None,\n    provider_options: dict | None = None,\n    envelope: str | None = None,\n    jmespath_options: dict | None = None,\n) -&gt; Any:\n    \"\"\"Standalone function to validate event data using a JSON Schema\n\n     Typically used when you need more control over the validation process.\n\n    Parameters\n    ----------\n    event : dict\n        Lambda event to be validated\n    schema : dict\n        JSON Schema to validate incoming event\n    envelope : dict\n        JMESPath expression to filter data against\n    jmespath_options : dict\n        Alternative JMESPath options to be included when filtering expr\n    formats: dict\n        Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool\n    handlers: Dict\n        Custom methods to retrieve remote schemes, keyed off of URI scheme\n    provider_options: Dict\n        Arguments that will be passed directly to the underlying validate call\n\n    Example\n    -------\n\n    **Validate event**\n\n        from aws_lambda_powertools.utilities.validation import validate\n\n        def handler(event, context):\n            validate(event=event, schema=json_schema_dict)\n            return event\n\n    **Unwrap event before validating against actual payload - using built-in envelopes**\n\n        from aws_lambda_powertools.utilities.validation import validate, envelopes\n\n        def handler(event, context):\n            validate(event=event, schema=json_schema_dict, envelope=envelopes.API_GATEWAY_REST)\n            return event\n\n    **Unwrap event before validating against actual payload - using custom JMESPath expression**\n\n        from aws_lambda_powertools.utilities.validation import validate\n\n        def handler(event, context):\n            validate(event=event, schema=json_schema_dict, envelope=\"payload[*].my_data\")\n            return event\n\n    **Unwrap and deserialize JSON string event before validating against actual payload - using built-in functions**\n\n        from aws_lambda_powertools.utilities.validation import validate\n\n        def handler(event, context):\n            validate(event=event, schema=json_schema_dict, envelope=\"Records[*].powertools_json(body)\")\n            return event\n\n    **Unwrap, decode base64 and deserialize JSON string event before validating against actual payload - using built-in functions**\n\n        from aws_lambda_powertools.utilities.validation import validate\n\n        def handler(event, context):\n            validate(event=event, schema=json_schema_dict, envelope=\"Records[*].kinesis.powertools_json(powertools_base64(data))\")\n            return event\n\n    **Unwrap, decompress ZIP archive and deserialize JSON string event before validating against actual payload - using built-in functions**\n\n        from aws_lambda_powertools.utilities.validation import validate\n\n        def handler(event, context):\n            validate(event=event, schema=json_schema_dict, envelope=\"awslogs.powertools_base64_gzip(data) | powertools_json(@).logEvents[*]\")\n            return event\n\n    Returns\n    -------\n    Dict\n        The validated event. If the schema specifies a `default` value for fields that are omitted,\n        those default values will be included in the response.\n\n    Raises\n    ------\n    SchemaValidationError\n        When schema validation fails against data set\n    InvalidSchemaFormatError\n        When JSON schema provided is invalid\n    InvalidEnvelopeExpressionError\n        When JMESPath expression to unwrap event is invalid\n    \"\"\"  # noqa: E501\n    if envelope:\n        event = jmespath_utils.query(\n            data=event,\n            envelope=envelope,\n            jmespath_options=jmespath_options,\n        )\n\n    return validate_data_against_schema(\n        data=event,\n        schema=schema,\n        formats=formats,\n        handlers=handlers,\n        provider_options=provider_options,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.base",
            "title": "base",
            "text": "FUNCTION DESCRIPTION <code>validate_data_against_schema</code> <p>Validate dict data against given JSON Schema</p>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.base.validate_data_against_schema",
            "title": "validate_data_against_schema",
            "text": "<pre><code>validate_data_against_schema(\n    data: dict | str,\n    schema: dict,\n    formats: dict | None = None,\n    handlers: dict | None = None,\n    provider_options: dict | None = None,\n) -&gt; dict | str\n</code></pre> <p>Validate dict data against given JSON Schema</p> PARAMETER DESCRIPTION <code>data</code> <p>Data set to be validated</p> <p> TYPE: <code>dict</code> </p> <code>schema</code> <p>JSON Schema to validate against</p> <p> TYPE: <code>dict</code> </p> <code>formats</code> <p>Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>handlers</code> <p>Custom methods to retrieve remote schemes, keyed off of URI scheme</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>provider_options</code> <p>Arguments that will be passed directly to the underlying validation call, in this case fastjsonchema.validate. For all supported arguments see: https://horejsek.github.io/python-fastjsonschema/#fastjsonschema.validate</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dict</code> <p>The validated event. If the schema specifies a <code>default</code> value for fields that are omitted, those default values will be included in the response.</p> RAISES DESCRIPTION <code>SchemaValidationError</code> <p>When schema validation fails against data set</p> <code>InvalidSchemaFormatError</code> <p>When JSON schema provided is invalid</p> Source code in <code>aws_lambda_powertools/utilities/validation/base.py</code> <pre><code>def validate_data_against_schema(\n    data: dict | str,\n    schema: dict,\n    formats: dict | None = None,\n    handlers: dict | None = None,\n    provider_options: dict | None = None,\n) -&gt; dict | str:\n    \"\"\"Validate dict data against given JSON Schema\n\n    Parameters\n    ----------\n    data : dict\n        Data set to be validated\n    schema : dict\n        JSON Schema to validate against\n    formats: dict\n        Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool\n    handlers: Dict\n        Custom methods to retrieve remote schemes, keyed off of URI scheme\n    provider_options: Dict\n        Arguments that will be passed directly to the underlying validation call, in this case fastjsonchema.validate.\n        For all supported arguments see: https://horejsek.github.io/python-fastjsonschema/#fastjsonschema.validate\n\n    Returns\n    -------\n    Dict\n        The validated event. If the schema specifies a `default` value for fields that are omitted,\n        those default values will be included in the response.\n\n    Raises\n    ------\n    SchemaValidationError\n        When schema validation fails against data set\n    InvalidSchemaFormatError\n        When JSON schema provided is invalid\n    \"\"\"\n    try:\n        formats = formats or {}\n        handlers = handlers or {}\n        provider_options = provider_options or {}\n        return fastjsonschema.validate(\n            definition=schema,\n            data=data,\n            formats=formats,\n            handlers=handlers,\n            **provider_options,\n        )\n    except (TypeError, AttributeError, fastjsonschema.JsonSchemaDefinitionException) as e:\n        raise InvalidSchemaFormatError(f\"Schema received: {schema}, Formats: {formats}. Error: {e}\")\n    except fastjsonschema.JsonSchemaValueException as e:\n        message = f\"Failed schema validation. Error: {e.message}, Path: {e.path}, Data: {e.value}\"  # noqa: B306\n        raise SchemaValidationError(\n            message,\n            validation_message=e.message,  # noqa: B306\n            name=e.name,\n            path=e.path,\n            value=e.value,\n            definition=e.definition,\n            rule=e.rule,\n            rule_definition=e.rule_definition,\n        )\n</code></pre>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.envelopes",
            "title": "envelopes",
            "text": "<p>Built-in envelopes</p>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.exceptions",
            "title": "exceptions",
            "text": "CLASS DESCRIPTION <code>InvalidEnvelopeExpressionError</code> <p>When JMESPath fails to parse expression</p> <code>InvalidSchemaFormatError</code> <p>When JSON Schema is in invalid format</p> <code>SchemaValidationError</code> <p>When serialization fail schema validation</p>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.exceptions.InvalidEnvelopeExpressionError",
            "title": "InvalidEnvelopeExpressionError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>When JMESPath fails to parse expression</p>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.exceptions.InvalidSchemaFormatError",
            "title": "InvalidSchemaFormatError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>When JSON Schema is in invalid format</p>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.exceptions.SchemaValidationError",
            "title": "SchemaValidationError",
            "text": "<pre><code>SchemaValidationError(\n    message: str | None = None,\n    validation_message: str | None = None,\n    name: str | None = None,\n    path: list | None = None,\n    value: Any | None = None,\n    definition: Any | None = None,\n    rule: str | None = None,\n    rule_definition: Any | None = None,\n)\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>When serialization fail schema validation</p> PARAMETER DESCRIPTION <code>message</code> <p>Powertools for AWS Lambda (Python) formatted error message</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>validation_message</code> <p>Containing human-readable information what is wrong (e.g. <code>data.property[index] must be smaller than or equal to 42</code>)</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>name</code> <p>name of a path in the data structure (e.g. <code>data.property[index]</code>)</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>path</code> <p><code>path</code> as an array in the data structure (e.g. <code>['data', 'property', 'index']</code>),</p> <p> TYPE: <code>list | None</code> DEFAULT: <code>None</code> </p> <code>value</code> <p>The invalid value</p> <p> TYPE: <code>Any</code> DEFAULT: <code>None</code> </p> <code>definition</code> <p>The full rule <code>definition</code> (e.g. <code>42</code>)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>None</code> </p> <code>rule</code> <p><code>rule</code> which the <code>data</code> is breaking (e.g. <code>maximum</code>)</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>rule_definition</code> <p>The specific rule <code>definition</code> (e.g. <code>42</code>)</p> <p> TYPE: <code>Any</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/utilities/validation/exceptions.py</code> <pre><code>def __init__(\n    self,\n    message: str | None = None,\n    validation_message: str | None = None,\n    name: str | None = None,\n    path: list | None = None,\n    value: Any | None = None,\n    definition: Any | None = None,\n    rule: str | None = None,\n    rule_definition: Any | None = None,\n):\n    \"\"\"When serialization fail schema validation\n\n    Parameters\n    ----------\n    message : str, optional\n        Powertools for AWS Lambda (Python) formatted error message\n    validation_message : str, optional\n        Containing human-readable information what is wrong\n        (e.g. `data.property[index] must be smaller than or equal to 42`)\n    name : str, optional\n        name of a path in the data structure\n        (e.g. `data.property[index]`)\n    path: list, optional\n        `path` as an array in the data structure\n        (e.g. `['data', 'property', 'index']`),\n    value : Any, optional\n        The invalid value\n    definition : Any, optional\n        The full rule `definition`\n        (e.g. `42`)\n    rule : str, optional\n        `rule` which the `data` is breaking\n        (e.g. `maximum`)\n    rule_definition : Any, optional\n        The specific rule `definition`\n        (e.g. `42`)\n    \"\"\"\n    super().__init__(message)\n    self.message = message\n    self.validation_message = validation_message\n    self.name = name\n    self.path = path\n    self.value = value\n    self.definition = definition\n    self.rule = rule\n    self.rule_definition = rule_definition\n</code></pre>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.validator",
            "title": "validator",
            "text": "FUNCTION DESCRIPTION <code>validate</code> <p>Standalone function to validate event data using a JSON Schema</p> <code>validator</code> <p>Lambda handler decorator to validate incoming/outbound data using a JSON Schema</p>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.validator.validate",
            "title": "validate",
            "text": "<pre><code>validate(\n    event: Any,\n    schema: dict,\n    formats: dict | None = None,\n    handlers: dict | None = None,\n    provider_options: dict | None = None,\n    envelope: str | None = None,\n    jmespath_options: dict | None = None,\n) -&gt; Any\n</code></pre> <p>Standalone function to validate event data using a JSON Schema</p> <p>Typically used when you need more control over the validation process.</p> PARAMETER DESCRIPTION <code>event</code> <p>Lambda event to be validated</p> <p> TYPE: <code>dict</code> </p> <code>schema</code> <p>JSON Schema to validate incoming event</p> <p> TYPE: <code>dict</code> </p> <code>envelope</code> <p>JMESPath expression to filter data against</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>jmespath_options</code> <p>Alternative JMESPath options to be included when filtering expr</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>formats</code> <p>Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>handlers</code> <p>Custom methods to retrieve remote schemes, keyed off of URI scheme</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>provider_options</code> <p>Arguments that will be passed directly to the underlying validate call</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> Example <p>Validate event</p> <pre><code>from aws_lambda_powertools.utilities.validation import validate\n\ndef handler(event, context):\n    validate(event=event, schema=json_schema_dict)\n    return event\n</code></pre> <p>Unwrap event before validating against actual payload - using built-in envelopes</p> <pre><code>from aws_lambda_powertools.utilities.validation import validate, envelopes\n\ndef handler(event, context):\n    validate(event=event, schema=json_schema_dict, envelope=envelopes.API_GATEWAY_REST)\n    return event\n</code></pre> <p>Unwrap event before validating against actual payload - using custom JMESPath expression</p> <pre><code>from aws_lambda_powertools.utilities.validation import validate\n\ndef handler(event, context):\n    validate(event=event, schema=json_schema_dict, envelope=\"payload[*].my_data\")\n    return event\n</code></pre> <p>Unwrap and deserialize JSON string event before validating against actual payload - using built-in functions</p> <pre><code>from aws_lambda_powertools.utilities.validation import validate\n\ndef handler(event, context):\n    validate(event=event, schema=json_schema_dict, envelope=\"Records[*].powertools_json(body)\")\n    return event\n</code></pre> <p>Unwrap, decode base64 and deserialize JSON string event before validating against actual payload - using built-in functions</p> <pre><code>from aws_lambda_powertools.utilities.validation import validate\n\ndef handler(event, context):\n    validate(event=event, schema=json_schema_dict, envelope=\"Records[*].kinesis.powertools_json(powertools_base64(data))\")\n    return event\n</code></pre> <p>Unwrap, decompress ZIP archive and deserialize JSON string event before validating against actual payload - using built-in functions</p> <pre><code>from aws_lambda_powertools.utilities.validation import validate\n\ndef handler(event, context):\n    validate(event=event, schema=json_schema_dict, envelope=\"awslogs.powertools_base64_gzip(data) | powertools_json(@).logEvents[*]\")\n    return event\n</code></pre> RETURNS DESCRIPTION <code>Dict</code> <p>The validated event. If the schema specifies a <code>default</code> value for fields that are omitted, those default values will be included in the response.</p> RAISES DESCRIPTION <code>SchemaValidationError</code> <p>When schema validation fails against data set</p> <code>InvalidSchemaFormatError</code> <p>When JSON schema provided is invalid</p> <code>InvalidEnvelopeExpressionError</code> <p>When JMESPath expression to unwrap event is invalid</p> Source code in <code>aws_lambda_powertools/utilities/validation/validator.py</code> <pre><code>def validate(\n    event: Any,\n    schema: dict,\n    formats: dict | None = None,\n    handlers: dict | None = None,\n    provider_options: dict | None = None,\n    envelope: str | None = None,\n    jmespath_options: dict | None = None,\n) -&gt; Any:\n    \"\"\"Standalone function to validate event data using a JSON Schema\n\n     Typically used when you need more control over the validation process.\n\n    Parameters\n    ----------\n    event : dict\n        Lambda event to be validated\n    schema : dict\n        JSON Schema to validate incoming event\n    envelope : dict\n        JMESPath expression to filter data against\n    jmespath_options : dict\n        Alternative JMESPath options to be included when filtering expr\n    formats: dict\n        Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool\n    handlers: Dict\n        Custom methods to retrieve remote schemes, keyed off of URI scheme\n    provider_options: Dict\n        Arguments that will be passed directly to the underlying validate call\n\n    Example\n    -------\n\n    **Validate event**\n\n        from aws_lambda_powertools.utilities.validation import validate\n\n        def handler(event, context):\n            validate(event=event, schema=json_schema_dict)\n            return event\n\n    **Unwrap event before validating against actual payload - using built-in envelopes**\n\n        from aws_lambda_powertools.utilities.validation import validate, envelopes\n\n        def handler(event, context):\n            validate(event=event, schema=json_schema_dict, envelope=envelopes.API_GATEWAY_REST)\n            return event\n\n    **Unwrap event before validating against actual payload - using custom JMESPath expression**\n\n        from aws_lambda_powertools.utilities.validation import validate\n\n        def handler(event, context):\n            validate(event=event, schema=json_schema_dict, envelope=\"payload[*].my_data\")\n            return event\n\n    **Unwrap and deserialize JSON string event before validating against actual payload - using built-in functions**\n\n        from aws_lambda_powertools.utilities.validation import validate\n\n        def handler(event, context):\n            validate(event=event, schema=json_schema_dict, envelope=\"Records[*].powertools_json(body)\")\n            return event\n\n    **Unwrap, decode base64 and deserialize JSON string event before validating against actual payload - using built-in functions**\n\n        from aws_lambda_powertools.utilities.validation import validate\n\n        def handler(event, context):\n            validate(event=event, schema=json_schema_dict, envelope=\"Records[*].kinesis.powertools_json(powertools_base64(data))\")\n            return event\n\n    **Unwrap, decompress ZIP archive and deserialize JSON string event before validating against actual payload - using built-in functions**\n\n        from aws_lambda_powertools.utilities.validation import validate\n\n        def handler(event, context):\n            validate(event=event, schema=json_schema_dict, envelope=\"awslogs.powertools_base64_gzip(data) | powertools_json(@).logEvents[*]\")\n            return event\n\n    Returns\n    -------\n    Dict\n        The validated event. If the schema specifies a `default` value for fields that are omitted,\n        those default values will be included in the response.\n\n    Raises\n    ------\n    SchemaValidationError\n        When schema validation fails against data set\n    InvalidSchemaFormatError\n        When JSON schema provided is invalid\n    InvalidEnvelopeExpressionError\n        When JMESPath expression to unwrap event is invalid\n    \"\"\"  # noqa: E501\n    if envelope:\n        event = jmespath_utils.query(\n            data=event,\n            envelope=envelope,\n            jmespath_options=jmespath_options,\n        )\n\n    return validate_data_against_schema(\n        data=event,\n        schema=schema,\n        formats=formats,\n        handlers=handlers,\n        provider_options=provider_options,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/validation/#aws_lambda_powertools.utilities.validation.validator.validator",
            "title": "validator",
            "text": "<pre><code>validator(\n    handler: Callable,\n    event: dict | str,\n    context: Any,\n    inbound_schema: dict | None = None,\n    inbound_formats: dict | None = None,\n    inbound_handlers: dict | None = None,\n    inbound_provider_options: dict | None = None,\n    outbound_schema: dict | None = None,\n    outbound_formats: dict | None = None,\n    outbound_handlers: dict | None = None,\n    outbound_provider_options: dict | None = None,\n    envelope: str = \"\",\n    jmespath_options: dict | None = None,\n    **kwargs: Any\n) -&gt; Any\n</code></pre> <p>Lambda handler decorator to validate incoming/outbound data using a JSON Schema</p> PARAMETER DESCRIPTION <code>handler</code> <p>Method to annotate on</p> <p> TYPE: <code>Callable</code> </p> <code>event</code> <p>Lambda event to be validated</p> <p> TYPE: <code>dict</code> </p> <code>context</code> <p>Lambda context object</p> <p> TYPE: <code>Any</code> </p> <code>inbound_schema</code> <p>JSON Schema to validate incoming event</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>outbound_schema</code> <p>JSON Schema to validate outbound event</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>envelope</code> <p>JMESPath expression to filter data against</p> <p> TYPE: <code>dict</code> DEFAULT: <code>''</code> </p> <code>jmespath_options</code> <p>Alternative JMESPath options to be included when filtering expr</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>inbound_formats</code> <p>Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>outbound_formats</code> <p>Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>inbound_handlers</code> <p>Custom methods to retrieve remote schemes, keyed off of URI scheme</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>outbound_handlers</code> <p>Custom methods to retrieve remote schemes, keyed off of URI scheme</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>inbound_provider_options</code> <p>Arguments that will be passed directly to the underlying validation call, in this case fastjsonchema.validate. For all supported arguments see: https://horejsek.github.io/python-fastjsonschema/#fastjsonschema.validate</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>outbound_provider_options</code> <p>Arguments that will be passed directly to the underlying validation call, in this case fastjsonchema.validate. For all supported arguments see: https://horejsek.github.io/python-fastjsonschema/#fastjsonschema.validate</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> Example <p>Validate incoming event</p> <pre><code>from aws_lambda_powertools.utilities.validation import validator\n\n@validator(inbound_schema=json_schema_dict)\ndef handler(event, context):\n    return event\n</code></pre> <p>Validate incoming and outgoing event</p> <pre><code>from aws_lambda_powertools.utilities.validation import validator\n\n@validator(inbound_schema=json_schema_dict, outbound_schema=response_json_schema_dict)\ndef handler(event, context):\n    return event\n</code></pre> <p>Unwrap event before validating against actual payload - using built-in envelopes</p> <pre><code>from aws_lambda_powertools.utilities.validation import validator, envelopes\n\n@validator(inbound_schema=json_schema_dict, envelope=envelopes.API_GATEWAY_REST)\ndef handler(event, context):\n    return event\n</code></pre> <p>Unwrap event before validating against actual payload - using custom JMESPath expression</p> <pre><code>from aws_lambda_powertools.utilities.validation import validator\n\n@validator(inbound_schema=json_schema_dict, envelope=\"payload[*].my_data\")\ndef handler(event, context):\n    return event\n</code></pre> <p>Unwrap and deserialize JSON string event before validating against actual payload - using built-in functions</p> <pre><code>from aws_lambda_powertools.utilities.validation import validator\n\n@validator(inbound_schema=json_schema_dict, envelope=\"Records[*].powertools_json(body)\")\ndef handler(event, context):\n    return event\n</code></pre> <p>Unwrap, decode base64 and deserialize JSON string event before validating against actual payload - using built-in functions</p> <pre><code>from aws_lambda_powertools.utilities.validation import validator\n\n@validator(inbound_schema=json_schema_dict, envelope=\"Records[*].kinesis.powertools_json(powertools_base64(data))\")\ndef handler(event, context):\n    return event\n</code></pre> <p>Unwrap, decompress ZIP archive and deserialize JSON string event before validating against actual payload - using built-in functions</p> <pre><code>from aws_lambda_powertools.utilities.validation import validator\n\n@validator(inbound_schema=json_schema_dict, envelope=\"awslogs.powertools_base64_gzip(data) | powertools_json(@).logEvents[*]\")\ndef handler(event, context):\n    return event\n</code></pre> RETURNS DESCRIPTION <code>Any</code> <p>Lambda handler response</p> RAISES DESCRIPTION <code>SchemaValidationError</code> <p>When schema validation fails against data set</p> <code>InvalidSchemaFormatError</code> <p>When JSON schema provided is invalid</p> <code>InvalidEnvelopeExpressionError</code> <p>When JMESPath expression to unwrap event is invalid</p> Source code in <code>aws_lambda_powertools/utilities/validation/validator.py</code> <pre><code>@lambda_handler_decorator\ndef validator(\n    handler: Callable,\n    event: dict | str,\n    context: Any,\n    inbound_schema: dict | None = None,\n    inbound_formats: dict | None = None,\n    inbound_handlers: dict | None = None,\n    inbound_provider_options: dict | None = None,\n    outbound_schema: dict | None = None,\n    outbound_formats: dict | None = None,\n    outbound_handlers: dict | None = None,\n    outbound_provider_options: dict | None = None,\n    envelope: str = \"\",\n    jmespath_options: dict | None = None,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"Lambda handler decorator to validate incoming/outbound data using a JSON Schema\n\n    Parameters\n    ----------\n    handler : Callable\n        Method to annotate on\n    event : dict\n        Lambda event to be validated\n    context : Any\n        Lambda context object\n    inbound_schema : dict\n        JSON Schema to validate incoming event\n    outbound_schema : dict\n        JSON Schema to validate outbound event\n    envelope : dict\n        JMESPath expression to filter data against\n    jmespath_options : dict\n        Alternative JMESPath options to be included when filtering expr\n    inbound_formats: dict\n        Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool\n    outbound_formats: dict\n        Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool\n    inbound_handlers: Dict\n        Custom methods to retrieve remote schemes, keyed off of URI scheme\n    outbound_handlers: Dict\n        Custom methods to retrieve remote schemes, keyed off of URI scheme\n    inbound_provider_options: Dict\n        Arguments that will be passed directly to the underlying validation call, in this case fastjsonchema.validate.\n        For all supported arguments see: https://horejsek.github.io/python-fastjsonschema/#fastjsonschema.validate\n    outbound_provider_options: Dict\n        Arguments that will be passed directly to the underlying validation call, in this case fastjsonchema.validate.\n        For all supported arguments see: https://horejsek.github.io/python-fastjsonschema/#fastjsonschema.validate\n\n\n    Example\n    -------\n\n    **Validate incoming event**\n\n        from aws_lambda_powertools.utilities.validation import validator\n\n        @validator(inbound_schema=json_schema_dict)\n        def handler(event, context):\n            return event\n\n    **Validate incoming and outgoing event**\n\n        from aws_lambda_powertools.utilities.validation import validator\n\n        @validator(inbound_schema=json_schema_dict, outbound_schema=response_json_schema_dict)\n        def handler(event, context):\n            return event\n\n    **Unwrap event before validating against actual payload - using built-in envelopes**\n\n        from aws_lambda_powertools.utilities.validation import validator, envelopes\n\n        @validator(inbound_schema=json_schema_dict, envelope=envelopes.API_GATEWAY_REST)\n        def handler(event, context):\n            return event\n\n    **Unwrap event before validating against actual payload - using custom JMESPath expression**\n\n        from aws_lambda_powertools.utilities.validation import validator\n\n        @validator(inbound_schema=json_schema_dict, envelope=\"payload[*].my_data\")\n        def handler(event, context):\n            return event\n\n    **Unwrap and deserialize JSON string event before validating against actual payload - using built-in functions**\n\n        from aws_lambda_powertools.utilities.validation import validator\n\n        @validator(inbound_schema=json_schema_dict, envelope=\"Records[*].powertools_json(body)\")\n        def handler(event, context):\n            return event\n\n    **Unwrap, decode base64 and deserialize JSON string event before validating against actual payload - using built-in functions**\n\n        from aws_lambda_powertools.utilities.validation import validator\n\n        @validator(inbound_schema=json_schema_dict, envelope=\"Records[*].kinesis.powertools_json(powertools_base64(data))\")\n        def handler(event, context):\n            return event\n\n    **Unwrap, decompress ZIP archive and deserialize JSON string event before validating against actual payload - using built-in functions**\n\n        from aws_lambda_powertools.utilities.validation import validator\n\n        @validator(inbound_schema=json_schema_dict, envelope=\"awslogs.powertools_base64_gzip(data) | powertools_json(@).logEvents[*]\")\n        def handler(event, context):\n            return event\n\n    Returns\n    -------\n    Any\n        Lambda handler response\n\n    Raises\n    ------\n    SchemaValidationError\n        When schema validation fails against data set\n    InvalidSchemaFormatError\n        When JSON schema provided is invalid\n    InvalidEnvelopeExpressionError\n        When JMESPath expression to unwrap event is invalid\n    \"\"\"  # noqa: E501\n    if envelope:\n        event = jmespath_utils.query(\n            data=event,\n            envelope=envelope,\n            jmespath_options=jmespath_options,\n        )\n\n    if inbound_schema:\n        logger.debug(\"Validating inbound event\")\n        validate_data_against_schema(\n            data=event,\n            schema=inbound_schema,\n            formats=inbound_formats,\n            handlers=inbound_handlers,\n            provider_options=inbound_provider_options,\n        )\n\n    response = handler(event, context, **kwargs)\n\n    if outbound_schema:\n        logger.debug(\"Validating outbound event\")\n        validate_data_against_schema(\n            data=response,\n            schema=outbound_schema,\n            formats=outbound_formats,\n            handlers=outbound_handlers,\n            provider_options=outbound_provider_options,\n        )\n\n    return response\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/",
            "title": "Base",
            "text": "<p>Batch processing utilities</p> <p>Usage Documentation</p> <p><code>Batch processing</code></p> CLASS DESCRIPTION <code>AsyncBatchProcessor</code> <p>Process native partial responses from SQS, Kinesis Data Streams, and DynamoDB asynchronously.</p> <code>BasePartialBatchProcessor</code> <code>BasePartialProcessor</code> <p>Abstract class for batch processors.</p> <code>BatchProcessor</code> <p>Process native partial responses from SQS, Kinesis Data Streams, and DynamoDB.</p>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.AsyncBatchProcessor",
            "title": "AsyncBatchProcessor",
            "text": "<pre><code>AsyncBatchProcessor(\n    event_type: EventType,\n    model: BatchTypeModels | None = None,\n    raise_on_entire_batch_failure: bool = True,\n)\n</code></pre> <p>               Bases: <code>BasePartialBatchProcessor</code></p> <p>Process native partial responses from SQS, Kinesis Data Streams, and DynamoDB asynchronously.</p> Example RAISES DESCRIPTION <code>BatchProcessingError</code> <p>When all batch records fail processing and raise_on_entire_batch_failure is True</p> Limitations <ul> <li>Sync record handler not supported, use BatchProcessor instead.</li> </ul> Source code in <code>aws_lambda_powertools/utilities/batch/base.py</code> <pre><code>def __init__(\n    self,\n    event_type: EventType,\n    model: BatchTypeModels | None = None,\n    raise_on_entire_batch_failure: bool = True,\n):\n    \"\"\"Process batch and partially report failed items\n\n    Parameters\n    ----------\n    event_type: EventType\n        Whether this is a SQS, DynamoDB Streams, or Kinesis Data Stream event\n    model: BatchTypeModels | None\n        Parser's data model using either SqsRecordModel, DynamoDBStreamRecordModel, KinesisDataStreamRecord\n    raise_on_entire_batch_failure: bool\n        Raise an exception when the entire batch has failed processing.\n        When set to False, partial failures are reported in the response\n\n    Exceptions\n    ----------\n    BatchProcessingError\n        Raised when the entire batch has failed processing\n    \"\"\"\n    self.event_type = event_type\n    self.model = model\n    self.raise_on_entire_batch_failure = raise_on_entire_batch_failure\n    self.batch_response: PartialItemFailureResponse = copy.deepcopy(self.DEFAULT_RESPONSE)\n    self._COLLECTOR_MAPPING = {\n        EventType.SQS: self._collect_sqs_failures,\n        EventType.KinesisDataStreams: self._collect_kinesis_failures,\n        EventType.DynamoDBStreams: self._collect_dynamodb_failures,\n    }\n    self._DATA_CLASS_MAPPING = {\n        EventType.SQS: SQSRecord,\n        EventType.KinesisDataStreams: KinesisStreamRecord,\n        EventType.DynamoDBStreams: DynamoDBRecord,\n    }\n\n    super().__init__()\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.AsyncBatchProcessor--process-batch-triggered-by-sqs",
            "title": "Process batch triggered by SQS",
            "text": "<pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\nasync def record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n    ...\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\n@batch_processor(record_handler=record_handler, processor=processor)\ndef lambda_handler(event, context: LambdaContext):\n    return processor.response()\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.AsyncBatchProcessor--process-batch-triggered-by-kinesis-data-streams",
            "title": "Process batch triggered by Kinesis Data Streams",
            "text": "<pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor\nfrom aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import KinesisStreamRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nprocessor = BatchProcessor(event_type=EventType.KinesisDataStreams)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\nasync def record_handler(record: KinesisStreamRecord):\n    logger.info(record.kinesis.data_as_text)\n    payload: dict = record.kinesis.data_as_json()\n    ...\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\n@batch_processor(record_handler=record_handler, processor=processor)\ndef lambda_handler(event, context: LambdaContext):\n    return processor.response()\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.AsyncBatchProcessor--process-batch-triggered-by-dynamodb-data-streams",
            "title": "Process batch triggered by DynamoDB Data Streams",
            "text": "<pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor\nfrom aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import DynamoDBRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nprocessor = BatchProcessor(event_type=EventType.DynamoDBStreams)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\nasync def record_handler(record: DynamoDBRecord):\n    logger.info(record.dynamodb.new_image)\n    payload: dict = json.loads(record.dynamodb.new_image.get(\"item\"))\n    # alternatively:\n    # changes: dict[str, Any] = record.dynamodb.new_image  # noqa: ERA001\n    # payload = change.get(\"Message\") -&gt; \"&lt;payload&gt;\"\n    ...\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    batch = event[\"Records\"]\n    with processor(records=batch, processor=processor):\n        processed_messages = processor.process() # kick off processing, return list[tuple]\n\n    return processor.response()\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor",
            "title": "BasePartialBatchProcessor",
            "text": "<pre><code>BasePartialBatchProcessor(\n    event_type: EventType,\n    model: BatchTypeModels | None = None,\n    raise_on_entire_batch_failure: bool = True,\n)\n</code></pre> <p>               Bases: <code>BasePartialProcessor</code></p> PARAMETER DESCRIPTION <code>event_type</code> <p>Whether this is a SQS, DynamoDB Streams, or Kinesis Data Stream event</p> <p> TYPE: <code>EventType</code> </p> <code>model</code> <p>Parser's data model using either SqsRecordModel, DynamoDBStreamRecordModel, KinesisDataStreamRecord</p> <p> TYPE: <code>BatchTypeModels | None</code> DEFAULT: <code>None</code> </p> <code>raise_on_entire_batch_failure</code> <p>Raise an exception when the entire batch has failed processing. When set to False, partial failures are reported in the response</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Exceptions <p>BatchProcessingError     Raised when the entire batch has failed processing</p> METHOD DESCRIPTION <code>response</code> <p>Batch items that failed processing, if any</p> Source code in <code>aws_lambda_powertools/utilities/batch/base.py</code> <pre><code>def __init__(\n    self,\n    event_type: EventType,\n    model: BatchTypeModels | None = None,\n    raise_on_entire_batch_failure: bool = True,\n):\n    \"\"\"Process batch and partially report failed items\n\n    Parameters\n    ----------\n    event_type: EventType\n        Whether this is a SQS, DynamoDB Streams, or Kinesis Data Stream event\n    model: BatchTypeModels | None\n        Parser's data model using either SqsRecordModel, DynamoDBStreamRecordModel, KinesisDataStreamRecord\n    raise_on_entire_batch_failure: bool\n        Raise an exception when the entire batch has failed processing.\n        When set to False, partial failures are reported in the response\n\n    Exceptions\n    ----------\n    BatchProcessingError\n        Raised when the entire batch has failed processing\n    \"\"\"\n    self.event_type = event_type\n    self.model = model\n    self.raise_on_entire_batch_failure = raise_on_entire_batch_failure\n    self.batch_response: PartialItemFailureResponse = copy.deepcopy(self.DEFAULT_RESPONSE)\n    self._COLLECTOR_MAPPING = {\n        EventType.SQS: self._collect_sqs_failures,\n        EventType.KinesisDataStreams: self._collect_kinesis_failures,\n        EventType.DynamoDBStreams: self._collect_dynamodb_failures,\n    }\n    self._DATA_CLASS_MAPPING = {\n        EventType.SQS: SQSRecord,\n        EventType.KinesisDataStreams: KinesisStreamRecord,\n        EventType.DynamoDBStreams: DynamoDBRecord,\n    }\n\n    super().__init__()\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.BasePartialBatchProcessor.response",
            "title": "response",
            "text": "<pre><code>response() -&gt; PartialItemFailureResponse\n</code></pre> <p>Batch items that failed processing, if any</p> Source code in <code>aws_lambda_powertools/utilities/batch/base.py</code> <pre><code>def response(self) -&gt; PartialItemFailureResponse:\n    \"\"\"Batch items that failed processing, if any\"\"\"\n    return self.batch_response\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor",
            "title": "BasePartialProcessor",
            "text": "<pre><code>BasePartialProcessor()\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract class for batch processors.</p> METHOD DESCRIPTION <code>async_process</code> <p>Async call instance's handler for each record.</p> <code>failure_handler</code> <p>Keeps track of batch records that failed processing</p> <code>process</code> <p>Call instance's handler for each record.</p> <code>success_handler</code> <p>Keeps track of batch records that were processed successfully</p> Source code in <code>aws_lambda_powertools/utilities/batch/base.py</code> <pre><code>def __init__(self):\n    self.success_messages: list[BatchEventTypes] = []\n    self.fail_messages: list[BatchEventTypes] = []\n    self.exceptions: list[ExceptionInfo] = []\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.async_process",
            "title": "async_process",
            "text": "<pre><code>async_process() -&gt; list[tuple]\n</code></pre> <p>Async call instance's handler for each record.</p> Note <p>We keep the outer function synchronous to prevent making Lambda handler async, so to not impact customers' existing middlewares. Instead, we create an async closure to handle asynchrony.</p> <p>We also handle edge cases like Lambda container thaw by getting an existing or creating an event loop.</p> <p>See: https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtime-environment.html#runtimes-lifecycle-shutdown</p> Source code in <code>aws_lambda_powertools/utilities/batch/base.py</code> <pre><code>def async_process(self) -&gt; list[tuple]:\n    \"\"\"\n    Async call instance's handler for each record.\n\n    Note\n    ----\n\n    We keep the outer function synchronous to prevent making Lambda handler async, so to not impact\n    customers' existing middlewares. Instead, we create an async closure to handle asynchrony.\n\n    We also handle edge cases like Lambda container thaw by getting an existing or creating an event loop.\n\n    See: https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtime-environment.html#runtimes-lifecycle-shutdown\n    \"\"\"\n\n    async def async_process_closure():\n        return list(await asyncio.gather(*[self._async_process_record(record) for record in self.records]))\n\n    # WARNING\n    # Do not use \"asyncio.run(async_process())\" due to Lambda container thaws/freeze, otherwise we might get \"Event Loop is closed\" # noqa: E501\n    # Instead, get_event_loop() can also create one if a previous was erroneously closed\n    # Mangum library does this as well. It's battle tested with other popular async-only frameworks like FastAPI\n    # https://github.com/jordaneremieff/mangum/discussions/256#discussioncomment-2638946\n    # https://github.com/jordaneremieff/mangum/blob/b85cd4a97f8ddd56094ccc540ca7156c76081745/mangum/protocols/http.py#L44\n\n    # Let's prime the coroutine and decide\n    # whether we create an event loop (Lambda) or schedule it as usual (non-Lambda)\n    coro = async_process_closure()\n    if os.getenv(constants.LAMBDA_TASK_ROOT_ENV):\n        loop = asyncio.get_event_loop()  # NOTE: this might return an error starting in Python 3.12 in a few years\n        task_instance = loop.create_task(coro)\n        return loop.run_until_complete(task_instance)\n\n    # Non-Lambda environment, run coroutine as usual\n    return asyncio.run(coro)\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.failure_handler",
            "title": "failure_handler",
            "text": "<pre><code>failure_handler(\n    record, exception: ExceptionInfo\n) -&gt; FailureResponse\n</code></pre> <p>Keeps track of batch records that failed processing</p> PARAMETER DESCRIPTION <code>record</code> <p>record that failed processing</p> <p> </p> <code>exception</code> <p>Exception information containing type, value, and traceback (sys.exc_info())</p> <p> TYPE: <code>ExceptionInfo</code> </p> RETURNS DESCRIPTION <code>FailureResponse</code> <p>\"fail\", exceptions args, original record</p> Source code in <code>aws_lambda_powertools/utilities/batch/base.py</code> <pre><code>def failure_handler(self, record, exception: ExceptionInfo) -&gt; FailureResponse:\n    \"\"\"\n    Keeps track of batch records that failed processing\n\n    Parameters\n    ----------\n    record: Any\n        record that failed processing\n    exception: ExceptionInfo\n        Exception information containing type, value, and traceback (sys.exc_info())\n\n    Returns\n    -------\n    FailureResponse\n        \"fail\", exceptions args, original record\n    \"\"\"\n    exception_string = f\"{exception[0]}:{exception[1]}\"\n    entry = (\"fail\", exception_string, record)\n    logger.debug(f\"Record processing exception: {exception_string}\")\n    self.exceptions.append(exception)\n    self.fail_messages.append(record)\n    return entry\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.process",
            "title": "process",
            "text": "<pre><code>process() -&gt; list[tuple]\n</code></pre> <p>Call instance's handler for each record.</p> Source code in <code>aws_lambda_powertools/utilities/batch/base.py</code> <pre><code>def process(self) -&gt; list[tuple]:\n    \"\"\"\n    Call instance's handler for each record.\n    \"\"\"\n    return [self._process_record(record) for record in self.records]\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.BasePartialProcessor.success_handler",
            "title": "success_handler",
            "text": "<pre><code>success_handler(record, result: Any) -&gt; SuccessResponse\n</code></pre> <p>Keeps track of batch records that were processed successfully</p> PARAMETER DESCRIPTION <code>record</code> <p>record that succeeded processing</p> <p> </p> <code>result</code> <p>result from record handler</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>SuccessResponse</code> <p>\"success\", result, original record</p> Source code in <code>aws_lambda_powertools/utilities/batch/base.py</code> <pre><code>def success_handler(self, record, result: Any) -&gt; SuccessResponse:\n    \"\"\"\n    Keeps track of batch records that were processed successfully\n\n    Parameters\n    ----------\n    record: Any\n        record that succeeded processing\n    result: Any\n        result from record handler\n\n    Returns\n    -------\n    SuccessResponse\n        \"success\", result, original record\n    \"\"\"\n    entry = (\"success\", result, record)\n    self.success_messages.append(record)\n    return entry\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.BatchProcessor",
            "title": "BatchProcessor",
            "text": "<pre><code>BatchProcessor(\n    event_type: EventType,\n    model: BatchTypeModels | None = None,\n    raise_on_entire_batch_failure: bool = True,\n)\n</code></pre> <p>               Bases: <code>BasePartialBatchProcessor</code></p> <p>Process native partial responses from SQS, Kinesis Data Streams, and DynamoDB.</p> Example RAISES DESCRIPTION <code>BatchProcessingError</code> <p>When all batch records fail processing and raise_on_entire_batch_failure is True</p> Limitations <ul> <li>Async record handler not supported, use AsyncBatchProcessor instead.</li> </ul> Source code in <code>aws_lambda_powertools/utilities/batch/base.py</code> <pre><code>def __init__(\n    self,\n    event_type: EventType,\n    model: BatchTypeModels | None = None,\n    raise_on_entire_batch_failure: bool = True,\n):\n    \"\"\"Process batch and partially report failed items\n\n    Parameters\n    ----------\n    event_type: EventType\n        Whether this is a SQS, DynamoDB Streams, or Kinesis Data Stream event\n    model: BatchTypeModels | None\n        Parser's data model using either SqsRecordModel, DynamoDBStreamRecordModel, KinesisDataStreamRecord\n    raise_on_entire_batch_failure: bool\n        Raise an exception when the entire batch has failed processing.\n        When set to False, partial failures are reported in the response\n\n    Exceptions\n    ----------\n    BatchProcessingError\n        Raised when the entire batch has failed processing\n    \"\"\"\n    self.event_type = event_type\n    self.model = model\n    self.raise_on_entire_batch_failure = raise_on_entire_batch_failure\n    self.batch_response: PartialItemFailureResponse = copy.deepcopy(self.DEFAULT_RESPONSE)\n    self._COLLECTOR_MAPPING = {\n        EventType.SQS: self._collect_sqs_failures,\n        EventType.KinesisDataStreams: self._collect_kinesis_failures,\n        EventType.DynamoDBStreams: self._collect_dynamodb_failures,\n    }\n    self._DATA_CLASS_MAPPING = {\n        EventType.SQS: SQSRecord,\n        EventType.KinesisDataStreams: KinesisStreamRecord,\n        EventType.DynamoDBStreams: DynamoDBRecord,\n    }\n\n    super().__init__()\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.BatchProcessor--process-batch-triggered-by-sqs",
            "title": "Process batch triggered by SQS",
            "text": "<pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n    ...\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\n@batch_processor(record_handler=record_handler, processor=processor)\ndef lambda_handler(event, context: LambdaContext):\n    return processor.response()\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.BatchProcessor--process-batch-triggered-by-kinesis-data-streams",
            "title": "Process batch triggered by Kinesis Data Streams",
            "text": "<pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor\nfrom aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import KinesisStreamRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nprocessor = BatchProcessor(event_type=EventType.KinesisDataStreams)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: KinesisStreamRecord):\n    logger.info(record.kinesis.data_as_text)\n    payload: dict = record.kinesis.data_as_json()\n    ...\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\n@batch_processor(record_handler=record_handler, processor=processor)\ndef lambda_handler(event, context: LambdaContext):\n    return processor.response()\n</code></pre>"
        },
        {
            "location": "api_doc/batch/base/#aws_lambda_powertools.utilities.batch.base.BatchProcessor--process-batch-triggered-by-dynamodb-data-streams",
            "title": "Process batch triggered by DynamoDB Data Streams",
            "text": "<pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, batch_processor\nfrom aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import DynamoDBRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nprocessor = BatchProcessor(event_type=EventType.DynamoDBStreams)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: DynamoDBRecord):\n    logger.info(record.dynamodb.new_image)\n    payload: dict = json.loads(record.dynamodb.new_image.get(\"item\"))\n    # alternatively:\n    # changes: dict[str, Any] = record.dynamodb.new_image  # noqa: ERA001\n    # payload = change.get(\"Message\") -&gt; \"&lt;payload&gt;\"\n    ...\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    batch = event[\"Records\"]\n    with processor(records=batch, processor=processor):\n        processed_messages = processor.process() # kick off processing, return list[tuple]\n\n    return processor.response()\n</code></pre>"
        },
        {
            "location": "api_doc/batch/decorators/",
            "title": "Decorators",
            "text": "FUNCTION DESCRIPTION <code>async_batch_processor</code> <p>Middleware to handle batch event processing</p> <code>async_process_partial_response</code> <p>Higher level function to handle batch event processing asynchronously.</p> <code>batch_processor</code> <p>Middleware to handle batch event processing</p> <code>process_partial_response</code> <p>Higher level function to handle batch event processing.</p> CLASS DESCRIPTION <code>SqsFifoPartialProcessor</code> <p>Process native partial responses from SQS FIFO queues.</p>"
        },
        {
            "location": "api_doc/batch/decorators/#aws_lambda_powertools.utilities.batch.decorators.async_batch_processor",
            "title": "async_batch_processor",
            "text": "<pre><code>async_batch_processor(\n    handler: Callable,\n    event: dict,\n    context: LambdaContext,\n    record_handler: Callable[..., Awaitable[Any]],\n    processor: AsyncBatchProcessor,\n)\n</code></pre> <p>Middleware to handle batch event processing</p> Notes <p>Consider using async_process_partial_response function for an easier experience.</p> PARAMETER DESCRIPTION <code>handler</code> <p>Lambda's handler</p> <p> TYPE: <code>Callable</code> </p> <code>event</code> <p>Lambda's Event</p> <p> TYPE: <code>dict</code> </p> <code>context</code> <p>Lambda's Context</p> <p> TYPE: <code>LambdaContext</code> </p> <code>record_handler</code> <p>Callable to process each record from the batch</p> <p> TYPE: <code>Callable[..., Awaitable[Any]]</code> </p> <code>processor</code> <p>Batch Processor to handle partial failure cases</p> <p> TYPE: <code>AsyncBatchProcessor</code> </p> Example <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.batch import async_batch_processor, AsyncBatchProcessor\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\n&gt;&gt;&gt;\n&gt;&gt;&gt; processor = AsyncBatchProcessor(event_type=EventType.SQS)\n&gt;&gt;&gt;\n&gt;&gt;&gt; async def async_record_handler(record: SQSRecord):\n&gt;&gt;&gt;     payload: str = record.body\n&gt;&gt;&gt;     return payload\n&gt;&gt;&gt;\n&gt;&gt;&gt; @async_batch_processor(record_handler=async_record_handler, processor=processor)\n&gt;&gt;&gt; def lambda_handler(event, context):\n&gt;&gt;&gt;     return processor.response()\n</code></pre> Limitations <ul> <li>Sync batch processors. Use <code>batch_processor</code> instead.</li> </ul> Source code in <code>aws_lambda_powertools/utilities/batch/decorators.py</code> <pre><code>@lambda_handler_decorator\n@deprecated(\n    \"`async_batch_processor` decorator is deprecated; use `async_process_partial_response` function instead.\",\n    category=None,\n)\ndef async_batch_processor(\n    handler: Callable,\n    event: dict,\n    context: LambdaContext,\n    record_handler: Callable[..., Awaitable[Any]],\n    processor: AsyncBatchProcessor,\n):\n    \"\"\"\n    Middleware to handle batch event processing\n\n    Notes\n    -----\n    Consider using async_process_partial_response function for an easier experience.\n\n    Parameters\n    ----------\n    handler: Callable\n        Lambda's handler\n    event: dict\n        Lambda's Event\n    context: LambdaContext\n        Lambda's Context\n    record_handler: Callable[..., Awaitable[Any]]\n        Callable to process each record from the batch\n    processor: AsyncBatchProcessor\n        Batch Processor to handle partial failure cases\n\n    Example\n    --------\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.batch import async_batch_processor, AsyncBatchProcessor\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; processor = AsyncBatchProcessor(event_type=EventType.SQS)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; async def async_record_handler(record: SQSRecord):\n        &gt;&gt;&gt;     payload: str = record.body\n        &gt;&gt;&gt;     return payload\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; @async_batch_processor(record_handler=async_record_handler, processor=processor)\n        &gt;&gt;&gt; def lambda_handler(event, context):\n        &gt;&gt;&gt;     return processor.response()\n\n    Limitations\n    -----------\n    * Sync batch processors. Use `batch_processor` instead.\n    \"\"\"\n\n    warnings.warn(\n        \"The `async_batch_processor` decorator is deprecated in V3 \"\n        \"and will be removed in the next major version. Use `async_process_partial_response` function instead.\",\n        category=PowertoolsDeprecationWarning,\n        stacklevel=2,\n    )\n\n    records = event[\"Records\"]\n\n    with processor(records, record_handler, lambda_context=context):\n        processor.async_process()\n\n    return handler(event, context)\n</code></pre>"
        },
        {
            "location": "api_doc/batch/decorators/#aws_lambda_powertools.utilities.batch.decorators.async_process_partial_response",
            "title": "async_process_partial_response",
            "text": "<pre><code>async_process_partial_response(\n    event: dict,\n    record_handler: Callable,\n    processor: AsyncBatchProcessor,\n    context: LambdaContext | None = None,\n) -&gt; PartialItemFailureResponse\n</code></pre> <p>Higher level function to handle batch event processing asynchronously.</p> PARAMETER DESCRIPTION <code>event</code> <p>Lambda's original event</p> <p> TYPE: <code>dict</code> </p> <code>record_handler</code> <p>Callable to process each record from the batch</p> <p> TYPE: <code>Callable</code> </p> <code>processor</code> <p>Batch Processor to handle partial failure cases</p> <p> TYPE: <code>AsyncBatchProcessor</code> </p> <code>context</code> <p>Lambda's context, used to optionally inject in record handler</p> <p> TYPE: <code>LambdaContext | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>result</code> <p>Lambda Partial Batch Response</p> <p> TYPE: <code>PartialItemFailureResponse</code> </p> Example <p>Processes Lambda's SQS event</p> <pre><code>from aws_lambda_powertools.utilities.batch import AsyncBatchProcessor, EventType, process_partial_response\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\n\nprocessor = BatchProcessor(EventType.SQS)\n\nasync def record_handler(record: SQSRecord):\n    return record.body\n\ndef handler(event, context):\n    return async_process_partial_response(\n        event=event, record_handler=record_handler, processor=processor, context=context\n    )\n</code></pre> Limitations <ul> <li>Sync batch processors. Use <code>process_partial_response</code> instead.</li> </ul> Source code in <code>aws_lambda_powertools/utilities/batch/decorators.py</code> <pre><code>def async_process_partial_response(\n    event: dict,\n    record_handler: Callable,\n    processor: AsyncBatchProcessor,\n    context: LambdaContext | None = None,\n) -&gt; PartialItemFailureResponse:\n    \"\"\"\n    Higher level function to handle batch event processing asynchronously.\n\n    Parameters\n    ----------\n    event: dict\n        Lambda's original event\n    record_handler: Callable\n        Callable to process each record from the batch\n    processor: AsyncBatchProcessor\n        Batch Processor to handle partial failure cases\n    context: LambdaContext\n        Lambda's context, used to optionally inject in record handler\n\n    Returns\n    -------\n    result: PartialItemFailureResponse\n        Lambda Partial Batch Response\n\n    Example\n    --------\n    **Processes Lambda's SQS event**\n\n    ```python\n    from aws_lambda_powertools.utilities.batch import AsyncBatchProcessor, EventType, process_partial_response\n    from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\n\n    processor = BatchProcessor(EventType.SQS)\n\n    async def record_handler(record: SQSRecord):\n        return record.body\n\n    def handler(event, context):\n        return async_process_partial_response(\n            event=event, record_handler=record_handler, processor=processor, context=context\n        )\n    ```\n\n    Limitations\n    -----------\n    * Sync batch processors. Use `process_partial_response` instead.\n    \"\"\"\n    try:\n        records: list[dict] = event.get(\"Records\", [])\n        if not records or not isinstance(records, list):\n            raise UnexpectedBatchTypeError(\n                \"Unexpected batch event type. Possible values are: SQS, KinesisDataStreams, DynamoDBStreams\",\n            )\n\n    except AttributeError:\n        event_types = \", \".join(list(EventType.__members__))\n        docs = \"https://docs.powertools.aws.dev/lambda/python/latest/utilities/batch/#processing-messages-from-sqs\"  # noqa: E501 # long-line\n        raise ValueError(\n            f\"Invalid event format. Please ensure batch event is a valid {processor.event_type.value} event. \\n\"\n            f\"See sample events in our documentation for either {event_types}: \\n {docs}\",\n        )\n\n    with processor(records, record_handler, context):\n        processor.async_process()\n\n    return processor.response()\n</code></pre>"
        },
        {
            "location": "api_doc/batch/decorators/#aws_lambda_powertools.utilities.batch.decorators.batch_processor",
            "title": "batch_processor",
            "text": "<pre><code>batch_processor(\n    handler: Callable,\n    event: dict,\n    context: LambdaContext,\n    record_handler: Callable,\n    processor: BatchProcessor,\n)\n</code></pre> <p>Middleware to handle batch event processing</p> Notes <p>Consider using process_partial_response function for an easier experience.</p> PARAMETER DESCRIPTION <code>handler</code> <p>Lambda's handler</p> <p> TYPE: <code>Callable</code> </p> <code>event</code> <p>Lambda's Event</p> <p> TYPE: <code>dict</code> </p> <code>context</code> <p>Lambda's Context</p> <p> TYPE: <code>LambdaContext</code> </p> <code>record_handler</code> <p>Callable or corutine to process each record from the batch</p> <p> TYPE: <code>Callable</code> </p> <code>processor</code> <p>Batch Processor to handle partial failure cases</p> <p> TYPE: <code>BatchProcessor</code> </p> Example <p>Processes Lambda's event with a BatchProcessor</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.batch import batch_processor, BatchProcessor, EventType\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\n&gt;&gt;&gt;\n&gt;&gt;&gt; processor = BatchProcessor(EventType.SQS)\n&gt;&gt;&gt;\n&gt;&gt;&gt; def record_handler(record):\n&gt;&gt;&gt;     return record[\"body\"]\n&gt;&gt;&gt;\n&gt;&gt;&gt; @batch_processor(record_handler=record_handler, processor=BatchProcessor())\n&gt;&gt;&gt; def handler(event, context):\n&gt;&gt;&gt;     return processor.response()\n</code></pre> Limitations <ul> <li>Async batch processors. Use <code>async_batch_processor</code> instead.</li> </ul> Source code in <code>aws_lambda_powertools/utilities/batch/decorators.py</code> <pre><code>@lambda_handler_decorator\n@deprecated(\n    \"`batch_processor` decorator is deprecated; use `process_partial_response` function instead.\",\n    category=None,\n)\ndef batch_processor(\n    handler: Callable,\n    event: dict,\n    context: LambdaContext,\n    record_handler: Callable,\n    processor: BatchProcessor,\n):\n    \"\"\"\n    Middleware to handle batch event processing\n\n    Notes\n    -----\n    Consider using process_partial_response function for an easier experience.\n\n    Parameters\n    ----------\n    handler: Callable\n        Lambda's handler\n    event: dict\n        Lambda's Event\n    context: LambdaContext\n        Lambda's Context\n    record_handler: Callable\n        Callable or corutine to process each record from the batch\n    processor: BatchProcessor\n        Batch Processor to handle partial failure cases\n\n    Example\n    --------\n    **Processes Lambda's event with a BatchProcessor**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.batch import batch_processor, BatchProcessor, EventType\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; processor = BatchProcessor(EventType.SQS)\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; def record_handler(record):\n        &gt;&gt;&gt;     return record[\"body\"]\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; @batch_processor(record_handler=record_handler, processor=BatchProcessor())\n        &gt;&gt;&gt; def handler(event, context):\n        &gt;&gt;&gt;     return processor.response()\n\n    Limitations\n    -----------\n    * Async batch processors. Use `async_batch_processor` instead.\n    \"\"\"\n\n    warnings.warn(\n        \"The `batch_processor` decorator is deprecated in V3 \"\n        \"and will be removed in the next major version. Use `process_partial_response` function instead.\",\n        category=PowertoolsDeprecationWarning,\n        stacklevel=2,\n    )\n\n    records = event[\"Records\"]\n\n    with processor(records, record_handler, lambda_context=context):\n        processor.process()\n\n    return handler(event, context)\n</code></pre>"
        },
        {
            "location": "api_doc/batch/decorators/#aws_lambda_powertools.utilities.batch.decorators.process_partial_response",
            "title": "process_partial_response",
            "text": "<pre><code>process_partial_response(\n    event: dict,\n    record_handler: Callable,\n    processor: BasePartialBatchProcessor,\n    context: LambdaContext | None = None,\n) -&gt; PartialItemFailureResponse\n</code></pre> <p>Higher level function to handle batch event processing.</p> PARAMETER DESCRIPTION <code>event</code> <p>Lambda's original event</p> <p> TYPE: <code>dict</code> </p> <code>record_handler</code> <p>Callable to process each record from the batch</p> <p> TYPE: <code>Callable</code> </p> <code>processor</code> <p>Batch Processor to handle partial failure cases</p> <p> TYPE: <code>BasePartialBatchProcessor</code> </p> <code>context</code> <p>Lambda's context, used to optionally inject in record handler</p> <p> TYPE: <code>LambdaContext | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>result</code> <p>Lambda Partial Batch Response</p> <p> TYPE: <code>PartialItemFailureResponse</code> </p> Example <p>Processes Lambda's SQS event</p> <pre><code>from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, process_partial_response\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\n\nprocessor = BatchProcessor(EventType.SQS)\n\ndef record_handler(record: SQSRecord):\n    return record.body\n\ndef handler(event, context):\n    return process_partial_response(\n        event=event, record_handler=record_handler, processor=processor, context=context\n    )\n</code></pre> Limitations <ul> <li>Async batch processors. Use <code>async_process_partial_response</code> instead.</li> </ul> Source code in <code>aws_lambda_powertools/utilities/batch/decorators.py</code> <pre><code>def process_partial_response(\n    event: dict,\n    record_handler: Callable,\n    processor: BasePartialBatchProcessor,\n    context: LambdaContext | None = None,\n) -&gt; PartialItemFailureResponse:\n    \"\"\"\n    Higher level function to handle batch event processing.\n\n    Parameters\n    ----------\n    event: dict\n        Lambda's original event\n    record_handler: Callable\n        Callable to process each record from the batch\n    processor: BasePartialBatchProcessor\n        Batch Processor to handle partial failure cases\n    context: LambdaContext\n        Lambda's context, used to optionally inject in record handler\n\n    Returns\n    -------\n    result: PartialItemFailureResponse\n        Lambda Partial Batch Response\n\n    Example\n    --------\n    **Processes Lambda's SQS event**\n\n    ```python\n    from aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, process_partial_response\n    from aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\n\n    processor = BatchProcessor(EventType.SQS)\n\n    def record_handler(record: SQSRecord):\n        return record.body\n\n    def handler(event, context):\n        return process_partial_response(\n            event=event, record_handler=record_handler, processor=processor, context=context\n        )\n    ```\n\n    Limitations\n    -----------\n    * Async batch processors. Use `async_process_partial_response` instead.\n    \"\"\"\n    try:\n        records: list[dict] = event.get(\"Records\", [])\n        if not records or not isinstance(records, list):\n            raise UnexpectedBatchTypeError(\n                \"Unexpected batch event type. Possible values are: SQS, KinesisDataStreams, DynamoDBStreams\",\n            )\n\n    except AttributeError:\n        event_types = \", \".join(list(EventType.__members__))\n        docs = \"https://docs.powertools.aws.dev/lambda/python/latest/utilities/batch/#processing-messages-from-sqs\"  # noqa: E501 # long-line\n        raise ValueError(\n            f\"Invalid event format. Please ensure batch event is a valid {processor.event_type.value} event. \\n\"\n            f\"See sample events in our documentation for either {event_types}: \\n {docs}\",\n        )\n\n    with processor(records, record_handler, context):\n        processor.process()\n\n    return processor.response()\n</code></pre>"
        },
        {
            "location": "api_doc/batch/decorators/#aws_lambda_powertools.utilities.batch.sqs_fifo_partial_processor.SqsFifoPartialProcessor",
            "title": "SqsFifoPartialProcessor",
            "text": "<pre><code>SqsFifoPartialProcessor(\n    model: BatchSqsTypeModel | None = None,\n    skip_group_on_error: bool = False,\n)\n</code></pre> <p>               Bases: <code>BatchProcessor</code></p> <p>Process native partial responses from SQS FIFO queues.</p> <p>Stops processing records when the first record fails. The remaining records are reported as failed items.</p> Example PARAMETER DESCRIPTION <code>model</code> <p>An optional model for batch processing.</p> <p> TYPE: <code>BatchSqsTypeModel | None</code> DEFAULT: <code>None</code> </p> <code>skip_group_on_error</code> <p>Determines whether to exclusively skip messages from the MessageGroupID that encountered processing failures Default is False.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>aws_lambda_powertools/utilities/batch/sqs_fifo_partial_processor.py</code> <pre><code>def __init__(self, model: BatchSqsTypeModel | None = None, skip_group_on_error: bool = False):\n    \"\"\"\n    Initialize the SqsFifoProcessor.\n\n    Parameters\n    ----------\n    model: BatchSqsTypeModel | None\n        An optional model for batch processing.\n    skip_group_on_error: bool\n        Determines whether to exclusively skip messages from the MessageGroupID that encountered processing failures\n        Default is False.\n\n    \"\"\"\n    self._skip_group_on_error: bool = skip_group_on_error\n    self._current_group_id = None\n    self._failed_group_ids: set[str] = set()\n    super().__init__(EventType.SQS, model)\n</code></pre>"
        },
        {
            "location": "api_doc/batch/decorators/#aws_lambda_powertools.utilities.batch.sqs_fifo_partial_processor.SqsFifoPartialProcessor--process-batch-triggered-by-a-fifo-sqs",
            "title": "Process batch triggered by a FIFO SQS",
            "text": "<pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import SqsFifoPartialProcessor, EventType, batch_processor\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nprocessor = SqsFifoPartialProcessor()\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n    ...\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\n@batch_processor(record_handler=record_handler, processor=processor)\ndef lambda_handler(event, context: LambdaContext):\n    return processor.response()\n</code></pre>"
        },
        {
            "location": "api_doc/batch/exceptions/",
            "title": "Exceptions",
            "text": "<p>Batch processing exceptions</p> CLASS DESCRIPTION <code>BatchProcessingError</code> <p>When all batch records failed to be processed</p> <code>SQSFifoCircuitBreakerError</code> <p>Signals a record not processed due to the SQS FIFO processing being interrupted</p> <code>SQSFifoMessageGroupCircuitBreakerError</code> <p>Signals a record not processed due to the SQS FIFO message group processing being interrupted</p> <code>UnexpectedBatchTypeError</code> <p>Error thrown by the Batch Processing utility when a partial processor receives an unexpected batch type</p>"
        },
        {
            "location": "api_doc/batch/exceptions/#aws_lambda_powertools.utilities.batch.exceptions.BatchProcessingError",
            "title": "BatchProcessingError",
            "text": "<pre><code>BatchProcessingError(\n    msg=\"\",\n    child_exceptions: list[ExceptionInfo] | None = None,\n)\n</code></pre> <p>               Bases: <code>BaseBatchProcessingError</code></p> <p>When all batch records failed to be processed</p> Source code in <code>aws_lambda_powertools/utilities/batch/exceptions.py</code> <pre><code>def __init__(self, msg=\"\", child_exceptions: list[ExceptionInfo] | None = None):\n    super().__init__(msg, child_exceptions)\n</code></pre>"
        },
        {
            "location": "api_doc/batch/exceptions/#aws_lambda_powertools.utilities.batch.exceptions.SQSFifoCircuitBreakerError",
            "title": "SQSFifoCircuitBreakerError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>Signals a record not processed due to the SQS FIFO processing being interrupted</p>"
        },
        {
            "location": "api_doc/batch/exceptions/#aws_lambda_powertools.utilities.batch.exceptions.SQSFifoMessageGroupCircuitBreakerError",
            "title": "SQSFifoMessageGroupCircuitBreakerError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>Signals a record not processed due to the SQS FIFO message group processing being interrupted</p>"
        },
        {
            "location": "api_doc/batch/exceptions/#aws_lambda_powertools.utilities.batch.exceptions.UnexpectedBatchTypeError",
            "title": "UnexpectedBatchTypeError",
            "text": "<pre><code>UnexpectedBatchTypeError(\n    msg=\"\",\n    child_exceptions: list[ExceptionInfo] | None = None,\n)\n</code></pre> <p>               Bases: <code>BatchProcessingError</code></p> <p>Error thrown by the Batch Processing utility when a partial processor receives an unexpected batch type</p> Source code in <code>aws_lambda_powertools/utilities/batch/exceptions.py</code> <pre><code>def __init__(self, msg=\"\", child_exceptions: list[ExceptionInfo] | None = None):\n    super().__init__(msg, child_exceptions)\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/base/",
            "title": "Base",
            "text": "<p>Base class for Data Masking</p> <p>Usage Documentation</p> <p><code>Data masking</code></p> CLASS DESCRIPTION <code>DataMasking</code> <p>The DataMasking class orchestrates erasing, encrypting, and decrypting</p>"
        },
        {
            "location": "api_doc/data_masking/base/#aws_lambda_powertools.utilities.data_masking.base.DataMasking",
            "title": "DataMasking",
            "text": "<pre><code>DataMasking(\n    provider: BaseProvider | None = None,\n    raise_on_missing_field: bool = True,\n)\n</code></pre> <p>The DataMasking class orchestrates erasing, encrypting, and decrypting for the base provider.</p> Example <pre><code>from aws_lambda_powertools.utilities.data_masking.base import DataMasking\n\ndef lambda_handler(event, context):\n    masker = DataMasking()\n\n    data = {\n        \"project\": \"powertools\",\n        \"sensitive\": \"password\"\n    }\n\n    erased = masker.erase(data,fields=[\"sensitive\"])\n\n    return erased\n</code></pre> METHOD DESCRIPTION <code>decrypt</code> <p>Decrypt data using the configured encryption provider.</p> <code>encrypt</code> <p>Encrypt data using the configured encryption provider.</p> <code>erase</code> <p>Erase or mask sensitive data in the input.</p> Source code in <code>aws_lambda_powertools/utilities/data_masking/base.py</code> <pre><code>def __init__(\n    self,\n    provider: BaseProvider | None = None,\n    raise_on_missing_field: bool = True,\n):\n    self.provider = provider or BaseProvider()\n    # NOTE: we depend on Provider to not confuse customers in passing the same 2 serializers in 2 places\n    self.json_serializer = self.provider.json_serializer\n    self.json_deserializer = self.provider.json_deserializer\n    self.raise_on_missing_field = raise_on_missing_field\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/base/#aws_lambda_powertools.utilities.data_masking.base.DataMasking.decrypt",
            "title": "decrypt",
            "text": "<pre><code>decrypt(\n    data,\n    provider_options: dict | None = None,\n    **encryption_context: str\n) -&gt; Any\n</code></pre> <p>Decrypt data using the configured encryption provider.</p> PARAMETER DESCRIPTION <code>data</code> <p>The data to encrypt.</p> <p> TYPE: <code>dict, Mapping, Sequence, or Number</code> </p> <code>provider_options</code> <p>Provider-specific options for encryption.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>**encryption_context</code> <p>Additional key-value pairs for encryption context.</p> <p> TYPE: <code>str</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The encrypted data as a base64-encoded string.</p> Example <pre><code>encryption_provider = AWSEncryptionSDKProvider(keys=[KMS_KEY_ARN])\ndata_masker = DataMasking(provider=encryption_provider)\nencrypted = data_masker.decrypt(encrypted_data)\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/data_masking/base.py</code> <pre><code>def decrypt(\n    self,\n    data,\n    provider_options: dict | None = None,\n    **encryption_context: str,\n) -&gt; Any:\n    \"\"\"\n    Decrypt data using the configured encryption provider.\n\n    Parameters\n    ----------\n    data : dict, Mapping, Sequence, or Number\n        The data to encrypt.\n    provider_options : dict, optional\n        Provider-specific options for encryption.\n    **encryption_context : str\n        Additional key-value pairs for encryption context.\n\n    Returns\n    -------\n    str\n        The encrypted data as a base64-encoded string.\n\n    Example\n    --------\n\n        encryption_provider = AWSEncryptionSDKProvider(keys=[KMS_KEY_ARN])\n        data_masker = DataMasking(provider=encryption_provider)\n        encrypted = data_masker.decrypt(encrypted_data)\n    \"\"\"\n\n    return self._apply_action(\n        data=data,\n        fields=None,\n        action=self.provider.decrypt,\n        provider_options=provider_options or {},\n        dynamic_mask=None,\n        custom_mask=None,\n        regex_pattern=None,\n        mask_format=None,\n        **encryption_context,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/base/#aws_lambda_powertools.utilities.data_masking.base.DataMasking.encrypt",
            "title": "encrypt",
            "text": "<pre><code>encrypt(\n    data: dict | Mapping | Sequence | Number,\n    provider_options: dict | None = None,\n    **encryption_context: str\n) -&gt; str\n</code></pre> <p>Encrypt data using the configured encryption provider.</p> PARAMETER DESCRIPTION <code>data</code> <p>The data to encrypt.</p> <p> TYPE: <code>dict, Mapping, Sequence, or Number</code> </p> <code>provider_options</code> <p>Provider-specific options for encryption.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>**encryption_context</code> <p>Additional key-value pairs for encryption context.</p> <p> TYPE: <code>str</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The encrypted data as a base64-encoded string.</p> Example <pre><code>encryption_provider = AWSEncryptionSDKProvider(keys=[KMS_KEY_ARN])\ndata_masker = DataMasking(provider=encryption_provider)\nencrypted = data_masker.encrypt({\"secret\": \"value\"})\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/data_masking/base.py</code> <pre><code>def encrypt(\n    self,\n    data: dict | Mapping | Sequence | Number,\n    provider_options: dict | None = None,\n    **encryption_context: str,\n) -&gt; str:\n    \"\"\"\n    Encrypt data using the configured encryption provider.\n\n    Parameters\n    ----------\n    data : dict, Mapping, Sequence, or Number\n        The data to encrypt.\n    provider_options : dict, optional\n        Provider-specific options for encryption.\n    **encryption_context : str\n        Additional key-value pairs for encryption context.\n\n    Returns\n    -------\n    str\n        The encrypted data as a base64-encoded string.\n\n    Example\n    --------\n\n        encryption_provider = AWSEncryptionSDKProvider(keys=[KMS_KEY_ARN])\n        data_masker = DataMasking(provider=encryption_provider)\n        encrypted = data_masker.encrypt({\"secret\": \"value\"})\n    \"\"\"\n    return self._apply_action(\n        data=data,\n        fields=None,\n        action=self.provider.encrypt,\n        provider_options=provider_options or {},\n        dynamic_mask=None,\n        custom_mask=None,\n        regex_pattern=None,\n        mask_format=None,\n        **encryption_context,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/base/#aws_lambda_powertools.utilities.data_masking.base.DataMasking.erase",
            "title": "erase",
            "text": "<pre><code>erase(\n    data: Any,\n    fields: list[str] | None = None,\n    *,\n    dynamic_mask: bool | None = None,\n    custom_mask: str | None = None,\n    regex_pattern: str | None = None,\n    mask_format: str | None = None,\n    masking_rules: dict | None = None\n) -&gt; Any\n</code></pre> <p>Erase or mask sensitive data in the input.</p> PARAMETER DESCRIPTION <code>data</code> <p>The data to be erased or masked.</p> <p> TYPE: <code>Any</code> </p> <code>fields</code> <p>List of field names to be erased or masked.</p> <p> TYPE: <code>list of str</code> DEFAULT: <code>None</code> </p> <code>dynamic_mask</code> <p>Whether to use dynamic masking.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>None</code> </p> <code>custom_mask</code> <p>Custom mask to apply instead of the default.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>regex_pattern</code> <p>Regular expression pattern for identifying data to mask.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>mask_format</code> <p>Format string for the mask.</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>masking_rules</code> <p>Dictionary of custom masking rules.</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The data with sensitive information erased or masked.</p> Source code in <code>aws_lambda_powertools/utilities/data_masking/base.py</code> <pre><code>def erase(\n    self,\n    data: Any,\n    fields: list[str] | None = None,\n    *,\n    dynamic_mask: bool | None = None,\n    custom_mask: str | None = None,\n    regex_pattern: str | None = None,\n    mask_format: str | None = None,\n    masking_rules: dict | None = None,\n) -&gt; Any:\n    \"\"\"\n    Erase or mask sensitive data in the input.\n\n    Parameters\n    ----------\n    data : Any\n        The data to be erased or masked.\n    fields : list of str, optional\n        List of field names to be erased or masked.\n    dynamic_mask : bool, optional\n        Whether to use dynamic masking.\n    custom_mask : str, optional\n        Custom mask to apply instead of the default.\n    regex_pattern : str, optional\n        Regular expression pattern for identifying data to mask.\n    mask_format : str, optional\n        Format string for the mask.\n    masking_rules : dict, optional\n        Dictionary of custom masking rules.\n\n    Returns\n    -------\n    Any\n        The data with sensitive information erased or masked.\n    \"\"\"\n    if masking_rules:\n        return self._apply_masking_rules(data=data, masking_rules=masking_rules)\n    else:\n        return self._apply_action(\n            data=data,\n            fields=fields,\n            action=self.provider.erase,\n            dynamic_mask=dynamic_mask,\n            custom_mask=custom_mask,\n            regex_pattern=regex_pattern,\n            mask_format=mask_format,\n        )\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/exceptions/",
            "title": "Exception",
            "text": "CLASS DESCRIPTION <code>DataMaskingContextMismatchError</code> <p>Decrypting with the incorrect encryption context.</p> <code>DataMaskingDecryptKeyError</code> <p>Decrypting with an invalid AWS KMS Key ARN.</p> <code>DataMaskingDecryptValueError</code> <p>Decrypting an invalid field.</p> <code>DataMaskingEncryptKeyError</code> <p>Encrypting with an invalid AWS KMS Key ARN.</p> <code>DataMaskingFieldNotFoundError</code> <p>Field not found.</p> <code>DataMaskingUnsupportedTypeError</code> <p>UnsupportedType Error</p>"
        },
        {
            "location": "api_doc/data_masking/exceptions/#aws_lambda_powertools.utilities.data_masking.exceptions.DataMaskingContextMismatchError",
            "title": "DataMaskingContextMismatchError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>Decrypting with the incorrect encryption context.</p>"
        },
        {
            "location": "api_doc/data_masking/exceptions/#aws_lambda_powertools.utilities.data_masking.exceptions.DataMaskingDecryptKeyError",
            "title": "DataMaskingDecryptKeyError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>Decrypting with an invalid AWS KMS Key ARN.</p>"
        },
        {
            "location": "api_doc/data_masking/exceptions/#aws_lambda_powertools.utilities.data_masking.exceptions.DataMaskingDecryptValueError",
            "title": "DataMaskingDecryptValueError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>Decrypting an invalid field.</p>"
        },
        {
            "location": "api_doc/data_masking/exceptions/#aws_lambda_powertools.utilities.data_masking.exceptions.DataMaskingEncryptKeyError",
            "title": "DataMaskingEncryptKeyError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>Encrypting with an invalid AWS KMS Key ARN.</p>"
        },
        {
            "location": "api_doc/data_masking/exceptions/#aws_lambda_powertools.utilities.data_masking.exceptions.DataMaskingFieldNotFoundError",
            "title": "DataMaskingFieldNotFoundError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>Field not found.</p>"
        },
        {
            "location": "api_doc/data_masking/exceptions/#aws_lambda_powertools.utilities.data_masking.exceptions.DataMaskingUnsupportedTypeError",
            "title": "DataMaskingUnsupportedTypeError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>UnsupportedType Error</p>"
        },
        {
            "location": "api_doc/data_masking/provider/",
            "title": "Provider",
            "text": "MODULE DESCRIPTION <code>base</code> <code>kms</code> CLASS DESCRIPTION <code>BaseProvider</code> <p>The BaseProvider class serves as an abstract base class for data masking providers.</p>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.BaseProvider",
            "title": "BaseProvider",
            "text": "<pre><code>BaseProvider(\n    json_serializer: Callable[..., str] = functools.partial(\n        json.dumps, ensure_ascii=False\n    ),\n    json_deserializer: Callable[[str], Any] = json.loads,\n)\n</code></pre> <p>The BaseProvider class serves as an abstract base class for data masking providers.</p> Example <pre><code>from aws_lambda_powertools.utilities._data_masking.provider import BaseProvider\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\n\nclass MyCustomProvider(BaseProvider):\n    def encrypt(self, data) -&gt; str:\n        # Implementation logic for data encryption\n\n    def decrypt(self, data) -&gt; Any:\n        # Implementation logic for data decryption\n\n    def erase(self, data) -&gt; Any | Iterable:\n        # Implementation logic for data masking\n        pass\n\ndef lambda_handler(event, context):\n    provider = MyCustomProvider([\"secret-key\"])\n    data_masker = DataMasking(provider=provider)\n\n    data = {\n        \"project\": \"powertools\",\n        \"sensitive\": \"password\"\n    }\n\n    encrypted = data_masker.encrypt(data)\n\n    return encrypted\n</code></pre> METHOD DESCRIPTION <code>decrypt</code> <p>Abstract method for decrypting data. Subclasses must implement this method.</p> <code>encrypt</code> <p>Abstract method for encrypting data. Subclasses must implement this method.</p> Source code in <code>aws_lambda_powertools/utilities/data_masking/provider/base.py</code> <pre><code>def __init__(\n    self,\n    json_serializer: Callable[..., str] = functools.partial(json.dumps, ensure_ascii=False),\n    json_deserializer: Callable[[str], Any] = json.loads,\n) -&gt; None:\n    self.json_serializer = json_serializer\n    self.json_deserializer = json_deserializer\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.BaseProvider.decrypt",
            "title": "decrypt",
            "text": "<pre><code>decrypt(\n    data,\n    provider_options: dict | None = None,\n    **encryption_context: str\n) -&gt; Any\n</code></pre> <p>Abstract method for decrypting data. Subclasses must implement this method.</p> Source code in <code>aws_lambda_powertools/utilities/data_masking/provider/base.py</code> <pre><code>def decrypt(self, data, provider_options: dict | None = None, **encryption_context: str) -&gt; Any:\n    \"\"\"\n    Abstract method for decrypting data. Subclasses must implement this method.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement decrypt()\")\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.BaseProvider.encrypt",
            "title": "encrypt",
            "text": "<pre><code>encrypt(\n    data,\n    provider_options: dict | None = None,\n    **encryption_context: str\n) -&gt; str\n</code></pre> <p>Abstract method for encrypting data. Subclasses must implement this method.</p> Source code in <code>aws_lambda_powertools/utilities/data_masking/provider/base.py</code> <pre><code>def encrypt(self, data, provider_options: dict | None = None, **encryption_context: str) -&gt; str:\n    \"\"\"\n    Abstract method for encrypting data. Subclasses must implement this method.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement encrypt()\")\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.base",
            "title": "base",
            "text": "CLASS DESCRIPTION <code>BaseProvider</code> <p>The BaseProvider class serves as an abstract base class for data masking providers.</p>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.base.BaseProvider",
            "title": "BaseProvider",
            "text": "<pre><code>BaseProvider(\n    json_serializer: Callable[..., str] = functools.partial(\n        json.dumps, ensure_ascii=False\n    ),\n    json_deserializer: Callable[[str], Any] = json.loads,\n)\n</code></pre> <p>The BaseProvider class serves as an abstract base class for data masking providers.</p> Example <pre><code>from aws_lambda_powertools.utilities._data_masking.provider import BaseProvider\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\n\nclass MyCustomProvider(BaseProvider):\n    def encrypt(self, data) -&gt; str:\n        # Implementation logic for data encryption\n\n    def decrypt(self, data) -&gt; Any:\n        # Implementation logic for data decryption\n\n    def erase(self, data) -&gt; Any | Iterable:\n        # Implementation logic for data masking\n        pass\n\ndef lambda_handler(event, context):\n    provider = MyCustomProvider([\"secret-key\"])\n    data_masker = DataMasking(provider=provider)\n\n    data = {\n        \"project\": \"powertools\",\n        \"sensitive\": \"password\"\n    }\n\n    encrypted = data_masker.encrypt(data)\n\n    return encrypted\n</code></pre> METHOD DESCRIPTION <code>decrypt</code> <p>Abstract method for decrypting data. Subclasses must implement this method.</p> <code>encrypt</code> <p>Abstract method for encrypting data. Subclasses must implement this method.</p> Source code in <code>aws_lambda_powertools/utilities/data_masking/provider/base.py</code> <pre><code>def __init__(\n    self,\n    json_serializer: Callable[..., str] = functools.partial(json.dumps, ensure_ascii=False),\n    json_deserializer: Callable[[str], Any] = json.loads,\n) -&gt; None:\n    self.json_serializer = json_serializer\n    self.json_deserializer = json_deserializer\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.base.BaseProvider.decrypt",
            "title": "decrypt",
            "text": "<pre><code>decrypt(\n    data,\n    provider_options: dict | None = None,\n    **encryption_context: str\n) -&gt; Any\n</code></pre> <p>Abstract method for decrypting data. Subclasses must implement this method.</p> Source code in <code>aws_lambda_powertools/utilities/data_masking/provider/base.py</code> <pre><code>def decrypt(self, data, provider_options: dict | None = None, **encryption_context: str) -&gt; Any:\n    \"\"\"\n    Abstract method for decrypting data. Subclasses must implement this method.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement decrypt()\")\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.base.BaseProvider.encrypt",
            "title": "encrypt",
            "text": "<pre><code>encrypt(\n    data,\n    provider_options: dict | None = None,\n    **encryption_context: str\n) -&gt; str\n</code></pre> <p>Abstract method for encrypting data. Subclasses must implement this method.</p> Source code in <code>aws_lambda_powertools/utilities/data_masking/provider/base.py</code> <pre><code>def encrypt(self, data, provider_options: dict | None = None, **encryption_context: str) -&gt; str:\n    \"\"\"\n    Abstract method for encrypting data. Subclasses must implement this method.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement encrypt()\")\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.kms",
            "title": "kms",
            "text": "MODULE DESCRIPTION <code>aws_encryption_sdk</code> CLASS DESCRIPTION <code>AWSEncryptionSDKProvider</code> <p>The AWSEncryptionSDKProvider is used as a provider for the DataMasking class.</p>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.kms.AWSEncryptionSDKProvider",
            "title": "AWSEncryptionSDKProvider",
            "text": "<pre><code>AWSEncryptionSDKProvider(\n    keys: list[str],\n    key_provider=None,\n    local_cache_capacity: int = CACHE_CAPACITY,\n    max_cache_age_seconds: float = MAX_CACHE_AGE_SECONDS,\n    max_messages_encrypted: int = MAX_MESSAGES_ENCRYPTED,\n    max_bytes_encrypted: int = MAX_BYTES_ENCRYPTED,\n    json_serializer: Callable[..., str] = functools.partial(\n        json.dumps, ensure_ascii=False\n    ),\n    json_deserializer: Callable[[str], Any] = json.loads,\n)\n</code></pre> <p>               Bases: <code>BaseProvider</code></p> <p>The AWSEncryptionSDKProvider is used as a provider for the DataMasking class.</p> Example <pre><code>from aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.data_masking.providers.kms.aws_encryption_sdk import (\n    AWSEncryptionSDKProvider,\n)\n\n\ndef lambda_handler(event, context):\n    provider = AWSEncryptionSDKProvider([\"arn:aws:kms:us-east-1:0123456789012:key/key-id\"])\n    data_masker = DataMasking(provider=provider)\n\n    data = {\n        \"project\": \"powertools\",\n        \"sensitive\": \"password\"\n    }\n\n    encrypted = data_masker.encrypt(data)\n\n    return encrypted\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/data_masking/provider/kms/aws_encryption_sdk.py</code> <pre><code>def __init__(\n    self,\n    keys: list[str],\n    key_provider=None,\n    local_cache_capacity: int = CACHE_CAPACITY,\n    max_cache_age_seconds: float = MAX_CACHE_AGE_SECONDS,\n    max_messages_encrypted: int = MAX_MESSAGES_ENCRYPTED,\n    max_bytes_encrypted: int = MAX_BYTES_ENCRYPTED,\n    json_serializer: Callable[..., str] = functools.partial(json.dumps, ensure_ascii=False),\n    json_deserializer: Callable[[str], Any] = json.loads,\n):\n    super().__init__(json_serializer=json_serializer, json_deserializer=json_deserializer)\n\n    self._key_provider = key_provider or KMSKeyProvider(\n        keys=keys,\n        local_cache_capacity=local_cache_capacity,\n        max_cache_age_seconds=max_cache_age_seconds,\n        max_messages_encrypted=max_messages_encrypted,\n        max_bytes_encrypted=max_bytes_encrypted,\n        json_serializer=json_serializer,\n        json_deserializer=json_deserializer,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk",
            "title": "aws_encryption_sdk",
            "text": "CLASS DESCRIPTION <code>AWSEncryptionSDKProvider</code> <p>The AWSEncryptionSDKProvider is used as a provider for the DataMasking class.</p> <code>KMSKeyProvider</code> <p>The KMSKeyProvider is responsible for assembling an AWS Key Management Service (KMS)</p>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk.AWSEncryptionSDKProvider",
            "title": "AWSEncryptionSDKProvider",
            "text": "<pre><code>AWSEncryptionSDKProvider(\n    keys: list[str],\n    key_provider=None,\n    local_cache_capacity: int = CACHE_CAPACITY,\n    max_cache_age_seconds: float = MAX_CACHE_AGE_SECONDS,\n    max_messages_encrypted: int = MAX_MESSAGES_ENCRYPTED,\n    max_bytes_encrypted: int = MAX_BYTES_ENCRYPTED,\n    json_serializer: Callable[..., str] = functools.partial(\n        json.dumps, ensure_ascii=False\n    ),\n    json_deserializer: Callable[[str], Any] = json.loads,\n)\n</code></pre> <p>               Bases: <code>BaseProvider</code></p> <p>The AWSEncryptionSDKProvider is used as a provider for the DataMasking class.</p> Example <pre><code>from aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.data_masking.providers.kms.aws_encryption_sdk import (\n    AWSEncryptionSDKProvider,\n)\n\n\ndef lambda_handler(event, context):\n    provider = AWSEncryptionSDKProvider([\"arn:aws:kms:us-east-1:0123456789012:key/key-id\"])\n    data_masker = DataMasking(provider=provider)\n\n    data = {\n        \"project\": \"powertools\",\n        \"sensitive\": \"password\"\n    }\n\n    encrypted = data_masker.encrypt(data)\n\n    return encrypted\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/data_masking/provider/kms/aws_encryption_sdk.py</code> <pre><code>def __init__(\n    self,\n    keys: list[str],\n    key_provider=None,\n    local_cache_capacity: int = CACHE_CAPACITY,\n    max_cache_age_seconds: float = MAX_CACHE_AGE_SECONDS,\n    max_messages_encrypted: int = MAX_MESSAGES_ENCRYPTED,\n    max_bytes_encrypted: int = MAX_BYTES_ENCRYPTED,\n    json_serializer: Callable[..., str] = functools.partial(json.dumps, ensure_ascii=False),\n    json_deserializer: Callable[[str], Any] = json.loads,\n):\n    super().__init__(json_serializer=json_serializer, json_deserializer=json_deserializer)\n\n    self._key_provider = key_provider or KMSKeyProvider(\n        keys=keys,\n        local_cache_capacity=local_cache_capacity,\n        max_cache_age_seconds=max_cache_age_seconds,\n        max_messages_encrypted=max_messages_encrypted,\n        max_bytes_encrypted=max_bytes_encrypted,\n        json_serializer=json_serializer,\n        json_deserializer=json_deserializer,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk.KMSKeyProvider",
            "title": "KMSKeyProvider",
            "text": "<pre><code>KMSKeyProvider(\n    keys: list[str],\n    json_serializer: Callable[..., str],\n    json_deserializer: Callable[[str], Any],\n    local_cache_capacity: int = CACHE_CAPACITY,\n    max_cache_age_seconds: float = MAX_CACHE_AGE_SECONDS,\n    max_messages_encrypted: int = MAX_MESSAGES_ENCRYPTED,\n    max_bytes_encrypted: int = MAX_BYTES_ENCRYPTED,\n)\n</code></pre> <p>The KMSKeyProvider is responsible for assembling an AWS Key Management Service (KMS) client, a caching mechanism, and a keyring for secure key management and data encryption.</p> METHOD DESCRIPTION <code>decrypt</code> <p>Decrypt data using AWSEncryptionSDKProvider.</p> <code>encrypt</code> <p>Encrypt data using the AWSEncryptionSDKProvider.</p> Source code in <code>aws_lambda_powertools/utilities/data_masking/provider/kms/aws_encryption_sdk.py</code> <pre><code>def __init__(\n    self,\n    keys: list[str],\n    json_serializer: Callable[..., str],\n    json_deserializer: Callable[[str], Any],\n    local_cache_capacity: int = CACHE_CAPACITY,\n    max_cache_age_seconds: float = MAX_CACHE_AGE_SECONDS,\n    max_messages_encrypted: int = MAX_MESSAGES_ENCRYPTED,\n    max_bytes_encrypted: int = MAX_BYTES_ENCRYPTED,\n):\n    session = botocore.session.Session()\n    register_feature_to_botocore_session(session, \"data-masking\")\n\n    self.json_serializer = json_serializer\n    self.json_deserializer = json_deserializer\n    self.client = EncryptionSDKClient()\n    self.keys = keys\n    self.cache = LocalCryptoMaterialsCache(local_cache_capacity)\n    self.key_provider = StrictAwsKmsMasterKeyProvider(key_ids=self.keys, botocore_session=session)\n    self.cache_cmm = CachingCryptoMaterialsManager(\n        master_key_provider=self.key_provider,\n        cache=self.cache,\n        max_age=max_cache_age_seconds,\n        max_messages_encrypted=max_messages_encrypted,\n        max_bytes_encrypted=max_bytes_encrypted,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk.KMSKeyProvider.decrypt",
            "title": "decrypt",
            "text": "<pre><code>decrypt(\n    data: str,\n    provider_options: dict | None = None,\n    **encryption_context: str\n) -&gt; Any\n</code></pre> <p>Decrypt data using AWSEncryptionSDKProvider.</p> PARAMETER DESCRIPTION <code>data</code> <p>The encrypted data, as a base64-encoded string</p> <p> TYPE: <code>str</code> </p> <code>provider_options</code> <p>Additional options for the aws_encryption_sdk.EncryptionSDKClient</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>ciphertext</code> <p>The decrypted data in bytes</p> <p> TYPE: <code>bytes</code> </p> Source code in <code>aws_lambda_powertools/utilities/data_masking/provider/kms/aws_encryption_sdk.py</code> <pre><code>def decrypt(self, data: str, provider_options: dict | None = None, **encryption_context: str) -&gt; Any:\n    \"\"\"\n    Decrypt data using AWSEncryptionSDKProvider.\n\n    Parameters\n    -------\n    data: str\n        The encrypted data, as a base64-encoded string\n    provider_options\n        Additional options for the aws_encryption_sdk.EncryptionSDKClient\n\n    Returns\n    -------\n    ciphertext: bytes\n        The decrypted data in bytes\n    \"\"\"\n    provider_options = provider_options or {}\n    self._validate_encryption_context(encryption_context)\n\n    try:\n        ciphertext_decoded = base64_decode(data)\n    except Error:\n        raise DataMaskingDecryptValueError(\n            \"Data decryption failed. Please ensure that you are attempting to decrypt data that was previously encrypted.\",  # noqa E501\n        )\n\n    try:\n        ciphertext, decryptor_header = self.client.decrypt(\n            source=ciphertext_decoded,\n            key_provider=self.key_provider,\n            **provider_options,\n        )\n    except DecryptKeyError:\n        raise DataMaskingDecryptKeyError(\n            \"Failed to decrypt data - Please ensure you are using a valid Symmetric AWS KMS Key ARN, not KMS Key ID or alias.\",  # noqa E501\n        )\n    except (TypeError, NotSupportedError):\n        raise DataMaskingDecryptValueError(\n            \"Data decryption failed. Please ensure that you are attempting to decrypt data that was previously encrypted.\",  # noqa E501\n        )\n\n    self._compare_encryption_context(decryptor_header.encryption_context, encryption_context)\n\n    decoded_ciphertext = bytes_to_string(ciphertext)\n\n    return self.json_deserializer(decoded_ciphertext)\n</code></pre>"
        },
        {
            "location": "api_doc/data_masking/provider/#aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk.KMSKeyProvider.encrypt",
            "title": "encrypt",
            "text": "<pre><code>encrypt(\n    data: Any,\n    provider_options: dict | None = None,\n    **encryption_context: str\n) -&gt; str\n</code></pre> <p>Encrypt data using the AWSEncryptionSDKProvider.</p> PARAMETER DESCRIPTION <code>data</code> <p>The data to be encrypted.</p> <p> TYPE: <code>Any</code> </p> <code>provider_options</code> <p>Additional options for the aws_encryption_sdk.EncryptionSDKClient</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>**encryption_context</code> <p>Additional keyword arguments collected into a dictionary.</p> <p> TYPE: <code>str</code> DEFAULT: <code>{}</code> </p> RETURNS DESCRIPTION <code>ciphertext</code> <p>The encrypted data, as a base64-encoded string.</p> <p> TYPE: <code>str</code> </p> Source code in <code>aws_lambda_powertools/utilities/data_masking/provider/kms/aws_encryption_sdk.py</code> <pre><code>def encrypt(self, data: Any, provider_options: dict | None = None, **encryption_context: str) -&gt; str:\n    \"\"\"\n    Encrypt data using the AWSEncryptionSDKProvider.\n\n    Parameters\n    -------\n    data: Any\n        The data to be encrypted.\n    provider_options: dict\n        Additional options for the aws_encryption_sdk.EncryptionSDKClient\n    **encryption_context: str\n        Additional keyword arguments collected into a dictionary.\n\n    Returns\n    -------\n    ciphertext: str\n        The encrypted data, as a base64-encoded string.\n    \"\"\"\n    provider_options = provider_options or {}\n    self._validate_encryption_context(encryption_context)\n\n    data_encoded = self.json_serializer(data).encode(\"utf-8\")\n\n    try:\n        ciphertext, _ = self.client.encrypt(\n            source=data_encoded,\n            materials_manager=self.cache_cmm,\n            encryption_context=encryption_context,\n            **provider_options,\n        )\n    except GenerateKeyError:\n        raise DataMaskingEncryptKeyError(\n            \"Failed to encrypt data. Please ensure you are using a valid Symmetric AWS KMS Key ARN, not KMS Key ID or alias.\",  # noqa E501\n        )\n\n    return bytes_to_base64_string(ciphertext)\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/",
            "title": "REST",
            "text": "CLASS DESCRIPTION <code>ALBResolver</code> <p>Amazon Application Load Balancer (ALB) resolver</p> <code>APIGatewayHttpResolver</code> <p>Amazon API Gateway HTTP API v2 payload resolver</p> <code>APIGatewayRestResolver</code> <p>Amazon API Gateway REST and HTTP API v1 payload resolver</p> <code>ApiGatewayResolver</code> <p>API Gateway, VPC Laticce, Bedrock and ALB proxy resolver</p> <code>BaseRouter</code> <p>Base class for Routing</p> <code>CORSConfig</code> <p>CORS Config</p> <code>MiddlewareFrame</code> <p>Creates a Middle Stack Wrapper instance to be used as a \"Frame\" in the overall stack of</p> <code>ProxyEventType</code> <p>An enumerations of the supported proxy event types.</p> <code>Response</code> <p>Response data class that provides greater control over what is returned from the proxy event</p> <code>ResponseBuilder</code> <p>Internally used Response builder</p> <code>Route</code> <p>Internally used Route Configuration</p> <code>Router</code> <p>Router helper class to allow splitting ApiGatewayResolver into multiple files</p>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ALBResolver",
            "title": "ALBResolver",
            "text": "<pre><code>ALBResolver(\n    cors: CORSConfig | None = None,\n    debug: bool | None = None,\n    serializer: Callable[[dict], str] | None = None,\n    strip_prefixes: list[str | Pattern] | None = None,\n    enable_validation: bool = False,\n    response_validation_error_http_code: (\n        HTTPStatus | int | None\n    ) = None,\n)\n</code></pre> <p>               Bases: <code>ApiGatewayResolver</code></p> <p>Amazon Application Load Balancer (ALB) resolver</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def __init__(\n    self,\n    cors: CORSConfig | None = None,\n    debug: bool | None = None,\n    serializer: Callable[[dict], str] | None = None,\n    strip_prefixes: list[str | Pattern] | None = None,\n    enable_validation: bool = False,\n    response_validation_error_http_code: HTTPStatus | int | None = None,\n):\n    \"\"\"Amazon Application Load Balancer (ALB) resolver\"\"\"\n    super().__init__(\n        ProxyEventType.ALBEvent,\n        cors,\n        debug,\n        serializer,\n        strip_prefixes,\n        enable_validation,\n        response_validation_error_http_code,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.APIGatewayHttpResolver",
            "title": "APIGatewayHttpResolver",
            "text": "<pre><code>APIGatewayHttpResolver(\n    cors: CORSConfig | None = None,\n    debug: bool | None = None,\n    serializer: Callable[[dict], str] | None = None,\n    strip_prefixes: list[str | Pattern] | None = None,\n    enable_validation: bool = False,\n    response_validation_error_http_code: (\n        HTTPStatus | int | None\n    ) = None,\n)\n</code></pre> <p>               Bases: <code>ApiGatewayResolver</code></p> <p>Amazon API Gateway HTTP API v2 payload resolver</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def __init__(\n    self,\n    cors: CORSConfig | None = None,\n    debug: bool | None = None,\n    serializer: Callable[[dict], str] | None = None,\n    strip_prefixes: list[str | Pattern] | None = None,\n    enable_validation: bool = False,\n    response_validation_error_http_code: HTTPStatus | int | None = None,\n):\n    \"\"\"Amazon API Gateway HTTP API v2 payload resolver\"\"\"\n    super().__init__(\n        ProxyEventType.APIGatewayProxyEventV2,\n        cors,\n        debug,\n        serializer,\n        strip_prefixes,\n        enable_validation,\n        response_validation_error_http_code,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.APIGatewayRestResolver",
            "title": "APIGatewayRestResolver",
            "text": "<pre><code>APIGatewayRestResolver(\n    cors: CORSConfig | None = None,\n    debug: bool | None = None,\n    serializer: Callable[[dict], str] | None = None,\n    strip_prefixes: list[str | Pattern] | None = None,\n    enable_validation: bool = False,\n    response_validation_error_http_code: (\n        HTTPStatus | int | None\n    ) = None,\n)\n</code></pre> <p>               Bases: <code>ApiGatewayResolver</code></p> <p>Amazon API Gateway REST and HTTP API v1 payload resolver</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def __init__(\n    self,\n    cors: CORSConfig | None = None,\n    debug: bool | None = None,\n    serializer: Callable[[dict], str] | None = None,\n    strip_prefixes: list[str | Pattern] | None = None,\n    enable_validation: bool = False,\n    response_validation_error_http_code: HTTPStatus | int | None = None,\n):\n    \"\"\"Amazon API Gateway REST and HTTP API v1 payload resolver\"\"\"\n    super().__init__(\n        ProxyEventType.APIGatewayProxyEvent,\n        cors,\n        debug,\n        serializer,\n        strip_prefixes,\n        enable_validation,\n        response_validation_error_http_code,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ApiGatewayResolver",
            "title": "ApiGatewayResolver",
            "text": "<pre><code>ApiGatewayResolver(\n    proxy_type: Enum = ProxyEventType.APIGatewayProxyEvent,\n    cors: CORSConfig | None = None,\n    debug: bool | None = None,\n    serializer: Callable[[dict], str] | None = None,\n    strip_prefixes: list[str | Pattern] | None = None,\n    enable_validation: bool = False,\n    response_validation_error_http_code: (\n        HTTPStatus | int | None\n    ) = None,\n)\n</code></pre> <p>               Bases: <code>BaseRouter</code></p> <p>API Gateway, VPC Laticce, Bedrock and ALB proxy resolver</p> <p>Examples:</p> <p>Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator</p> <pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\ntracer = Tracer()\napp = APIGatewayRestResolver()\n\n@app.get(\"/get-call\")\ndef simple_get():\n    return {\"message\": \"Foo\"}\n\n@app.post(\"/post-call\")\ndef simple_post():\n    post_data: dict = app.current_event.json_body\n    return {\"message\": post_data[\"value\"]}\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <p>response_validation_error_http_code     Sets the returned status code if response is not validated. enable_validation must be True.</p> METHOD DESCRIPTION <code>configure_openapi</code> <p>Configure OpenAPI specification settings for the API.</p> <code>enable_swagger</code> <p>Returns the OpenAPI schema as a JSON serializable dict</p> <code>get_openapi_json_schema</code> <p>Returns the OpenAPI schema as a JSON serializable dict</p> <code>get_openapi_schema</code> <p>Returns the OpenAPI schema as a pydantic model.</p> <code>include_router</code> <p>Adds all routes and context defined in a router</p> <code>resolve</code> <p>Resolves the response based on the provide event and decorator routes</p> <code>route</code> <p>Route decorator includes parameter <code>method</code></p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def __init__(\n    self,\n    proxy_type: Enum = ProxyEventType.APIGatewayProxyEvent,\n    cors: CORSConfig | None = None,\n    debug: bool | None = None,\n    serializer: Callable[[dict], str] | None = None,\n    strip_prefixes: list[str | Pattern] | None = None,\n    enable_validation: bool = False,\n    response_validation_error_http_code: HTTPStatus | int | None = None,\n):\n    \"\"\"\n    Parameters\n    ----------\n    proxy_type: ProxyEventType\n        Proxy request type, defaults to API Gateway V1\n    cors: CORSConfig\n        Optionally configure and enabled CORS. Not each route will need to have to cors=True\n    debug: bool | None\n        Enables debug mode, by default False. Can be also be enabled by \"POWERTOOLS_DEV\"\n        environment variable\n    serializer: Callable, optional\n        function to serialize `obj` to a JSON formatted `str`, by default json.dumps\n    strip_prefixes: list[str | Pattern], optional\n        optional list of prefixes to be removed from the request path before doing the routing.\n        This is often used with api gateways with multiple custom mappings.\n        Each prefix can be a static string or a compiled regex pattern\n    enable_validation: bool | None\n        Enables validation of the request body against the route schema, by default False.\n    response_validation_error_http_code\n        Sets the returned status code if response is not validated. enable_validation must be True.\n    \"\"\"\n    self._proxy_type = proxy_type\n    self._dynamic_routes: list[Route] = []\n    self._static_routes: list[Route] = []\n    self._route_keys: list[str] = []\n    self._exception_handlers: dict[type, Callable] = {}\n    self._cors = cors\n    self._cors_enabled: bool = cors is not None\n    self._cors_methods: set[str] = {\"OPTIONS\"}\n    self._debug = self._has_debug(debug)\n    self._enable_validation = enable_validation\n    self._strip_prefixes = strip_prefixes\n    self.context: dict = {}  # early init as customers might add context before event resolution\n    self.processed_stack_frames = []\n    self._response_builder_class = ResponseBuilder[BaseProxyEvent]\n    self.openapi_config = OpenAPIConfig()  # starting an empty dataclass\n    self._has_response_validation_error = response_validation_error_http_code is not None\n    self._response_validation_error_http_code = self._validate_response_validation_error_http_code(\n        response_validation_error_http_code,\n        enable_validation,\n    )\n\n    # Allow for a custom serializer or a concise json serialization\n    self._serializer = serializer or partial(json.dumps, separators=(\",\", \":\"), cls=Encoder)\n\n    if self._enable_validation:\n        from aws_lambda_powertools.event_handler.middlewares.openapi_validation import OpenAPIValidationMiddleware\n\n        # Note the serializer argument: only use custom serializer if provided by the caller\n        # Otherwise, fully rely on the internal Pydantic based mechanism to serialize responses for validation.\n        self.use(\n            [\n                OpenAPIValidationMiddleware(\n                    validation_serializer=serializer,\n                    has_response_validation_error=self._has_response_validation_error,\n                ),\n            ],\n        )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ApiGatewayResolver.configure_openapi",
            "title": "configure_openapi",
            "text": "<pre><code>configure_openapi(\n    title: str = DEFAULT_OPENAPI_TITLE,\n    version: str = DEFAULT_API_VERSION,\n    openapi_version: str = DEFAULT_OPENAPI_VERSION,\n    summary: str | None = None,\n    description: str | None = None,\n    tags: list[Tag | str] | None = None,\n    servers: list[Server] | None = None,\n    terms_of_service: str | None = None,\n    contact: Contact | None = None,\n    license_info: License | None = None,\n    security_schemes: (\n        dict[str, SecurityScheme] | None\n    ) = None,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n)\n</code></pre> <p>Configure OpenAPI specification settings for the API.</p> <p>Sets up the OpenAPI documentation configuration that can be later used when enabling Swagger UI or generating OpenAPI specifications.</p> PARAMETER DESCRIPTION <code>title</code> <p>The title of the application.</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_OPENAPI_TITLE</code> </p> <code>version</code> <p>The version of the OpenAPI document (which is distinct from the OpenAPI Specification version or the API</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_API_VERSION</code> </p> <code>openapi_version</code> <p>The version of the OpenAPI Specification (which the document uses).</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_OPENAPI_VERSION</code> </p> <code>summary</code> <p>A short summary of what the application does.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>description</code> <p>A verbose explanation of the application behavior.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>tags</code> <p>A list of tags used by the specification with additional metadata.</p> <p> TYPE: <code>list[Tag | str] | None</code> DEFAULT: <code>None</code> </p> <code>servers</code> <p>An array of Server Objects, which provide connectivity information to a target server.</p> <p> TYPE: <code>list[Server] | None</code> DEFAULT: <code>None</code> </p> <code>terms_of_service</code> <p>A URL to the Terms of Service for the API. MUST be in the format of a URL.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>contact</code> <p>The contact information for the exposed API.</p> <p> TYPE: <code>Contact | None</code> DEFAULT: <code>None</code> </p> <code>license_info</code> <p>The license information for the exposed API.</p> <p> TYPE: <code>License | None</code> DEFAULT: <code>None</code> </p> <code>security_schemes</code> <p>A declaration of the security schemes available to be used in the specification.</p> <p> TYPE: <code>dict[str, SecurityScheme] | None</code> DEFAULT: <code>None</code> </p> <code>security</code> <p>A declaration of which security mechanisms are applied globally across the API.</p> <p> TYPE: <code>list[dict[str, list[str]]] | None</code> DEFAULT: <code>None</code> </p> <code>openapi_extensions</code> <p>Additional OpenAPI extensions as a dictionary.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Example <p>api.configure_openapi( ...     title=\"My API\", ...     version=\"1.0.0\", ...     description=\"API for managing resources\", ...     contact=Contact( ...         name=\"API Support\", ...         email=\"support@example.com\" ...     ) ... )</p> See Also <p>enable_swagger : Method to enable Swagger UI using these configurations OpenAPIConfig : Data class containing all OpenAPI configuration options</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def configure_openapi(\n    self,\n    title: str = DEFAULT_OPENAPI_TITLE,\n    version: str = DEFAULT_API_VERSION,\n    openapi_version: str = DEFAULT_OPENAPI_VERSION,\n    summary: str | None = None,\n    description: str | None = None,\n    tags: list[Tag | str] | None = None,\n    servers: list[Server] | None = None,\n    terms_of_service: str | None = None,\n    contact: Contact | None = None,\n    license_info: License | None = None,\n    security_schemes: dict[str, SecurityScheme] | None = None,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n):\n    \"\"\"Configure OpenAPI specification settings for the API.\n\n    Sets up the OpenAPI documentation configuration that can be later used\n    when enabling Swagger UI or generating OpenAPI specifications.\n\n    Parameters\n    ----------\n    title: str\n        The title of the application.\n    version: str\n        The version of the OpenAPI document (which is distinct from the OpenAPI Specification version or the API\n    openapi_version: str, default = \"3.0.0\"\n        The version of the OpenAPI Specification (which the document uses).\n    summary: str, optional\n        A short summary of what the application does.\n    description: str, optional\n        A verbose explanation of the application behavior.\n    tags: list[Tag, str], optional\n        A list of tags used by the specification with additional metadata.\n    servers: list[Server], optional\n        An array of Server Objects, which provide connectivity information to a target server.\n    terms_of_service: str, optional\n        A URL to the Terms of Service for the API. MUST be in the format of a URL.\n    contact: Contact, optional\n        The contact information for the exposed API.\n    license_info: License, optional\n        The license information for the exposed API.\n    security_schemes: dict[str, SecurityScheme]], optional\n        A declaration of the security schemes available to be used in the specification.\n    security: list[dict[str, list[str]]], optional\n        A declaration of which security mechanisms are applied globally across the API.\n    openapi_extensions: Dict[str, Any], optional\n        Additional OpenAPI extensions as a dictionary.\n\n    Example\n    --------\n    &gt;&gt;&gt; api.configure_openapi(\n    ...     title=\"My API\",\n    ...     version=\"1.0.0\",\n    ...     description=\"API for managing resources\",\n    ...     contact=Contact(\n    ...         name=\"API Support\",\n    ...         email=\"support@example.com\"\n    ...     )\n    ... )\n\n    See Also\n    --------\n    enable_swagger : Method to enable Swagger UI using these configurations\n    OpenAPIConfig : Data class containing all OpenAPI configuration options\n    \"\"\"\n    self.openapi_config = OpenAPIConfig(\n        title=title,\n        version=version,\n        openapi_version=openapi_version,\n        summary=summary,\n        description=description,\n        tags=tags,\n        servers=servers,\n        terms_of_service=terms_of_service,\n        contact=contact,\n        license_info=license_info,\n        security_schemes=security_schemes,\n        security=security,\n        openapi_extensions=openapi_extensions,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ApiGatewayResolver.enable_swagger",
            "title": "enable_swagger",
            "text": "<pre><code>enable_swagger(\n    *,\n    path: str = \"/swagger\",\n    title: str = DEFAULT_OPENAPI_TITLE,\n    version: str = DEFAULT_API_VERSION,\n    openapi_version: str = DEFAULT_OPENAPI_VERSION,\n    summary: str | None = None,\n    description: str | None = None,\n    tags: list[Tag | str] | None = None,\n    servers: list[Server] | None = None,\n    terms_of_service: str | None = None,\n    contact: Contact | None = None,\n    license_info: License | None = None,\n    swagger_base_url: str | None = None,\n    middlewares: (\n        list[Callable[..., Response]] | None\n    ) = None,\n    compress: bool = False,\n    security_schemes: (\n        dict[str, SecurityScheme] | None\n    ) = None,\n    security: list[dict[str, list[str]]] | None = None,\n    oauth2_config: OAuth2Config | None = None,\n    persist_authorization: bool = False,\n    openapi_extensions: dict[str, Any] | None = None\n)\n</code></pre> <p>Returns the OpenAPI schema as a JSON serializable dict</p> PARAMETER DESCRIPTION <code>path</code> <p>The path to the swagger UI.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'/swagger'</code> </p> <code>title</code> <p>The title of the application.</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_OPENAPI_TITLE</code> </p> <code>version</code> <p>The version of the OpenAPI document (which is distinct from the OpenAPI Specification version or the API</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_API_VERSION</code> </p> <code>openapi_version</code> <p>The version of the OpenAPI Specification (which the document uses).</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_OPENAPI_VERSION</code> </p> <code>summary</code> <p>A short summary of what the application does.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>description</code> <p>A verbose explanation of the application behavior.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>tags</code> <p>A list of tags used by the specification with additional metadata.</p> <p> TYPE: <code>list[Tag | str] | None</code> DEFAULT: <code>None</code> </p> <code>servers</code> <p>An array of Server Objects, which provide connectivity information to a target server.</p> <p> TYPE: <code>list[Server] | None</code> DEFAULT: <code>None</code> </p> <code>terms_of_service</code> <p>A URL to the Terms of Service for the API. MUST be in the format of a URL.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>contact</code> <p>The contact information for the exposed API.</p> <p> TYPE: <code>Contact | None</code> DEFAULT: <code>None</code> </p> <code>license_info</code> <p>The license information for the exposed API.</p> <p> TYPE: <code>License | None</code> DEFAULT: <code>None</code> </p> <code>swagger_base_url</code> <p>The base url for the swagger UI. If not provided, we will serve a recent version of the Swagger UI.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>middlewares</code> <p>List of middlewares to be used for the swagger route.</p> <p> TYPE: <code>list[Callable[..., Response]] | None</code> DEFAULT: <code>None</code> </p> <code>compress</code> <p>Whether or not to enable gzip compression swagger route.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>security_schemes</code> <p>A declaration of the security schemes available to be used in the specification.</p> <p> TYPE: <code>dict[str, SecurityScheme] | None</code> DEFAULT: <code>None</code> </p> <code>security</code> <p>A declaration of which security mechanisms are applied globally across the API.</p> <p> TYPE: <code>list[dict[str, list[str]]] | None</code> DEFAULT: <code>None</code> </p> <code>oauth2_config</code> <p>The OAuth2 configuration for the Swagger UI.</p> <p> TYPE: <code>OAuth2Config | None</code> DEFAULT: <code>None</code> </p> <code>persist_authorization</code> <p>Whether to persist authorization data on browser close/refresh.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>openapi_extensions</code> <p>Additional OpenAPI extensions as a dictionary.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def enable_swagger(\n    self,\n    *,\n    path: str = \"/swagger\",\n    title: str = DEFAULT_OPENAPI_TITLE,\n    version: str = DEFAULT_API_VERSION,\n    openapi_version: str = DEFAULT_OPENAPI_VERSION,\n    summary: str | None = None,\n    description: str | None = None,\n    tags: list[Tag | str] | None = None,\n    servers: list[Server] | None = None,\n    terms_of_service: str | None = None,\n    contact: Contact | None = None,\n    license_info: License | None = None,\n    swagger_base_url: str | None = None,\n    middlewares: list[Callable[..., Response]] | None = None,\n    compress: bool = False,\n    security_schemes: dict[str, SecurityScheme] | None = None,\n    security: list[dict[str, list[str]]] | None = None,\n    oauth2_config: OAuth2Config | None = None,\n    persist_authorization: bool = False,\n    openapi_extensions: dict[str, Any] | None = None,\n):\n    \"\"\"\n    Returns the OpenAPI schema as a JSON serializable dict\n\n    Parameters\n    ----------\n    path: str, default = \"/swagger\"\n        The path to the swagger UI.\n    title: str\n        The title of the application.\n    version: str\n        The version of the OpenAPI document (which is distinct from the OpenAPI Specification version or the API\n    openapi_version: str, default = \"3.0.0\"\n        The version of the OpenAPI Specification (which the document uses).\n    summary: str, optional\n        A short summary of what the application does.\n    description: str, optional\n        A verbose explanation of the application behavior.\n    tags: list[Tag, str], optional\n        A list of tags used by the specification with additional metadata.\n    servers: list[Server], optional\n        An array of Server Objects, which provide connectivity information to a target server.\n    terms_of_service: str, optional\n        A URL to the Terms of Service for the API. MUST be in the format of a URL.\n    contact: Contact, optional\n        The contact information for the exposed API.\n    license_info: License, optional\n        The license information for the exposed API.\n    swagger_base_url: str, optional\n        The base url for the swagger UI. If not provided, we will serve a recent version of the Swagger UI.\n    middlewares: list[Callable[..., Response]], optional\n        List of middlewares to be used for the swagger route.\n    compress: bool, default = False\n        Whether or not to enable gzip compression swagger route.\n    security_schemes: dict[str, \"SecurityScheme\"], optional\n        A declaration of the security schemes available to be used in the specification.\n    security: list[dict[str, list[str]]], optional\n        A declaration of which security mechanisms are applied globally across the API.\n    oauth2_config: OAuth2Config, optional\n        The OAuth2 configuration for the Swagger UI.\n    persist_authorization: bool, optional\n        Whether to persist authorization data on browser close/refresh.\n    openapi_extensions: dict[str, Any], optional\n        Additional OpenAPI extensions as a dictionary.\n    \"\"\"\n\n    from aws_lambda_powertools.event_handler.openapi.compat import model_json\n    from aws_lambda_powertools.event_handler.openapi.models import Server\n    from aws_lambda_powertools.event_handler.openapi.swagger_ui import (\n        generate_oauth2_redirect_html,\n        generate_swagger_html,\n    )\n\n    @self.get(path, middlewares=middlewares, include_in_schema=False, compress=compress)\n    def swagger_handler():\n        query_params = self.current_event.query_string_parameters or {}\n\n        # Check for query parameters; if \"format\" is specified as \"oauth2-redirect\",\n        # send the oauth2-redirect HTML stanza so OAuth2 can be used\n        # Source: https://github.com/swagger-api/swagger-ui/blob/master/dist/oauth2-redirect.html\n        if query_params.get(\"format\") == \"oauth2-redirect\":\n            return Response(\n                status_code=200,\n                content_type=\"text/html\",\n                body=generate_oauth2_redirect_html(),\n            )\n\n        base_path = self._get_base_path()\n\n        if swagger_base_url:\n            swagger_js = f\"{swagger_base_url}/swagger-ui-bundle.min.js\"\n            swagger_css = f\"{swagger_base_url}/swagger-ui.min.css\"\n        else:\n            # We now inject CSS and JS into the SwaggerUI file\n            swagger_js = Path.open(\n                Path(__file__).parent / \"openapi\" / \"swagger_ui\" / \"swagger-ui-bundle.min.js\",\n            ).read()\n            swagger_css = Path.open(Path(__file__).parent / \"openapi\" / \"swagger_ui\" / \"swagger-ui.min.css\").read()\n\n        openapi_servers = servers or [Server(url=(base_path or \"/\"))]\n\n        spec = self.get_openapi_schema(\n            title=title,\n            version=version,\n            openapi_version=openapi_version,\n            summary=summary,\n            description=description,\n            tags=tags,\n            servers=openapi_servers,\n            terms_of_service=terms_of_service,\n            contact=contact,\n            license_info=license_info,\n            security_schemes=security_schemes,\n            security=security,\n            openapi_extensions=openapi_extensions,\n        )\n\n        # The .replace('&lt;/', '&lt;\\\\/') part is necessary to prevent a potential issue where the JSON string contains\n        # &lt;/script&gt; or similar tags. Escaping the forward slash in &lt;/ as &lt;\\/ ensures that the JSON does not\n        # inadvertently close the script tag, and the JSON remains a valid string within the JavaScript code.\n        escaped_spec = model_json(\n            spec,\n            by_alias=True,\n            exclude_none=True,\n            indent=2,\n        ).replace(\"&lt;/\", \"&lt;\\\\/\")\n\n        # Check for query parameters; if \"format\" is specified as \"json\",\n        # respond with the JSON used in the OpenAPI spec\n        # Example: https://www.example.com/swagger?format=json\n        if query_params.get(\"format\") == \"json\":\n            return Response(\n                status_code=200,\n                content_type=\"application/json\",\n                body=escaped_spec,\n            )\n\n        body = generate_swagger_html(\n            escaped_spec,\n            swagger_js,\n            swagger_css,\n            swagger_base_url,\n            oauth2_config,\n            persist_authorization,\n        )\n\n        return Response(\n            status_code=200,\n            content_type=\"text/html\",\n            body=body,\n        )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ApiGatewayResolver.get_openapi_json_schema",
            "title": "get_openapi_json_schema",
            "text": "<pre><code>get_openapi_json_schema(\n    *,\n    title: str = DEFAULT_OPENAPI_TITLE,\n    version: str = DEFAULT_API_VERSION,\n    openapi_version: str = DEFAULT_OPENAPI_VERSION,\n    summary: str | None = None,\n    description: str | None = None,\n    tags: list[Tag | str] | None = None,\n    servers: list[Server] | None = None,\n    terms_of_service: str | None = None,\n    contact: Contact | None = None,\n    license_info: License | None = None,\n    security_schemes: (\n        dict[str, SecurityScheme] | None\n    ) = None,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None\n) -&gt; str\n</code></pre> <p>Returns the OpenAPI schema as a JSON serializable dict</p> PARAMETER DESCRIPTION <code>title</code> <p>The title of the application.</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_OPENAPI_TITLE</code> </p> <code>version</code> <p>The version of the OpenAPI document (which is distinct from the OpenAPI Specification version or the API</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_API_VERSION</code> </p> <code>openapi_version</code> <p>The version of the OpenAPI Specification (which the document uses).</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_OPENAPI_VERSION</code> </p> <code>summary</code> <p>A short summary of what the application does.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>description</code> <p>A verbose explanation of the application behavior.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>tags</code> <p>A list of tags used by the specification with additional metadata.</p> <p> TYPE: <code>list[Tag | str] | None</code> DEFAULT: <code>None</code> </p> <code>servers</code> <p>An array of Server Objects, which provide connectivity information to a target server.</p> <p> TYPE: <code>list[Server] | None</code> DEFAULT: <code>None</code> </p> <code>terms_of_service</code> <p>A URL to the Terms of Service for the API. MUST be in the format of a URL.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>contact</code> <p>The contact information for the exposed API.</p> <p> TYPE: <code>Contact | None</code> DEFAULT: <code>None</code> </p> <code>license_info</code> <p>The license information for the exposed API.</p> <p> TYPE: <code>License | None</code> DEFAULT: <code>None</code> </p> <code>security_schemes</code> <p>A declaration of the security schemes available to be used in the specification.</p> <p> TYPE: <code>dict[str, SecurityScheme] | None</code> DEFAULT: <code>None</code> </p> <code>security</code> <p>A declaration of which security mechanisms are applied globally across the API.</p> <p> TYPE: <code>list[dict[str, list[str]]] | None</code> DEFAULT: <code>None</code> </p> <code>openapi_extensions</code> <p>Additional OpenAPI extensions as a dictionary.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>str</code> <p>The OpenAPI schema as a JSON serializable dict.</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def get_openapi_json_schema(\n    self,\n    *,\n    title: str = DEFAULT_OPENAPI_TITLE,\n    version: str = DEFAULT_API_VERSION,\n    openapi_version: str = DEFAULT_OPENAPI_VERSION,\n    summary: str | None = None,\n    description: str | None = None,\n    tags: list[Tag | str] | None = None,\n    servers: list[Server] | None = None,\n    terms_of_service: str | None = None,\n    contact: Contact | None = None,\n    license_info: License | None = None,\n    security_schemes: dict[str, SecurityScheme] | None = None,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n) -&gt; str:\n    \"\"\"\n    Returns the OpenAPI schema as a JSON serializable dict\n\n    Parameters\n    ----------\n    title: str\n        The title of the application.\n    version: str\n        The version of the OpenAPI document (which is distinct from the OpenAPI Specification version or the API\n    openapi_version: str, default = \"3.0.0\"\n        The version of the OpenAPI Specification (which the document uses).\n    summary: str, optional\n        A short summary of what the application does.\n    description: str, optional\n        A verbose explanation of the application behavior.\n    tags: list[Tag, str], optional\n        A list of tags used by the specification with additional metadata.\n    servers: list[Server], optional\n        An array of Server Objects, which provide connectivity information to a target server.\n    terms_of_service: str, optional\n        A URL to the Terms of Service for the API. MUST be in the format of a URL.\n    contact: Contact, optional\n        The contact information for the exposed API.\n    license_info: License, optional\n        The license information for the exposed API.\n    security_schemes: dict[str, SecurityScheme]], optional\n        A declaration of the security schemes available to be used in the specification.\n    security: list[dict[str, list[str]]], optional\n        A declaration of which security mechanisms are applied globally across the API.\n    openapi_extensions: Dict[str, Any], optional\n        Additional OpenAPI extensions as a dictionary.\n\n    Returns\n    -------\n    str\n        The OpenAPI schema as a JSON serializable dict.\n    \"\"\"\n\n    from aws_lambda_powertools.event_handler.openapi.compat import model_json\n\n    return model_json(\n        self.get_openapi_schema(\n            title=title,\n            version=version,\n            openapi_version=openapi_version,\n            summary=summary,\n            description=description,\n            tags=tags,\n            servers=servers,\n            terms_of_service=terms_of_service,\n            contact=contact,\n            license_info=license_info,\n            security_schemes=security_schemes,\n            security=security,\n            openapi_extensions=openapi_extensions,\n        ),\n        by_alias=True,\n        exclude_none=True,\n        indent=2,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ApiGatewayResolver.get_openapi_schema",
            "title": "get_openapi_schema",
            "text": "<pre><code>get_openapi_schema(\n    *,\n    title: str = DEFAULT_OPENAPI_TITLE,\n    version: str = DEFAULT_API_VERSION,\n    openapi_version: str = DEFAULT_OPENAPI_VERSION,\n    summary: str | None = None,\n    description: str | None = None,\n    tags: list[Tag | str] | None = None,\n    servers: list[Server] | None = None,\n    terms_of_service: str | None = None,\n    contact: Contact | None = None,\n    license_info: License | None = None,\n    security_schemes: (\n        dict[str, SecurityScheme] | None\n    ) = None,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None\n) -&gt; OpenAPI\n</code></pre> <p>Returns the OpenAPI schema as a pydantic model.</p> PARAMETER DESCRIPTION <code>title</code> <p>The title of the application.</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_OPENAPI_TITLE</code> </p> <code>version</code> <p>The version of the OpenAPI document (which is distinct from the OpenAPI Specification version or the API</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_API_VERSION</code> </p> <code>openapi_version</code> <p>The version of the OpenAPI Specification (which the document uses).</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_OPENAPI_VERSION</code> </p> <code>summary</code> <p>A short summary of what the application does.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>description</code> <p>A verbose explanation of the application behavior.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>tags</code> <p>A list of tags used by the specification with additional metadata.</p> <p> TYPE: <code>list[Tag | str] | None</code> DEFAULT: <code>None</code> </p> <code>servers</code> <p>An array of Server Objects, which provide connectivity information to a target server.</p> <p> TYPE: <code>list[Server] | None</code> DEFAULT: <code>None</code> </p> <code>terms_of_service</code> <p>A URL to the Terms of Service for the API. MUST be in the format of a URL.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>contact</code> <p>The contact information for the exposed API.</p> <p> TYPE: <code>Contact | None</code> DEFAULT: <code>None</code> </p> <code>license_info</code> <p>The license information for the exposed API.</p> <p> TYPE: <code>License | None</code> DEFAULT: <code>None</code> </p> <code>security_schemes</code> <p>A declaration of the security schemes available to be used in the specification.</p> <p> TYPE: <code>dict[str, SecurityScheme] | None</code> DEFAULT: <code>None</code> </p> <code>security</code> <p>A declaration of which security mechanisms are applied globally across the API.</p> <p> TYPE: <code>list[dict[str, list[str]]] | None</code> DEFAULT: <code>None</code> </p> <code>openapi_extensions</code> <p>Additional OpenAPI extensions as a dictionary.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>OpenAPI</code> <p>The OpenAPI schema as a pydantic model.</p> <p> TYPE: <code>pydantic model</code> </p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def get_openapi_schema(\n    self,\n    *,\n    title: str = DEFAULT_OPENAPI_TITLE,\n    version: str = DEFAULT_API_VERSION,\n    openapi_version: str = DEFAULT_OPENAPI_VERSION,\n    summary: str | None = None,\n    description: str | None = None,\n    tags: list[Tag | str] | None = None,\n    servers: list[Server] | None = None,\n    terms_of_service: str | None = None,\n    contact: Contact | None = None,\n    license_info: License | None = None,\n    security_schemes: dict[str, SecurityScheme] | None = None,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n) -&gt; OpenAPI:\n    \"\"\"\n    Returns the OpenAPI schema as a pydantic model.\n\n    Parameters\n    ----------\n    title: str\n        The title of the application.\n    version: str\n        The version of the OpenAPI document (which is distinct from the OpenAPI Specification version or the API\n    openapi_version: str, default = \"3.0.0\"\n        The version of the OpenAPI Specification (which the document uses).\n    summary: str, optional\n        A short summary of what the application does.\n    description: str, optional\n        A verbose explanation of the application behavior.\n    tags: list[Tag | str], optional\n        A list of tags used by the specification with additional metadata.\n    servers: list[Server], optional\n        An array of Server Objects, which provide connectivity information to a target server.\n    terms_of_service: str, optional\n        A URL to the Terms of Service for the API. MUST be in the format of a URL.\n    contact: Contact, optional\n        The contact information for the exposed API.\n    license_info: License, optional\n        The license information for the exposed API.\n    security_schemes: dict[str, SecurityScheme]], optional\n        A declaration of the security schemes available to be used in the specification.\n    security: list[dict[str, list[str]]], optional\n        A declaration of which security mechanisms are applied globally across the API.\n    openapi_extensions: Dict[str, Any], optional\n        Additional OpenAPI extensions as a dictionary.\n\n    Returns\n    -------\n    OpenAPI: pydantic model\n        The OpenAPI schema as a pydantic model.\n    \"\"\"\n\n    # DEPRECATION: Will be removed in v4.0.0. Use configure_api() instead.\n    # Maintained for backwards compatibility.\n    # See: https://github.com/aws-powertools/powertools-lambda-python/issues/6122\n    if title == DEFAULT_OPENAPI_TITLE and self.openapi_config.title:\n        title = self.openapi_config.title\n\n    if version == DEFAULT_API_VERSION and self.openapi_config.version:\n        version = self.openapi_config.version\n\n    if openapi_version == DEFAULT_OPENAPI_VERSION and self.openapi_config.openapi_version:\n        openapi_version = self.openapi_config.openapi_version\n\n    summary = summary or self.openapi_config.summary\n    description = description or self.openapi_config.description\n    tags = tags or self.openapi_config.tags\n    servers = servers or self.openapi_config.servers\n    terms_of_service = terms_of_service or self.openapi_config.terms_of_service\n    contact = contact or self.openapi_config.contact\n    license_info = license_info or self.openapi_config.license_info\n    security_schemes = security_schemes or self.openapi_config.security_schemes\n    security = security or self.openapi_config.security\n    openapi_extensions = openapi_extensions or self.openapi_config.openapi_extensions\n\n    from aws_lambda_powertools.event_handler.openapi.compat import (\n        GenerateJsonSchema,\n        get_compat_model_name_map,\n        get_definitions,\n    )\n    from aws_lambda_powertools.event_handler.openapi.models import OpenAPI, PathItem, Tag\n    from aws_lambda_powertools.event_handler.openapi.types import (\n        COMPONENT_REF_TEMPLATE,\n    )\n\n    openapi_version = self._determine_openapi_version(openapi_version)\n\n    # Start with the bare minimum required for a valid OpenAPI schema\n    info: dict[str, Any] = {\"title\": title, \"version\": version}\n\n    optional_fields = {\n        \"summary\": summary,\n        \"description\": description,\n        \"termsOfService\": terms_of_service,\n        \"contact\": contact,\n        \"license\": license_info,\n    }\n\n    info.update({field: value for field, value in optional_fields.items() if value})\n\n    if not isinstance(openapi_extensions, dict):\n        openapi_extensions = {}\n\n    output: dict[str, Any] = {\n        \"openapi\": openapi_version,\n        \"info\": info,\n        \"servers\": self._get_openapi_servers(servers),\n        \"security\": self._get_openapi_security(security, security_schemes),\n        **openapi_extensions,\n    }\n\n    components: dict[str, dict[str, Any]] = {}\n    paths: dict[str, dict[str, Any]] = {}\n    operation_ids: set[str] = set()\n\n    all_routes = self._dynamic_routes + self._static_routes\n    all_fields = self._get_fields_from_routes(all_routes)\n    model_name_map = get_compat_model_name_map(all_fields)\n\n    # Collect all models and definitions\n    schema_generator = GenerateJsonSchema(ref_template=COMPONENT_REF_TEMPLATE)\n    field_mapping, definitions = get_definitions(\n        fields=all_fields,\n        schema_generator=schema_generator,\n        model_name_map=model_name_map,\n    )\n\n    # Add routes to the OpenAPI schema\n    for route in all_routes:\n        if route.security and not _validate_openapi_security_parameters(\n            security=route.security,\n            security_schemes=security_schemes,\n        ):\n            raise SchemaValidationError(\n                \"Security configuration was not found in security_schemas or security_schema was not defined. \"\n                \"See: https://docs.powertools.aws.dev/lambda/python/latest/core/event_handler/api_gateway/#security-schemes\",\n            )\n\n        if not route.include_in_schema:\n            continue\n\n        result = route._get_openapi_path(\n            dependant=route.dependant,\n            operation_ids=operation_ids,\n            model_name_map=model_name_map,\n            field_mapping=field_mapping,\n        )\n        if result:\n            path, path_definitions = result\n            if path:\n                paths.setdefault(route.openapi_path, {}).update(path)\n            if path_definitions:\n                definitions.update(path_definitions)\n\n    if definitions:\n        components[\"schemas\"] = {k: definitions[k] for k in sorted(definitions)}\n    if security_schemes:\n        components[\"securitySchemes\"] = security_schemes\n    if components:\n        output[\"components\"] = components\n    if tags:\n        output[\"tags\"] = [Tag(name=tag) if isinstance(tag, str) else tag for tag in tags]\n\n    output[\"paths\"] = {k: PathItem(**v) for k, v in paths.items()}\n\n    return OpenAPI(**output)\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ApiGatewayResolver.include_router",
            "title": "include_router",
            "text": "<pre><code>include_router(\n    router: Router, prefix: str | None = None\n) -&gt; None\n</code></pre> <p>Adds all routes and context defined in a router</p> PARAMETER DESCRIPTION <code>router</code> <p>The Router containing a list of routes to be registered after the existing routes</p> <p> TYPE: <code>Router</code> </p> <code>prefix</code> <p>An optional prefix to be added to the originally defined rule</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def include_router(self, router: Router, prefix: str | None = None) -&gt; None:\n    \"\"\"Adds all routes and context defined in a router\n\n    Parameters\n    ----------\n    router : Router\n        The Router containing a list of routes to be registered after the existing routes\n    prefix : str, optional\n        An optional prefix to be added to the originally defined rule\n    \"\"\"\n\n    # Add reference to parent ApiGatewayResolver to support use cases where people subclass it to add custom logic\n    router.api_resolver = self\n\n    logger.debug(\"Merging App context with Router context\")\n    self.context.update(**router.context)\n\n    logger.debug(\"Appending Router middlewares into App middlewares.\")\n    self._router_middlewares = self._router_middlewares + router._router_middlewares\n\n    logger.debug(\"Appending Router exception_handler into App exception_handler.\")\n    self._exception_handlers.update(router._exception_handlers)\n\n    # use pointer to allow context clearance after event is processed e.g., resolve(evt, ctx)\n    router.context = self.context\n\n    # Iterate through the routes defined in the router to configure and apply middlewares for each route\n    for route, func in router._routes.items():\n        new_route = route\n\n        if prefix:\n            rule = route[0]\n            rule = prefix if rule == \"/\" else f\"{prefix}{rule}\"\n            new_route = (rule, *route[1:])\n\n        # Middlewares are stored by route separately - must grab them to include\n        # Middleware store the route without prefix, so we must not include prefix when grabbing\n        middlewares = router._routes_with_middleware.get(route)\n\n        # Need to use \"type: ignore\" here since mypy does not like a named parameter after\n        # tuple expansion since may cause duplicate named parameters in the function signature.\n        # In this case this is not possible since the tuple expansion is from a hashable source\n        # and the `middlewares` list is a non-hashable structure so will never be included.\n        # Still need to ignore for mypy checks or will cause failures (false-positive)\n        self.route(*new_route, middlewares=middlewares)(func)  # type: ignore\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ApiGatewayResolver.resolve",
            "title": "resolve",
            "text": "<pre><code>resolve(\n    event: dict[str, Any], context: LambdaContext\n) -&gt; dict[str, Any]\n</code></pre> <p>Resolves the response based on the provide event and decorator routes</p>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ApiGatewayResolver.resolve--internals",
            "title": "Internals",
            "text": "<p>Request processing chain is triggered by a Route object being called (<code>_call_route</code> -&gt; <code>__call__</code>):</p> <ol> <li>When a route is matched   1.1. Exception handlers (if any exception bubbled up and caught)   1.2. Global middlewares (before, and after on the way back)   1.3. Path level middleware (before, and after on the way back)   1.4. Middleware adapter to ensure Response is homogenous (_registered_api_adapter)   1.5. Run actual route</li> <li>When a route is NOT matched   2.1. Exception handlers (if any exception bubbled up and caught)   2.2. Global middlewares (before, and after on the way back)   2.3. Path level middleware (before, and after on the way back)   2.4. Middleware adapter to ensure Response is homogenous (_registered_api_adapter)   2.5. Run 404 route handler</li> <li>When a route is a pre-flight CORS (often not matched)   3.1. Exception handlers (if any exception bubbled up and caught)   3.2. Global middlewares (before, and after on the way back)   3.3. Path level middleware (before, and after on the way back)   3.4. Middleware adapter to ensure Response is homogenous (_registered_api_adapter)   3.5. Return 204 with appropriate CORS headers</li> <li>When a route is matched with Data Validation enabled   4.1. Exception handlers (if any exception bubbled up and caught)   4.2. Data Validation middleware (before, and after on the way back)   4.3. Global middlewares (before, and after on the way back)   4.4. Path level middleware (before, and after on the way back)   4.5. Middleware adapter to ensure Response is homogenous (_registered_api_adapter)   4.6. Run actual route</li> </ol> PARAMETER DESCRIPTION <code>event</code> <p>Event</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>context</code> <p>Lambda context</p> <p> TYPE: <code>LambdaContext</code> </p> RETURNS DESCRIPTION <code>dict</code> <p>Returns the dict response</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def resolve(self, event: dict[str, Any], context: LambdaContext) -&gt; dict[str, Any]:\n    \"\"\"Resolves the response based on the provide event and decorator routes\n\n    ## Internals\n\n    Request processing chain is triggered by a Route object being called _(`_call_route` -&gt; `__call__`)_:\n\n    1. **When a route is matched**\n      1.1. Exception handlers _(if any exception bubbled up and caught)_\n      1.2. Global middlewares _(before, and after on the way back)_\n      1.3. Path level middleware _(before, and after on the way back)_\n      1.4. Middleware adapter to ensure Response is homogenous (_registered_api_adapter)\n      1.5. Run actual route\n    2. **When a route is NOT matched**\n      2.1. Exception handlers _(if any exception bubbled up and caught)_\n      2.2. Global middlewares _(before, and after on the way back)_\n      2.3. Path level middleware _(before, and after on the way back)_\n      2.4. Middleware adapter to ensure Response is homogenous (_registered_api_adapter)\n      2.5. Run 404 route handler\n    3. **When a route is a pre-flight CORS (often not matched)**\n      3.1. Exception handlers _(if any exception bubbled up and caught)_\n      3.2. Global middlewares _(before, and after on the way back)_\n      3.3. Path level middleware _(before, and after on the way back)_\n      3.4. Middleware adapter to ensure Response is homogenous (_registered_api_adapter)\n      3.5. Return 204 with appropriate CORS headers\n    4. **When a route is matched with Data Validation enabled**\n      4.1. Exception handlers _(if any exception bubbled up and caught)_\n      4.2. Data Validation middleware _(before, and after on the way back)_\n      4.3. Global middlewares _(before, and after on the way back)_\n      4.4. Path level middleware _(before, and after on the way back)_\n      4.5. Middleware adapter to ensure Response is homogenous (_registered_api_adapter)\n      4.6. Run actual route\n\n    Parameters\n    ----------\n    event: dict[str, Any]\n        Event\n    context: LambdaContext\n        Lambda context\n    Returns\n    -------\n    dict\n        Returns the dict response\n    \"\"\"\n    if isinstance(event, BaseProxyEvent):\n        warnings.warn(\n            \"You don't need to serialize event to Event Source Data Class when using Event Handler; \"\n            \"see issue #1152\",\n            stacklevel=2,\n        )\n        event = event.raw_event\n\n    if self._debug:\n        print(self._serializer(event))\n\n    # Populate router(s) dependencies without keeping a reference to each registered router\n    BaseRouter.current_event = self._to_proxy_event(event)\n    BaseRouter.lambda_context = context\n\n    response = self._resolve().build(self.current_event, self._cors)\n\n    # Debug print Processed Middlewares\n    if self._debug:\n        print(\"\\nProcessed Middlewares:\")\n        print(\"======================\")\n        print(\"\\n\".join(self.processed_stack_frames))\n        print(\"======================\")\n\n    self.clear_context()\n\n    return response\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ApiGatewayResolver.route",
            "title": "route",
            "text": "<pre><code>route(\n    rule: str,\n    method: str | list[str] | tuple[str],\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable[..., Any]] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]\n</code></pre> <p>Route decorator includes parameter <code>method</code></p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def route(\n    self,\n    rule: str,\n    method: str | list[str] | tuple[str],\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable[..., Any]] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]:\n    \"\"\"Route decorator includes parameter `method`\"\"\"\n\n    def register_resolver(func: AnyCallableT) -&gt; AnyCallableT:\n        methods = (method,) if isinstance(method, str) else method\n        logger.debug(f\"Adding route using rule {rule} and methods: {','.join(m.upper() for m in methods)}\")\n\n        cors_enabled = self._cors_enabled if cors is None else cors\n\n        for item in methods:\n            _route = Route(\n                item,\n                rule,\n                self._compile_regex(rule),\n                func,\n                cors_enabled,\n                compress,\n                cache_control,\n                summary,\n                description,\n                responses,\n                response_description,\n                tags,\n                operation_id,\n                include_in_schema,\n                security,\n                openapi_extensions,\n                deprecated,\n                middlewares,\n            )\n\n            # The more specific route wins.\n            # We store dynamic (/studies/{studyid}) and static routes (/studies/fetch) separately.\n            # Then attempt a match for static routes before dynamic routes.\n            # This ensures that the most specific route is prioritized and processed first (studies/fetch).\n            if _route.rule.groups &gt; 0:\n                self._dynamic_routes.append(_route)\n            else:\n                self._static_routes.append(_route)\n\n            self._create_route_key(item, rule)\n\n            if cors_enabled:\n                logger.debug(f\"Registering method {item.upper()} to Allow Methods in CORS\")\n                self._cors_methods.add(item.upper())\n\n        return func\n\n    return register_resolver\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.BaseRouter",
            "title": "BaseRouter",
            "text": "<p>               Bases: <code>ABC</code></p> <p>Base class for Routing</p> METHOD DESCRIPTION <code>append_context</code> <p>Append key=value data as routing context</p> <code>clear_context</code> <p>Resets routing context</p> <code>delete</code> <p>Delete route decorator with DELETE <code>method</code></p> <code>get</code> <p>Get route decorator with GET <code>method</code></p> <code>head</code> <p>Head route decorator with HEAD <code>method</code></p> <code>patch</code> <p>Patch route decorator with PATCH <code>method</code></p> <code>post</code> <p>Post route decorator with POST <code>method</code></p> <code>put</code> <p>Put route decorator with PUT <code>method</code></p> <code>use</code> <p>Add one or more global middlewares that run before/after route specific middleware.</p>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.BaseRouter.append_context",
            "title": "append_context",
            "text": "<pre><code>append_context(**additional_context)\n</code></pre> <p>Append key=value data as routing context</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def append_context(self, **additional_context):\n    \"\"\"Append key=value data as routing context\"\"\"\n    self.context.update(**additional_context)\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.BaseRouter.clear_context",
            "title": "clear_context",
            "text": "<pre><code>clear_context()\n</code></pre> <p>Resets routing context</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def clear_context(self):\n    \"\"\"Resets routing context\"\"\"\n    self.context.clear()\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.BaseRouter.delete",
            "title": "delete",
            "text": "<pre><code>delete(\n    rule: str,\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable[..., Any]] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]\n</code></pre> <p>Delete route decorator with DELETE <code>method</code></p> <p>Examples:</p> <p>Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator</p> <pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\ntracer = Tracer()\napp = APIGatewayRestResolver()\n\n@app.delete(\"/delete-call\")\ndef simple_delete():\n    return {\"message\": \"deleted\"}\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def delete(\n    self,\n    rule: str,\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable[..., Any]] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]:\n    \"\"\"Delete route decorator with DELETE `method`\n\n    Examples\n    --------\n    Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator\n\n    ```python\n    from aws_lambda_powertools import Tracer\n    from aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\n    tracer = Tracer()\n    app = APIGatewayRestResolver()\n\n    @app.delete(\"/delete-call\")\n    def simple_delete():\n        return {\"message\": \"deleted\"}\n\n    @tracer.capture_lambda_handler\n    def lambda_handler(event, context):\n        return app.resolve(event, context)\n    ```\n    \"\"\"\n    return self.route(\n        rule,\n        \"DELETE\",\n        cors,\n        compress,\n        cache_control,\n        summary,\n        description,\n        responses,\n        response_description,\n        tags,\n        operation_id,\n        include_in_schema,\n        security,\n        openapi_extensions,\n        deprecated,\n        middlewares,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.BaseRouter.get",
            "title": "get",
            "text": "<pre><code>get(\n    rule: str,\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable[..., Any]] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]\n</code></pre> <p>Get route decorator with GET <code>method</code></p> <p>Examples:</p> <p>Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator</p> <pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\ntracer = Tracer()\napp = APIGatewayRestResolver()\n\n@app.get(\"/get-call\")\ndef simple_get():\n    return {\"message\": \"Foo\"}\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def get(\n    self,\n    rule: str,\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable[..., Any]] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]:\n    \"\"\"Get route decorator with GET `method`\n\n    Examples\n    --------\n    Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator\n\n    ```python\n    from aws_lambda_powertools import Tracer\n    from aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\n    tracer = Tracer()\n    app = APIGatewayRestResolver()\n\n    @app.get(\"/get-call\")\n    def simple_get():\n        return {\"message\": \"Foo\"}\n\n    @tracer.capture_lambda_handler\n    def lambda_handler(event, context):\n        return app.resolve(event, context)\n    ```\n    \"\"\"\n    return self.route(\n        rule,\n        \"GET\",\n        cors,\n        compress,\n        cache_control,\n        summary,\n        description,\n        responses,\n        response_description,\n        tags,\n        operation_id,\n        include_in_schema,\n        security,\n        openapi_extensions,\n        deprecated,\n        middlewares,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.BaseRouter.head",
            "title": "head",
            "text": "<pre><code>head(\n    rule: str,\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]\n</code></pre> <p>Head route decorator with HEAD <code>method</code></p> <p>Examples:</p> <p>Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator</p> <pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response, content_types\n\ntracer = Tracer()\napp = APIGatewayRestResolver()\n\n@app.head(\"/head-call\")\ndef simple_head():\n    return Response(status_code=200,\n                    content_type=content_types.APPLICATION_JSON,\n                    headers={\"Content-Length\": \"123\"})\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def head(\n    self,\n    rule: str,\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]:\n    \"\"\"Head route decorator with HEAD `method`\n\n    Examples\n    --------\n    Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator\n\n    ```python\n    from aws_lambda_powertools import Tracer\n    from aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response, content_types\n\n    tracer = Tracer()\n    app = APIGatewayRestResolver()\n\n    @app.head(\"/head-call\")\n    def simple_head():\n        return Response(status_code=200,\n                        content_type=content_types.APPLICATION_JSON,\n                        headers={\"Content-Length\": \"123\"})\n\n    @tracer.capture_lambda_handler\n    def lambda_handler(event, context):\n        return app.resolve(event, context)\n    ```\n    \"\"\"\n    return self.route(\n        rule,\n        \"HEAD\",\n        cors,\n        compress,\n        cache_control,\n        summary,\n        description,\n        responses,\n        response_description,\n        tags,\n        operation_id,\n        include_in_schema,\n        security,\n        openapi_extensions,\n        deprecated,\n        middlewares,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.BaseRouter.patch",
            "title": "patch",
            "text": "<pre><code>patch(\n    rule: str,\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]\n</code></pre> <p>Patch route decorator with PATCH <code>method</code></p> <p>Examples:</p> <p>Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator</p> <pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\ntracer = Tracer()\napp = APIGatewayRestResolver()\n\n@app.patch(\"/patch-call\")\ndef simple_patch():\n    patch_data: dict = app.current_event.json_body\n    patch_data[\"value\"] = patched\n\n    return {\"message\": patch_data}\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def patch(\n    self,\n    rule: str,\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]:\n    \"\"\"Patch route decorator with PATCH `method`\n\n    Examples\n    --------\n    Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator\n\n    ```python\n    from aws_lambda_powertools import Tracer\n    from aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\n    tracer = Tracer()\n    app = APIGatewayRestResolver()\n\n    @app.patch(\"/patch-call\")\n    def simple_patch():\n        patch_data: dict = app.current_event.json_body\n        patch_data[\"value\"] = patched\n\n        return {\"message\": patch_data}\n\n    @tracer.capture_lambda_handler\n    def lambda_handler(event, context):\n        return app.resolve(event, context)\n    ```\n    \"\"\"\n    return self.route(\n        rule,\n        \"PATCH\",\n        cors,\n        compress,\n        cache_control,\n        summary,\n        description,\n        responses,\n        response_description,\n        tags,\n        operation_id,\n        include_in_schema,\n        security,\n        openapi_extensions,\n        deprecated,\n        middlewares,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.BaseRouter.post",
            "title": "post",
            "text": "<pre><code>post(\n    rule: str,\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable[..., Any]] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]\n</code></pre> <p>Post route decorator with POST <code>method</code></p> <p>Examples:</p> <p>Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator</p> <pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\ntracer = Tracer()\napp = APIGatewayRestResolver()\n\n@app.post(\"/post-call\")\ndef simple_post():\n    post_data: dict = app.current_event.json_body\n    return {\"message\": post_data[\"value\"]}\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def post(\n    self,\n    rule: str,\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable[..., Any]] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]:\n    \"\"\"Post route decorator with POST `method`\n\n    Examples\n    --------\n    Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator\n\n    ```python\n    from aws_lambda_powertools import Tracer\n    from aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\n    tracer = Tracer()\n    app = APIGatewayRestResolver()\n\n    @app.post(\"/post-call\")\n    def simple_post():\n        post_data: dict = app.current_event.json_body\n        return {\"message\": post_data[\"value\"]}\n\n    @tracer.capture_lambda_handler\n    def lambda_handler(event, context):\n        return app.resolve(event, context)\n    ```\n    \"\"\"\n    return self.route(\n        rule,\n        \"POST\",\n        cors,\n        compress,\n        cache_control,\n        summary,\n        description,\n        responses,\n        response_description,\n        tags,\n        operation_id,\n        include_in_schema,\n        security,\n        openapi_extensions,\n        deprecated,\n        middlewares,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.BaseRouter.put",
            "title": "put",
            "text": "<pre><code>put(\n    rule: str,\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable[..., Any]] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]\n</code></pre> <p>Put route decorator with PUT <code>method</code></p> <p>Examples:</p> <p>Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator</p> <pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\ntracer = Tracer()\napp = APIGatewayRestResolver()\n\n@app.put(\"/put-call\")\ndef simple_put():\n    put_data: dict = app.current_event.json_body\n    return {\"message\": put_data[\"value\"]}\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def put(\n    self,\n    rule: str,\n    cors: bool | None = None,\n    compress: bool = False,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str = _DEFAULT_OPENAPI_RESPONSE_DESCRIPTION,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable[..., Any]] | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]:\n    \"\"\"Put route decorator with PUT `method`\n\n    Examples\n    --------\n    Simple example with a custom lambda handler using the Tracer capture_lambda_handler decorator\n\n    ```python\n    from aws_lambda_powertools import Tracer\n    from aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\n    tracer = Tracer()\n    app = APIGatewayRestResolver()\n\n    @app.put(\"/put-call\")\n    def simple_put():\n        put_data: dict = app.current_event.json_body\n        return {\"message\": put_data[\"value\"]}\n\n    @tracer.capture_lambda_handler\n    def lambda_handler(event, context):\n        return app.resolve(event, context)\n    ```\n    \"\"\"\n    return self.route(\n        rule,\n        \"PUT\",\n        cors,\n        compress,\n        cache_control,\n        summary,\n        description,\n        responses,\n        response_description,\n        tags,\n        operation_id,\n        include_in_schema,\n        security,\n        openapi_extensions,\n        deprecated,\n        middlewares,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.BaseRouter.use",
            "title": "use",
            "text": "<pre><code>use(middlewares: list[Callable[..., Response]]) -&gt; None\n</code></pre> <p>Add one or more global middlewares that run before/after route specific middleware.</p> <p>NOTE: Middlewares are called in insertion order.</p> PARAMETER DESCRIPTION <code>middlewares</code> <p>List of global middlewares to be used</p> <p> TYPE: <code>list[Callable[..., Response]]</code> </p> <p>Examples:</p> <p>Add middlewares to be used for every request processed by the Router.</p> <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\nfrom aws_lambda_powertools.event_handler.middlewares import NextMiddleware\n\nlogger = Logger()\napp = APIGatewayRestResolver()\n\ndef log_request_response(app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:\n    logger.info(\"Incoming request\", path=app.current_event.path, request=app.current_event.raw_event)\n\n    result = next_middleware(app)\n    logger.info(\"Response received\", response=result.__dict__)\n\n    return result\n\napp.use(middlewares=[log_request_response])\n\n\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def use(self, middlewares: list[Callable[..., Response]]) -&gt; None:\n    \"\"\"\n    Add one or more global middlewares that run before/after route specific middleware.\n\n    NOTE: Middlewares are called in insertion order.\n\n    Parameters\n    ----------\n    middlewares: list[Callable[..., Response]]\n        List of global middlewares to be used\n\n    Examples\n    --------\n\n    Add middlewares to be used for every request processed by the Router.\n\n    ```python\n    from aws_lambda_powertools import Logger\n    from aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\n    from aws_lambda_powertools.event_handler.middlewares import NextMiddleware\n\n    logger = Logger()\n    app = APIGatewayRestResolver()\n\n    def log_request_response(app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:\n        logger.info(\"Incoming request\", path=app.current_event.path, request=app.current_event.raw_event)\n\n        result = next_middleware(app)\n        logger.info(\"Response received\", response=result.__dict__)\n\n        return result\n\n    app.use(middlewares=[log_request_response])\n\n\n    def lambda_handler(event, context):\n        return app.resolve(event, context)\n    ```\n    \"\"\"\n    self._router_middlewares = self._router_middlewares + middlewares\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.CORSConfig",
            "title": "CORSConfig",
            "text": "<pre><code>CORSConfig(\n    allow_origin: str = \"*\",\n    extra_origins: list[str] | None = None,\n    allow_headers: list[str] | None = None,\n    expose_headers: list[str] | None = None,\n    max_age: int | None = None,\n    allow_credentials: bool = False,\n)\n</code></pre> <p>CORS Config</p> <p>Examples:</p> <p>Simple CORS example using the default permissive CORS, note that this should only be used during early prototyping.</p> <pre><code>from aws_lambda_powertools.event_handler.api_gateway import (\n    APIGatewayRestResolver, CORSConfig\n)\n\napp = APIGatewayRestResolver(cors=CORSConfig())\n\n@app.get(\"/my/path\")\ndef with_cors():\n    return {\"message\": \"Foo\"}\n</code></pre> <p>Using a custom CORSConfig where <code>with_cors</code> used the custom provided CORSConfig and <code>without_cors</code> do not include any CORS headers.</p> <pre><code>from aws_lambda_powertools.event_handler.api_gateway import (\n    APIGatewayRestResolver, CORSConfig\n)\n\ncors_config = CORSConfig(\n    allow_origin=\"https://wwww.example.com/\",\n    extra_origins=[\"https://dev.example.com/\"],\n    expose_headers=[\"x-exposed-response-header\"],\n    allow_headers=[\"x-custom-request-header\"],\n    max_age=100,\n    allow_credentials=True,\n)\napp = APIGatewayRestResolver(cors=cors_config)\n\n@app.get(\"/my/path\")\ndef with_cors():\n    return {\"message\": \"Foo\"}\n\n@app.get(\"/another-one\", cors=False)\ndef without_cors():\n    return {\"message\": \"Foo\"}\n</code></pre> METHOD DESCRIPTION <code>build_allow_methods</code> <p>Build sorted comma delimited methods for Access-Control-Allow-Methods header</p> <code>to_dict</code> <p>Builds the configured Access-Control http headers</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def __init__(\n    self,\n    allow_origin: str = \"*\",\n    extra_origins: list[str] | None = None,\n    allow_headers: list[str] | None = None,\n    expose_headers: list[str] | None = None,\n    max_age: int | None = None,\n    allow_credentials: bool = False,\n):\n    \"\"\"\n    Parameters\n    ----------\n    allow_origin: str\n        The value of the `Access-Control-Allow-Origin` to send in the response. Defaults to \"*\", but should\n        only be used during development.\n    extra_origins: list[str] | None\n        The list of additional allowed origins.\n    allow_headers: list[str] | None\n        The list of additional allowed headers. This list is added to list of\n        built-in allowed headers: `Authorization`, `Content-Type`, `X-Amz-Date`,\n        `X-Api-Key`, `X-Amz-Security-Token`.\n    expose_headers: list[str] | None\n        A list of values to return for the Access-Control-Expose-Headers\n    max_age: int | None\n        The value for the `Access-Control-Max-Age`\n    allow_credentials: bool\n        A boolean value that sets the value of `Access-Control-Allow-Credentials`\n    \"\"\"\n\n    self._allowed_origins = [allow_origin]\n\n    if extra_origins:\n        self._allowed_origins.extend(extra_origins)\n\n    self.allow_headers = set(self._REQUIRED_HEADERS + (allow_headers or []))\n    self.expose_headers = expose_headers or []\n    self.max_age = max_age\n    self.allow_credentials = allow_credentials\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.CORSConfig.build_allow_methods",
            "title": "build_allow_methods  <code>staticmethod</code>",
            "text": "<pre><code>build_allow_methods(methods: set[str]) -&gt; str\n</code></pre> <p>Build sorted comma delimited methods for Access-Control-Allow-Methods header</p> PARAMETER DESCRIPTION <code>methods</code> <p>Set of HTTP Methods</p> <p> TYPE: <code>set[str]</code> </p> RETURNS DESCRIPTION <code>set[str]</code> <p>Formatted string with all HTTP Methods allowed for CORS e.g., <code>GET, OPTIONS</code></p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>@staticmethod\ndef build_allow_methods(methods: set[str]) -&gt; str:\n    \"\"\"Build sorted comma delimited methods for Access-Control-Allow-Methods header\n\n    Parameters\n    ----------\n    methods : set[str]\n        Set of HTTP Methods\n\n    Returns\n    -------\n    set[str]\n        Formatted string with all HTTP Methods allowed for CORS e.g., `GET, OPTIONS`\n\n    \"\"\"\n    return \",\".join(sorted(methods))\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.CORSConfig.to_dict",
            "title": "to_dict",
            "text": "<pre><code>to_dict(origin: str | None) -&gt; dict[str, str]\n</code></pre> <p>Builds the configured Access-Control http headers</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def to_dict(self, origin: str | None) -&gt; dict[str, str]:\n    \"\"\"Builds the configured Access-Control http headers\"\"\"\n\n    # If there's no Origin, don't add any CORS headers\n    if not origin:\n        return {}\n\n    # If the origin doesn't match any of the allowed origins, and we don't allow all origins (\"*\"),\n    # don't add any CORS headers\n    if origin not in self._allowed_origins and \"*\" not in self._allowed_origins:\n        return {}\n\n    # The origin matched an allowed origin, so return the CORS headers\n    headers = {\n        \"Access-Control-Allow-Origin\": origin,\n        \"Access-Control-Allow-Headers\": CORSConfig.build_allow_methods(self.allow_headers),\n    }\n\n    if self.expose_headers:\n        headers[\"Access-Control-Expose-Headers\"] = \",\".join(self.expose_headers)\n    if self.max_age is not None:\n        headers[\"Access-Control-Max-Age\"] = str(self.max_age)\n    if origin != \"*\" and self.allow_credentials is True:\n        headers[\"Access-Control-Allow-Credentials\"] = \"true\"\n    return headers\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.MiddlewareFrame",
            "title": "MiddlewareFrame",
            "text": "<pre><code>MiddlewareFrame(\n    current_middleware: Callable[..., Any],\n    next_middleware: Callable[..., Any],\n)\n</code></pre> <p>Creates a Middle Stack Wrapper instance to be used as a \"Frame\" in the overall stack of middleware functions.  Each instance contains the current middleware and the next middleware function to be called in the stack.</p> <p>In this way the middleware stack is constructed in a recursive fashion, with each middleware calling the next as a simple function call.  The actual Python call-stack will contain each MiddlewareStackWrapper \"Frame\", meaning any Middleware function can cause the entire Middleware call chain to be exited early (short-circuited) by raising an exception or by simply returning early with a custom Response.  The decision to short-circuit the middleware chain is at the user's discretion but instantly available due to the Wrapped nature of the callable constructs in the Middleware stack and each Middleware function having complete control over whether the \"Next\" handler in the stack is called or not.</p> PARAMETER DESCRIPTION <code>current_middleware</code> <p>The current middleware function to be called as a request is processed.</p> <p> TYPE: <code>Callable</code> </p> <code>next_middleware</code> <p>The next middleware in the middleware stack.</p> <p> TYPE: <code>Callable</code> </p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def __init__(\n    self,\n    current_middleware: Callable[..., Any],\n    next_middleware: Callable[..., Any],\n) -&gt; None:\n    self.current_middleware: Callable[..., Any] = current_middleware\n    self.next_middleware: Callable[..., Any] = next_middleware\n    self._next_middleware_name = next_middleware.__name__\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ProxyEventType",
            "title": "ProxyEventType",
            "text": "<p>               Bases: <code>Enum</code></p> <p>An enumerations of the supported proxy event types.</p>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.Response",
            "title": "Response",
            "text": "<pre><code>Response(\n    status_code: int,\n    content_type: str | None = None,\n    body: ResponseT | None = None,\n    headers: Mapping[str, str | list[str]] | None = None,\n    cookies: list[Cookie] | None = None,\n    compress: bool | None = None,\n)\n</code></pre> <p>               Bases: <code>Generic[ResponseT]</code></p> <p>Response data class that provides greater control over what is returned from the proxy event</p> METHOD DESCRIPTION <code>is_json</code> <p>Returns True if the response is JSON, based on the Content-Type.</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def __init__(\n    self,\n    status_code: int,\n    content_type: str | None = None,\n    body: ResponseT | None = None,\n    headers: Mapping[str, str | list[str]] | None = None,\n    cookies: list[Cookie] | None = None,\n    compress: bool | None = None,\n):\n    \"\"\"\n\n    Parameters\n    ----------\n    status_code: int\n        Http status code, example 200\n    content_type: str\n        Optionally set the Content-Type header, example \"application/json\". Note this will be merged into any\n        provided http headers\n    body: str | bytes | None\n        Optionally set the response body. Note: bytes body will be automatically base64 encoded\n    headers: Mapping[str, str | list[str]]\n        Optionally set specific http headers. Setting \"Content-Type\" here would override the `content_type` value.\n    cookies: list[Cookie]\n        Optionally set cookies.\n    \"\"\"\n    self.status_code = status_code\n    self.body = body\n    self.base64_encoded = False\n    self.headers: dict[str, str | list[str]] = dict(headers) if headers else {}\n    self.cookies = cookies or []\n    self.compress = compress\n    self.content_type = content_type\n    if content_type:\n        self.headers.setdefault(\"Content-Type\", content_type)\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.Response.is_json",
            "title": "is_json",
            "text": "<pre><code>is_json() -&gt; bool\n</code></pre> <p>Returns True if the response is JSON, based on the Content-Type.</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def is_json(self) -&gt; bool:\n    \"\"\"\n    Returns True if the response is JSON, based on the Content-Type.\n    \"\"\"\n    content_type = self.headers.get(\"Content-Type\", \"\")\n    if isinstance(content_type, list):\n        content_type = content_type[0]\n    return content_type.startswith(\"application/json\")\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ResponseBuilder",
            "title": "ResponseBuilder",
            "text": "<pre><code>ResponseBuilder(\n    response: Response,\n    serializer: Callable[[Any], str] = partial(\n        json.dumps, separators=(\",\", \":\"), cls=Encoder\n    ),\n    route: Route | None = None,\n)\n</code></pre> <p>               Bases: <code>Generic[ResponseEventT]</code></p> <p>Internally used Response builder</p> METHOD DESCRIPTION <code>build</code> <p>Build the full response dict to be returned by the lambda</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def __init__(\n    self,\n    response: Response,\n    serializer: Callable[[Any], str] = partial(json.dumps, separators=(\",\", \":\"), cls=Encoder),\n    route: Route | None = None,\n):\n    self.response = response\n    self.serializer = serializer\n    self.route = route\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.ResponseBuilder.build",
            "title": "build",
            "text": "<pre><code>build(\n    event: ResponseEventT, cors: CORSConfig | None = None\n) -&gt; dict[str, Any]\n</code></pre> <p>Build the full response dict to be returned by the lambda</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def build(self, event: ResponseEventT, cors: CORSConfig | None = None) -&gt; dict[str, Any]:\n    \"\"\"Build the full response dict to be returned by the lambda\"\"\"\n\n    # We only apply the serializer when the content type is JSON and the\n    # body is not a str, to avoid double encoding\n    if self.response.is_json() and not isinstance(self.response.body, str):\n        self.response.body = self.serializer(self.response.body)\n\n    self._route(event, cors)\n\n    if isinstance(self.response.body, bytes):\n        logger.debug(\"Encoding bytes response with base64\")\n        self.response.base64_encoded = True\n        self.response.body = base64.b64encode(self.response.body).decode()\n\n    return {\n        \"statusCode\": self.response.status_code,\n        \"body\": self.response.body,\n        \"isBase64Encoded\": self.response.base64_encoded,\n        **event.header_serializer().serialize(headers=self.response.headers, cookies=self.response.cookies),\n    }\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.Route",
            "title": "Route",
            "text": "<pre><code>Route(\n    method: str,\n    path: str,\n    rule: Pattern,\n    func: Callable,\n    cors: bool,\n    compress: bool,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str | None = None,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: (\n        list[Callable[..., Response]] | None\n    ) = None,\n)\n</code></pre> <p>Internally used Route Configuration</p> PARAMETER DESCRIPTION <code>method</code> <p>The HTTP method, example \"GET\"</p> <p> TYPE: <code>str</code> </p> <code>path</code> <p>The path of the route</p> <p> TYPE: <code>str</code> </p> <code>rule</code> <p>The route rule, example \"/my/path\"</p> <p> TYPE: <code>Pattern</code> </p> <code>func</code> <p>The route handler function</p> <p> TYPE: <code>Callable</code> </p> <code>cors</code> <p>Whether or not to enable CORS for this route</p> <p> TYPE: <code>bool</code> </p> <code>compress</code> <p>Whether or not to enable gzip compression for this route</p> <p> TYPE: <code>bool</code> </p> <code>cache_control</code> <p>The cache control header value, example \"max-age=3600\"</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>summary</code> <p>The OpenAPI summary for this route</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>description</code> <p>The OpenAPI description for this route</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>responses</code> <p>The OpenAPI responses for this route</p> <p> TYPE: <code>dict[int, OpenAPIResponse] | None</code> DEFAULT: <code>None</code> </p> <code>response_description</code> <p>The OpenAPI response description for this route</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>tags</code> <p>The list of OpenAPI tags to be used for this route</p> <p> TYPE: <code>list[str] | None</code> DEFAULT: <code>None</code> </p> <code>operation_id</code> <p>The OpenAPI operationId for this route</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>include_in_schema</code> <p>Whether or not to include this route in the OpenAPI schema</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>security</code> <p>The OpenAPI security for this route</p> <p> TYPE: <code>list[dict[str, list[str]]] | None</code> DEFAULT: <code>None</code> </p> <code>openapi_extensions</code> <p>Additional OpenAPI extensions as a dictionary.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>deprecated</code> <p>Whether or not to mark this route as deprecated in the OpenAPI schema</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>middlewares</code> <p>The list of route middlewares to be called in order.</p> <p> TYPE: <code>list[Callable[..., Response]] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def __init__(\n    self,\n    method: str,\n    path: str,\n    rule: Pattern,\n    func: Callable,\n    cors: bool,\n    compress: bool,\n    cache_control: str | None = None,\n    summary: str | None = None,\n    description: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n    response_description: str | None = None,\n    tags: list[str] | None = None,\n    operation_id: str | None = None,\n    include_in_schema: bool = True,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n    deprecated: bool = False,\n    middlewares: list[Callable[..., Response]] | None = None,\n):\n    \"\"\"\n    Internally used Route Configuration\n\n    Parameters\n    ----------\n    method: str\n        The HTTP method, example \"GET\"\n    path: str\n        The path of the route\n    rule: Pattern\n        The route rule, example \"/my/path\"\n    func: Callable\n        The route handler function\n    cors: bool\n        Whether or not to enable CORS for this route\n    compress: bool\n        Whether or not to enable gzip compression for this route\n    cache_control: str | None\n        The cache control header value, example \"max-age=3600\"\n    summary: str | None\n        The OpenAPI summary for this route\n    description: str | None\n        The OpenAPI description for this route\n    responses: dict[int, OpenAPIResponse] | None\n        The OpenAPI responses for this route\n    response_description: str | None\n        The OpenAPI response description for this route\n    tags: list[str] | None\n        The list of OpenAPI tags to be used for this route\n    operation_id: str | None\n        The OpenAPI operationId for this route\n    include_in_schema: bool\n        Whether or not to include this route in the OpenAPI schema\n    security: list[dict[str, list[str]]], optional\n        The OpenAPI security for this route\n    openapi_extensions: dict[str, Any], optional\n        Additional OpenAPI extensions as a dictionary.\n    deprecated: bool\n        Whether or not to mark this route as deprecated in the OpenAPI schema\n    middlewares: list[Callable[..., Response]] | None\n        The list of route middlewares to be called in order.\n    \"\"\"\n    self.method = method.upper()\n    self.path = \"/\" if path.strip() == \"\" else path\n\n    # OpenAPI spec only understands paths with { }. So we'll have to convert Powertools' &lt; &gt;.\n    # https://swagger.io/specification/#path-templating\n    self.openapi_path = re.sub(r\"&lt;(.*?)&gt;\", lambda m: f\"{{{''.join(m.group(1))}}}\", self.path)\n\n    self.rule = rule\n    self.func = func\n    self._middleware_stack = func\n    self.cors = cors\n    self.compress = compress\n    self.cache_control = cache_control\n    self.summary = summary\n    self.description = description\n    self.responses = responses\n    self.response_description = response_description\n    self.tags = tags or []\n    self.include_in_schema = include_in_schema\n    self.security = security\n    self.openapi_extensions = openapi_extensions\n    self.middlewares = middlewares or []\n    self.operation_id = operation_id or self._generate_operation_id()\n    self.deprecated = deprecated\n\n    # _middleware_stack_built is used to ensure the middleware stack is only built once.\n    self._middleware_stack_built = False\n\n    # _dependant is used to cache the dependant model for the handler function\n    self._dependant: Dependant | None = None\n\n    # _body_field is used to cache the dependant model for the body field\n    self._body_field: ModelField | None = None\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/api_gateway/#aws_lambda_powertools.event_handler.api_gateway.Router",
            "title": "Router",
            "text": "<pre><code>Router()\n</code></pre> <p>               Bases: <code>BaseRouter</code></p> <p>Router helper class to allow splitting ApiGatewayResolver into multiple files</p> Source code in <code>aws_lambda_powertools/event_handler/api_gateway.py</code> <pre><code>def __init__(self):\n    self._routes: dict[tuple, Callable] = {}\n    self._routes_with_middleware: dict[tuple, list[Callable]] = {}\n    self.api_resolver: BaseRouter | None = None\n    self.context = {}  # early init as customers might add context before event resolution\n    self._exception_handlers: dict[type, Callable] = {}\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/appsync/",
            "title": "AppSync",
            "text": "CLASS DESCRIPTION <code>AppSyncResolver</code> <p>AppSync GraphQL API Resolver</p>"
        },
        {
            "location": "api_doc/event_handler/appsync/#aws_lambda_powertools.event_handler.appsync.AppSyncResolver",
            "title": "AppSyncResolver",
            "text": "<pre><code>AppSyncResolver()\n</code></pre> <p>               Bases: <code>Router</code></p> <p>AppSync GraphQL API Resolver</p> Example <pre><code>from aws_lambda_powertools.event_handler import AppSyncResolver\n\napp = AppSyncResolver()\n\n@app.resolver(type_name=\"Query\", field_name=\"listLocations\")\ndef list_locations(page: int = 0, size: int = 10) -&gt; list:\n    # Your logic to fetch locations with arguments passed in\n    return [{\"id\": 100, \"name\": \"Smooth Grooves\"}]\n\n@app.resolver(type_name=\"Merchant\", field_name=\"extraInfo\")\ndef get_extra_info() -&gt; dict:\n    # Can use \"app.current_event.source\" to filter within the parent context\n    account_type = app.current_event.source[\"accountType\"]\n    method = \"BTC\" if account_type == \"NEW\" else \"USD\"\n    return {\"preferredPaymentMethod\": method}\n\n@app.resolver(field_name=\"commonField\")\ndef common_field() -&gt; str:\n    # Would match all fieldNames matching 'commonField'\n    return str(uuid.uuid4())\n</code></pre> METHOD DESCRIPTION <code>batch_resolver</code> <p>Registers batch resolver function for GraphQL type and field name.</p> <code>exception_handler</code> <p>A decorator function that registers a handler for one or more exception types.</p> <code>include_router</code> <p>Adds all resolvers defined in a router</p> <code>resolve</code> <p>Resolves the response based on the provide event and decorator routes</p> <code>resolver</code> <p>Registers direct resolver function for GraphQL type and field name.</p> Source code in <code>aws_lambda_powertools/event_handler/appsync.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initialize a new instance of the AppSyncResolver.\n    \"\"\"\n    super().__init__()\n    self.context = {}  # early init as customers might add context before event resolution\n    self._exception_handlers: dict[type, Callable] = {}\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/appsync/#aws_lambda_powertools.event_handler.appsync.AppSyncResolver.batch_resolver",
            "title": "batch_resolver",
            "text": "<pre><code>batch_resolver(\n    type_name: str = \"*\",\n    field_name: str | None = None,\n    raise_on_error: bool = False,\n    aggregate: bool = True,\n) -&gt; Callable\n</code></pre> <p>Registers batch resolver function for GraphQL type and field name.</p> <p>By default, we handle errors gracefully by returning <code>None</code>. If you want to short-circuit and fail the entire batch use <code>raise_on_error=True</code>.</p> PARAMETER DESCRIPTION <code>type_name</code> <p>GraphQL type e.g., Query, Mutation, by default \"*\" meaning any</p> <p> TYPE: <code>str</code> DEFAULT: <code>'*'</code> </p> <code>field_name</code> <p>GraphQL field e.g., getTodo, createTodo, by default None</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> <code>raise_on_error</code> <p>Whether to fail entire batch upon error, or handle errors gracefully (None), by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>aggregate</code> <p>A flag indicating whether the batch items should be processed at once or individually. If True (default), the batch resolver will process all items in the batch as a single event. If False, the batch resolver will process each item in the batch individually.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>Registered resolver</p> Source code in <code>aws_lambda_powertools/event_handler/appsync.py</code> <pre><code>def batch_resolver(\n    self,\n    type_name: str = \"*\",\n    field_name: str | None = None,\n    raise_on_error: bool = False,\n    aggregate: bool = True,\n) -&gt; Callable:\n    \"\"\"Registers batch resolver function for GraphQL type and field name.\n\n    By default, we handle errors gracefully by returning `None`. If you want\n    to short-circuit and fail the entire batch use `raise_on_error=True`.\n\n    Parameters\n    ----------\n    type_name : str, optional\n        GraphQL type e.g., Query, Mutation, by default \"*\" meaning any\n    field_name : Optional[str], optional\n        GraphQL field e.g., getTodo, createTodo, by default None\n    raise_on_error : bool, optional\n        Whether to fail entire batch upon error, or handle errors gracefully (None), by default False\n    aggregate: bool\n        A flag indicating whether the batch items should be processed at once or individually.\n        If True (default), the batch resolver will process all items in the batch as a single event.\n        If False, the batch resolver will process each item in the batch individually.\n\n    Returns\n    -------\n    Callable\n        Registered resolver\n    \"\"\"\n    return self._batch_resolver_registry.register(\n        field_name=field_name,\n        type_name=type_name,\n        raise_on_error=raise_on_error,\n        aggregate=aggregate,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/appsync/#aws_lambda_powertools.event_handler.appsync.AppSyncResolver.exception_handler",
            "title": "exception_handler",
            "text": "<pre><code>exception_handler(\n    exc_class: type[Exception] | list[type[Exception]],\n)\n</code></pre> <p>A decorator function that registers a handler for one or more exception types.</p> PARAMETER DESCRIPTION <code>exc_class</code> <p>A single exception type or a list of exception types.</p> <p> TYPE: <code>type[Exception] | list[type[Exception]]</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>A decorator function that registers the exception handler.</p> Source code in <code>aws_lambda_powertools/event_handler/appsync.py</code> <pre><code>def exception_handler(self, exc_class: type[Exception] | list[type[Exception]]):\n    \"\"\"\n    A decorator function that registers a handler for one or more exception types.\n\n    Parameters\n    ----------\n    exc_class (type[Exception] | list[type[Exception]])\n        A single exception type or a list of exception types.\n\n    Returns\n    -------\n    Callable:\n        A decorator function that registers the exception handler.\n    \"\"\"\n\n    def register_exception_handler(func: Callable):\n        if isinstance(exc_class, list):  # pragma: no cover\n            for exp in exc_class:\n                self._exception_handlers[exp] = func\n        else:\n            self._exception_handlers[exc_class] = func\n        return func\n\n    return register_exception_handler\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/appsync/#aws_lambda_powertools.event_handler.appsync.AppSyncResolver.include_router",
            "title": "include_router",
            "text": "<pre><code>include_router(router: Router) -&gt; None\n</code></pre> <p>Adds all resolvers defined in a router</p> PARAMETER DESCRIPTION <code>router</code> <p>A router containing a dict of field resolvers</p> <p> TYPE: <code>Router</code> </p> Source code in <code>aws_lambda_powertools/event_handler/appsync.py</code> <pre><code>def include_router(self, router: Router) -&gt; None:\n    \"\"\"Adds all resolvers defined in a router\n\n    Parameters\n    ----------\n    router : Router\n        A router containing a dict of field resolvers\n    \"\"\"\n\n    # Merge app and router context\n    logger.debug(\"Merging router and app context\")\n    self.context.update(**router.context)\n\n    # use pointer to allow context clearance after event is processed e.g., resolve(evt, ctx)\n    router.context = self.context\n\n    logger.debug(\"Merging router resolver registries\")\n    self._resolver_registry.merge(router._resolver_registry)\n    self._batch_resolver_registry.merge(router._batch_resolver_registry)\n    self._async_batch_resolver_registry.merge(router._async_batch_resolver_registry)\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/appsync/#aws_lambda_powertools.event_handler.appsync.AppSyncResolver.resolve",
            "title": "resolve",
            "text": "<pre><code>resolve(\n    event: dict | list[dict],\n    context: LambdaContext,\n    data_model: type[\n        AppSyncResolverEvent\n    ] = AppSyncResolverEvent,\n) -&gt; Any\n</code></pre> <p>Resolves the response based on the provide event and decorator routes</p> PARAMETER DESCRIPTION <code>event</code> <p>Lambda event either coming from batch processing endpoint or from standard processing endpoint</p> <p> TYPE: <code>dict | list[Dict]</code> </p> <code>context</code> <p>Lambda context</p> <p> TYPE: <code>LambdaContext</code> </p> <code>data_model</code> <p>Your data data_model to decode AppSync event, by default AppSyncResolverEvent</p> <p> TYPE: <code>type[AppSyncResolverEvent]</code> DEFAULT: <code>AppSyncResolverEvent</code> </p> Example <pre><code>from aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n@app.resolver(field_name=\"createSomething\")\ndef create_something(id: str):  # noqa AA03 VNE003\n    return id\n\ndef handler(event, context: LambdaContext):\n    return app.resolve(event, context)\n</code></pre> <p>Bringing custom models</p> <pre><code>from aws_lambda_powertools import Logger, Tracer\n\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\n\ntracer = Tracer(service=\"sample_resolver\")\nlogger = Logger(service=\"sample_resolver\")\napp = AppSyncResolver()\n\n\nclass MyCustomModel(AppSyncResolverEvent):\n    @property\n    def country_viewer(self) -&gt; str:\n        return self.request_headers.get(\"cloudfront-viewer-country\", \"\")\n\n\n@app.resolver(field_name=\"listLocations\")\n@app.resolver(field_name=\"locations\")\ndef get_locations(name: str, description: str = \"\"):\n    if app.current_event.country_viewer == \"US\":\n        ...\n    return name + description\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context, data_model=MyCustomModel)\n</code></pre> RETURNS DESCRIPTION <code>Any</code> <p>Returns the result of the resolver</p> RAISES DESCRIPTION <code>ValueError</code> <p>If we could not find a field resolver</p> Source code in <code>aws_lambda_powertools/event_handler/appsync.py</code> <pre><code>def resolve(\n    self,\n    event: dict | list[dict],\n    context: LambdaContext,\n    data_model: type[AppSyncResolverEvent] = AppSyncResolverEvent,\n) -&gt; Any:\n    \"\"\"Resolves the response based on the provide event and decorator routes\n\n    Parameters\n    ----------\n    event : dict | list[Dict]\n        Lambda event either coming from batch processing endpoint or from standard processing endpoint\n    context : LambdaContext\n        Lambda context\n    data_model:\n        Your data data_model to decode AppSync event, by default AppSyncResolverEvent\n\n    Example\n    -------\n\n    ```python\n    from aws_lambda_powertools.event_handler import AppSyncResolver\n    from aws_lambda_powertools.utilities.typing import LambdaContext\n\n    @app.resolver(field_name=\"createSomething\")\n    def create_something(id: str):  # noqa AA03 VNE003\n        return id\n\n    def handler(event, context: LambdaContext):\n        return app.resolve(event, context)\n    ```\n\n    **Bringing custom models**\n\n    ```python\n    from aws_lambda_powertools import Logger, Tracer\n\n    from aws_lambda_powertools.logging import correlation_paths\n    from aws_lambda_powertools.event_handler import AppSyncResolver\n\n    tracer = Tracer(service=\"sample_resolver\")\n    logger = Logger(service=\"sample_resolver\")\n    app = AppSyncResolver()\n\n\n    class MyCustomModel(AppSyncResolverEvent):\n        @property\n        def country_viewer(self) -&gt; str:\n            return self.request_headers.get(\"cloudfront-viewer-country\", \"\")\n\n\n    @app.resolver(field_name=\"listLocations\")\n    @app.resolver(field_name=\"locations\")\n    def get_locations(name: str, description: str = \"\"):\n        if app.current_event.country_viewer == \"US\":\n            ...\n        return name + description\n\n\n    @logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n    @tracer.capture_lambda_handler\n    def lambda_handler(event, context):\n        return app.resolve(event, context, data_model=MyCustomModel)\n    ```\n\n    Returns\n    -------\n    Any\n        Returns the result of the resolver\n\n    Raises\n    -------\n    ValueError\n        If we could not find a field resolver\n    \"\"\"\n\n    self.lambda_context = context\n    Router.lambda_context = context\n\n    try:\n        if isinstance(event, list):\n            Router.current_batch_event = [data_model(e) for e in event]\n            response = self._call_batch_resolver(event=event, data_model=data_model)\n        else:\n            Router.current_event = data_model(event)\n            response = self._call_single_resolver(event=event, data_model=data_model)\n    except Exception as exp:\n        response_builder = self._lookup_exception_handler(type(exp))\n        if response_builder:\n            return response_builder(exp)\n        raise\n\n    # We don't clear the context for coroutines because we don't have control over the event loop.\n    # If we clean the context immediately, it might not be available when the coroutine is actually executed.\n    # For single async operations, the context should be cleaned up manually after the coroutine completes.\n    # See: https://github.com/aws-powertools/powertools-lambda-python/issues/5290\n    # REVIEW: Review this support in Powertools V4\n    if not asyncio.iscoroutine(response):\n        self.clear_context()\n\n    return response\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/appsync/#aws_lambda_powertools.event_handler.appsync.AppSyncResolver.resolver",
            "title": "resolver",
            "text": "<pre><code>resolver(\n    type_name: str = \"*\", field_name: str | None = None\n) -&gt; Callable\n</code></pre> <p>Registers direct resolver function for GraphQL type and field name.</p> PARAMETER DESCRIPTION <code>type_name</code> <p>GraphQL type e.g., Query, Mutation, by default \"*\" meaning any</p> <p> TYPE: <code>str</code> DEFAULT: <code>'*'</code> </p> <code>field_name</code> <p>GraphQL field e.g., getTodo, createTodo, by default None</p> <p> TYPE: <code>Optional[str]</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>Registered resolver</p> Example <pre><code>from aws_lambda_powertools.event_handler import AppSyncResolver\n\nfrom typing import TypedDict\n\napp = AppSyncResolver()\n\nclass Todo(TypedDict, total=False):\n    id: str\n    userId: str\n    title: str\n    completed: bool\n\n# resolve any GraphQL `getTodo` queries\n# arguments are injected as function arguments as-is\n@app.resolver(type_name=\"Query\", field_name=\"getTodo\")\ndef get_todo(id: str = \"\", status: str = \"open\") -&gt; Todo:\n    todos: Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{id}\")\n    todos.raise_for_status()\n\n    return todos.json()\n\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> Source code in <code>aws_lambda_powertools/event_handler/appsync.py</code> <pre><code>def resolver(self, type_name: str = \"*\", field_name: str | None = None) -&gt; Callable:\n    \"\"\"Registers direct resolver function for GraphQL type and field name.\n\n    Parameters\n    ----------\n    type_name : str, optional\n        GraphQL type e.g., Query, Mutation, by default \"*\" meaning any\n    field_name : Optional[str], optional\n        GraphQL field e.g., getTodo, createTodo, by default None\n\n    Returns\n    -------\n    Callable\n        Registered resolver\n\n    Example\n    -------\n\n    ```python\n    from aws_lambda_powertools.event_handler import AppSyncResolver\n\n    from typing import TypedDict\n\n    app = AppSyncResolver()\n\n    class Todo(TypedDict, total=False):\n        id: str\n        userId: str\n        title: str\n        completed: bool\n\n    # resolve any GraphQL `getTodo` queries\n    # arguments are injected as function arguments as-is\n    @app.resolver(type_name=\"Query\", field_name=\"getTodo\")\n    def get_todo(id: str = \"\", status: str = \"open\") -&gt; Todo:\n        todos: Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{id}\")\n        todos.raise_for_status()\n\n        return todos.json()\n\n    def lambda_handler(event, context):\n        return app.resolve(event, context)\n    ```\n    \"\"\"\n    return self._resolver_registry.register(field_name=field_name, type_name=type_name)\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/middleware/",
            "title": "Middleware",
            "text": "MODULE DESCRIPTION <code>base</code> <code>openapi_validation</code> <code>schema_validation</code> CLASS DESCRIPTION <code>BaseMiddlewareHandler</code> <p>Base implementation for Middlewares to run code before and after in a chain.</p> <code>NextMiddleware</code>"
        },
        {
            "location": "api_doc/event_handler/middleware/#aws_lambda_powertools.event_handler.middlewares.BaseMiddlewareHandler",
            "title": "BaseMiddlewareHandler",
            "text": "<p>               Bases: <code>Generic[EventHandlerInstance]</code>, <code>ABC</code></p> <p>Base implementation for Middlewares to run code before and after in a chain.</p> <p>This is the middleware handler function where middleware logic is implemented. The next middleware handler is represented by <code>next_middleware</code>, returning a Response object.</p> Example <p>Correlation ID Middleware</p> <pre><code>import requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\nfrom aws_lambda_powertools.event_handler.middlewares import BaseMiddlewareHandler, NextMiddleware\n\napp = APIGatewayRestResolver()\nlogger = Logger()\n\n\nclass CorrelationIdMiddleware(BaseMiddlewareHandler):\n    def __init__(self, header: str):\n        super().__init__()\n        self.header = header\n\n    def handler(self, app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:\n        # BEFORE logic\n        request_id = app.current_event.request_context.request_id\n        correlation_id = app.current_event.headers.get(self.header, request_id)\n\n        # Call next middleware or route handler ('/todos')\n        response = next_middleware(app)\n\n        # AFTER logic\n        response.headers[self.header] = correlation_id\n\n        return response\n\n\n@app.get(\"/todos\", middlewares=[CorrelationIdMiddleware(header=\"x-correlation-id\")])\ndef get_todos():\n    todos: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> METHOD DESCRIPTION <code>handler</code> <p>The Middleware Handler</p>"
        },
        {
            "location": "api_doc/event_handler/middleware/#aws_lambda_powertools.event_handler.middlewares.BaseMiddlewareHandler.handler",
            "title": "handler  <code>abstractmethod</code>",
            "text": "<pre><code>handler(\n    app: EventHandlerInstance,\n    next_middleware: NextMiddleware,\n) -&gt; Response\n</code></pre> <p>The Middleware Handler</p> PARAMETER DESCRIPTION <code>app</code> <p>An instance of an Event Handler that implements ApiGatewayResolver</p> <p> TYPE: <code>EventHandlerInstance</code> </p> <code>next_middleware</code> <p>The next middleware handler in the chain</p> <p> TYPE: <code>NextMiddleware</code> </p> RETURNS DESCRIPTION <code>Response</code> <p>The response from the next middleware handler in the chain</p> Source code in <code>aws_lambda_powertools/event_handler/middlewares/base.py</code> <pre><code>@abstractmethod\ndef handler(self, app: EventHandlerInstance, next_middleware: NextMiddleware) -&gt; Response:\n    \"\"\"\n    The Middleware Handler\n\n    Parameters\n    ----------\n    app: EventHandlerInstance\n        An instance of an Event Handler that implements ApiGatewayResolver\n    next_middleware: NextMiddleware\n        The next middleware handler in the chain\n\n    Returns\n    -------\n    Response\n        The response from the next middleware handler in the chain\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/middleware/#aws_lambda_powertools.event_handler.middlewares.NextMiddleware",
            "title": "NextMiddleware",
            "text": "<p>               Bases: <code>Protocol</code></p>"
        },
        {
            "location": "api_doc/event_handler/middleware/#aws_lambda_powertools.event_handler.middlewares.base",
            "title": "base",
            "text": "CLASS DESCRIPTION <code>BaseMiddlewareHandler</code> <p>Base implementation for Middlewares to run code before and after in a chain.</p> <code>NextMiddleware</code>"
        },
        {
            "location": "api_doc/event_handler/middleware/#aws_lambda_powertools.event_handler.middlewares.base.BaseMiddlewareHandler",
            "title": "BaseMiddlewareHandler",
            "text": "<p>               Bases: <code>Generic[EventHandlerInstance]</code>, <code>ABC</code></p> <p>Base implementation for Middlewares to run code before and after in a chain.</p> <p>This is the middleware handler function where middleware logic is implemented. The next middleware handler is represented by <code>next_middleware</code>, returning a Response object.</p> Example <p>Correlation ID Middleware</p> <pre><code>import requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\nfrom aws_lambda_powertools.event_handler.middlewares import BaseMiddlewareHandler, NextMiddleware\n\napp = APIGatewayRestResolver()\nlogger = Logger()\n\n\nclass CorrelationIdMiddleware(BaseMiddlewareHandler):\n    def __init__(self, header: str):\n        super().__init__()\n        self.header = header\n\n    def handler(self, app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:\n        # BEFORE logic\n        request_id = app.current_event.request_context.request_id\n        correlation_id = app.current_event.headers.get(self.header, request_id)\n\n        # Call next middleware or route handler ('/todos')\n        response = next_middleware(app)\n\n        # AFTER logic\n        response.headers[self.header] = correlation_id\n\n        return response\n\n\n@app.get(\"/todos\", middlewares=[CorrelationIdMiddleware(header=\"x-correlation-id\")])\ndef get_todos():\n    todos: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> METHOD DESCRIPTION <code>handler</code> <p>The Middleware Handler</p>"
        },
        {
            "location": "api_doc/event_handler/middleware/#aws_lambda_powertools.event_handler.middlewares.base.BaseMiddlewareHandler.handler",
            "title": "handler  <code>abstractmethod</code>",
            "text": "<pre><code>handler(\n    app: EventHandlerInstance,\n    next_middleware: NextMiddleware,\n) -&gt; Response\n</code></pre> <p>The Middleware Handler</p> PARAMETER DESCRIPTION <code>app</code> <p>An instance of an Event Handler that implements ApiGatewayResolver</p> <p> TYPE: <code>EventHandlerInstance</code> </p> <code>next_middleware</code> <p>The next middleware handler in the chain</p> <p> TYPE: <code>NextMiddleware</code> </p> RETURNS DESCRIPTION <code>Response</code> <p>The response from the next middleware handler in the chain</p> Source code in <code>aws_lambda_powertools/event_handler/middlewares/base.py</code> <pre><code>@abstractmethod\ndef handler(self, app: EventHandlerInstance, next_middleware: NextMiddleware) -&gt; Response:\n    \"\"\"\n    The Middleware Handler\n\n    Parameters\n    ----------\n    app: EventHandlerInstance\n        An instance of an Event Handler that implements ApiGatewayResolver\n    next_middleware: NextMiddleware\n        The next middleware handler in the chain\n\n    Returns\n    -------\n    Response\n        The response from the next middleware handler in the chain\n\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/middleware/#aws_lambda_powertools.event_handler.middlewares.base.NextMiddleware",
            "title": "NextMiddleware",
            "text": "<p>               Bases: <code>Protocol</code></p>"
        },
        {
            "location": "api_doc/event_handler/middleware/#aws_lambda_powertools.event_handler.middlewares.openapi_validation",
            "title": "openapi_validation",
            "text": "CLASS DESCRIPTION <code>OpenAPIValidationMiddleware</code> <p>OpenAPIValidationMiddleware is a middleware that validates the request against the OpenAPI schema defined by the</p>"
        },
        {
            "location": "api_doc/event_handler/middleware/#aws_lambda_powertools.event_handler.middlewares.openapi_validation.OpenAPIValidationMiddleware",
            "title": "OpenAPIValidationMiddleware",
            "text": "<pre><code>OpenAPIValidationMiddleware(\n    validation_serializer: (\n        Callable[[Any], str] | None\n    ) = None,\n    has_response_validation_error: bool = False,\n)\n</code></pre> <p>               Bases: <code>BaseMiddlewareHandler</code></p> <p>OpenAPIValidationMiddleware is a middleware that validates the request against the OpenAPI schema defined by the Lambda handler. It also validates the response against the OpenAPI schema defined by the Lambda handler. It should not be used directly, but rather through the <code>enable_validation</code> parameter of the <code>ApiGatewayResolver</code>.</p> Example <pre><code>from pydantic import BaseModel\n\nfrom aws_lambda_powertools.event_handler.api_gateway import (\n    APIGatewayRestResolver,\n)\n\nclass Todo(BaseModel):\n  name: str\n\napp = APIGatewayRestResolver(enable_validation=True)\n\n@app.get(\"/todos\")\ndef get_todos(): list[Todo]:\n  return [Todo(name=\"hello world\")]\n</code></pre> PARAMETER DESCRIPTION <code>validation_serializer</code> <p>Optional serializer to use when serializing the response for validation. Use it when you have a custom type that cannot be serialized by the default jsonable_encoder.</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>has_response_validation_error</code> <p>Optional flag used to distinguish between payload and validation errors. By setting this flag to True, ResponseValidationError will be raised if response could not be validated.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>aws_lambda_powertools/event_handler/middlewares/openapi_validation.py</code> <pre><code>def __init__(\n    self,\n    validation_serializer: Callable[[Any], str] | None = None,\n    has_response_validation_error: bool = False,\n):\n    \"\"\"\n    Initialize the OpenAPIValidationMiddleware.\n\n    Parameters\n    ----------\n    validation_serializer : Callable, optional\n        Optional serializer to use when serializing the response for validation.\n        Use it when you have a custom type that cannot be serialized by the default jsonable_encoder.\n\n    has_response_validation_error: bool, optional\n        Optional flag used to distinguish between payload and validation errors.\n        By setting this flag to True, ResponseValidationError will be raised if response could not be validated.\n    \"\"\"\n    self._validation_serializer = validation_serializer\n    self._has_response_validation_error = has_response_validation_error\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/middleware/#aws_lambda_powertools.event_handler.middlewares.schema_validation",
            "title": "schema_validation",
            "text": "CLASS DESCRIPTION <code>SchemaValidationMiddleware</code> <p>Middleware to validate API request and response against JSON Schema using the Validation utility.</p>"
        },
        {
            "location": "api_doc/event_handler/middleware/#aws_lambda_powertools.event_handler.middlewares.schema_validation.SchemaValidationMiddleware",
            "title": "SchemaValidationMiddleware",
            "text": "<pre><code>SchemaValidationMiddleware(\n    inbound_schema: dict,\n    inbound_formats: dict | None = None,\n    outbound_schema: dict | None = None,\n    outbound_formats: dict | None = None,\n)\n</code></pre> <p>               Bases: <code>BaseMiddlewareHandler</code></p> <p>Middleware to validate API request and response against JSON Schema using the Validation utility.</p> Example <p>Validating incoming event</p> <pre><code>import requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\nfrom aws_lambda_powertools.event_handler.middlewares import BaseMiddlewareHandler, NextMiddleware\nfrom aws_lambda_powertools.event_handler.middlewares.schema_validation import SchemaValidationMiddleware\n\napp = APIGatewayRestResolver()\nlogger = Logger()\njson_schema_validation = SchemaValidationMiddleware(inbound_schema=INCOMING_JSON_SCHEMA)\n\n\n@app.get(\"/todos\", middlewares=[json_schema_validation])\ndef get_todos():\n    todos: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> PARAMETER DESCRIPTION <code>inbound_schema</code> <p>JSON Schema to validate incoming event</p> <p> TYPE: <code>dict</code> </p> <code>inbound_formats</code> <p>Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool, by default None JSON Schema to validate outbound event, by default None</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>outbound_formats</code> <p>Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool, by default None</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> METHOD DESCRIPTION <code>handler</code> <p>Validates incoming JSON payload (body) against JSON Schema provided.</p> Source code in <code>aws_lambda_powertools/event_handler/middlewares/schema_validation.py</code> <pre><code>def __init__(\n    self,\n    inbound_schema: dict,\n    inbound_formats: dict | None = None,\n    outbound_schema: dict | None = None,\n    outbound_formats: dict | None = None,\n):\n    \"\"\"See [Validation utility](https://docs.powertools.aws.dev/lambda/python/latest/utilities/validation/) docs for examples on all parameters.\n\n    Parameters\n    ----------\n    inbound_schema : dict\n        JSON Schema to validate incoming event\n    inbound_formats : dict | None, optional\n        Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool, by default None\n        JSON Schema to validate outbound event, by default None\n    outbound_formats : dict | None, optional\n        Custom formats containing a key (e.g. int64) and a value expressed as regex or callback returning bool, by default None\n    \"\"\"  # noqa: E501\n    super().__init__()\n    self.inbound_schema = inbound_schema\n    self.inbound_formats = inbound_formats\n    self.outbound_schema = outbound_schema\n    self.outbound_formats = outbound_formats\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/middleware/#aws_lambda_powertools.event_handler.middlewares.schema_validation.SchemaValidationMiddleware.handler",
            "title": "handler",
            "text": "<pre><code>handler(\n    app: EventHandlerInstance,\n    next_middleware: NextMiddleware,\n) -&gt; Response\n</code></pre> <p>Validates incoming JSON payload (body) against JSON Schema provided.</p> PARAMETER DESCRIPTION <code>app</code> <p>An instance of an Event Handler</p> <p> TYPE: <code>EventHandlerInstance</code> </p> <code>next_middleware</code> <p>Callable to get response from the next middleware or route handler in the chain</p> <p> TYPE: <code>NextMiddleware</code> </p> RETURNS DESCRIPTION <code>Response</code> <p>It can return three types of response objects</p> <ul> <li>Original response: Propagates HTTP response returned from the next middleware if validation succeeds</li> <li>HTTP 400: Payload or response failed JSON Schema validation</li> <li>HTTP 500: JSON Schema provided has incorrect format</li> </ul> Source code in <code>aws_lambda_powertools/event_handler/middlewares/schema_validation.py</code> <pre><code>def handler(self, app: EventHandlerInstance, next_middleware: NextMiddleware) -&gt; Response:\n    \"\"\"Validates incoming JSON payload (body) against JSON Schema provided.\n\n    Parameters\n    ----------\n    app : EventHandlerInstance\n        An instance of an Event Handler\n    next_middleware : NextMiddleware\n        Callable to get response from the next middleware or route handler in the chain\n\n    Returns\n    -------\n    Response\n        It can return three types of response objects\n\n        - Original response: Propagates HTTP response returned from the next middleware if validation succeeds\n        - HTTP 400: Payload or response failed JSON Schema validation\n        - HTTP 500: JSON Schema provided has incorrect format\n    \"\"\"\n    try:\n        validate(event=app.current_event.json_body, schema=self.inbound_schema, formats=self.inbound_formats)\n    except SchemaValidationError as error:\n        return self.bad_request(error)\n    except InvalidSchemaFormatError as error:\n        return self.bad_config(error)\n\n    result = next_middleware(app)\n\n    if self.outbound_formats is not None:\n        try:\n            validate(event=result.body, schema=self.inbound_schema, formats=self.inbound_formats)\n        except SchemaValidationError as error:\n            return self.bad_response(error)\n        except InvalidSchemaFormatError as error:\n            return self.bad_config(error)\n\n    return result\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/",
            "title": "OpenAPI",
            "text": "MODULE DESCRIPTION <code>config</code> <code>dependant</code> <code>encoders</code> <code>exceptions</code> <code>models</code> <code>params</code> <code>swagger_ui</code>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.config",
            "title": "config",
            "text": "CLASS DESCRIPTION <code>OpenAPIConfig</code> <p>Configuration class for OpenAPI specification.</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.config.OpenAPIConfig",
            "title": "OpenAPIConfig  <code>dataclass</code>",
            "text": "<pre><code>OpenAPIConfig(\n    title: str = DEFAULT_OPENAPI_TITLE,\n    version: str = DEFAULT_API_VERSION,\n    openapi_version: str = DEFAULT_OPENAPI_VERSION,\n    summary: str | None = None,\n    description: str | None = None,\n    tags: list[Tag | str] | None = None,\n    servers: list[Server] | None = None,\n    terms_of_service: str | None = None,\n    contact: Contact | None = None,\n    license_info: License | None = None,\n    security_schemes: (\n        dict[str, SecurityScheme] | None\n    ) = None,\n    security: list[dict[str, list[str]]] | None = None,\n    openapi_extensions: dict[str, Any] | None = None,\n)\n</code></pre> <p>Configuration class for OpenAPI specification.</p> <p>This class holds all the necessary configuration parameters to generate an OpenAPI specification.</p> PARAMETER DESCRIPTION <code>title</code> <p>The title of the application.</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_OPENAPI_TITLE</code> </p> <code>version</code> <p>The version of the OpenAPI document (which is distinct from the OpenAPI Specification version or the API</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_API_VERSION</code> </p> <code>openapi_version</code> <p>The version of the OpenAPI Specification (which the document uses).</p> <p> TYPE: <code>str</code> DEFAULT: <code>DEFAULT_OPENAPI_VERSION</code> </p> <code>summary</code> <p>A short summary of what the application does.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>description</code> <p>A verbose explanation of the application behavior.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>tags</code> <p>A list of tags used by the specification with additional metadata.</p> <p> TYPE: <code>list[Tag | str] | None</code> DEFAULT: <code>None</code> </p> <code>servers</code> <p>An array of Server Objects, which provide connectivity information to a target server.</p> <p> TYPE: <code>list[Server] | None</code> DEFAULT: <code>None</code> </p> <code>terms_of_service</code> <p>A URL to the Terms of Service for the API. MUST be in the format of a URL.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>contact</code> <p>The contact information for the exposed API.</p> <p> TYPE: <code>Contact | None</code> DEFAULT: <code>None</code> </p> <code>license_info</code> <p>The license information for the exposed API.</p> <p> TYPE: <code>License | None</code> DEFAULT: <code>None</code> </p> <code>security_schemes</code> <p>A declaration of the security schemes available to be used in the specification.</p> <p> TYPE: <code>dict[str, SecurityScheme] | None</code> DEFAULT: <code>None</code> </p> <code>security</code> <p>A declaration of which security mechanisms are applied globally across the API.</p> <p> TYPE: <code>list[dict[str, list[str]]] | None</code> DEFAULT: <code>None</code> </p> <code>openapi_extensions</code> <p>Additional OpenAPI extensions as a dictionary.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Example <p>config = OpenAPIConfig( ...     title=\"My API\", ...     version=\"1.0.0\", ...     description=\"This is my API description\", ...     contact=Contact(name=\"API Support\", email=\"support@example.com\"), ...     servers=[Server(url=\"https://api.example.com/v1\")] ... )</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.dependant",
            "title": "dependant",
            "text": "FUNCTION DESCRIPTION <code>add_param_to_fields</code> <p>Adds a parameter to the list of parameters in the dependant model.</p> <code>get_body_field</code> <p>Get the Body field for a given Dependant object.</p> <code>get_body_field_info</code> <p>Get the Body field info and kwargs for a given body model.</p> <code>get_dependant</code> <p>Returns a dependant model for a handler function. A dependant model is a model that contains</p> <code>get_flat_params</code> <p>Get a list of all the parameters from a Dependant object.</p> <code>get_path_param_names</code> <p>Returns the path parameter names from a path template. Those are the strings between { and }.</p> <code>get_typed_annotation</code> <p>Evaluates a type annotation, which can be a string or a ForwardRef.</p> <code>get_typed_signature</code> <p>Returns a typed signature for a callable, resolving forward references.</p> <code>is_body_param</code> <p>Returns whether a parameter is a request body parameter, by checking if it is a scalar field or a body field.</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.dependant.add_param_to_fields",
            "title": "add_param_to_fields",
            "text": "<pre><code>add_param_to_fields(\n    *, field: ModelField, dependant: Dependant\n) -&gt; None\n</code></pre> <p>Adds a parameter to the list of parameters in the dependant model.</p> PARAMETER DESCRIPTION <code>field</code> <p>The field to add</p> <p> TYPE: <code>ModelField</code> </p> <code>dependant</code> <p>The dependant model to add the field to</p> <p> TYPE: <code>Dependant</code> </p> Source code in <code>aws_lambda_powertools/event_handler/openapi/dependant.py</code> <pre><code>def add_param_to_fields(\n    *,\n    field: ModelField,\n    dependant: Dependant,\n) -&gt; None:\n    \"\"\"\n    Adds a parameter to the list of parameters in the dependant model.\n\n    Parameters\n    ----------\n    field: ModelField\n        The field to add\n    dependant: Dependant\n        The dependant model to add the field to\n\n    \"\"\"\n    field_info = cast(Param, field.field_info)\n\n    # Dictionary to map ParamTypes to their corresponding lists in dependant\n    param_type_map = {\n        ParamTypes.path: dependant.path_params,\n        ParamTypes.query: dependant.query_params,\n        ParamTypes.header: dependant.header_params,\n        ParamTypes.cookie: dependant.cookie_params,\n    }\n\n    # Check if field_info.in_ is a valid key in param_type_map and append the field to the corresponding list\n    # or raise an exception if it's not a valid key.\n    if field_info.in_ in param_type_map:\n        param_type_map[field_info.in_].append(field)\n    else:\n        raise AssertionError(f\"Unsupported param type: {field_info.in_}\")\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.dependant.get_body_field",
            "title": "get_body_field",
            "text": "<pre><code>get_body_field(\n    *, dependant: Dependant, name: str\n) -&gt; ModelField | None\n</code></pre> <p>Get the Body field for a given Dependant object.</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/dependant.py</code> <pre><code>def get_body_field(*, dependant: Dependant, name: str) -&gt; ModelField | None:\n    \"\"\"\n    Get the Body field for a given Dependant object.\n    \"\"\"\n\n    flat_dependant = get_flat_dependant(dependant)\n    if not flat_dependant.body_params:\n        return None\n\n    first_param = flat_dependant.body_params[0]\n    field_info = first_param.field_info\n\n    # Handle the case where there is only one body parameter and it is embedded\n    embed = getattr(field_info, \"embed\", None)\n    body_param_names_set = {param.name for param in flat_dependant.body_params}\n    if len(body_param_names_set) == 1 and not embed:\n        return first_param\n\n    # If one field requires to embed, all have to be embedded\n    for param in flat_dependant.body_params:\n        setattr(param.field_info, \"embed\", True)  # noqa: B010\n\n    # Generate a custom body model for this endpoint\n    model_name = \"Body_\" + name\n    body_model = create_body_model(fields=flat_dependant.body_params, model_name=model_name)\n\n    required = any(True for f in flat_dependant.body_params if f.required)\n\n    body_field_info, body_field_info_kwargs = get_body_field_info(\n        body_model=body_model,\n        flat_dependant=flat_dependant,\n        required=required,\n    )\n\n    final_field = create_response_field(\n        name=\"body\",\n        type_=body_model,\n        required=required,\n        alias=\"body\",\n        field_info=body_field_info(**body_field_info_kwargs),\n    )\n    return final_field\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.dependant.get_body_field_info",
            "title": "get_body_field_info",
            "text": "<pre><code>get_body_field_info(\n    *,\n    body_model: type[BaseModel],\n    flat_dependant: Dependant,\n    required: bool\n) -&gt; tuple[type[Body], dict[str, Any]]\n</code></pre> <p>Get the Body field info and kwargs for a given body model.</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/dependant.py</code> <pre><code>def get_body_field_info(\n    *,\n    body_model: type[BaseModel],\n    flat_dependant: Dependant,\n    required: bool,\n) -&gt; tuple[type[Body], dict[str, Any]]:\n    \"\"\"\n    Get the Body field info and kwargs for a given body model.\n    \"\"\"\n\n    body_field_info_kwargs: dict[str, Any] = {\"annotation\": body_model, \"alias\": \"body\"}\n\n    if not required:\n        body_field_info_kwargs[\"default\"] = None\n\n    if any(isinstance(f.field_info, _File) for f in flat_dependant.body_params):\n        # MAINTENANCE: body_field_info: type[Body] = _File\n        raise NotImplementedError(\"_File fields are not supported in request bodies\")\n    elif any(isinstance(f.field_info, _Form) for f in flat_dependant.body_params):\n        # MAINTENANCE: body_field_info: type[Body] = _Form\n        raise NotImplementedError(\"_Form fields are not supported in request bodies\")\n    else:\n        body_field_info = Body\n\n        body_param_media_types = [\n            f.field_info.media_type for f in flat_dependant.body_params if isinstance(f.field_info, Body)\n        ]\n        if len(set(body_param_media_types)) == 1:\n            body_field_info_kwargs[\"media_type\"] = body_param_media_types[0]\n\n    return body_field_info, body_field_info_kwargs\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.dependant.get_dependant",
            "title": "get_dependant",
            "text": "<pre><code>get_dependant(\n    *,\n    path: str,\n    call: Callable[..., Any],\n    name: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None\n) -&gt; Dependant\n</code></pre> <p>Returns a dependant model for a handler function. A dependant model is a model that contains the parameters and return value of a handler function.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path template</p> <p> TYPE: <code>str</code> </p> <code>call</code> <p>The handler function</p> <p> TYPE: <code>Callable[..., Any]</code> </p> <code>name</code> <p>The name of the handler function</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>responses</code> <p>The list of extra responses for the handler function</p> <p> TYPE: <code>dict[int, OpenAPIResponse] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dependant</code> <p>The dependant model for the handler function</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/dependant.py</code> <pre><code>def get_dependant(\n    *,\n    path: str,\n    call: Callable[..., Any],\n    name: str | None = None,\n    responses: dict[int, OpenAPIResponse] | None = None,\n) -&gt; Dependant:\n    \"\"\"\n    Returns a dependant model for a handler function. A dependant model is a model that contains\n    the parameters and return value of a handler function.\n\n    Parameters\n    ----------\n    path: str\n        The path template\n    call: Callable[..., Any]\n        The handler function\n    name: str, optional\n        The name of the handler function\n    responses: list[dict[int, OpenAPIResponse]], optional\n        The list of extra responses for the handler function\n\n    Returns\n    -------\n    Dependant\n        The dependant model for the handler function\n    \"\"\"\n    path_param_names = get_path_param_names(path)\n    endpoint_signature = get_typed_signature(call)\n    signature_params = endpoint_signature.parameters\n\n    dependant = Dependant(\n        call=call,\n        name=name,\n        path=path,\n    )\n\n    # Add each parameter to the dependant model\n    for param_name, param in signature_params.items():\n        # If the parameter is a path parameter, we need to set the in_ field to \"path\".\n        is_path_param = param_name in path_param_names\n\n        # Analyze the parameter to get the Pydantic field.\n        param_field = analyze_param(\n            param_name=param_name,\n            annotation=param.annotation,\n            value=param.default,\n            is_path_param=is_path_param,\n            is_response_param=False,\n        )\n        if param_field is None:\n            raise AssertionError(f\"Parameter field is None for param: {param_name}\")\n\n        if is_body_param(param_field=param_field, is_path_param=is_path_param):\n            dependant.body_params.append(param_field)\n        else:\n            add_param_to_fields(field=param_field, dependant=dependant)\n\n    _add_return_annotation(dependant, endpoint_signature)\n    _add_extra_responses(dependant, responses)\n\n    return dependant\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.dependant.get_flat_params",
            "title": "get_flat_params",
            "text": "<pre><code>get_flat_params(dependant: Dependant) -&gt; list[ModelField]\n</code></pre> <p>Get a list of all the parameters from a Dependant object.</p> PARAMETER DESCRIPTION <code>dependant</code> <p>The Dependant object containing the parameters.</p> <p> TYPE: <code>Dependant</code> </p> RETURNS DESCRIPTION <code>list[ModelField]</code> <p>A list of ModelField objects containing the flat parameters from the Dependant object.</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/dependant.py</code> <pre><code>def get_flat_params(dependant: Dependant) -&gt; list[ModelField]:\n    \"\"\"\n    Get a list of all the parameters from a Dependant object.\n\n    Parameters\n    ----------\n    dependant : Dependant\n        The Dependant object containing the parameters.\n\n    Returns\n    -------\n    list[ModelField]\n        A list of ModelField objects containing the flat parameters from the Dependant object.\n\n    \"\"\"\n    flat_dependant = get_flat_dependant(dependant)\n    return (\n        flat_dependant.path_params\n        + flat_dependant.query_params\n        + flat_dependant.header_params\n        + flat_dependant.cookie_params\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.dependant.get_path_param_names",
            "title": "get_path_param_names",
            "text": "<pre><code>get_path_param_names(path: str) -&gt; set[str]\n</code></pre> <p>Returns the path parameter names from a path template. Those are the strings between { and }.</p> PARAMETER DESCRIPTION <code>path</code> <p>The path template</p> <p> TYPE: <code>str</code> </p> RETURNS DESCRIPTION <code>set[str]</code> <p>The path parameter names</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/dependant.py</code> <pre><code>def get_path_param_names(path: str) -&gt; set[str]:\n    \"\"\"\n    Returns the path parameter names from a path template. Those are the strings between { and }.\n\n    Parameters\n    ----------\n    path: str\n        The path template\n\n    Returns\n    -------\n    set[str]\n        The path parameter names\n\n    \"\"\"\n    return set(re.findall(\"{(.*?)}\", path))\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.dependant.get_typed_annotation",
            "title": "get_typed_annotation",
            "text": "<pre><code>get_typed_annotation(\n    annotation: Any, globalns: dict[str, Any]\n) -&gt; Any\n</code></pre> <p>Evaluates a type annotation, which can be a string or a ForwardRef.</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/dependant.py</code> <pre><code>def get_typed_annotation(annotation: Any, globalns: dict[str, Any]) -&gt; Any:\n    \"\"\"\n    Evaluates a type annotation, which can be a string or a ForwardRef.\n    \"\"\"\n    if isinstance(annotation, str):\n        annotation = ForwardRef(annotation)\n        annotation = evaluate_forwardref(annotation, globalns, globalns)\n    return annotation\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.dependant.get_typed_signature",
            "title": "get_typed_signature",
            "text": "<pre><code>get_typed_signature(\n    call: Callable[..., Any],\n) -&gt; inspect.Signature\n</code></pre> <p>Returns a typed signature for a callable, resolving forward references.</p> PARAMETER DESCRIPTION <code>call</code> <p>The callable to get the signature for</p> <p> TYPE: <code>Callable[..., Any]</code> </p> RETURNS DESCRIPTION <code>Signature</code> <p>The typed signature</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/dependant.py</code> <pre><code>def get_typed_signature(call: Callable[..., Any]) -&gt; inspect.Signature:\n    \"\"\"\n    Returns a typed signature for a callable, resolving forward references.\n\n    Parameters\n    ----------\n    call: Callable[..., Any]\n        The callable to get the signature for\n\n    Returns\n    -------\n    inspect.Signature\n        The typed signature\n    \"\"\"\n    signature = inspect.signature(call)\n\n    # Gets the global namespace for the call. This is used to resolve forward references.\n    globalns = getattr(call, \"__globals__\", {})\n\n    typed_params = [\n        inspect.Parameter(\n            name=param.name,\n            kind=param.kind,\n            default=param.default,\n            annotation=get_typed_annotation(param.annotation, globalns),\n        )\n        for param in signature.parameters.values()\n    ]\n\n    # If the return annotation is not empty, add it to the signature.\n    if signature.return_annotation is not inspect.Signature.empty:\n        return_param = inspect.Parameter(\n            name=\"Return\",\n            kind=inspect.Parameter.POSITIONAL_OR_KEYWORD,\n            default=None,\n            annotation=get_typed_annotation(signature.return_annotation, globalns),\n        )\n        return inspect.Signature(typed_params, return_annotation=return_param.annotation)\n    else:\n        return inspect.Signature(typed_params)\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.dependant.is_body_param",
            "title": "is_body_param",
            "text": "<pre><code>is_body_param(\n    *, param_field: ModelField, is_path_param: bool\n) -&gt; bool\n</code></pre> <p>Returns whether a parameter is a request body parameter, by checking if it is a scalar field or a body field.</p> PARAMETER DESCRIPTION <code>param_field</code> <p>The parameter field</p> <p> TYPE: <code>ModelField</code> </p> <code>is_path_param</code> <p>Whether the parameter is a path parameter</p> <p> TYPE: <code>bool</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the parameter is a request body parameter</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/dependant.py</code> <pre><code>def is_body_param(*, param_field: ModelField, is_path_param: bool) -&gt; bool:\n    \"\"\"\n    Returns whether a parameter is a request body parameter, by checking if it is a scalar field or a body field.\n\n    Parameters\n    ----------\n    param_field: ModelField\n        The parameter field\n    is_path_param: bool\n        Whether the parameter is a path parameter\n\n    Returns\n    -------\n    bool\n        Whether the parameter is a request body parameter\n    \"\"\"\n    if is_path_param:\n        if not is_scalar_field(field=param_field):\n            raise AssertionError(\"Path params must be of one of the supported types\")\n        return False\n    elif is_scalar_field(field=param_field):\n        return False\n    elif isinstance(param_field.field_info, (Query, Header)) and is_scalar_sequence_field(param_field):\n        return False\n    else:\n        if not isinstance(param_field.field_info, Body):\n            raise AssertionError(f\"Param: {param_field.name} can only be a request body, use Body()\")\n        return True\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.encoders",
            "title": "encoders",
            "text": "FUNCTION DESCRIPTION <code>decimal_encoder</code> <p>Encodes a Decimal as int of there's no exponent, otherwise float</p> <code>iso_format</code> <p>ISO format for date and time</p> <code>jsonable_encoder</code> <p>JSON encodes an arbitrary Python object into JSON serializable data types.</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.encoders.decimal_encoder",
            "title": "decimal_encoder",
            "text": "<pre><code>decimal_encoder(dec_value: Decimal) -&gt; int | float\n</code></pre> <p>Encodes a Decimal as int of there's no exponent, otherwise float</p> <p>This is useful when we use ConstrainedDecimal to represent Numeric(x,0) where an integer (but not int typed) is used. Encoding this as a float results in failed round-tripping between encode and parse.</p> <p>decimal_encoder(Decimal(\"1.0\")) 1.0</p> <p>decimal_encoder(Decimal(\"1\")) 1</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/encoders.py</code> <pre><code>def decimal_encoder(dec_value: Decimal) -&gt; int | float:\n    \"\"\"\n    Encodes a Decimal as int of there's no exponent, otherwise float\n\n    This is useful when we use ConstrainedDecimal to represent Numeric(x,0)\n    where an integer (but not int typed) is used. Encoding this as a float\n    results in failed round-tripping between encode and parse.\n\n    &gt;&gt;&gt; decimal_encoder(Decimal(\"1.0\"))\n    1.0\n\n    &gt;&gt;&gt; decimal_encoder(Decimal(\"1\"))\n    1\n    \"\"\"\n    if dec_value.as_tuple().exponent &gt;= 0:  # type: ignore[operator]\n        return int(dec_value)\n    else:\n        return float(dec_value)\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.encoders.iso_format",
            "title": "iso_format",
            "text": "<pre><code>iso_format(o: date | time) -&gt; str\n</code></pre> <p>ISO format for date and time</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/encoders.py</code> <pre><code>def iso_format(o: datetime.date | datetime.time) -&gt; str:\n    \"\"\"\n    ISO format for date and time\n    \"\"\"\n    return o.isoformat()\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.encoders.jsonable_encoder",
            "title": "jsonable_encoder",
            "text": "<pre><code>jsonable_encoder(\n    obj: Any,\n    include: IncEx | None = None,\n    exclude: IncEx | None = None,\n    by_alias: bool = True,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    custom_serializer: Callable[[Any], str] | None = None,\n) -&gt; Any\n</code></pre> <p>JSON encodes an arbitrary Python object into JSON serializable data types.</p> <p>This is a modified version of fastapi.encoders.jsonable_encoder that supports encoding of pydantic.BaseModel objects.</p> PARAMETER DESCRIPTION <code>obj</code> <p>The object to encode</p> <p> TYPE: <code>Any</code> </p> <code>include</code> <p>A set or dictionary of strings that specifies which properties should be included, by default None, meaning everything is included</p> <p> TYPE: <code>IncEx | None</code> DEFAULT: <code>None</code> </p> <code>exclude</code> <p>A set or dictionary of strings that specifies which properties should be excluded, by default None, meaning nothing is excluded</p> <p> TYPE: <code>IncEx | None</code> DEFAULT: <code>None</code> </p> <code>by_alias</code> <p>Whether field aliases should be respected, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>exclude_unset</code> <p>Whether fields that are not set should be excluded, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>exclude_defaults</code> <p>Whether fields that are equal to their default value (as specified in the model) should be excluded, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>exclude_none</code> <p>Whether fields that are equal to None should be excluded, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>custom_serializer</code> <p>A custom serializer to use for encoding the object, when everything else fails.</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Any</code> <p>The JSON serializable data types</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/encoders.py</code> <pre><code>def jsonable_encoder(  # noqa: PLR0911\n    obj: Any,\n    include: IncEx | None = None,\n    exclude: IncEx | None = None,\n    by_alias: bool = True,\n    exclude_unset: bool = False,\n    exclude_defaults: bool = False,\n    exclude_none: bool = False,\n    custom_serializer: Callable[[Any], str] | None = None,\n) -&gt; Any:\n    \"\"\"\n    JSON encodes an arbitrary Python object into JSON serializable data types.\n\n    This is a modified version of fastapi.encoders.jsonable_encoder that supports\n    encoding of pydantic.BaseModel objects.\n\n    Parameters\n    ----------\n    obj : Any\n        The object to encode\n    include : IncEx | None, optional\n        A set or dictionary of strings that specifies which properties should be included, by default None,\n        meaning everything is included\n    exclude : IncEx | None, optional\n        A set or dictionary of strings that specifies which properties should be excluded, by default None,\n        meaning nothing is excluded\n    by_alias : bool, optional\n        Whether field aliases should be respected, by default True\n    exclude_unset : bool, optional\n        Whether fields that are not set should be excluded, by default False\n    exclude_defaults : bool, optional\n        Whether fields that are equal to their default value (as specified in the model) should be excluded,\n        by default False\n    exclude_none : bool, optional\n        Whether fields that are equal to None should be excluded, by default False\n    custom_serializer : Callable, optional\n        A custom serializer to use for encoding the object, when everything else fails.\n\n    Returns\n    -------\n    Any\n        The JSON serializable data types\n    \"\"\"\n    if include is not None and not isinstance(include, (set, dict)):\n        include = set(include)\n    if exclude is not None and not isinstance(exclude, (set, dict)):\n        exclude = set(exclude)\n\n    try:\n        # Pydantic models\n        if isinstance(obj, BaseModel):\n            return _dump_base_model(\n                obj=obj,\n                include=include,\n                exclude=exclude,\n                by_alias=by_alias,\n                exclude_unset=exclude_unset,\n                exclude_none=exclude_none,\n                exclude_defaults=exclude_defaults,\n            )\n\n        # Dataclasses\n        if dataclasses.is_dataclass(obj):\n            obj_dict = dataclasses.asdict(obj)  # type: ignore[arg-type]\n            return jsonable_encoder(\n                obj_dict,\n                include=include,\n                exclude=exclude,\n                by_alias=by_alias,\n                exclude_unset=exclude_unset,\n                exclude_defaults=exclude_defaults,\n                exclude_none=exclude_none,\n                custom_serializer=custom_serializer,\n            )\n\n        # Enums\n        if isinstance(obj, Enum):\n            return obj.value\n\n        # Paths\n        if isinstance(obj, PurePath):\n            return str(obj)\n\n        # Scalars\n        if isinstance(obj, (str, int, float, type(None))):\n            return obj\n\n        # Dictionaries\n        if isinstance(obj, dict):\n            return _dump_dict(\n                obj=obj,\n                include=include,\n                exclude=exclude,\n                by_alias=by_alias,\n                exclude_unset=exclude_unset,\n                exclude_none=exclude_none,\n                custom_serializer=custom_serializer,\n            )\n\n        # Sequences\n        if isinstance(obj, (list, set, frozenset, GeneratorType, tuple, deque)):\n            return _dump_sequence(\n                obj=obj,\n                include=include,\n                exclude=exclude,\n                by_alias=by_alias,\n                exclude_none=exclude_none,\n                exclude_defaults=exclude_defaults,\n                exclude_unset=exclude_unset,\n                custom_serializer=custom_serializer,\n            )\n\n        # Other types\n        if type(obj) in ENCODERS_BY_TYPE:\n            return ENCODERS_BY_TYPE[type(obj)](obj)\n\n        for encoder, classes_tuple in encoders_by_class_tuples.items():\n            if isinstance(obj, classes_tuple):\n                return encoder(obj)\n\n        # Use custom serializer if present\n        if custom_serializer:\n            return custom_serializer(obj)\n\n        # Default\n        return _dump_other(\n            obj=obj,\n            include=include,\n            exclude=exclude,\n            by_alias=by_alias,\n            exclude_none=exclude_none,\n            exclude_unset=exclude_unset,\n            exclude_defaults=exclude_defaults,\n            custom_serializer=custom_serializer,\n        )\n    except ValueError as exc:\n        raise SerializationError(\n            f\"Unable to serialize the object {obj} as it is not a supported type. Error details: {exc}\",\n            \"See: https://docs.powertools.aws.dev/lambda/python/latest/core/event_handler/api_gateway/#serializing-objects\",\n        ) from exc\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.exceptions",
            "title": "exceptions",
            "text": "CLASS DESCRIPTION <code>RequestValidationError</code> <p>Raised when the request body does not match the OpenAPI schema</p> <code>ResponseValidationError</code> <p>Raised when the response body does not match the OpenAPI schema</p> <code>SchemaValidationError</code> <p>Raised when the OpenAPI schema validation fails</p> <code>SerializationError</code> <p>Base exception for all encoding errors</p> <code>ValidationException</code> <p>Base exception for all validation errors</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.exceptions.RequestValidationError",
            "title": "RequestValidationError",
            "text": "<pre><code>RequestValidationError(\n    errors: Sequence[Any], *, body: Any = None\n)\n</code></pre> <p>               Bases: <code>ValidationException</code></p> <p>Raised when the request body does not match the OpenAPI schema</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/exceptions.py</code> <pre><code>def __init__(self, errors: Sequence[Any], *, body: Any = None) -&gt; None:\n    super().__init__(errors)\n    self.body = body\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.exceptions.ResponseValidationError",
            "title": "ResponseValidationError",
            "text": "<pre><code>ResponseValidationError(\n    errors: Sequence[Any], *, body: Any = None\n)\n</code></pre> <p>               Bases: <code>ValidationException</code></p> <p>Raised when the response body does not match the OpenAPI schema</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/exceptions.py</code> <pre><code>def __init__(self, errors: Sequence[Any], *, body: Any = None) -&gt; None:\n    super().__init__(errors)\n    self.body = body\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.exceptions.SchemaValidationError",
            "title": "SchemaValidationError",
            "text": "<pre><code>SchemaValidationError(errors: Sequence[Any])\n</code></pre> <p>               Bases: <code>ValidationException</code></p> <p>Raised when the OpenAPI schema validation fails</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/exceptions.py</code> <pre><code>def __init__(self, errors: Sequence[Any]) -&gt; None:\n    self._errors = errors\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.exceptions.SerializationError",
            "title": "SerializationError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>Base exception for all encoding errors</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.exceptions.ValidationException",
            "title": "ValidationException",
            "text": "<pre><code>ValidationException(errors: Sequence[Any])\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>Base exception for all validation errors</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/exceptions.py</code> <pre><code>def __init__(self, errors: Sequence[Any]) -&gt; None:\n    self._errors = errors\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.models",
            "title": "models",
            "text": "CLASS DESCRIPTION <code>OpenAPIExtensions</code> <p>This class serves as a Pydantic proxy model to add OpenAPI extensions.</p> ATTRIBUTE DESCRIPTION <code>MODEL_CONFIG_IGNORE</code> <p>The code defines Pydantic models for the various OpenAPI objects like OpenAPI, PathItem, Operation, Parameter etc.</p> <p> </p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.models.MODEL_CONFIG_IGNORE",
            "title": "MODEL_CONFIG_IGNORE  <code>module-attribute</code>",
            "text": "<pre><code>MODEL_CONFIG_IGNORE = ConfigDict(extra='ignore')\n</code></pre> <p>The code defines Pydantic models for the various OpenAPI objects like OpenAPI, PathItem, Operation, Parameter etc. These models can be used to parse OpenAPI JSON/YAML files into Python objects, or generate OpenAPI from Python data.</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.models.OpenAPIExtensions",
            "title": "OpenAPIExtensions",
            "text": "<p>               Bases: <code>BaseModel</code></p> <p>This class serves as a Pydantic proxy model to add OpenAPI extensions.</p> <p>OpenAPI extensions are arbitrary fields, so we remove openapi_extensions when dumping and add only the provided value in the schema.</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.params",
            "title": "params",
            "text": "CLASS DESCRIPTION <code>Body</code> <p>A class used internally to represent a body parameter in a path operation.</p> <code>Dependant</code> <p>A class used internally to represent a dependency between path operation decorators and the path operation function.</p> <code>Header</code> <p>A class used internally to represent a header parameter in a path operation.</p> <code>Param</code> <p>A class used internally to represent a parameter in a path operation.</p> <code>Path</code> <p>A class used internally to represent a path parameter in a path operation.</p> <code>Query</code> <p>A class used internally to represent a query parameter in a path operation.</p> FUNCTION DESCRIPTION <code>analyze_param</code> <p>Analyze a parameter annotation and value to determine the type and default value of the parameter.</p> <code>create_response_field</code> <p>Create a new response field. Raises if type_ is invalid.</p> <code>get_field_info_and_type_annotation</code> <p>Get the FieldInfo and type annotation from an annotation and value.</p> <code>get_field_info_annotated_type</code> <p>Get the FieldInfo and type annotation from an Annotated type.</p> <code>get_flat_dependant</code> <p>Flatten a recursive Dependant model structure.</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.params.Body",
            "title": "Body",
            "text": "<pre><code>Body(\n    default: Any = Undefined,\n    *,\n    default_factory: Callable[[], Any] | None = _Unset,\n    annotation: Any | None = None,\n    embed: bool = False,\n    media_type: str = \"application/json\",\n    alias: str | None = None,\n    alias_priority: int | None = _Unset,\n    validation_alias: str | None = None,\n    serialization_alias: str | None = None,\n    title: str | None = None,\n    description: str | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | None = None,\n    discriminator: str | None = None,\n    strict: bool | None = _Unset,\n    multiple_of: float | None = _Unset,\n    allow_inf_nan: bool | None = _Unset,\n    max_digits: int | None = _Unset,\n    decimal_places: int | None = _Unset,\n    examples: list[Any] | None = None,\n    openapi_examples: dict[str, Example] | None = None,\n    deprecated: bool | None = None,\n    include_in_schema: bool = True,\n    json_schema_extra: dict[str, Any] | None = None,\n    **extra: Any\n)\n</code></pre> <p>               Bases: <code>FieldInfo</code></p> <p>A class used internally to represent a body parameter in a path operation.</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/params.py</code> <pre><code>def __init__(\n    self,\n    default: Any = Undefined,\n    *,\n    default_factory: Callable[[], Any] | None = _Unset,\n    annotation: Any | None = None,\n    embed: bool = False,\n    media_type: str = \"application/json\",\n    alias: str | None = None,\n    alias_priority: int | None = _Unset,\n    # MAINTENANCE: update when deprecating Pydantic v1, import these types\n    # str | AliasPath | AliasChoices | None\n    validation_alias: str | None = None,\n    serialization_alias: str | None = None,\n    title: str | None = None,\n    description: str | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | None = None,\n    discriminator: str | None = None,\n    strict: bool | None = _Unset,\n    multiple_of: float | None = _Unset,\n    allow_inf_nan: bool | None = _Unset,\n    max_digits: int | None = _Unset,\n    decimal_places: int | None = _Unset,\n    examples: list[Any] | None = None,\n    openapi_examples: dict[str, Example] | None = None,\n    deprecated: bool | None = None,\n    include_in_schema: bool = True,\n    json_schema_extra: dict[str, Any] | None = None,\n    **extra: Any,\n):\n    self.embed = embed\n    self.media_type = media_type\n    self.deprecated = deprecated\n    self.include_in_schema = include_in_schema\n    kwargs = dict(\n        default=default,\n        default_factory=default_factory,\n        alias=alias,\n        title=title,\n        description=description,\n        gt=gt,\n        ge=ge,\n        lt=lt,\n        le=le,\n        min_length=min_length,\n        max_length=max_length,\n        discriminator=discriminator,\n        multiple_of=multiple_of,\n        allow_nan=allow_inf_nan,\n        max_digits=max_digits,\n        decimal_places=decimal_places,\n        **extra,\n    )\n    if examples is not None:\n        kwargs[\"examples\"] = examples\n    current_json_schema_extra = json_schema_extra or extra\n\n    kwargs.update(\n        {\n            \"annotation\": annotation,\n            \"alias_priority\": alias_priority,\n            \"validation_alias\": validation_alias,\n            \"serialization_alias\": serialization_alias,\n            \"strict\": strict,\n            \"json_schema_extra\": current_json_schema_extra,\n            \"pattern\": pattern,\n        },\n    )\n\n    use_kwargs = {k: v for k, v in kwargs.items() if v is not _Unset}\n\n    super().__init__(**use_kwargs)\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.params.Dependant",
            "title": "Dependant",
            "text": "<pre><code>Dependant(\n    *,\n    path_params: list[ModelField] | None = None,\n    query_params: list[ModelField] | None = None,\n    header_params: list[ModelField] | None = None,\n    cookie_params: list[ModelField] | None = None,\n    body_params: list[ModelField] | None = None,\n    return_param: ModelField | None = None,\n    response_extra_models: list[ModelField] | None = None,\n    name: str | None = None,\n    call: Callable[..., Any] | None = None,\n    request_param_name: str | None = None,\n    websocket_param_name: str | None = None,\n    http_connection_param_name: str | None = None,\n    response_param_name: str | None = None,\n    background_tasks_param_name: str | None = None,\n    path: str | None = None\n)\n</code></pre> <p>A class used internally to represent a dependency between path operation decorators and the path operation function.</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/params.py</code> <pre><code>def __init__(\n    self,\n    *,\n    path_params: list[ModelField] | None = None,\n    query_params: list[ModelField] | None = None,\n    header_params: list[ModelField] | None = None,\n    cookie_params: list[ModelField] | None = None,\n    body_params: list[ModelField] | None = None,\n    return_param: ModelField | None = None,\n    response_extra_models: list[ModelField] | None = None,\n    name: str | None = None,\n    call: Callable[..., Any] | None = None,\n    request_param_name: str | None = None,\n    websocket_param_name: str | None = None,\n    http_connection_param_name: str | None = None,\n    response_param_name: str | None = None,\n    background_tasks_param_name: str | None = None,\n    path: str | None = None,\n) -&gt; None:\n    self.path_params = path_params or []\n    self.query_params = query_params or []\n    self.header_params = header_params or []\n    self.cookie_params = cookie_params or []\n    self.body_params = body_params or []\n    self.return_param = return_param or None\n    self.response_extra_models = response_extra_models or []\n    self.request_param_name = request_param_name\n    self.websocket_param_name = websocket_param_name\n    self.http_connection_param_name = http_connection_param_name\n    self.response_param_name = response_param_name\n    self.background_tasks_param_name = background_tasks_param_name\n    self.name = name\n    self.call = call\n    # Store the path to be able to re-generate a dependable from it in overrides\n    self.path = path\n    # Save the cache key at creation to optimize performance\n    self.cache_key: CacheKey = self.call\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.params.Header",
            "title": "Header",
            "text": "<pre><code>Header(\n    default: Any = Undefined,\n    *,\n    default_factory: Callable[[], Any] | None = _Unset,\n    annotation: Any | None = None,\n    alias: str | None = None,\n    alias_priority: int | None = _Unset,\n    validation_alias: str | None = None,\n    serialization_alias: str | None = None,\n    convert_underscores: bool = True,\n    title: str | None = None,\n    description: str | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | None = None,\n    discriminator: str | None = None,\n    strict: bool | None = _Unset,\n    multiple_of: float | None = _Unset,\n    allow_inf_nan: bool | None = _Unset,\n    max_digits: int | None = _Unset,\n    decimal_places: int | None = _Unset,\n    examples: list[Any] | None = None,\n    openapi_examples: dict[str, Example] | None = None,\n    deprecated: bool | None = None,\n    include_in_schema: bool = True,\n    json_schema_extra: dict[str, Any] | None = None,\n    **extra: Any\n)\n</code></pre> <p>               Bases: <code>Param</code></p> <p>A class used internally to represent a header parameter in a path operation.</p> PARAMETER DESCRIPTION <code>default</code> <p>The default value of the parameter</p> <p> TYPE: <code>Any</code> DEFAULT: <code>Undefined</code> </p> <code>default_factory</code> <p>Callable that will be called when a default value is needed for this field</p> <p> TYPE: <code>Callable[[], Any] | None</code> DEFAULT: <code>_Unset</code> </p> <code>annotation</code> <p>The type annotation of the parameter</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>alias</code> <p>The public name of the field</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>alias_priority</code> <p>Priority of the alias. This affects whether an alias generator is used</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>_Unset</code> </p> <code>validation_alias</code> <p>Alias to be used for validation only</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>serialization_alias</code> <p>Alias to be used for serialization only</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>convert_underscores</code> <p>If true convert \"_\" to \"-\" See RFC: https://www.rfc-editor.org/rfc/rfc9110.html#name-field-name-registry</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>title</code> <p>The title of the parameter</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>description</code> <p>The description of the parameter</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>gt</code> <p>Only applies to numbers, required the field to be \"greater than\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>ge</code> <p>Only applies to numbers, required the field to be \"greater than or equal\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>lt</code> <p>Only applies to numbers, required the field to be \"less than\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>le</code> <p>Only applies to numbers, required the field to be \"less than or equal\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Only applies to strings, required the field to have a minimum length</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>max_length</code> <p>Only applies to strings, required the field to have a maximum length</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>pattern</code> <p>Only applies to strings, requires the field match against a regular expression pattern string</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>discriminator</code> <p>Parameter field name for discriminating the type in a tagged union</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>strict</code> <p>Enables Pydantic's strict mode for the field</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>_Unset</code> </p> <code>multiple_of</code> <p>Only applies to numbers, requires the field to be a multiple of the given value</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>_Unset</code> </p> <code>allow_inf_nan</code> <p>Only applies to numbers, requires the field to allow infinity and NaN values</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>_Unset</code> </p> <code>max_digits</code> <p>Only applies to Decimals, requires the field to have a maxmium number of digits within the decimal.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>_Unset</code> </p> <code>decimal_places</code> <p>Only applies to Decimals, requires the field to have at most a number of decimal places</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>_Unset</code> </p> <code>examples</code> <p>A list of examples for the parameter</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>deprecated</code> <p>If <code>True</code>, the parameter will be marked as deprecated</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>include_in_schema</code> <p>If <code>False</code>, the parameter will be excluded from the generated OpenAPI schema</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>json_schema_extra</code> <p>Extra values to include in the generated OpenAPI schema</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/event_handler/openapi/params.py</code> <pre><code>def __init__(\n    self,\n    default: Any = Undefined,\n    *,\n    default_factory: Callable[[], Any] | None = _Unset,\n    annotation: Any | None = None,\n    alias: str | None = None,\n    alias_priority: int | None = _Unset,\n    # MAINTENANCE: update when deprecating Pydantic v1, import these types\n    # str | AliasPath | AliasChoices | None\n    validation_alias: str | None = None,\n    serialization_alias: str | None = None,\n    convert_underscores: bool = True,\n    title: str | None = None,\n    description: str | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | None = None,\n    discriminator: str | None = None,\n    strict: bool | None = _Unset,\n    multiple_of: float | None = _Unset,\n    allow_inf_nan: bool | None = _Unset,\n    max_digits: int | None = _Unset,\n    decimal_places: int | None = _Unset,\n    examples: list[Any] | None = None,\n    openapi_examples: dict[str, Example] | None = None,\n    deprecated: bool | None = None,\n    include_in_schema: bool = True,\n    json_schema_extra: dict[str, Any] | None = None,\n    **extra: Any,\n):\n    \"\"\"\n    Constructs a new Query param.\n\n    Parameters\n    ----------\n    default: Any\n        The default value of the parameter\n    default_factory: Callable[[], Any], optional\n        Callable that will be called when a default value is needed for this field\n    annotation: Any, optional\n        The type annotation of the parameter\n    alias: str, optional\n        The public name of the field\n    alias_priority: int, optional\n        Priority of the alias. This affects whether an alias generator is used\n    validation_alias: str | AliasPath | AliasChoices | None, optional\n        Alias to be used for validation only\n    serialization_alias: str | AliasPath | AliasChoices | None, optional\n        Alias to be used for serialization only\n    convert_underscores: bool\n        If true convert \"_\" to \"-\"\n        See RFC: https://www.rfc-editor.org/rfc/rfc9110.html#name-field-name-registry\n    title: str, optional\n        The title of the parameter\n    description: str, optional\n        The description of the parameter\n    gt: float, optional\n        Only applies to numbers, required the field to be \"greater than\"\n    ge: float, optional\n        Only applies to numbers, required the field to be \"greater than or equal\"\n    lt: float, optional\n        Only applies to numbers, required the field to be \"less than\"\n    le: float, optional\n        Only applies to numbers, required the field to be \"less than or equal\"\n    min_length: int, optional\n        Only applies to strings, required the field to have a minimum length\n    max_length: int, optional\n        Only applies to strings, required the field to have a maximum length\n    pattern: str, optional\n        Only applies to strings, requires the field match against a regular expression pattern string\n    discriminator: str, optional\n        Parameter field name for discriminating the type in a tagged union\n    strict: bool, optional\n        Enables Pydantic's strict mode for the field\n    multiple_of: float, optional\n        Only applies to numbers, requires the field to be a multiple of the given value\n    allow_inf_nan: bool, optional\n        Only applies to numbers, requires the field to allow infinity and NaN values\n    max_digits: int, optional\n        Only applies to Decimals, requires the field to have a maxmium number of digits within the decimal.\n    decimal_places: int, optional\n        Only applies to Decimals, requires the field to have at most a number of decimal places\n    examples: list[Any], optional\n        A list of examples for the parameter\n    deprecated: bool, optional\n        If `True`, the parameter will be marked as deprecated\n    include_in_schema: bool, optional\n        If `False`, the parameter will be excluded from the generated OpenAPI schema\n    json_schema_extra: dict[str, Any], optional\n        Extra values to include in the generated OpenAPI schema\n    \"\"\"\n    self.convert_underscores = convert_underscores\n    self._alias = alias\n\n    super().__init__(\n        default=default,\n        default_factory=default_factory,\n        annotation=annotation,\n        alias=self._alias,\n        alias_priority=alias_priority,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        title=title,\n        description=description,\n        gt=gt,\n        ge=ge,\n        lt=lt,\n        le=le,\n        min_length=min_length,\n        max_length=max_length,\n        pattern=pattern,\n        discriminator=discriminator,\n        strict=strict,\n        multiple_of=multiple_of,\n        allow_inf_nan=allow_inf_nan,\n        max_digits=max_digits,\n        decimal_places=decimal_places,\n        deprecated=deprecated,\n        examples=examples,\n        openapi_examples=openapi_examples,\n        include_in_schema=include_in_schema,\n        json_schema_extra=json_schema_extra,\n        **extra,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.params.Param",
            "title": "Param",
            "text": "<pre><code>Param(\n    default: Any = Undefined,\n    *,\n    default_factory: Callable[[], Any] | None = _Unset,\n    annotation: Any | None = None,\n    alias: str | None = None,\n    alias_priority: int | None = _Unset,\n    validation_alias: str | None = None,\n    serialization_alias: str | None = None,\n    title: str | None = None,\n    description: str | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | None = None,\n    discriminator: str | None = None,\n    strict: bool | None = _Unset,\n    multiple_of: float | None = _Unset,\n    allow_inf_nan: bool | None = _Unset,\n    max_digits: int | None = _Unset,\n    decimal_places: int | None = _Unset,\n    examples: list[Any] | None = None,\n    openapi_examples: dict[str, Example] | None = None,\n    deprecated: bool | None = None,\n    include_in_schema: bool = True,\n    json_schema_extra: dict[str, Any] | None = None,\n    **extra: Any\n)\n</code></pre> <p>               Bases: <code>FieldInfo</code></p> <p>A class used internally to represent a parameter in a path operation.</p> PARAMETER DESCRIPTION <code>default</code> <p>The default value of the parameter</p> <p> TYPE: <code>Any</code> DEFAULT: <code>Undefined</code> </p> <code>default_factory</code> <p>Callable that will be called when a default value is needed for this field</p> <p> TYPE: <code>Callable[[], Any] | None</code> DEFAULT: <code>_Unset</code> </p> <code>annotation</code> <p>The type annotation of the parameter</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>alias</code> <p>The public name of the field</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>alias_priority</code> <p>Priority of the alias. This affects whether an alias generator is used</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>_Unset</code> </p> <code>validation_alias</code> <p>Alias to be used for validation only</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>serialization_alias</code> <p>Alias to be used for serialization only</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>title</code> <p>The title of the parameter</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>description</code> <p>The description of the parameter</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>gt</code> <p>Only applies to numbers, required the field to be \"greater than\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>ge</code> <p>Only applies to numbers, required the field to be \"greater than or equal\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>lt</code> <p>Only applies to numbers, required the field to be \"less than\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>le</code> <p>Only applies to numbers, required the field to be \"less than or equal\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Only applies to strings, required the field to have a minimum length</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>max_length</code> <p>Only applies to strings, required the field to have a maximum length</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>pattern</code> <p>Only applies to strings, requires the field match against a regular expression pattern string</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>discriminator</code> <p>Parameter field name for discriminating the type in a tagged union</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>strict</code> <p>Enables Pydantic's strict mode for the field</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>_Unset</code> </p> <code>multiple_of</code> <p>Only applies to numbers, requires the field to be a multiple of the given value</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>_Unset</code> </p> <code>allow_inf_nan</code> <p>Only applies to numbers, requires the field to allow infinity and NaN values</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>_Unset</code> </p> <code>max_digits</code> <p>Only applies to Decimals, requires the field to have a maxmium number of digits within the decimal.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>_Unset</code> </p> <code>decimal_places</code> <p>Only applies to Decimals, requires the field to have at most a number of decimal places</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>_Unset</code> </p> <code>examples</code> <p>A list of examples for the parameter</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>deprecated</code> <p>If <code>True</code>, the parameter will be marked as deprecated</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>include_in_schema</code> <p>If <code>False</code>, the parameter will be excluded from the generated OpenAPI schema</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>json_schema_extra</code> <p>Extra values to include in the generated OpenAPI schema</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/event_handler/openapi/params.py</code> <pre><code>def __init__(\n    self,\n    default: Any = Undefined,\n    *,\n    default_factory: Callable[[], Any] | None = _Unset,\n    annotation: Any | None = None,\n    alias: str | None = None,\n    alias_priority: int | None = _Unset,\n    # MAINTENANCE: update when deprecating Pydantic v1, import these types\n    # MAINTENANCE: validation_alias: str | AliasPath | AliasChoices | None\n    validation_alias: str | None = None,\n    serialization_alias: str | None = None,\n    title: str | None = None,\n    description: str | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | None = None,\n    discriminator: str | None = None,\n    strict: bool | None = _Unset,\n    multiple_of: float | None = _Unset,\n    allow_inf_nan: bool | None = _Unset,\n    max_digits: int | None = _Unset,\n    decimal_places: int | None = _Unset,\n    examples: list[Any] | None = None,\n    openapi_examples: dict[str, Example] | None = None,\n    deprecated: bool | None = None,\n    include_in_schema: bool = True,\n    json_schema_extra: dict[str, Any] | None = None,\n    **extra: Any,\n):\n    \"\"\"\n    Constructs a new Param.\n\n    Parameters\n    ----------\n    default: Any\n        The default value of the parameter\n    default_factory: Callable[[], Any], optional\n        Callable that will be called when a default value is needed for this field\n    annotation: Any, optional\n        The type annotation of the parameter\n    alias: str, optional\n        The public name of the field\n    alias_priority: int, optional\n        Priority of the alias. This affects whether an alias generator is used\n    validation_alias: str | AliasPath | AliasChoices | None, optional\n        Alias to be used for validation only\n    serialization_alias: str | AliasPath | AliasChoices | None, optional\n        Alias to be used for serialization only\n    title: str, optional\n        The title of the parameter\n    description: str, optional\n        The description of the parameter\n    gt: float, optional\n        Only applies to numbers, required the field to be \"greater than\"\n    ge: float, optional\n        Only applies to numbers, required the field to be \"greater than or equal\"\n    lt: float, optional\n        Only applies to numbers, required the field to be \"less than\"\n    le: float, optional\n        Only applies to numbers, required the field to be \"less than or equal\"\n    min_length: int, optional\n        Only applies to strings, required the field to have a minimum length\n    max_length: int, optional\n        Only applies to strings, required the field to have a maximum length\n    pattern: str, optional\n        Only applies to strings, requires the field match against a regular expression pattern string\n    discriminator: str, optional\n        Parameter field name for discriminating the type in a tagged union\n    strict: bool, optional\n        Enables Pydantic's strict mode for the field\n    multiple_of: float, optional\n        Only applies to numbers, requires the field to be a multiple of the given value\n    allow_inf_nan: bool, optional\n        Only applies to numbers, requires the field to allow infinity and NaN values\n    max_digits: int, optional\n        Only applies to Decimals, requires the field to have a maxmium number of digits within the decimal.\n    decimal_places: int, optional\n        Only applies to Decimals, requires the field to have at most a number of decimal places\n    examples: list[Any], optional\n        A list of examples for the parameter\n    deprecated: bool, optional\n        If `True`, the parameter will be marked as deprecated\n    include_in_schema: bool, optional\n        If `False`, the parameter will be excluded from the generated OpenAPI schema\n    json_schema_extra: dict[str, Any], optional\n        Extra values to include in the generated OpenAPI schema\n    \"\"\"\n    self.deprecated = deprecated\n    self.include_in_schema = include_in_schema\n\n    kwargs = dict(\n        default=default,\n        default_factory=default_factory,\n        alias=alias,\n        title=title,\n        description=description,\n        gt=gt,\n        ge=ge,\n        lt=lt,\n        le=le,\n        min_length=min_length,\n        max_length=max_length,\n        discriminator=discriminator,\n        multiple_of=multiple_of,\n        allow_nan=allow_inf_nan,\n        max_digits=max_digits,\n        decimal_places=decimal_places,\n        **extra,\n    )\n    if examples is not None:\n        kwargs[\"examples\"] = examples\n\n    if openapi_examples is not None:\n        kwargs[\"openapi_examples\"] = openapi_examples\n\n    current_json_schema_extra = json_schema_extra or extra\n\n    self.openapi_examples = openapi_examples\n\n    kwargs.update(\n        {\n            \"annotation\": annotation,\n            \"alias_priority\": alias_priority,\n            \"validation_alias\": validation_alias,\n            \"serialization_alias\": serialization_alias,\n            \"strict\": strict,\n            \"json_schema_extra\": current_json_schema_extra,\n            \"pattern\": pattern,\n        },\n    )\n\n    use_kwargs = {k: v for k, v in kwargs.items() if v is not _Unset}\n\n    super().__init__(**use_kwargs)\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.params.Path",
            "title": "Path",
            "text": "<pre><code>Path(\n    default: Any = ...,\n    *,\n    default_factory: Callable[[], Any] | None = _Unset,\n    annotation: Any | None = None,\n    alias: str | None = None,\n    alias_priority: int | None = _Unset,\n    validation_alias: str | None = None,\n    serialization_alias: str | None = None,\n    title: str | None = None,\n    description: str | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | None = None,\n    discriminator: str | None = None,\n    strict: bool | None = _Unset,\n    multiple_of: float | None = _Unset,\n    allow_inf_nan: bool | None = _Unset,\n    max_digits: int | None = _Unset,\n    decimal_places: int | None = _Unset,\n    examples: list[Any] | None = None,\n    openapi_examples: dict[str, Example] | None = None,\n    deprecated: bool | None = None,\n    include_in_schema: bool = True,\n    json_schema_extra: dict[str, Any] | None = None,\n    **extra: Any\n)\n</code></pre> <p>               Bases: <code>Param</code></p> <p>A class used internally to represent a path parameter in a path operation.</p> PARAMETER DESCRIPTION <code>default</code> <p>The default value of the parameter</p> <p> TYPE: <code>Any</code> DEFAULT: <code>...</code> </p> <code>default_factory</code> <p>Callable that will be called when a default value is needed for this field</p> <p> TYPE: <code>Callable[[], Any] | None</code> DEFAULT: <code>_Unset</code> </p> <code>annotation</code> <p>The type annotation of the parameter</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>alias</code> <p>The public name of the field</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>alias_priority</code> <p>Priority of the alias. This affects whether an alias generator is used</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>_Unset</code> </p> <code>validation_alias</code> <p>Alias to be used for validation only</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>serialization_alias</code> <p>Alias to be used for serialization only</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>title</code> <p>The title of the parameter</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>description</code> <p>The description of the parameter</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>gt</code> <p>Only applies to numbers, required the field to be \"greater than\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>ge</code> <p>Only applies to numbers, required the field to be \"greater than or equal\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>lt</code> <p>Only applies to numbers, required the field to be \"less than\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>le</code> <p>Only applies to numbers, required the field to be \"less than or equal\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Only applies to strings, required the field to have a minimum length</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>max_length</code> <p>Only applies to strings, required the field to have a maximum length</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>pattern</code> <p>Only applies to strings, requires the field match against a regular expression pattern string</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>discriminator</code> <p>Parameter field name for discriminating the type in a tagged union</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>strict</code> <p>Enables Pydantic's strict mode for the field</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>_Unset</code> </p> <code>multiple_of</code> <p>Only applies to numbers, requires the field to be a multiple of the given value</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>_Unset</code> </p> <code>allow_inf_nan</code> <p>Only applies to numbers, requires the field to allow infinity and NaN values</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>_Unset</code> </p> <code>max_digits</code> <p>Only applies to Decimals, requires the field to have a maxmium number of digits within the decimal.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>_Unset</code> </p> <code>decimal_places</code> <p>Only applies to Decimals, requires the field to have at most a number of decimal places</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>_Unset</code> </p> <code>examples</code> <p>A list of examples for the parameter</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>deprecated</code> <p>If <code>True</code>, the parameter will be marked as deprecated</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>include_in_schema</code> <p>If <code>False</code>, the parameter will be excluded from the generated OpenAPI schema</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>json_schema_extra</code> <p>Extra values to include in the generated OpenAPI schema</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/event_handler/openapi/params.py</code> <pre><code>def __init__(\n    self,\n    default: Any = ...,\n    *,\n    default_factory: Callable[[], Any] | None = _Unset,\n    annotation: Any | None = None,\n    alias: str | None = None,\n    alias_priority: int | None = _Unset,\n    # MAINTENANCE: update when deprecating Pydantic v1, import these types\n    # MAINTENANCE: validation_alias: str | AliasPath | AliasChoices | None\n    validation_alias: str | None = None,\n    serialization_alias: str | None = None,\n    title: str | None = None,\n    description: str | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | None = None,\n    discriminator: str | None = None,\n    strict: bool | None = _Unset,\n    multiple_of: float | None = _Unset,\n    allow_inf_nan: bool | None = _Unset,\n    max_digits: int | None = _Unset,\n    decimal_places: int | None = _Unset,\n    examples: list[Any] | None = None,\n    openapi_examples: dict[str, Example] | None = None,\n    deprecated: bool | None = None,\n    include_in_schema: bool = True,\n    json_schema_extra: dict[str, Any] | None = None,\n    **extra: Any,\n):\n    \"\"\"\n    Constructs a new Path param.\n\n    Parameters\n    ----------\n    default: Any\n        The default value of the parameter\n    default_factory: Callable[[], Any], optional\n        Callable that will be called when a default value is needed for this field\n    annotation: Any, optional\n        The type annotation of the parameter\n    alias: str, optional\n        The public name of the field\n    alias_priority: int, optional\n        Priority of the alias. This affects whether an alias generator is used\n    validation_alias: str | AliasPath | AliasChoices | None, optional\n        Alias to be used for validation only\n    serialization_alias: str | AliasPath | AliasChoices | None, optional\n        Alias to be used for serialization only\n    title: str, optional\n        The title of the parameter\n    description: str, optional\n        The description of the parameter\n    gt: float, optional\n        Only applies to numbers, required the field to be \"greater than\"\n    ge: float, optional\n        Only applies to numbers, required the field to be \"greater than or equal\"\n    lt: float, optional\n        Only applies to numbers, required the field to be \"less than\"\n    le: float, optional\n        Only applies to numbers, required the field to be \"less than or equal\"\n    min_length: int, optional\n        Only applies to strings, required the field to have a minimum length\n    max_length: int, optional\n        Only applies to strings, required the field to have a maximum length\n    pattern: str, optional\n        Only applies to strings, requires the field match against a regular expression pattern string\n    discriminator: str, optional\n        Parameter field name for discriminating the type in a tagged union\n    strict: bool, optional\n        Enables Pydantic's strict mode for the field\n    multiple_of: float, optional\n        Only applies to numbers, requires the field to be a multiple of the given value\n    allow_inf_nan: bool, optional\n        Only applies to numbers, requires the field to allow infinity and NaN values\n    max_digits: int, optional\n        Only applies to Decimals, requires the field to have a maxmium number of digits within the decimal.\n    decimal_places: int, optional\n        Only applies to Decimals, requires the field to have at most a number of decimal places\n    examples: list[Any], optional\n        A list of examples for the parameter\n    deprecated: bool, optional\n        If `True`, the parameter will be marked as deprecated\n    include_in_schema: bool, optional\n        If `False`, the parameter will be excluded from the generated OpenAPI schema\n    json_schema_extra: dict[str, Any], optional\n        Extra values to include in the generated OpenAPI schema\n    \"\"\"\n    if default is not ...:\n        raise AssertionError(\"Path parameters cannot have a default value\")\n\n    super().__init__(\n        default=default,\n        default_factory=default_factory,\n        annotation=annotation,\n        alias=alias,\n        alias_priority=alias_priority,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        title=title,\n        description=description,\n        gt=gt,\n        ge=ge,\n        lt=lt,\n        le=le,\n        min_length=min_length,\n        max_length=max_length,\n        pattern=pattern,\n        discriminator=discriminator,\n        strict=strict,\n        multiple_of=multiple_of,\n        allow_inf_nan=allow_inf_nan,\n        max_digits=max_digits,\n        decimal_places=decimal_places,\n        deprecated=deprecated,\n        examples=examples,\n        openapi_examples=openapi_examples,\n        include_in_schema=include_in_schema,\n        json_schema_extra=json_schema_extra,\n        **extra,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.params.Query",
            "title": "Query",
            "text": "<pre><code>Query(\n    default: Any = _Unset,\n    *,\n    default_factory: Callable[[], Any] | None = _Unset,\n    annotation: Any | None = None,\n    alias: str | None = None,\n    alias_priority: int | None = _Unset,\n    validation_alias: str | None = None,\n    serialization_alias: str | None = None,\n    title: str | None = None,\n    description: str | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | None = None,\n    discriminator: str | None = None,\n    strict: bool | None = _Unset,\n    multiple_of: float | None = _Unset,\n    allow_inf_nan: bool | None = _Unset,\n    max_digits: int | None = _Unset,\n    decimal_places: int | None = _Unset,\n    examples: list[Any] | None = None,\n    openapi_examples: dict[str, Example] | None = None,\n    deprecated: bool | None = None,\n    include_in_schema: bool = True,\n    json_schema_extra: dict[str, Any] | None = None,\n    **extra: Any\n)\n</code></pre> <p>               Bases: <code>Param</code></p> <p>A class used internally to represent a query parameter in a path operation.</p> PARAMETER DESCRIPTION <code>default</code> <p>The default value of the parameter</p> <p> TYPE: <code>Any</code> DEFAULT: <code>_Unset</code> </p> <code>default_factory</code> <p>Callable that will be called when a default value is needed for this field</p> <p> TYPE: <code>Callable[[], Any] | None</code> DEFAULT: <code>_Unset</code> </p> <code>annotation</code> <p>The type annotation of the parameter</p> <p> TYPE: <code>Any | None</code> DEFAULT: <code>None</code> </p> <code>alias</code> <p>The public name of the field</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>alias_priority</code> <p>Priority of the alias. This affects whether an alias generator is used</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>_Unset</code> </p> <code>validation_alias</code> <p>Alias to be used for validation only</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>serialization_alias</code> <p>Alias to be used for serialization only</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>title</code> <p>The title of the parameter</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>description</code> <p>The description of the parameter</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>gt</code> <p>Only applies to numbers, required the field to be \"greater than\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>ge</code> <p>Only applies to numbers, required the field to be \"greater than or equal\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>lt</code> <p>Only applies to numbers, required the field to be \"less than\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>le</code> <p>Only applies to numbers, required the field to be \"less than or equal\"</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>min_length</code> <p>Only applies to strings, required the field to have a minimum length</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>max_length</code> <p>Only applies to strings, required the field to have a maximum length</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>pattern</code> <p>Only applies to strings, requires the field match against a regular expression pattern string</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>discriminator</code> <p>Parameter field name for discriminating the type in a tagged union</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>strict</code> <p>Enables Pydantic's strict mode for the field</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>_Unset</code> </p> <code>multiple_of</code> <p>Only applies to numbers, requires the field to be a multiple of the given value</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>_Unset</code> </p> <code>allow_inf_nan</code> <p>Only applies to numbers, requires the field to allow infinity and NaN values</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>_Unset</code> </p> <code>max_digits</code> <p>Only applies to Decimals, requires the field to have a maxmium number of digits within the decimal.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>_Unset</code> </p> <code>decimal_places</code> <p>Only applies to Decimals, requires the field to have at most a number of decimal places</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>_Unset</code> </p> <code>examples</code> <p>A list of examples for the parameter</p> <p> TYPE: <code>list[Any] | None</code> DEFAULT: <code>None</code> </p> <code>deprecated</code> <p>If <code>True</code>, the parameter will be marked as deprecated</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>include_in_schema</code> <p>If <code>False</code>, the parameter will be excluded from the generated OpenAPI schema</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>json_schema_extra</code> <p>Extra values to include in the generated OpenAPI schema</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/event_handler/openapi/params.py</code> <pre><code>def __init__(\n    self,\n    default: Any = _Unset,\n    *,\n    default_factory: Callable[[], Any] | None = _Unset,\n    annotation: Any | None = None,\n    alias: str | None = None,\n    alias_priority: int | None = _Unset,\n    validation_alias: str | None = None,\n    serialization_alias: str | None = None,\n    title: str | None = None,\n    description: str | None = None,\n    gt: float | None = None,\n    ge: float | None = None,\n    lt: float | None = None,\n    le: float | None = None,\n    min_length: int | None = None,\n    max_length: int | None = None,\n    pattern: str | None = None,\n    discriminator: str | None = None,\n    strict: bool | None = _Unset,\n    multiple_of: float | None = _Unset,\n    allow_inf_nan: bool | None = _Unset,\n    max_digits: int | None = _Unset,\n    decimal_places: int | None = _Unset,\n    examples: list[Any] | None = None,\n    openapi_examples: dict[str, Example] | None = None,\n    deprecated: bool | None = None,\n    include_in_schema: bool = True,\n    json_schema_extra: dict[str, Any] | None = None,\n    **extra: Any,\n):\n    \"\"\"\n    Constructs a new Query param.\n\n    Parameters\n    ----------\n    default: Any\n        The default value of the parameter\n    default_factory: Callable[[], Any], optional\n        Callable that will be called when a default value is needed for this field\n    annotation: Any, optional\n        The type annotation of the parameter\n    alias: str, optional\n        The public name of the field\n    alias_priority: int, optional\n        Priority of the alias. This affects whether an alias generator is used\n    validation_alias: str | AliasPath | AliasChoices | None, optional\n        Alias to be used for validation only\n    serialization_alias: str | AliasPath | AliasChoices | None, optional\n        Alias to be used for serialization only\n    title: str, optional\n        The title of the parameter\n    description: str, optional\n        The description of the parameter\n    gt: float, optional\n        Only applies to numbers, required the field to be \"greater than\"\n    ge: float, optional\n        Only applies to numbers, required the field to be \"greater than or equal\"\n    lt: float, optional\n        Only applies to numbers, required the field to be \"less than\"\n    le: float, optional\n        Only applies to numbers, required the field to be \"less than or equal\"\n    min_length: int, optional\n        Only applies to strings, required the field to have a minimum length\n    max_length: int, optional\n        Only applies to strings, required the field to have a maximum length\n    pattern: str, optional\n        Only applies to strings, requires the field match against a regular expression pattern string\n    discriminator: str, optional\n        Parameter field name for discriminating the type in a tagged union\n    strict: bool, optional\n        Enables Pydantic's strict mode for the field\n    multiple_of: float, optional\n        Only applies to numbers, requires the field to be a multiple of the given value\n    allow_inf_nan: bool, optional\n        Only applies to numbers, requires the field to allow infinity and NaN values\n    max_digits: int, optional\n        Only applies to Decimals, requires the field to have a maxmium number of digits within the decimal.\n    decimal_places: int, optional\n        Only applies to Decimals, requires the field to have at most a number of decimal places\n    examples: list[Any], optional\n        A list of examples for the parameter\n    deprecated: bool, optional\n        If `True`, the parameter will be marked as deprecated\n    include_in_schema: bool, optional\n        If `False`, the parameter will be excluded from the generated OpenAPI schema\n    json_schema_extra: dict[str, Any], optional\n        Extra values to include in the generated OpenAPI schema\n    \"\"\"\n    super().__init__(\n        default=default,\n        default_factory=default_factory,\n        annotation=annotation,\n        alias=alias,\n        alias_priority=alias_priority,\n        validation_alias=validation_alias,\n        serialization_alias=serialization_alias,\n        title=title,\n        description=description,\n        gt=gt,\n        ge=ge,\n        lt=lt,\n        le=le,\n        min_length=min_length,\n        max_length=max_length,\n        pattern=pattern,\n        discriminator=discriminator,\n        strict=strict,\n        multiple_of=multiple_of,\n        allow_inf_nan=allow_inf_nan,\n        max_digits=max_digits,\n        decimal_places=decimal_places,\n        deprecated=deprecated,\n        examples=examples,\n        openapi_examples=openapi_examples,\n        include_in_schema=include_in_schema,\n        json_schema_extra=json_schema_extra,\n        **extra,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.params.analyze_param",
            "title": "analyze_param",
            "text": "<pre><code>analyze_param(\n    *,\n    param_name: str,\n    annotation: Any,\n    value: Any,\n    is_path_param: bool,\n    is_response_param: bool\n) -&gt; ModelField | None\n</code></pre> <p>Analyze a parameter annotation and value to determine the type and default value of the parameter.</p> PARAMETER DESCRIPTION <code>param_name</code> <p>The name of the parameter</p> <p> TYPE: <code>str</code> </p> <code>annotation</code> <p>The annotation of the parameter</p> <p> TYPE: <code>Any</code> </p> <code>value</code> <p>The value of the parameter</p> <p> TYPE: <code>Any</code> </p> <code>is_path_param</code> <p>Whether the parameter is a path parameter</p> <p> TYPE: <code>bool</code> </p> <code>is_response_param</code> <p>Whether the parameter is the return annotation</p> <p> TYPE: <code>bool</code> </p> RETURNS DESCRIPTION <code>ModelField | None</code> <p>The type annotation and the Pydantic field representing the parameter</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/params.py</code> <pre><code>def analyze_param(\n    *,\n    param_name: str,\n    annotation: Any,\n    value: Any,\n    is_path_param: bool,\n    is_response_param: bool,\n) -&gt; ModelField | None:\n    \"\"\"\n    Analyze a parameter annotation and value to determine the type and default value of the parameter.\n\n    Parameters\n    ----------\n    param_name: str\n        The name of the parameter\n    annotation\n        The annotation of the parameter\n    value\n        The value of the parameter\n    is_path_param\n        Whether the parameter is a path parameter\n    is_response_param\n        Whether the parameter is the return annotation\n\n    Returns\n    -------\n    ModelField | None\n        The type annotation and the Pydantic field representing the parameter\n    \"\"\"\n    field_info, type_annotation = get_field_info_and_type_annotation(\n        annotation,\n        value,\n        is_path_param,\n        is_response_param,\n    )\n\n    # If the value is a FieldInfo, we use it as the FieldInfo for the parameter\n    if isinstance(value, FieldInfo):\n        if field_info is not None:\n            raise AssertionError(\"Cannot use a FieldInfo as a parameter annotation and pass a FieldInfo as a value\")\n        field_info = value\n\n        field_info.annotation = type_annotation  # type: ignore[attr-defined,unused-ignore]\n\n    # If we didn't determine the FieldInfo yet, we create a default one\n    if field_info is None:\n        default_value = value if value is not inspect.Signature.empty else Required\n\n        # Check if the parameter is part of the path. Otherwise, defaults to query.\n        if is_path_param:\n            field_info = Path(annotation=type_annotation)\n        elif not field_annotation_is_scalar(annotation=type_annotation):\n            field_info = Body(annotation=type_annotation, default=default_value)\n        else:\n            field_info = Query(annotation=type_annotation, default=default_value)\n\n    # When we have a response field, we need to set the default value to Required\n    if is_response_param:\n        field_info.default = Required\n\n    field = _create_model_field(field_info, type_annotation, param_name, is_path_param)\n    return field\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.params.create_response_field",
            "title": "create_response_field",
            "text": "<pre><code>create_response_field(\n    name: str,\n    type_: type[Any],\n    default: Any | None = Undefined,\n    required: bool | UndefinedType = Undefined,\n    model_config: type[BaseConfig] = BaseConfig,\n    field_info: FieldInfo | None = None,\n    alias: str | None = None,\n    mode: Literal[\n        \"validation\", \"serialization\"\n    ] = \"validation\",\n) -&gt; ModelField\n</code></pre> <p>Create a new response field. Raises if type_ is invalid.</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/params.py</code> <pre><code>def create_response_field(\n    name: str,\n    type_: type[Any],\n    default: Any | None = Undefined,\n    required: bool | UndefinedType = Undefined,\n    model_config: type[BaseConfig] = BaseConfig,\n    field_info: FieldInfo | None = None,\n    alias: str | None = None,\n    mode: Literal[\"validation\", \"serialization\"] = \"validation\",\n) -&gt; ModelField:\n    \"\"\"\n    Create a new response field. Raises if type_ is invalid.\n    \"\"\"\n    field_info = field_info or FieldInfo(\n        annotation=type_,\n        default=default,\n        alias=alias,\n    )\n\n    kwargs = {\"name\": name, \"field_info\": field_info, \"mode\": mode}\n\n    return ModelField(**kwargs)  # type: ignore[arg-type]\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.params.get_field_info_and_type_annotation",
            "title": "get_field_info_and_type_annotation",
            "text": "<pre><code>get_field_info_and_type_annotation(\n    annotation,\n    value,\n    is_path_param: bool,\n    is_response_param: bool,\n) -&gt; tuple[FieldInfo | None, Any]\n</code></pre> <p>Get the FieldInfo and type annotation from an annotation and value.</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/params.py</code> <pre><code>def get_field_info_and_type_annotation(\n    annotation,\n    value,\n    is_path_param: bool,\n    is_response_param: bool,\n) -&gt; tuple[FieldInfo | None, Any]:\n    \"\"\"\n    Get the FieldInfo and type annotation from an annotation and value.\n    \"\"\"\n    field_info: FieldInfo | None = None\n    type_annotation: Any = Any\n\n    if annotation is not inspect.Signature.empty:\n        # If the annotation is an Annotated type, we need to extract the type annotation and the FieldInfo\n        if get_origin(annotation) is Annotated:\n            field_info, type_annotation = get_field_info_annotated_type(annotation, value, is_path_param)\n        # If the annotation is a Response type, we recursively call this function with the inner type\n        elif get_origin(annotation) is Response:\n            field_info, type_annotation = get_field_info_response_type(annotation, value)\n        # If the response param is a tuple with two elements, we use the first element as the type annotation,\n        # just like we did in the APIGateway._to_response\n        elif is_response_param and get_origin(annotation) is tuple and len(get_args(annotation)) == 2:\n            field_info, type_annotation = get_field_info_tuple_type(annotation, value)\n        # If the annotation is not an Annotated type, we use it as the type annotation\n        else:\n            type_annotation = annotation\n\n    return field_info, type_annotation\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.params.get_field_info_annotated_type",
            "title": "get_field_info_annotated_type",
            "text": "<pre><code>get_field_info_annotated_type(\n    annotation, value, is_path_param: bool\n) -&gt; tuple[FieldInfo | None, Any]\n</code></pre> <p>Get the FieldInfo and type annotation from an Annotated type.</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/params.py</code> <pre><code>def get_field_info_annotated_type(annotation, value, is_path_param: bool) -&gt; tuple[FieldInfo | None, Any]:\n    \"\"\"\n    Get the FieldInfo and type annotation from an Annotated type.\n    \"\"\"\n    field_info: FieldInfo | None = None\n    annotated_args = get_args(annotation)\n    type_annotation = annotated_args[0]\n    powertools_annotations = [arg for arg in annotated_args[1:] if isinstance(arg, FieldInfo)]\n\n    if len(powertools_annotations) &gt; 1:\n        raise AssertionError(\"Only one FieldInfo can be used per parameter\")\n\n    powertools_annotation = next(iter(powertools_annotations), None)\n\n    if isinstance(powertools_annotation, FieldInfo):\n        # Copy `field_info` because we mutate `field_info.default` later\n        field_info = copy_field_info(\n            field_info=powertools_annotation,\n            annotation=annotation,\n        )\n        if field_info.default not in [Undefined, Required]:\n            raise AssertionError(\"FieldInfo needs to have a default value of Undefined or Required\")\n\n        if value is not inspect.Signature.empty:\n            if is_path_param:\n                raise AssertionError(\"Cannot use a FieldInfo as a path parameter and pass a value\")\n            field_info.default = value\n        else:\n            field_info.default = Required\n\n    return field_info, type_annotation\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.params.get_flat_dependant",
            "title": "get_flat_dependant",
            "text": "<pre><code>get_flat_dependant(\n    dependant: Dependant,\n    visited: list[CacheKey] | None = None,\n) -&gt; Dependant\n</code></pre> <p>Flatten a recursive Dependant model structure.</p> <p>This function recursively concatenates the parameter fields of a Dependant model and its dependencies into a flat Dependant structure. This is useful for scenarios like parameter validation where the nested structure is not relevant.</p> PARAMETER DESCRIPTION <code>dependant</code> <p>The dependant model to flatten</p> <p> TYPE: <code>Dependant</code> </p> <code>visited</code> <p>Keeps track of visited Dependents to avoid infinite recursion. Defaults to empty list.</p> <p> TYPE: <code>list[CacheKey] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Dependant</code> <p>The flattened Dependant model</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/params.py</code> <pre><code>def get_flat_dependant(\n    dependant: Dependant,\n    visited: list[CacheKey] | None = None,\n) -&gt; Dependant:\n    \"\"\"\n    Flatten a recursive Dependant model structure.\n\n    This function recursively concatenates the parameter fields of a Dependant model and its dependencies into a flat\n    Dependant structure. This is useful for scenarios like parameter validation where the nested structure is not\n    relevant.\n\n    Parameters\n    ----------\n    dependant: Dependant\n        The dependant model to flatten\n    visited: list[CacheKey], optional\n        Keeps track of visited Dependents to avoid infinite recursion. Defaults to empty list.\n\n    Returns\n    -------\n    Dependant\n        The flattened Dependant model\n    \"\"\"\n    if visited is None:\n        visited = []\n    visited.append(dependant.cache_key)\n\n    return Dependant(\n        path_params=dependant.path_params.copy(),\n        query_params=dependant.query_params.copy(),\n        header_params=dependant.header_params.copy(),\n        cookie_params=dependant.cookie_params.copy(),\n        body_params=dependant.body_params.copy(),\n        path=dependant.path,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.swagger_ui",
            "title": "swagger_ui",
            "text": "MODULE DESCRIPTION <code>html</code> <code>oauth2</code> CLASS DESCRIPTION <code>OAuth2Config</code> <p>OAuth2 configuration for Swagger UI</p> FUNCTION DESCRIPTION <code>generate_oauth2_redirect_html</code> <p>Generates the HTML content for the OAuth2 redirect page.</p> <code>generate_swagger_html</code> <p>Generate Swagger UI HTML page</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.swagger_ui.OAuth2Config",
            "title": "OAuth2Config",
            "text": "<p>               Bases: <code>BaseModel</code></p> <p>OAuth2 configuration for Swagger UI</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.swagger_ui.generate_oauth2_redirect_html",
            "title": "generate_oauth2_redirect_html",
            "text": "<pre><code>generate_oauth2_redirect_html() -&gt; str\n</code></pre> <p>Generates the HTML content for the OAuth2 redirect page.</p> <p>Source: https://github.com/swagger-api/swagger-ui/blob/master/dist/oauth2-redirect.html</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/swagger_ui/oauth2.py</code> <pre><code>def generate_oauth2_redirect_html() -&gt; str:\n    \"\"\"\n    Generates the HTML content for the OAuth2 redirect page.\n\n    Source: https://github.com/swagger-api/swagger-ui/blob/master/dist/oauth2-redirect.html\n    \"\"\"\n    return \"\"\"\n&lt;!doctype html&gt;\n&lt;html lang=\"en-US\"&gt;\n&lt;head&gt;\n    &lt;title&gt;Swagger UI: OAuth2 Redirect&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;script&gt;\n    'use strict';\n    function run () {\n        var oauth2 = window.opener.swaggerUIRedirectOauth2;\n        var sentState = oauth2.state;\n        var redirectUrl = oauth2.redirectUrl;\n        var isValid, qp, arr;\n\n        if (/code|token|error/.test(window.location.hash)) {\n            qp = window.location.hash.substring(1).replace('?', '&amp;');\n        } else {\n            qp = location.search.substring(1);\n        }\n\n        arr = qp.split(\"&amp;\");\n        arr.forEach(function (v,i,_arr) { _arr[i] = '\"' + v.replace('=', '\":\"') + '\"';});\n        qp = qp ? JSON.parse('{' + arr.join() + '}',\n                function (key, value) {\n                    return key === \"\" ? value : decodeURIComponent(value);\n                }\n        ) : {};\n\n        isValid = qp.state === sentState;\n\n        if ((\n          oauth2.auth.schema.get(\"flow\") === \"accessCode\" ||\n          oauth2.auth.schema.get(\"flow\") === \"authorizationCode\" ||\n          oauth2.auth.schema.get(\"flow\") === \"authorization_code\"\n        ) &amp;&amp; !oauth2.auth.code) {\n            if (!isValid) {\n                oauth2.errCb({\n                    authId: oauth2.auth.name,\n                    source: \"auth\",\n                    level: \"warning\",\n                    message: \"Authorization may be unsafe, passed state was changed in server. The passed state wasn't returned from auth server.\"\n                });\n            }\n\n            if (qp.code) {\n                delete oauth2.state;\n                oauth2.auth.code = qp.code;\n                oauth2.callback({auth: oauth2.auth, redirectUrl: redirectUrl});\n            } else {\n                let oauthErrorMsg;\n                if (qp.error) {\n                    oauthErrorMsg = \"[\"+qp.error+\"]: \" +\n                        (qp.error_description ? qp.error_description+ \". \" : \"no accessCode received from the server. \") +\n                        (qp.error_uri ? \"More info: \"+qp.error_uri : \"\");\n                }\n\n                oauth2.errCb({\n                    authId: oauth2.auth.name,\n                    source: \"auth\",\n                    level: \"error\",\n                    message: oauthErrorMsg || \"[Authorization failed]: no accessCode received from the server.\"\n                });\n            }\n        } else {\n            oauth2.callback({auth: oauth2.auth, token: qp, isValid: isValid, redirectUrl: redirectUrl});\n        }\n        window.close();\n    }\n\n    if (document.readyState !== 'loading') {\n        run();\n    } else {\n        document.addEventListener('DOMContentLoaded', function () {\n            run();\n        });\n    }\n&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n    \"\"\".strip()\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.swagger_ui.generate_swagger_html",
            "title": "generate_swagger_html",
            "text": "<pre><code>generate_swagger_html(\n    spec: str,\n    swagger_js: str,\n    swagger_css: str,\n    swagger_base_url: str,\n    oauth2_config: OAuth2Config | None,\n    persist_authorization: bool = False,\n) -&gt; str\n</code></pre> <p>Generate Swagger UI HTML page</p> PARAMETER DESCRIPTION <code>spec</code> <p>The OpenAPI spec</p> <p> TYPE: <code>str</code> </p> <code>swagger_js</code> <p>Swagger UI JavaScript source code or URL</p> <p> TYPE: <code>str</code> </p> <code>swagger_css</code> <p>Swagger UI CSS source code or URL</p> <p> TYPE: <code>str</code> </p> <code>swagger_base_url</code> <p>The base URL for Swagger UI</p> <p> TYPE: <code>str</code> </p> <code>oauth2_config</code> <p>The OAuth2 configuration.</p> <p> TYPE: <code>OAuth2Config | None</code> </p> <code>persist_authorization</code> <p>Whether to persist authorization data on browser close/refresh.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>aws_lambda_powertools/event_handler/openapi/swagger_ui/html.py</code> <pre><code>def generate_swagger_html(\n    spec: str,\n    swagger_js: str,\n    swagger_css: str,\n    swagger_base_url: str,\n    oauth2_config: OAuth2Config | None,\n    persist_authorization: bool = False,\n) -&gt; str:\n    \"\"\"\n    Generate Swagger UI HTML page\n\n    Parameters\n    ----------\n    spec: str\n        The OpenAPI spec\n    swagger_js: str\n        Swagger UI JavaScript source code or URL\n    swagger_css: str\n        Swagger UI CSS source code or URL\n    swagger_base_url: str\n        The base URL for Swagger UI\n    oauth2_config: OAuth2Config, optional\n        The OAuth2 configuration.\n    persist_authorization: bool, optional\n        Whether to persist authorization data on browser close/refresh.\n    \"\"\"\n\n    # If Swagger base URL is present, generate HTML content with linked CSS and JavaScript files\n    # If no Swagger base URL is provided, include CSS and JavaScript directly in the HTML\n    if swagger_base_url:\n        swagger_css_content = f\"&lt;link rel='stylesheet' type='text/css' href='{swagger_css}'&gt;\"\n        swagger_js_content = f\"&lt;script src='{swagger_js}'&gt;&lt;/script&gt;\"\n    else:\n        swagger_css_content = f\"&lt;style&gt;{swagger_css}&lt;/style&gt;\"\n        swagger_js_content = f\"&lt;script&gt;{swagger_js}&lt;/script&gt;\"\n\n    # Prepare oauth2 config\n    oauth2_content = (\n        f\"ui.initOAuth({oauth2_config.json(exclude_none=True, exclude_unset=True)});\" if oauth2_config else \"\"\n    )\n\n    return f\"\"\"\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;Swagger UI&lt;/title&gt;\n    &lt;meta\n      http-equiv=\"Cache-control\"\n      content=\"no-cache, no-store, must-revalidate\"\n    /&gt;\n    {swagger_css_content}\n&lt;/head&gt;\n\n&lt;body&gt;\n    &lt;div id=\"swagger-ui\"&gt;\n        Loading...\n    &lt;/div&gt;\n&lt;/body&gt;\n\n{swagger_js_content}\n\n&lt;script&gt;\n  var currentUrl = new URL(window.location.href);\n  var baseUrl = currentUrl.protocol + \"//\" + currentUrl.host + currentUrl.pathname;\n\n  var swaggerUIOptions = {{\n    dom_id: \"#swagger-ui\",\n    docExpansion: \"list\",\n    deepLinking: true,\n    filter: true,\n    layout: \"BaseLayout\",\n    showExtensions: true,\n    showCommonExtensions: true,\n    spec: {spec},\n    presets: [\n      SwaggerUIBundle.presets.apis,\n      SwaggerUIBundle.SwaggerUIStandalonePreset\n    ],\n    plugins: [\n      SwaggerUIBundle.plugins.DownloadUrl\n    ],\n    withCredentials: true,\n    persistAuthorization: {str(persist_authorization).lower()},\n    oauth2RedirectUrl: baseUrl + \"?format=oauth2-redirect\",\n  }}\n\n  var ui = SwaggerUIBundle(swaggerUIOptions)\n  ui.specActions.updateUrl(currentUrl.pathname + \"?format=json\");\n  {oauth2_content}\n&lt;/script&gt;\n&lt;/html&gt;\n            \"\"\".strip()\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.swagger_ui.html",
            "title": "html",
            "text": "FUNCTION DESCRIPTION <code>generate_swagger_html</code> <p>Generate Swagger UI HTML page</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.swagger_ui.html.generate_swagger_html",
            "title": "generate_swagger_html",
            "text": "<pre><code>generate_swagger_html(\n    spec: str,\n    swagger_js: str,\n    swagger_css: str,\n    swagger_base_url: str,\n    oauth2_config: OAuth2Config | None,\n    persist_authorization: bool = False,\n) -&gt; str\n</code></pre> <p>Generate Swagger UI HTML page</p> PARAMETER DESCRIPTION <code>spec</code> <p>The OpenAPI spec</p> <p> TYPE: <code>str</code> </p> <code>swagger_js</code> <p>Swagger UI JavaScript source code or URL</p> <p> TYPE: <code>str</code> </p> <code>swagger_css</code> <p>Swagger UI CSS source code or URL</p> <p> TYPE: <code>str</code> </p> <code>swagger_base_url</code> <p>The base URL for Swagger UI</p> <p> TYPE: <code>str</code> </p> <code>oauth2_config</code> <p>The OAuth2 configuration.</p> <p> TYPE: <code>OAuth2Config | None</code> </p> <code>persist_authorization</code> <p>Whether to persist authorization data on browser close/refresh.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>aws_lambda_powertools/event_handler/openapi/swagger_ui/html.py</code> <pre><code>def generate_swagger_html(\n    spec: str,\n    swagger_js: str,\n    swagger_css: str,\n    swagger_base_url: str,\n    oauth2_config: OAuth2Config | None,\n    persist_authorization: bool = False,\n) -&gt; str:\n    \"\"\"\n    Generate Swagger UI HTML page\n\n    Parameters\n    ----------\n    spec: str\n        The OpenAPI spec\n    swagger_js: str\n        Swagger UI JavaScript source code or URL\n    swagger_css: str\n        Swagger UI CSS source code or URL\n    swagger_base_url: str\n        The base URL for Swagger UI\n    oauth2_config: OAuth2Config, optional\n        The OAuth2 configuration.\n    persist_authorization: bool, optional\n        Whether to persist authorization data on browser close/refresh.\n    \"\"\"\n\n    # If Swagger base URL is present, generate HTML content with linked CSS and JavaScript files\n    # If no Swagger base URL is provided, include CSS and JavaScript directly in the HTML\n    if swagger_base_url:\n        swagger_css_content = f\"&lt;link rel='stylesheet' type='text/css' href='{swagger_css}'&gt;\"\n        swagger_js_content = f\"&lt;script src='{swagger_js}'&gt;&lt;/script&gt;\"\n    else:\n        swagger_css_content = f\"&lt;style&gt;{swagger_css}&lt;/style&gt;\"\n        swagger_js_content = f\"&lt;script&gt;{swagger_js}&lt;/script&gt;\"\n\n    # Prepare oauth2 config\n    oauth2_content = (\n        f\"ui.initOAuth({oauth2_config.json(exclude_none=True, exclude_unset=True)});\" if oauth2_config else \"\"\n    )\n\n    return f\"\"\"\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;Swagger UI&lt;/title&gt;\n    &lt;meta\n      http-equiv=\"Cache-control\"\n      content=\"no-cache, no-store, must-revalidate\"\n    /&gt;\n    {swagger_css_content}\n&lt;/head&gt;\n\n&lt;body&gt;\n    &lt;div id=\"swagger-ui\"&gt;\n        Loading...\n    &lt;/div&gt;\n&lt;/body&gt;\n\n{swagger_js_content}\n\n&lt;script&gt;\n  var currentUrl = new URL(window.location.href);\n  var baseUrl = currentUrl.protocol + \"//\" + currentUrl.host + currentUrl.pathname;\n\n  var swaggerUIOptions = {{\n    dom_id: \"#swagger-ui\",\n    docExpansion: \"list\",\n    deepLinking: true,\n    filter: true,\n    layout: \"BaseLayout\",\n    showExtensions: true,\n    showCommonExtensions: true,\n    spec: {spec},\n    presets: [\n      SwaggerUIBundle.presets.apis,\n      SwaggerUIBundle.SwaggerUIStandalonePreset\n    ],\n    plugins: [\n      SwaggerUIBundle.plugins.DownloadUrl\n    ],\n    withCredentials: true,\n    persistAuthorization: {str(persist_authorization).lower()},\n    oauth2RedirectUrl: baseUrl + \"?format=oauth2-redirect\",\n  }}\n\n  var ui = SwaggerUIBundle(swaggerUIOptions)\n  ui.specActions.updateUrl(currentUrl.pathname + \"?format=json\");\n  {oauth2_content}\n&lt;/script&gt;\n&lt;/html&gt;\n            \"\"\".strip()\n</code></pre>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.swagger_ui.oauth2",
            "title": "oauth2",
            "text": "CLASS DESCRIPTION <code>OAuth2Config</code> <p>OAuth2 configuration for Swagger UI</p> FUNCTION DESCRIPTION <code>generate_oauth2_redirect_html</code> <p>Generates the HTML content for the OAuth2 redirect page.</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.swagger_ui.oauth2.OAuth2Config",
            "title": "OAuth2Config",
            "text": "<p>               Bases: <code>BaseModel</code></p> <p>OAuth2 configuration for Swagger UI</p>"
        },
        {
            "location": "api_doc/event_handler/openapi/#aws_lambda_powertools.event_handler.openapi.swagger_ui.oauth2.generate_oauth2_redirect_html",
            "title": "generate_oauth2_redirect_html",
            "text": "<pre><code>generate_oauth2_redirect_html() -&gt; str\n</code></pre> <p>Generates the HTML content for the OAuth2 redirect page.</p> <p>Source: https://github.com/swagger-api/swagger-ui/blob/master/dist/oauth2-redirect.html</p> Source code in <code>aws_lambda_powertools/event_handler/openapi/swagger_ui/oauth2.py</code> <pre><code>def generate_oauth2_redirect_html() -&gt; str:\n    \"\"\"\n    Generates the HTML content for the OAuth2 redirect page.\n\n    Source: https://github.com/swagger-api/swagger-ui/blob/master/dist/oauth2-redirect.html\n    \"\"\"\n    return \"\"\"\n&lt;!doctype html&gt;\n&lt;html lang=\"en-US\"&gt;\n&lt;head&gt;\n    &lt;title&gt;Swagger UI: OAuth2 Redirect&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;script&gt;\n    'use strict';\n    function run () {\n        var oauth2 = window.opener.swaggerUIRedirectOauth2;\n        var sentState = oauth2.state;\n        var redirectUrl = oauth2.redirectUrl;\n        var isValid, qp, arr;\n\n        if (/code|token|error/.test(window.location.hash)) {\n            qp = window.location.hash.substring(1).replace('?', '&amp;');\n        } else {\n            qp = location.search.substring(1);\n        }\n\n        arr = qp.split(\"&amp;\");\n        arr.forEach(function (v,i,_arr) { _arr[i] = '\"' + v.replace('=', '\":\"') + '\"';});\n        qp = qp ? JSON.parse('{' + arr.join() + '}',\n                function (key, value) {\n                    return key === \"\" ? value : decodeURIComponent(value);\n                }\n        ) : {};\n\n        isValid = qp.state === sentState;\n\n        if ((\n          oauth2.auth.schema.get(\"flow\") === \"accessCode\" ||\n          oauth2.auth.schema.get(\"flow\") === \"authorizationCode\" ||\n          oauth2.auth.schema.get(\"flow\") === \"authorization_code\"\n        ) &amp;&amp; !oauth2.auth.code) {\n            if (!isValid) {\n                oauth2.errCb({\n                    authId: oauth2.auth.name,\n                    source: \"auth\",\n                    level: \"warning\",\n                    message: \"Authorization may be unsafe, passed state was changed in server. The passed state wasn't returned from auth server.\"\n                });\n            }\n\n            if (qp.code) {\n                delete oauth2.state;\n                oauth2.auth.code = qp.code;\n                oauth2.callback({auth: oauth2.auth, redirectUrl: redirectUrl});\n            } else {\n                let oauthErrorMsg;\n                if (qp.error) {\n                    oauthErrorMsg = \"[\"+qp.error+\"]: \" +\n                        (qp.error_description ? qp.error_description+ \". \" : \"no accessCode received from the server. \") +\n                        (qp.error_uri ? \"More info: \"+qp.error_uri : \"\");\n                }\n\n                oauth2.errCb({\n                    authId: oauth2.auth.name,\n                    source: \"auth\",\n                    level: \"error\",\n                    message: oauthErrorMsg || \"[Authorization failed]: no accessCode received from the server.\"\n                });\n            }\n        } else {\n            oauth2.callback({auth: oauth2.auth, token: qp, isValid: isValid, redirectUrl: redirectUrl});\n        }\n        window.close();\n    }\n\n    if (document.readyState !== 'loading') {\n        run();\n    } else {\n        document.addEventListener('DOMContentLoaded', function () {\n            run();\n        });\n    }\n&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n    \"\"\".strip()\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/appconfig/",
            "title": "AppConfig",
            "text": "<p>Advanced feature flags utility</p> <p>Usage Documentation</p> <p><code>Feature Flags</code></p> CLASS DESCRIPTION <code>AppConfigStore</code>"
        },
        {
            "location": "api_doc/feature_flags/appconfig/#aws_lambda_powertools.utilities.feature_flags.appconfig.AppConfigStore",
            "title": "AppConfigStore",
            "text": "<pre><code>AppConfigStore(\n    environment: str,\n    application: str,\n    name: str,\n    max_age: int = 5,\n    sdk_config: Config | None = None,\n    envelope: str | None = \"\",\n    jmespath_options: dict | None = None,\n    logger: Logger | Logger | None = None,\n    boto_config: Config | None = None,\n    boto3_session: Session | None = None,\n    boto3_client: AppConfigDataClient | None = None,\n)\n</code></pre> <p>               Bases: <code>StoreProvider</code></p> PARAMETER DESCRIPTION <code>environment</code> <p>Appconfig environment, e.g. 'dev/test' etc.</p> <p> TYPE: <code>str</code> </p> <code>application</code> <p>AppConfig application name, e.g. 'powertools'</p> <p> TYPE: <code>str</code> </p> <code>name</code> <p>AppConfig configuration name e.g. <code>my_conf</code></p> <p> TYPE: <code>str</code> </p> <code>max_age</code> <p>cache expiration time in seconds, or how often to call AppConfig to fetch latest configuration</p> <p> TYPE: <code>int</code> DEFAULT: <code>5</code> </p> <code>sdk_config</code> <p>Botocore Config object to pass during client initialization</p> <p> TYPE: <code>Config | None</code> DEFAULT: <code>None</code> </p> <code>envelope</code> <p>JMESPath expression to pluck feature flags data from config</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>''</code> </p> <code>jmespath_options</code> <p>Alternative JMESPath options to be included when filtering expr</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> <code>logger</code> <p>Used to log messages. If None is supplied, one will be created.</p> <p> TYPE: <code>Logger | Logger | None</code> DEFAULT: <code>None</code> </p> <code>boto_config</code> <p>Botocore configuration to pass during client initialization</p> <p> TYPE: <code>Config | None</code> DEFAULT: <code>None</code> </p> <code>boto3_session</code> <p>Boto3 session to use for AWS API communication</p> <p> TYPE: <code>Session</code> DEFAULT: <code>None</code> </p> <code>boto3_client</code> <p>Boto3 AppConfigDataClient Client to use, boto3_session and boto_config will be ignored if both are provided</p> <p> TYPE: <code>AppConfigDataClient</code> DEFAULT: <code>None</code> </p> METHOD DESCRIPTION <code>get_configuration</code> <p>Fetch feature schema configuration from AWS AppConfig</p> ATTRIBUTE DESCRIPTION <code>get_raw_configuration</code> <p>Fetch feature schema configuration from AWS AppConfig</p> <p> TYPE: <code>dict[str, Any]</code> </p> Source code in <code>aws_lambda_powertools/utilities/feature_flags/appconfig.py</code> <pre><code>def __init__(\n    self,\n    environment: str,\n    application: str,\n    name: str,\n    max_age: int = 5,\n    sdk_config: Config | None = None,\n    envelope: str | None = \"\",\n    jmespath_options: dict | None = None,\n    logger: logging.Logger | Logger | None = None,\n    boto_config: Config | None = None,\n    boto3_session: boto3.session.Session | None = None,\n    boto3_client: AppConfigDataClient | None = None,\n):\n    \"\"\"This class fetches JSON schemas from AWS AppConfig\n\n    Parameters\n    ----------\n    environment: str\n        Appconfig environment, e.g. 'dev/test' etc.\n    application: str\n        AppConfig application name, e.g. 'powertools'\n    name: str\n        AppConfig configuration name e.g. `my_conf`\n    max_age: int\n        cache expiration time in seconds, or how often to call AppConfig to fetch latest configuration\n    sdk_config: Config | None\n        Botocore Config object to pass during client initialization\n    envelope : str | None\n        JMESPath expression to pluck feature flags data from config\n    jmespath_options : dict | None\n        Alternative JMESPath options to be included when filtering expr\n    logger: A logging object\n        Used to log messages. If None is supplied, one will be created.\n    boto_config: botocore.config.Config, optional\n        Botocore configuration to pass during client initialization\n    boto3_session : boto3.Session, optional\n        Boto3 session to use for AWS API communication\n    boto3_client : AppConfigDataClient, optional\n        Boto3 AppConfigDataClient Client to use, boto3_session and boto_config will be ignored if both are provided\n    \"\"\"\n    super().__init__()\n    self.logger = logger or logging.getLogger(__name__)\n    self.environment = environment\n    self.application = application\n    self.name = name\n    self.cache_seconds = max_age\n    self.config = sdk_config or boto_config\n    self.envelope = envelope\n    self.jmespath_options = jmespath_options\n    self._conf_store = AppConfigProvider(\n        environment=environment,\n        application=application,\n        config=sdk_config or boto_config,\n        boto3_client=boto3_client,\n        boto3_session=boto3_session,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/appconfig/#aws_lambda_powertools.utilities.feature_flags.appconfig.AppConfigStore.get_raw_configuration",
            "title": "get_raw_configuration  <code>property</code>",
            "text": "<pre><code>get_raw_configuration: dict[str, Any]\n</code></pre> <p>Fetch feature schema configuration from AWS AppConfig</p>"
        },
        {
            "location": "api_doc/feature_flags/appconfig/#aws_lambda_powertools.utilities.feature_flags.appconfig.AppConfigStore.get_configuration",
            "title": "get_configuration",
            "text": "<pre><code>get_configuration() -&gt; dict[str, Any]\n</code></pre> <p>Fetch feature schema configuration from AWS AppConfig</p> <p>If envelope is set, it'll extract and return feature flags from configuration, otherwise it'll return the entire configuration fetched from AWS AppConfig.</p> RAISES DESCRIPTION <code>ConfigurationStoreError</code> <p>Any validation error or AppConfig error that can occur</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>parsed JSON dictionary</p> Source code in <code>aws_lambda_powertools/utilities/feature_flags/appconfig.py</code> <pre><code>def get_configuration(self) -&gt; dict[str, Any]:\n    \"\"\"Fetch feature schema configuration from AWS AppConfig\n\n    If envelope is set, it'll extract and return feature flags from configuration,\n    otherwise it'll return the entire configuration fetched from AWS AppConfig.\n\n    Raises\n    ------\n    ConfigurationStoreError\n        Any validation error or AppConfig error that can occur\n\n    Returns\n    -------\n    dict[str, Any]\n        parsed JSON dictionary\n    \"\"\"\n    config = self.get_raw_configuration\n\n    if self.envelope:\n        self.logger.debug(\"Envelope enabled; extracting data from config\", extra={\"envelope\": self.envelope})\n        config = jmespath_utils.query(\n            data=config,\n            envelope=self.envelope,\n            jmespath_options=self.jmespath_options,\n        )\n\n    return config\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/base/",
            "title": "Base",
            "text": "CLASS DESCRIPTION <code>StoreProvider</code>"
        },
        {
            "location": "api_doc/feature_flags/base/#aws_lambda_powertools.utilities.feature_flags.base.StoreProvider",
            "title": "StoreProvider",
            "text": "<p>               Bases: <code>ABC</code></p> METHOD DESCRIPTION <code>get_configuration</code> <p>Get configuration from any store and return the parsed JSON dictionary</p> ATTRIBUTE DESCRIPTION <code>get_raw_configuration</code> <p>Get configuration from any store and return the parsed JSON dictionary</p> <p> TYPE: <code>dict[str, Any]</code> </p>"
        },
        {
            "location": "api_doc/feature_flags/base/#aws_lambda_powertools.utilities.feature_flags.base.StoreProvider.get_raw_configuration",
            "title": "get_raw_configuration  <code>abstractmethod</code> <code>property</code>",
            "text": "<pre><code>get_raw_configuration: dict[str, Any]\n</code></pre> <p>Get configuration from any store and return the parsed JSON dictionary</p>"
        },
        {
            "location": "api_doc/feature_flags/base/#aws_lambda_powertools.utilities.feature_flags.base.StoreProvider.get_configuration",
            "title": "get_configuration  <code>abstractmethod</code>",
            "text": "<pre><code>get_configuration() -&gt; dict[str, Any]\n</code></pre> <p>Get configuration from any store and return the parsed JSON dictionary</p> <p>If envelope is set, it'll extract and return feature flags from configuration, otherwise it'll return the entire configuration fetched from the store.</p> RAISES DESCRIPTION <code>ConfigurationStoreError</code> <p>Any error that can occur during schema fetch or JSON parse</p> RETURNS DESCRIPTION <code>dict[str, Any]</code> <p>parsed JSON dictionary</p> Example <pre><code>{\n    \"premium_features\": {\n        \"default\": False,\n        \"rules\": {\n            \"customer tier equals premium\": {\n                \"when_match\": True,\n                \"conditions\": [\n                    {\n                        \"action\": \"EQUALS\",\n                        \"key\": \"tier\",\n                        \"value\": \"premium\",\n                    }\n                ],\n            }\n        },\n    },\n    \"feature_two\": {\n        \"default\": False\n    }\n}\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/feature_flags/base.py</code> <pre><code>@abstractmethod\ndef get_configuration(self) -&gt; dict[str, Any]:\n    \"\"\"Get configuration from any store and return the parsed JSON dictionary\n\n    If envelope is set, it'll extract and return feature flags from configuration,\n    otherwise it'll return the entire configuration fetched from the store.\n\n    Raises\n    ------\n    ConfigurationStoreError\n        Any error that can occur during schema fetch or JSON parse\n\n    Returns\n    -------\n    dict[str, Any]\n        parsed JSON dictionary\n\n    Example\n    -------\n\n    ```python\n    {\n        \"premium_features\": {\n            \"default\": False,\n            \"rules\": {\n                \"customer tier equals premium\": {\n                    \"when_match\": True,\n                    \"conditions\": [\n                        {\n                            \"action\": \"EQUALS\",\n                            \"key\": \"tier\",\n                            \"value\": \"premium\",\n                        }\n                    ],\n                }\n            },\n        },\n        \"feature_two\": {\n            \"default\": False\n        }\n    }\n    ```\n    \"\"\"\n    raise NotImplementedError()  # pragma: no cover\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/comparators/",
            "title": "Comparators",
            "text": "FUNCTION DESCRIPTION <code>compare_all_in_list</code> <p>Comparator for ALL_IN_VALUE action</p> <code>compare_any_in_list</code> <p>Comparator for ANY_IN_VALUE action</p> <code>compare_modulo_range</code> <p>Returns for a given context 'a' and modulo condition 'b' -&gt; b.start &lt;= a % b.base &lt;= b.end</p> <code>compare_none_in_list</code> <p>Comparator for NONE_IN_VALUE action</p>"
        },
        {
            "location": "api_doc/feature_flags/comparators/#aws_lambda_powertools.utilities.feature_flags.comparators.compare_all_in_list",
            "title": "compare_all_in_list",
            "text": "<pre><code>compare_all_in_list(\n    context_value: list, condition_value: list\n) -&gt; bool\n</code></pre> <p>Comparator for ALL_IN_VALUE action</p> PARAMETER DESCRIPTION <code>context_value</code> <p>user-defined context for flag evaluation</p> <p> TYPE: <code>list</code> </p> <code>condition_value</code> <p>schema value available for condition being evaluated</p> <p> TYPE: <code>list</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether all list items in context_value are available in condition_value</p> Source code in <code>aws_lambda_powertools/utilities/feature_flags/comparators.py</code> <pre><code>def compare_all_in_list(context_value: list, condition_value: list) -&gt; bool:\n    \"\"\"Comparator for ALL_IN_VALUE action\n\n    Parameters\n    ----------\n    context_value : list\n        user-defined context for flag evaluation\n    condition_value : list\n        schema value available for condition being evaluated\n\n    Returns\n    -------\n    bool\n        Whether all list items in context_value are available in condition_value\n    \"\"\"\n    if not isinstance(context_value, list):\n        raise ValueError(\"Context provided must be a list. Unable to compare ALL_IN_VALUE action.\")\n\n    return all(key in condition_value for key in context_value)\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/comparators/#aws_lambda_powertools.utilities.feature_flags.comparators.compare_any_in_list",
            "title": "compare_any_in_list",
            "text": "<pre><code>compare_any_in_list(\n    context_value: list, condition_value: list\n) -&gt; bool\n</code></pre> <p>Comparator for ANY_IN_VALUE action</p> PARAMETER DESCRIPTION <code>context_value</code> <p>user-defined context for flag evaluation</p> <p> TYPE: <code>list</code> </p> <code>condition_value</code> <p>schema value available for condition being evaluated</p> <p> TYPE: <code>list</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether any list item in context_value is available in condition_value</p> Source code in <code>aws_lambda_powertools/utilities/feature_flags/comparators.py</code> <pre><code>def compare_any_in_list(context_value: list, condition_value: list) -&gt; bool:\n    \"\"\"Comparator for ANY_IN_VALUE action\n\n    Parameters\n    ----------\n    context_value : list\n        user-defined context for flag evaluation\n    condition_value : list\n        schema value available for condition being evaluated\n\n    Returns\n    -------\n    bool\n        Whether any list item in context_value is available in condition_value\n    \"\"\"\n    if not isinstance(context_value, list):\n        raise ValueError(\"Context provided must be a list. Unable to compare ANY_IN_VALUE action.\")\n\n    return any(key in condition_value for key in context_value)\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/comparators/#aws_lambda_powertools.utilities.feature_flags.comparators.compare_modulo_range",
            "title": "compare_modulo_range",
            "text": "<pre><code>compare_modulo_range(\n    context_value: int, condition_value: dict\n) -&gt; bool\n</code></pre> <p>Returns for a given context 'a' and modulo condition 'b' -&gt; b.start &lt;= a % b.base &lt;= b.end</p> Source code in <code>aws_lambda_powertools/utilities/feature_flags/comparators.py</code> <pre><code>def compare_modulo_range(context_value: int, condition_value: dict) -&gt; bool:\n    \"\"\"\n    Returns for a given context 'a' and modulo condition 'b' -&gt; b.start &lt;= a % b.base &lt;= b.end\n    \"\"\"\n    base = condition_value.get(ModuloRangeValues.BASE.value, 1)\n    start = condition_value.get(ModuloRangeValues.START.value, 1)\n    end = condition_value.get(ModuloRangeValues.END.value, 1)\n\n    return start &lt;= context_value % base &lt;= end\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/comparators/#aws_lambda_powertools.utilities.feature_flags.comparators.compare_none_in_list",
            "title": "compare_none_in_list",
            "text": "<pre><code>compare_none_in_list(\n    context_value: list, condition_value: list\n) -&gt; bool\n</code></pre> <p>Comparator for NONE_IN_VALUE action</p> PARAMETER DESCRIPTION <code>context_value</code> <p>user-defined context for flag evaluation</p> <p> TYPE: <code>list</code> </p> <code>condition_value</code> <p>schema value available for condition being evaluated</p> <p> TYPE: <code>list</code> </p> RETURNS DESCRIPTION <code>bool</code> <p>Whether list items in context_value are not available in condition_value</p> Source code in <code>aws_lambda_powertools/utilities/feature_flags/comparators.py</code> <pre><code>def compare_none_in_list(context_value: list, condition_value: list) -&gt; bool:\n    \"\"\"Comparator for NONE_IN_VALUE action\n\n    Parameters\n    ----------\n    context_value : list\n        user-defined context for flag evaluation\n    condition_value : list\n        schema value available for condition being evaluated\n\n    Returns\n    -------\n    bool\n        Whether list items in context_value are **not** available in condition_value\n    \"\"\"\n    if not isinstance(context_value, list):\n        raise ValueError(\"Context provided must be a list. Unable to compare NONE_IN_VALUE action.\")\n\n    return all(key not in condition_value for key in context_value)\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/exceptions/",
            "title": "Exceptions",
            "text": "CLASS DESCRIPTION <code>ConfigurationStoreError</code> <p>When a configuration store raises an exception on config retrieval or parsing</p> <code>SchemaValidationError</code> <p>When feature flag schema fails validation</p> <code>StoreClientError</code> <p>When a store raises an exception that should be propagated to the client</p>"
        },
        {
            "location": "api_doc/feature_flags/exceptions/#aws_lambda_powertools.utilities.feature_flags.exceptions.ConfigurationStoreError",
            "title": "ConfigurationStoreError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>When a configuration store raises an exception on config retrieval or parsing</p>"
        },
        {
            "location": "api_doc/feature_flags/exceptions/#aws_lambda_powertools.utilities.feature_flags.exceptions.SchemaValidationError",
            "title": "SchemaValidationError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>When feature flag schema fails validation</p>"
        },
        {
            "location": "api_doc/feature_flags/exceptions/#aws_lambda_powertools.utilities.feature_flags.exceptions.StoreClientError",
            "title": "StoreClientError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>When a store raises an exception that should be propagated to the client</p> <p>For example, Access Denied errors when the client doesn't permissions to fetch config</p>"
        },
        {
            "location": "api_doc/feature_flags/feature_flags/",
            "title": "Feature flags",
            "text": "CLASS DESCRIPTION <code>FeatureFlags</code>"
        },
        {
            "location": "api_doc/feature_flags/feature_flags/#aws_lambda_powertools.utilities.feature_flags.feature_flags.FeatureFlags",
            "title": "FeatureFlags",
            "text": "<pre><code>FeatureFlags(\n    store: StoreProvider,\n    logger: Logger | Logger | None = None,\n)\n</code></pre> <p>It uses the provided store to fetch feature flag rules before evaluating them.</p> <p>Examples:</p> <pre><code>from aws_lambda_powertools.utilities.feature_flags import FeatureFlags, AppConfigStore\n\napp_config = AppConfigStore(\n    environment=\"test\",\n    application=\"powertools\",\n    name=\"test_conf_name\",\n    max_age=300,\n    envelope=\"features\"\n)\n\nfeature_flags: FeatureFlags = FeatureFlags(store=app_config)\n</code></pre> PARAMETER DESCRIPTION <code>store</code> <p>Store to use to fetch feature flag schema configuration.</p> <p> TYPE: <code>StoreProvider</code> </p> <code>logger</code> <p>Used to log messages. If None is supplied, one will be created.</p> <p> TYPE: <code>Logger | Logger | None</code> DEFAULT: <code>None</code> </p> METHOD DESCRIPTION <code>evaluate</code> <p>Evaluate whether a feature flag should be enabled according to stored schema and input context</p> <code>get_configuration</code> <p>Get validated feature flag schema from configured store.</p> <code>get_enabled_features</code> <p>Get all enabled feature flags while also taking into account context</p> <code>validation_exception_handler</code> <p>Registers function to handle unexpected validation exceptions when evaluating flags.</p> Source code in <code>aws_lambda_powertools/utilities/feature_flags/feature_flags.py</code> <pre><code>def __init__(self, store: StoreProvider, logger: logging.Logger | Logger | None = None):\n    \"\"\"Evaluates whether feature flags should be enabled based on a given context.\n\n    It uses the provided store to fetch feature flag rules before evaluating them.\n\n    Examples\n    --------\n\n    ```python\n    from aws_lambda_powertools.utilities.feature_flags import FeatureFlags, AppConfigStore\n\n    app_config = AppConfigStore(\n        environment=\"test\",\n        application=\"powertools\",\n        name=\"test_conf_name\",\n        max_age=300,\n        envelope=\"features\"\n    )\n\n    feature_flags: FeatureFlags = FeatureFlags(store=app_config)\n    ```\n\n    Parameters\n    ----------\n    store: StoreProvider\n        Store to use to fetch feature flag schema configuration.\n    logger: A logging object\n        Used to log messages. If None is supplied, one will be created.\n    \"\"\"\n    self.store = store\n    self.logger = logger or logging.getLogger(__name__)\n    self._exception_handlers: dict[Exception, Callable] = {}\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/feature_flags/#aws_lambda_powertools.utilities.feature_flags.feature_flags.FeatureFlags.evaluate",
            "title": "evaluate",
            "text": "<pre><code>evaluate(\n    *,\n    name: str,\n    context: dict[str, Any] | None = None,\n    default: JSONType\n) -&gt; JSONType\n</code></pre> <p>Evaluate whether a feature flag should be enabled according to stored schema and input context</p> <p>Logic when evaluating a feature flag</p> <ol> <li>Feature exists and a rule matches, returns when_match value</li> <li>Feature exists but has either no rules or no match, return feature default value</li> <li>Feature doesn't exist in stored schema, encountered an error when fetching -&gt; return default value provided</li> </ol> <p>┌────────────────────────┐      ┌────────────────────────┐       ┌────────────────────────┐ │     Feature flags      │──────▶   Get Configuration    ├───────▶     Evaluate rules     │ └────────────────────────┘      │                        │       │                        │                                 │┌──────────────────────┐│       │┌──────────────────────┐│                                 ││     Fetch schema     ││       ││      Match rule      ││                                 │└───────────┬──────────┘│       │└───────────┬──────────┘│                                 │            │           │       │            │           │                                 │┌───────────▼──────────┐│       │┌───────────▼──────────┐│                                 ││     Cache schema     ││       ││   Match condition    ││                                 │└───────────┬──────────┘│       │└───────────┬──────────┘│                                 │            │           │       │            │           │                                 │┌───────────▼──────────┐│       │┌───────────▼──────────┐│                                 ││   Validate schema    ││       ││     Match action     ││                                 │└──────────────────────┘│       │└──────────────────────┘│                                 └────────────────────────┘       └────────────────────────┘</p> PARAMETER DESCRIPTION <code>name</code> <p>feature name to evaluate</p> <p> TYPE: <code>str</code> </p> <code>context</code> <p>Attributes that should be evaluated against the stored schema.</p> <p>for example: <code>{\"tenant_id\": \"X\", \"username\": \"Y\", \"region\": \"Z\"}</code></p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> <code>default</code> <p>default value if feature flag doesn't exist in the schema, or there has been an error when fetching the configuration from the store Can be boolean or any JSON values for non-boolean features.</p> <p> TYPE: <code>JSONType</code> </p> Example <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    # Get customer's tier from incoming request\n    ctx = {\"tier\": event.get(\"tier\", \"standard\")}\n\n    # Evaluate whether customer's tier has access to premium features\n    # based on `has_premium_features` rules\n    has_premium_features: bool = feature_flags.evaluate(name=\"premium_features\", context=ctx, default=False)\n    if has_premium_features:\n        # enable premium features\n        ...\n</code></pre> RETURNS DESCRIPTION <code>JSONType</code> <p>whether feature should be enabled (bool flags) or JSON value when non-bool feature matches</p> RAISES DESCRIPTION <code>SchemaValidationError</code> <p>When schema doesn't conform with feature flag schema</p> Source code in <code>aws_lambda_powertools/utilities/feature_flags/feature_flags.py</code> <pre><code>def evaluate(self, *, name: str, context: dict[str, Any] | None = None, default: JSONType) -&gt; JSONType:\n    \"\"\"Evaluate whether a feature flag should be enabled according to stored schema and input context\n\n    **Logic when evaluating a feature flag**\n\n    1. Feature exists and a rule matches, returns when_match value\n    2. Feature exists but has either no rules or no match, return feature default value\n    3. Feature doesn't exist in stored schema, encountered an error when fetching -&gt; return default value provided\n\n    ┌────────────────────────┐      ┌────────────────────────┐       ┌────────────────────────┐\n    │     Feature flags      │──────▶   Get Configuration    ├───────▶     Evaluate rules     │\n    └────────────────────────┘      │                        │       │                        │\n                                    │┌──────────────────────┐│       │┌──────────────────────┐│\n                                    ││     Fetch schema     ││       ││      Match rule      ││\n                                    │└───────────┬──────────┘│       │└───────────┬──────────┘│\n                                    │            │           │       │            │           │\n                                    │┌───────────▼──────────┐│       │┌───────────▼──────────┐│\n                                    ││     Cache schema     ││       ││   Match condition    ││\n                                    │└───────────┬──────────┘│       │└───────────┬──────────┘│\n                                    │            │           │       │            │           │\n                                    │┌───────────▼──────────┐│       │┌───────────▼──────────┐│\n                                    ││   Validate schema    ││       ││     Match action     ││\n                                    │└──────────────────────┘│       │└──────────────────────┘│\n                                    └────────────────────────┘       └────────────────────────┘\n\n    Parameters\n    ----------\n    name: str\n        feature name to evaluate\n    context: dict[str, Any] | None\n        Attributes that should be evaluated against the stored schema.\n\n        for example: `{\"tenant_id\": \"X\", \"username\": \"Y\", \"region\": \"Z\"}`\n    default: JSONType\n        default value if feature flag doesn't exist in the schema,\n        or there has been an error when fetching the configuration from the store\n        Can be boolean or any JSON values for non-boolean features.\n\n\n    Example\n    --------\n\n    ```python\n    from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\n    from aws_lambda_powertools.utilities.typing import LambdaContext\n\n    app_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\n    feature_flags = FeatureFlags(store=app_config)\n\n\n    def lambda_handler(event: dict, context: LambdaContext):\n        # Get customer's tier from incoming request\n        ctx = {\"tier\": event.get(\"tier\", \"standard\")}\n\n        # Evaluate whether customer's tier has access to premium features\n        # based on `has_premium_features` rules\n        has_premium_features: bool = feature_flags.evaluate(name=\"premium_features\", context=ctx, default=False)\n        if has_premium_features:\n            # enable premium features\n            ...\n    ```\n\n    Returns\n    ------\n    JSONType\n        whether feature should be enabled (bool flags) or JSON value when non-bool feature matches\n\n    Raises\n    ------\n    SchemaValidationError\n        When schema doesn't conform with feature flag schema\n    \"\"\"\n    if context is None:\n        context = {}\n\n    try:\n        features = self.get_configuration()\n    except ConfigurationStoreError as err:\n        self.logger.debug(f\"Failed to fetch feature flags from store, returning default provided, reason={err}\")\n        return default\n\n    feature = features.get(name)\n    if feature is None:\n        self.logger.debug(f\"Feature not found; returning default provided, name={name}, default={default}\")\n        return default\n\n    rules = feature.get(schema.RULES_KEY)\n    feat_default = feature.get(schema.FEATURE_DEFAULT_VAL_KEY)\n    # Maintenance: Revisit before going GA. We might to simplify customers on-boarding by not requiring it\n    # for non-boolean flags. It'll need minor implementation changes, docs changes, and maybe refactor\n    # get_enabled_features. We can minimize breaking change, despite Beta label, by having a new\n    # method `get_matching_features` returning dict[feature_name, feature_value]\n    boolean_feature = feature.get(\n        schema.FEATURE_DEFAULT_VAL_TYPE_KEY,\n        True,\n    )  # backwards compatibility, assume feature flag\n    if not rules:\n        self.logger.debug(\n            f\"no rules found, returning feature default, name={name}, default={str(feat_default)}, boolean_feature={boolean_feature}\",  # noqa: E501\n        )\n        # Maintenance: Revisit before going GA. We might to simplify customers on-boarding by not requiring it\n        # for non-boolean flags.\n        return bool(feat_default) if boolean_feature else feat_default\n\n    self.logger.debug(\n        f\"looking for rule match, name={name}, default={str(feat_default)}, boolean_feature={boolean_feature}\",  # noqa: E501\n    )\n    return self._evaluate_rules(\n        feature_name=name,\n        context=context,\n        feat_default=feat_default,\n        rules=rules,\n        boolean_feature=boolean_feature,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/feature_flags/#aws_lambda_powertools.utilities.feature_flags.feature_flags.FeatureFlags.get_configuration",
            "title": "get_configuration",
            "text": "<pre><code>get_configuration() -&gt; dict\n</code></pre> <p>Get validated feature flag schema from configured store.</p> <p>Largely used to aid testing, since it's called by <code>evaluate</code> and <code>get_enabled_features</code> methods.</p> RAISES DESCRIPTION <code>ConfigurationStoreError</code> <p>Any propagated error from store</p> <code>SchemaValidationError</code> <p>When schema doesn't conform with feature flag schema</p> RETURNS DESCRIPTION <code>dict[str, dict]</code> <p>parsed JSON dictionary</p> Example <pre><code>{\n    \"premium_features\": {\n        \"default\": False,\n        \"rules\": {\n            \"customer tier equals premium\": {\n                \"when_match\": True,\n                \"conditions\": [\n                    {\n                        \"action\": \"EQUALS\",\n                        \"key\": \"tier\",\n                        \"value\": \"premium\",\n                    }\n                ],\n            }\n        },\n    },\n    \"feature_two\": {\n        \"default\": False\n    }\n}\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/feature_flags/feature_flags.py</code> <pre><code>def get_configuration(self) -&gt; dict:\n    \"\"\"Get validated feature flag schema from configured store.\n\n    Largely used to aid testing, since it's called by `evaluate` and `get_enabled_features` methods.\n\n    Raises\n    ------\n    ConfigurationStoreError\n        Any propagated error from store\n    SchemaValidationError\n        When schema doesn't conform with feature flag schema\n\n    Returns\n    ------\n    dict[str, dict]\n        parsed JSON dictionary\n\n    Example\n    -------\n\n    ```python\n    {\n        \"premium_features\": {\n            \"default\": False,\n            \"rules\": {\n                \"customer tier equals premium\": {\n                    \"when_match\": True,\n                    \"conditions\": [\n                        {\n                            \"action\": \"EQUALS\",\n                            \"key\": \"tier\",\n                            \"value\": \"premium\",\n                        }\n                    ],\n                }\n            },\n        },\n        \"feature_two\": {\n            \"default\": False\n        }\n    }\n    ```\n    \"\"\"\n    # parse result conf as JSON, keep in cache for max age defined in store\n    self.logger.debug(f\"Fetching schema from registered store, store={self.store}\")\n    config: dict = self.store.get_configuration()\n    validator = schema.SchemaValidator(schema=config, logger=self.logger)\n    validator.validate()\n\n    return config\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/feature_flags/#aws_lambda_powertools.utilities.feature_flags.feature_flags.FeatureFlags.get_enabled_features",
            "title": "get_enabled_features",
            "text": "<pre><code>get_enabled_features(\n    *, context: dict[str, Any] | None = None\n) -&gt; list[str]\n</code></pre> <p>Get all enabled feature flags while also taking into account context (when a feature has defined rules)</p> PARAMETER DESCRIPTION <code>context</code> <p>dict of attributes that you would like to match the rules against, can be <code>{'tenant_id: 'X', 'username':' 'Y', 'region': 'Z'}</code> etc.</p> <p> TYPE: <code>dict[str, Any] | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>list[str]</code> <p>list of all feature names that either matches context or have True as default</p> Example <pre><code>[\"premium_features\", \"my_feature_two\", \"always_true_feature\"]\n</code></pre> RAISES DESCRIPTION <code>SchemaValidationError</code> <p>When schema doesn't conform with feature flag schema</p> Source code in <code>aws_lambda_powertools/utilities/feature_flags/feature_flags.py</code> <pre><code>def get_enabled_features(self, *, context: dict[str, Any] | None = None) -&gt; list[str]:\n    \"\"\"Get all enabled feature flags while also taking into account context\n    (when a feature has defined rules)\n\n    Parameters\n    ----------\n    context: dict[str, Any] | None\n        dict of attributes that you would like to match the rules\n        against, can be `{'tenant_id: 'X', 'username':' 'Y', 'region': 'Z'}` etc.\n\n    Returns\n    ----------\n    list[str]\n        list of all feature names that either matches context or have True as default\n\n    Example\n    -------\n\n    ```python\n    [\"premium_features\", \"my_feature_two\", \"always_true_feature\"]\n    ```\n\n    Raises\n    ------\n    SchemaValidationError\n        When schema doesn't conform with feature flag schema\n    \"\"\"\n    if context is None:\n        context = {}\n\n    features_enabled: list[str] = []\n\n    try:\n        features: dict[str, Any] = self.get_configuration()\n    except ConfigurationStoreError as err:\n        self.logger.debug(f\"Failed to fetch feature flags from store, returning empty list, reason={err}\")\n        return features_enabled\n\n    self.logger.debug(\"Evaluating all features\")\n    for name, feature in features.items():\n        rules = feature.get(schema.RULES_KEY, {})\n        feature_default_value = feature.get(schema.FEATURE_DEFAULT_VAL_KEY)\n        boolean_feature = feature.get(\n            schema.FEATURE_DEFAULT_VAL_TYPE_KEY,\n            True,\n        )  # backwards compatibility, assume feature flag\n\n        if feature_default_value and not rules:\n            self.logger.debug(f\"feature is enabled by default and has no defined rules, name={name}\")\n            features_enabled.append(name)\n        elif self._evaluate_rules(\n            feature_name=name,\n            context=context,\n            feat_default=feature_default_value,\n            rules=rules,\n            boolean_feature=boolean_feature,\n        ):\n            self.logger.debug(f\"feature's calculated value is True, name={name}\")\n            features_enabled.append(name)\n\n    return features_enabled\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/feature_flags/#aws_lambda_powertools.utilities.feature_flags.feature_flags.FeatureFlags.validation_exception_handler",
            "title": "validation_exception_handler",
            "text": "<pre><code>validation_exception_handler(\n    exc_class: Exception | list[Exception],\n)\n</code></pre> <p>Registers function to handle unexpected validation exceptions when evaluating flags.</p> <p>It does not override the function of a default flag value in case of network and IAM permissions. For example, you won't be able to catch ConfigurationStoreError exception.</p> PARAMETER DESCRIPTION <code>exc_class</code> <p>One or more exceptions to catch</p> <p> TYPE: <code>Exception | list[Exception]</code> </p> Example <pre><code>feature_flags = FeatureFlags(store=app_config)\n\n@feature_flags.validation_exception_handler(Exception)  # any exception\ndef catch_exception(exc):\n    raise TypeError(\"re-raised\") from exc\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/feature_flags/feature_flags.py</code> <pre><code>def validation_exception_handler(self, exc_class: Exception | list[Exception]):\n    \"\"\"Registers function to handle unexpected validation exceptions when evaluating flags.\n\n    It does not override the function of a default flag value in case of network and IAM permissions.\n    For example, you won't be able to catch ConfigurationStoreError exception.\n\n    Parameters\n    ----------\n    exc_class : Exception | list[Exception]\n        One or more exceptions to catch\n\n    Example\n    -------\n\n    ```python\n    feature_flags = FeatureFlags(store=app_config)\n\n    @feature_flags.validation_exception_handler(Exception)  # any exception\n    def catch_exception(exc):\n        raise TypeError(\"re-raised\") from exc\n    ```\n    \"\"\"\n\n    def register_exception_handler(func: Callable[P, T]) -&gt; Callable[P, T]:\n        if isinstance(exc_class, list):\n            for exp in exc_class:\n                self._exception_handlers[exp] = func\n        else:\n            self._exception_handlers[exc_class] = func\n\n        return func\n\n    return register_exception_handler\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/schema/",
            "title": "Schema",
            "text": "CLASS DESCRIPTION <code>FeaturesValidator</code> <p>Validates each feature and calls RulesValidator to validate its rules</p> <code>ModuloRangeValues</code> <p>Possible values when using modulo range rule</p> <code>RulesValidator</code> <p>Validates each rule and calls ConditionsValidator to validate each rule's conditions</p> <code>SchemaValidator</code> <p>Validates feature flag schema configuration</p> <code>TimeKeys</code> <p>Possible keys when using time rules</p> <code>TimeValues</code> <p>Possible values when using time rules</p>"
        },
        {
            "location": "api_doc/feature_flags/schema/#aws_lambda_powertools.utilities.feature_flags.schema.FeaturesValidator",
            "title": "FeaturesValidator",
            "text": "<pre><code>FeaturesValidator(\n    schema: dict, logger: Logger | Logger | None = None\n)\n</code></pre> <p>               Bases: <code>BaseValidator</code></p> <p>Validates each feature and calls RulesValidator to validate its rules</p> Source code in <code>aws_lambda_powertools/utilities/feature_flags/schema.py</code> <pre><code>def __init__(self, schema: dict, logger: logging.Logger | Logger | None = None):\n    self.schema = schema\n    self.logger = logger or LOGGER\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/schema/#aws_lambda_powertools.utilities.feature_flags.schema.ModuloRangeValues",
            "title": "ModuloRangeValues",
            "text": "<p>               Bases: <code>Enum</code></p> <p>Possible values when using modulo range rule</p>"
        },
        {
            "location": "api_doc/feature_flags/schema/#aws_lambda_powertools.utilities.feature_flags.schema.RulesValidator",
            "title": "RulesValidator",
            "text": "<pre><code>RulesValidator(\n    feature: dict[str, Any],\n    boolean_feature: bool,\n    logger: Logger | Logger | None = None,\n)\n</code></pre> <p>               Bases: <code>BaseValidator</code></p> <p>Validates each rule and calls ConditionsValidator to validate each rule's conditions</p> Source code in <code>aws_lambda_powertools/utilities/feature_flags/schema.py</code> <pre><code>def __init__(\n    self,\n    feature: dict[str, Any],\n    boolean_feature: bool,\n    logger: logging.Logger | Logger | None = None,\n):\n    self.feature = feature\n    self.feature_name = next(iter(self.feature))\n    self.rules: dict | None = self.feature.get(RULES_KEY)\n    self.logger = logger or LOGGER\n    self.boolean_feature = boolean_feature\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/schema/#aws_lambda_powertools.utilities.feature_flags.schema.SchemaValidator",
            "title": "SchemaValidator",
            "text": "<pre><code>SchemaValidator(\n    schema: dict[str, Any],\n    logger: Logger | Logger | None = None,\n)\n</code></pre> <p>               Bases: <code>BaseValidator</code></p> <p>Validates feature flag schema configuration</p> RAISES DESCRIPTION <code>SchemaValidationError</code> <p>When schema doesn't conform with feature flag schema</p> Schema <p>Feature object</p> <p>A dictionary containing default value and rules for matching. The value MUST be an object and MIGHT contain the following members:</p> <ul> <li>default: <code>bool | JSONType</code>. Defines default feature value. This MUST be present</li> <li>boolean_type: bool. Defines whether feature has non-boolean value (<code>JSONType</code>). This MIGHT be present</li> <li>rules: <code>dict[str, dict]</code>. Rules object. This MIGHT be present</li> </ul> <p><code>JSONType</code> being any JSON primitive value: <code>str | int | float | bool | None | dict[str, Any] | list[Any]</code></p> <pre><code>{\n    \"my_feature\": {\n        \"default\": true,\n        \"rules\": {}\n    },\n    \"my_non_boolean_feature\": {\n        \"default\": {\"group\": \"read-only\"},\n        \"boolean_type\": false,\n        \"rules\": {}\n    }\n}\n</code></pre> <p>Rules object</p> <p>A dictionary with each rule and their conditions that a feature might have. The value MIGHT be present, and when defined it MUST contain the following members:</p> <ul> <li>when_match: <code>bool | JSONType</code>. Defines value to return when context matches conditions</li> <li>conditions: <code>list[dict]</code>. Conditions object. This MUST be present</li> </ul> <pre><code>{\n    \"my_feature\": {\n        \"default\": true,\n        \"rules\": {\n            \"tenant id equals 345345435\": {\n                \"when_match\": false,\n                \"conditions\": []\n            }\n        }\n    },\n    \"my_non_boolean_feature\": {\n        \"default\": {\"group\": \"read-only\"},\n        \"boolean_type\": false,\n        \"rules\": {\n            \"tenant id equals 345345435\": {\n                \"when_match\": {\"group\": \"admin\"},\n                \"conditions\": []\n            }\n        }\n    }\n}\n</code></pre> <p>Conditions object</p> <p>A list of dictionaries containing conditions for a given rule. The value MUST contain the following members:</p> <ul> <li> <p>action: <code>str</code>. Operation to perform to match a key and value. The value MUST be either EQUALS, STARTSWITH, ENDSWITH, KEY_IN_VALUE KEY_NOT_IN_VALUE VALUE_IN_KEY VALUE_NOT_IN_KEY</p> </li> <li> <p>key: <code>str</code>. Key in given context to perform operation</p> </li> <li>value: <code>Any</code>. Value in given context that should match action operation.</li> </ul> <pre><code>{\n    \"my_feature\": {\n        \"default\": true,\n        \"rules\": {\n            \"tenant id equals 345345435\": {\n                \"when_match\": false,\n                \"conditions\": [\n                    {\n                        \"action\": \"EQUALS\",\n                        \"key\": \"tenant_id\",\n                        \"value\": \"345345435\",\n                    }\n                ]\n            }\n        }\n    }\n}\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/feature_flags/schema.py</code> <pre><code>def __init__(self, schema: dict[str, Any], logger: logging.Logger | Logger | None = None):\n    self.schema = schema\n    self.logger = logger or LOGGER\n\n    # Validators are designed for modular testing\n    # therefore we link the custom logger with global LOGGER\n    # so custom validators can use them when necessary\n    SchemaValidator._link_global_logger(self.logger)\n</code></pre>"
        },
        {
            "location": "api_doc/feature_flags/schema/#aws_lambda_powertools.utilities.feature_flags.schema.TimeKeys",
            "title": "TimeKeys",
            "text": "<p>               Bases: <code>Enum</code></p> <p>Possible keys when using time rules</p>"
        },
        {
            "location": "api_doc/feature_flags/schema/#aws_lambda_powertools.utilities.feature_flags.schema.TimeValues",
            "title": "TimeValues",
            "text": "<p>               Bases: <code>Enum</code></p> <p>Possible values when using time rules</p>"
        },
        {
            "location": "api_doc/idempotency/base/",
            "title": "Base",
            "text": "<p>Base for Idempotency utility</p> <p>Usage Documentation</p> <p><code>Idempotency</code></p> CLASS DESCRIPTION <code>IdempotencyHandler</code> <p>Base class to orchestrate calls to persistence layer.</p>"
        },
        {
            "location": "api_doc/idempotency/base/#aws_lambda_powertools.utilities.idempotency.base.IdempotencyHandler",
            "title": "IdempotencyHandler",
            "text": "<pre><code>IdempotencyHandler(\n    function: Callable,\n    function_payload: Any,\n    config: IdempotencyConfig,\n    persistence_store: BasePersistenceLayer,\n    output_serializer: (\n        BaseIdempotencySerializer | None\n    ) = None,\n    key_prefix: str | None = None,\n    function_args: tuple | None = None,\n    function_kwargs: dict | None = None,\n)\n</code></pre> <p>Base class to orchestrate calls to persistence layer.</p> PARAMETER DESCRIPTION <code>function_payload</code> <p>JSON Serializable payload to be hashed</p> <p> TYPE: <code>Any</code> </p> <code>config</code> <p>Idempotency Configuration</p> <p> TYPE: <code>IdempotencyConfig</code> </p> <code>persistence_store</code> <p>Instance of persistence layer to store idempotency records</p> <p> TYPE: <code>BasePersistenceLayer</code> </p> <code>output_serializer</code> <p>Serializer to transform the data to and from a dictionary. If not supplied, no serialization is done via the NoOpSerializer</p> <p> TYPE: <code>BaseIdempotencySerializer | None</code> DEFAULT: <code>None</code> </p> <code>key_prefix</code> <p>Custom prefix for idempotency key: key_prefix#hash</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>function_args</code> <p>Function arguments</p> <p> TYPE: <code>tuple | None</code> DEFAULT: <code>None</code> </p> <code>function_kwargs</code> <p>Function keyword arguments</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> METHOD DESCRIPTION <code>handle</code> <p>Main entry point for handling idempotent execution of a function.</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/base.py</code> <pre><code>def __init__(\n    self,\n    function: Callable,\n    function_payload: Any,\n    config: IdempotencyConfig,\n    persistence_store: BasePersistenceLayer,\n    output_serializer: BaseIdempotencySerializer | None = None,\n    key_prefix: str | None = None,\n    function_args: tuple | None = None,\n    function_kwargs: dict | None = None,\n):\n    \"\"\"\n    Initialize the IdempotencyHandler\n\n    Parameters\n    ----------\n    function_payload: Any\n        JSON Serializable payload to be hashed\n    config: IdempotencyConfig\n        Idempotency Configuration\n    persistence_store : BasePersistenceLayer\n        Instance of persistence layer to store idempotency records\n    output_serializer: BaseIdempotencySerializer | None\n        Serializer to transform the data to and from a dictionary.\n        If not supplied, no serialization is done via the NoOpSerializer\n    key_prefix: str | Optional\n        Custom prefix for idempotency key: key_prefix#hash\n    function_args: tuple | None\n        Function arguments\n    function_kwargs: dict | None\n        Function keyword arguments\n    \"\"\"\n    self.function = function\n    self.output_serializer = output_serializer or NoOpSerializer()\n    self.data = deepcopy(_prepare_data(function_payload))\n    self.fn_args = function_args\n    self.fn_kwargs = function_kwargs\n    self.config = config\n    self.key_prefix = key_prefix\n\n    persistence_store.configure(\n        config=config,\n        function_name=f\"{self.function.__module__}.{self.function.__qualname__}\",\n        key_prefix=self.key_prefix,\n    )\n\n    self.persistence_store = persistence_store\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/base/#aws_lambda_powertools.utilities.idempotency.base.IdempotencyHandler.handle",
            "title": "handle",
            "text": "<pre><code>handle() -&gt; Any\n</code></pre> <p>Main entry point for handling idempotent execution of a function.</p> RETURNS DESCRIPTION <code>Any</code> <p>Function response</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/base.py</code> <pre><code>def handle(self) -&gt; Any:\n    \"\"\"\n    Main entry point for handling idempotent execution of a function.\n\n    Returns\n    -------\n    Any\n        Function response\n\n    \"\"\"\n    # IdempotencyInconsistentStateError can happen under rare but expected cases\n    # when persistent state changes in the small time between put &amp; get requests.\n    # In most cases we can retry successfully on this exception.\n    for i in range(MAX_RETRIES + 1):  # pragma: no cover\n        try:\n            return self._process_idempotency()\n        except IdempotencyInconsistentStateError:\n            if i == MAX_RETRIES:\n                raise  # Bubble up when exceeded max tries\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/config/",
            "title": "Config",
            "text": "CLASS DESCRIPTION <code>IdempotencyConfig</code>"
        },
        {
            "location": "api_doc/idempotency/config/#aws_lambda_powertools.utilities.idempotency.config.IdempotencyConfig",
            "title": "IdempotencyConfig",
            "text": "<pre><code>IdempotencyConfig(\n    event_key_jmespath: str = \"\",\n    payload_validation_jmespath: str = \"\",\n    jmespath_options: dict | None = None,\n    raise_on_no_idempotency_key: bool = False,\n    expires_after_seconds: int = 60 * 60,\n    use_local_cache: bool = False,\n    local_cache_max_items: int = 256,\n    hash_function: str = \"md5\",\n    lambda_context: LambdaContext | None = None,\n    response_hook: IdempotentHookFunction | None = None,\n)\n</code></pre> PARAMETER DESCRIPTION <code>event_key_jmespath</code> <p>A jmespath expression to extract the idempotency key from the event record</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>payload_validation_jmespath</code> <p>A jmespath expression to extract the payload to be validated from the event record</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>raise_on_no_idempotency_key</code> <p>Raise exception if no idempotency key was found in the request, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>expires_after_seconds</code> <p>The number of seconds to wait before a record is expired</p> <p> TYPE: <code>int</code> DEFAULT: <code>60 * 60</code> </p> <code>use_local_cache</code> <p>Whether to locally cache idempotency results, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>local_cache_max_items</code> <p>Max number of items to store in local cache, by default 1024</p> <p> TYPE: <code>int</code> DEFAULT: <code>256</code> </p> <code>hash_function</code> <p>Function to use for calculating hashes, by default md5.</p> <p> TYPE: <code>str</code> DEFAULT: <code>'md5'</code> </p> <code>lambda_context</code> <p>Lambda Context containing information about the invocation, function and execution environment.</p> <p> TYPE: <code>LambdaContext | None</code> DEFAULT: <code>None</code> </p> <code>response_hook</code> <p>Hook function to be called when an idempotent response is returned from the idempotent store.</p> <p> TYPE: <code>IdempotentHookFunction | None</code> DEFAULT: <code>None</code> </p> METHOD DESCRIPTION <code>register_lambda_context</code> <p>Captures the Lambda context, to calculate the remaining time before the invocation times out</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/config.py</code> <pre><code>def __init__(\n    self,\n    event_key_jmespath: str = \"\",\n    payload_validation_jmespath: str = \"\",\n    jmespath_options: dict | None = None,\n    raise_on_no_idempotency_key: bool = False,\n    expires_after_seconds: int = 60 * 60,  # 1 hour default\n    use_local_cache: bool = False,\n    local_cache_max_items: int = 256,\n    hash_function: str = \"md5\",\n    lambda_context: LambdaContext | None = None,\n    response_hook: IdempotentHookFunction | None = None,\n):\n    \"\"\"\n    Initialize the base persistence layer\n\n    Parameters\n    ----------\n    event_key_jmespath: str\n        A jmespath expression to extract the idempotency key from the event record\n    payload_validation_jmespath: str\n        A jmespath expression to extract the payload to be validated from the event record\n    raise_on_no_idempotency_key: bool, optional\n        Raise exception if no idempotency key was found in the request, by default False\n    expires_after_seconds: int\n        The number of seconds to wait before a record is expired\n    use_local_cache: bool, optional\n        Whether to locally cache idempotency results, by default False\n    local_cache_max_items: int, optional\n        Max number of items to store in local cache, by default 1024\n    hash_function: str, optional\n        Function to use for calculating hashes, by default md5.\n    lambda_context: LambdaContext, optional\n        Lambda Context containing information about the invocation, function and execution environment.\n    response_hook: IdempotentHookFunction, optional\n        Hook function to be called when an idempotent response is returned from the idempotent store.\n    \"\"\"\n    self.event_key_jmespath = event_key_jmespath\n    self.payload_validation_jmespath = payload_validation_jmespath\n    self.jmespath_options = jmespath_options\n    self.raise_on_no_idempotency_key = raise_on_no_idempotency_key\n    self.expires_after_seconds = expires_after_seconds\n    self.use_local_cache = use_local_cache\n    self.local_cache_max_items = local_cache_max_items\n    self.hash_function = hash_function\n    self.lambda_context: LambdaContext | None = lambda_context\n    self.response_hook: IdempotentHookFunction | None = response_hook\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/config/#aws_lambda_powertools.utilities.idempotency.config.IdempotencyConfig.register_lambda_context",
            "title": "register_lambda_context",
            "text": "<pre><code>register_lambda_context(lambda_context: LambdaContext)\n</code></pre> <p>Captures the Lambda context, to calculate the remaining time before the invocation times out</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/config.py</code> <pre><code>def register_lambda_context(self, lambda_context: LambdaContext):\n    \"\"\"Captures the Lambda context, to calculate the remaining time before the invocation times out\"\"\"\n    self.lambda_context = lambda_context\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/",
            "title": "Exceptions",
            "text": "<p>Idempotency errors</p> CLASS DESCRIPTION <code>BaseError</code> <p>Base error class that overwrites the way exception and extra information is printed.</p> <code>IdempotencyAlreadyInProgressError</code> <p>Execution with idempotency key is already in progress</p> <code>IdempotencyInconsistentStateError</code> <p>State is inconsistent across multiple requests to persistence store</p> <code>IdempotencyInvalidStatusError</code> <p>An invalid status was provided</p> <code>IdempotencyItemAlreadyExistsError</code> <p>Item attempting to be inserted into persistence store already exists and is not expired</p> <code>IdempotencyItemNotFoundError</code> <p>Item does not exist in persistence store</p> <code>IdempotencyKeyError</code> <p>Payload does not contain an idempotent key</p> <code>IdempotencyModelTypeError</code> <p>Model type does not match expected payload output</p> <code>IdempotencyNoSerializationModelError</code> <p>No model was supplied to the serializer</p> <code>IdempotencyPersistenceConfigError</code> <p>The idempotency persistency configuration was unsupported</p> <code>IdempotencyPersistenceConnectionError</code> <p>Idempotency persistence connection error</p> <code>IdempotencyPersistenceConsistencyError</code> <p>Idempotency persistency consistency error, needs to be removed</p> <code>IdempotencyPersistenceLayerError</code> <p>Unrecoverable error from the data store</p> <code>IdempotencyValidationError</code> <p>Payload does not match stored idempotency record</p>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.BaseError",
            "title": "BaseError",
            "text": "<pre><code>BaseError(*args: str | Exception | None)\n</code></pre> <p>               Bases: <code>Exception</code></p> <p>Base error class that overwrites the way exception and extra information is printed. See https://github.com/aws-powertools/powertools-lambda-python/issues/1772</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyAlreadyInProgressError",
            "title": "IdempotencyAlreadyInProgressError",
            "text": "<pre><code>IdempotencyAlreadyInProgressError(\n    *args: str | Exception | None,\n)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>Execution with idempotency key is already in progress</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyInconsistentStateError",
            "title": "IdempotencyInconsistentStateError",
            "text": "<pre><code>IdempotencyInconsistentStateError(\n    *args: str | Exception | None,\n)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>State is inconsistent across multiple requests to persistence store</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyInvalidStatusError",
            "title": "IdempotencyInvalidStatusError",
            "text": "<pre><code>IdempotencyInvalidStatusError(\n    *args: str | Exception | None,\n)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>An invalid status was provided</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyItemAlreadyExistsError",
            "title": "IdempotencyItemAlreadyExistsError",
            "text": "<pre><code>IdempotencyItemAlreadyExistsError(\n    *args: str | Exception | None,\n    old_data_record: DataRecord | None = None\n)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>Item attempting to be inserted into persistence store already exists and is not expired</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None, old_data_record: DataRecord | None = None):\n    self.old_data_record = old_data_record\n    super().__init__(*args)\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyItemNotFoundError",
            "title": "IdempotencyItemNotFoundError",
            "text": "<pre><code>IdempotencyItemNotFoundError(*args: str | Exception | None)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>Item does not exist in persistence store</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyKeyError",
            "title": "IdempotencyKeyError",
            "text": "<pre><code>IdempotencyKeyError(*args: str | Exception | None)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>Payload does not contain an idempotent key</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyModelTypeError",
            "title": "IdempotencyModelTypeError",
            "text": "<pre><code>IdempotencyModelTypeError(*args: str | Exception | None)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>Model type does not match expected payload output</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyNoSerializationModelError",
            "title": "IdempotencyNoSerializationModelError",
            "text": "<pre><code>IdempotencyNoSerializationModelError(\n    *args: str | Exception | None,\n)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>No model was supplied to the serializer</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyPersistenceConfigError",
            "title": "IdempotencyPersistenceConfigError",
            "text": "<pre><code>IdempotencyPersistenceConfigError(\n    *args: str | Exception | None,\n)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>The idempotency persistency configuration was unsupported</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyPersistenceConnectionError",
            "title": "IdempotencyPersistenceConnectionError",
            "text": "<pre><code>IdempotencyPersistenceConnectionError(\n    *args: str | Exception | None,\n)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>Idempotency persistence connection error</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyPersistenceConsistencyError",
            "title": "IdempotencyPersistenceConsistencyError",
            "text": "<pre><code>IdempotencyPersistenceConsistencyError(\n    *args: str | Exception | None,\n)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>Idempotency persistency consistency error, needs to be removed</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyPersistenceLayerError",
            "title": "IdempotencyPersistenceLayerError",
            "text": "<pre><code>IdempotencyPersistenceLayerError(\n    *args: str | Exception | None,\n)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>Unrecoverable error from the data store</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/exceptions/#aws_lambda_powertools.utilities.idempotency.exceptions.IdempotencyValidationError",
            "title": "IdempotencyValidationError",
            "text": "<pre><code>IdempotencyValidationError(*args: str | Exception | None)\n</code></pre> <p>               Bases: <code>BaseError</code></p> <p>Payload does not match stored idempotency record</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/exceptions.py</code> <pre><code>def __init__(self, *args: str | Exception | None):\n    self.message = str(args[0]) if args else \"\"\n    self.details = \"\".join(str(arg) for arg in args[1:]) if args[1:] else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/",
            "title": "Persistence",
            "text": "MODULE DESCRIPTION <code>base</code> <p>Persistence layers supporting idempotency</p> <code>datarecord</code> <p>Data Class for idempotency records.</p> <code>dynamodb</code> <code>redis</code>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.base",
            "title": "base",
            "text": "<p>Persistence layers supporting idempotency</p> CLASS DESCRIPTION <code>BasePersistenceLayer</code> <p>Abstract Base Class for Idempotency persistence layer.</p>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.base.BasePersistenceLayer",
            "title": "BasePersistenceLayer",
            "text": "<pre><code>BasePersistenceLayer()\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract Base Class for Idempotency persistence layer.</p> METHOD DESCRIPTION <code>configure</code> <p>Initialize the base persistence layer from the configuration settings</p> <code>delete_record</code> <p>Delete record from the persistence store</p> <code>get_record</code> <p>Retrieve idempotency key for data provided, fetch from persistence store, and convert to DataRecord.</p> <code>save_inprogress</code> <p>Save record of function's execution being in progress</p> <code>save_success</code> <p>Save record of function's execution completing successfully</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/base.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize the defaults\"\"\"\n    self.function_name = \"\"\n    self.configured = False\n    self.event_key_jmespath: str = \"\"\n    self.event_key_compiled_jmespath = None\n    self.jmespath_options: dict | None = None\n    self.payload_validation_enabled = False\n    self.validation_key_jmespath = None\n    self.raise_on_no_idempotency_key = False\n    self.expires_after_seconds: int = 60 * 60  # 1 hour default\n    self.use_local_cache = False\n    self.hash_function = hashlib.md5\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.base.BasePersistenceLayer.configure",
            "title": "configure",
            "text": "<pre><code>configure(\n    config: IdempotencyConfig,\n    function_name: str | None = None,\n    key_prefix: str | None = None,\n) -&gt; None\n</code></pre> <p>Initialize the base persistence layer from the configuration settings</p> PARAMETER DESCRIPTION <code>config</code> <p>Idempotency configuration settings</p> <p> TYPE: <code>IdempotencyConfig</code> </p> <code>function_name</code> <p>The name of the function being decorated</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>key_prefix</code> <p>Custom prefix for idempotency key: key_prefix#hash</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/base.py</code> <pre><code>def configure(\n    self,\n    config: IdempotencyConfig,\n    function_name: str | None = None,\n    key_prefix: str | None = None,\n) -&gt; None:\n    \"\"\"\n    Initialize the base persistence layer from the configuration settings\n\n    Parameters\n    ----------\n    config: IdempotencyConfig\n        Idempotency configuration settings\n    function_name: str, Optional\n        The name of the function being decorated\n    key_prefix: str | Optional\n        Custom prefix for idempotency key: key_prefix#hash\n    \"\"\"\n    self.function_name = (\n        key_prefix or f\"{os.getenv(constants.LAMBDA_FUNCTION_NAME_ENV, 'test-func')}.{function_name or ''}\"\n    )\n\n    if self.configured:\n        # Prevent being reconfigured multiple times\n        return\n    self.configured = True\n\n    self.event_key_jmespath = config.event_key_jmespath\n    if config.event_key_jmespath:\n        self.event_key_compiled_jmespath = jmespath.compile(config.event_key_jmespath)\n    self.jmespath_options = config.jmespath_options or {\"custom_functions\": PowertoolsFunctions()}\n    if config.payload_validation_jmespath:\n        self.validation_key_jmespath = jmespath.compile(config.payload_validation_jmespath)\n        self.payload_validation_enabled = True\n    self.raise_on_no_idempotency_key = config.raise_on_no_idempotency_key\n    self.expires_after_seconds = config.expires_after_seconds\n    self.use_local_cache = config.use_local_cache\n    if self.use_local_cache:\n        self._cache = LRUDict(max_items=config.local_cache_max_items)\n    self.hash_function = getattr(hashlib, config.hash_function)\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.base.BasePersistenceLayer.delete_record",
            "title": "delete_record",
            "text": "<pre><code>delete_record(data: dict[str, Any], exception: Exception)\n</code></pre> <p>Delete record from the persistence store</p> PARAMETER DESCRIPTION <code>data</code> <p>Payload</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>exception</code> <p>The exception raised by the function</p> <p> TYPE: <code>Exception</code> </p> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/base.py</code> <pre><code>def delete_record(self, data: dict[str, Any], exception: Exception):\n    \"\"\"\n    Delete record from the persistence store\n\n    Parameters\n    ----------\n    data: dict[str, Any]\n        Payload\n    exception\n        The exception raised by the function\n    \"\"\"\n\n    idempotency_key = self._get_hashed_idempotency_key(data=data)\n    if idempotency_key is None:\n        # If the idempotency key is None, no data will be saved in the Persistence Layer.\n        # See: https://github.com/aws-powertools/powertools-lambda-python/issues/2465\n        return None\n\n    data_record = DataRecord(idempotency_key=idempotency_key)\n\n    logger.debug(\n        f\"Function raised an exception ({type(exception).__name__}). Clearing in progress record in persistence \"\n        f\"store for idempotency key: {data_record.idempotency_key}\",\n    )\n    self._delete_record(data_record=data_record)\n\n    self._delete_from_cache(idempotency_key=data_record.idempotency_key)\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.base.BasePersistenceLayer.get_record",
            "title": "get_record",
            "text": "<pre><code>get_record(data: dict[str, Any]) -&gt; DataRecord | None\n</code></pre> <p>Retrieve idempotency key for data provided, fetch from persistence store, and convert to DataRecord.</p> PARAMETER DESCRIPTION <code>data</code> <p>Payload</p> <p> TYPE: <code>dict[str, Any]</code> </p> RETURNS DESCRIPTION <code>DataRecord</code> <p>DataRecord representation of existing record found in persistence store</p> RAISES DESCRIPTION <code>IdempotencyItemNotFoundError</code> <p>Exception raised if no record exists in persistence store with the idempotency key</p> <code>IdempotencyValidationError</code> <p>Payload doesn't match the stored record for the given idempotency key</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/base.py</code> <pre><code>def get_record(self, data: dict[str, Any]) -&gt; DataRecord | None:\n    \"\"\"\n    Retrieve idempotency key for data provided, fetch from persistence store, and convert to DataRecord.\n\n    Parameters\n    ----------\n    data: dict[str, Any]\n        Payload\n\n    Returns\n    -------\n    DataRecord\n        DataRecord representation of existing record found in persistence store\n\n    Raises\n    ------\n    IdempotencyItemNotFoundError\n        Exception raised if no record exists in persistence store with the idempotency key\n    IdempotencyValidationError\n        Payload doesn't match the stored record for the given idempotency key\n    \"\"\"\n\n    idempotency_key = self._get_hashed_idempotency_key(data=data)\n    if idempotency_key is None:\n        # If the idempotency key is None, no data will be saved in the Persistence Layer.\n        # See: https://github.com/aws-powertools/powertools-lambda-python/issues/2465\n        return None\n\n    cached_record = self._retrieve_from_cache(idempotency_key=idempotency_key)\n    if cached_record:\n        logger.debug(f\"Idempotency record found in cache with idempotency key: {idempotency_key}\")\n        self._validate_payload(data_payload=data, stored_data_record=cached_record)\n        return cached_record\n\n    record = self._get_record(idempotency_key=idempotency_key)\n\n    self._validate_payload(data_payload=data, stored_data_record=record)\n    self._save_to_cache(data_record=record)\n\n    return record\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.base.BasePersistenceLayer.save_inprogress",
            "title": "save_inprogress",
            "text": "<pre><code>save_inprogress(\n    data: dict[str, Any],\n    remaining_time_in_millis: int | None = None,\n) -&gt; None\n</code></pre> <p>Save record of function's execution being in progress</p> PARAMETER DESCRIPTION <code>data</code> <p>Payload</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>remaining_time_in_millis</code> <p>If expiry of in-progress invocations is enabled, this will contain the remaining time available in millis</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/base.py</code> <pre><code>def save_inprogress(self, data: dict[str, Any], remaining_time_in_millis: int | None = None) -&gt; None:\n    \"\"\"\n    Save record of function's execution being in progress\n\n    Parameters\n    ----------\n    data: dict[str, Any]\n        Payload\n    remaining_time_in_millis: int | None\n        If expiry of in-progress invocations is enabled, this will contain the remaining time available in millis\n    \"\"\"\n\n    idempotency_key = self._get_hashed_idempotency_key(data=data)\n    if idempotency_key is None:\n        # If the idempotency key is None, no data will be saved in the Persistence Layer.\n        # See: https://github.com/aws-powertools/powertools-lambda-python/issues/2465\n        return None\n\n    data_record = DataRecord(\n        idempotency_key=idempotency_key,\n        status=STATUS_CONSTANTS[\"INPROGRESS\"],\n        expiry_timestamp=self._get_expiry_timestamp(),\n        payload_hash=self._get_hashed_payload(data=data),\n    )\n\n    # When Lambda kills the container after timeout, the remaining_time_in_millis is 0, which is considered False.\n    # Therefore, we need to check if remaining_time_in_millis is not None (&gt;=0) to handle this case.\n    # See: https://github.com/aws-powertools/powertools-lambda-python/issues/4759\n    if remaining_time_in_millis is not None:\n        now = datetime.datetime.now()\n        period = datetime.timedelta(milliseconds=remaining_time_in_millis)\n        timestamp = (now + period).timestamp()\n        data_record.in_progress_expiry_timestamp = int(timestamp * 1000)\n    else:\n        warnings.warn(\n            \"Couldn't determine the remaining time left. \"\n            \"Did you call register_lambda_context on IdempotencyConfig?\",\n            stacklevel=2,\n        )\n\n    logger.debug(f\"Saving in progress record for idempotency key: {data_record.idempotency_key}\")\n\n    if self._retrieve_from_cache(idempotency_key=data_record.idempotency_key):\n        raise IdempotencyItemAlreadyExistsError\n\n    self._put_record(data_record=data_record)\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.base.BasePersistenceLayer.save_success",
            "title": "save_success",
            "text": "<pre><code>save_success(data: dict[str, Any], result: dict) -&gt; None\n</code></pre> <p>Save record of function's execution completing successfully</p> PARAMETER DESCRIPTION <code>data</code> <p>Payload</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>result</code> <p>The response from function</p> <p> TYPE: <code>dict</code> </p> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/base.py</code> <pre><code>def save_success(self, data: dict[str, Any], result: dict) -&gt; None:\n    \"\"\"\n    Save record of function's execution completing successfully\n\n    Parameters\n    ----------\n    data: dict[str, Any]\n        Payload\n    result: dict\n        The response from function\n    \"\"\"\n    idempotency_key = self._get_hashed_idempotency_key(data=data)\n    if idempotency_key is None:\n        # If the idempotency key is None, no data will be saved in the Persistence Layer.\n        # See: https://github.com/aws-powertools/powertools-lambda-python/issues/2465\n        return None\n\n    response_data = json.dumps(result, cls=Encoder, sort_keys=True)\n\n    data_record = DataRecord(\n        idempotency_key=idempotency_key,\n        status=STATUS_CONSTANTS[\"COMPLETED\"],\n        expiry_timestamp=self._get_expiry_timestamp(),\n        response_data=response_data,\n        payload_hash=self._get_hashed_payload(data=data),\n    )\n    logger.debug(\n        f\"Function successfully executed. Saving record to persistence store with \"\n        f\"idempotency key: {data_record.idempotency_key}\",\n    )\n    self._update_record(data_record=data_record)\n\n    self._save_to_cache(data_record=data_record)\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.datarecord",
            "title": "datarecord",
            "text": "<p>Data Class for idempotency records.</p> CLASS DESCRIPTION <code>DataRecord</code> <p>Data Class for idempotency records.</p>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.datarecord.DataRecord",
            "title": "DataRecord",
            "text": "<pre><code>DataRecord(\n    idempotency_key: str,\n    status: str = \"\",\n    expiry_timestamp: int | None = None,\n    in_progress_expiry_timestamp: int | None = None,\n    response_data: str = \"\",\n    payload_hash: str = \"\",\n    sort_key: str | None = None,\n)\n</code></pre> <p>Data Class for idempotency records.</p> METHOD DESCRIPTION <code>get_expiration_datetime</code> <p>Converts the expiry timestamp to a datetime object.</p> <code>response_json_as_dict</code> <p>Get response data deserialized to python dict</p> ATTRIBUTE DESCRIPTION <code>is_expired</code> <p>Check if data record is expired</p> <p> TYPE: <code>bool</code> </p> <code>status</code> <p>Get status of data record</p> <p> TYPE: <code>str</code> </p> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/datarecord.py</code> <pre><code>def __init__(\n    self,\n    idempotency_key: str,\n    status: str = \"\",\n    expiry_timestamp: int | None = None,\n    in_progress_expiry_timestamp: int | None = None,\n    response_data: str = \"\",\n    payload_hash: str = \"\",\n    sort_key: str | None = None,\n) -&gt; None:\n    \"\"\"\n\n    Parameters\n    ----------\n    idempotency_key: str\n        hashed representation of the idempotent data\n    status: str, optional\n        status of the idempotent record\n    expiry_timestamp: int, optional\n        time before the record should expire, in seconds\n    in_progress_expiry_timestamp: int, optional\n        time before the record should expire while in the INPROGRESS state, in seconds\n    payload_hash: str, optional\n        hashed representation of payload\n    response_data: str, optional\n        response data from previous executions using the record\n    sort_key: str, optional\n        sort key when using composite key\n    \"\"\"\n    self.idempotency_key = idempotency_key\n    self.payload_hash = payload_hash\n    self.expiry_timestamp = expiry_timestamp\n    self.in_progress_expiry_timestamp = in_progress_expiry_timestamp\n    self._status = status\n    self.response_data = response_data\n    self.sort_key = sort_key\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.datarecord.DataRecord.is_expired",
            "title": "is_expired  <code>property</code>",
            "text": "<pre><code>is_expired: bool\n</code></pre> <p>Check if data record is expired</p> RETURNS DESCRIPTION <code>bool</code> <p>Whether the record is currently expired or not</p>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.datarecord.DataRecord.status",
            "title": "status  <code>property</code>",
            "text": "<pre><code>status: str\n</code></pre> <p>Get status of data record</p> RETURNS DESCRIPTION <code>str</code>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.datarecord.DataRecord.get_expiration_datetime",
            "title": "get_expiration_datetime",
            "text": "<pre><code>get_expiration_datetime() -&gt; datetime.datetime | None\n</code></pre> <p>Converts the expiry timestamp to a datetime object.</p> <p>This method checks if an expiry timestamp exists and converts it to a datetime object. If no timestamp is present, it returns None.</p> <p>datetime.datetime | None     A datetime object representing the expiration time, or None if no expiry timestamp is set.</p> <p>The returned datetime object is timezone-naive and assumes the timestamp is in the system's local timezone. Lambda default timezone is UTC.</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/datarecord.py</code> <pre><code>def get_expiration_datetime(self) -&gt; datetime.datetime | None:\n    \"\"\"\n    Converts the expiry timestamp to a datetime object.\n\n    This method checks if an expiry timestamp exists and converts it to a\n    datetime object. If no timestamp is present, it returns None.\n\n    Returns:\n    -------\n    datetime.datetime | None\n        A datetime object representing the expiration time, or None if no expiry timestamp is set.\n\n    Note:\n    ----\n    The returned datetime object is timezone-naive and assumes the timestamp\n    is in the system's local timezone. Lambda default timezone is UTC.\n    \"\"\"\n    if self.expiry_timestamp:\n        return datetime.datetime.fromtimestamp(int(self.expiry_timestamp))\n    return None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.datarecord.DataRecord.response_json_as_dict",
            "title": "response_json_as_dict",
            "text": "<pre><code>response_json_as_dict() -&gt; dict | None\n</code></pre> <p>Get response data deserialized to python dict</p> RETURNS DESCRIPTION <code>dict | None</code> <p>previous response data deserialized</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/datarecord.py</code> <pre><code>def response_json_as_dict(self) -&gt; dict | None:\n    \"\"\"\n    Get response data deserialized to python dict\n\n    Returns\n    -------\n    dict | None\n        previous response data deserialized\n    \"\"\"\n    return json.loads(self.response_data) if self.response_data else None\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.dynamodb",
            "title": "dynamodb",
            "text": "CLASS DESCRIPTION <code>DynamoDBPersistenceLayer</code>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.dynamodb.DynamoDBPersistenceLayer",
            "title": "DynamoDBPersistenceLayer",
            "text": "<pre><code>DynamoDBPersistenceLayer(\n    table_name: str,\n    key_attr: str = \"id\",\n    static_pk_value: str | None = None,\n    sort_key_attr: str | None = None,\n    expiry_attr: str = \"expiration\",\n    in_progress_expiry_attr: str = \"in_progress_expiration\",\n    status_attr: str = \"status\",\n    data_attr: str = \"data\",\n    validation_key_attr: str = \"validation\",\n    boto_config: Config | None = None,\n    boto3_session: Session | None = None,\n    boto3_client: DynamoDBClient | None = None,\n)\n</code></pre> <p>               Bases: <code>BasePersistenceLayer</code></p> PARAMETER DESCRIPTION <code>table_name</code> <p>Name of the table to use for storing execution records</p> <p> TYPE: <code>str</code> </p> <code>key_attr</code> <p>DynamoDB attribute name for partition key, by default \"id\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'id'</code> </p> <code>static_pk_value</code> <p>DynamoDB attribute value for partition key, by default \"idempotency#\". This will be used if the sort_key_attr is set. <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>sort_key_attr</code> <p>DynamoDB attribute name for the sort key</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>expiry_attr</code> <p>DynamoDB attribute name for expiry timestamp, by default \"expiration\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'expiration'</code> </p> <code>in_progress_expiry_attr</code> <p>DynamoDB attribute name for in-progress expiry timestamp, by default \"in_progress_expiration\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'in_progress_expiration'</code> </p> <code>status_attr</code> <p>DynamoDB attribute name for status, by default \"status\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'status'</code> </p> <code>data_attr</code> <p>DynamoDB attribute name for response data, by default \"data\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'data'</code> </p> <code>validation_key_attr</code> <p>DynamoDB attribute name for hashed representation of the parts of the event used for validation</p> <p> TYPE: <code>str</code> DEFAULT: <code>'validation'</code> </p> <code>boto_config</code> <p>Botocore configuration to pass during client initialization</p> <p> TYPE: <code>Config | None</code> DEFAULT: <code>None</code> </p> <code>boto3_session</code> <p>Boto3 session to use for AWS API communication</p> <p> TYPE: <code>Session</code> DEFAULT: <code>None</code> </p> <code>boto3_client</code> <p>Boto3 DynamoDB Client to use, boto3_session and boto_config will be ignored if both are provided</p> <p> TYPE: <code>DynamoDBClient</code> DEFAULT: <code>None</code> </p> Example <p>Create a DynamoDB persistence layer with custom settings</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.idempotency import (\n&gt;&gt;&gt;    idempotent, DynamoDBPersistenceLayer\n&gt;&gt;&gt; )\n&gt;&gt;&gt;\n&gt;&gt;&gt; persistence_store = DynamoDBPersistenceLayer(table_name=\"idempotency_store\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; @idempotent(persistence_store=persistence_store)\n&gt;&gt;&gt; def handler(event, context):\n&gt;&gt;&gt;     return {\"StatusCode\": 200}\n</code></pre> METHOD DESCRIPTION <code>boto3_supports_condition_check_failure</code> <p>Check if the installed boto3 version supports condition check failure.</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/dynamodb.py</code> <pre><code>def __init__(\n    self,\n    table_name: str,\n    key_attr: str = \"id\",\n    static_pk_value: str | None = None,\n    sort_key_attr: str | None = None,\n    expiry_attr: str = \"expiration\",\n    in_progress_expiry_attr: str = \"in_progress_expiration\",\n    status_attr: str = \"status\",\n    data_attr: str = \"data\",\n    validation_key_attr: str = \"validation\",\n    boto_config: Config | None = None,\n    boto3_session: boto3.session.Session | None = None,\n    boto3_client: DynamoDBClient | None = None,\n):\n    \"\"\"\n    Initialize the DynamoDB client\n\n    Parameters\n    ----------\n    table_name: str\n        Name of the table to use for storing execution records\n    key_attr: str, optional\n        DynamoDB attribute name for partition key, by default \"id\"\n    static_pk_value: str, optional\n        DynamoDB attribute value for partition key, by default \"idempotency#&lt;function-name&gt;\".\n        This will be used if the sort_key_attr is set.\n    sort_key_attr: str, optional\n        DynamoDB attribute name for the sort key\n    expiry_attr: str, optional\n        DynamoDB attribute name for expiry timestamp, by default \"expiration\"\n    in_progress_expiry_attr: str, optional\n        DynamoDB attribute name for in-progress expiry timestamp, by default \"in_progress_expiration\"\n    status_attr: str, optional\n        DynamoDB attribute name for status, by default \"status\"\n    data_attr: str, optional\n        DynamoDB attribute name for response data, by default \"data\"\n    validation_key_attr: str, optional\n        DynamoDB attribute name for hashed representation of the parts of the event used for validation\n    boto_config: botocore.config.Config, optional\n        Botocore configuration to pass during client initialization\n    boto3_session : boto3.session.Session, optional\n        Boto3 session to use for AWS API communication\n    boto3_client : DynamoDBClient, optional\n        Boto3 DynamoDB Client to use, boto3_session and boto_config will be ignored if both are provided\n\n    Example\n    --------\n    **Create a DynamoDB persistence layer with custom settings**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.idempotency import (\n        &gt;&gt;&gt;    idempotent, DynamoDBPersistenceLayer\n        &gt;&gt;&gt; )\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; persistence_store = DynamoDBPersistenceLayer(table_name=\"idempotency_store\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; @idempotent(persistence_store=persistence_store)\n        &gt;&gt;&gt; def handler(event, context):\n        &gt;&gt;&gt;     return {\"StatusCode\": 200}\n    \"\"\"\n    if boto3_client is None:\n        boto3_session = boto3_session or boto3.session.Session()\n        boto3_client = boto3_session.client(\"dynamodb\", config=boto_config)\n    self.client = boto3_client\n\n    user_agent.register_feature_to_client(client=self.client, feature=\"idempotency\")\n\n    if sort_key_attr == key_attr:\n        raise ValueError(f\"key_attr [{key_attr}] and sort_key_attr [{sort_key_attr}] cannot be the same!\")\n\n    if static_pk_value is None:\n        static_pk_value = f\"idempotency#{os.getenv(constants.LAMBDA_FUNCTION_NAME_ENV, '')}\"\n\n    self.table_name = table_name\n    self.key_attr = key_attr\n    self.static_pk_value = static_pk_value\n    self.sort_key_attr = sort_key_attr\n    self.expiry_attr = expiry_attr\n    self.in_progress_expiry_attr = in_progress_expiry_attr\n    self.status_attr = status_attr\n    self.data_attr = data_attr\n    self.validation_key_attr = validation_key_attr\n\n    # Use DynamoDB's ReturnValuesOnConditionCheckFailure to optimize put and get operations and optimize costs.\n    # This feature is supported in boto3 versions 1.26.164 and later.\n    self.return_value_on_condition = (\n        {\"ReturnValuesOnConditionCheckFailure\": \"ALL_OLD\"}\n        if self.boto3_supports_condition_check_failure(boto3.__version__)\n        else {}\n    )\n\n    self._deserializer = TypeDeserializer()\n\n    super().__init__()\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.dynamodb.DynamoDBPersistenceLayer.boto3_supports_condition_check_failure",
            "title": "boto3_supports_condition_check_failure  <code>staticmethod</code>",
            "text": "<pre><code>boto3_supports_condition_check_failure(\n    boto3_version: str,\n) -&gt; bool\n</code></pre> <p>Check if the installed boto3 version supports condition check failure.</p> Params RETURNS DESCRIPTION <code>bool</code> <p>True if the boto3 version supports condition check failure, False otherwise.</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/dynamodb.py</code> <pre><code>@staticmethod\ndef boto3_supports_condition_check_failure(boto3_version: str) -&gt; bool:\n    \"\"\"\n    Check if the installed boto3 version supports condition check failure.\n\n    Params\n    ------\n    boto3_version: str\n        The boto3 version\n\n    Returns\n    -------\n    bool\n        True if the boto3 version supports condition check failure, False otherwise.\n    \"\"\"\n    # Only supported in boto3 1.26.164 and above\n    major, minor, *patch = map(int, boto3_version.split(\".\"))\n    return (major, minor, *patch) &gt;= (1, 26, 164)\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.redis",
            "title": "redis",
            "text": "CLASS DESCRIPTION <code>RedisCachePersistenceLayer</code> <code>RedisClientProtocol</code> <p>Protocol class defining the interface for a Redis client.</p> <code>RedisConnection</code>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.redis.RedisCachePersistenceLayer",
            "title": "RedisCachePersistenceLayer",
            "text": "<pre><code>RedisCachePersistenceLayer(\n    url: str = \"\",\n    host: str = \"\",\n    port: int = 6379,\n    username: str = \"\",\n    password: str = \"\",\n    db_index: int = 0,\n    mode: Literal[\"standalone\", \"cluster\"] = \"standalone\",\n    ssl: bool = True,\n    client: RedisClientProtocol | None = None,\n    in_progress_expiry_attr: str = \"in_progress_expiration\",\n    expiry_attr: str = \"expiration\",\n    status_attr: str = \"status\",\n    data_attr: str = \"data\",\n    validation_key_attr: str = \"validation\",\n)\n</code></pre> <p>               Bases: <code>BasePersistenceLayer</code></p> PARAMETER DESCRIPTION <code>host</code> <p>Redis host</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>port</code> <p>Redis port</p> <p> TYPE: <code>int</code> DEFAULT: <code>6379</code> </p> <code>username</code> <p>Redis username</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>password</code> <p>Redis password</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>url</code> <p>Redis connection string, using url will override the host/port in the previous parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>db_index</code> <p>Redis db index</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>mode</code> <p>set Redis client mode, choose from standalone/cluster</p> <p> TYPE: <code>Literal['standalone', 'cluster']</code> DEFAULT: <code>'standalone'</code> </p> <code>ssl</code> <p>set whether to use ssl for Redis connection</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>client</code> <p>Bring your own Redis client that follows RedisClientProtocol. If provided, all other connection configuration options will be ignored</p> <p> TYPE: <code>RedisClientProtocol | None</code> DEFAULT: <code>None</code> </p> <code>expiry_attr</code> <p>Redis json attribute name for expiry timestamp, by default \"expiration\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'expiration'</code> </p> <code>in_progress_expiry_attr</code> <p>Redis json attribute name for in-progress expiry timestamp, by default \"in_progress_expiration\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'in_progress_expiration'</code> </p> <code>status_attr</code> <p>Redis json attribute name for status, by default \"status\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'status'</code> </p> <code>data_attr</code> <p>Redis json attribute name for response data, by default \"data\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'data'</code> </p> <code>validation_key_attr</code> <p>Redis json attribute name for hashed representation of the parts of the event used for validation</p> <p> TYPE: <code>str</code> DEFAULT: <code>'validation'</code> </p> <p>Examples:</p> <pre><code>from redis import Redis\nfrom aws_lambda_powertools.utilities.idempotency import (\n    idempotent,\n)\n\nfrom aws_lambda_powertools.utilities.idempotency.persistence.redis import (\n    RedisCachePersistenceLayer,\n)\n\nclient = redis.Redis(\n    host=\"localhost\",\n    port=\"6379\",\n    decode_responses=True,\n)\npersistence_layer = RedisCachePersistenceLayer(client=client)\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    print(\"expensive operation\")\n    return {\n        \"payment_id\": 12345,\n        \"message\": \"success\",\n        \"statusCode\": 200,\n    }\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/redis.py</code> <pre><code>def __init__(\n    self,\n    url: str = \"\",\n    host: str = \"\",\n    port: int = 6379,\n    username: str = \"\",\n    password: str = \"\",  # nosec - password for Redis connection\n    db_index: int = 0,\n    mode: Literal[\"standalone\", \"cluster\"] = \"standalone\",\n    ssl: bool = True,\n    client: RedisClientProtocol | None = None,\n    in_progress_expiry_attr: str = \"in_progress_expiration\",\n    expiry_attr: str = \"expiration\",\n    status_attr: str = \"status\",\n    data_attr: str = \"data\",\n    validation_key_attr: str = \"validation\",\n):\n    \"\"\"\n    Initialize the Redis Persistence Layer\n\n    Parameters\n    ----------\n    host: str, optional\n        Redis host\n    port: int, optional: default 6379\n        Redis port\n    username: str, optional\n        Redis username\n    password: str, optional\n        Redis password\n    url: str, optional\n        Redis connection string, using url will override the host/port in the previous parameters\n    db_index: int, optional: default 0\n        Redis db index\n    mode: str, Literal[\"standalone\",\"cluster\"]\n        set Redis client mode, choose from standalone/cluster\n    ssl: bool, optional: default True\n        set whether to use ssl for Redis connection\n    client: RedisClientProtocol, optional\n        Bring your own Redis client that follows RedisClientProtocol.\n        If provided, all other connection configuration options will be ignored\n    expiry_attr: str, optional\n        Redis json attribute name for expiry timestamp, by default \"expiration\"\n    in_progress_expiry_attr: str, optional\n        Redis json attribute name for in-progress expiry timestamp, by default \"in_progress_expiration\"\n    status_attr: str, optional\n        Redis json attribute name for status, by default \"status\"\n    data_attr: str, optional\n        Redis json attribute name for response data, by default \"data\"\n    validation_key_attr: str, optional\n        Redis json attribute name for hashed representation of the parts of the event used for validation\n\n    Examples\n    --------\n\n    ```python\n    from redis import Redis\n    from aws_lambda_powertools.utilities.idempotency import (\n        idempotent,\n    )\n\n    from aws_lambda_powertools.utilities.idempotency.persistence.redis import (\n        RedisCachePersistenceLayer,\n    )\n\n    client = redis.Redis(\n        host=\"localhost\",\n        port=\"6379\",\n        decode_responses=True,\n    )\n    persistence_layer = RedisCachePersistenceLayer(client=client)\n\n    @idempotent(persistence_store=persistence_layer)\n    def lambda_handler(event: dict, context: LambdaContext):\n        print(\"expensive operation\")\n        return {\n            \"payment_id\": 12345,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n    ```\n    \"\"\"\n\n    # Initialize Redis client with Redis config if no client is passed in\n    if client is None:\n        self.client = RedisConnection(\n            host=host,\n            port=port,\n            username=username,\n            password=password,\n            db_index=db_index,\n            url=url,\n            mode=mode,\n            ssl=ssl,\n        )._init_client()\n    else:\n        self.client = client\n\n    self.in_progress_expiry_attr = in_progress_expiry_attr\n    self.expiry_attr = expiry_attr\n    self.status_attr = status_attr\n    self.data_attr = data_attr\n    self.validation_key_attr = validation_key_attr\n    self._json_serializer = json.dumps\n    self._json_deserializer = json.loads\n    super().__init__()\n    self._orphan_lock_timeout = min(10, self.expires_after_seconds)\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.redis.RedisClientProtocol",
            "title": "RedisClientProtocol",
            "text": "<p>               Bases: <code>Protocol</code></p> <p>Protocol class defining the interface for a Redis client.</p> <p>This protocol outlines the expected behavior of a Redis client, allowing for standardization among different implementations and allowing customers to extend it in their own implementation.</p> METHOD DESCRIPTION <code>- get</code> <p>Retrieves the value associated with the given key.</p> <code>- set</code> <code>) -&gt; bool | None:</code> <p>Sets the value for the specified key with optional parameters.</p> <code>- delete</code> <p>Deletes one or more keys.</p> Note <ul> <li>The <code>ex</code> parameter represents the expiration time in seconds.</li> <li>The <code>px</code> parameter represents the expiration time in milliseconds.</li> <li>The <code>nx</code> parameter, if True, sets the value only if the key does not exist.</li> </ul> RAISES DESCRIPTION <code>- NotImplementedError: If any of the methods are not implemented by the concrete class.</code>"
        },
        {
            "location": "api_doc/idempotency/persistence/#aws_lambda_powertools.utilities.idempotency.persistence.redis.RedisConnection",
            "title": "RedisConnection",
            "text": "<pre><code>RedisConnection(\n    url: str = \"\",\n    host: str = \"\",\n    port: int = 6379,\n    username: str = \"\",\n    password: str = \"\",\n    db_index: int = 0,\n    mode: Literal[\"standalone\", \"cluster\"] = \"standalone\",\n    ssl: bool = True,\n)\n</code></pre> PARAMETER DESCRIPTION <code>host</code> <p>Redis host</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>port</code> <p>Redis port</p> <p> TYPE: <code>int</code> DEFAULT: <code>6379</code> </p> <code>username</code> <p>Redis username</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>password</code> <p>Redis password</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>url</code> <p>Redis connection string, using url will override the host/port in the previous parameters</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>db_index</code> <p>Redis db index</p> <p> TYPE: <code>int</code> DEFAULT: <code>0</code> </p> <code>mode</code> <p>set Redis client mode, choose from standalone/cluster. The default is standalone</p> <p> TYPE: <code>Literal['standalone', 'cluster']</code> DEFAULT: <code>'standalone'</code> </p> <code>ssl</code> <p>set whether to use ssl for Redis connection</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Example <pre><code>from dataclasses import dataclass, field\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.idempotency.persistence.redis import (\n    RedisCachePersistenceLayer,\n)\n\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = RedisCachePersistenceLayer(host=\"localhost\", port=6379)\n\n\n@dataclass\nclass Payment:\n    user_id: str\n    product_id: str\n    payment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass PaymentError(Exception):\n    ...\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        payment: Payment = create_subscription_payment(event)\n        return {\n            \"payment_id\": payment.payment_id,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n    except Exception as exc:\n        raise PaymentError(f\"Error creating payment {str(exc)}\")\n\n\ndef create_subscription_payment(event: dict) -&gt; Payment:\n    return Payment(**event)\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/idempotency/persistence/redis.py</code> <pre><code>def __init__(\n    self,\n    url: str = \"\",\n    host: str = \"\",\n    port: int = 6379,\n    username: str = \"\",\n    password: str = \"\",  # nosec - password for Redis connection\n    db_index: int = 0,\n    mode: Literal[\"standalone\", \"cluster\"] = \"standalone\",\n    ssl: bool = True,\n) -&gt; None:\n    \"\"\"\n    Initialize Redis connection which will be used in Redis persistence_store to support Idempotency\n\n    Parameters\n    ----------\n    host: str, optional\n        Redis host\n    port: int, optional: default 6379\n        Redis port\n    username: str, optional\n        Redis username\n    password: str, optional\n        Redis password\n    url: str, optional\n        Redis connection string, using url will override the host/port in the previous parameters\n    db_index: int, optional: default 0\n        Redis db index\n    mode: str, Literal[\"standalone\",\"cluster\"]\n        set Redis client mode, choose from standalone/cluster. The default is standalone\n    ssl: bool, optional: default True\n        set whether to use ssl for Redis connection\n\n    Example\n    --------\n\n    ```python\n    from dataclasses import dataclass, field\n    from uuid import uuid4\n\n    from aws_lambda_powertools.utilities.idempotency import (\n        idempotent,\n    )\n    from aws_lambda_powertools.utilities.idempotency.persistence.redis import (\n        RedisCachePersistenceLayer,\n    )\n\n    from aws_lambda_powertools.utilities.typing import LambdaContext\n\n    persistence_layer = RedisCachePersistenceLayer(host=\"localhost\", port=6379)\n\n\n    @dataclass\n    class Payment:\n        user_id: str\n        product_id: str\n        payment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\n    class PaymentError(Exception):\n        ...\n\n\n    @idempotent(persistence_store=persistence_layer)\n    def lambda_handler(event: dict, context: LambdaContext):\n        try:\n            payment: Payment = create_subscription_payment(event)\n            return {\n                \"payment_id\": payment.payment_id,\n                \"message\": \"success\",\n                \"statusCode\": 200,\n            }\n        except Exception as exc:\n            raise PaymentError(f\"Error creating payment {str(exc)}\")\n\n\n    def create_subscription_payment(event: dict) -&gt; Payment:\n        return Payment(**event)\n\n    ```\n    \"\"\"\n    self.url = url\n    self.host = host\n    self.port = port\n    self.username = username\n    self.password = password\n    self.db_index = db_index\n    self.ssl = ssl\n    self.mode = mode\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/serialization/",
            "title": "Serialization",
            "text": "MODULE DESCRIPTION <code>base</code> <p>Serialization for supporting idempotency</p> <code>custom_dict</code> <code>dataclass</code> <code>functions</code> <code>no_op</code> <code>pydantic</code>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.base",
            "title": "base",
            "text": "<p>Serialization for supporting idempotency</p> CLASS DESCRIPTION <code>BaseIdempotencyModelSerializer</code> <p>Abstract Base Class for Idempotency serialization layer, for using a model as data object representation.</p> <code>BaseIdempotencySerializer</code> <p>Abstract Base Class for Idempotency serialization layer, supporting dict operations.</p>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.base.BaseIdempotencyModelSerializer",
            "title": "BaseIdempotencyModelSerializer",
            "text": "<p>               Bases: <code>BaseIdempotencySerializer</code></p> <p>Abstract Base Class for Idempotency serialization layer, for using a model as data object representation.</p> METHOD DESCRIPTION <code>instantiate</code> <p>Creates an instance of a serializer based on a provided model type.</p>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.base.BaseIdempotencyModelSerializer.instantiate",
            "title": "instantiate  <code>abstractmethod</code> <code>classmethod</code>",
            "text": "<pre><code>instantiate(model_type: Any) -&gt; BaseIdempotencySerializer\n</code></pre> <p>Creates an instance of a serializer based on a provided model type. In case the model_type is unknown, None will be sent as <code>model_type</code>. It's on the implementer to verify that: - None is handled correctly - A model type not matching the expected types is handled</p> PARAMETER DESCRIPTION <code>model_type</code> <p>The model type to instantiate the class for</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>BaseIdempotencySerializer</code> <p>Instance of the serializer class</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/serialization/base.py</code> <pre><code>@classmethod\n@abstractmethod\ndef instantiate(cls, model_type: Any) -&gt; BaseIdempotencySerializer:\n    \"\"\"\n    Creates an instance of a serializer based on a provided model type.\n    In case the model_type is unknown, None will be sent as `model_type`.\n    It's on the implementer to verify that:\n    - None is handled correctly\n    - A model type not matching the expected types is handled\n\n    Parameters\n    ----------\n    model_type: Any\n        The model type to instantiate the class for\n\n    Returns\n    -------\n    BaseIdempotencySerializer\n        Instance of the serializer class\n    \"\"\"\n    pass\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.base.BaseIdempotencySerializer",
            "title": "BaseIdempotencySerializer",
            "text": "<p>               Bases: <code>ABC</code></p> <p>Abstract Base Class for Idempotency serialization layer, supporting dict operations.</p>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.custom_dict",
            "title": "custom_dict",
            "text": "CLASS DESCRIPTION <code>CustomDictSerializer</code>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.custom_dict.CustomDictSerializer",
            "title": "CustomDictSerializer",
            "text": "<pre><code>CustomDictSerializer(\n    to_dict: Callable[[Any], dict],\n    from_dict: Callable[[dict], Any],\n)\n</code></pre> <p>               Bases: <code>BaseIdempotencySerializer</code></p> Source code in <code>aws_lambda_powertools/utilities/idempotency/serialization/custom_dict.py</code> <pre><code>def __init__(self, to_dict: Callable[[Any], dict], from_dict: Callable[[dict], Any]):\n    \"\"\"\n    Parameters\n    ----------\n    to_dict: Callable[[Any], dict]\n        A function capable of transforming the saved data object representation into a dictionary\n    from_dict: Callable[[dict], Any]\n        A function capable of transforming the saved dictionary into the original data object representation\n    \"\"\"\n    self.__to_dict: Callable[[Any], dict] = to_dict\n    self.__from_dict: Callable[[dict], Any] = from_dict\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.dataclass",
            "title": "dataclass",
            "text": "CLASS DESCRIPTION <code>DataclassSerializer</code> <p>A serializer class for transforming data between dataclass objects and dictionaries.</p>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.dataclass.DataclassSerializer",
            "title": "DataclassSerializer",
            "text": "<pre><code>DataclassSerializer(model: type[DataClass])\n</code></pre> <p>               Bases: <code>BaseIdempotencyModelSerializer</code></p> <p>A serializer class for transforming data between dataclass objects and dictionaries.</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/serialization/dataclass.py</code> <pre><code>def __init__(self, model: type[DataClass]):\n    \"\"\"\n    Parameters\n    ----------\n    model: type[DataClass]\n        A dataclass type to be used for serialization and deserialization\n    \"\"\"\n    self.__model: type[DataClass] = model\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.functions",
            "title": "functions",
            "text": "FUNCTION DESCRIPTION <code>get_actual_type</code> <p>Extract the actual type from a potentially Optional or Union type.</p>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.functions.get_actual_type",
            "title": "get_actual_type",
            "text": "<pre><code>get_actual_type(model_type: Any) -&gt; Any\n</code></pre> <p>Extract the actual type from a potentially Optional or Union type. This function handles types that may be wrapped in Optional or Union, including the Python 3.10+ Union syntax (Type | None).</p> PARAMETER DESCRIPTION <code>model_type</code> <p>The type to analyze. Can be a simple type, Optional[Type], BaseModel, dataclass</p> <p> TYPE: <code>Any</code> </p> RETURNS DESCRIPTION <code>The actual type without Optional or Union wrappers.</code> <code>Raises</code> <p> TYPE: <code>Any</code> </p> Source code in <code>aws_lambda_powertools/utilities/idempotency/serialization/functions.py</code> <pre><code>def get_actual_type(model_type: Any) -&gt; Any:\n    \"\"\"\n    Extract the actual type from a potentially Optional or Union type.\n    This function handles types that may be wrapped in Optional or Union,\n    including the Python 3.10+ Union syntax (Type | None).\n    Parameters\n    ----------\n    model_type: Any\n        The type to analyze. Can be a simple type, Optional[Type], BaseModel, dataclass\n    Returns\n    -------\n    The actual type without Optional or Union wrappers.\n    Raises:\n        IdempotencyModelTypeError: If the type specification is invalid\n                                   (e.g., Union with multiple non-None types).\n    \"\"\"\n\n    # Get the origin of the type (e.g., Union, Optional)\n    origin = get_origin(model_type)\n\n    # Check if type is Union, Optional, or UnionType (Python 3.10+)\n    if origin in (Union, Optional) or (sys.version_info &gt;= (3, 10) and origin in (Union, UnionType)):\n        # Get type arguments\n        args = get_args(model_type)\n\n        # Filter out NoneType\n        actual_type = _extract_non_none_types(args)\n\n        # Ensure only one non-None type exists\n        if len(actual_type) != 1:\n            raise IdempotencyModelTypeError(\n                \"Invalid type: expected a single type, optionally wrapped in Optional or Union with None.\",\n            )\n\n        return actual_type[0]\n\n    # If not a Union/Optional type, return original type\n    return model_type\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.no_op",
            "title": "no_op",
            "text": "CLASS DESCRIPTION <code>NoOpSerializer</code>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.no_op.NoOpSerializer",
            "title": "NoOpSerializer",
            "text": "<pre><code>NoOpSerializer()\n</code></pre> <p>               Bases: <code>BaseIdempotencySerializer</code></p> <p>Default serializer, does not transform data</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/serialization/no_op.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Parameters\n    ----------\n    Default serializer, does not transform data\n    \"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.pydantic",
            "title": "pydantic",
            "text": "CLASS DESCRIPTION <code>PydanticSerializer</code> <p>Pydantic serializer for idempotency models</p>"
        },
        {
            "location": "api_doc/idempotency/serialization/#aws_lambda_powertools.utilities.idempotency.serialization.pydantic.PydanticSerializer",
            "title": "PydanticSerializer",
            "text": "<pre><code>PydanticSerializer(model: type[BaseModel])\n</code></pre> <p>               Bases: <code>BaseIdempotencyModelSerializer</code></p> <p>Pydantic serializer for idempotency models</p> Source code in <code>aws_lambda_powertools/utilities/idempotency/serialization/pydantic.py</code> <pre><code>def __init__(self, model: type[BaseModel]):\n    \"\"\"\n    Parameters\n    ----------\n    model: Model\n        Pydantic model to be used for serialization\n    \"\"\"\n    self.__model: type[BaseModel] = model\n</code></pre>"
        },
        {
            "location": "api_doc/logger/datadog_formatter/",
            "title": "DataDog Formatter",
            "text": "CLASS DESCRIPTION <code>DatadogLogFormatter</code>"
        },
        {
            "location": "api_doc/logger/datadog_formatter/#aws_lambda_powertools.logging.formatters.datadog.DatadogLogFormatter",
            "title": "DatadogLogFormatter",
            "text": "<pre><code>DatadogLogFormatter(\n    json_serializer: (\n        Callable[[LogRecord], str] | None\n    ) = None,\n    json_deserializer: (\n        Callable[[dict | str | bool | int | float], str]\n        | None\n    ) = None,\n    json_default: Callable[[Any], Any] | None = None,\n    datefmt: str | None = None,\n    use_datetime_directive: bool = False,\n    log_record_order: list[str] | None = None,\n    utc: bool = False,\n    use_rfc3339: bool = True,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>LambdaPowertoolsFormatter</code></p> <p>Changes compared to the default Logger Formatter:</p> <ul> <li>timestamp format to use RFC3339 e.g., \"2023-05-01T15:34:26.841+0200\"</li> </ul> PARAMETER DESCRIPTION <code>log_record_order</code> <p>description, by default None</p> <p> TYPE: <code>list[str] | None</code> DEFAULT: <code>None</code> </p> PARAMETER DESCRIPTION <code>json_serializer</code> <p>function to serialize <code>obj</code> to a JSON formatted <code>str</code>, by default json.dumps</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>json_deserializer</code> <p>function to deserialize <code>str</code>, <code>bytes</code>, bytearray<code>containing a JSON document to a Python</code>obj`, by default json.loads</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>json_default</code> <p>function to coerce unserializable values, by default str</p> <p>Only used when no custom JSON encoder is set</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>datefmt</code> <p>String directives (strftime) to format log timestamp.</p> <p>See https://docs.python.org/3/library/time.html#time.strftime or</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>use_datetime_directive</code> <p>Interpret <code>datefmt</code> as a format string for <code>datetime.datetime.strftime</code>, rather than <code>time.strftime</code> - Only useful when used alongside <code>datefmt</code>.</p> <p>See https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior . This also supports a custom %F directive for milliseconds.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>log_record_order</code> <p>set order of log keys when logging, by default [\"level\", \"location\", \"message\", \"timestamp\"]</p> <p> TYPE: <code>list</code> DEFAULT: <code>None</code> </p> <code>utc</code> <p>set logging timestamp to UTC, by default False to continue to use local time as per stdlib</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_rfc3339</code> <p>Whether to use a popular dateformat that complies with both RFC3339 and ISO8601. e.g., 2022-10-27T16:27:43.738+02:00.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>kwargs</code> <p>Key-value to persist in all log messages</p> <p> DEFAULT: <code>{}</code> </p> Source code in <code>aws_lambda_powertools/logging/formatters/datadog.py</code> <pre><code>def __init__(\n    self,\n    json_serializer: Callable[[LogRecord], str] | None = None,\n    json_deserializer: Callable[[dict | str | bool | int | float], str] | None = None,\n    json_default: Callable[[Any], Any] | None = None,\n    datefmt: str | None = None,\n    use_datetime_directive: bool = False,\n    log_record_order: list[str] | None = None,\n    utc: bool = False,\n    use_rfc3339: bool = True,  # NOTE: The only change from our base formatter\n    **kwargs,\n):\n    \"\"\"Datadog formatter to comply with Datadog log parsing\n\n    Changes compared to the default Logger Formatter:\n\n    - timestamp format to use RFC3339 e.g., \"2023-05-01T15:34:26.841+0200\"\n\n\n    Parameters\n    ----------\n    log_record_order : list[str] | None, optional\n        _description_, by default None\n\n    Parameters\n    ----------\n    json_serializer : Callable, optional\n        function to serialize `obj` to a JSON formatted `str`, by default json.dumps\n    json_deserializer : Callable, optional\n        function to deserialize `str`, `bytes`, bytearray` containing a JSON document to a Python `obj`,\n        by default json.loads\n    json_default : Callable, optional\n        function to coerce unserializable values, by default str\n\n        Only used when no custom JSON encoder is set\n\n    datefmt : str, optional\n        String directives (strftime) to format log timestamp.\n\n        See https://docs.python.org/3/library/time.html#time.strftime or\n    use_datetime_directive: str, optional\n        Interpret `datefmt` as a format string for `datetime.datetime.strftime`, rather than\n        `time.strftime` - Only useful when used alongside `datefmt`.\n\n        See https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior . This\n        also supports a custom %F directive for milliseconds.\n\n    log_record_order : list, optional\n        set order of log keys when logging, by default [\"level\", \"location\", \"message\", \"timestamp\"]\n\n    utc : bool, optional\n        set logging timestamp to UTC, by default False to continue to use local time as per stdlib\n    use_rfc3339: bool, optional\n        Whether to use a popular dateformat that complies with both RFC3339 and ISO8601.\n        e.g., 2022-10-27T16:27:43.738+02:00.\n    kwargs\n        Key-value to persist in all log messages\n    \"\"\"\n    super().__init__(\n        json_serializer=json_serializer,\n        json_deserializer=json_deserializer,\n        json_default=json_default,\n        datefmt=datefmt,\n        use_datetime_directive=use_datetime_directive,\n        log_record_order=log_record_order,\n        utc=utc,\n        use_rfc3339=use_rfc3339,\n        **kwargs,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/logger/exceptions/",
            "title": "Exceptions",
            "text": "CLASS DESCRIPTION <code>InvalidLoggerSamplingRateError</code> <p>Logger configured with Invalid Sampling value</p> <code>OrphanedChildLoggerError</code> <p>Orphaned Child logger exception</p>"
        },
        {
            "location": "api_doc/logger/exceptions/#aws_lambda_powertools.logging.exceptions.InvalidLoggerSamplingRateError",
            "title": "InvalidLoggerSamplingRateError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>Logger configured with Invalid Sampling value</p>"
        },
        {
            "location": "api_doc/logger/exceptions/#aws_lambda_powertools.logging.exceptions.OrphanedChildLoggerError",
            "title": "OrphanedChildLoggerError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>Orphaned Child logger exception</p>"
        },
        {
            "location": "api_doc/logger/formatter/",
            "title": "Formatter",
            "text": "CLASS DESCRIPTION <code>BasePowertoolsFormatter</code> <code>LambdaPowertoolsFormatter</code> <p>Powertools for AWS Lambda (Python) Logging formatter.</p>"
        },
        {
            "location": "api_doc/logger/formatter/#aws_lambda_powertools.logging.formatter.BasePowertoolsFormatter",
            "title": "BasePowertoolsFormatter",
            "text": "<p>               Bases: <code>Formatter</code></p> METHOD DESCRIPTION <code>clear_state</code> <p>Removes any previously added logging keys</p> <code>thread_safe_clear_keys</code> <p>Removes any previously added logging keys in a specific thread</p>"
        },
        {
            "location": "api_doc/logger/formatter/#aws_lambda_powertools.logging.formatter.BasePowertoolsFormatter.clear_state",
            "title": "clear_state  <code>abstractmethod</code>",
            "text": "<pre><code>clear_state() -&gt; None\n</code></pre> <p>Removes any previously added logging keys</p> Source code in <code>aws_lambda_powertools/logging/formatter.py</code> <pre><code>@abstractmethod\ndef clear_state(self) -&gt; None:\n    \"\"\"Removes any previously added logging keys\"\"\"\n    raise NotImplementedError()\n</code></pre>"
        },
        {
            "location": "api_doc/logger/formatter/#aws_lambda_powertools.logging.formatter.BasePowertoolsFormatter.thread_safe_clear_keys",
            "title": "thread_safe_clear_keys",
            "text": "<pre><code>thread_safe_clear_keys() -&gt; None\n</code></pre> <p>Removes any previously added logging keys in a specific thread</p> Source code in <code>aws_lambda_powertools/logging/formatter.py</code> <pre><code>def thread_safe_clear_keys(self) -&gt; None:\n    \"\"\"Removes any previously added logging keys in a specific thread\"\"\"\n    raise NotImplementedError()\n</code></pre>"
        },
        {
            "location": "api_doc/logger/formatter/#aws_lambda_powertools.logging.formatter.LambdaPowertoolsFormatter",
            "title": "LambdaPowertoolsFormatter",
            "text": "<pre><code>LambdaPowertoolsFormatter(\n    json_serializer: (\n        Callable[[LogRecord], str] | None\n    ) = None,\n    json_deserializer: (\n        Callable[[dict | str | bool | int | float], str]\n        | None\n    ) = None,\n    json_default: Callable[[Any], Any] | None = None,\n    datefmt: str | None = None,\n    use_datetime_directive: bool = False,\n    log_record_order: list[str] | None = None,\n    utc: bool = False,\n    use_rfc3339: bool = False,\n    serialize_stacktrace: bool = True,\n    **kwargs\n)\n</code></pre> <p>               Bases: <code>BasePowertoolsFormatter</code></p> <p>Powertools for AWS Lambda (Python) Logging formatter.</p> <p>Formats the log message as a JSON encoded string. If the message is a dict it will be used directly.</p> <p>The <code>log_record_order</code> kwarg is used to specify the order of the keys used in the structured json logs. By default the order is: \"level\", \"location\", \"message\", \"timestamp\", \"service\".</p> <p>Other kwargs are used to specify log field format strings.</p> PARAMETER DESCRIPTION <code>json_serializer</code> <p>function to serialize <code>obj</code> to a JSON formatted <code>str</code>, by default json.dumps</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>json_deserializer</code> <p>function to deserialize <code>str</code>, <code>bytes</code>, bytearray<code>containing a JSON document to a Python</code>obj`, by default json.loads</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>json_default</code> <p>function to coerce unserializable values, by default str</p> <p>Only used when no custom JSON encoder is set</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>datefmt</code> <p>String directives (strftime) to format log timestamp.</p> <p>See https://docs.python.org/3/library/time.html#time.strftime or</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>use_datetime_directive</code> <p>Interpret <code>datefmt</code> as a format string for <code>datetime.datetime.strftime</code>, rather than <code>time.strftime</code> - Only useful when used alongside <code>datefmt</code>.</p> <p>See https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior . This also supports a custom %F directive for milliseconds.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>utc</code> <p>set logging timestamp to UTC, by default False to continue to use local time as per stdlib</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>use_rfc3339</code> <p>Whether to use a popular dateformat that complies with both RFC3339 and ISO8601. e.g., 2022-10-27T16:27:43.738+02:00.</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>log_record_order</code> <p>set order of log keys when logging, by default [\"level\", \"location\", \"message\", \"timestamp\"]</p> <p> TYPE: <code>list</code> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Key-value to be included in log messages</p> <p> DEFAULT: <code>{}</code> </p> METHOD DESCRIPTION <code>append_context_keys</code> <p>Context manager to temporarily add logging keys.</p> <code>format</code> <p>Format logging record as structured JSON str</p> <code>serialize</code> <p>Serialize structured log dict to JSON str</p> Source code in <code>aws_lambda_powertools/logging/formatter.py</code> <pre><code>def __init__(\n    self,\n    json_serializer: Callable[[LogRecord], str] | None = None,\n    json_deserializer: Callable[[dict | str | bool | int | float], str] | None = None,\n    json_default: Callable[[Any], Any] | None = None,\n    datefmt: str | None = None,\n    use_datetime_directive: bool = False,\n    log_record_order: list[str] | None = None,\n    utc: bool = False,\n    use_rfc3339: bool = False,\n    serialize_stacktrace: bool = True,\n    **kwargs,\n) -&gt; None:\n    \"\"\"Return a LambdaPowertoolsFormatter instance.\n\n    The `log_record_order` kwarg is used to specify the order of the keys used in\n    the structured json logs. By default the order is: \"level\", \"location\", \"message\", \"timestamp\",\n    \"service\".\n\n    Other kwargs are used to specify log field format strings.\n\n    Parameters\n    ----------\n    json_serializer : Callable, optional\n        function to serialize `obj` to a JSON formatted `str`, by default json.dumps\n    json_deserializer : Callable, optional\n        function to deserialize `str`, `bytes`, bytearray` containing a JSON document to a Python `obj`,\n        by default json.loads\n    json_default : Callable, optional\n        function to coerce unserializable values, by default str\n\n        Only used when no custom JSON encoder is set\n\n    datefmt : str, optional\n        String directives (strftime) to format log timestamp.\n\n        See https://docs.python.org/3/library/time.html#time.strftime or\n    use_datetime_directive: str, optional\n        Interpret `datefmt` as a format string for `datetime.datetime.strftime`, rather than\n        `time.strftime` - Only useful when used alongside `datefmt`.\n\n        See https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior . This\n        also supports a custom %F directive for milliseconds.\n    utc : bool, optional\n        set logging timestamp to UTC, by default False to continue to use local time as per stdlib\n    use_rfc3339: bool, optional\n        Whether to use a popular dateformat that complies with both RFC3339 and ISO8601.\n        e.g., 2022-10-27T16:27:43.738+02:00.\n    log_record_order : list, optional\n        set order of log keys when logging, by default [\"level\", \"location\", \"message\", \"timestamp\"]\n    kwargs\n        Key-value to be included in log messages\n\n    \"\"\"\n\n    self.json_deserializer = json_deserializer or json.loads\n    self.json_default = json_default or str\n    self.json_indent = (\n        constants.PRETTY_INDENT if powertools_dev_is_set() else constants.COMPACT_INDENT\n    )  # indented json serialization when in AWS SAM Local\n    self.json_serializer = json_serializer or partial(\n        json.dumps,\n        default=self.json_default,\n        separators=(\",\", \":\"),\n        indent=self.json_indent,\n        ensure_ascii=False,  # see #3474\n    )\n\n    self.datefmt = datefmt\n    self.use_datetime_directive = use_datetime_directive\n\n    self.utc = utc\n    self.log_record_order = log_record_order or [\"level\", \"location\", \"message\", \"timestamp\"]\n    self.log_format = dict.fromkeys(self.log_record_order)  # Set the insertion order for the log messages\n    self.update_formatter = self.append_keys  # alias to old method\n    self.use_rfc3339_iso8601 = use_rfc3339\n\n    if self.utc:\n        self.converter = time.gmtime\n    else:\n        self.converter = time.localtime\n\n    self.keys_combined = {**self._build_default_keys(), **kwargs}\n    self.log_format.update(**self.keys_combined)\n\n    self.serialize_stacktrace = serialize_stacktrace\n\n    super().__init__(datefmt=self.datefmt)\n</code></pre>"
        },
        {
            "location": "api_doc/logger/formatter/#aws_lambda_powertools.logging.formatter.LambdaPowertoolsFormatter.append_context_keys",
            "title": "append_context_keys",
            "text": "<pre><code>append_context_keys(\n    **additional_keys: Any,\n) -&gt; Generator[None, None, None]\n</code></pre> <p>Context manager to temporarily add logging keys.</p> PARAMETER DESCRIPTION <code>**additional_keys</code> <p>Key-value pairs to include in the log context during the lifespan of the context manager.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Example <pre><code>logger = Logger(service=\"example_service\")\nwith logger.append_context_keys(user_id=\"123\", operation=\"process\"):\n    logger.info(\"Log with context\")\nlogger.info(\"Log without context\")\n</code></pre> Source code in <code>aws_lambda_powertools/logging/formatter.py</code> <pre><code>@contextmanager\ndef append_context_keys(self, **additional_keys: Any) -&gt; Generator[None, None, None]:\n    \"\"\"\n    Context manager to temporarily add logging keys.\n\n    Parameters\n    -----------\n    **additional_keys: Any\n        Key-value pairs to include in the log context during the lifespan of the context manager.\n\n    Example\n    --------\n        logger = Logger(service=\"example_service\")\n        with logger.append_context_keys(user_id=\"123\", operation=\"process\"):\n            logger.info(\"Log with context\")\n        logger.info(\"Log without context\")\n    \"\"\"\n    # Add keys to the context\n    self.append_keys(**additional_keys)\n    try:\n        yield\n    finally:\n        # Remove the keys after exiting the context\n        self.remove_keys(additional_keys.keys())\n</code></pre>"
        },
        {
            "location": "api_doc/logger/formatter/#aws_lambda_powertools.logging.formatter.LambdaPowertoolsFormatter.format",
            "title": "format",
            "text": "<pre><code>format(record: LogRecord) -&gt; str\n</code></pre> <p>Format logging record as structured JSON str</p> Source code in <code>aws_lambda_powertools/logging/formatter.py</code> <pre><code>def format(self, record: logging.LogRecord) -&gt; str:  # noqa: A003\n    \"\"\"Format logging record as structured JSON str\"\"\"\n    formatted_log = self._extract_log_keys(log_record=record)\n    formatted_log[\"message\"] = self._extract_log_message(log_record=record)\n\n    # exception and exception_name fields can be added as extra key\n    # in any log level, we try to extract and use them first\n    extracted_exception, extracted_exception_name = self._extract_log_exception(log_record=record)\n    formatted_log[\"exception\"] = formatted_log.get(\"exception\", extracted_exception)\n    formatted_log[\"exception_name\"] = formatted_log.get(\"exception_name\", extracted_exception_name)\n    if self.serialize_stacktrace:\n        # Generate the traceback from the traceback library\n        formatted_log[\"stack_trace\"] = self._serialize_stacktrace(log_record=record)\n    formatted_log[\"xray_trace_id\"] = self._get_latest_trace_id()\n    formatted_log = self._strip_none_records(records=formatted_log)\n\n    return self.serialize(log=formatted_log)\n</code></pre>"
        },
        {
            "location": "api_doc/logger/formatter/#aws_lambda_powertools.logging.formatter.LambdaPowertoolsFormatter.serialize",
            "title": "serialize",
            "text": "<pre><code>serialize(log: LogRecord) -&gt; str\n</code></pre> <p>Serialize structured log dict to JSON str</p> Source code in <code>aws_lambda_powertools/logging/formatter.py</code> <pre><code>def serialize(self, log: LogRecord) -&gt; str:\n    \"\"\"Serialize structured log dict to JSON str\"\"\"\n    return self.json_serializer(log)\n</code></pre>"
        },
        {
            "location": "api_doc/logger/lambda_context/",
            "title": "Lambda Context",
            "text": "CLASS DESCRIPTION <code>LambdaContextModel</code> <p>A handful of Lambda Runtime Context fields</p> FUNCTION DESCRIPTION <code>build_lambda_context_model</code> <p>Captures Lambda function runtime info to be used across all log statements</p>"
        },
        {
            "location": "api_doc/logger/lambda_context/#aws_lambda_powertools.logging.lambda_context.LambdaContextModel",
            "title": "LambdaContextModel",
            "text": "<pre><code>LambdaContextModel(\n    function_name: str = \"UNDEFINED\",\n    function_memory_size: int = 128,\n    function_arn: str = \"UNDEFINED\",\n    function_request_id: str = \"UNDEFINED\",\n)\n</code></pre> <p>A handful of Lambda Runtime Context fields</p> <p>Full Lambda Context object: https://docs.aws.amazon.com/lambda/latest/dg/python-context-object.html</p> PARAMETER DESCRIPTION <code>function_name</code> <p>Lambda function name, by default \"UNDEFINED\" e.g. \"test\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'UNDEFINED'</code> </p> <code>function_memory_size</code> <p>Lambda function memory in MB, by default 128</p> <p> TYPE: <code>int</code> DEFAULT: <code>128</code> </p> <code>function_arn</code> <p>Lambda function ARN, by default \"UNDEFINED\" e.g. \"arn:aws:lambda:eu-west-1:809313241:function:test\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'UNDEFINED'</code> </p> <code>function_request_id</code> <p>Lambda function unique request id, by default \"UNDEFINED\" e.g. \"52fdfc07-2182-154f-163f-5f0f9a621d72\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>'UNDEFINED'</code> </p> Source code in <code>aws_lambda_powertools/logging/lambda_context.py</code> <pre><code>def __init__(\n    self,\n    function_name: str = \"UNDEFINED\",\n    function_memory_size: int = 128,\n    function_arn: str = \"UNDEFINED\",\n    function_request_id: str = \"UNDEFINED\",\n):\n    self.function_name = function_name\n    self.function_memory_size = function_memory_size\n    self.function_arn = function_arn\n    self.function_request_id = function_request_id\n</code></pre>"
        },
        {
            "location": "api_doc/logger/lambda_context/#aws_lambda_powertools.logging.lambda_context.build_lambda_context_model",
            "title": "build_lambda_context_model",
            "text": "<pre><code>build_lambda_context_model(\n    context: Any,\n) -&gt; LambdaContextModel\n</code></pre> <p>Captures Lambda function runtime info to be used across all log statements</p> PARAMETER DESCRIPTION <code>context</code> <p>Lambda context object</p> <p> TYPE: <code>object</code> </p> RETURNS DESCRIPTION <code>LambdaContextModel</code> <p>Lambda context only with select fields</p> Source code in <code>aws_lambda_powertools/logging/lambda_context.py</code> <pre><code>def build_lambda_context_model(context: Any) -&gt; LambdaContextModel:\n    \"\"\"Captures Lambda function runtime info to be used across all log statements\n\n    Parameters\n    ----------\n    context : object\n        Lambda context object\n\n    Returns\n    -------\n    LambdaContextModel\n        Lambda context only with select fields\n    \"\"\"\n\n    context = {\n        \"function_name\": context.function_name,\n        \"function_memory_size\": context.memory_limit_in_mb,\n        \"function_arn\": context.invoked_function_arn,\n        \"function_request_id\": context.aws_request_id,\n    }\n\n    return LambdaContextModel(**context)\n</code></pre>"
        },
        {
            "location": "api_doc/logger/logger/",
            "title": "Logger",
            "text": "<p>Logger utility</p> <p>Usage Documentation</p> <p><code>Logger</code></p> CLASS DESCRIPTION <code>Logger</code> <p>Creates and setups a logger to format statements in JSON.</p> FUNCTION DESCRIPTION <code>log_uncaught_exception_hook</code> <p>Callback function for sys.excepthook to use Logger to log uncaught exceptions</p> <code>set_package_logger</code> <p>Set an additional stream handler, formatter, and log level for aws_lambda_powertools package logger.</p>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger",
            "title": "Logger",
            "text": "<pre><code>Logger(\n    service: str | None = None,\n    level: str | int | None = None,\n    child: bool = False,\n    sampling_rate: float | None = None,\n    stream: IO[str] | None = None,\n    logger_formatter: PowertoolsFormatter | None = None,\n    logger_handler: Handler | None = None,\n    log_uncaught_exceptions: bool = False,\n    json_serializer: Callable[[dict], str] | None = None,\n    json_deserializer: (\n        Callable[[dict | str | bool | int | float], str]\n        | None\n    ) = None,\n    json_default: Callable[[Any], Any] | None = None,\n    datefmt: str | None = None,\n    use_datetime_directive: bool = False,\n    log_record_order: list[str] | None = None,\n    utc: bool = False,\n    use_rfc3339: bool = False,\n    serialize_stacktrace: bool = True,\n    buffer_config: LoggerBufferConfig | None = None,\n    **kwargs\n)\n</code></pre> <p>Creates and setups a logger to format statements in JSON.</p> <p>Includes service name and any additional key=value into logs It also accepts both service name or level explicitly via env vars</p> Environment variables <p>POWERTOOLS_SERVICE_NAME : str     service name POWERTOOLS_LOG_LEVEL: str     logging level (e.g. INFO, DEBUG) POWERTOOLS_LOGGER_SAMPLE_RATE: float     sampling rate ranging from 0 to 1, 1 being 100% sampling</p> PARAMETER DESCRIPTION <code>service</code> <p>service name to be appended in logs, by default \"service_undefined\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>level</code> <p>The level to set. Can be a string representing the level name: 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL' or an integer representing the level value: 10 for 'DEBUG', 20 for 'INFO', 30 for 'WARNING', 40 for 'ERROR', 50 for 'CRITICAL'. by default \"INFO\"</p> <p> TYPE: <code>str, int optional</code> DEFAULT: <code>None</code> </p> <code>child</code> <p>create a child Logger named ., False by default <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>sampling_rate</code> <p>sample rate for debug calls within execution context defaults to 0.0</p> <p> TYPE: <code>float | None</code> DEFAULT: <code>None</code> </p> <code>stream</code> <p>valid output for a logging stream, by default sys.stdout</p> <p> TYPE: <code>IO[str] | None</code> DEFAULT: <code>None</code> </p> <code>logger_formatter</code> <p>custom logging formatter that implements PowertoolsFormatter</p> <p> TYPE: <code>PowertoolsFormatter | None</code> DEFAULT: <code>None</code> </p> <code>logger_handler</code> <p>custom logging handler e.g. logging.FileHandler(\"file.log\")</p> <p> TYPE: <code>Handler | None</code> DEFAULT: <code>None</code> </p> <code>log_uncaught_exceptions</code> <p>logs uncaught exception using sys.excepthook</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>buffer_config</code> <p>logger buffer configuration</p> <p>See: https://docs.python.org/3/library/sys.html#sys.excepthook</p> <p> TYPE: <code>LoggerBufferConfig | None</code> DEFAULT: <code>None</code> </p> Parameters propagated to LambdaPowertoolsFormatter <p>json_serializer : Callable, optional     function to serialize <code>obj</code> to a JSON formatted <code>str</code>, by default json.dumps json_deserializer : Callable, optional     function to deserialize <code>str</code>, <code>bytes</code>, bytearray<code>containing a JSON document to a Python</code>obj<code>,     by default json.loads json_default : Callable, optional     function to coerce unserializable values, by default</code>str()`     Only used when no custom formatter is set utc : bool, optional     set logging timestamp to UTC, by default False to continue to use local time as per stdlib log_record_order : list, optional     set order of log keys when logging, by default [\"level\", \"location\", \"message\", \"timestamp\"]</p> Example <p>Setups structured logging in JSON for Lambda functions with explicit service name</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools import Logger\n&gt;&gt;&gt; logger = Logger(service=\"payment\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; def handler(event, context):\n        logger.info(\"Hello\")\n</code></pre> <p>Setups structured logging in JSON for Lambda functions using env vars</p> <pre><code>$ export POWERTOOLS_SERVICE_NAME=\"payment\"\n$ export POWERTOOLS_LOGGER_SAMPLE_RATE=0.01 # 1% debug sampling\n&gt;&gt;&gt; from aws_lambda_powertools import Logger\n&gt;&gt;&gt; logger = Logger()\n&gt;&gt;&gt;\n&gt;&gt;&gt; def handler(event, context):\n        logger.info(\"Hello\")\n</code></pre> <p>Append payment_id to previously setup logger</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools import Logger\n&gt;&gt;&gt; logger = Logger(service=\"payment\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; def handler(event, context):\n        logger.append_keys(payment_id=event[\"payment_id\"])\n        logger.info(\"Hello\")\n</code></pre> <p>Create child Logger using logging inheritance via child param</p> <pre><code>&gt;&gt;&gt; # app.py\n&gt;&gt;&gt; import another_file\n&gt;&gt;&gt; from aws_lambda_powertools import Logger\n&gt;&gt;&gt; logger = Logger(service=\"payment\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; # another_file.py\n&gt;&gt;&gt; from aws_lambda_powertools import Logger\n&gt;&gt;&gt; logger = Logger(service=\"payment\", child=True)\n</code></pre> <p>Logging in UTC timezone</p> <pre><code>&gt;&gt;&gt; # app.py\n&gt;&gt;&gt; import logging\n&gt;&gt;&gt; from aws_lambda_powertools import Logger\n&gt;&gt;&gt;\n&gt;&gt;&gt; logger = Logger(service=\"payment\", utc=True)\n</code></pre> <p>Brings message as the first key in log statements</p> <pre><code>&gt;&gt;&gt; # app.py\n&gt;&gt;&gt; import logging\n&gt;&gt;&gt; from aws_lambda_powertools import Logger\n&gt;&gt;&gt;\n&gt;&gt;&gt; logger = Logger(service=\"payment\", log_record_order=[\"message\"])\n</code></pre> <p>Logging to a file instead of standard output for testing</p> <pre><code>&gt;&gt;&gt; # app.py\n&gt;&gt;&gt; import logging\n&gt;&gt;&gt; from aws_lambda_powertools import Logger\n&gt;&gt;&gt;\n&gt;&gt;&gt; logger = Logger(service=\"payment\", logger_handler=logging.FileHandler(\"log.json\"))\n</code></pre> RAISES DESCRIPTION <code>InvalidLoggerSamplingRateError</code> <p>When sampling rate provided is not a float</p> METHOD DESCRIPTION <code>append_context_keys</code> <p>Context manager to temporarily add logging keys.</p> <code>clear_buffer</code> <p>Clear the internal buffer cache.</p> <code>clear_state</code> <p>Removes all custom keys that were appended to the Logger.</p> <code>flush_buffer</code> <p>Flush all buffered log records associated with current execution.</p> <code>get_correlation_id</code> <p>Gets the correlation_id in the logging json</p> <code>inject_lambda_context</code> <p>Decorator to capture Lambda contextual info and inject into logger</p> <code>refresh_sample_rate_calculation</code> <p>Refreshes the sample rate calculation by reconfiguring logging settings.</p> <code>set_correlation_id</code> <p>Sets the correlation_id in the logging json</p> <code>structure_logs</code> <p>Sets logging formatting to JSON.</p> ATTRIBUTE DESCRIPTION <code>handlers</code> <p>List of registered logging handlers</p> <p> TYPE: <code>list[Handler]</code> </p> <code>registered_formatter</code> <p>Convenience property to access the first logger formatter</p> <p> TYPE: <code>BasePowertoolsFormatter</code> </p> <code>registered_handler</code> <p>Convenience property to access the first logger handler</p> <p> TYPE: <code>Handler</code> </p> Source code in <code>aws_lambda_powertools/logging/logger.py</code> <pre><code>def __init__(\n    self,\n    service: str | None = None,\n    level: str | int | None = None,\n    child: bool = False,\n    sampling_rate: float | None = None,\n    stream: IO[str] | None = None,\n    logger_formatter: PowertoolsFormatter | None = None,\n    logger_handler: logging.Handler | None = None,\n    log_uncaught_exceptions: bool = False,\n    json_serializer: Callable[[dict], str] | None = None,\n    json_deserializer: Callable[[dict | str | bool | int | float], str] | None = None,\n    json_default: Callable[[Any], Any] | None = None,\n    datefmt: str | None = None,\n    use_datetime_directive: bool = False,\n    log_record_order: list[str] | None = None,\n    utc: bool = False,\n    use_rfc3339: bool = False,\n    serialize_stacktrace: bool = True,\n    buffer_config: LoggerBufferConfig | None = None,\n    **kwargs,\n) -&gt; None:\n\n    # Used in case of sampling\n    self.initial_log_level = self._determine_log_level(level)\n\n    self.service = resolve_env_var_choice(\n        choice=service,\n        env=os.getenv(constants.SERVICE_NAME_ENV, \"service_undefined\"),\n    )\n    self.sampling_rate = resolve_env_var_choice(\n        choice=sampling_rate,\n        env=os.getenv(constants.LOGGER_LOG_SAMPLING_RATE),\n    )\n    self._default_log_keys: dict[str, Any] = {\"service\": self.service, \"sampling_rate\": self.sampling_rate}\n    self.child = child\n    self.logger_formatter = logger_formatter\n    self._stream = stream or sys.stdout\n\n    self.log_uncaught_exceptions = log_uncaught_exceptions\n\n    self._is_deduplication_disabled = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.LOGGER_LOG_DEDUPLICATION_ENV, \"false\"),\n    )\n    self._logger = self._get_logger()\n    self.logger_handler = logger_handler or self._get_handler()\n\n    # NOTE: This is primarily to improve UX, so IDEs can autocomplete LambdaPowertoolsFormatter options\n    # previously, we masked all of them as kwargs thus limiting feature discovery\n    formatter_options = {\n        \"json_serializer\": json_serializer,\n        \"json_deserializer\": json_deserializer,\n        \"json_default\": json_default,\n        \"datefmt\": datefmt,\n        \"use_datetime_directive\": use_datetime_directive,\n        \"log_record_order\": log_record_order,\n        \"utc\": utc,\n        \"use_rfc3339\": use_rfc3339,\n        \"serialize_stacktrace\": serialize_stacktrace,\n    }\n\n    self._buffer_config = buffer_config\n    if self._buffer_config:\n        self._buffer_cache = LoggerBufferCache(max_size_bytes=self._buffer_config.max_bytes)\n\n    self._init_logger(\n        formatter_options=formatter_options,\n        log_level=level,\n        buffer_config=self._buffer_config,\n        buffer_cache=getattr(self, \"_buffer_cache\", None),\n        **kwargs,\n    )\n\n    if self.log_uncaught_exceptions:\n        logger.debug(\"Replacing exception hook\")\n        sys.excepthook = functools.partial(log_uncaught_exception_hook, logger=self)\n</code></pre>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger.handlers",
            "title": "handlers  <code>property</code>",
            "text": "<pre><code>handlers: list[Handler]\n</code></pre> <p>List of registered logging handlers</p> Notes <p>Looking for the first configured handler? Use registered_handler property instead.</p>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger.registered_formatter",
            "title": "registered_formatter  <code>property</code>",
            "text": "<pre><code>registered_formatter: BasePowertoolsFormatter\n</code></pre> <p>Convenience property to access the first logger formatter</p>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger.registered_handler",
            "title": "registered_handler  <code>property</code>",
            "text": "<pre><code>registered_handler: Handler\n</code></pre> <p>Convenience property to access the first logger handler</p>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger.append_context_keys",
            "title": "append_context_keys",
            "text": "<pre><code>append_context_keys(\n    **additional_keys: Any,\n) -&gt; Generator[None, None, None]\n</code></pre> <p>Context manager to temporarily add logging keys.</p> PARAMETER DESCRIPTION <code>**additional_keys</code> <p>Key-value pairs to include in the log context during the lifespan of the context manager.</p> <p> TYPE: <code>Any</code> DEFAULT: <code>{}</code> </p> Example <p>Logging with contextual keys</p> <pre><code>logger = Logger(service=\"example_service\")\nwith logger.append_context_keys(user_id=\"123\", operation=\"process\"):\n    logger.info(\"Log with context\")\nlogger.info(\"Log without context\")\n</code></pre> Source code in <code>aws_lambda_powertools/logging/logger.py</code> <pre><code>@contextmanager\ndef append_context_keys(self, **additional_keys: Any) -&gt; Generator[None, None, None]:\n    \"\"\"\n    Context manager to temporarily add logging keys.\n\n    Parameters\n    -----------\n    **additional_keys: Any\n        Key-value pairs to include in the log context during the lifespan of the context manager.\n\n    Example\n    --------\n    **Logging with contextual keys**\n\n        logger = Logger(service=\"example_service\")\n        with logger.append_context_keys(user_id=\"123\", operation=\"process\"):\n            logger.info(\"Log with context\")\n        logger.info(\"Log without context\")\n    \"\"\"\n    with self.registered_formatter.append_context_keys(**additional_keys):\n        yield\n</code></pre>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger.clear_buffer",
            "title": "clear_buffer",
            "text": "<pre><code>clear_buffer() -&gt; None\n</code></pre> <p>Clear the internal buffer cache.</p> <p>This method removes all items from the buffer cache, effectively resetting it to an empty state.</p> RETURNS DESCRIPTION <code>None</code> Source code in <code>aws_lambda_powertools/logging/logger.py</code> <pre><code>def clear_buffer(self) -&gt; None:\n    \"\"\"\n    Clear the internal buffer cache.\n\n    This method removes all items from the buffer cache, effectively resetting it to an empty state.\n\n    Returns\n    -------\n    None\n    \"\"\"\n    if self._buffer_config:\n        self._buffer_cache.clear()\n</code></pre>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger.clear_state",
            "title": "clear_state",
            "text": "<pre><code>clear_state() -&gt; None\n</code></pre> <p>Removes all custom keys that were appended to the Logger.</p> Source code in <code>aws_lambda_powertools/logging/logger.py</code> <pre><code>def clear_state(self) -&gt; None:\n    \"\"\"Removes all custom keys that were appended to the Logger.\"\"\"\n    # Clear all custom keys from the formatter\n    self.registered_formatter.clear_state()\n\n    # Reset to default keys\n    self.structure_logs(**self._default_log_keys)\n</code></pre>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger.flush_buffer",
            "title": "flush_buffer",
            "text": "<pre><code>flush_buffer() -&gt; None\n</code></pre> <p>Flush all buffered log records associated with current execution.</p> Notes <p>Retrieves log records for current trace from buffer Immediately processes and logs each record Warning if some cache was evicted in that execution Clears buffer after complete processing</p> RAISES DESCRIPTION <code>Any exceptions from underlying logging or buffer mechanisms</code> <code>will be propagated to caller</code> Source code in <code>aws_lambda_powertools/logging/logger.py</code> <pre><code>def flush_buffer(self) -&gt; None:\n    \"\"\"\n    Flush all buffered log records associated with current execution.\n\n    Notes\n    -----\n    Retrieves log records for current trace from buffer\n    Immediately processes and logs each record\n    Warning if some cache was evicted in that execution\n    Clears buffer after complete processing\n\n    Raises\n    ------\n    Any exceptions from underlying logging or buffer mechanisms\n    will be propagated to caller\n    \"\"\"\n    tracer_id = get_tracer_id()\n\n    # Flushing log without a tracer id? Return\n    if not tracer_id:\n        return\n\n    # is buffer empty? return\n    buffer = self._buffer_cache.get(tracer_id)\n    if not buffer:\n        return\n\n    # Process log records\n    for log_line in buffer:\n        self._create_and_flush_log_record(log_line)\n\n    # Has items evicted?\n    if self._buffer_cache.has_items_evicted(tracer_id):\n        warnings.warn(\n            message=\"Some logs are not displayed because they were evicted from the buffer. \"\n            \"Increase buffer size to store more logs in the buffer\",\n            category=PowertoolsUserWarning,\n            stacklevel=2,\n        )\n\n    # Clear the entire cache\n    self._buffer_cache.clear()\n</code></pre>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger.get_correlation_id",
            "title": "get_correlation_id",
            "text": "<pre><code>get_correlation_id() -&gt; str | None\n</code></pre> <p>Gets the correlation_id in the logging json</p> RETURNS DESCRIPTION <code>(str, optional)</code> <p>Value for the correlation id</p> Source code in <code>aws_lambda_powertools/logging/logger.py</code> <pre><code>def get_correlation_id(self) -&gt; str | None:\n    \"\"\"Gets the correlation_id in the logging json\n\n    Returns\n    -------\n    str, optional\n        Value for the correlation id\n    \"\"\"\n    if isinstance(self.registered_formatter, LambdaPowertoolsFormatter):\n        return self.registered_formatter.log_format.get(\"correlation_id\")\n    return None\n</code></pre>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger.inject_lambda_context",
            "title": "inject_lambda_context",
            "text": "<pre><code>inject_lambda_context(\n    lambda_handler: AnyCallableT,\n    log_event: bool | None = None,\n    correlation_id_path: str | None = None,\n    clear_state: bool | None = False,\n    flush_buffer_on_uncaught_error: bool = False,\n) -&gt; AnyCallableT\n</code></pre><pre><code>inject_lambda_context(\n    lambda_handler: None = None,\n    log_event: bool | None = None,\n    correlation_id_path: str | None = None,\n    clear_state: bool | None = False,\n    flush_buffer_on_uncaught_error: bool = False,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]\n</code></pre> <pre><code>inject_lambda_context(\n    lambda_handler: AnyCallableT | None = None,\n    log_event: bool | None = None,\n    correlation_id_path: str | None = None,\n    clear_state: bool | None = False,\n    flush_buffer_on_uncaught_error: bool = False,\n) -&gt; Any\n</code></pre> <p>Decorator to capture Lambda contextual info and inject into logger</p> PARAMETER DESCRIPTION <code>clear_state</code> <p>Instructs logger to remove any custom keys previously added</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>lambda_handler</code> <p>Method to inject the lambda context</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>log_event</code> <p>Instructs logger to log Lambda Event, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>None</code> </p> <code>correlation_id_path</code> <p>Optional JMESPath for the correlation_id</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> Environment variables <p>POWERTOOLS_LOGGER_LOG_EVENT : str     instruct logger to log Lambda Event (e.g. <code>\"true\", \"True\", \"TRUE\"</code>)</p> Example <p>Captures Lambda contextual runtime info (e.g memory, arn, req_id)</p> <pre><code>from aws_lambda_powertools import Logger\n\nlogger = Logger(service=\"payment\")\n\n@logger.inject_lambda_context\ndef handler(event, context):\n    logger.info(\"Hello\")\n</code></pre> <p>Captures Lambda contextual runtime info and logs incoming request</p> <pre><code>from aws_lambda_powertools import Logger\n\nlogger = Logger(service=\"payment\")\n\n@logger.inject_lambda_context(log_event=True)\ndef handler(event, context):\n    logger.info(\"Hello\")\n</code></pre> RETURNS DESCRIPTION <code>decorate</code> <p>Decorated lambda handler</p> <p> TYPE: <code>Callable</code> </p> Source code in <code>aws_lambda_powertools/logging/logger.py</code> <pre><code>def inject_lambda_context(\n    self,\n    lambda_handler: AnyCallableT | None = None,\n    log_event: bool | None = None,\n    correlation_id_path: str | None = None,\n    clear_state: bool | None = False,\n    flush_buffer_on_uncaught_error: bool = False,\n) -&gt; Any:\n    \"\"\"Decorator to capture Lambda contextual info and inject into logger\n\n    Parameters\n    ----------\n    clear_state : bool, optional\n        Instructs logger to remove any custom keys previously added\n    lambda_handler : Callable\n        Method to inject the lambda context\n    log_event : bool, optional\n        Instructs logger to log Lambda Event, by default False\n    correlation_id_path: str, optional\n        Optional JMESPath for the correlation_id\n\n    Environment variables\n    ---------------------\n    POWERTOOLS_LOGGER_LOG_EVENT : str\n        instruct logger to log Lambda Event (e.g. `\"true\", \"True\", \"TRUE\"`)\n\n    Example\n    -------\n    **Captures Lambda contextual runtime info (e.g memory, arn, req_id)**\n\n        from aws_lambda_powertools import Logger\n\n        logger = Logger(service=\"payment\")\n\n        @logger.inject_lambda_context\n        def handler(event, context):\n            logger.info(\"Hello\")\n\n    **Captures Lambda contextual runtime info and logs incoming request**\n\n        from aws_lambda_powertools import Logger\n\n        logger = Logger(service=\"payment\")\n\n        @logger.inject_lambda_context(log_event=True)\n        def handler(event, context):\n            logger.info(\"Hello\")\n\n    Returns\n    -------\n    decorate : Callable\n        Decorated lambda handler\n    \"\"\"\n\n    # If handler is None we've been called with parameters\n    # Return a partial function with args filled\n    if lambda_handler is None:\n        logger.debug(\"Decorator called with parameters\")\n        return functools.partial(\n            self.inject_lambda_context,\n            log_event=log_event,\n            correlation_id_path=correlation_id_path,\n            clear_state=clear_state,\n            flush_buffer_on_uncaught_error=flush_buffer_on_uncaught_error,\n        )\n\n    log_event = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.LOGGER_LOG_EVENT_ENV, \"false\"),\n        choice=log_event,\n    )\n\n    @functools.wraps(lambda_handler)\n    def decorate(event, context, *args, **kwargs):\n        lambda_context = build_lambda_context_model(context)\n        cold_start = _is_cold_start()\n\n        if clear_state:\n            self.structure_logs(cold_start=cold_start, **lambda_context.__dict__)\n        else:\n            self.append_keys(cold_start=cold_start, **lambda_context.__dict__)\n\n        if correlation_id_path:\n            self.set_correlation_id(\n                jmespath_utils.query(envelope=correlation_id_path, data=event),\n            )\n\n        if log_event:\n            logger.debug(\"Event received\")\n            self.info(extract_event_from_common_models(event))\n\n        # Sampling rate is defined, and this is not ColdStart\n        # then we need to recalculate the sampling\n        # See: https://github.com/aws-powertools/powertools-lambda-python/issues/6141\n        if self.sampling_rate and not cold_start:\n            self.refresh_sample_rate_calculation()\n\n        try:\n            # Execute the Lambda handler with provided event and context\n            return lambda_handler(event, context, *args, **kwargs)\n        except:\n            # Flush the log buffer if configured to do so on uncaught errors\n            # Ensures logging state is cleaned up even if an exception is raised\n            if flush_buffer_on_uncaught_error:\n                logger.debug(\"Uncaught error detected, flushing log buffer before exit\")\n                self.flush_buffer()\n            # Re-raise any exceptions that occur during handler execution\n            raise\n        finally:\n            # Clear the cache after invocation is complete\n            if self._buffer_config:\n                self._buffer_cache.clear()\n\n    return decorate\n</code></pre>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger.refresh_sample_rate_calculation",
            "title": "refresh_sample_rate_calculation",
            "text": "<pre><code>refresh_sample_rate_calculation() -&gt; None\n</code></pre> <p>Refreshes the sample rate calculation by reconfiguring logging settings.</p> RETURNS DESCRIPTION <code>    None</code> Source code in <code>aws_lambda_powertools/logging/logger.py</code> <pre><code>def refresh_sample_rate_calculation(self) -&gt; None:\n    \"\"\"\n    Refreshes the sample rate calculation by reconfiguring logging settings.\n\n    Returns\n    -------\n        None\n    \"\"\"\n    self._logger.setLevel(self.initial_log_level)\n    self._configure_sampling()\n</code></pre>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger.set_correlation_id",
            "title": "set_correlation_id",
            "text": "<pre><code>set_correlation_id(value: str | None) -&gt; None\n</code></pre> <p>Sets the correlation_id in the logging json</p> PARAMETER DESCRIPTION <code>value</code> <p>Value for the correlation id. None will remove the correlation_id</p> <p> TYPE: <code>str</code> </p> Source code in <code>aws_lambda_powertools/logging/logger.py</code> <pre><code>def set_correlation_id(self, value: str | None) -&gt; None:\n    \"\"\"Sets the correlation_id in the logging json\n\n    Parameters\n    ----------\n    value : str, optional\n        Value for the correlation id. None will remove the correlation_id\n    \"\"\"\n    self.append_keys(correlation_id=value)\n</code></pre>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.Logger.structure_logs",
            "title": "structure_logs",
            "text": "<pre><code>structure_logs(\n    append: bool = False,\n    formatter_options: dict | None = None,\n    **keys\n) -&gt; None\n</code></pre> <p>Sets logging formatting to JSON.</p> <p>Optionally, it can append keyword arguments to an existing logger, so it is available across future log statements.</p> <p>Last keyword argument and value wins if duplicated.</p> PARAMETER DESCRIPTION <code>append</code> <p>append keys provided to logger formatter, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>formatter_options</code> <p>LambdaPowertoolsFormatter options to be propagated, by default {}</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/logging/logger.py</code> <pre><code>def structure_logs(self, append: bool = False, formatter_options: dict | None = None, **keys) -&gt; None:\n    \"\"\"Sets logging formatting to JSON.\n\n    Optionally, it can append keyword arguments\n    to an existing logger, so it is available across future log statements.\n\n    Last keyword argument and value wins if duplicated.\n\n    Parameters\n    ----------\n    append : bool, optional\n        append keys provided to logger formatter, by default False\n    formatter_options : dict, optional\n        LambdaPowertoolsFormatter options to be propagated, by default {}\n    \"\"\"\n    formatter_options = formatter_options or {}\n\n    # There are 3 operational modes for this method\n    ## 1. Register a Powertools for AWS Lambda (Python) Formatter for the first time\n    ## 2. Append new keys to the current logger formatter; deprecated in favour of append_keys\n    ## 3. Add new keys and discard existing to the registered formatter\n\n    # Mode 1\n    log_keys = {**self._default_log_keys, **keys}\n    is_logger_preconfigured = getattr(self._logger, LOGGER_ATTRIBUTE_PRECONFIGURED, False)\n    if not is_logger_preconfigured:\n        formatter = self.logger_formatter or LambdaPowertoolsFormatter(**formatter_options, **log_keys)\n        self.registered_handler.setFormatter(formatter)\n\n        # when using a custom Powertools for AWS Lambda (Python) Formatter\n        # standard and custom keys that are not Powertools for AWS Lambda (Python) Formatter parameters\n        # should be appended and custom keys that might happen to be Powertools for AWS Lambda (Python)\n        # Formatter parameters should be discarded this prevents adding them as custom keys, for example,\n        # `json_default=&lt;callable&gt;` see https://github.com/aws-powertools/powertools-lambda-python/issues/1263\n        custom_keys = {k: v for k, v in log_keys.items() if k not in RESERVED_FORMATTER_CUSTOM_KEYS}\n        return self.registered_formatter.append_keys(**custom_keys)\n\n    # Mode 2 (legacy)\n    if append:\n        # Maintenance: Add deprecation warning for major version\n        return self.append_keys(**keys)\n\n    # Mode 3\n    self.registered_formatter.clear_state()\n    self.registered_formatter.thread_safe_clear_keys()\n    self.registered_formatter.append_keys(**log_keys)\n</code></pre>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.log_uncaught_exception_hook",
            "title": "log_uncaught_exception_hook",
            "text": "<pre><code>log_uncaught_exception_hook(\n    exc_type, exc_value, exc_traceback, logger: Logger\n) -&gt; None\n</code></pre> <p>Callback function for sys.excepthook to use Logger to log uncaught exceptions</p> Source code in <code>aws_lambda_powertools/logging/logger.py</code> <pre><code>def log_uncaught_exception_hook(exc_type, exc_value, exc_traceback, logger: Logger) -&gt; None:\n    \"\"\"Callback function for sys.excepthook to use Logger to log uncaught exceptions\"\"\"\n    logger.exception(exc_value, exc_info=(exc_type, exc_value, exc_traceback))  # pragma: no cover\n</code></pre>"
        },
        {
            "location": "api_doc/logger/logger/#aws_lambda_powertools.logging.logger.set_package_logger",
            "title": "set_package_logger",
            "text": "<pre><code>set_package_logger(\n    level: str | int = logging.DEBUG,\n    stream: IO[str] | None = None,\n    formatter: Formatter | None = None,\n) -&gt; None\n</code></pre> <p>Set an additional stream handler, formatter, and log level for aws_lambda_powertools package logger.</p> <p>Package log by default is suppressed (NullHandler), this should only used for debugging. This is separate from application Logger class utility</p> Example <p>Enables debug logging for Powertools for AWS Lambda (Python) package</p> <pre><code>&gt;&gt;&gt; aws_lambda_powertools.logging.logger import set_package_logger\n&gt;&gt;&gt; set_package_logger()\n</code></pre> PARAMETER DESCRIPTION <code>level</code> <p>log level, DEBUG by default</p> <p> TYPE: <code>str | int</code> DEFAULT: <code>DEBUG</code> </p> <code>stream</code> <p>log stream, stdout by default</p> <p> TYPE: <code>IO[str] | None</code> DEFAULT: <code>None</code> </p> <code>formatter</code> <p>log formatter, \"%(asctime)s %(name)s [%(levelname)s] %(message)s\" by default</p> <p> TYPE: <code>Formatter | None</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/logging/logger.py</code> <pre><code>def set_package_logger(\n    level: str | int = logging.DEBUG,\n    stream: IO[str] | None = None,\n    formatter: logging.Formatter | None = None,\n) -&gt; None:\n    \"\"\"Set an additional stream handler, formatter, and log level for aws_lambda_powertools package logger.\n\n    **Package log by default is suppressed (NullHandler), this should only used for debugging.\n    This is separate from application Logger class utility**\n\n    Example\n    -------\n    **Enables debug logging for Powertools for AWS Lambda (Python) package**\n\n        &gt;&gt;&gt; aws_lambda_powertools.logging.logger import set_package_logger\n        &gt;&gt;&gt; set_package_logger()\n\n    Parameters\n    ----------\n    level: str, int\n        log level, DEBUG by default\n    stream: sys.stdout\n        log stream, stdout by default\n    formatter: logging.Formatter\n        log formatter, \"%(asctime)s %(name)s [%(levelname)s] %(message)s\" by default\n    \"\"\"\n    if formatter is None:\n        formatter = logging.Formatter(\"%(asctime)s %(name)s [%(levelname)s] %(message)s\")\n\n    if stream is None:\n        stream = sys.stdout\n\n    logger = logging.getLogger(\"aws_lambda_powertools\")\n    logger.setLevel(level)\n    handler = logging.StreamHandler(stream)\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/base/",
            "title": "Base",
            "text": "<p>Metrics utility</p> <p>Usage Documentation</p> <p><code>Metrics</code></p> CLASS DESCRIPTION <code>MetricManager</code> <p>Base class for metric functionality (namespace, metric, dimension, serialization)</p> <code>SingleMetric</code> <p>SingleMetric creates an EMF object with a single metric.</p> FUNCTION DESCRIPTION <code>single_metric</code> <p>Context manager to simplify creation of a single metric</p>"
        },
        {
            "location": "api_doc/metrics/base/#aws_lambda_powertools.metrics.base.MetricManager",
            "title": "MetricManager",
            "text": "<pre><code>MetricManager(\n    metric_set: dict[str, Any] | None = None,\n    dimension_set: dict | None = None,\n    namespace: str | None = None,\n    metadata_set: dict[str, Any] | None = None,\n    service: str | None = None,\n)\n</code></pre> <p>Base class for metric functionality (namespace, metric, dimension, serialization)</p> <p>MetricManager creates metrics asynchronously thanks to CloudWatch Embedded Metric Format (EMF). CloudWatch EMF can create up to 100 metrics per EMF object and metrics, dimensions, and namespace created via MetricManager will adhere to the schema, will be serialized and validated against EMF Schema.</p> <p>Use <code>aws_lambda_powertools.metrics.metrics.Metrics</code> or <code>aws_lambda_powertools.metrics.metric.single_metric</code> to create EMF metrics.</p> Environment variables <p>POWERTOOLS_METRICS_NAMESPACE : str     metric namespace to be set for all metrics POWERTOOLS_SERVICE_NAME : str     service name used for default dimension</p> RAISES DESCRIPTION <code>MetricUnitError</code> <p>When metric unit isn't supported by CloudWatch</p> <code>MetricResolutionError</code> <p>When metric resolution isn't supported by CloudWatch</p> <code>MetricValueError</code> <p>When metric value isn't a number</p> <code>SchemaValidationError</code> <p>When metric object fails EMF schema validation</p> METHOD DESCRIPTION <code>add_dimension</code> <p>Adds given dimension to all metrics</p> <code>add_metadata</code> <p>Adds high cardinal metadata for metrics object</p> <code>add_metric</code> <p>Adds given metric</p> <code>flush_metrics</code> <p>Manually flushes the metrics. This is normally not necessary,</p> <code>log_metrics</code> <p>Decorator to serialize and publish metrics at the end of a function execution.</p> <code>serialize_metric_set</code> <p>Serializes metric and dimensions set</p> <code>set_timestamp</code> <p>Set the timestamp for the metric.</p> Source code in <code>aws_lambda_powertools/metrics/base.py</code> <pre><code>def __init__(\n    self,\n    metric_set: dict[str, Any] | None = None,\n    dimension_set: dict | None = None,\n    namespace: str | None = None,\n    metadata_set: dict[str, Any] | None = None,\n    service: str | None = None,\n):\n    self.metric_set = metric_set if metric_set is not None else {}\n    self.dimension_set = dimension_set if dimension_set is not None else {}\n    self.namespace = resolve_env_var_choice(choice=namespace, env=os.getenv(constants.METRICS_NAMESPACE_ENV))\n    self.service = resolve_env_var_choice(choice=service, env=os.getenv(constants.SERVICE_NAME_ENV))\n    self.metadata_set = metadata_set if metadata_set is not None else {}\n    self.timestamp: int | None = None\n\n    self._metric_units = [unit.value for unit in MetricUnit]\n    self._metric_unit_valid_options = list(MetricUnit.__members__)\n    self._metric_resolutions = [resolution.value for resolution in MetricResolution]\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/base/#aws_lambda_powertools.metrics.base.MetricManager.add_dimension",
            "title": "add_dimension",
            "text": "<pre><code>add_dimension(name: str, value: str) -&gt; None\n</code></pre> <p>Adds given dimension to all metrics</p> Example <p>Add a metric dimensions</p> <pre><code>metric.add_dimension(name=\"operation\", value=\"confirm_booking\")\n</code></pre> PARAMETER DESCRIPTION <code>name</code> <p>Dimension name</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Dimension value</p> <p> TYPE: <code>str</code> </p> Source code in <code>aws_lambda_powertools/metrics/base.py</code> <pre><code>def add_dimension(self, name: str, value: str) -&gt; None:\n    \"\"\"Adds given dimension to all metrics\n\n    Example\n    -------\n    **Add a metric dimensions**\n\n        metric.add_dimension(name=\"operation\", value=\"confirm_booking\")\n\n    Parameters\n    ----------\n    name : str\n        Dimension name\n    value : str\n        Dimension value\n    \"\"\"\n    logger.debug(f\"Adding dimension: {name}:{value}\")\n    if len(self.dimension_set) == MAX_DIMENSIONS:\n        raise SchemaValidationError(\n            f\"Maximum number of dimensions exceeded ({MAX_DIMENSIONS}): Unable to add dimension {name}.\",\n        )\n    # Cast value to str according to EMF spec\n    # Majority of values are expected to be string already, so\n    # checking before casting improves performance in most cases\n    self.dimension_set[name] = value if isinstance(value, str) else str(value)\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/base/#aws_lambda_powertools.metrics.base.MetricManager.add_metadata",
            "title": "add_metadata",
            "text": "<pre><code>add_metadata(key: str, value: Any) -&gt; None\n</code></pre> <p>Adds high cardinal metadata for metrics object</p> <p>This will not be available during metrics visualization. Instead, this will be searchable through logs.</p> <p>If you're looking to add metadata to filter metrics, then use add_dimensions method.</p> Example <p>Add metrics metadata</p> <pre><code>metric.add_metadata(key=\"booking_id\", value=\"booking_id\")\n</code></pre> PARAMETER DESCRIPTION <code>key</code> <p>Metadata key</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Metadata value</p> <p> TYPE: <code>any</code> </p> Source code in <code>aws_lambda_powertools/metrics/base.py</code> <pre><code>def add_metadata(self, key: str, value: Any) -&gt; None:\n    \"\"\"Adds high cardinal metadata for metrics object\n\n    This will not be available during metrics visualization.\n    Instead, this will be searchable through logs.\n\n    If you're looking to add metadata to filter metrics, then\n    use add_dimensions method.\n\n    Example\n    -------\n    **Add metrics metadata**\n\n        metric.add_metadata(key=\"booking_id\", value=\"booking_id\")\n\n    Parameters\n    ----------\n    key : str\n        Metadata key\n    value : any\n        Metadata value\n    \"\"\"\n    logger.debug(f\"Adding metadata: {key}:{value}\")\n\n    # Cast key to str according to EMF spec\n    # Majority of keys are expected to be string already, so\n    # checking before casting improves performance in most cases\n    if isinstance(key, str):\n        self.metadata_set[key] = value\n    else:\n        self.metadata_set[str(key)] = value\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/base/#aws_lambda_powertools.metrics.base.MetricManager.add_metric",
            "title": "add_metric",
            "text": "<pre><code>add_metric(\n    name: str,\n    unit: MetricUnit | str,\n    value: float,\n    resolution: MetricResolution | int = 60,\n) -&gt; None\n</code></pre> <p>Adds given metric</p> Example <p>Add given metric using MetricUnit enum</p> <pre><code>metric.add_metric(name=\"BookingConfirmation\", unit=MetricUnit.Count, value=1)\n</code></pre> <p>Add given metric using plain string as value unit</p> <pre><code>metric.add_metric(name=\"BookingConfirmation\", unit=\"Count\", value=1)\n</code></pre> <p>Add given metric with MetricResolution non default value</p> <pre><code>metric.add_metric(name=\"BookingConfirmation\", unit=\"Count\", value=1, resolution=MetricResolution.High)\n</code></pre> PARAMETER DESCRIPTION <code>name</code> <p>Metric name</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p><code>aws_lambda_powertools.helper.models.MetricUnit</code></p> <p> TYPE: <code>MetricUnit | str</code> </p> <code>value</code> <p>Metric value</p> <p> TYPE: <code>float</code> </p> <code>resolution</code> <p><code>aws_lambda_powertools.helper.models.MetricResolution</code></p> <p> TYPE: <code>MetricResolution | int</code> DEFAULT: <code>60</code> </p> RAISES DESCRIPTION <code>MetricUnitError</code> <p>When metric unit is not supported by CloudWatch</p> <code>MetricResolutionError</code> <p>When metric resolution is not supported by CloudWatch</p> Source code in <code>aws_lambda_powertools/metrics/base.py</code> <pre><code>def add_metric(\n    self,\n    name: str,\n    unit: MetricUnit | str,\n    value: float,\n    resolution: MetricResolution | int = 60,\n) -&gt; None:\n    \"\"\"Adds given metric\n\n    Example\n    -------\n    **Add given metric using MetricUnit enum**\n\n        metric.add_metric(name=\"BookingConfirmation\", unit=MetricUnit.Count, value=1)\n\n    **Add given metric using plain string as value unit**\n\n        metric.add_metric(name=\"BookingConfirmation\", unit=\"Count\", value=1)\n\n    **Add given metric with MetricResolution non default value**\n\n        metric.add_metric(name=\"BookingConfirmation\", unit=\"Count\", value=1, resolution=MetricResolution.High)\n\n    Parameters\n    ----------\n    name : str\n        Metric name\n    unit : MetricUnit | str\n        `aws_lambda_powertools.helper.models.MetricUnit`\n    value : float\n        Metric value\n    resolution : MetricResolution | int\n        `aws_lambda_powertools.helper.models.MetricResolution`\n\n    Raises\n    ------\n    MetricUnitError\n        When metric unit is not supported by CloudWatch\n    MetricResolutionError\n        When metric resolution is not supported by CloudWatch\n    \"\"\"\n    if not isinstance(value, numbers.Number):\n        raise MetricValueError(f\"{value} is not a valid number\")\n\n    unit = self._extract_metric_unit_value(unit=unit)\n    resolution = self._extract_metric_resolution_value(resolution=resolution)\n    metric: dict = self.metric_set.get(name, defaultdict(list))\n    metric[\"Unit\"] = unit\n    metric[\"StorageResolution\"] = resolution\n    metric[\"Value\"].append(float(value))\n    logger.debug(f\"Adding metric: {name} with {metric}\")\n    self.metric_set[name] = metric\n\n    if len(self.metric_set) == MAX_METRICS or len(metric[\"Value\"]) == MAX_METRICS:\n        logger.debug(f\"Exceeded maximum of {MAX_METRICS} metrics - Publishing existing metric set\")\n        metrics = self.serialize_metric_set()\n        print(json.dumps(metrics))\n\n        # clear metric set only as opposed to metrics and dimensions set\n        # since we could have more than 100 metrics\n        self.metric_set.clear()\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/base/#aws_lambda_powertools.metrics.base.MetricManager.flush_metrics",
            "title": "flush_metrics",
            "text": "<pre><code>flush_metrics(raise_on_empty_metrics: bool = False) -&gt; None\n</code></pre> <p>Manually flushes the metrics. This is normally not necessary, unless you're running on other runtimes besides Lambda, where the @log_metrics decorator already handles things for you.</p> PARAMETER DESCRIPTION <code>raise_on_empty_metrics</code> <p>raise exception if no metrics are emitted, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>aws_lambda_powertools/metrics/base.py</code> <pre><code>def flush_metrics(self, raise_on_empty_metrics: bool = False) -&gt; None:\n    \"\"\"Manually flushes the metrics. This is normally not necessary,\n    unless you're running on other runtimes besides Lambda, where the @log_metrics\n    decorator already handles things for you.\n\n    Parameters\n    ----------\n    raise_on_empty_metrics : bool, optional\n        raise exception if no metrics are emitted, by default False\n    \"\"\"\n    if not raise_on_empty_metrics and not self.metric_set:\n        warnings.warn(\n            \"No application metrics to publish. The cold-start metric may be published if enabled. \"\n            \"If application metrics should never be empty, consider using 'raise_on_empty_metrics'\",\n            stacklevel=2,\n        )\n    else:\n        logger.debug(\"Flushing existing metrics\")\n        metrics = self.serialize_metric_set()\n        print(json.dumps(metrics, separators=(\",\", \":\")))\n        self.clear_metrics()\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/base/#aws_lambda_powertools.metrics.base.MetricManager.log_metrics",
            "title": "log_metrics",
            "text": "<pre><code>log_metrics(\n    lambda_handler: (\n        Callable[[dict, Any], Any]\n        | Callable[[dict, Any, dict | None], Any]\n        | None\n    ) = None,\n    capture_cold_start_metric: bool = False,\n    raise_on_empty_metrics: bool = False,\n    default_dimensions: dict[str, str] | None = None,\n)\n</code></pre> <p>Decorator to serialize and publish metrics at the end of a function execution.</p> <p>Be aware that the log_metrics *does call the decorated function (e.g. lambda_handler).</p> Example <p>Lambda function using tracer and metrics decorators</p> <pre><code>from aws_lambda_powertools import Metrics, Tracer\n\nmetrics = Metrics(service=\"payment\")\ntracer = Tracer(service=\"payment\")\n\n@tracer.capture_lambda_handler\n@metrics.log_metrics\ndef handler(event, context):\n        ...\n</code></pre> PARAMETER DESCRIPTION <code>lambda_handler</code> <p>lambda function handler, by default None</p> <p> TYPE: <code>Callable[[Any, Any], Any]</code> DEFAULT: <code>None</code> </p> <code>capture_cold_start_metric</code> <p>captures cold start metric, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>raise_on_empty_metrics</code> <p>raise exception if no metrics are emitted, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>default_dimensions</code> <p>metric dimensions as key=value that will always be present</p> <p> TYPE: <code>dict[str, str] | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>e</code> <p>Propagate error received</p> Source code in <code>aws_lambda_powertools/metrics/base.py</code> <pre><code>def log_metrics(\n    self,\n    lambda_handler: Callable[[dict, Any], Any] | Callable[[dict, Any, dict | None], Any] | None = None,\n    capture_cold_start_metric: bool = False,\n    raise_on_empty_metrics: bool = False,\n    default_dimensions: dict[str, str] | None = None,\n):\n    \"\"\"Decorator to serialize and publish metrics at the end of a function execution.\n\n    Be aware that the log_metrics **does call* the decorated function (e.g. lambda_handler).\n\n    Example\n    -------\n    **Lambda function using tracer and metrics decorators**\n\n        from aws_lambda_powertools import Metrics, Tracer\n\n        metrics = Metrics(service=\"payment\")\n        tracer = Tracer(service=\"payment\")\n\n        @tracer.capture_lambda_handler\n        @metrics.log_metrics\n        def handler(event, context):\n                ...\n\n    Parameters\n    ----------\n    lambda_handler : Callable[[Any, Any], Any], optional\n        lambda function handler, by default None\n    capture_cold_start_metric : bool, optional\n        captures cold start metric, by default False\n    raise_on_empty_metrics : bool, optional\n        raise exception if no metrics are emitted, by default False\n    default_dimensions: dict[str, str], optional\n        metric dimensions as key=value that will always be present\n\n    Raises\n    ------\n    e\n        Propagate error received\n    \"\"\"\n\n    # If handler is None we've been called with parameters\n    # Return a partial function with args filled\n    if lambda_handler is None:\n        logger.debug(\"Decorator called with parameters\")\n        return functools.partial(\n            self.log_metrics,\n            capture_cold_start_metric=capture_cold_start_metric,\n            raise_on_empty_metrics=raise_on_empty_metrics,\n            default_dimensions=default_dimensions,\n        )\n\n    @functools.wraps(lambda_handler)\n    def decorate(event, context, *args, **kwargs):\n        try:\n            if default_dimensions:\n                self.set_default_dimensions(**default_dimensions)\n            response = lambda_handler(event, context, *args, **kwargs)\n            if capture_cold_start_metric:\n                self._add_cold_start_metric(context=context)\n        finally:\n            self.flush_metrics(raise_on_empty_metrics=raise_on_empty_metrics)\n\n        return response\n\n    return decorate\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/base/#aws_lambda_powertools.metrics.base.MetricManager.serialize_metric_set",
            "title": "serialize_metric_set",
            "text": "<pre><code>serialize_metric_set(\n    metrics: dict | None = None,\n    dimensions: dict | None = None,\n    metadata: dict | None = None,\n) -&gt; dict\n</code></pre> <p>Serializes metric and dimensions set</p> PARAMETER DESCRIPTION <code>metrics</code> <p>Dictionary of metrics to serialize, by default None</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>dimensions</code> <p>Dictionary of dimensions to serialize, by default None</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>metadata</code> <p>Dictionary of metadata to serialize, by default None</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> Example <p>Serialize metrics into EMF format</p> <pre><code>metrics = MetricManager()\n# ...add metrics, dimensions, namespace\nret = metrics.serialize_metric_set()\n</code></pre> RETURNS DESCRIPTION <code>dict</code> <p>Serialized metrics following EMF specification</p> RAISES DESCRIPTION <code>SchemaValidationError</code> <p>Raised when serialization fail schema validation</p> Source code in <code>aws_lambda_powertools/metrics/base.py</code> <pre><code>def serialize_metric_set(\n    self,\n    metrics: dict | None = None,\n    dimensions: dict | None = None,\n    metadata: dict | None = None,\n) -&gt; dict:\n    \"\"\"Serializes metric and dimensions set\n\n    Parameters\n    ----------\n    metrics : dict, optional\n        Dictionary of metrics to serialize, by default None\n    dimensions : dict, optional\n        Dictionary of dimensions to serialize, by default None\n    metadata: dict, optional\n        Dictionary of metadata to serialize, by default None\n\n    Example\n    -------\n    **Serialize metrics into EMF format**\n\n        metrics = MetricManager()\n        # ...add metrics, dimensions, namespace\n        ret = metrics.serialize_metric_set()\n\n    Returns\n    -------\n    dict\n        Serialized metrics following EMF specification\n\n    Raises\n    ------\n    SchemaValidationError\n        Raised when serialization fail schema validation\n    \"\"\"\n    if metrics is None:  # pragma: no cover\n        metrics = self.metric_set\n\n    if dimensions is None:  # pragma: no cover\n        dimensions = self.dimension_set\n\n    if metadata is None:  # pragma: no cover\n        metadata = self.metadata_set\n\n    if self.service and not self.dimension_set.get(\"service\"):\n        # self.service won't be a float\n        self.add_dimension(name=\"service\", value=self.service)\n\n    if len(metrics) == 0:\n        raise SchemaValidationError(\"Must contain at least one metric.\")\n\n    if self.namespace is None:\n        raise SchemaValidationError(\"Must contain a metric namespace.\")\n\n    logger.debug({\"details\": \"Serializing metrics\", \"metrics\": metrics, \"dimensions\": dimensions})\n\n    # For standard resolution metrics, don't add StorageResolution field to avoid unnecessary ingestion of data into cloudwatch # noqa E501\n    # Example: [ { \"Name\": \"metric_name\", \"Unit\": \"Count\"} ] # noqa ERA001\n    #\n    # In case using high-resolution metrics, add StorageResolution field\n    # Example: [ { \"Name\": \"metric_name\", \"Unit\": \"Count\", \"StorageResolution\": 1 } ] # noqa ERA001\n    metric_definition: list[MetricNameUnitResolution] = []\n    metric_names_and_values: dict[str, float] = {}  # { \"metric_name\": 1.0 }\n\n    for metric_name in metrics:\n        metric: dict = metrics[metric_name]\n        metric_value: int = metric.get(\"Value\", 0)\n        metric_unit: str = metric.get(\"Unit\", \"\")\n        metric_resolution: int = metric.get(\"StorageResolution\", 60)\n\n        metric_definition_data: MetricNameUnitResolution = {\"Name\": metric_name, \"Unit\": metric_unit}\n\n        # high-resolution metrics\n        if metric_resolution == 1:\n            metric_definition_data[\"StorageResolution\"] = metric_resolution\n\n        metric_definition.append(metric_definition_data)\n\n        metric_names_and_values.update({metric_name: metric_value})\n\n    return {\n        \"_aws\": {\n            \"Timestamp\": self.timestamp or int(datetime.datetime.now().timestamp() * 1000),  # epoch\n            \"CloudWatchMetrics\": [\n                {\n                    \"Namespace\": self.namespace,  # \"test_namespace\"\n                    \"Dimensions\": [list(dimensions.keys())],  # [ \"service\" ]\n                    \"Metrics\": metric_definition,\n                },\n            ],\n        },\n        **dimensions,  # \"service\": \"test_service\"\n        **metadata,  # \"username\": \"test\"\n        **metric_names_and_values,  # \"single_metric\": 1.0\n    }\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/base/#aws_lambda_powertools.metrics.base.MetricManager.set_timestamp",
            "title": "set_timestamp",
            "text": "<pre><code>set_timestamp(timestamp: int | datetime)\n</code></pre> <p>Set the timestamp for the metric.</p> Source code in <code>aws_lambda_powertools/metrics/base.py</code> <pre><code>def set_timestamp(self, timestamp: int | datetime.datetime):\n    \"\"\"\n    Set the timestamp for the metric.\n\n    Parameters:\n    -----------\n    timestamp: int | datetime.datetime\n        The timestamp to create the metric.\n        If an integer is provided, it is assumed to be the epoch time in milliseconds.\n        If a datetime object is provided, it will be converted to epoch time in milliseconds.\n    \"\"\"\n    # The timestamp must be a Datetime object or an integer representing an epoch time.\n    # This should not exceed 14 days in the past or be more than 2 hours in the future.\n    # Any metrics failing to meet this criteria will be skipped by Amazon CloudWatch.\n    # See: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Embedded_Metric_Format_Specification.html\n    # See: https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CloudWatch-Logs-Monitoring-CloudWatch-Metrics.html\n    if not validate_emf_timestamp(timestamp):\n        warnings.warn(\n            \"This metric doesn't meet the requirements and will be skipped by Amazon CloudWatch. \"\n            \"Ensure the timestamp is within 14 days past or 2 hours future.\",\n            stacklevel=2,\n        )\n\n    self.timestamp = convert_timestamp_to_emf_format(timestamp)\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/base/#aws_lambda_powertools.metrics.base.SingleMetric",
            "title": "SingleMetric",
            "text": "<pre><code>SingleMetric(\n    metric_set: dict[str, Any] | None = None,\n    dimension_set: dict | None = None,\n    namespace: str | None = None,\n    metadata_set: dict[str, Any] | None = None,\n    service: str | None = None,\n)\n</code></pre> <p>               Bases: <code>MetricManager</code></p> <p>SingleMetric creates an EMF object with a single metric.</p> <p>EMF specification doesn't allow metrics with different dimensions. SingleMetric overrides MetricManager's add_metric method to do just that.</p> <p>Use <code>single_metric</code> when you need to create metrics with different dimensions, otherwise <code>aws_lambda_powertools.metrics.metrics.Metrics</code> is a more cost effective option</p> Environment variables <p>POWERTOOLS_METRICS_NAMESPACE : str     metric namespace</p> Example <p>Creates cold start metric with function_version as dimension</p> <pre><code>import json\nfrom aws_lambda_powertools.metrics import single_metric, MetricUnit, MetricResolution\nmetric = single_metric(namespace=\"ServerlessAirline\")\n\nmetric.add_metric(name=\"ColdStart\", unit=MetricUnit.Count, value=1, resolution=MetricResolution.Standard)\nmetric.add_dimension(name=\"function_version\", value=47)\n\nprint(json.dumps(metric.serialize_metric_set(), indent=4))\n</code></pre> PARAMETER DESCRIPTION <code>MetricManager</code> <p>Inherits from <code>aws_lambda_powertools.metrics.base.MetricManager</code></p> <p> TYPE: <code>MetricManager</code> </p> METHOD DESCRIPTION <code>add_metric</code> <p>Method to prevent more than one metric being created</p> Source code in <code>aws_lambda_powertools/metrics/base.py</code> <pre><code>def __init__(\n    self,\n    metric_set: dict[str, Any] | None = None,\n    dimension_set: dict | None = None,\n    namespace: str | None = None,\n    metadata_set: dict[str, Any] | None = None,\n    service: str | None = None,\n):\n    self.metric_set = metric_set if metric_set is not None else {}\n    self.dimension_set = dimension_set if dimension_set is not None else {}\n    self.namespace = resolve_env_var_choice(choice=namespace, env=os.getenv(constants.METRICS_NAMESPACE_ENV))\n    self.service = resolve_env_var_choice(choice=service, env=os.getenv(constants.SERVICE_NAME_ENV))\n    self.metadata_set = metadata_set if metadata_set is not None else {}\n    self.timestamp: int | None = None\n\n    self._metric_units = [unit.value for unit in MetricUnit]\n    self._metric_unit_valid_options = list(MetricUnit.__members__)\n    self._metric_resolutions = [resolution.value for resolution in MetricResolution]\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/base/#aws_lambda_powertools.metrics.base.SingleMetric.add_metric",
            "title": "add_metric",
            "text": "<pre><code>add_metric(\n    name: str,\n    unit: MetricUnit | str,\n    value: float,\n    resolution: MetricResolution | int = 60,\n) -&gt; None\n</code></pre> <p>Method to prevent more than one metric being created</p> PARAMETER DESCRIPTION <code>name</code> <p>Metric name (e.g. BookingConfirmation)</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p>Metric unit (e.g. \"Seconds\", MetricUnit.Seconds)</p> <p> TYPE: <code>MetricUnit</code> </p> <code>value</code> <p>Metric value</p> <p> TYPE: <code>float</code> </p> <code>resolution</code> <p>Metric resolution (e.g. 60, MetricResolution.Standard)</p> <p> TYPE: <code>MetricResolution</code> DEFAULT: <code>60</code> </p> Source code in <code>aws_lambda_powertools/metrics/base.py</code> <pre><code>def add_metric(\n    self,\n    name: str,\n    unit: MetricUnit | str,\n    value: float,\n    resolution: MetricResolution | int = 60,\n) -&gt; None:\n    \"\"\"Method to prevent more than one metric being created\n\n    Parameters\n    ----------\n    name : str\n        Metric name (e.g. BookingConfirmation)\n    unit : MetricUnit\n        Metric unit (e.g. \"Seconds\", MetricUnit.Seconds)\n    value : float\n        Metric value\n    resolution : MetricResolution\n        Metric resolution (e.g. 60, MetricResolution.Standard)\n    \"\"\"\n    if len(self.metric_set) &gt; 0:\n        logger.debug(f\"Metric {name} already set, skipping...\")\n        return\n    return super().add_metric(name, unit, value, resolution)\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/base/#aws_lambda_powertools.metrics.base.single_metric",
            "title": "single_metric",
            "text": "<pre><code>single_metric(\n    name: str,\n    unit: MetricUnit,\n    value: float,\n    resolution: MetricResolution | int = 60,\n    namespace: str | None = None,\n    default_dimensions: dict[str, str] | None = None,\n) -&gt; Generator[SingleMetric, None, None]\n</code></pre> <p>Context manager to simplify creation of a single metric</p> Example <p>Creates cold start metric with function_version as dimension</p> <pre><code>from aws_lambda_powertools import single_metric\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.metrics import MetricResolution\n\nwith single_metric(name=\"ColdStart\", unit=MetricUnit.Count, value=1, resolution=MetricResolution.Standard, namespace=\"ServerlessAirline\") as metric:\n    metric.add_dimension(name=\"function_version\", value=\"47\")\n</code></pre> <p>Same as above but set namespace using environment variable</p> <pre><code>$ export POWERTOOLS_METRICS_NAMESPACE=\"ServerlessAirline\"\n\nfrom aws_lambda_powertools import single_metric\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.metrics import MetricResolution\n\nwith single_metric(name=\"ColdStart\", unit=MetricUnit.Count, value=1, resolution=MetricResolution.Standard) as metric:\n    metric.add_dimension(name=\"function_version\", value=\"47\")\n</code></pre> PARAMETER DESCRIPTION <code>name</code> <p>Metric name</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p><code>aws_lambda_powertools.helper.models.MetricUnit</code></p> <p> TYPE: <code>MetricUnit</code> </p> <code>resolution</code> <p><code>aws_lambda_powertools.helper.models.MetricResolution</code></p> <p> TYPE: <code>MetricResolution</code> DEFAULT: <code>60</code> </p> <code>value</code> <p>Metric value</p> <p> TYPE: <code>float</code> </p> <code>namespace</code> <p>Namespace for metrics</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>default_dimensions</code> <p>Metric dimensions as key=value that will always be present</p> <p> TYPE: <code>dict[str, str] | None</code> DEFAULT: <code>None</code> </p> YIELDS DESCRIPTION <code>SingleMetric</code> <p>SingleMetric class instance</p> RAISES DESCRIPTION <code>MetricUnitError</code> <p>When metric metric isn't supported by CloudWatch</p> <code>MetricResolutionError</code> <p>When metric resolution isn't supported by CloudWatch</p> <code>MetricValueError</code> <p>When metric value isn't a number</p> <code>SchemaValidationError</code> <p>When metric object fails EMF schema validation</p> Source code in <code>aws_lambda_powertools/metrics/base.py</code> <pre><code>@contextmanager\ndef single_metric(\n    name: str,\n    unit: MetricUnit,\n    value: float,\n    resolution: MetricResolution | int = 60,\n    namespace: str | None = None,\n    default_dimensions: dict[str, str] | None = None,\n) -&gt; Generator[SingleMetric, None, None]:\n    \"\"\"Context manager to simplify creation of a single metric\n\n    Example\n    -------\n    **Creates cold start metric with function_version as dimension**\n\n        from aws_lambda_powertools import single_metric\n        from aws_lambda_powertools.metrics import MetricUnit\n        from aws_lambda_powertools.metrics import MetricResolution\n\n        with single_metric(name=\"ColdStart\", unit=MetricUnit.Count, value=1, resolution=MetricResolution.Standard, namespace=\"ServerlessAirline\") as metric:\n            metric.add_dimension(name=\"function_version\", value=\"47\")\n\n    **Same as above but set namespace using environment variable**\n\n        $ export POWERTOOLS_METRICS_NAMESPACE=\"ServerlessAirline\"\n\n        from aws_lambda_powertools import single_metric\n        from aws_lambda_powertools.metrics import MetricUnit\n        from aws_lambda_powertools.metrics import MetricResolution\n\n        with single_metric(name=\"ColdStart\", unit=MetricUnit.Count, value=1, resolution=MetricResolution.Standard) as metric:\n            metric.add_dimension(name=\"function_version\", value=\"47\")\n\n    Parameters\n    ----------\n    name : str\n        Metric name\n    unit : MetricUnit\n        `aws_lambda_powertools.helper.models.MetricUnit`\n    resolution : MetricResolution\n        `aws_lambda_powertools.helper.models.MetricResolution`\n    value : float\n        Metric value\n    namespace: str\n        Namespace for metrics\n    default_dimensions: dict[str, str], optional\n        Metric dimensions as key=value that will always be present\n\n\n    Yields\n    -------\n    SingleMetric\n        SingleMetric class instance\n\n    Raises\n    ------\n    MetricUnitError\n        When metric metric isn't supported by CloudWatch\n    MetricResolutionError\n        When metric resolution isn't supported by CloudWatch\n    MetricValueError\n        When metric value isn't a number\n    SchemaValidationError\n        When metric object fails EMF schema validation\n    \"\"\"  # noqa: E501\n    metric_set: dict | None = None\n    try:\n        metric: SingleMetric = SingleMetric(namespace=namespace)\n        metric.add_metric(name=name, unit=unit, value=value, resolution=resolution)\n\n        if default_dimensions:\n            for dim_name, dim_value in default_dimensions.items():\n                metric.add_dimension(name=dim_name, value=dim_value)\n\n        yield metric\n        metric_set = metric.serialize_metric_set()\n    finally:\n        print(json.dumps(metric_set, separators=(\",\", \":\")))\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/exceptions/",
            "title": "Exceptions",
            "text": "CLASS DESCRIPTION <code>MetricResolutionError</code> <p>When metric resolution is not supported by CloudWatch</p> <code>MetricUnitError</code> <p>When metric unit is not supported by CloudWatch</p> <code>MetricValueError</code> <p>When metric value isn't a valid number</p> <code>SchemaValidationError</code> <p>When serialization fail schema validation</p>"
        },
        {
            "location": "api_doc/metrics/exceptions/#aws_lambda_powertools.metrics.exceptions.MetricResolutionError",
            "title": "MetricResolutionError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>When metric resolution is not supported by CloudWatch</p>"
        },
        {
            "location": "api_doc/metrics/exceptions/#aws_lambda_powertools.metrics.exceptions.MetricUnitError",
            "title": "MetricUnitError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>When metric unit is not supported by CloudWatch</p>"
        },
        {
            "location": "api_doc/metrics/exceptions/#aws_lambda_powertools.metrics.exceptions.MetricValueError",
            "title": "MetricValueError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>When metric value isn't a valid number</p>"
        },
        {
            "location": "api_doc/metrics/exceptions/#aws_lambda_powertools.metrics.exceptions.SchemaValidationError",
            "title": "SchemaValidationError",
            "text": "<p>               Bases: <code>Exception</code></p> <p>When serialization fail schema validation</p>"
        },
        {
            "location": "api_doc/metrics/metrics/",
            "title": "Metrics",
            "text": "CLASS DESCRIPTION <code>Metrics</code> <p>Metrics create an CloudWatch EMF object with up to 100 metrics</p>"
        },
        {
            "location": "api_doc/metrics/metrics/#aws_lambda_powertools.metrics.metrics.Metrics",
            "title": "Metrics",
            "text": "<pre><code>Metrics(\n    service: str | None = None,\n    namespace: str | None = None,\n    provider: AmazonCloudWatchEMFProvider | None = None,\n    function_name: str | None = None,\n)\n</code></pre> <p>Metrics create an CloudWatch EMF object with up to 100 metrics</p> <p>Use Metrics when you need to create multiple metrics that have dimensions in common (e.g. service_name=\"payment\").</p> <p>Metrics up to 100 metrics in memory and are shared across all its instances. That means it can be safely instantiated outside of a Lambda function, or anywhere else.</p> <p>A decorator (log_metrics) is provided so metrics are published at the end of its execution. If more than 100 metrics are added at a given function execution, these metrics are serialized and published before adding a given metric to prevent metric truncation.</p> Example <p>Creates a few metrics and publish at the end of a function execution</p> <pre><code>from aws_lambda_powertools import Metrics\n\nmetrics = Metrics(namespace=\"ServerlessAirline\", service=\"payment\")\n\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler():\n    metrics.add_metric(name=\"BookingConfirmation\", unit=\"Count\", value=1)\n    metrics.add_dimension(name=\"function_version\", value=\"$LATEST\")\n\n    return True\n</code></pre> Environment variables <p>POWERTOOLS_METRICS_NAMESPACE : str     metric namespace POWERTOOLS_SERVICE_NAME : str     service name used for default dimension POWERTOOLS_METRICS_DISABLED: bool     Powertools metrics disabled (e.g. <code>\"true\", \"True\", \"TRUE\"</code>)</p> PARAMETER DESCRIPTION <code>service</code> <p>service name to be used as metric dimension, by default \"service_undefined\"</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>namespace</code> <p>Namespace for metrics</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> <code>provider</code> <p>Pre-configured AmazonCloudWatchEMFProvider provider</p> <p> TYPE: <code>AmazonCloudWatchEMFProvider | None</code> DEFAULT: <code>None</code> </p> RAISES DESCRIPTION <code>MetricUnitError</code> <p>When metric unit isn't supported by CloudWatch</p> <code>MetricResolutionError</code> <p>When metric resolution isn't supported by CloudWatch</p> <code>MetricValueError</code> <p>When metric value isn't a number</p> <code>SchemaValidationError</code> <p>When metric object fails EMF schema validation</p> METHOD DESCRIPTION <code>set_timestamp</code> <p>Set the timestamp for the metric.</p> Source code in <code>aws_lambda_powertools/metrics/metrics.py</code> <pre><code>def __init__(\n    self,\n    service: str | None = None,\n    namespace: str | None = None,\n    provider: AmazonCloudWatchEMFProvider | None = None,\n    function_name: str | None = None,\n):\n    self.metric_set = self._metrics\n    self.metadata_set = self._metadata\n    self.default_dimensions = self._default_dimensions\n    self.dimension_set = self._dimensions\n\n    self.dimension_set.update(**self._default_dimensions)\n\n    if provider is None:\n        self.provider = AmazonCloudWatchEMFProvider(\n            namespace=namespace,\n            service=service,\n            metric_set=self.metric_set,\n            dimension_set=self.dimension_set,\n            metadata_set=self.metadata_set,\n            default_dimensions=self._default_dimensions,\n            function_name=function_name,\n        )\n    else:\n        self.provider = provider\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/metrics/#aws_lambda_powertools.metrics.metrics.Metrics.set_timestamp",
            "title": "set_timestamp",
            "text": "<pre><code>set_timestamp(timestamp: int)\n</code></pre> <p>Set the timestamp for the metric.</p> Source code in <code>aws_lambda_powertools/metrics/metrics.py</code> <pre><code>def set_timestamp(self, timestamp: int):\n    \"\"\"\n    Set the timestamp for the metric.\n\n    Parameters:\n    -----------\n    timestamp: int | datetime.datetime\n        The timestamp to create the metric.\n        If an integer is provided, it is assumed to be the epoch time in milliseconds.\n        If a datetime object is provided, it will be converted to epoch time in milliseconds.\n    \"\"\"\n    self.provider.set_timestamp(timestamp=timestamp)\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_datadog/",
            "title": "DataDog",
            "text": "CLASS DESCRIPTION <code>DatadogProvider</code> <p>DatadogProvider creates metrics asynchronously via Datadog extension or exporter.</p>"
        },
        {
            "location": "api_doc/metrics/provider_datadog/#aws_lambda_powertools.metrics.provider.datadog.datadog.DatadogProvider",
            "title": "DatadogProvider",
            "text": "<pre><code>DatadogProvider(\n    metric_set: list | None = None,\n    namespace: str | None = None,\n    flush_to_log: bool | None = None,\n    default_tags: dict[str, Any] | None = None,\n    function_name: str | None = None,\n)\n</code></pre> <p>               Bases: <code>BaseProvider</code></p> <p>DatadogProvider creates metrics asynchronously via Datadog extension or exporter.</p> <p>Use <code>aws_lambda_powertools.DatadogMetrics</code> to create and metrics to Datadog.</p> Environment variables <p>POWERTOOLS_METRICS_NAMESPACE : str     metric namespace to be set for all metrics</p> RAISES DESCRIPTION <code>MetricValueError</code> <p>When metric value isn't a number</p> <code>SchemaValidationError</code> <p>When metric object fails EMF schema validation</p> METHOD DESCRIPTION <code>add_cold_start_metric</code> <p>Add cold start metric and function_name dimension</p> <code>add_metric</code> <p>The add_metrics function that will be used by metrics class.</p> <code>flush_metrics</code> <p>Manually flushes the metrics. This is normally not necessary,</p> <code>log_metrics</code> <p>Decorator to serialize and publish metrics at the end of a function execution.</p> <code>serialize_metric_set</code> <p>Serializes metrics</p> <code>set_default_tags</code> <p>Persist tags across Lambda invocations</p> Source code in <code>aws_lambda_powertools/metrics/provider/datadog/datadog.py</code> <pre><code>def __init__(\n    self,\n    metric_set: list | None = None,\n    namespace: str | None = None,\n    flush_to_log: bool | None = None,\n    default_tags: dict[str, Any] | None = None,\n    function_name: str | None = None,\n):\n    self.metric_set = metric_set if metric_set is not None else []\n    self.function_name = function_name\n    self.namespace = (\n        resolve_env_var_choice(choice=namespace, env=os.getenv(constants.METRICS_NAMESPACE_ENV))\n        or DEFAULT_NAMESPACE\n    )\n    self.default_tags = default_tags or {}\n    self.flush_to_log = resolve_env_var_choice(choice=flush_to_log, env=os.getenv(constants.DATADOG_FLUSH_TO_LOG))\n    # When set as env var, the value is a string\n    if isinstance(self.flush_to_log, str):\n        self.flush_to_log = strtobool(self.flush_to_log)\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_datadog/#aws_lambda_powertools.metrics.provider.datadog.datadog.DatadogProvider.add_cold_start_metric",
            "title": "add_cold_start_metric",
            "text": "<pre><code>add_cold_start_metric(context: LambdaContext) -&gt; None\n</code></pre> <p>Add cold start metric and function_name dimension</p> PARAMETER DESCRIPTION <code>context</code> <p>Lambda context</p> <p> TYPE: <code>Any</code> </p> Source code in <code>aws_lambda_powertools/metrics/provider/datadog/datadog.py</code> <pre><code>def add_cold_start_metric(self, context: LambdaContext) -&gt; None:\n    \"\"\"Add cold start metric and function_name dimension\n\n    Parameters\n    ----------\n    context : Any\n        Lambda context\n    \"\"\"\n\n    cold_start_function_name = resolve_cold_start_function_name(function_name=self.function_name, context=context)\n\n    logger.debug(\"Adding cold start metric and function_name tagging\")\n    self.add_metric(name=\"ColdStart\", value=1, function_name=cold_start_function_name)\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_datadog/#aws_lambda_powertools.metrics.provider.datadog.datadog.DatadogProvider.add_metric",
            "title": "add_metric",
            "text": "<pre><code>add_metric(\n    name: str,\n    value: float,\n    timestamp: int | None = None,\n    **tags\n) -&gt; None\n</code></pre> <p>The add_metrics function that will be used by metrics class.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name/Key for the metrics</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Value for the metrics</p> <p> TYPE: <code>float</code> </p> <code>timestamp</code> <p>Timestamp in int for the metrics, default = time.time()</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>tags</code> <p>In format like [\"tag:value\", \"tag2:value2\"]</p> <p> DEFAULT: <code>{}</code> </p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; provider = DatadogProvider()\n&gt;&gt;&gt;\n&gt;&gt;&gt; provider.add_metric(\n&gt;&gt;&gt;     name='coffee_house.order_value',\n&gt;&gt;&gt;     value=12.45,\n&gt;&gt;&gt;     tags=['product:latte', 'order:online'],\n&gt;&gt;&gt;     sales='sam'\n&gt;&gt;&gt; )\n</code></pre> Source code in <code>aws_lambda_powertools/metrics/provider/datadog/datadog.py</code> <pre><code>def add_metric(\n    self,\n    name: str,\n    value: float,\n    timestamp: int | None = None,\n    **tags,\n) -&gt; None:\n    \"\"\"\n    The add_metrics function that will be used by metrics class.\n\n    Parameters\n    ----------\n    name: str\n        Name/Key for the metrics\n    value: float\n        Value for the metrics\n    timestamp: int\n        Timestamp in int for the metrics, default = time.time()\n    tags: list[str]\n        In format like [\"tag:value\", \"tag2:value2\"]\n\n    Examples\n    --------\n        &gt;&gt;&gt; provider = DatadogProvider()\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; provider.add_metric(\n        &gt;&gt;&gt;     name='coffee_house.order_value',\n        &gt;&gt;&gt;     value=12.45,\n        &gt;&gt;&gt;     tags=['product:latte', 'order:online'],\n        &gt;&gt;&gt;     sales='sam'\n        &gt;&gt;&gt; )\n    \"\"\"\n    # validating metric name\n    if not self._validate_datadog_metric_name(name):\n        docs = \"https://docs.datadoghq.com/metrics/custom_metrics/#naming-custom-metrics\"\n        raise SchemaValidationError(\n            f\"Invalid metric name. Please ensure the metric {name} follows the requirements. \\n\"\n            f\"See Datadog documentation here: \\n {docs}\",\n        )\n\n    # validating metric tag\n    self._validate_datadog_tags_name(tags)\n\n    if not isinstance(value, numbers.Real):\n        raise MetricValueError(f\"{value} is not a valid number\")\n\n    if not timestamp:\n        timestamp = int(time.time())\n\n    logger.debug({\"details\": \"Appending metric\", \"metrics\": name})\n    self.metric_set.append({\"m\": name, \"v\": value, \"e\": timestamp, \"t\": tags})\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_datadog/#aws_lambda_powertools.metrics.provider.datadog.datadog.DatadogProvider.flush_metrics",
            "title": "flush_metrics",
            "text": "<pre><code>flush_metrics(raise_on_empty_metrics: bool = False) -&gt; None\n</code></pre> <p>Manually flushes the metrics. This is normally not necessary, unless you're running on other runtimes besides Lambda, where the @log_metrics decorator already handles things for you.</p> PARAMETER DESCRIPTION <code>raise_on_empty_metrics</code> <p>raise exception if no metrics are emitted, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>aws_lambda_powertools/metrics/provider/datadog/datadog.py</code> <pre><code>def flush_metrics(self, raise_on_empty_metrics: bool = False) -&gt; None:\n    \"\"\"Manually flushes the metrics. This is normally not necessary,\n    unless you're running on other runtimes besides Lambda, where the @log_metrics\n    decorator already handles things for you.\n\n    Parameters\n    ----------\n    raise_on_empty_metrics : bool, optional\n        raise exception if no metrics are emitted, by default False\n    \"\"\"\n\n    if not raise_on_empty_metrics and len(self.metric_set) == 0:\n        warnings.warn(\n            \"No application metrics to publish. The cold-start metric may be published if enabled. \"\n            \"If application metrics should never be empty, consider using 'raise_on_empty_metrics'\",\n            stacklevel=2,\n        )\n\n    else:\n        logger.debug(\"Flushing existing metrics\")\n        metrics = self.serialize_metric_set()\n        # submit through datadog extension\n        if lambda_metric and not self.flush_to_log:\n            # use lambda_metric function from datadog package, submit metrics to datadog\n            for metric_item in metrics:  # pragma: no cover\n                lambda_metric(  # pragma: no cover\n                    metric_name=metric_item[\"m\"],\n                    value=metric_item[\"v\"],\n                    timestamp=metric_item[\"e\"],\n                    tags=metric_item[\"t\"],\n                )\n        elif not is_metrics_disabled():\n            # dd module not found: flush to log, this format can be recognized via datadog log forwarder\n            # https://github.com/Datadog/datadog-lambda-python/blob/main/datadog_lambda/metric.py#L77\n            for metric_item in metrics:\n                print(json.dumps(metric_item, separators=(\",\", \":\")))\n\n        self.clear_metrics()\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_datadog/#aws_lambda_powertools.metrics.provider.datadog.datadog.DatadogProvider.log_metrics",
            "title": "log_metrics",
            "text": "<pre><code>log_metrics(\n    lambda_handler: AnyCallableT | None = None,\n    capture_cold_start_metric: bool = False,\n    raise_on_empty_metrics: bool = False,\n    **kwargs\n)\n</code></pre> <p>Decorator to serialize and publish metrics at the end of a function execution.</p> <p>Be aware that the log_metrics *does call the decorated function (e.g. lambda_handler).</p> Example <p>Lambda function using tracer and metrics decorators</p> <pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\n\nmetrics = DatadogMetrics(namespace=\"powertools\")\ntracer = Tracer(service=\"payment\")\n\n@tracer.capture_lambda_handler\n@metrics.log_metrics\ndef handler(event, context):\n        ...\n</code></pre> PARAMETER DESCRIPTION <code>lambda_handler</code> <p>lambda function handler, by default None</p> <p> TYPE: <code>Callable[[Any, Any], Any]</code> DEFAULT: <code>None</code> </p> <code>capture_cold_start_metric</code> <p>captures cold start metric, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>raise_on_empty_metrics</code> <p>raise exception if no metrics are emitted, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>**kwargs</code> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>e</code> <p>Propagate error received</p> Source code in <code>aws_lambda_powertools/metrics/provider/datadog/datadog.py</code> <pre><code>def log_metrics(\n    self,\n    lambda_handler: AnyCallableT | None = None,\n    capture_cold_start_metric: bool = False,\n    raise_on_empty_metrics: bool = False,\n    **kwargs,\n):\n    \"\"\"Decorator to serialize and publish metrics at the end of a function execution.\n\n    Be aware that the log_metrics **does call* the decorated function (e.g. lambda_handler).\n\n    Example\n    -------\n    **Lambda function using tracer and metrics decorators**\n\n        from aws_lambda_powertools import Tracer\n        from aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\n\n        metrics = DatadogMetrics(namespace=\"powertools\")\n        tracer = Tracer(service=\"payment\")\n\n        @tracer.capture_lambda_handler\n        @metrics.log_metrics\n        def handler(event, context):\n                ...\n\n    Parameters\n    ----------\n    lambda_handler : Callable[[Any, Any], Any], optional\n        lambda function handler, by default None\n    capture_cold_start_metric : bool, optional\n        captures cold start metric, by default False\n    raise_on_empty_metrics : bool, optional\n        raise exception if no metrics are emitted, by default False\n    **kwargs\n\n    Raises\n    ------\n    e\n        Propagate error received\n    \"\"\"\n\n    default_tags = kwargs.get(\"default_tags\")\n\n    if default_tags:\n        self.set_default_tags(**default_tags)\n\n    return super().log_metrics(\n        lambda_handler=lambda_handler,\n        capture_cold_start_metric=capture_cold_start_metric,\n        raise_on_empty_metrics=raise_on_empty_metrics,\n        **kwargs,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_datadog/#aws_lambda_powertools.metrics.provider.datadog.datadog.DatadogProvider.serialize_metric_set",
            "title": "serialize_metric_set",
            "text": "<pre><code>serialize_metric_set(metrics: list | None = None) -&gt; list\n</code></pre> <p>Serializes metrics</p> Example <p>Serialize metrics into Datadog format</p> <pre><code>metrics = DatadogMetric()\n# ...add metrics, tags, namespace\nret = metrics.serialize_metric_set()\n</code></pre> RETURNS DESCRIPTION <code>list</code> <p>Serialized metrics following Datadog specification</p> RAISES DESCRIPTION <code>SchemaValidationError</code> <p>Raised when serialization fail schema validation</p> Source code in <code>aws_lambda_powertools/metrics/provider/datadog/datadog.py</code> <pre><code>def serialize_metric_set(self, metrics: list | None = None) -&gt; list:\n    \"\"\"Serializes metrics\n\n    Example\n    -------\n    **Serialize metrics into Datadog format**\n\n        metrics = DatadogMetric()\n        # ...add metrics, tags, namespace\n        ret = metrics.serialize_metric_set()\n\n    Returns\n    -------\n    list\n        Serialized metrics following Datadog specification\n\n    Raises\n    ------\n    SchemaValidationError\n        Raised when serialization fail schema validation\n    \"\"\"\n\n    if metrics is None:  # pragma: no cover\n        metrics = self.metric_set\n\n    if len(metrics) == 0:\n        raise SchemaValidationError(\"Must contain at least one metric.\")\n\n    output_list: list = []\n\n    logger.debug({\"details\": \"Serializing metrics\", \"metrics\": metrics})\n\n    for single_metric in metrics:\n        if self.namespace != DEFAULT_NAMESPACE:\n            metric_name = f\"{self.namespace}.{single_metric['m']}\"\n        else:\n            metric_name = single_metric[\"m\"]\n\n        output_list.append(\n            {\n                \"m\": metric_name,\n                \"v\": single_metric[\"v\"],\n                \"e\": single_metric[\"e\"],\n                \"t\": self._serialize_datadog_tags(metric_tags=single_metric[\"t\"], default_tags=self.default_tags),\n            },\n        )\n\n    return output_list\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_datadog/#aws_lambda_powertools.metrics.provider.datadog.datadog.DatadogProvider.set_default_tags",
            "title": "set_default_tags",
            "text": "<pre><code>set_default_tags(**tags) -&gt; None\n</code></pre> <p>Persist tags across Lambda invocations</p> PARAMETER DESCRIPTION <code>tags</code> <p>tags as key=value</p> <p> TYPE: <code>**kwargs</code> DEFAULT: <code>{}</code> </p> Example <p>Sets some default dimensions that will always be present across metrics and invocations</p> <pre><code>from aws_lambda_powertools import Metrics\n\nmetrics = Metrics(namespace=\"ServerlessAirline\", service=\"payment\")\nmetrics.set_default_tags(environment=\"demo\", another=\"one\")\n\n@metrics.log_metrics()\ndef lambda_handler():\n    return True\n</code></pre> Source code in <code>aws_lambda_powertools/metrics/provider/datadog/datadog.py</code> <pre><code>def set_default_tags(self, **tags) -&gt; None:\n    \"\"\"Persist tags across Lambda invocations\n\n    Parameters\n    ----------\n    tags : **kwargs\n        tags as key=value\n\n    Example\n    -------\n    **Sets some default dimensions that will always be present across metrics and invocations**\n\n        from aws_lambda_powertools import Metrics\n\n        metrics = Metrics(namespace=\"ServerlessAirline\", service=\"payment\")\n        metrics.set_default_tags(environment=\"demo\", another=\"one\")\n\n        @metrics.log_metrics()\n        def lambda_handler():\n            return True\n    \"\"\"\n    self._validate_datadog_tags_name(tags)\n    self.default_tags.update(**tags)\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_emf/",
            "title": "EMF",
            "text": "CLASS DESCRIPTION <code>AmazonCloudWatchEMFProvider</code> <p>AmazonCloudWatchEMFProvider creates metrics asynchronously via CloudWatch Embedded Metric Format (EMF).</p>"
        },
        {
            "location": "api_doc/metrics/provider_emf/#aws_lambda_powertools.metrics.provider.cloudwatch_emf.cloudwatch.AmazonCloudWatchEMFProvider",
            "title": "AmazonCloudWatchEMFProvider",
            "text": "<pre><code>AmazonCloudWatchEMFProvider(\n    metric_set: dict[str, Any] | None = None,\n    dimension_set: dict | None = None,\n    namespace: str | None = None,\n    metadata_set: dict[str, Any] | None = None,\n    service: str | None = None,\n    default_dimensions: dict[str, Any] | None = None,\n    function_name: str | None = None,\n)\n</code></pre> <p>               Bases: <code>BaseProvider</code></p> <p>AmazonCloudWatchEMFProvider creates metrics asynchronously via CloudWatch Embedded Metric Format (EMF).</p> <p>CloudWatch EMF can create up to 100 metrics per EMF object and metrics, dimensions, and namespace created via AmazonCloudWatchEMFProvider will adhere to the schema, will be serialized and validated against EMF Schema.</p> <p>Use <code>aws_lambda_powertools.Metrics</code> or <code>aws_lambda_powertools.single_metric</code> to create EMF metrics.</p> Environment variables <p>POWERTOOLS_METRICS_NAMESPACE : str     metric namespace to be set for all metrics POWERTOOLS_SERVICE_NAME : str     service name used for default dimension POWERTOOLS_METRICS_FUNCTION_NAME: str     function name used as dimension for the ColdStart metric POWERTOOLS_METRICS_DISABLED: bool     disables all metrics emitted by Powertools</p> RAISES DESCRIPTION <code>MetricUnitError</code> <p>When metric unit isn't supported by CloudWatch</p> <code>MetricResolutionError</code> <p>When metric resolution isn't supported by CloudWatch</p> <code>MetricValueError</code> <p>When metric value isn't a number</p> <code>SchemaValidationError</code> <p>When metric object fails EMF schema validation</p> METHOD DESCRIPTION <code>add_cold_start_metric</code> <p>Add cold start metric and function_name dimension</p> <code>add_dimension</code> <p>Adds given dimension to all metrics</p> <code>add_metadata</code> <p>Adds high cardinal metadata for metrics object</p> <code>add_metric</code> <p>Adds given metric</p> <code>flush_metrics</code> <p>Manually flushes the metrics. This is normally not necessary,</p> <code>log_metrics</code> <p>Decorator to serialize and publish metrics at the end of a function execution.</p> <code>serialize_metric_set</code> <p>Serializes metric and dimensions set</p> <code>set_default_dimensions</code> <p>Persist dimensions across Lambda invocations</p> <code>set_timestamp</code> <p>Set the timestamp for the metric.</p> Source code in <code>aws_lambda_powertools/metrics/provider/cloudwatch_emf/cloudwatch.py</code> <pre><code>def __init__(\n    self,\n    metric_set: dict[str, Any] | None = None,\n    dimension_set: dict | None = None,\n    namespace: str | None = None,\n    metadata_set: dict[str, Any] | None = None,\n    service: str | None = None,\n    default_dimensions: dict[str, Any] | None = None,\n    function_name: str | None = None,\n):\n    self.metric_set = metric_set if metric_set is not None else {}\n    self.dimension_set = dimension_set if dimension_set is not None else {}\n    self.default_dimensions = default_dimensions or {}\n    self.namespace = resolve_env_var_choice(choice=namespace, env=os.getenv(constants.METRICS_NAMESPACE_ENV))\n    self.service = resolve_env_var_choice(choice=service, env=os.getenv(constants.SERVICE_NAME_ENV))\n    self.function_name = function_name\n\n    self.metadata_set = metadata_set if metadata_set is not None else {}\n    self.timestamp: int | None = None\n\n    self._metric_units = [unit.value for unit in MetricUnit]\n    self._metric_unit_valid_options = list(MetricUnit.__members__)\n    self._metric_resolutions = [resolution.value for resolution in MetricResolution]\n\n    self.dimension_set.update(**self.default_dimensions)\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_emf/#aws_lambda_powertools.metrics.provider.cloudwatch_emf.cloudwatch.AmazonCloudWatchEMFProvider.add_cold_start_metric",
            "title": "add_cold_start_metric",
            "text": "<pre><code>add_cold_start_metric(context: LambdaContext) -&gt; None\n</code></pre> <p>Add cold start metric and function_name dimension</p> PARAMETER DESCRIPTION <code>context</code> <p>Lambda context</p> <p> TYPE: <code>Any</code> </p> Source code in <code>aws_lambda_powertools/metrics/provider/cloudwatch_emf/cloudwatch.py</code> <pre><code>def add_cold_start_metric(self, context: LambdaContext) -&gt; None:\n    \"\"\"Add cold start metric and function_name dimension\n\n    Parameters\n    ----------\n    context : Any\n        Lambda context\n    \"\"\"\n\n    cold_start_function_name = resolve_cold_start_function_name(function_name=self.function_name, context=context)\n    logger.debug(\"Adding cold start metric and function_name dimension\")\n    with single_metric(name=\"ColdStart\", unit=MetricUnit.Count, value=1, namespace=self.namespace) as metric:\n        metric.add_dimension(name=\"function_name\", value=cold_start_function_name)\n        if self.service:\n            metric.add_dimension(name=\"service\", value=str(self.service))\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_emf/#aws_lambda_powertools.metrics.provider.cloudwatch_emf.cloudwatch.AmazonCloudWatchEMFProvider.add_dimension",
            "title": "add_dimension",
            "text": "<pre><code>add_dimension(name: str, value: str) -&gt; None\n</code></pre> <p>Adds given dimension to all metrics</p> Example <p>Add a metric dimensions</p> <pre><code>metric.add_dimension(name=\"operation\", value=\"confirm_booking\")\n</code></pre> PARAMETER DESCRIPTION <code>name</code> <p>Dimension name</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Dimension value</p> <p> TYPE: <code>str</code> </p> Source code in <code>aws_lambda_powertools/metrics/provider/cloudwatch_emf/cloudwatch.py</code> <pre><code>def add_dimension(self, name: str, value: str) -&gt; None:\n    \"\"\"Adds given dimension to all metrics\n\n    Example\n    -------\n    **Add a metric dimensions**\n\n        metric.add_dimension(name=\"operation\", value=\"confirm_booking\")\n\n    Parameters\n    ----------\n    name : str\n        Dimension name\n    value : str\n        Dimension value\n    \"\"\"\n\n    logger.debug(f\"Adding dimension: {name}:{value}\")\n    if len(self.dimension_set) == MAX_DIMENSIONS:\n        raise SchemaValidationError(\n            f\"Maximum number of dimensions exceeded ({MAX_DIMENSIONS}): Unable to add dimension {name}.\",\n        )\n\n    value = value if isinstance(value, str) else str(value)\n\n    if not name.strip() or not value.strip():\n        warnings.warn(\n            f\"The dimension {name} doesn't meet the requirements and won't be added. \"\n            \"Ensure the dimension name and value are non-empty strings\",\n            category=PowertoolsUserWarning,\n            stacklevel=2,\n        )\n        return\n\n    if name in self.dimension_set or name in self.default_dimensions:\n        warnings.warn(\n            f\"Dimension '{name}' has already been added. The previous value will be overwritten.\",\n            category=PowertoolsUserWarning,\n            stacklevel=2,\n        )\n\n    self.dimension_set[name] = value\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_emf/#aws_lambda_powertools.metrics.provider.cloudwatch_emf.cloudwatch.AmazonCloudWatchEMFProvider.add_metadata",
            "title": "add_metadata",
            "text": "<pre><code>add_metadata(key: str, value: Any) -&gt; None\n</code></pre> <p>Adds high cardinal metadata for metrics object</p> <p>This will not be available during metrics visualization. Instead, this will be searchable through logs.</p> <p>If you're looking to add metadata to filter metrics, then use add_dimension method.</p> Example <p>Add metrics metadata</p> <pre><code>metric.add_metadata(key=\"booking_id\", value=\"booking_id\")\n</code></pre> PARAMETER DESCRIPTION <code>key</code> <p>Metadata key</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Metadata value</p> <p> TYPE: <code>any</code> </p> Source code in <code>aws_lambda_powertools/metrics/provider/cloudwatch_emf/cloudwatch.py</code> <pre><code>def add_metadata(self, key: str, value: Any) -&gt; None:\n    \"\"\"Adds high cardinal metadata for metrics object\n\n    This will not be available during metrics visualization.\n    Instead, this will be searchable through logs.\n\n    If you're looking to add metadata to filter metrics, then\n    use add_dimension method.\n\n    Example\n    -------\n    **Add metrics metadata**\n\n        metric.add_metadata(key=\"booking_id\", value=\"booking_id\")\n\n    Parameters\n    ----------\n    key : str\n        Metadata key\n    value : any\n        Metadata value\n    \"\"\"\n    logger.debug(f\"Adding metadata: {key}:{value}\")\n\n    # Cast key to str according to EMF spec\n    # Majority of keys are expected to be string already, so\n    # checking before casting improves performance in most cases\n    if isinstance(key, str):\n        self.metadata_set[key] = value\n    else:\n        self.metadata_set[str(key)] = value\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_emf/#aws_lambda_powertools.metrics.provider.cloudwatch_emf.cloudwatch.AmazonCloudWatchEMFProvider.add_metric",
            "title": "add_metric",
            "text": "<pre><code>add_metric(\n    name: str,\n    unit: MetricUnit | str,\n    value: float,\n    resolution: MetricResolution | int = 60,\n) -&gt; None\n</code></pre> <p>Adds given metric</p> Example <p>Add given metric using MetricUnit enum</p> <pre><code>metric.add_metric(name=\"BookingConfirmation\", unit=MetricUnit.Count, value=1)\n</code></pre> <p>Add given metric using plain string as value unit</p> <pre><code>metric.add_metric(name=\"BookingConfirmation\", unit=\"Count\", value=1)\n</code></pre> <p>Add given metric with MetricResolution non default value</p> <pre><code>metric.add_metric(name=\"BookingConfirmation\", unit=\"Count\", value=1, resolution=MetricResolution.High)\n</code></pre> PARAMETER DESCRIPTION <code>name</code> <p>Metric name</p> <p> TYPE: <code>str</code> </p> <code>unit</code> <p><code>aws_lambda_powertools.helper.models.MetricUnit</code></p> <p> TYPE: <code>MetricUnit | str</code> </p> <code>value</code> <p>Metric value</p> <p> TYPE: <code>float</code> </p> <code>resolution</code> <p><code>aws_lambda_powertools.helper.models.MetricResolution</code></p> <p> TYPE: <code>MetricResolution | int</code> DEFAULT: <code>60</code> </p> RAISES DESCRIPTION <code>MetricUnitError</code> <p>When metric unit is not supported by CloudWatch</p> <code>MetricResolutionError</code> <p>When metric resolution is not supported by CloudWatch</p> Source code in <code>aws_lambda_powertools/metrics/provider/cloudwatch_emf/cloudwatch.py</code> <pre><code>def add_metric(\n    self,\n    name: str,\n    unit: MetricUnit | str,\n    value: float,\n    resolution: MetricResolution | int = 60,\n) -&gt; None:\n    \"\"\"Adds given metric\n\n    Example\n    -------\n    **Add given metric using MetricUnit enum**\n\n        metric.add_metric(name=\"BookingConfirmation\", unit=MetricUnit.Count, value=1)\n\n    **Add given metric using plain string as value unit**\n\n        metric.add_metric(name=\"BookingConfirmation\", unit=\"Count\", value=1)\n\n    **Add given metric with MetricResolution non default value**\n\n        metric.add_metric(name=\"BookingConfirmation\", unit=\"Count\", value=1, resolution=MetricResolution.High)\n\n    Parameters\n    ----------\n    name : str\n        Metric name\n    unit : MetricUnit | str\n        `aws_lambda_powertools.helper.models.MetricUnit`\n    value : float\n        Metric value\n    resolution : MetricResolution | int\n        `aws_lambda_powertools.helper.models.MetricResolution`\n\n    Raises\n    ------\n    MetricUnitError\n        When metric unit is not supported by CloudWatch\n    MetricResolutionError\n        When metric resolution is not supported by CloudWatch\n    \"\"\"\n\n    if not isinstance(value, numbers.Number):\n        raise MetricValueError(f\"{value} is not a valid number\")\n\n    unit = extract_cloudwatch_metric_unit_value(\n        metric_units=self._metric_units,\n        metric_valid_options=self._metric_unit_valid_options,\n        unit=unit,\n    )\n    resolution = extract_cloudwatch_metric_resolution_value(\n        metric_resolutions=self._metric_resolutions,\n        resolution=resolution,\n    )\n    metric: dict = self.metric_set.get(name, defaultdict(list))\n    metric[\"Unit\"] = unit\n    metric[\"StorageResolution\"] = resolution\n    metric[\"Value\"].append(float(value))\n    logger.debug(f\"Adding metric: {name} with {metric}\")\n    self.metric_set[name] = metric\n\n    if len(self.metric_set) == MAX_METRICS or len(metric[\"Value\"]) == MAX_METRICS:\n        logger.debug(f\"Exceeded maximum of {MAX_METRICS} metrics - Publishing existing metric set\")\n        metrics = self.serialize_metric_set()\n        print(json.dumps(metrics))\n\n        # clear metric set only as opposed to metrics and dimensions set\n        # since we could have more than 100 metrics\n        self.metric_set.clear()\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_emf/#aws_lambda_powertools.metrics.provider.cloudwatch_emf.cloudwatch.AmazonCloudWatchEMFProvider.flush_metrics",
            "title": "flush_metrics",
            "text": "<pre><code>flush_metrics(raise_on_empty_metrics: bool = False) -&gt; None\n</code></pre> <p>Manually flushes the metrics. This is normally not necessary, unless you're running on other runtimes besides Lambda, where the @log_metrics decorator already handles things for you.</p> PARAMETER DESCRIPTION <code>raise_on_empty_metrics</code> <p>raise exception if no metrics are emitted, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>aws_lambda_powertools/metrics/provider/cloudwatch_emf/cloudwatch.py</code> <pre><code>def flush_metrics(self, raise_on_empty_metrics: bool = False) -&gt; None:\n    \"\"\"Manually flushes the metrics. This is normally not necessary,\n    unless you're running on other runtimes besides Lambda, where the @log_metrics\n    decorator already handles things for you.\n\n    Parameters\n    ----------\n    raise_on_empty_metrics : bool, optional\n        raise exception if no metrics are emitted, by default False\n    \"\"\"\n    if not raise_on_empty_metrics and not self.metric_set:\n        warnings.warn(\n            \"No application metrics to publish. The cold-start metric may be published if enabled. \"\n            \"If application metrics should never be empty, consider using 'raise_on_empty_metrics'\",\n            stacklevel=2,\n        )\n    elif not is_metrics_disabled():\n        logger.debug(\"Flushing existing metrics\")\n        metrics = self.serialize_metric_set()\n        print(json.dumps(metrics, separators=(\",\", \":\")))\n        self.clear_metrics()\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_emf/#aws_lambda_powertools.metrics.provider.cloudwatch_emf.cloudwatch.AmazonCloudWatchEMFProvider.log_metrics",
            "title": "log_metrics",
            "text": "<pre><code>log_metrics(\n    lambda_handler: AnyCallableT | None = None,\n    capture_cold_start_metric: bool = False,\n    raise_on_empty_metrics: bool = False,\n    **kwargs\n)\n</code></pre> <p>Decorator to serialize and publish metrics at the end of a function execution.</p> <p>Be aware that the log_metrics *does call the decorated function (e.g. lambda_handler).</p> Example <p>Lambda function using tracer and metrics decorators</p> <pre><code>from aws_lambda_powertools import Metrics, Tracer\n\nmetrics = Metrics(service=\"payment\")\ntracer = Tracer(service=\"payment\")\n\n@tracer.capture_lambda_handler\n@metrics.log_metrics\ndef handler(event, context):\n        ...\n</code></pre> PARAMETER DESCRIPTION <code>lambda_handler</code> <p>lambda function handler, by default None</p> <p> TYPE: <code>Callable[[Any, Any], Any]</code> DEFAULT: <code>None</code> </p> <code>capture_cold_start_metric</code> <p>captures cold start metric, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>raise_on_empty_metrics</code> <p>raise exception if no metrics are emitted, by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>**kwargs</code> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>e</code> <p>Propagate error received</p> Source code in <code>aws_lambda_powertools/metrics/provider/cloudwatch_emf/cloudwatch.py</code> <pre><code>def log_metrics(\n    self,\n    lambda_handler: AnyCallableT | None = None,\n    capture_cold_start_metric: bool = False,\n    raise_on_empty_metrics: bool = False,\n    **kwargs,\n):\n    \"\"\"Decorator to serialize and publish metrics at the end of a function execution.\n\n    Be aware that the log_metrics **does call* the decorated function (e.g. lambda_handler).\n\n    Example\n    -------\n    **Lambda function using tracer and metrics decorators**\n\n        from aws_lambda_powertools import Metrics, Tracer\n\n        metrics = Metrics(service=\"payment\")\n        tracer = Tracer(service=\"payment\")\n\n        @tracer.capture_lambda_handler\n        @metrics.log_metrics\n        def handler(event, context):\n                ...\n\n    Parameters\n    ----------\n    lambda_handler : Callable[[Any, Any], Any], optional\n        lambda function handler, by default None\n    capture_cold_start_metric : bool, optional\n        captures cold start metric, by default False\n    raise_on_empty_metrics : bool, optional\n        raise exception if no metrics are emitted, by default False\n    **kwargs\n\n    Raises\n    ------\n    e\n        Propagate error received\n    \"\"\"\n\n    default_dimensions = kwargs.get(\"default_dimensions\")\n\n    if default_dimensions:\n        self.set_default_dimensions(**default_dimensions)\n\n    return super().log_metrics(\n        lambda_handler=lambda_handler,\n        capture_cold_start_metric=capture_cold_start_metric,\n        raise_on_empty_metrics=raise_on_empty_metrics,\n        **kwargs,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_emf/#aws_lambda_powertools.metrics.provider.cloudwatch_emf.cloudwatch.AmazonCloudWatchEMFProvider.serialize_metric_set",
            "title": "serialize_metric_set",
            "text": "<pre><code>serialize_metric_set(\n    metrics: dict | None = None,\n    dimensions: dict | None = None,\n    metadata: dict | None = None,\n) -&gt; CloudWatchEMFOutput\n</code></pre> <p>Serializes metric and dimensions set</p> PARAMETER DESCRIPTION <code>metrics</code> <p>Dictionary of metrics to serialize, by default None</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>dimensions</code> <p>Dictionary of dimensions to serialize, by default None</p> <p> TYPE: <code>dict</code> DEFAULT: <code>None</code> </p> <code>metadata</code> <p>Dictionary of metadata to serialize, by default None</p> <p> TYPE: <code>dict | None</code> DEFAULT: <code>None</code> </p> Example <p>Serialize metrics into EMF format</p> <pre><code>metrics = MetricManager()\n# ...add metrics, dimensions, namespace\nret = metrics.serialize_metric_set()\n</code></pre> RETURNS DESCRIPTION <code>CloudWatchEMFOutput</code> <p>Serialized metrics following EMF specification</p> RAISES DESCRIPTION <code>SchemaValidationError</code> <p>Raised when serialization fail schema validation</p> Source code in <code>aws_lambda_powertools/metrics/provider/cloudwatch_emf/cloudwatch.py</code> <pre><code>def serialize_metric_set(\n    self,\n    metrics: dict | None = None,\n    dimensions: dict | None = None,\n    metadata: dict | None = None,\n) -&gt; CloudWatchEMFOutput:\n    \"\"\"Serializes metric and dimensions set\n\n    Parameters\n    ----------\n    metrics : dict, optional\n        Dictionary of metrics to serialize, by default None\n    dimensions : dict, optional\n        Dictionary of dimensions to serialize, by default None\n    metadata: dict, optional\n        Dictionary of metadata to serialize, by default None\n\n    Example\n    -------\n    **Serialize metrics into EMF format**\n\n        metrics = MetricManager()\n        # ...add metrics, dimensions, namespace\n        ret = metrics.serialize_metric_set()\n\n    Returns\n    -------\n    CloudWatchEMFOutput\n        Serialized metrics following EMF specification\n\n    Raises\n    ------\n    SchemaValidationError\n        Raised when serialization fail schema validation\n    \"\"\"\n    if metrics is None:  # pragma: no cover\n        metrics = self.metric_set\n\n    if dimensions is None:  # pragma: no cover\n        dimensions = self.dimension_set\n\n    if metadata is None:  # pragma: no cover\n        metadata = self.metadata_set\n\n    if self.service and not self.dimension_set.get(\"service\"):\n        # self.service won't be a float\n        self.add_dimension(name=\"service\", value=self.service)\n\n    if len(metrics) == 0:\n        raise SchemaValidationError(\"Must contain at least one metric.\")\n\n    if self.namespace is None:\n        raise SchemaValidationError(\"Must contain a metric namespace.\")\n\n    logger.debug({\"details\": \"Serializing metrics\", \"metrics\": metrics, \"dimensions\": dimensions})\n\n    # For standard resolution metrics, don't add StorageResolution field to avoid unnecessary ingestion of data into cloudwatch # noqa E501\n    # Example: [ { \"Name\": \"metric_name\", \"Unit\": \"Count\"} ] # noqa ERA001\n    #\n    # In case using high-resolution metrics, add StorageResolution field\n    # Example: [ { \"Name\": \"metric_name\", \"Unit\": \"Count\", \"StorageResolution\": 1 } ] # noqa ERA001\n    metric_definition: list[MetricNameUnitResolution] = []\n    metric_names_and_values: dict[str, float] = {}  # { \"metric_name\": 1.0 }\n\n    for metric_name in metrics:\n        metric: dict = metrics[metric_name]\n        metric_value: int = metric.get(\"Value\", 0)\n        metric_unit: str = metric.get(\"Unit\", \"\")\n        metric_resolution: int = metric.get(\"StorageResolution\", 60)\n\n        metric_definition_data: MetricNameUnitResolution = {\"Name\": metric_name, \"Unit\": metric_unit}\n\n        # high-resolution metrics\n        if metric_resolution == 1:\n            metric_definition_data[\"StorageResolution\"] = metric_resolution\n\n        metric_definition.append(metric_definition_data)\n\n        metric_names_and_values.update({metric_name: metric_value})\n\n    return {\n        \"_aws\": {\n            \"Timestamp\": self.timestamp or int(datetime.datetime.now().timestamp() * 1000),  # epoch\n            \"CloudWatchMetrics\": [\n                {\n                    \"Namespace\": self.namespace,  # \"test_namespace\"\n                    \"Dimensions\": [list(dimensions.keys())],  # [ \"service\" ]\n                    \"Metrics\": metric_definition,\n                },\n            ],\n        },\n        # NOTE: Mypy doesn't recognize splats '** syntax' in TypedDict\n        **dimensions,  # \"service\": \"test_service\"\n        **metadata,  # type: ignore[typeddict-item] # \"username\": \"test\"\n        **metric_names_and_values,  # \"single_metric\": 1.0\n    }\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_emf/#aws_lambda_powertools.metrics.provider.cloudwatch_emf.cloudwatch.AmazonCloudWatchEMFProvider.set_default_dimensions",
            "title": "set_default_dimensions",
            "text": "<pre><code>set_default_dimensions(**dimensions) -&gt; None\n</code></pre> <p>Persist dimensions across Lambda invocations</p> PARAMETER DESCRIPTION <code>dimensions</code> <p>metric dimensions as key=value</p> <p> TYPE: <code>dict[str, Any]</code> DEFAULT: <code>{}</code> </p> Example <p>Sets some default dimensions that will always be present across metrics and invocations</p> <pre><code>from aws_lambda_powertools import Metrics\n\nmetrics = Metrics(namespace=\"ServerlessAirline\", service=\"payment\")\nmetrics.set_default_dimensions(environment=\"demo\", another=\"one\")\n\n@metrics.log_metrics()\ndef lambda_handler():\n    return True\n</code></pre> Source code in <code>aws_lambda_powertools/metrics/provider/cloudwatch_emf/cloudwatch.py</code> <pre><code>def set_default_dimensions(self, **dimensions) -&gt; None:\n    \"\"\"Persist dimensions across Lambda invocations\n\n    Parameters\n    ----------\n    dimensions : dict[str, Any], optional\n        metric dimensions as key=value\n\n    Example\n    -------\n    **Sets some default dimensions that will always be present across metrics and invocations**\n\n        from aws_lambda_powertools import Metrics\n\n        metrics = Metrics(namespace=\"ServerlessAirline\", service=\"payment\")\n        metrics.set_default_dimensions(environment=\"demo\", another=\"one\")\n\n        @metrics.log_metrics()\n        def lambda_handler():\n            return True\n    \"\"\"\n    for name, value in dimensions.items():\n        self.add_dimension(name, value)\n\n    self.default_dimensions.update(**dimensions)\n</code></pre>"
        },
        {
            "location": "api_doc/metrics/provider_emf/#aws_lambda_powertools.metrics.provider.cloudwatch_emf.cloudwatch.AmazonCloudWatchEMFProvider.set_timestamp",
            "title": "set_timestamp",
            "text": "<pre><code>set_timestamp(timestamp: int | datetime)\n</code></pre> <p>Set the timestamp for the metric.</p> PARAMETER DESCRIPTION <code>timestamp</code> <p>The timestamp to create the metric. If an integer is provided, it is assumed to be the epoch time in milliseconds. If a datetime object is provided, it will be converted to epoch time in milliseconds.</p> <p> TYPE: <code>int | datetime</code> </p> Source code in <code>aws_lambda_powertools/metrics/provider/cloudwatch_emf/cloudwatch.py</code> <pre><code>def set_timestamp(self, timestamp: int | datetime.datetime):\n    \"\"\"\n    Set the timestamp for the metric.\n\n    Parameters\n    -----------\n    timestamp: int | datetime.datetime\n        The timestamp to create the metric.\n        If an integer is provided, it is assumed to be the epoch time in milliseconds.\n        If a datetime object is provided, it will be converted to epoch time in milliseconds.\n    \"\"\"\n    # The timestamp must be a Datetime object or an integer representing an epoch time.\n    # This should not exceed 14 days in the past or be more than 2 hours in the future.\n    # Any metrics failing to meet this criteria will be skipped by Amazon CloudWatch.\n    # See: https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Embedded_Metric_Format_Specification.html\n    # See: https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CloudWatch-Logs-Monitoring-CloudWatch-Metrics.html\n    if not validate_emf_timestamp(timestamp):\n        warnings.warn(\n            \"This metric doesn't meet the requirements and will be skipped by Amazon CloudWatch. \"\n            \"Ensure the timestamp is within 14 days past or 2 hours future.\",\n            stacklevel=2,\n        )\n\n    self.timestamp = convert_timestamp_to_emf_format(timestamp)\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/appconfig/",
            "title": "AppConfig",
            "text": "<p>AWS App Config configuration retrieval and caching utility</p> CLASS DESCRIPTION <code>AppConfigProvider</code> <p>AWS App Config Provider</p> FUNCTION DESCRIPTION <code>get_app_config</code> <p>Retrieve a configuration value from AWS App Config.</p>"
        },
        {
            "location": "api_doc/parameters/appconfig/#aws_lambda_powertools.utilities.parameters.appconfig.AppConfigProvider",
            "title": "AppConfigProvider",
            "text": "<pre><code>AppConfigProvider(\n    environment: str,\n    application: str | None = None,\n    config: Config | None = None,\n    boto_config: Config | None = None,\n    boto3_session: Session | None = None,\n    boto3_client: AppConfigDataClient | None = None,\n)\n</code></pre> <p>               Bases: <code>BaseProvider</code></p> <p>AWS App Config Provider</p> PARAMETER DESCRIPTION <code>environment</code> <p>Environment of the configuration to pass during client initialization</p> <p> TYPE: <code>str</code> </p> <code>application</code> <p>Application of the configuration to pass during client initialization</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Botocore configuration to pass during client initialization</p> <p> TYPE: <code>Config | None</code> DEFAULT: <code>None</code> </p> <code>boto3_session</code> <pre><code>Boto3 session to create a boto3_client from\n</code></pre> <p> TYPE: <code>Session</code> DEFAULT: <code>None</code> </p> <code>boto3_client</code> <pre><code>Boto3 AppConfigData Client to use, boto3_session will be ignored if both are provided\n</code></pre> <p> TYPE: <code>AppConfigDataClient | None</code> DEFAULT: <code>None</code> </p> Example <p>Retrieves the latest configuration value from App Config</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n&gt;&gt;&gt;\n&gt;&gt;&gt; appconf_provider = parameters.AppConfigProvider(environment=\"my_env\", application=\"my_app\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; value : bytes = appconf_provider.get(\"my_conf\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy configuration value\n</code></pre> <p>Retrieves a configuration value from App Config in another AWS region</p> <pre><code>&gt;&gt;&gt; from botocore.config import Config\n&gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n&gt;&gt;&gt;\n&gt;&gt;&gt; config = Config(region_name=\"us-west-1\")\n&gt;&gt;&gt; appconf_provider = parameters.AppConfigProvider(environment=\"my_env\", application=\"my_app\", config=config)\n&gt;&gt;&gt;\n&gt;&gt;&gt; value : bytes = appconf_provider.get(\"my_conf\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy configuration value\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/parameters/appconfig.py</code> <pre><code>def __init__(\n    self,\n    environment: str,\n    application: str | None = None,\n    config: Config | None = None,\n    boto_config: Config | None = None,\n    boto3_session: boto3.session.Session | None = None,\n    boto3_client: AppConfigDataClient | None = None,\n):\n    \"\"\"\n    Initialize the App Config client\n    \"\"\"\n\n    super().__init__()\n\n    if config:\n        warnings.warn(\n            message=\"The 'config' parameter is deprecated in V3 and will be removed in V4. \"\n            \"Please use 'boto_config' instead.\",\n            category=PowertoolsDeprecationWarning,\n            stacklevel=2,\n        )\n\n    if boto3_client is None:\n        boto3_session = boto3_session or boto3.session.Session()\n        boto3_client = boto3_session.client(\"appconfigdata\", config=boto_config or config)\n\n    self.client = boto3_client\n\n    self.application = resolve_env_var_choice(\n        choice=application,\n        env=os.getenv(constants.SERVICE_NAME_ENV, \"service_undefined\"),\n    )\n    self.environment = environment\n    self.current_version = \"\"\n\n    self._next_token: dict[str, str] = {}  # nosec - token for get_latest_configuration executions\n    # Dict to store the recently retrieved value for a specific configuration.\n    self.last_returned_value: dict[str, bytes] = {}\n\n    super().__init__(client=self.client)\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/appconfig/#aws_lambda_powertools.utilities.parameters.appconfig.get_app_config",
            "title": "get_app_config",
            "text": "<pre><code>get_app_config(\n    name: str,\n    environment: str,\n    application: str | None = None,\n    transform: TransformOptions = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options\n) -&gt; str | bytes | list | dict\n</code></pre> <p>Retrieve a configuration value from AWS App Config.</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of the configuration</p> <p> TYPE: <code>str</code> </p> <code>environment</code> <p>Environment of the configuration</p> <p> TYPE: <code>str</code> </p> <code>application</code> <p>Application of the configuration</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>transform</code> <p>Transforms the content from a JSON object ('json') or base64 binary string ('binary')</p> <p> TYPE: <code>TransformOptions</code> DEFAULT: <code>None</code> </p> <code>force_fetch</code> <p>Force update even before a cached item has expired, defaults to False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_age</code> <p>Maximum age of the cached value</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>sdk_options</code> <p>SDK options to propagate to <code>start_configuration_session</code> API call</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>GetParameterError</code> <p>When the parameter provider fails to retrieve a parameter value for a given name.</p> <code>TransformParameterError</code> <p>When the parameter provider fails to transform a parameter value.</p> Example <p>Retrieves the latest version of configuration value from App Config</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_app_config\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = get_app_config(\"my_config\", environment=\"my_env\", application=\"my_env\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy configuration value\n</code></pre> <p>Retrieves a configuration value and decodes it using a JSON decoder</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_app_config\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = get_app_config(\"my_config\", environment=\"my_env\", application=\"my_env\", transform='json')\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy configuration's JSON value\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/parameters/appconfig.py</code> <pre><code>def get_app_config(\n    name: str,\n    environment: str,\n    application: str | None = None,\n    transform: TransformOptions = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options,\n) -&gt; str | bytes | list | dict:\n    \"\"\"\n    Retrieve a configuration value from AWS App Config.\n\n    Parameters\n    ----------\n    name: str\n        Name of the configuration\n    environment: str\n        Environment of the configuration\n    application: str\n        Application of the configuration\n    transform: str, optional\n        Transforms the content from a JSON object ('json') or base64 binary string ('binary')\n    force_fetch: bool, optional\n        Force update even before a cached item has expired, defaults to False\n    max_age: int, optional\n        Maximum age of the cached value\n    sdk_options: dict, optional\n        SDK options to propagate to `start_configuration_session` API call\n\n    Raises\n    ------\n    GetParameterError\n        When the parameter provider fails to retrieve a parameter value for\n        a given name.\n    TransformParameterError\n        When the parameter provider fails to transform a parameter value.\n\n    Example\n    -------\n    **Retrieves the latest version of configuration value from App Config**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_app_config\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; value = get_app_config(\"my_config\", environment=\"my_env\", application=\"my_env\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; print(value)\n        My configuration value\n\n    **Retrieves a configuration value and decodes it using a JSON decoder**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_app_config\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; value = get_app_config(\"my_config\", environment=\"my_env\", application=\"my_env\", transform='json')\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; print(value)\n        My configuration's JSON value\n    \"\"\"\n    # If max_age is not set, resolve it from the environment variable, defaulting to DEFAULT_MAX_AGE_SECS\n    max_age = resolve_max_age(env=os.getenv(constants.PARAMETERS_MAX_AGE_ENV, DEFAULT_MAX_AGE_SECS), choice=max_age)\n\n    # Only create the provider if this function is called at least once\n    if \"appconfig\" not in DEFAULT_PROVIDERS:\n        DEFAULT_PROVIDERS[\"appconfig\"] = AppConfigProvider(environment=environment, application=application)\n\n    return DEFAULT_PROVIDERS[\"appconfig\"].get(\n        name,\n        max_age=max_age,\n        transform=transform,\n        force_fetch=force_fetch,\n        **sdk_options,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/base/",
            "title": "Base",
            "text": "<p>Base for Parameter providers</p> <p>Usage Documentation</p> <p><code>Parameters</code></p> CLASS DESCRIPTION <code>BaseProvider</code> <p>Abstract Base Class for Parameter providers</p> FUNCTION DESCRIPTION <code>clear_caches</code> <p>Clear cached parameter values from all providers</p> <code>get_transform_method</code> <p>Determine the transform method</p> <code>transform_value</code> <p>Transform a value using one of the available options.</p>"
        },
        {
            "location": "api_doc/parameters/base/#aws_lambda_powertools.utilities.parameters.base.BaseProvider",
            "title": "BaseProvider",
            "text": "<pre><code>BaseProvider(*, client=None, resource=None)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract Base Class for Parameter providers</p> METHOD DESCRIPTION <code>get</code> <p>Retrieve a parameter value or return the cached value</p> <code>get_multiple</code> <p>Retrieve multiple parameters based on a path prefix</p> <code>set</code> <p>Set parameter value from the underlying parameter store</p> Source code in <code>aws_lambda_powertools/utilities/parameters/base.py</code> <pre><code>def __init__(self, *, client=None, resource=None):\n    \"\"\"\n    Initialize the base provider\n    \"\"\"\n    if client is not None:\n        user_agent.register_feature_to_client(client=client, feature=\"parameters\")\n    if resource is not None:\n        user_agent.register_feature_to_resource(resource=resource, feature=\"parameters\")\n\n    self.store: dict[tuple, ExpirableValue] = {}\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/base/#aws_lambda_powertools.utilities.parameters.base.BaseProvider.get",
            "title": "get",
            "text": "<pre><code>get(\n    name: str,\n    max_age: int | None = None,\n    transform: TransformOptions = None,\n    force_fetch: bool = False,\n    **sdk_options\n) -&gt; str | bytes | dict | None\n</code></pre> <p>Retrieve a parameter value or return the cached value</p> PARAMETER DESCRIPTION <code>name</code> <p>Parameter name</p> <p> TYPE: <code>str</code> </p> <code>max_age</code> <p>Maximum age of the cached value</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>transform</code> <p>Optional transformation of the parameter value. Supported values are \"json\" for JSON strings and \"binary\" for base 64 encoded values.</p> <p> TYPE: <code>TransformOptions</code> DEFAULT: <code>None</code> </p> <code>force_fetch</code> <p>Force update even before a cached item has expired, defaults to False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>sdk_options</code> <p>Arguments that will be passed directly to the underlying API call</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>GetParameterError</code> <p>When the parameter provider fails to retrieve a parameter value for a given name.</p> <code>TransformParameterError</code> <p>When the parameter provider fails to transform a parameter value.</p> Source code in <code>aws_lambda_powertools/utilities/parameters/base.py</code> <pre><code>def get(\n    self,\n    name: str,\n    max_age: int | None = None,\n    transform: TransformOptions = None,\n    force_fetch: bool = False,\n    **sdk_options,\n) -&gt; str | bytes | dict | None:\n    \"\"\"\n    Retrieve a parameter value or return the cached value\n\n    Parameters\n    ----------\n    name: str\n        Parameter name\n    max_age: int\n        Maximum age of the cached value\n    transform: str\n        Optional transformation of the parameter value. Supported values\n        are \"json\" for JSON strings and \"binary\" for base 64 encoded\n        values.\n    force_fetch: bool, optional\n        Force update even before a cached item has expired, defaults to False\n    sdk_options: dict, optional\n        Arguments that will be passed directly to the underlying API call\n\n    Raises\n    ------\n    GetParameterError\n        When the parameter provider fails to retrieve a parameter value for\n        a given name.\n    TransformParameterError\n        When the parameter provider fails to transform a parameter value.\n    \"\"\"\n\n    # If there are multiple calls to the same parameter but in a different\n    # transform, they will be stored multiple times. This allows us to\n    # optimize by transforming the data only once per retrieval, thus there\n    # is no need to transform cached values multiple times. However, this\n    # means that we need to make multiple calls to the underlying parameter\n    # store if we need to return it in different transforms. Since the number\n    # of supported transform is small and the probability that a given\n    # parameter will always be used in a specific transform, this should be\n    # an acceptable tradeoff.\n    value: str | bytes | dict | None = None\n    key = self._build_cache_key(name=name, transform=transform)\n\n    # If max_age is not set, resolve it from the environment variable, defaulting to DEFAULT_MAX_AGE_SECS\n    max_age = resolve_max_age(env=os.getenv(constants.PARAMETERS_MAX_AGE_ENV, DEFAULT_MAX_AGE_SECS), choice=max_age)\n\n    if not force_fetch and self.has_not_expired_in_cache(key):\n        return self.fetch_from_cache(key)\n\n    try:\n        value = self._get(name, **sdk_options)\n    # Encapsulate all errors into a generic GetParameterError\n    except Exception as exc:\n        raise GetParameterError(str(exc))\n\n    if transform:\n        value = transform_value(key=name, value=value, transform=transform, raise_on_transform_error=True)\n\n    # NOTE: don't cache None, as they might've been failed transforms and may be corrected\n    if value is not None:\n        self.add_to_cache(key=key, value=value, max_age=max_age)\n\n    return value\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/base/#aws_lambda_powertools.utilities.parameters.base.BaseProvider.get_multiple",
            "title": "get_multiple",
            "text": "<pre><code>get_multiple(\n    path: str,\n    max_age: int | None = None,\n    transform: TransformOptions = None,\n    raise_on_transform_error: bool = False,\n    force_fetch: bool = False,\n    **sdk_options\n) -&gt; dict[str, str] | dict[str, bytes] | dict[str, dict]\n</code></pre> <p>Retrieve multiple parameters based on a path prefix</p> PARAMETER DESCRIPTION <code>path</code> <p>Parameter path used to retrieve multiple parameters</p> <p> TYPE: <code>str</code> </p> <code>max_age</code> <p>Maximum age of the cached value</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>transform</code> <p>Optional transformation of the parameter value. Supported values are \"json\" for JSON strings, \"binary\" for base 64 encoded values or \"auto\" which looks at the attribute key to determine the type.</p> <p> TYPE: <code>TransformOptions</code> DEFAULT: <code>None</code> </p> <code>raise_on_transform_error</code> <p>Raises an exception if any transform fails, otherwise this will return a None value for each transform that failed</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>force_fetch</code> <p>Force update even before a cached item has expired, defaults to False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>sdk_options</code> <p>Arguments that will be passed directly to the underlying API call</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>GetParameterError</code> <p>When the parameter provider fails to retrieve parameter values for a given path.</p> <code>TransformParameterError</code> <p>When the parameter provider fails to transform a parameter value.</p> Source code in <code>aws_lambda_powertools/utilities/parameters/base.py</code> <pre><code>def get_multiple(\n    self,\n    path: str,\n    max_age: int | None = None,\n    transform: TransformOptions = None,\n    raise_on_transform_error: bool = False,\n    force_fetch: bool = False,\n    **sdk_options,\n) -&gt; dict[str, str] | dict[str, bytes] | dict[str, dict]:\n    \"\"\"\n    Retrieve multiple parameters based on a path prefix\n\n    Parameters\n    ----------\n    path: str\n        Parameter path used to retrieve multiple parameters\n    max_age: int, optional\n        Maximum age of the cached value\n    transform: str, optional\n        Optional transformation of the parameter value. Supported values\n        are \"json\" for JSON strings, \"binary\" for base 64 encoded\n        values or \"auto\" which looks at the attribute key to determine the type.\n    raise_on_transform_error: bool, optional\n        Raises an exception if any transform fails, otherwise this will\n        return a None value for each transform that failed\n    force_fetch: bool, optional\n        Force update even before a cached item has expired, defaults to False\n    sdk_options: dict, optional\n        Arguments that will be passed directly to the underlying API call\n\n    Raises\n    ------\n    GetParameterError\n        When the parameter provider fails to retrieve parameter values for\n        a given path.\n    TransformParameterError\n        When the parameter provider fails to transform a parameter value.\n    \"\"\"\n    key = self._build_cache_key(name=path, transform=transform, is_nested=True)\n\n    # If max_age is not set, resolve it from the environment variable, defaulting to DEFAULT_MAX_AGE_SECS\n    max_age = resolve_max_age(env=os.getenv(constants.PARAMETERS_MAX_AGE_ENV, DEFAULT_MAX_AGE_SECS), choice=max_age)\n\n    if not force_fetch and self.has_not_expired_in_cache(key):\n        return self.fetch_from_cache(key)\n\n    try:\n        values = self._get_multiple(path, **sdk_options)\n    # Encapsulate all errors into a generic GetParameterError\n    except Exception as exc:\n        raise GetParameterError(str(exc))\n\n    if transform:\n        values.update(transform_value(values, transform, raise_on_transform_error))\n\n    self.add_to_cache(key=key, value=values, max_age=max_age)\n\n    return values\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/base/#aws_lambda_powertools.utilities.parameters.base.BaseProvider.set",
            "title": "set",
            "text": "<pre><code>set(\n    name: str,\n    value: Any,\n    *,\n    overwrite: bool = False,\n    **kwargs\n)\n</code></pre> <p>Set parameter value from the underlying parameter store</p> Source code in <code>aws_lambda_powertools/utilities/parameters/base.py</code> <pre><code>def set(self, name: str, value: Any, *, overwrite: bool = False, **kwargs):\n    \"\"\"\n    Set parameter value from the underlying parameter store\n    \"\"\"\n    raise NotImplementedError()\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/base/#aws_lambda_powertools.utilities.parameters.base.clear_caches",
            "title": "clear_caches",
            "text": "<pre><code>clear_caches()\n</code></pre> <p>Clear cached parameter values from all providers</p> Source code in <code>aws_lambda_powertools/utilities/parameters/base.py</code> <pre><code>def clear_caches():\n    \"\"\"Clear cached parameter values from all providers\"\"\"\n    DEFAULT_PROVIDERS.clear()\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/base/#aws_lambda_powertools.utilities.parameters.base.get_transform_method",
            "title": "get_transform_method",
            "text": "<pre><code>get_transform_method(\n    value: str, transform: TransformOptions = None\n) -&gt; Callable[..., Any]\n</code></pre> <p>Determine the transform method</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; get_transform_method(\"key\",\"any_other_value\")\n'any_other_value'\n&gt;&gt;&gt; get_transform_method(\"key.json\",\"auto\")\n'json'\n&gt;&gt;&gt; get_transform_method(\"key.binary\",\"auto\")\n'binary'\n&gt;&gt;&gt; get_transform_method(\"key\",\"auto\")\nNone\n&gt;&gt;&gt; get_transform_method(\"key\",None)\nNone\n</code></pre> PARAMETER DESCRIPTION <code>value</code> <p>Only used when the transform is \"auto\".</p> <p> TYPE: <code>str</code> </p> <code>transform</code> <p>Original transform method, only \"auto\" will try to detect the transform method by the key</p> <p> TYPE: <code>TransformOptions</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Callable</code> <p>Transform function could be json.loads, base64.b64decode, or a lambda that echo the str value</p> <p> TYPE: <code>Callable[..., Any]</code> </p> Source code in <code>aws_lambda_powertools/utilities/parameters/base.py</code> <pre><code>def get_transform_method(value: str, transform: TransformOptions = None) -&gt; Callable[..., Any]:\n    \"\"\"\n    Determine the transform method\n\n    Examples\n    -------\n        &gt;&gt;&gt; get_transform_method(\"key\",\"any_other_value\")\n        'any_other_value'\n        &gt;&gt;&gt; get_transform_method(\"key.json\",\"auto\")\n        'json'\n        &gt;&gt;&gt; get_transform_method(\"key.binary\",\"auto\")\n        'binary'\n        &gt;&gt;&gt; get_transform_method(\"key\",\"auto\")\n        None\n        &gt;&gt;&gt; get_transform_method(\"key\",None)\n        None\n\n    Parameters\n    ---------\n    value: str\n        Only used when the transform is \"auto\".\n    transform: str, optional\n        Original transform method, only \"auto\" will try to detect the transform method by the key\n\n    Returns\n    ------\n    Callable:\n        Transform function could be json.loads, base64.b64decode, or a lambda that echo the str value\n    \"\"\"\n    transform_method = TRANSFORM_METHOD_MAPPING.get(transform)\n\n    if transform == \"auto\":\n        key_suffix = value.rsplit(\".\")[-1]\n        transform_method = TRANSFORM_METHOD_MAPPING.get(key_suffix, TRANSFORM_METHOD_MAPPING[None])\n\n    return cast(Callable, transform_method)  # https://github.com/python/mypy/issues/10740\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/base/#aws_lambda_powertools.utilities.parameters.base.transform_value",
            "title": "transform_value",
            "text": "<pre><code>transform_value(\n    value: dict[str, Any],\n    transform: TransformOptions,\n    raise_on_transform_error: bool = False,\n    key: str = \"\",\n) -&gt; dict[str, Any]\n</code></pre><pre><code>transform_value(\n    value: str | bytes | dict[str, Any],\n    transform: TransformOptions,\n    raise_on_transform_error: bool = False,\n    key: str = \"\",\n) -&gt; str | bytes | dict[str, Any] | None\n</code></pre> <pre><code>transform_value(\n    value: str | bytes | dict[str, Any],\n    transform: TransformOptions,\n    raise_on_transform_error: bool = True,\n    key: str = \"\",\n) -&gt; str | bytes | dict[str, Any] | None\n</code></pre> <p>Transform a value using one of the available options.</p> PARAMETER DESCRIPTION <code>value</code> <p>Parameter value to transform</p> <p> TYPE: <code>str | bytes | dict[str, Any]</code> </p> <code>transform</code> <p>Type of transform, supported values are \"json\", \"binary\", and \"auto\" based on suffix (.json, .binary)</p> <p> TYPE: <code>TransformOptions</code> </p> <code>key</code> <p>Parameter key when transform is auto to infer its transform method</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>raise_on_transform_error</code> <p>Raises an exception if any transform fails, otherwise this will return a None value for each transform that failed</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>TransformParameterError:</code> <p>When the parameter value could not be transformed</p> Source code in <code>aws_lambda_powertools/utilities/parameters/base.py</code> <pre><code>def transform_value(\n    value: str | bytes | dict[str, Any],\n    transform: TransformOptions,\n    raise_on_transform_error: bool = True,\n    key: str = \"\",\n) -&gt; str | bytes | dict[str, Any] | None:\n    \"\"\"\n    Transform a value using one of the available options.\n\n    Parameters\n    ---------\n    value: str\n        Parameter value to transform\n    transform: str\n        Type of transform, supported values are \"json\", \"binary\", and \"auto\" based on suffix (.json, .binary)\n    key: str\n        Parameter key when transform is auto to infer its transform method\n    raise_on_transform_error: bool, optional\n        Raises an exception if any transform fails, otherwise this will\n        return a None value for each transform that failed\n\n    Raises\n    ------\n    TransformParameterError:\n        When the parameter value could not be transformed\n    \"\"\"\n    # Maintenance: For v3, we should consider returning the original value for soft transform failures.\n\n    err_msg = \"Unable to transform value using '{transform}' transform: {exc}\"\n\n    if isinstance(value, bytes):\n        value = value.decode(\"utf-8\")\n\n    if isinstance(value, dict):\n        # NOTE: We must handle partial failures when receiving multiple values\n        # where one of the keys might fail during transform, e.g. `{\"a\": \"valid\", \"b\": \"{\"}`\n        # expected: `{\"a\": \"valid\", \"b\": None}`\n\n        transformed_values: dict[str, Any] = {}\n        for dict_key, dict_value in value.items():\n            transform_method = get_transform_method(value=dict_key, transform=transform)\n            try:\n                transformed_values[dict_key] = transform_method(dict_value)\n            except Exception as exc:\n                if raise_on_transform_error:\n                    raise TransformParameterError(err_msg.format(transform=transform, exc=exc)) from exc\n                transformed_values[dict_key] = None\n        return transformed_values\n\n    if transform == \"auto\":\n        # key=\"a.json\", value='{\"a\": \"b\"}', or key=\"a.binary\", value=\"b64_encoded\"\n        transform_method = get_transform_method(value=key, transform=transform)\n    else:\n        # value='{\"key\": \"value\"}\n        transform_method = get_transform_method(value=value, transform=transform)\n\n    try:\n        return transform_method(value)\n    except Exception as exc:\n        if raise_on_transform_error:\n            raise TransformParameterError(err_msg.format(transform=transform, exc=exc)) from exc\n        return None\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/dynamodb/",
            "title": "DynamoDB",
            "text": "<p>Amazon DynamoDB parameter retrieval and caching utility</p> CLASS DESCRIPTION <code>DynamoDBProvider</code> <p>Amazon DynamoDB Parameter Provider</p>"
        },
        {
            "location": "api_doc/parameters/dynamodb/#aws_lambda_powertools.utilities.parameters.dynamodb.DynamoDBProvider",
            "title": "DynamoDBProvider",
            "text": "<pre><code>DynamoDBProvider(\n    table_name: str,\n    key_attr: str = \"id\",\n    sort_attr: str = \"sk\",\n    value_attr: str = \"value\",\n    endpoint_url: str | None = None,\n    config: Config | None = None,\n    boto_config: Config | None = None,\n    boto3_session: Session | None = None,\n    boto3_client: DynamoDBServiceResource | None = None,\n)\n</code></pre> <p>               Bases: <code>BaseProvider</code></p> <p>Amazon DynamoDB Parameter Provider</p> PARAMETER DESCRIPTION <code>table_name</code> <p>Name of the DynamoDB table that stores parameters</p> <p> TYPE: <code>str</code> </p> <code>key_attr</code> <p>Hash key for the DynamoDB table (default to 'id')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'id'</code> </p> <code>sort_attr</code> <p>Name of the DynamoDB table sort key (defaults to 'sk'), used only for get_multiple</p> <p> TYPE: <code>str</code> DEFAULT: <code>'sk'</code> </p> <code>value_attr</code> <p>Attribute that contains the values in the DynamoDB table (defaults to 'value')</p> <p> TYPE: <code>str</code> DEFAULT: <code>'value'</code> </p> <code>endpoint_url</code> <p>Complete url to reference local DynamoDB instance, e.g. http://localhost:8080</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>config</code> <p>Botocore configuration to pass during client initialization</p> <p> TYPE: <code>Config | None</code> DEFAULT: <code>None</code> </p> <code>boto3_session</code> <pre><code>Boto3 session to create a boto3_client from\n</code></pre> <p> TYPE: <code>Session</code> DEFAULT: <code>None</code> </p> <code>boto3_client</code> <pre><code>Boto3 DynamoDB Resource Client to use; boto3_session will be ignored if both are provided\n</code></pre> <p> TYPE: <code>DynamoDBServiceResource | None</code> DEFAULT: <code>None</code> </p> Example <p>Retrieves a parameter value from a DynamoDB table</p> <p>In this example, the DynamoDB table uses <code>id</code> as hash key and stores the value in the <code>value</code> attribute. The parameter item looks like this:</p> <pre><code>{ \"id\": \"my-parameters\", \"value\": \"Parameter value a\" }\n\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import DynamoDBProvider\n&gt;&gt;&gt; ddb_provider = DynamoDBProvider(\"ParametersTable\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = ddb_provider.get(\"my-parameter\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy parameter value\n</code></pre> <p>Retrieves a parameter value from a DynamoDB table that has custom attribute names</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import DynamoDBProvider\n&gt;&gt;&gt; ddb_provider = DynamoDBProvider(\n...     \"ParametersTable\",\n...     key_attr=\"my-id\",\n...     value_attr=\"my-value\"\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = ddb_provider.get(\"my-parameter\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy parameter value\n</code></pre> <p>Retrieves a parameter value from a DynamoDB table in another AWS region</p> <pre><code>&gt;&gt;&gt; from botocore.config import Config\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import DynamoDBProvider\n&gt;&gt;&gt;\n&gt;&gt;&gt; config = Config(region_name=\"us-west-1\")\n&gt;&gt;&gt; ddb_provider = DynamoDBProvider(\"ParametersTable\", config=config)\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = ddb_provider.get(\"my-parameter\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy parameter value\n</code></pre> <p>Retrieves a parameter value from a DynamoDB table passing options to the SDK call</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import DynamoDBProvider\n&gt;&gt;&gt; ddb_provider = DynamoDBProvider(\"ParametersTable\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = ddb_provider.get(\"my-parameter\", ConsistentRead=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy parameter value\n</code></pre> <p>Retrieves multiple values from a DynamoDB table</p> <p>In this case, the provider will use a sort key to retrieve multiple values using a query under the hood. This expects that the sort key is named <code>sk</code>. The DynamoDB table contains three items looking like this:</p> <pre><code>{ \"id\": \"my-parameters\", \"sk\": \"a\", \"value\": \"Parameter value a\" }\n{ \"id\": \"my-parameters\", \"sk\": \"b\", \"value\": \"Parameter value b\" }\n{ \"id\": \"my-parameters\", \"sk\": \"c\", \"value\": \"Parameter value c\" }\n\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import DynamoDBProvider\n&gt;&gt;&gt; ddb_provider = DynamoDBProvider(\"ParametersTable\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; values = ddb_provider.get_multiple(\"my-parameters\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; for key, value in values.items():\n...     print(key, value)\na   Parameter value a\nb   Parameter value b\nc   Parameter value c\n</code></pre> <p>Retrieves multiple values from a DynamoDB table that has custom attribute names</p> <p>In this case, the provider will use a sort key to retrieve multiple values using a query under the hood.</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import DynamoDBProvider\n&gt;&gt;&gt; ddb_provider = DynamoDBProvider(\n...     \"ParametersTable\",\n...     key_attr=\"my-id\",\n...     sort_attr=\"my-sort-key\",\n...     value_attr=\"my-value\"\n... )\n&gt;&gt;&gt;\n&gt;&gt;&gt; values = ddb_provider.get_multiple(\"my-parameters\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; for key, value in values.items():\n...     print(key, value)\na   Parameter value a\nb   Parameter value b\nc   Parameter value c\n</code></pre> <p>Retrieves multiple values from a DynamoDB table passing options to the SDK calls</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import DynamoDBProvider\n&gt;&gt;&gt; ddb_provider = DynamoDBProvider(\"ParametersTable\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; values = ddb_provider.get_multiple(\"my-parameters\", ConsistentRead=True)\n&gt;&gt;&gt;\n&gt;&gt;&gt; for key, value in values.items():\n...     print(key, value)\na   Parameter value a\nb   Parameter value b\nc   Parameter value c\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/parameters/dynamodb.py</code> <pre><code>def __init__(\n    self,\n    table_name: str,\n    key_attr: str = \"id\",\n    sort_attr: str = \"sk\",\n    value_attr: str = \"value\",\n    endpoint_url: str | None = None,\n    config: Config | None = None,\n    boto_config: Config | None = None,\n    boto3_session: boto3.session.Session | None = None,\n    boto3_client: DynamoDBServiceResource | None = None,\n):\n    \"\"\"\n    Initialize the DynamoDB client\n    \"\"\"\n    if config:\n        warnings.warn(\n            message=\"The 'config' parameter is deprecated in V3 and will be removed in V4. \"\n            \"Please use 'boto_config' instead.\",\n            category=PowertoolsDeprecationWarning,\n            stacklevel=2,\n        )\n\n    if boto3_client is None:\n        boto3_session = boto3_session or boto3.session.Session()\n        boto3_client = boto3_session.resource(\"dynamodb\", config=boto_config or config, endpoint_url=endpoint_url)\n\n    self.table = boto3_client.Table(table_name)\n    self.key_attr = key_attr\n    self.sort_attr = sort_attr\n    self.value_attr = value_attr\n\n    super().__init__(resource=boto3_client)\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/secrets/",
            "title": "Secrets",
            "text": "<p>AWS Secrets Manager parameter retrieval and caching utility</p> CLASS DESCRIPTION <code>SecretsProvider</code> <p>AWS Secrets Manager Parameter Provider</p> FUNCTION DESCRIPTION <code>get_secret</code> <p>Retrieve a parameter value from AWS Secrets Manager</p> <code>set_secret</code> <p>Modify the details of a secret or create a new secret if it doesn't already exist.</p>"
        },
        {
            "location": "api_doc/parameters/secrets/#aws_lambda_powertools.utilities.parameters.secrets.SecretsProvider",
            "title": "SecretsProvider",
            "text": "<pre><code>SecretsProvider(\n    config: Config | None = None,\n    boto_config: Config | None = None,\n    boto3_session: Session | None = None,\n    boto3_client: SecretsManagerClient | None = None,\n)\n</code></pre> <p>               Bases: <code>BaseProvider</code></p> <p>AWS Secrets Manager Parameter Provider</p> PARAMETER DESCRIPTION <code>config</code> <p>Botocore configuration to pass during client initialization</p> <p> TYPE: <code>Config | None</code> DEFAULT: <code>None</code> </p> <code>boto3_session</code> <pre><code>Boto3 session to create a boto3_client from\n</code></pre> <p> TYPE: <code>Session</code> DEFAULT: <code>None</code> </p> <code>boto3_client</code> <pre><code>Boto3 SecretsManager Client to use, boto3_session will be ignored if both are provided\n</code></pre> <p> TYPE: <code>SecretsManagerClient | None</code> DEFAULT: <code>None</code> </p> Example <p>Retrieves a parameter value from Secrets Manager</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import SecretsProvider\n&gt;&gt;&gt; secrets_provider = SecretsProvider()\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = secrets_provider.get(\"my-parameter\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy parameter value\n</code></pre> <p>Retrieves a parameter value from Secrets Manager in another AWS region</p> <pre><code>&gt;&gt;&gt; from botocore.config import Config\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import SecretsProvider\n&gt;&gt;&gt;\n&gt;&gt;&gt; config = Config(region_name=\"us-west-1\")\n&gt;&gt;&gt; secrets_provider = SecretsProvider(config=config)\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = secrets_provider.get(\"my-parameter\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy parameter value\n</code></pre> <p>Retrieves a parameter value from Secrets Manager passing options to the SDK call</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import SecretsProvider\n&gt;&gt;&gt; secrets_provider = SecretsProvider()\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = secrets_provider.get(\"my-parameter\", VersionId=\"f658cac0-98a5-41d9-b993-8a76a7799194\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy parameter value\n</code></pre> METHOD DESCRIPTION <code>set</code> <p>Modify the details of a secret or create a new secret if it doesn't already exist.</p> Source code in <code>aws_lambda_powertools/utilities/parameters/secrets.py</code> <pre><code>def __init__(\n    self,\n    config: Config | None = None,\n    boto_config: Config | None = None,\n    boto3_session: boto3.session.Session | None = None,\n    boto3_client: SecretsManagerClient | None = None,\n):\n    \"\"\"\n    Initialize the Secrets Manager client\n    \"\"\"\n    if config:\n        warnings.warn(\n            message=\"The 'config' parameter is deprecated in V3 and will be removed in V4. \"\n            \"Please use 'boto_config' instead.\",\n            category=PowertoolsDeprecationWarning,\n            stacklevel=2,\n        )\n\n    if boto3_client is None:\n        boto3_session = boto3_session or boto3.session.Session()\n        boto3_client = boto3_session.client(\"secretsmanager\", config=boto_config or config)\n    self.client = boto3_client\n\n    super().__init__(client=self.client)\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/secrets/#aws_lambda_powertools.utilities.parameters.secrets.SecretsProvider.set",
            "title": "set",
            "text": "<pre><code>set(\n    name: str,\n    value: str | bytes | dict,\n    *,\n    client_request_token: str | None = None,\n    **sdk_options\n) -&gt; CreateSecretResponseTypeDef\n</code></pre> <p>Modify the details of a secret or create a new secret if it doesn't already exist.</p> <p>We aim to minimize API calls by assuming that the secret already exists and needs updating. If it doesn't exist, we attempt to create a new one. Refer to the following workflow for a better understanding:</p> <pre><code>              ┌────────────────────────┐      ┌─────────────────┐\n    ┌───────▶│Resource NotFound error?│────▶│Create Secret API│─────┐\n    │         └────────────────────────┘      └─────────────────┘     │\n    │                                                                 │\n    │                                                                 │\n    │                                                                 ▼\n</code></pre> <p>┌─────────────────┐                                              ┌─────────────────────┐ │Update Secret API│────────────────────────────────────────────▶│ Return or Exception │ └─────────────────┘                                              └─────────────────────┘</p> PARAMETER DESCRIPTION <code>name</code> <p>The ARN or name of the secret to add a new version to or create a new one.</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Specifies text data that you want to encrypt and store in this new version of the secret.</p> <p> TYPE: <code>str | bytes | dict</code> </p> <code>client_request_token</code> <p>This value helps ensure idempotency. It's recommended that you generate a UUID-type value to ensure uniqueness within the specified secret. This value becomes the VersionId of the new version. This field is auto-populated if not provided, but no idempotency will be enforced this way.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>sdk_options</code> <p>Dictionary of options that will be passed to the Secrets Manager update_secret API call</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>SetSecretError</code> <p>When attempting to update or create a secret fails.</p> Example <p>Sets a secret*</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n&gt;&gt;&gt;\n&gt;&gt;&gt; parameters.set_secret(name=\"llamas-are-awesome\", value=\"supers3cr3tllam@passw0rd\")\n</code></pre> <p>Sets a secret and includes an client_request_token</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n&gt;&gt;&gt; import uuid\n&gt;&gt;&gt;\n&gt;&gt;&gt; parameters.set_secret(\n        name=\"my-secret\",\n        value='{\"password\": \"supers3cr3tllam@passw0rd\"}',\n        client_request_token=str(uuid.uuid4())\n    )\n</code></pre> <pre><code>https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/secretsmanager/client/put_secret_value.html\nhttps://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/secretsmanager/client/create_secret.html\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/parameters/secrets.py</code> <pre><code>def set(\n    self,\n    name: str,\n    value: str | bytes | dict,\n    *,  # force keyword arguments\n    client_request_token: str | None = None,\n    **sdk_options,\n) -&gt; CreateSecretResponseTypeDef:\n    \"\"\"\n    Modify the details of a secret or create a new secret if it doesn't already exist.\n\n    We aim to minimize API calls by assuming that the secret already exists and needs updating.\n    If it doesn't exist, we attempt to create a new one. Refer to the following workflow for a better understanding:\n\n\n                      ┌────────────────────────┐      ┌─────────────────┐\n            ┌───────▶│Resource NotFound error?│────▶│Create Secret API│─────┐\n            │         └────────────────────────┘      └─────────────────┘     │\n            │                                                                 │\n            │                                                                 │\n            │                                                                 ▼\n    ┌─────────────────┐                                              ┌─────────────────────┐\n    │Update Secret API│────────────────────────────────────────────▶│ Return or Exception │\n    └─────────────────┘                                              └─────────────────────┘\n\n    Parameters\n    ----------\n    name: str\n        The ARN or name of the secret to add a new version to or create a new one.\n    value: str, dict or bytes\n        Specifies text data that you want to encrypt and store in this new version of the secret.\n    client_request_token: str, optional\n        This value helps ensure idempotency. It's recommended that you generate\n        a UUID-type value to ensure uniqueness within the specified secret.\n        This value becomes the VersionId of the new version. This field is\n        auto-populated if not provided, but no idempotency will be enforced this way.\n    sdk_options: dict, optional\n        Dictionary of options that will be passed to the Secrets Manager update_secret API call\n\n    Raises\n    ------\n    SetSecretError\n        When attempting to update or create a secret fails.\n\n    Returns:\n    -------\n    SetSecretResponse:\n        The dict returned by boto3.\n\n    Example\n    -------\n    **Sets a secret***\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; parameters.set_secret(name=\"llamas-are-awesome\", value=\"supers3cr3tllam@passw0rd\")\n\n    **Sets a secret and includes an client_request_token**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n        &gt;&gt;&gt; import uuid\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; parameters.set_secret(\n                name=\"my-secret\",\n                value='{\"password\": \"supers3cr3tllam@passw0rd\"}',\n                client_request_token=str(uuid.uuid4())\n            )\n\n    URLs:\n    -------\n        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/secretsmanager/client/put_secret_value.html\n        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/secretsmanager/client/create_secret.html\n    \"\"\"\n\n    if isinstance(value, dict):\n        value = json.dumps(value, cls=Encoder)\n\n    if isinstance(value, bytes):\n        sdk_options[\"SecretBinary\"] = value\n    else:\n        sdk_options[\"SecretString\"] = value\n\n    if client_request_token:\n        sdk_options[\"ClientRequestToken\"] = client_request_token\n\n    try:\n        logger.debug(f\"Attempting to update secret {name}\")\n        return self._update_secret(name=name, **sdk_options)\n    except self.client.exceptions.ResourceNotFoundException:\n        logger.debug(f\"Secret {name} doesn't exist, creating a new one\")\n        return self._create_secret(name=name, **sdk_options)\n    except Exception as exc:\n        raise SetSecretError(f\"Error setting secret - {str(exc)}\") from exc\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/secrets/#aws_lambda_powertools.utilities.parameters.secrets.get_secret",
            "title": "get_secret",
            "text": "<pre><code>get_secret(\n    name: str,\n    transform: None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options\n) -&gt; str\n</code></pre><pre><code>get_secret(\n    name: str,\n    transform: Literal[\"json\"],\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options\n) -&gt; dict\n</code></pre><pre><code>get_secret(\n    name: str,\n    transform: Literal[\"binary\"],\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options\n) -&gt; str | bytes | dict\n</code></pre><pre><code>get_secret(\n    name: str,\n    transform: Literal[\"auto\"],\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options\n) -&gt; bytes\n</code></pre> <pre><code>get_secret(\n    name: str,\n    transform: TransformOptions = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options\n) -&gt; str | bytes | dict\n</code></pre> <p>Retrieve a parameter value from AWS Secrets Manager</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of the parameter</p> <p> TYPE: <code>str</code> </p> <code>transform</code> <p>Transforms the content from a JSON object ('json') or base64 binary string ('binary')</p> <p> TYPE: <code>TransformOptions</code> DEFAULT: <code>None</code> </p> <code>force_fetch</code> <p>Force update even before a cached item has expired, defaults to False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_age</code> <p>Maximum age of the cached value</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>sdk_options</code> <p>Dictionary of options that will be passed to the get_secret_value call</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>GetParameterError</code> <p>When the parameter provider fails to retrieve a parameter value for a given name.</p> <code>TransformParameterError</code> <p>When the parameter provider fails to transform a parameter value.</p> Example <p>Retrieves a secret*</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_secret\n&gt;&gt;&gt;\n&gt;&gt;&gt; get_secret(\"my-secret\")\n</code></pre> <p>Retrieves a secret and transforms using a JSON deserializer*</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_secret\n&gt;&gt;&gt;\n&gt;&gt;&gt; get_secret(\"my-secret\", transform=\"json\")\n</code></pre> <p>Retrieves a secret and passes custom arguments to the SDK</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_secret\n&gt;&gt;&gt;\n&gt;&gt;&gt; get_secret(\"my-secret\", VersionId=\"f658cac0-98a5-41d9-b993-8a76a7799194\")\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/parameters/secrets.py</code> <pre><code>def get_secret(\n    name: str,\n    transform: TransformOptions = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options,\n) -&gt; str | bytes | dict:\n    \"\"\"\n    Retrieve a parameter value from AWS Secrets Manager\n\n    Parameters\n    ----------\n    name: str\n        Name of the parameter\n    transform: str, optional\n        Transforms the content from a JSON object ('json') or base64 binary string ('binary')\n    force_fetch: bool, optional\n        Force update even before a cached item has expired, defaults to False\n    max_age: int, optional\n        Maximum age of the cached value\n    sdk_options: dict, optional\n        Dictionary of options that will be passed to the get_secret_value call\n\n    Raises\n    ------\n    GetParameterError\n        When the parameter provider fails to retrieve a parameter value for\n        a given name.\n    TransformParameterError\n        When the parameter provider fails to transform a parameter value.\n\n    Example\n    -------\n    **Retrieves a secret***\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_secret\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; get_secret(\"my-secret\")\n\n    **Retrieves a secret and transforms using a JSON deserializer***\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_secret\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; get_secret(\"my-secret\", transform=\"json\")\n\n    **Retrieves a secret and passes custom arguments to the SDK**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_secret\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; get_secret(\"my-secret\", VersionId=\"f658cac0-98a5-41d9-b993-8a76a7799194\")\n    \"\"\"\n\n    # If max_age is not set, resolve it from the environment variable, defaulting to DEFAULT_MAX_AGE_SECS\n    max_age = resolve_max_age(env=os.getenv(constants.PARAMETERS_MAX_AGE_ENV, DEFAULT_MAX_AGE_SECS), choice=max_age)\n\n    # Only create the provider if this function is called at least once\n    if \"secrets\" not in DEFAULT_PROVIDERS:\n        DEFAULT_PROVIDERS[\"secrets\"] = SecretsProvider()\n\n    return DEFAULT_PROVIDERS[\"secrets\"].get(\n        name,\n        max_age=max_age,\n        transform=transform,\n        force_fetch=force_fetch,\n        **sdk_options,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/secrets/#aws_lambda_powertools.utilities.parameters.secrets.set_secret",
            "title": "set_secret",
            "text": "<pre><code>set_secret(\n    name: str,\n    value: str | bytes,\n    *,\n    client_request_token: str | None = None,\n    **sdk_options\n) -&gt; CreateSecretResponseTypeDef\n</code></pre> <p>Modify the details of a secret or create a new secret if it doesn't already exist.</p> <p>We aim to minimize API calls by assuming that the secret already exists and needs updating. If it doesn't exist, we attempt to create a new one. Refer to the following workflow for a better understanding:</p> <pre><code>              ┌────────────────────────┐      ┌─────────────────┐\n    ┌───────▶│Resource NotFound error?│────▶│Create Secret API│─────┐\n    │         └────────────────────────┘      └─────────────────┘     │\n    │                                                                 │\n    │                                                                 │\n    │                                                                 ▼\n</code></pre> <p>┌─────────────────┐                                              ┌─────────────────────┐ │Update Secret API│────────────────────────────────────────────▶│ Return or Exception │ └─────────────────┘                                              └─────────────────────┘</p> PARAMETER DESCRIPTION <code>name</code> <p>The ARN or name of the secret to add a new version to or create a new one.</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Specifies text data that you want to encrypt and store in this new version of the secret.</p> <p> TYPE: <code>str | bytes</code> </p> <code>client_request_token</code> <p>This value helps ensure idempotency. It's recommended that you generate a UUID-type value to ensure uniqueness within the specified secret. This value becomes the VersionId of the new version. This field is auto-populated if not provided, but no idempotency will be enforced this way.</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>sdk_options</code> <p>Dictionary of options that will be passed to the Secrets Manager update_secret API call</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>SetSecretError</code> <p>When attempting to update or create a secret fails.</p> Example <p>Sets a secret*</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n&gt;&gt;&gt;\n&gt;&gt;&gt; parameters.set_secret(name=\"llamas-are-awesome\", value=\"supers3cr3tllam@passw0rd\")\n</code></pre> <p>Sets a secret and includes an client_request_token</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n&gt;&gt;&gt;\n&gt;&gt;&gt; parameters.set_secret(\n        name=\"my-secret\",\n        value='{\"password\": \"supers3cr3tllam@passw0rd\"}',\n        client_request_token=\"YOUR_TOKEN_HERE\"\n    )\n</code></pre> <pre><code>https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/secretsmanager/client/put_secret_value.html\nhttps://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/secretsmanager/client/create_secret.html\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/parameters/secrets.py</code> <pre><code>def set_secret(\n    name: str,\n    value: str | bytes,\n    *,  # force keyword arguments\n    client_request_token: str | None = None,\n    **sdk_options,\n) -&gt; CreateSecretResponseTypeDef:\n    \"\"\"\n    Modify the details of a secret or create a new secret if it doesn't already exist.\n\n    We aim to minimize API calls by assuming that the secret already exists and needs updating.\n    If it doesn't exist, we attempt to create a new one. Refer to the following workflow for a better understanding:\n\n\n                      ┌────────────────────────┐      ┌─────────────────┐\n            ┌───────▶│Resource NotFound error?│────▶│Create Secret API│─────┐\n            │         └────────────────────────┘      └─────────────────┘     │\n            │                                                                 │\n            │                                                                 │\n            │                                                                 ▼\n    ┌─────────────────┐                                              ┌─────────────────────┐\n    │Update Secret API│────────────────────────────────────────────▶│ Return or Exception │\n    └─────────────────┘                                              └─────────────────────┘\n\n    Parameters\n    ----------\n    name: str\n        The ARN or name of the secret to add a new version to or create a new one.\n    value: str, dict or bytes\n        Specifies text data that you want to encrypt and store in this new version of the secret.\n    client_request_token: str, optional\n        This value helps ensure idempotency. It's recommended that you generate\n        a UUID-type value to ensure uniqueness within the specified secret.\n        This value becomes the VersionId of the new version. This field is\n        auto-populated if not provided, but no idempotency will be enforced this way.\n    sdk_options: dict, optional\n        Dictionary of options that will be passed to the Secrets Manager update_secret API call\n\n    Raises\n    ------\n    SetSecretError\n        When attempting to update or create a secret fails.\n\n    Returns:\n    -------\n    SetSecretResponse:\n        The dict returned by boto3.\n\n    Example\n    -------\n    **Sets a secret***\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; parameters.set_secret(name=\"llamas-are-awesome\", value=\"supers3cr3tllam@passw0rd\")\n\n    **Sets a secret and includes an client_request_token**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; parameters.set_secret(\n                name=\"my-secret\",\n                value='{\"password\": \"supers3cr3tllam@passw0rd\"}',\n                client_request_token=\"YOUR_TOKEN_HERE\"\n            )\n\n    URLs:\n    -------\n        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/secretsmanager/client/put_secret_value.html\n        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/secretsmanager/client/create_secret.html\n    \"\"\"\n\n    # Only create the provider if this function is called at least once\n    if \"secrets\" not in DEFAULT_PROVIDERS:\n        DEFAULT_PROVIDERS[\"secrets\"] = SecretsProvider()\n\n    return DEFAULT_PROVIDERS[\"secrets\"].set(\n        name=name,\n        value=value,\n        client_request_token=client_request_token,\n        **sdk_options,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/ssm/",
            "title": "SSM",
            "text": "<p>AWS SSM Parameter retrieval and caching utility</p> CLASS DESCRIPTION <code>SSMProvider</code> <p>AWS Systems Manager Parameter Store Provider</p> FUNCTION DESCRIPTION <code>get_parameter</code> <p>Retrieve a parameter value from AWS Systems Manager (SSM) Parameter Store</p> <code>get_parameters</code> <p>Retrieve multiple parameter values from AWS Systems Manager (SSM) Parameter Store</p> <code>get_parameters_by_name</code> <p>Retrieve multiple parameter values by name from AWS Systems Manager (SSM) Parameter Store</p> <code>set_parameter</code> <p>Sets a parameter in AWS Systems Manager Parameter Store.</p>"
        },
        {
            "location": "api_doc/parameters/ssm/#aws_lambda_powertools.utilities.parameters.ssm.SSMProvider",
            "title": "SSMProvider",
            "text": "<pre><code>SSMProvider(\n    config: Config | None = None,\n    boto_config: Config | None = None,\n    boto3_session: Session | None = None,\n    boto3_client: SSMClient | None = None,\n)\n</code></pre> <p>               Bases: <code>BaseProvider</code></p> <p>AWS Systems Manager Parameter Store Provider</p> PARAMETER DESCRIPTION <code>config</code> <p>Botocore configuration to pass during client initialization</p> <p> TYPE: <code>Config | None</code> DEFAULT: <code>None</code> </p> <code>boto3_session</code> <pre><code>Boto3 session to create a boto3_client from\n</code></pre> <p> TYPE: <code>Session</code> DEFAULT: <code>None</code> </p> <code>boto3_client</code> <pre><code>Boto3 SSM Client to use, boto3_session will be ignored if both are provided\n</code></pre> <p> TYPE: <code>SSMClient | None</code> DEFAULT: <code>None</code> </p> Example <p>Retrieves a parameter value from Systems Manager Parameter Store</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import SSMProvider\n&gt;&gt;&gt; ssm_provider = SSMProvider()\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = ssm_provider.get(\"/my/parameter\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy parameter value\n</code></pre> <p>Retrieves a parameter value from Systems Manager Parameter Store in another AWS region</p> <pre><code>&gt;&gt;&gt; from botocore.config import Config\n&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import SSMProvider\n&gt;&gt;&gt;\n&gt;&gt;&gt; config = Config(region_name=\"us-west-1\")\n&gt;&gt;&gt; ssm_provider = SSMProvider(config=config)\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = ssm_provider.get(\"/my/parameter\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy parameter value\n</code></pre> <p>Retrieves multiple parameter values from Systems Manager Parameter Store using a path prefix</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import SSMProvider\n&gt;&gt;&gt; ssm_provider = SSMProvider()\n&gt;&gt;&gt;\n&gt;&gt;&gt; values = ssm_provider.get_multiple(\"/my/path/prefix\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; for key, value in values.items():\n...     print(key, value)\n/my/path/prefix/a   Parameter value a\n/my/path/prefix/b   Parameter value b\n/my/path/prefix/c   Parameter value c\n</code></pre> <p>Retrieves multiple parameter values from Systems Manager Parameter Store passing options to the SDK call</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import SSMProvider\n&gt;&gt;&gt; ssm_provider = SSMProvider()\n&gt;&gt;&gt;\n&gt;&gt;&gt; values = ssm_provider.get_multiple(\"/my/path/prefix\", MaxResults=10)\n&gt;&gt;&gt;\n&gt;&gt;&gt; for key, value in values.items():\n...     print(key, value)\n/my/path/prefix/a   Parameter value a\n/my/path/prefix/b   Parameter value b\n/my/path/prefix/c   Parameter value c\n</code></pre> METHOD DESCRIPTION <code>get</code> <p>Retrieve a parameter value or return the cached value</p> <code>get_multiple</code> <p>Retrieve multiple parameters based on a path prefix</p> <code>get_parameters_by_name</code> <p>Retrieve multiple parameter values by name from SSM or cache.</p> <code>set</code> <p>Sets a parameter in AWS Systems Manager Parameter Store.</p> Source code in <code>aws_lambda_powertools/utilities/parameters/ssm.py</code> <pre><code>def __init__(\n    self,\n    config: Config | None = None,\n    boto_config: Config | None = None,\n    boto3_session: boto3.session.Session | None = None,\n    boto3_client: SSMClient | None = None,\n):\n    \"\"\"\n    Initialize the SSM Parameter Store client\n    \"\"\"\n    if config:\n        warnings.warn(\n            message=\"The 'config' parameter is deprecated in V3 and will be removed in V4. \"\n            \"Please use 'boto_config' instead.\",\n            category=PowertoolsDeprecationWarning,\n            stacklevel=2,\n        )\n\n    if boto3_client is None:\n        boto3_session = boto3_session or boto3.session.Session()\n        boto3_client = boto3_session.client(\"ssm\", config=boto_config or config)\n    self.client = boto3_client\n\n    super().__init__(client=self.client)\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/ssm/#aws_lambda_powertools.utilities.parameters.ssm.SSMProvider.get",
            "title": "get",
            "text": "<pre><code>get(\n    name: str,\n    max_age: int | None = None,\n    transform: TransformOptions = None,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    **sdk_options\n) -&gt; str | bytes | dict | None\n</code></pre> <p>Retrieve a parameter value or return the cached value</p> PARAMETER DESCRIPTION <code>name</code> <p>Parameter name</p> <p> TYPE: <code>str</code> </p> <code>max_age</code> <p>Maximum age of the cached value</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>transform</code> <p>Optional transformation of the parameter value. Supported values are \"json\" for JSON strings and \"binary\" for base 64 encoded values.</p> <p> TYPE: <code>TransformOptions</code> DEFAULT: <code>None</code> </p> <code>decrypt</code> <p>If the parameter value should be decrypted</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>force_fetch</code> <p>Force update even before a cached item has expired, defaults to False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>sdk_options</code> <p>Arguments that will be passed directly to the underlying API call</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>GetParameterError</code> <p>When the parameter provider fails to retrieve a parameter value for a given name.</p> <code>TransformParameterError</code> <p>When the parameter provider fails to transform a parameter value.</p> Source code in <code>aws_lambda_powertools/utilities/parameters/ssm.py</code> <pre><code>def get(  # type: ignore[override]\n    self,\n    name: str,\n    max_age: int | None = None,\n    transform: TransformOptions = None,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    **sdk_options,\n) -&gt; str | bytes | dict | None:\n    \"\"\"\n    Retrieve a parameter value or return the cached value\n\n    Parameters\n    ----------\n    name: str\n        Parameter name\n    max_age: int, optional\n        Maximum age of the cached value\n    transform: str\n        Optional transformation of the parameter value. Supported values\n        are \"json\" for JSON strings and \"binary\" for base 64 encoded\n        values.\n    decrypt: bool, optional\n        If the parameter value should be decrypted\n    force_fetch: bool, optional\n        Force update even before a cached item has expired, defaults to False\n    sdk_options: dict, optional\n        Arguments that will be passed directly to the underlying API call\n\n    Raises\n    ------\n    GetParameterError\n        When the parameter provider fails to retrieve a parameter value for\n        a given name.\n    TransformParameterError\n        When the parameter provider fails to transform a parameter value.\n    \"\"\"\n\n    # If max_age is not set, resolve it from the environment variable, defaulting to DEFAULT_MAX_AGE_SECS\n    max_age = resolve_max_age(env=os.getenv(constants.PARAMETERS_MAX_AGE_ENV, DEFAULT_MAX_AGE_SECS), choice=max_age)\n\n    # If decrypt is not set, resolve it from the environment variable, defaulting to False\n    decrypt = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.PARAMETERS_SSM_DECRYPT_ENV, \"false\"),\n        choice=decrypt,\n    )\n\n    # Add to `decrypt` sdk_options to we can have an explicit option for this\n    sdk_options[\"decrypt\"] = decrypt\n\n    return super().get(name, max_age, transform, force_fetch, **sdk_options)\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/ssm/#aws_lambda_powertools.utilities.parameters.ssm.SSMProvider.get_multiple",
            "title": "get_multiple",
            "text": "<pre><code>get_multiple(\n    path: str,\n    max_age: int | None = None,\n    transform: TransformOptions = None,\n    raise_on_transform_error: bool = False,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    recursive: bool = False,\n    **sdk_options\n) -&gt; dict[str, str] | dict[str, bytes] | dict[str, dict]\n</code></pre> <p>Retrieve multiple parameters based on a path prefix</p> PARAMETER DESCRIPTION <code>path</code> <p>Parameter path used to retrieve multiple parameters</p> <p> TYPE: <code>str</code> </p> <code>max_age</code> <p>Maximum age of the cached value</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>transform</code> <p>Optional transformation of the parameter value. Supported values are \"json\" for JSON strings, \"binary\" for base 64 encoded values or \"auto\" which looks at the attribute key to determine the type.</p> <p> TYPE: <code>TransformOptions</code> DEFAULT: <code>None</code> </p> <code>raise_on_transform_error</code> <p>Raises an exception if any transform fails, otherwise this will return a None value for each transform that failed</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>force_fetch</code> <p>Force update even before a cached item has expired, defaults to False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>recursive</code> <p>If this should retrieve the parameter values recursively or not</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>sdk_options</code> <p>Arguments that will be passed directly to the underlying API call</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>GetParameterError</code> <p>When the parameter provider fails to retrieve parameter values for a given path.</p> <code>TransformParameterError</code> <p>When the parameter provider fails to transform a parameter value.</p> Source code in <code>aws_lambda_powertools/utilities/parameters/ssm.py</code> <pre><code>def get_multiple(  # type: ignore[override]\n    self,\n    path: str,\n    max_age: int | None = None,\n    transform: TransformOptions = None,\n    raise_on_transform_error: bool = False,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    recursive: bool = False,\n    **sdk_options,\n) -&gt; dict[str, str] | dict[str, bytes] | dict[str, dict]:\n    \"\"\"\n    Retrieve multiple parameters based on a path prefix\n\n    Parameters\n    ----------\n    path: str\n        Parameter path used to retrieve multiple parameters\n    max_age: int, optional\n        Maximum age of the cached value\n    transform: str, optional\n        Optional transformation of the parameter value. Supported values\n        are \"json\" for JSON strings, \"binary\" for base 64 encoded\n        values or \"auto\" which looks at the attribute key to determine the type.\n    raise_on_transform_error: bool, optional\n        Raises an exception if any transform fails, otherwise this will\n        return a None value for each transform that failed\n    force_fetch: bool, optional\n        Force update even before a cached item has expired, defaults to False\n    recursive: bool, optional\n        If this should retrieve the parameter values recursively or not\n    sdk_options: dict, optional\n        Arguments that will be passed directly to the underlying API call\n\n    Raises\n    ------\n    GetParameterError\n        When the parameter provider fails to retrieve parameter values for\n        a given path.\n    TransformParameterError\n        When the parameter provider fails to transform a parameter value.\n    \"\"\"\n\n    # If max_age is not set, resolve it from the environment variable, defaulting to DEFAULT_MAX_AGE_SECS\n    max_age = resolve_max_age(env=os.getenv(constants.PARAMETERS_MAX_AGE_ENV, DEFAULT_MAX_AGE_SECS), choice=max_age)\n\n    # If decrypt is not set, resolve it from the environment variable, defaulting to False\n    decrypt = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.PARAMETERS_SSM_DECRYPT_ENV, \"false\"),\n        choice=decrypt,\n    )\n\n    sdk_options[\"decrypt\"] = decrypt\n    sdk_options[\"recursive\"] = recursive\n\n    return super().get_multiple(path, max_age, transform, raise_on_transform_error, force_fetch, **sdk_options)\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/ssm/#aws_lambda_powertools.utilities.parameters.ssm.SSMProvider.get_parameters_by_name",
            "title": "get_parameters_by_name",
            "text": "<pre><code>get_parameters_by_name(\n    parameters: dict[str, dict],\n    transform: TransformOptions = None,\n    decrypt: bool | None = None,\n    max_age: int | None = None,\n    raise_on_error: bool = True,\n) -&gt; dict[str, str] | dict[str, bytes] | dict[str, dict]\n</code></pre> <p>Retrieve multiple parameter values by name from SSM or cache.</p> <p>Raise_on_error decides on error handling strategy:</p> <ul> <li>A) Default to fail-fast. Raises GetParameterError upon any error</li> <li>B) Gracefully aggregate all parameters that failed under \"_errors\" key</li> </ul> <p>It transparently uses GetParameter and/or GetParameters depending on decryption requirements.</p> <pre><code>                        ┌────────────────────────┐\n                    ┌───▶  Decrypt entire batch  │─────┐\n                    │   └────────────────────────┘     │     ┌────────────────────┐\n                    │                                  ├─────▶ GetParameters API  │\n</code></pre> <p>┌──────────────────┐    │   ┌────────────────────────┐     │     └────────────────────┘ │   Split batch    │─── ┼──▶│ No decryption required │─────┘ └──────────────────┘    │   └────────────────────────┘                         │                                        ┌────────────────────┐                         │   ┌────────────────────────┐           │  GetParameter API  │                         └──▶│Decrypt some but not all│───────────▶────────────────────┤                             └────────────────────────┘           │ GetParameters API  │                                                                  └────────────────────┘</p> PARAMETER DESCRIPTION <code>parameters</code> <p>List of parameter names, and any optional overrides</p> <p> TYPE: <code>dict[str, dict]</code> </p> <code>transform</code> <p>Transforms the content from a JSON object ('json') or base64 binary string ('binary')</p> <p> TYPE: <code>TransformOptions</code> DEFAULT: <code>None</code> </p> <code>decrypt</code> <p>If the parameter values should be decrypted</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>max_age</code> <p>Maximum age of the cached value</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>raise_on_error</code> <p>Whether to fail-fast or fail gracefully by including \"_errors\" key in the response, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> RAISES DESCRIPTION <code>GetParameterError</code> <p>When the parameter provider fails to retrieve a parameter value for a given name.</p> <p>When \"_errors\" reserved key is in parameters to be fetched from SSM.</p> Source code in <code>aws_lambda_powertools/utilities/parameters/ssm.py</code> <pre><code>def get_parameters_by_name(\n    self,\n    parameters: dict[str, dict],\n    transform: TransformOptions = None,\n    decrypt: bool | None = None,\n    max_age: int | None = None,\n    raise_on_error: bool = True,\n) -&gt; dict[str, str] | dict[str, bytes] | dict[str, dict]:\n    \"\"\"\n    Retrieve multiple parameter values by name from SSM or cache.\n\n    Raise_on_error decides on error handling strategy:\n\n    - A) Default to fail-fast. Raises GetParameterError upon any error\n    - B) Gracefully aggregate all parameters that failed under \"_errors\" key\n\n    It transparently uses GetParameter and/or GetParameters depending on decryption requirements.\n\n                                ┌────────────────────────┐\n                            ┌───▶  Decrypt entire batch  │─────┐\n                            │   └────────────────────────┘     │     ┌────────────────────┐\n                            │                                  ├─────▶ GetParameters API  │\n    ┌──────────────────┐    │   ┌────────────────────────┐     │     └────────────────────┘\n    │   Split batch    │─── ┼──▶│ No decryption required │─────┘\n    └──────────────────┘    │   └────────────────────────┘\n                            │                                        ┌────────────────────┐\n                            │   ┌────────────────────────┐           │  GetParameter API  │\n                            └──▶│Decrypt some but not all│───────────▶────────────────────┤\n                                └────────────────────────┘           │ GetParameters API  │\n                                                                     └────────────────────┘\n\n    Parameters\n    ----------\n    parameters: dict[str, dict]\n        List of parameter names, and any optional overrides\n    transform: str, optional\n        Transforms the content from a JSON object ('json') or base64 binary string ('binary')\n    decrypt: bool, optional\n        If the parameter values should be decrypted\n    max_age: int, optional\n        Maximum age of the cached value\n    raise_on_error: bool\n        Whether to fail-fast or fail gracefully by including \"_errors\" key in the response, by default True\n\n    Raises\n    ------\n    GetParameterError\n        When the parameter provider fails to retrieve a parameter value for a given name.\n\n        When \"_errors\" reserved key is in parameters to be fetched from SSM.\n    \"\"\"\n\n    # If max_age is not set, resolve it from the environment variable, defaulting to DEFAULT_MAX_AGE_SECS\n    max_age = resolve_max_age(env=os.getenv(constants.PARAMETERS_MAX_AGE_ENV, DEFAULT_MAX_AGE_SECS), choice=max_age)\n\n    # If decrypt is not set, resolve it from the environment variable, defaulting to False\n    decrypt = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.PARAMETERS_SSM_DECRYPT_ENV, \"false\"),\n        choice=decrypt,\n    )\n\n    # Init potential batch/decrypt batch responses and errors\n    batch_ret: dict[str, Any] = {}\n    decrypt_ret: dict[str, Any] = {}\n    batch_err: list[str] = []\n    decrypt_err: list[str] = []\n    response: dict[str, Any] = {}\n\n    # NOTE: We fail early to avoid unintended graceful errors being replaced with their '_errors' param values\n    self._raise_if_errors_key_is_present(parameters, self._ERRORS_KEY, raise_on_error)\n\n    batch_params, decrypt_params = self._split_batch_and_decrypt_parameters(parameters, transform, max_age, decrypt)\n\n    # NOTE: We need to find out whether all parameters must be decrypted or not to know which API to use\n    ## Logic:\n    ##\n    ## GetParameters API -&gt; When decrypt is used for all parameters in the the batch\n    ## GetParameter  API -&gt; When decrypt is used for one or more in the batch\n\n    if len(decrypt_params) != len(parameters):\n        decrypt_ret, decrypt_err = self._get_parameters_by_name_with_decrypt_option(decrypt_params, raise_on_error)\n        batch_ret, batch_err = self._get_parameters_batch_by_name(batch_params, raise_on_error, decrypt=False)\n    else:\n        batch_ret, batch_err = self._get_parameters_batch_by_name(decrypt_params, raise_on_error, decrypt=True)\n\n    # Fail-fast disabled, let's aggregate errors under \"_errors\" key so they can handle gracefully\n    if not raise_on_error:\n        response[self._ERRORS_KEY] = [*decrypt_err, *batch_err]\n\n    return {**response, **batch_ret, **decrypt_ret}\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/ssm/#aws_lambda_powertools.utilities.parameters.ssm.SSMProvider.set",
            "title": "set",
            "text": "<pre><code>set(\n    name: str,\n    value: list[str],\n    *,\n    overwrite: bool = False,\n    description: str = \"\",\n    parameter_type: Literal[\"StringList\"] = \"StringList\",\n    tier: Literal[\n        \"Standard\", \"Advanced\", \"Intelligent-Tiering\"\n    ] = \"Standard\",\n    kms_key_id: str | None = \"None\",\n    **sdk_options\n)\n</code></pre><pre><code>set(\n    name: str,\n    value: str,\n    *,\n    overwrite: bool = False,\n    description: str = \"\",\n    parameter_type: Literal[\n        \"SecureString\"\n    ] = \"SecureString\",\n    tier: Literal[\n        \"Standard\", \"Advanced\", \"Intelligent-Tiering\"\n    ] = \"Standard\",\n    kms_key_id: str,\n    **sdk_options\n)\n</code></pre><pre><code>set(\n    name: str,\n    value: str,\n    *,\n    overwrite: bool = False,\n    description: str = \"\",\n    parameter_type: Literal[\"String\"] = \"String\",\n    tier: Literal[\n        \"Standard\", \"Advanced\", \"Intelligent-Tiering\"\n    ] = \"Standard\",\n    kms_key_id: str | None = None,\n    **sdk_options\n)\n</code></pre> <pre><code>set(\n    name: str,\n    value: str | list[str],\n    *,\n    overwrite: bool = False,\n    description: str = \"\",\n    parameter_type: SSM_PARAMETER_TYPES = \"String\",\n    tier: SSM_PARAMETER_TIER = \"Standard\",\n    kms_key_id: str | None = None,\n    **sdk_options\n) -&gt; PutParameterResultTypeDef\n</code></pre> <p>Sets a parameter in AWS Systems Manager Parameter Store.</p> PARAMETER DESCRIPTION <code>name</code> <p>The fully qualified name includes the complete hierarchy of the parameter name and name.</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>The parameter value</p> <p> TYPE: <code>str | list[str]</code> </p> <code>overwrite</code> <p>If the parameter value should be overwritten, False by default</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>description</code> <p>The description of the parameter</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>parameter_type</code> <p>Type of the parameter.  Allowed values are String, StringList, and SecureString</p> <p> TYPE: <code>SSM_PARAMETER_TYPES</code> DEFAULT: <code>'String'</code> </p> <code>tier</code> <p>The parameter tier to use. Allowed values are Standard, Advanced, and Intelligent-Tiering</p> <p> TYPE: <code>SSM_PARAMETER_TIER</code> DEFAULT: <code>'Standard'</code> </p> <code>kms_key_id</code> <p>The KMS key id to use to encrypt the parameter</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>sdk_options</code> <p>Dictionary of options that will be passed to the Parameter Store get_parameter API call</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>SetParameterError</code> <p>When the parameter provider fails to retrieve a parameter value for a given name.</p> <pre><code>https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ssm/client/put_parameter.html\n</code></pre> Example <p>Sets a parameter value from Systems Manager Parameter Store</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n&gt;&gt;&gt;\n&gt;&gt;&gt; response = parameters.set_parameter(name=\"/my/example/parameter\", value=\"More Powertools\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(response)\n123\n</code></pre> RETURNS DESCRIPTION <code>PutParameterResultTypeDef</code> <p>The dict returned by boto3.</p> Source code in <code>aws_lambda_powertools/utilities/parameters/ssm.py</code> <pre><code>def set(\n    self,\n    name: str,\n    value: str | list[str],\n    *,\n    overwrite: bool = False,\n    description: str = \"\",\n    parameter_type: SSM_PARAMETER_TYPES = \"String\",\n    tier: SSM_PARAMETER_TIER = \"Standard\",\n    kms_key_id: str | None = None,\n    **sdk_options,\n) -&gt; PutParameterResultTypeDef:\n    \"\"\"\n    Sets a parameter in AWS Systems Manager Parameter Store.\n\n    Parameters\n    ----------\n    name: str\n        The fully qualified name includes the complete hierarchy of the parameter name and name.\n    value: str\n        The parameter value\n    overwrite: bool, optional\n        If the parameter value should be overwritten, False by default\n    description: str, optional\n        The description of the parameter\n    parameter_type: str, optional\n        Type of the parameter.  Allowed values are String, StringList, and SecureString\n    tier: str, optional\n        The parameter tier to use. Allowed values are Standard, Advanced, and Intelligent-Tiering\n    kms_key_id: str, optional\n        The KMS key id to use to encrypt the parameter\n    sdk_options: dict, optional\n        Dictionary of options that will be passed to the Parameter Store get_parameter API call\n\n    Raises\n    ------\n    SetParameterError\n        When the parameter provider fails to retrieve a parameter value for\n        a given name.\n\n    URLs:\n    -------\n        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ssm/client/put_parameter.html\n\n    Example\n    -------\n    **Sets a parameter value from Systems Manager Parameter Store**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; response = parameters.set_parameter(name=\"/my/example/parameter\", value=\"More Powertools\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; print(response)\n        123\n\n    Returns\n    -------\n    PutParameterResultTypeDef\n        The dict returned by boto3.\n    \"\"\"\n    opts = {\n        \"Name\": name,\n        \"Value\": value,\n        \"Overwrite\": overwrite,\n        \"Type\": parameter_type,\n        \"Tier\": tier,\n        \"Description\": description,\n        **sdk_options,\n    }\n\n    if kms_key_id:\n        opts[\"KeyId\"] = kms_key_id\n\n    try:\n        return self.client.put_parameter(**opts)\n    except Exception as exc:\n        raise SetParameterError(f\"Error setting parameter - {str(exc)}\") from exc\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/ssm/#aws_lambda_powertools.utilities.parameters.ssm.get_parameter",
            "title": "get_parameter",
            "text": "<pre><code>get_parameter(\n    name: str,\n    transform: None = None,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options\n) -&gt; str\n</code></pre><pre><code>get_parameter(\n    name: str,\n    transform: Literal[\"json\"],\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options\n) -&gt; dict\n</code></pre><pre><code>get_parameter(\n    name: str,\n    transform: Literal[\"binary\"],\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options\n) -&gt; str | bytes | dict\n</code></pre><pre><code>get_parameter(\n    name: str,\n    transform: Literal[\"auto\"],\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options\n) -&gt; bytes\n</code></pre> <pre><code>get_parameter(\n    name: str,\n    transform: TransformOptions = None,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options\n) -&gt; str | bytes | dict\n</code></pre> <p>Retrieve a parameter value from AWS Systems Manager (SSM) Parameter Store</p> PARAMETER DESCRIPTION <code>name</code> <p>Name of the parameter</p> <p> TYPE: <code>str</code> </p> <code>transform</code> <p>Transforms the content from a JSON object ('json') or base64 binary string ('binary')</p> <p> TYPE: <code>TransformOptions</code> DEFAULT: <code>None</code> </p> <code>decrypt</code> <p>If the parameter values should be decrypted</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>force_fetch</code> <p>Force update even before a cached item has expired, defaults to False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_age</code> <p>Maximum age of the cached value</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>sdk_options</code> <p>Dictionary of options that will be passed to the Parameter Store get_parameter API call</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>GetParameterError</code> <p>When the parameter provider fails to retrieve a parameter value for a given name.</p> <code>TransformParameterError</code> <p>When the parameter provider fails to transform a parameter value.</p> Example <p>Retrieves a parameter value from Systems Manager Parameter Store</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_parameter\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = get_parameter(\"/my/parameter\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy parameter value\n</code></pre> <p>Retrieves a parameter value and decodes it using a Base64 decoder</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_parameter\n&gt;&gt;&gt;\n&gt;&gt;&gt; value = get_parameter(\"/my/parameter\", transform='binary')\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(value)\nMy parameter value\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/parameters/ssm.py</code> <pre><code>def get_parameter(\n    name: str,\n    transform: TransformOptions = None,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    **sdk_options,\n) -&gt; str | bytes | dict:\n    \"\"\"\n    Retrieve a parameter value from AWS Systems Manager (SSM) Parameter Store\n\n    Parameters\n    ----------\n    name: str\n        Name of the parameter\n    transform: str, optional\n        Transforms the content from a JSON object ('json') or base64 binary string ('binary')\n    decrypt: bool, optional\n        If the parameter values should be decrypted\n    force_fetch: bool, optional\n        Force update even before a cached item has expired, defaults to False\n    max_age: int, optional\n        Maximum age of the cached value\n    sdk_options: dict, optional\n        Dictionary of options that will be passed to the Parameter Store get_parameter API call\n\n    Raises\n    ------\n    GetParameterError\n        When the parameter provider fails to retrieve a parameter value for\n        a given name.\n    TransformParameterError\n        When the parameter provider fails to transform a parameter value.\n\n    Example\n    -------\n    **Retrieves a parameter value from Systems Manager Parameter Store**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_parameter\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; value = get_parameter(\"/my/parameter\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; print(value)\n        My parameter value\n\n    **Retrieves a parameter value and decodes it using a Base64 decoder**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_parameter\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; value = get_parameter(\"/my/parameter\", transform='binary')\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; print(value)\n        My parameter value\n    \"\"\"\n\n    # Only create the provider if this function is called at least once\n    if \"ssm\" not in DEFAULT_PROVIDERS:\n        DEFAULT_PROVIDERS[\"ssm\"] = SSMProvider()\n\n    # If max_age is not set, resolve it from the environment variable, defaulting to DEFAULT_MAX_AGE_SECS\n    max_age = resolve_max_age(env=os.getenv(constants.PARAMETERS_MAX_AGE_ENV, DEFAULT_MAX_AGE_SECS), choice=max_age)\n\n    # If decrypt is not set, resolve it from the environment variable, defaulting to False\n    decrypt = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.PARAMETERS_SSM_DECRYPT_ENV, \"false\"),\n        choice=decrypt,\n    )\n\n    return DEFAULT_PROVIDERS[\"ssm\"].get(\n        name=name,\n        max_age=max_age,\n        transform=transform,\n        force_fetch=force_fetch,\n        decrypt=decrypt,\n        **sdk_options,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/ssm/#aws_lambda_powertools.utilities.parameters.ssm.get_parameters",
            "title": "get_parameters",
            "text": "<pre><code>get_parameters(\n    path: str,\n    transform: None = None,\n    recursive: bool = True,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    raise_on_transform_error: bool = False,\n    **sdk_options\n) -&gt; dict[str, str]\n</code></pre><pre><code>get_parameters(\n    path: str,\n    transform: Literal[\"json\"],\n    recursive: bool = True,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    raise_on_transform_error: bool = False,\n    **sdk_options\n) -&gt; dict[str, dict]\n</code></pre><pre><code>get_parameters(\n    path: str,\n    transform: Literal[\"binary\"],\n    recursive: bool = True,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    raise_on_transform_error: bool = False,\n    **sdk_options\n) -&gt; dict[str, bytes]\n</code></pre><pre><code>get_parameters(\n    path: str,\n    transform: Literal[\"auto\"],\n    recursive: bool = True,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    raise_on_transform_error: bool = False,\n    **sdk_options\n) -&gt; dict[str, str] | dict[str, bytes] | dict[str, dict]\n</code></pre> <pre><code>get_parameters(\n    path: str,\n    transform: TransformOptions = None,\n    recursive: bool = True,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    raise_on_transform_error: bool = False,\n    **sdk_options\n) -&gt; dict[str, str] | dict[str, bytes] | dict[str, dict]\n</code></pre> <p>Retrieve multiple parameter values from AWS Systems Manager (SSM) Parameter Store</p> <p>For readability, we strip the path prefix name in the response.</p> PARAMETER DESCRIPTION <code>path</code> <p>Path to retrieve the parameters</p> <p> TYPE: <code>str</code> </p> <code>transform</code> <p>Transforms the content from a JSON object ('json') or base64 binary string ('binary')</p> <p> TYPE: <code>TransformOptions</code> DEFAULT: <code>None</code> </p> <code>recursive</code> <p>If this should retrieve the parameter values recursively or not, defaults to True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> <code>decrypt</code> <p>If the parameter values should be decrypted</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>force_fetch</code> <p>Force update even before a cached item has expired, defaults to False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>max_age</code> <p>Maximum age of the cached value</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>raise_on_transform_error</code> <p>Raises an exception if any transform fails, otherwise this will return a None value for each transform that failed</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>sdk_options</code> <p>Dictionary of options that will be passed to the Parameter Store get_parameters_by_path API call</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>GetParameterError</code> <p>When the parameter provider fails to retrieve parameter values for a given path.</p> <code>TransformParameterError</code> <p>When the parameter provider fails to transform a parameter value.</p> Example <p>Retrieves parameter values from Systems Manager Parameter Store</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_parameter\n&gt;&gt;&gt;\n&gt;&gt;&gt; values = get_parameters(\"/my/path/prefix\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; for key, value in values.items():\n...     print(key, value)\nconfig              Parameter value (/my/path/prefix/config)\nwebhook/config      Parameter value (/my/path/prefix/webhook/config)\n</code></pre> <p>Retrieves parameter values and decodes them using a Base64 decoder</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_parameter\n&gt;&gt;&gt;\n&gt;&gt;&gt; values = get_parameters(\"/my/path/prefix\", transform='binary')\n</code></pre> Source code in <code>aws_lambda_powertools/utilities/parameters/ssm.py</code> <pre><code>def get_parameters(\n    path: str,\n    transform: TransformOptions = None,\n    recursive: bool = True,\n    decrypt: bool | None = None,\n    force_fetch: bool = False,\n    max_age: int | None = None,\n    raise_on_transform_error: bool = False,\n    **sdk_options,\n) -&gt; dict[str, str] | dict[str, bytes] | dict[str, dict]:\n    \"\"\"\n    Retrieve multiple parameter values from AWS Systems Manager (SSM) Parameter Store\n\n    For readability, we strip the path prefix name in the response.\n\n    Parameters\n    ----------\n    path: str\n        Path to retrieve the parameters\n    transform: str, optional\n        Transforms the content from a JSON object ('json') or base64 binary string ('binary')\n    recursive: bool, optional\n        If this should retrieve the parameter values recursively or not, defaults to True\n    decrypt: bool, optional\n        If the parameter values should be decrypted\n    force_fetch: bool, optional\n        Force update even before a cached item has expired, defaults to False\n    max_age: int, optional\n        Maximum age of the cached value\n    raise_on_transform_error: bool, optional\n        Raises an exception if any transform fails, otherwise this will\n        return a None value for each transform that failed\n    sdk_options: dict, optional\n        Dictionary of options that will be passed to the Parameter Store get_parameters_by_path API call\n\n    Raises\n    ------\n    GetParameterError\n        When the parameter provider fails to retrieve parameter values for\n        a given path.\n    TransformParameterError\n        When the parameter provider fails to transform a parameter value.\n\n    Example\n    -------\n    **Retrieves parameter values from Systems Manager Parameter Store**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_parameter\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; values = get_parameters(\"/my/path/prefix\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; for key, value in values.items():\n        ...     print(key, value)\n        config              Parameter value (/my/path/prefix/config)\n        webhook/config      Parameter value (/my/path/prefix/webhook/config)\n\n    **Retrieves parameter values and decodes them using a Base64 decoder**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities.parameters import get_parameter\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; values = get_parameters(\"/my/path/prefix\", transform='binary')\n    \"\"\"\n\n    # Only create the provider if this function is called at least once\n    if \"ssm\" not in DEFAULT_PROVIDERS:\n        DEFAULT_PROVIDERS[\"ssm\"] = SSMProvider()\n\n    # If max_age is not set, resolve it from the environment variable, defaulting to DEFAULT_MAX_AGE_SECS\n    max_age = resolve_max_age(env=os.getenv(constants.PARAMETERS_MAX_AGE_ENV, DEFAULT_MAX_AGE_SECS), choice=max_age)\n\n    # If decrypt is not set, resolve it from the environment variable, defaulting to False\n    decrypt = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.PARAMETERS_SSM_DECRYPT_ENV, \"false\"),\n        choice=decrypt,\n    )\n\n    return DEFAULT_PROVIDERS[\"ssm\"].get_multiple(\n        path=path,\n        max_age=max_age,\n        transform=transform,\n        raise_on_transform_error=raise_on_transform_error,\n        force_fetch=force_fetch,\n        recursive=recursive,\n        decrypt=decrypt,\n        **sdk_options,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/ssm/#aws_lambda_powertools.utilities.parameters.ssm.get_parameters_by_name",
            "title": "get_parameters_by_name",
            "text": "<pre><code>get_parameters_by_name(\n    parameters: dict[str, dict],\n    transform: None = None,\n    decrypt: bool | None = None,\n    max_age: int | None = None,\n    raise_on_error: bool = True,\n) -&gt; dict[str, str]\n</code></pre><pre><code>get_parameters_by_name(\n    parameters: dict[str, dict],\n    transform: Literal[\"binary\"],\n    decrypt: bool | None = None,\n    max_age: int | None = None,\n    raise_on_error: bool = True,\n) -&gt; dict[str, bytes]\n</code></pre><pre><code>get_parameters_by_name(\n    parameters: dict[str, dict],\n    transform: Literal[\"json\"],\n    decrypt: bool | None = None,\n    max_age: int | None = None,\n    raise_on_error: bool = True,\n) -&gt; dict[str, dict[str, Any]]\n</code></pre><pre><code>get_parameters_by_name(\n    parameters: dict[str, dict],\n    transform: Literal[\"auto\"],\n    decrypt: bool | None = None,\n    max_age: int | None = None,\n    raise_on_error: bool = True,\n) -&gt; dict[str, str] | dict[str, dict]\n</code></pre> <pre><code>get_parameters_by_name(\n    parameters: dict[str, Any],\n    transform: TransformOptions = None,\n    decrypt: bool | None = None,\n    max_age: int | None = None,\n    raise_on_error: bool = True,\n) -&gt; dict[str, str] | dict[str, bytes] | dict[str, dict]\n</code></pre> <p>Retrieve multiple parameter values by name from AWS Systems Manager (SSM) Parameter Store</p> PARAMETER DESCRIPTION <code>parameters</code> <p>List of parameter names, and any optional overrides</p> <p> TYPE: <code>dict[str, Any]</code> </p> <code>transform</code> <p>Transforms the content from a JSON object ('json') or base64 binary string ('binary')</p> <p> TYPE: <code>TransformOptions</code> DEFAULT: <code>None</code> </p> <code>decrypt</code> <p>If the parameter values should be decrypted</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>max_age</code> <p>Maximum age of the cached value</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> <code>raise_on_error</code> <p>Whether to fail-fast or fail gracefully by including \"_errors\" key in the response, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>True</code> </p> Example <p>Retrieves multiple parameters from distinct paths from Systems Manager Parameter Store</p> <pre><code>from aws_lambda_powertools.utilities.parameters import get_parameters_by_name\n\nparams = {\n    \"/param\": {},\n    \"/json\": {\"transform\": \"json\"},\n    \"/binary\": {\"transform\": \"binary\"},\n    \"/no_cache\": {\"max_age\": 0},\n    \"/api_key\": {\"decrypt\": True},\n}\n\nvalues = get_parameters_by_name(parameters=params)\nfor param_name, value in values.items():\n    print(f\"{param_name}: {value}\")\n\n# \"/param\": value\n# \"/json\": value\n# \"/binary\": value\n# \"/no_cache\": value\n# \"/api_key\": value\n</code></pre> RAISES DESCRIPTION <code>GetParameterError</code> <p>When the parameter provider fails to retrieve a parameter value for a given name.</p> Source code in <code>aws_lambda_powertools/utilities/parameters/ssm.py</code> <pre><code>def get_parameters_by_name(\n    parameters: dict[str, Any],\n    transform: TransformOptions = None,\n    decrypt: bool | None = None,\n    max_age: int | None = None,\n    raise_on_error: bool = True,\n) -&gt; dict[str, str] | dict[str, bytes] | dict[str, dict]:\n    \"\"\"\n    Retrieve multiple parameter values by name from AWS Systems Manager (SSM) Parameter Store\n\n    Parameters\n    ----------\n    parameters: dict[str, Any]\n        List of parameter names, and any optional overrides\n    transform: str, optional\n        Transforms the content from a JSON object ('json') or base64 binary string ('binary')\n    decrypt: bool, optional\n        If the parameter values should be decrypted\n    max_age: int, optional\n        Maximum age of the cached value\n    raise_on_error: bool, optional\n        Whether to fail-fast or fail gracefully by including \"_errors\" key in the response, by default True\n\n    Example\n    -------\n\n    **Retrieves multiple parameters from distinct paths from Systems Manager Parameter Store**\n\n        from aws_lambda_powertools.utilities.parameters import get_parameters_by_name\n\n        params = {\n            \"/param\": {},\n            \"/json\": {\"transform\": \"json\"},\n            \"/binary\": {\"transform\": \"binary\"},\n            \"/no_cache\": {\"max_age\": 0},\n            \"/api_key\": {\"decrypt\": True},\n        }\n\n        values = get_parameters_by_name(parameters=params)\n        for param_name, value in values.items():\n            print(f\"{param_name}: {value}\")\n\n        # \"/param\": value\n        # \"/json\": value\n        # \"/binary\": value\n        # \"/no_cache\": value\n        # \"/api_key\": value\n\n    Raises\n    ------\n    GetParameterError\n        When the parameter provider fails to retrieve a parameter value for\n        a given name.\n    \"\"\"\n\n    # NOTE: Decided against using multi-thread due to single-thread outperforming in 128M and 1G + timeout risk\n    # see: https://github.com/aws-powertools/powertools-lambda-python/issues/1040#issuecomment-1299954613\n\n    # If max_age is not set, resolve it from the environment variable, defaulting to DEFAULT_MAX_AGE_SECS\n    max_age = resolve_max_age(env=os.getenv(constants.PARAMETERS_MAX_AGE_ENV, DEFAULT_MAX_AGE_SECS), choice=max_age)\n\n    # If decrypt is not set, resolve it from the environment variable, defaulting to False\n    decrypt = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.PARAMETERS_SSM_DECRYPT_ENV, \"false\"),\n        choice=decrypt,\n    )\n\n    # Only create the provider if this function is called at least once\n    if \"ssm\" not in DEFAULT_PROVIDERS:\n        DEFAULT_PROVIDERS[\"ssm\"] = SSMProvider()\n\n    return DEFAULT_PROVIDERS[\"ssm\"].get_parameters_by_name(\n        parameters=parameters,\n        max_age=max_age,\n        transform=transform,\n        decrypt=decrypt,\n        raise_on_error=raise_on_error,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/parameters/ssm/#aws_lambda_powertools.utilities.parameters.ssm.set_parameter",
            "title": "set_parameter",
            "text": "<pre><code>set_parameter(\n    name: str,\n    value: str,\n    *,\n    overwrite: bool = False,\n    description: str = \"\",\n    parameter_type: SSM_PARAMETER_TYPES = \"String\",\n    tier: SSM_PARAMETER_TIER = \"Standard\",\n    kms_key_id: str | None = None,\n    **sdk_options\n) -&gt; PutParameterResultTypeDef\n</code></pre> <p>Sets a parameter in AWS Systems Manager Parameter Store.</p> PARAMETER DESCRIPTION <code>name</code> <p>The fully qualified name includes the complete hierarchy of the parameter name and name.</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>The parameter value</p> <p> TYPE: <code>str</code> </p> <code>overwrite</code> <p>If the parameter value should be overwritten, False by default</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> <code>description</code> <p>The description of the parameter</p> <p> TYPE: <code>str</code> DEFAULT: <code>''</code> </p> <code>parameter_type</code> <p>Type of the parameter.  Allowed values are String, StringList, and SecureString</p> <p> TYPE: <code>SSM_PARAMETER_TYPES</code> DEFAULT: <code>'String'</code> </p> <code>tier</code> <p>The parameter tier to use. Allowed values are Standard, Advanced, and Intelligent-Tiering</p> <p> TYPE: <code>SSM_PARAMETER_TIER</code> DEFAULT: <code>'Standard'</code> </p> <code>kms_key_id</code> <p>The KMS key id to use to encrypt the parameter</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>sdk_options</code> <p>Dictionary of options that will be passed to the Parameter Store get_parameter API call</p> <p> DEFAULT: <code>{}</code> </p> RAISES DESCRIPTION <code>SetParameterError</code> <p>When attempting to set a parameter fails.</p> <pre><code>https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ssm/client/put_parameter.html\n</code></pre> Example <p>Sets a parameter value from Systems Manager Parameter Store</p> <pre><code>&gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n&gt;&gt;&gt;\n&gt;&gt;&gt; response = parameters.set_parameter(name=\"/my/example/parameter\", value=\"More Powertools\")\n&gt;&gt;&gt;\n&gt;&gt;&gt; print(response)\n123\n</code></pre> RETURNS DESCRIPTION <code>PutParameterResultTypeDef</code> <p>The dict returned by boto3.</p> Source code in <code>aws_lambda_powertools/utilities/parameters/ssm.py</code> <pre><code>def set_parameter(\n    name: str,\n    value: str,\n    *,  # force keyword arguments\n    overwrite: bool = False,\n    description: str = \"\",\n    parameter_type: SSM_PARAMETER_TYPES = \"String\",\n    tier: SSM_PARAMETER_TIER = \"Standard\",\n    kms_key_id: str | None = None,\n    **sdk_options,\n) -&gt; PutParameterResultTypeDef:\n    \"\"\"\n    Sets a parameter in AWS Systems Manager Parameter Store.\n\n    Parameters\n    ----------\n    name: str\n        The fully qualified name includes the complete hierarchy of the parameter name and name.\n    value: str\n        The parameter value\n    overwrite: bool, optional\n        If the parameter value should be overwritten, False by default\n    description: str, optional\n        The description of the parameter\n    parameter_type: str, optional\n        Type of the parameter.  Allowed values are String, StringList, and SecureString\n    tier: str, optional\n        The parameter tier to use. Allowed values are Standard, Advanced, and Intelligent-Tiering\n    kms_key_id: str, optional\n        The KMS key id to use to encrypt the parameter\n    sdk_options: dict, optional\n        Dictionary of options that will be passed to the Parameter Store get_parameter API call\n\n    Raises\n    ------\n    SetParameterError\n        When attempting to set a parameter fails.\n\n    URLs:\n    -------\n        https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/ssm/client/put_parameter.html\n\n    Example\n    -------\n    **Sets a parameter value from Systems Manager Parameter Store**\n\n        &gt;&gt;&gt; from aws_lambda_powertools.utilities import parameters\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; response = parameters.set_parameter(name=\"/my/example/parameter\", value=\"More Powertools\")\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; print(response)\n        123\n\n    Returns\n    -------\n    PutParameterResultTypeDef\n        The dict returned by boto3.\n    \"\"\"\n\n    # Only create the provider if this function is called at least once\n    if \"ssm\" not in DEFAULT_PROVIDERS:\n        DEFAULT_PROVIDERS[\"ssm\"] = SSMProvider()\n\n    return DEFAULT_PROVIDERS[\"ssm\"].set(\n        name,\n        value,\n        parameter_type=parameter_type,\n        overwrite=overwrite,\n        tier=tier,\n        description=description,\n        kms_key_id=kms_key_id,\n        **sdk_options,\n    )\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/base/",
            "title": "Base",
            "text": "<p>Tracing utility</p> <p>Usage Documentation</p> <p><code>Tracer</code></p> CLASS DESCRIPTION <code>BaseProvider</code> <code>BaseSegment</code> <p>Holds common properties and methods on segment and subsegment.</p>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseProvider",
            "title": "BaseProvider",
            "text": "<p>               Bases: <code>ABC</code></p> METHOD DESCRIPTION <code>in_subsegment</code> <p>Return a subsegment context manger.</p> <code>in_subsegment_async</code> <p>Return a subsegment async context manger.</p> <code>patch</code> <p>Instrument a set of supported libraries</p> <code>patch_all</code> <p>Instrument all supported libraries</p> <code>put_annotation</code> <p>Annotate current active trace entity with a key-value pair.</p> <code>put_metadata</code> <p>Add metadata to the current active trace entity.</p>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseProvider.in_subsegment",
            "title": "in_subsegment  <code>abstractmethod</code>",
            "text": "<pre><code>in_subsegment(\n    name=None, **kwargs\n) -&gt; Generator[BaseSegment, None, None]\n</code></pre> <p>Return a subsegment context manger.</p> PARAMETER DESCRIPTION <code>name</code> <p>Subsegment name</p> <p> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Optional parameters to be propagated to segment</p> <p> DEFAULT: <code>{}</code> </p> Source code in <code>aws_lambda_powertools/tracing/base.py</code> <pre><code>@abc.abstractmethod\n@contextmanager\ndef in_subsegment(self, name=None, **kwargs) -&gt; Generator[BaseSegment, None, None]:\n    \"\"\"Return a subsegment context manger.\n\n    Parameters\n    ----------\n    name: str\n        Subsegment name\n    kwargs: dict | None\n        Optional parameters to be propagated to segment\n    \"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseProvider.in_subsegment_async",
            "title": "in_subsegment_async  <code>abstractmethod</code>",
            "text": "<pre><code>in_subsegment_async(\n    name=None, **kwargs\n) -&gt; Generator[BaseSegment, None, None]\n</code></pre> <p>Return a subsegment async context manger.</p> PARAMETER DESCRIPTION <code>name</code> <p>Subsegment name</p> <p> DEFAULT: <code>None</code> </p> <code>kwargs</code> <p>Optional parameters to be propagated to segment</p> <p> DEFAULT: <code>{}</code> </p> Source code in <code>aws_lambda_powertools/tracing/base.py</code> <pre><code>@abc.abstractmethod\n@contextmanager\ndef in_subsegment_async(self, name=None, **kwargs) -&gt; Generator[BaseSegment, None, None]:\n    \"\"\"Return a subsegment async context manger.\n\n    Parameters\n    ----------\n    name: str\n        Subsegment name\n    kwargs: dict | None\n        Optional parameters to be propagated to segment\n    \"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseProvider.patch",
            "title": "patch  <code>abstractmethod</code>",
            "text": "<pre><code>patch(modules: Sequence[str]) -&gt; None\n</code></pre> <p>Instrument a set of supported libraries</p> PARAMETER DESCRIPTION <code>modules</code> <p>Set of modules to be patched</p> <p> TYPE: <code>Sequence[str]</code> </p> Source code in <code>aws_lambda_powertools/tracing/base.py</code> <pre><code>@abc.abstractmethod\ndef patch(self, modules: Sequence[str]) -&gt; None:\n    \"\"\"Instrument a set of supported libraries\n\n    Parameters\n    ----------\n    modules: set[str]\n        Set of modules to be patched\n    \"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseProvider.patch_all",
            "title": "patch_all  <code>abstractmethod</code>",
            "text": "<pre><code>patch_all() -&gt; None\n</code></pre> <p>Instrument all supported libraries</p> Source code in <code>aws_lambda_powertools/tracing/base.py</code> <pre><code>@abc.abstractmethod\ndef patch_all(self) -&gt; None:\n    \"\"\"Instrument all supported libraries\"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseProvider.put_annotation",
            "title": "put_annotation  <code>abstractmethod</code>",
            "text": "<pre><code>put_annotation(\n    key: str, value: str | Number | bool\n) -&gt; None\n</code></pre> <p>Annotate current active trace entity with a key-value pair.</p> <p>Note: Annotations will be indexed for later search query.</p> PARAMETER DESCRIPTION <code>key</code> <p>Metadata key</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Annotation value</p> <p> TYPE: <code>str | Number | bool</code> </p> Source code in <code>aws_lambda_powertools/tracing/base.py</code> <pre><code>@abc.abstractmethod\ndef put_annotation(self, key: str, value: str | numbers.Number | bool) -&gt; None:\n    \"\"\"Annotate current active trace entity with a key-value pair.\n\n    Note: Annotations will be indexed for later search query.\n\n    Parameters\n    ----------\n    key: str\n        Metadata key\n    value: str | numbers.Number | bool\n        Annotation value\n    \"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseProvider.put_metadata",
            "title": "put_metadata  <code>abstractmethod</code>",
            "text": "<pre><code>put_metadata(\n    key: str, value: Any, namespace: str = \"default\"\n) -&gt; None\n</code></pre> <p>Add metadata to the current active trace entity.</p> <p>Note: Metadata is not indexed but can be later retrieved by BatchGetTraces API.</p> PARAMETER DESCRIPTION <code>key</code> <p>Metadata key</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Any object that can be serialized into a JSON string</p> <p> TYPE: <code>Any</code> </p> <code>namespace</code> <p>Metadata namespace, by default 'default'</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p> Source code in <code>aws_lambda_powertools/tracing/base.py</code> <pre><code>@abc.abstractmethod\ndef put_metadata(self, key: str, value: Any, namespace: str = \"default\") -&gt; None:\n    \"\"\"Add metadata to the current active trace entity.\n\n    Note: Metadata is not indexed but can be later retrieved by BatchGetTraces API.\n\n    Parameters\n    ----------\n    key: str\n        Metadata key\n    value: Any\n        Any object that can be serialized into a JSON string\n    namespace: set[str]\n        Metadata namespace, by default 'default'\n    \"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseSegment",
            "title": "BaseSegment",
            "text": "<p>               Bases: <code>ABC</code></p> <p>Holds common properties and methods on segment and subsegment.</p> METHOD DESCRIPTION <code>add_exception</code> <p>Add an exception to trace entities.</p> <code>add_subsegment</code> <p>Add input subsegment as a child subsegment.</p> <code>close</code> <p>Close the trace entity by setting <code>end_time</code></p> <code>put_annotation</code> <p>Annotate segment or subsegment with a key-value pair.</p> <code>put_metadata</code> <p>Add metadata to segment or subsegment. Metadata is not indexed</p> <code>remove_subsegment</code> <p>Remove input subsegment from child subsegments.</p>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseSegment.add_exception",
            "title": "add_exception  <code>abstractmethod</code>",
            "text": "<pre><code>add_exception(\n    exception: BaseException,\n    stack: list[StackSummary],\n    remote: bool = False,\n)\n</code></pre> <p>Add an exception to trace entities.</p> PARAMETER DESCRIPTION <code>exception</code> <p>Caught exception</p> <p> TYPE: <code>BaseException</code> </p> <code>stack</code> <p>List of traceback summaries</p> <p>Output from <code>traceback.extract_stack()</code>.</p> <p> TYPE: <code>list[StackSummary]</code> </p> <code>remote</code> <p>Whether it's a client error (False) or downstream service error (True), by default False</p> <p> TYPE: <code>bool</code> DEFAULT: <code>False</code> </p> Source code in <code>aws_lambda_powertools/tracing/base.py</code> <pre><code>@abc.abstractmethod\ndef add_exception(self, exception: BaseException, stack: list[traceback.StackSummary], remote: bool = False):\n    \"\"\"Add an exception to trace entities.\n\n    Parameters\n    ----------\n    exception: Exception\n        Caught exception\n    stack: list[traceback.StackSummary]\n        List of traceback summaries\n\n        Output from `traceback.extract_stack()`.\n    remote: bool\n        Whether it's a client error (False) or downstream service error (True), by default False\n    \"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseSegment.add_subsegment",
            "title": "add_subsegment  <code>abstractmethod</code>",
            "text": "<pre><code>add_subsegment(subsegment: Any)\n</code></pre> <p>Add input subsegment as a child subsegment.</p> Source code in <code>aws_lambda_powertools/tracing/base.py</code> <pre><code>@abc.abstractmethod\ndef add_subsegment(self, subsegment: Any):\n    \"\"\"Add input subsegment as a child subsegment.\"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseSegment.close",
            "title": "close  <code>abstractmethod</code>",
            "text": "<pre><code>close(end_time: int | None = None)\n</code></pre> <p>Close the trace entity by setting <code>end_time</code> and flip the in progress flag to False.</p> PARAMETER DESCRIPTION <code>end_time</code> <p>Time in epoch seconds, by default current time will be used.</p> <p> TYPE: <code>int | None</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/tracing/base.py</code> <pre><code>@abc.abstractmethod\ndef close(self, end_time: int | None = None):\n    \"\"\"Close the trace entity by setting `end_time`\n    and flip the in progress flag to False.\n\n    Parameters\n    ----------\n    end_time: int\n        Time in epoch seconds, by default current time will be used.\n    \"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseSegment.put_annotation",
            "title": "put_annotation  <code>abstractmethod</code>",
            "text": "<pre><code>put_annotation(\n    key: str, value: str | Number | bool\n) -&gt; None\n</code></pre> <p>Annotate segment or subsegment with a key-value pair.</p> <p>Note: Annotations will be indexed for later search query.</p> PARAMETER DESCRIPTION <code>key</code> <p>Metadata key</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Annotation value</p> <p> TYPE: <code>str | Number | bool</code> </p> Source code in <code>aws_lambda_powertools/tracing/base.py</code> <pre><code>@abc.abstractmethod\ndef put_annotation(self, key: str, value: str | numbers.Number | bool) -&gt; None:\n    \"\"\"Annotate segment or subsegment with a key-value pair.\n\n    Note: Annotations will be indexed for later search query.\n\n    Parameters\n    ----------\n    key: str\n        Metadata key\n    value: str | numbers.Number | bool\n        Annotation value\n    \"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseSegment.put_metadata",
            "title": "put_metadata  <code>abstractmethod</code>",
            "text": "<pre><code>put_metadata(\n    key: str, value: Any, namespace: str = \"default\"\n) -&gt; None\n</code></pre> <p>Add metadata to segment or subsegment. Metadata is not indexed but can be later retrieved by BatchGetTraces API.</p> PARAMETER DESCRIPTION <code>key</code> <p>Metadata key</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Any object that can be serialized into a JSON string</p> <p> TYPE: <code>Any</code> </p> <code>namespace</code> <p>Metadata namespace, by default 'default'</p> <p> TYPE: <code>str</code> DEFAULT: <code>'default'</code> </p> Source code in <code>aws_lambda_powertools/tracing/base.py</code> <pre><code>@abc.abstractmethod\ndef put_metadata(self, key: str, value: Any, namespace: str = \"default\") -&gt; None:\n    \"\"\"Add metadata to segment or subsegment. Metadata is not indexed\n    but can be later retrieved by BatchGetTraces API.\n\n    Parameters\n    ----------\n    key: str\n        Metadata key\n    value: Any\n        Any object that can be serialized into a JSON string\n    namespace: set[str]\n        Metadata namespace, by default 'default'\n    \"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/base/#aws_lambda_powertools.tracing.base.BaseSegment.remove_subsegment",
            "title": "remove_subsegment  <code>abstractmethod</code>",
            "text": "<pre><code>remove_subsegment(subsegment: Any)\n</code></pre> <p>Remove input subsegment from child subsegments.</p> Source code in <code>aws_lambda_powertools/tracing/base.py</code> <pre><code>@abc.abstractmethod\ndef remove_subsegment(self, subsegment: Any):\n    \"\"\"Remove input subsegment from child subsegments.\"\"\"\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/tracing/",
            "title": "Tracing",
            "text": "CLASS DESCRIPTION <code>Tracer</code> <p>Tracer using AWS-XRay to provide decorators with known defaults for Lambda functions</p>"
        },
        {
            "location": "api_doc/tracer/tracing/#aws_lambda_powertools.tracing.tracer.Tracer",
            "title": "Tracer",
            "text": "<pre><code>Tracer(\n    service: str | None = None,\n    disabled: bool | None = None,\n    auto_patch: bool | None = None,\n    patch_modules: Sequence[str] | None = None,\n    provider: BaseProvider | None = None,\n)\n</code></pre> <p>Tracer using AWS-XRay to provide decorators with known defaults for Lambda functions</p> <p>When running locally, it detects whether it's running via SAM CLI, and if it is it returns dummy segments/subsegments instead.</p> <p>By default, it patches all available libraries supported by X-Ray SDK. Patching is automatically disabled when running locally via SAM CLI or by any other means. </p> <p>Ref: https://docs.aws.amazon.com/xray-sdk-for-python/latest/reference/thirdparty.html</p> <p>Tracer keeps a copy of its configuration as it can be instantiated more than once. This is useful when you are using your own middlewares and want to utilize an existing Tracer. Make sure to set <code>auto_patch=False</code> in subsequent Tracer instances to avoid double patching.</p> Environment variables <p>POWERTOOLS_TRACE_DISABLED : str     disable tracer (e.g. <code>\"true\", \"True\", \"TRUE\"</code>) POWERTOOLS_SERVICE_NAME : str     service name POWERTOOLS_TRACER_CAPTURE_RESPONSE : str     disable auto-capture response as metadata (e.g. <code>\"true\", \"True\", \"TRUE\"</code>) POWERTOOLS_TRACER_CAPTURE_ERROR : str     disable auto-capture error as metadata (e.g. <code>\"true\", \"True\", \"TRUE\"</code>)</p> PARAMETER DESCRIPTION <code>service</code> <p>Service name that will be appended in all tracing metadata</p> <p> TYPE: <code>str | None</code> DEFAULT: <code>None</code> </p> <code>auto_patch</code> <p>Patch existing imported modules during initialization, by default True</p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>disabled</code> <p>Flag to explicitly disable tracing, useful when running/testing locally <code>Env POWERTOOLS_TRACE_DISABLED=\"true\"</code></p> <p> TYPE: <code>bool | None</code> DEFAULT: <code>None</code> </p> <code>patch_modules</code> <p>Tuple of modules supported by tracing provider to patch, by default all modules are patched</p> <p> TYPE: <code>Sequence[str] | None</code> DEFAULT: <code>None</code> </p> <code>provider</code> <p>Tracing provider, by default it is aws_xray_sdk.core.xray_recorder</p> <p> TYPE: <code>BaseProvider | None</code> DEFAULT: <code>None</code> </p> RETURNS DESCRIPTION <code>Tracer</code> <p>Tracer instance with imported modules patched</p> Example <p>A Lambda function using Tracer</p> <pre><code>from aws_lambda_powertools import Tracer\ntracer = Tracer(service=\"greeting\")\n\n@tracer.capture_method\ndef greeting(name: str) -&gt; dict:\n    return {\n        \"name\": name\n    }\n\n@tracer.capture_lambda_handler\ndef handler(event: dict, context: Any) -&gt; dict:\n    print(\"Received event from Lambda...\")\n    response = greeting(name=\"Heitor\")\n    return response\n</code></pre> <p>Booking Lambda function using Tracer that adds additional annotation/metadata</p> <pre><code>from aws_lambda_powertools import Tracer\ntracer = Tracer(service=\"booking\")\n\n@tracer.capture_method\ndef confirm_booking(booking_id: str) -&gt; dict:\n        resp = add_confirmation(booking_id)\n\n        tracer.put_annotation(\"BookingConfirmation\", resp[\"requestId\"])\n        tracer.put_metadata(\"Booking confirmation\", resp)\n\n        return resp\n\n@tracer.capture_lambda_handler\ndef handler(event: dict, context: Any) -&gt; dict:\n    print(\"Received event from Lambda...\")\n    booking_id = event.get(\"booking_id\")\n    response = confirm_booking(booking_id=booking_id)\n    return response\n</code></pre> <p>A Lambda function using service name via POWERTOOLS_SERVICE_NAME</p> <pre><code>export POWERTOOLS_SERVICE_NAME=\"booking\"\nfrom aws_lambda_powertools import Tracer\ntracer = Tracer()\n\n@tracer.capture_lambda_handler\ndef handler(event: dict, context: Any) -&gt; dict:\n    print(\"Received event from Lambda...\")\n    response = greeting(name=\"Lessa\")\n    return response\n</code></pre> <p>Reuse an existing instance of Tracer anywhere in the code</p> <pre><code># lambda_handler.py\nfrom aws_lambda_powertools import Tracer\ntracer = Tracer()\n\n@tracer.capture_lambda_handler\ndef handler(event: dict, context: Any) -&gt; dict:\n    ...\n\n# utils.py\nfrom aws_lambda_powertools import Tracer\ntracer = Tracer()\n...\n</code></pre> Limitations <ul> <li>Async handler not supported</li> </ul> METHOD DESCRIPTION <code>capture_lambda_handler</code> <p>Decorator to create subsegment for lambda handlers</p> <code>capture_method</code> <p>Decorator to create subsegment for arbitrary functions</p> <code>ignore_endpoint</code> <p>If you want to ignore certain httplib requests you can do so based on the hostname or URL that is being</p> <code>patch</code> <p>Patch modules for instrumentation.</p> <code>put_annotation</code> <p>Adds annotation to existing segment or subsegment</p> <code>put_metadata</code> <p>Adds metadata to existing segment or subsegment</p> Source code in <code>aws_lambda_powertools/tracing/tracer.py</code> <pre><code>def __init__(\n    self,\n    service: str | None = None,\n    disabled: bool | None = None,\n    auto_patch: bool | None = None,\n    patch_modules: Sequence[str] | None = None,\n    provider: BaseProvider | None = None,\n):\n    self.__build_config(\n        service=service,\n        disabled=disabled,\n        auto_patch=auto_patch,\n        patch_modules=patch_modules,\n        provider=provider,\n    )\n    self.provider: BaseProvider = self._config[\"provider\"]\n    self.disabled = self._config[\"disabled\"]\n    self.service = self._config[\"service\"]\n    self.auto_patch = self._config[\"auto_patch\"]\n\n    if self.disabled:\n        self._disable_tracer_provider()\n\n    if self.auto_patch:\n        self.patch(modules=patch_modules)\n\n    if self._is_xray_provider():\n        self._disable_xray_trace_batching()\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/tracing/#aws_lambda_powertools.tracing.tracer.Tracer.capture_lambda_handler",
            "title": "capture_lambda_handler",
            "text": "<pre><code>capture_lambda_handler(\n    lambda_handler: (\n        Callable[[T, Any], Any]\n        | Callable[[T, Any, Any], Any]\n        | None\n    ) = None,\n    capture_response: bool | None = None,\n    capture_error: bool | None = None,\n) -&gt; Callable[..., Any]\n</code></pre> <p>Decorator to create subsegment for lambda handlers</p> <p>As Lambda follows (event, context) signature we can remove some of the boilerplate and also capture any exception any Lambda function throws or its response as metadata</p> PARAMETER DESCRIPTION <code>lambda_handler</code> <p>Method to annotate on</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>capture_response</code> <p>Instructs tracer to not include handler's response as metadata</p> <p> TYPE: <code>bool</code> DEFAULT: <code>None</code> </p> <code>capture_error</code> <p>Instructs tracer to not include handler's error as metadata, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>None</code> </p> Example <p>Lambda function using capture_lambda_handler decorator</p> <pre><code>tracer = Tracer(service=\"payment\")\n@tracer.capture_lambda_handler\ndef handler(event, context):\n    ...\n</code></pre> <p>Preventing Tracer to log response as metadata</p> <pre><code>tracer = Tracer(service=\"payment\")\n@tracer.capture_lambda_handler(capture_response=False)\ndef handler(event, context):\n    ...\n</code></pre> RAISES DESCRIPTION <code>err</code> <p>Exception raised by method</p> Source code in <code>aws_lambda_powertools/tracing/tracer.py</code> <pre><code>def capture_lambda_handler(\n    self,\n    lambda_handler: Callable[[T, Any], Any] | Callable[[T, Any, Any], Any] | None = None,\n    capture_response: bool | None = None,\n    capture_error: bool | None = None,\n) -&gt; Callable[..., Any]:\n    \"\"\"Decorator to create subsegment for lambda handlers\n\n    As Lambda follows (event, context) signature we can remove some of the boilerplate\n    and also capture any exception any Lambda function throws or its response as metadata\n\n    Parameters\n    ----------\n    lambda_handler : Callable\n        Method to annotate on\n    capture_response : bool, optional\n        Instructs tracer to not include handler's response as metadata\n    capture_error : bool, optional\n        Instructs tracer to not include handler's error as metadata, by default True\n\n    Example\n    -------\n    **Lambda function using capture_lambda_handler decorator**\n\n        tracer = Tracer(service=\"payment\")\n        @tracer.capture_lambda_handler\n        def handler(event, context):\n            ...\n\n    **Preventing Tracer to log response as metadata**\n\n        tracer = Tracer(service=\"payment\")\n        @tracer.capture_lambda_handler(capture_response=False)\n        def handler(event, context):\n            ...\n\n    Raises\n    ------\n    err\n        Exception raised by method\n    \"\"\"\n    # If handler is None we've been called with parameters\n    # Return a partial function with args filled\n    if lambda_handler is None:\n        logger.debug(\"Decorator called with parameters\")\n        return functools.partial(\n            self.capture_lambda_handler,\n            capture_response=capture_response,\n            capture_error=capture_error,\n        )\n\n    lambda_handler_name = lambda_handler.__name__\n    capture_response = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.TRACER_CAPTURE_RESPONSE_ENV, \"true\"),\n        choice=capture_response,\n    )\n    capture_error = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.TRACER_CAPTURE_ERROR_ENV, \"true\"),\n        choice=capture_error,\n    )\n\n    @functools.wraps(lambda_handler)\n    def decorate(event, context, **kwargs):\n        with self.provider.in_subsegment(name=f\"## {lambda_handler_name}\") as subsegment:\n            try:\n                logger.debug(\"Calling lambda handler\")\n                response = lambda_handler(event, context, **kwargs)\n                logger.debug(\"Received lambda handler response successfully\")\n                self._add_response_as_metadata(\n                    method_name=lambda_handler_name,\n                    data=response,\n                    subsegment=subsegment,\n                    capture_response=capture_response,\n                )\n            except Exception as err:\n                logger.exception(f\"Exception received from {lambda_handler_name}\")\n                self._add_full_exception_as_metadata(\n                    method_name=lambda_handler_name,\n                    error=err,\n                    subsegment=subsegment,\n                    capture_error=capture_error,\n                )\n\n                raise\n            finally:\n                cold_start = _is_cold_start()\n                logger.debug(\"Annotating cold start\")\n                subsegment.put_annotation(key=\"ColdStart\", value=cold_start)\n\n                if self.service:\n                    subsegment.put_annotation(key=\"Service\", value=self.service)\n\n            return response\n\n    return decorate\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/tracing/#aws_lambda_powertools.tracing.tracer.Tracer.capture_method",
            "title": "capture_method",
            "text": "<pre><code>capture_method(method: AnyCallableT) -&gt; AnyCallableT\n</code></pre><pre><code>capture_method(\n    method: None = None,\n    capture_response: bool | None = None,\n    capture_error: bool | None = None,\n) -&gt; Callable[[AnyCallableT], AnyCallableT]\n</code></pre> <pre><code>capture_method(\n    method: AnyCallableT | None = None,\n    capture_response: bool | None = None,\n    capture_error: bool | None = None,\n) -&gt; AnyCallableT\n</code></pre> <p>Decorator to create subsegment for arbitrary functions</p> <p>It also captures both response and exceptions as metadata and creates a subsegment named <code>## &lt;method_module.method_qualifiedname&gt;</code></p>"
        },
        {
            "location": "api_doc/tracer/tracing/#aws_lambda_powertools.tracing.tracer.Tracer.capture_method--see-here-qualified-name-for-classes-and-functions",
            "title": "see here: Qualified name for classes and functions",
            "text": "<p>When running async functions concurrently, methods may impact each others subsegment, and can trigger and AlreadyEndedException from X-Ray due to async nature.</p> <p>For this use case, either use <code>capture_method</code> only where <code>async.gather</code> is called, or use <code>in_subsegment_async</code> context manager via our escape hatch mechanism - See examples.</p> PARAMETER DESCRIPTION <code>method</code> <p>Method to annotate on</p> <p> TYPE: <code>Callable</code> DEFAULT: <code>None</code> </p> <code>capture_response</code> <p>Instructs tracer to not include method's response as metadata</p> <p> TYPE: <code>bool</code> DEFAULT: <code>None</code> </p> <code>capture_error</code> <p>Instructs tracer to not include handler's error as metadata, by default True</p> <p> TYPE: <code>bool</code> DEFAULT: <code>None</code> </p> Example <p>Custom function using capture_method decorator</p> <pre><code>tracer = Tracer(service=\"payment\")\n@tracer.capture_method\ndef some_function()\n</code></pre> <p>Custom async method using capture_method decorator</p> <pre><code>from aws_lambda_powertools import Tracer\ntracer = Tracer(service=\"booking\")\n\n@tracer.capture_method\nasync def confirm_booking(booking_id: str) -&gt; dict:\n    resp = call_to_booking_service()\n\n    tracer.put_annotation(\"BookingConfirmation\", resp[\"requestId\"])\n    tracer.put_metadata(\"Booking confirmation\", resp)\n\n    return resp\n\ndef lambda_handler(event: dict, context: Any) -&gt; dict:\n    booking_id = event.get(\"booking_id\")\n    asyncio.run(confirm_booking(booking_id=booking_id))\n</code></pre> <p>Custom generator function using capture_method decorator</p> <pre><code>from aws_lambda_powertools import Tracer\ntracer = Tracer(service=\"booking\")\n\n@tracer.capture_method\ndef bookings_generator(booking_id):\n    resp = call_to_booking_service()\n    yield resp[0]\n    yield resp[1]\n\ndef lambda_handler(event: dict, context: Any) -&gt; dict:\n    gen = bookings_generator(booking_id=booking_id)\n    result = list(gen)\n</code></pre> <p>Custom generator context manager using capture_method decorator</p> <pre><code>from aws_lambda_powertools import Tracer\ntracer = Tracer(service=\"booking\")\n\n@tracer.capture_method\n@contextlib.contextmanager\ndef booking_actions(booking_id):\n    resp = call_to_booking_service()\n    yield \"example result\"\n    cleanup_stuff()\n\ndef lambda_handler(event: dict, context: Any) -&gt; dict:\n    booking_id = event.get(\"booking_id\")\n\n    with booking_actions(booking_id=booking_id) as booking:\n        result = booking\n</code></pre> <p>Tracing nested async calls</p> <pre><code>from aws_lambda_powertools import Tracer\ntracer = Tracer(service=\"booking\")\n\n@tracer.capture_method\nasync def get_identity():\n    ...\n\n@tracer.capture_method\nasync def long_async_call():\n    ...\n\n@tracer.capture_method\nasync def async_tasks():\n    await get_identity()\n    ret = await long_async_call()\n\n    return { \"task\": \"done\", **ret }\n</code></pre> <p>Safely tracing concurrent async calls with decorator</p> <p>This may not needed once this bug is closed</p> <pre><code>from aws_lambda_powertools import Tracer\ntracer = Tracer(service=\"booking\")\n\nasync def get_identity():\n    async with aioboto3.client(\"sts\") as sts:\n        account = await sts.get_caller_identity()\n        return account\n\nasync def long_async_call():\n    ...\n\n@tracer.capture_method\nasync def async_tasks():\n    _, ret = await asyncio.gather(get_identity(), long_async_call(), return_exceptions=True)\n\n    return { \"task\": \"done\", **ret }\n</code></pre> <p>Safely tracing each concurrent async calls with escape hatch</p> <p>This may not needed once this bug is closed</p> <pre><code>from aws_lambda_powertools import Tracer\ntracer = Tracer(service=\"booking\")\n\nasync def get_identity():\n    async tracer.provider.in_subsegment_async(\"## get_identity\"):\n        ...\n\nasync def long_async_call():\n    async tracer.provider.in_subsegment_async(\"## long_async_call\"):\n        ...\n\n@tracer.capture_method\nasync def async_tasks():\n    _, ret = await asyncio.gather(get_identity(), long_async_call(), return_exceptions=True)\n\n    return { \"task\": \"done\", **ret }\n</code></pre> RAISES DESCRIPTION <code>err</code> <p>Exception raised by method</p> Source code in <code>aws_lambda_powertools/tracing/tracer.py</code> <pre><code>def capture_method(\n    self,\n    method: AnyCallableT | None = None,\n    capture_response: bool | None = None,\n    capture_error: bool | None = None,\n) -&gt; AnyCallableT:\n    \"\"\"Decorator to create subsegment for arbitrary functions\n\n    It also captures both response and exceptions as metadata\n    and creates a subsegment named `## &lt;method_module.method_qualifiedname&gt;`\n    # see here: [Qualified name for classes and functions](https://peps.python.org/pep-3155/)\n\n    When running [async functions concurrently](https://docs.python.org/3/library/asyncio-task.html#id6),\n    methods may impact each others subsegment, and can trigger\n    and AlreadyEndedException from X-Ray due to async nature.\n\n    For this use case, either use `capture_method` only where\n    `async.gather` is called, or use `in_subsegment_async`\n    context manager via our escape hatch mechanism - See examples.\n\n    Parameters\n    ----------\n    method : Callable\n        Method to annotate on\n    capture_response : bool, optional\n        Instructs tracer to not include method's response as metadata\n    capture_error : bool, optional\n        Instructs tracer to not include handler's error as metadata, by default True\n\n    Example\n    -------\n    **Custom function using capture_method decorator**\n\n        tracer = Tracer(service=\"payment\")\n        @tracer.capture_method\n        def some_function()\n\n    **Custom async method using capture_method decorator**\n\n        from aws_lambda_powertools import Tracer\n        tracer = Tracer(service=\"booking\")\n\n        @tracer.capture_method\n        async def confirm_booking(booking_id: str) -&gt; dict:\n            resp = call_to_booking_service()\n\n            tracer.put_annotation(\"BookingConfirmation\", resp[\"requestId\"])\n            tracer.put_metadata(\"Booking confirmation\", resp)\n\n            return resp\n\n        def lambda_handler(event: dict, context: Any) -&gt; dict:\n            booking_id = event.get(\"booking_id\")\n            asyncio.run(confirm_booking(booking_id=booking_id))\n\n    **Custom generator function using capture_method decorator**\n\n        from aws_lambda_powertools import Tracer\n        tracer = Tracer(service=\"booking\")\n\n        @tracer.capture_method\n        def bookings_generator(booking_id):\n            resp = call_to_booking_service()\n            yield resp[0]\n            yield resp[1]\n\n        def lambda_handler(event: dict, context: Any) -&gt; dict:\n            gen = bookings_generator(booking_id=booking_id)\n            result = list(gen)\n\n    **Custom generator context manager using capture_method decorator**\n\n        from aws_lambda_powertools import Tracer\n        tracer = Tracer(service=\"booking\")\n\n        @tracer.capture_method\n        @contextlib.contextmanager\n        def booking_actions(booking_id):\n            resp = call_to_booking_service()\n            yield \"example result\"\n            cleanup_stuff()\n\n        def lambda_handler(event: dict, context: Any) -&gt; dict:\n            booking_id = event.get(\"booking_id\")\n\n            with booking_actions(booking_id=booking_id) as booking:\n                result = booking\n\n    **Tracing nested async calls**\n\n        from aws_lambda_powertools import Tracer\n        tracer = Tracer(service=\"booking\")\n\n        @tracer.capture_method\n        async def get_identity():\n            ...\n\n        @tracer.capture_method\n        async def long_async_call():\n            ...\n\n        @tracer.capture_method\n        async def async_tasks():\n            await get_identity()\n            ret = await long_async_call()\n\n            return { \"task\": \"done\", **ret }\n\n    **Safely tracing concurrent async calls with decorator**\n\n    This may not needed once [this bug is closed](https://github.com/aws/aws-xray-sdk-python/issues/164)\n\n        from aws_lambda_powertools import Tracer\n        tracer = Tracer(service=\"booking\")\n\n        async def get_identity():\n            async with aioboto3.client(\"sts\") as sts:\n                account = await sts.get_caller_identity()\n                return account\n\n        async def long_async_call():\n            ...\n\n        @tracer.capture_method\n        async def async_tasks():\n            _, ret = await asyncio.gather(get_identity(), long_async_call(), return_exceptions=True)\n\n            return { \"task\": \"done\", **ret }\n\n    **Safely tracing each concurrent async calls with escape hatch**\n\n    This may not needed once [this bug is closed](https://github.com/aws/aws-xray-sdk-python/issues/164)\n\n        from aws_lambda_powertools import Tracer\n        tracer = Tracer(service=\"booking\")\n\n        async def get_identity():\n            async tracer.provider.in_subsegment_async(\"## get_identity\"):\n                ...\n\n        async def long_async_call():\n            async tracer.provider.in_subsegment_async(\"## long_async_call\"):\n                ...\n\n        @tracer.capture_method\n        async def async_tasks():\n            _, ret = await asyncio.gather(get_identity(), long_async_call(), return_exceptions=True)\n\n            return { \"task\": \"done\", **ret }\n\n    Raises\n    ------\n    err\n        Exception raised by method\n    \"\"\"\n    # If method is None we've been called with parameters\n    # Return a partial function with args filled\n    if method is None:\n        logger.debug(\"Decorator called with parameters\")\n        return cast(\n            AnyCallableT,\n            functools.partial(self.capture_method, capture_response=capture_response, capture_error=capture_error),\n        )\n\n    # Example: app.ClassA.get_all  # noqa ERA001\n    # Valid characters can be found at http://docs.aws.amazon.com/xray/latest/devguide/xray-api-segmentdocuments.html\n    method_name = sanitize_xray_segment_name(f\"{method.__module__}.{method.__qualname__}\")\n\n    capture_response = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.TRACER_CAPTURE_RESPONSE_ENV, \"true\"),\n        choice=capture_response,\n    )\n    capture_error = resolve_truthy_env_var_choice(\n        env=os.getenv(constants.TRACER_CAPTURE_ERROR_ENV, \"true\"),\n        choice=capture_error,\n    )\n\n    # Maintenance: Need a factory/builder here to simplify this now\n    if inspect.iscoroutinefunction(method):\n        return self._decorate_async_function(\n            method=method,\n            capture_response=capture_response,\n            capture_error=capture_error,\n            method_name=method_name,\n        )\n    elif inspect.isgeneratorfunction(method):\n        return self._decorate_generator_function(\n            method=method,\n            capture_response=capture_response,\n            capture_error=capture_error,\n            method_name=method_name,\n        )\n    elif hasattr(method, \"__wrapped__\") and inspect.isgeneratorfunction(method.__wrapped__):\n        return self._decorate_generator_function_with_context_manager(\n            method=method,\n            capture_response=capture_response,\n            capture_error=capture_error,\n            method_name=method_name,\n        )\n    else:\n        return self._decorate_sync_function(\n            method=method,\n            capture_response=capture_response,\n            capture_error=capture_error,\n            method_name=method_name,\n        )\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/tracing/#aws_lambda_powertools.tracing.tracer.Tracer.ignore_endpoint",
            "title": "ignore_endpoint",
            "text": "<pre><code>ignore_endpoint(\n    hostname: str | None = None,\n    urls: list[str] | None = None,\n)\n</code></pre> <p>If you want to ignore certain httplib requests you can do so based on the hostname or URL that is being requested.</p> <p>NOTE: If the provider is not xray, nothing will be added to ignore list</p> Documentation <ul> <li>https://github.com/aws/aws-xray-sdk-python#ignoring-httplib-requests</li> </ul> PARAMETER DESCRIPTION <code>hostname</code> <p>The hostname is matched using the Python fnmatch library which does Unix glob style matching.</p> <p> TYPE: <code>(Optional, str)</code> DEFAULT: <code>None</code> </p> <code>urls</code> <p>List of urls to ignore. Example <code>tracer.ignore_endpoint(urls=[\"/ignored-url\"])</code></p> <p> TYPE: <code>list[str] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/tracing/tracer.py</code> <pre><code>def ignore_endpoint(self, hostname: str | None = None, urls: list[str] | None = None):\n    \"\"\"If you want to ignore certain httplib requests you can do so based on the hostname or URL that is being\n    requested.\n\n    &gt; NOTE: If the provider is not xray, nothing will be added to ignore list\n\n    Documentation\n    --------------\n    - https://github.com/aws/aws-xray-sdk-python#ignoring-httplib-requests\n\n    Parameters\n    ----------\n    hostname : Optional, str\n        The hostname is matched using the Python fnmatch library which does Unix glob style matching.\n    urls: Optional, list[str]\n        List of urls to ignore. Example `tracer.ignore_endpoint(urls=[\"/ignored-url\"])`\n    \"\"\"\n    if not self._is_xray_provider():\n        return\n\n    from aws_xray_sdk.ext.httplib import add_ignored  # type: ignore\n\n    add_ignored(hostname=hostname, urls=urls)\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/tracing/#aws_lambda_powertools.tracing.tracer.Tracer.patch",
            "title": "patch",
            "text": "<pre><code>patch(modules: Sequence[str] | None = None)\n</code></pre> <p>Patch modules for instrumentation.</p> <p>Patches all supported modules by default if none are given.</p> PARAMETER DESCRIPTION <code>modules</code> <p>List of modules to be patched, optional by default</p> <p> TYPE: <code>Sequence[str] | None</code> DEFAULT: <code>None</code> </p> Source code in <code>aws_lambda_powertools/tracing/tracer.py</code> <pre><code>def patch(self, modules: Sequence[str] | None = None):\n    \"\"\"Patch modules for instrumentation.\n\n    Patches all supported modules by default if none are given.\n\n    Parameters\n    ----------\n    modules : Sequence[str] | None\n        List of modules to be patched, optional by default\n    \"\"\"\n    if self.disabled:\n        logger.debug(\"Tracing has been disabled, aborting patch\")\n        return\n\n    if modules is None:\n        self.provider.patch_all()\n    else:\n        self.provider.patch(modules)\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/tracing/#aws_lambda_powertools.tracing.tracer.Tracer.put_annotation",
            "title": "put_annotation",
            "text": "<pre><code>put_annotation(key: str, value: str | Number | bool)\n</code></pre> <p>Adds annotation to existing segment or subsegment</p> PARAMETER DESCRIPTION <code>key</code> <p>Annotation key</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Value for annotation</p> <p> TYPE: <code>str | Number | bool</code> </p> Example <p>Custom annotation for a pseudo service named payment</p> <pre><code>tracer = Tracer(service=\"payment\")\ntracer.put_annotation(\"PaymentStatus\", \"CONFIRMED\")\n</code></pre> Source code in <code>aws_lambda_powertools/tracing/tracer.py</code> <pre><code>def put_annotation(self, key: str, value: str | numbers.Number | bool):\n    \"\"\"Adds annotation to existing segment or subsegment\n\n    Parameters\n    ----------\n    key : str\n        Annotation key\n    value : str | numbers.Number | bool\n        Value for annotation\n\n    Example\n    -------\n    Custom annotation for a pseudo service named payment\n\n        tracer = Tracer(service=\"payment\")\n        tracer.put_annotation(\"PaymentStatus\", \"CONFIRMED\")\n    \"\"\"\n    if self.disabled:\n        logger.debug(\"Tracing has been disabled, aborting put_annotation\")\n        return\n\n    logger.debug(f\"Annotating on key '{key}' with '{value}'\")\n    self.provider.put_annotation(key=key, value=value)\n</code></pre>"
        },
        {
            "location": "api_doc/tracer/tracing/#aws_lambda_powertools.tracing.tracer.Tracer.put_metadata",
            "title": "put_metadata",
            "text": "<pre><code>put_metadata(\n    key: str, value: Any, namespace: str | None = None\n)\n</code></pre> <p>Adds metadata to existing segment or subsegment</p> PARAMETER DESCRIPTION <code>key</code> <p>Metadata key</p> <p> TYPE: <code>str</code> </p> <code>value</code> <p>Value for metadata</p> <p> TYPE: <code>any</code> </p> <code>namespace</code> <p>Namespace that metadata will lie under, by default None</p> <p> TYPE: <code>str</code> DEFAULT: <code>None</code> </p> Example <p>Custom metadata for a pseudo service named payment</p> <pre><code>tracer = Tracer(service=\"payment\")\nresponse = collect_payment()\ntracer.put_metadata(\"Payment collection\", response)\n</code></pre> Source code in <code>aws_lambda_powertools/tracing/tracer.py</code> <pre><code>def put_metadata(self, key: str, value: Any, namespace: str | None = None):\n    \"\"\"Adds metadata to existing segment or subsegment\n\n    Parameters\n    ----------\n    key : str\n        Metadata key\n    value : any\n        Value for metadata\n    namespace : str, optional\n        Namespace that metadata will lie under, by default None\n\n    Example\n    -------\n    Custom metadata for a pseudo service named payment\n\n        tracer = Tracer(service=\"payment\")\n        response = collect_payment()\n        tracer.put_metadata(\"Payment collection\", response)\n    \"\"\"\n    if self.disabled:\n        logger.debug(\"Tracing has been disabled, aborting put_metadata\")\n        return\n\n    namespace = namespace or self.service\n    logger.debug(f\"Adding metadata on key '{key}' with '{value}' at namespace '{namespace}'\")\n    self.provider.put_metadata(key=key, value=value, namespace=namespace)\n</code></pre>"
        },
        {
            "location": "contributing/conventions/",
            "title": "Conventions",
            "text": ""
        },
        {
            "location": "contributing/conventions/#general-terminology-and-practices",
            "title": "General terminology and practices",
            "text": "<p>These are common conventions we keep on building as the project gains new contributors and grows in complexity.</p> <p>As we gather more concrete examples, this page will have one section for each category to demonstrate a before and after.</p> Category Convention Docstring We use Numpy convention with markdown to help generate more readable API references. For public APIs, we always include at least one Example to ease everyone's experience when using an IDE. Style guide We use black and Ruff to enforce beyond good practices PEP8. We use type annotations and enforce static type checking at CI (mypy). Core utilities Core utilities always accept <code>service</code> as a constructor parameter, can work in isolation, and are also available in other languages implementation. Utilities Utilities are not as strict as core and focus on community needs: development productivity, industry leading practices, etc. Both core and general utilities follow our Tenets. Exceptions Specific exceptions live within utilities themselves and use <code>Error</code> suffix e.g. <code>MetricUnitError</code>. Git commits We follow conventional commits. We do not enforce conventional commits on contributors to lower the entry bar. Instead, we enforce a conventional PR title so our label automation and changelog are generated correctly. API documentation API reference docs are generated from docstrings which should have Examples section to allow developers to have what they need within their own IDE. Documentation website covers the wider usage, tips, and strive to be concise. Documentation We treat it like a product. We sub-divide content aimed at getting started (80% of customers) vs advanced usage (20%). We also ensure customers know how to unit test their code when using our features."
        },
        {
            "location": "contributing/conventions/#testing-definition",
            "title": "Testing definition",
            "text": "<p>We group tests in different categories</p> Test When to write Notes Speed Unit tests Verify the smallest possible unit works. Networking access is prohibited. Prefer Functional tests given our complexity. Lightning fast (nsec to ms) Functional tests Guarantee functionality works as expected. It's a subset of integration test covering multiple units. No external dependency. Prefer Fake implementations (in-memory) over Mocks and Stubs. Fast (ms to few seconds at worst) End-to-end tests Gain confidence that a Lambda function with our code operates as expected. It simulates how customers configure, deploy, and run their Lambda function - Event Source configuration, IAM permissions, etc. Slow (minutes) Performance tests Ensure critical operations won't increase latency and costs to customers. CI arbitrary hardware can make it flaky. We'll resume writing perf test after we revamp our functional tests with internal utilities. Fast to moderate (a few seconds to a few minutes)"
        },
        {
            "location": "contributing/getting_started/",
            "title": "Your first contribution",
            "text": "<p>Thank you for your interest in contributing to our project - we couldn't be more excited!</p> <p> <pre><code>graph LR\n    Learn[\"Learn about contributions\"] --&gt; Find[\"Find areas to work / get mentoring\"] --&gt; Work[\"Prepare pull request\"] --&gt; Closing[\"Take learnings with you\"]</code></pre> End-to-end process </p>"
        },
        {
            "location": "contributing/getting_started/#types-of-contributions",
            "title": "Types of contributions",
            "text": "<p>We consider any contribution that help this project improve everyone's experience to be valid, as long as you agree with our tenets, licensing, and Code of Conduct.</p> <p>Whether you're new contributor or a pro, we compiled a list of the common contributions to help you choose your first:</p> <p>Please check existing open, or recently closed issues before creating a new one.</p> <pre><code>Each type link goes to their respective template, or Discord invite.\n</code></pre> Type Description Documentation Ideas to make user guide or API guide clearer. It generally go from typos, diagrams, tutorials, the lack of documentation, etc. Feature request New functionalities or enhancements that could help you, your team, existing and future customers. Check out our process to understand how we prioritize it. Design proposals Request for Comments (RFC) including user experience (UX) based on a feature request to gather the community feedback, and demonstrate the art of the possible. Bug report A runtime error that is reproducible whether you have an idea how to solve it or not. Advocacy Share what you did with Powertools for AWS Lambda. Blog posts, workshops, presentation, sample applications, podcasts, etc. Public reference Become a public reference to share how you're using Powertools for AWS Lambda at your organization. Discussions Kick off a discussion on Discord, introduce yourself, and help respond to existing questions from the community. Static typing Improvements to increase or correct static typing coverage to ease maintenance, autocompletion, etc. Technical debt Suggest areas to address technical debt that could make maintenance easier or provide customer value faster. Generally used by maintainers and contributors. Governance Ideas to improve to our governance processes, automation, and anything internal. Typically used by maintainers and regular contributors."
        },
        {
            "location": "contributing/getting_started/#finding-contributions-to-work-on",
            "title": "Finding contributions to work on",
            "text": "<p>Besides suggesting ideas you think it'll improve everyone's experience, these are the most common places to find work:</p> Area Description Help wanted issues These are triaged areas that we'd appreciate any level of contribution - from opinions to actual implementation. Missing customer feedback issues These are items we'd like to hear from more customers before making any decision. Sharing your thoughts, use case, or asking additional questions are great help. Pending design proposals These are feature requests that initially look good but need a RFC to enrich the discussion by validating user-experience, tradeoffs, and highlight use cases. Backlog items We use GitHub projects to surface what we're working on, needs triage, etc. This view shows items we already triaged but don't have the bandwidth to tackle them just yet. Documentation Documentation can always be improved. Look for areas that a better example, or a diagram, or more context helps everyone - keep in mind a diverse audience and English as a second language folks. Participate in discussions There's always a discussion that could benefit others in the form of documentation, blog post, etc. Roadmap Some roadmap items need a RFC to discuss design options, or gather customers use case before we can prioritize it. Build a sample application Using Powertools for AWS Lambda in different contexts will give you insights on what could be made easier, which documentation could be enriched, and more. <p>Still couldn't find anything that match your skill set?</p> <pre><code>Please reach out on [Discord](https://discord.gg/B8zZKbbyET){target=\"_blank\" rel=\"nofollow\"}, specially if you'd like to get mentoring for a task you'd like to take but you don't feel ready yet :)\n\nContributions are meant to be bi-directional. There's always something we can learn from each other.\n</code></pre>"
        },
        {
            "location": "contributing/getting_started/#sending-a-pull-request",
            "title": "Sending a pull request",
            "text": "<p>First time creating a Pull Request? Keep this document handy.</p> <p>Before sending us a pull request, please ensure that:</p> <ul> <li> You are working against the latest source on the develop branch.</li> <li> You check existing open, and recently merged pull requests to make sure someone else hasn't addressed the problem already.</li> <li> You open an issue before you begin any implementation. We value your time and bandwidth. As such, any pull requests created on non-triaged issues might not be successful.</li> <li> Create a new branch named after the change you are contributing e.g. <code>feat/logger-debug-sampling</code></li> </ul> <p>Ready?</p> <p>These are the steps to send a pull request:</p> <ol> <li>Run all formatting, linting, tests, documentation and baseline checks: <code>make pr</code></li> <li>Commit to your fork using clear commit messages. Don't worry about typos or format, we squash all commits during merge.</li> <li>Send us a pull request with a conventional semantic title.</li> <li>Fill in the areas pre-defined in the pull request body to help expedite reviewing your work.</li> <li>Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation.</li> </ol>"
        },
        {
            "location": "contributing/getting_started/#code-of-conduct",
            "title": "Code of Conduct",
            "text": "<p>This project has adopted the Amazon Open Source Code of Conduct</p> <p>For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.</p>"
        },
        {
            "location": "contributing/getting_started/#security-issue-notifications",
            "title": "Security issue notifications",
            "text": "<p>If you discover a potential security issue in this project, we kindly ask you to notify AWS/Amazon Security via our vulnerability reporting page. Please do not create a public github issue.</p>"
        },
        {
            "location": "contributing/getting_started/#troubleshooting",
            "title": "Troubleshooting",
            "text": ""
        },
        {
            "location": "contributing/getting_started/#api-reference-documentation",
            "title": "API reference documentation",
            "text": "<p>When you are working on the codebase and you use the local API reference documentation to preview your changes, you might see the following message: <code>Module aws_lambda_powertools not found</code>.</p> <p>This happens when:</p> <ul> <li>You did not install the local dev environment yet<ul> <li>You can install dev deps with <code>make dev</code> command</li> </ul> </li> <li>The code in the repository is raising an exception while the <code>pdoc</code> is scanning the codebase<ul> <li>Unfortunately, this exception is not shown to you, but if you run, <code>poetry run pdoc --pdf aws_lambda_powertools</code>, the exception is shown and you can prevent the exception from being raised</li> <li>Once resolved the documentation should load correctly again</li> </ul> </li> </ul>"
        },
        {
            "location": "contributing/setup/",
            "title": "Development environment",
            "text": "<p>This page describes how to setup your development environment (Cloud or locally) to contribute to Powertools for AWS Lambda.</p> <p> <pre><code>graph LR\n    Dev[\"Development environment\"] --&gt; Quality[\"Run quality checks locally\"] --&gt; PR[\"Prepare pull request\"] --&gt; Collaborate</code></pre> End-to-end process </p>"
        },
        {
            "location": "contributing/setup/#requirements",
            "title": "Requirements",
            "text": "<p>First time contributing to an open-source project ever?</p> <p>Read this introduction on how to fork and clone a project on GitHub.</p> <p>Unless you're using the pre-configured Cloud environment, you'll need the following installed:</p> <ul> <li>GitHub account. You'll need to be able to fork, clone, and contribute via pull request.</li> <li>Python 3.9+. Pick any version supported in AWS Lambda runtime.</li> <li>Docker. We use it to run documentation linters and non-Python tooling.</li> <li>Fork the repository. You'll work against your fork of this repository.</li> </ul> Additional requirements if running end-to-end tests <ul> <li>AWS CDK CLI</li> <li>AWS Account bootstrapped with CDK</li> <li>AWS CLI installed and configured</li> </ul>"
        },
        {
            "location": "contributing/setup/#cloud-environment",
            "title": "Cloud environment",
            "text": "<p>NOTE. Be mindful of Gitpod pricing structure for long-running contributions. When in doubt, use the local environment below.</p> <p>To use a pre-configured environment, replace <code>YOUR_USERNAME</code> with your GitHub username or organization.</p> <pre><code>https://gitpod.io/#https://github.com/YOUR_USERNAME/powertools-lambda-python  #(1)!\n</code></pre> <ol> <li>For example, my username is <code>heitorlessa</code>.  Therefore, my final URL should be <code>https://gitpod.io/#https://github.com/heitorlessa/powertools-lambda-python</code></li> </ol> <p>Once provisioned, it'll install all development dependencies and tools you'll need to contribute.</p>"
        },
        {
            "location": "contributing/setup/#local-environment",
            "title": "Local environment",
            "text": "<p>Assuming you've got all requirements.</p> <p>You can use <code>make dev</code> to create a local virtual environment and install all dependencies locally.</p> <p>Curious about what <code>make dev</code> does under the hood?</p> <p>We use <code>Make</code> to automate common tasks locally and in Continuous Integration environments.</p>"
        },
        {
            "location": "contributing/setup/#local-documentation",
            "title": "Local documentation",
            "text": "<p>You might find useful to run both the documentation website and the API reference locally while contributing:</p> <ul> <li>Docs website: <code>make docs-local</code><ul> <li>If you prefer using Docker: <code>make docs-local-docker</code></li> </ul> </li> <li>API reference: <code>make docs-api-local</code></li> </ul>"
        },
        {
            "location": "contributing/documentation/rfcs/",
            "title": "Writing Request For Comment (RFC)",
            "text": ""
        },
        {
            "location": "contributing/documentation/rfcs/#tbw",
            "title": "TBW",
            "text": "<p>Something great will come.</p>"
        },
        {
            "location": "core/logger/",
            "title": "Logger",
            "text": "<p>Logger provides an opinionated logger with output structured as JSON.</p>"
        },
        {
            "location": "core/logger/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Capture key fields from Lambda context, cold start and structures logging output as JSON</li> <li>Log Lambda event when instructed (disabled by default)</li> <li>Log sampling enables DEBUG log level for a percentage of requests (disabled by default)</li> <li>Append additional keys to structured log at any point in time</li> <li>Buffering logs for a specific request or invocation, and flushing them automatically on error or manually as needed.</li> </ul>"
        },
        {
            "location": "core/logger/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>Logger requires two settings:</p> Setting Description Environment variable Constructor parameter Logging level Sets how verbose Logger should be (INFO, by default) <code>POWERTOOLS_LOG_LEVEL</code> <code>level</code> Service Sets service key that will be present across all log statements <code>POWERTOOLS_SERVICE_NAME</code> <code>service</code> <p>There are some other environment variables which can be set to modify Logger's settings at a global scope.</p> AWS Serverless Application Model (SAM) example<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Powertools for AWS Lambda (Python) version\n\nGlobals:\n  Function:\n    Timeout: 5\n    Runtime: python3.12\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: payment\n        POWERTOOLS_LOG_LEVEL: INFO\n    Layers:\n      # Find the latest Layer version in the official documentation\n      # https://docs.powertools.aws.dev/lambda/python/latest/#lambda-layer\n      - !Sub arn:aws:lambda:${AWS::Region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12\n\nResources:\n  LoggerLambdaHandlerExample:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: ../src\n      Handler: inject_lambda_context.handler\n</code></pre>"
        },
        {
            "location": "core/logger/#standard-structured-keys",
            "title": "Standard structured keys",
            "text": "<p>Your Logger will include the following keys to your structured logging:</p> Key Example Note level: <code>str</code> <code>INFO</code> Logging level location: <code>str</code> <code>collect.handler:1</code> Source code location where statement was executed message: <code>Any</code> <code>Collecting payment</code> Unserializable JSON values are casted as <code>str</code> timestamp: <code>str</code> <code>2021-05-03 10:20:19,650+0000</code> Timestamp with milliseconds, by default uses default AWS Lambda timezone (UTC) service: <code>str</code> <code>payment</code> Service name defined, by default <code>service_undefined</code> xray_trace_id: <code>str</code> <code>1-5759e988-bd862e3fe1be46a994272793</code> When tracing is enabled, it shows X-Ray Trace ID sampling_rate: <code>float</code> <code>0.1</code> When enabled, it shows sampling rate in percentage e.g. 10% exception_name: <code>str</code> <code>ValueError</code> When <code>logger.exception</code> is used and there is an exception exception: <code>str</code> <code>Traceback (most recent call last)..</code> When <code>logger.exception</code> is used and there is an exception"
        },
        {
            "location": "core/logger/#capturing-lambda-context-info",
            "title": "Capturing Lambda context info",
            "text": "<p>You can enrich your structured logs with key Lambda context information via <code>inject_lambda_context</code>.</p> inject_lambda_context.pyinject_lambda_context_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.info(\"Collecting payment\")\n\n    # You can log entire objects too\n    logger.info({\"operation\": \"collect_payment\", \"charge_id\": event[\"charge_id\"]})\n    return \"hello world\"\n</code></pre> <pre><code>[\n    {\n        \"level\": \"INFO\",\n        \"location\": \"collect.handler:9\",\n        \"message\": \"Collecting payment\",\n        \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n        \"service\": \"payment\",\n        \"cold_start\": true,\n        \"function_name\": \"test\",\n        \"function_memory_size\": 128,\n        \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n        \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"collect.handler:12\",\n        \"message\": {\n            \"operation\": \"collect_payment\",\n            \"charge_id\": \"ch_AZFlk2345C0\"\n        },\n        \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n        \"service\": \"payment\",\n        \"cold_start\": true,\n        \"function_name\": \"test\",\n        \"function_memory_size\": 128,\n        \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n        \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n    }\n]\n</code></pre> <p>When used, this will include the following keys:</p> Key Example cold_start: <code>bool</code> <code>false</code> function_name <code>str</code> <code>example-powertools-HelloWorldFunction-1P1Z6B39FLU73</code> function_memory_size: <code>int</code> <code>128</code> function_arn: <code>str</code> <code>arn:aws:lambda:eu-west-1:012345678910:function:example-powertools-HelloWorldFunction-1P1Z6B39FLU73</code> function_request_id: <code>str</code> <code>899856cb-83d1-40d7-8611-9e78f15f32f4</code>"
        },
        {
            "location": "core/logger/#logging-incoming-event",
            "title": "Logging incoming event",
            "text": "<p>When debugging in non-production environments, you can instruct Logger to log the incoming event with <code>log_event</code> param or via <code>POWERTOOLS_LOGGER_LOG_EVENT</code> env var.</p> Warning <p>This is disabled by default to prevent sensitive info being logged</p> Logging incoming event<pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context(log_event=True)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    return \"hello world\"\n</code></pre>"
        },
        {
            "location": "core/logger/#setting-a-correlation-id",
            "title": "Setting a Correlation ID",
            "text": "<p>You can set a Correlation ID using <code>correlation_id_path</code> param by passing a JMESPath expression, including our custom JMESPath Functions.</p> Tip <p>You can retrieve correlation IDs via <code>get_correlation_id</code> method.</p> set_correlation_id.pyset_correlation_id_event.jsonset_correlation_id_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context(correlation_id_path=\"headers.my_request_id_header\")\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.debug(f\"Correlation ID =&gt; {logger.get_correlation_id()}\")\n    logger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n    \"headers\": {\n        \"my_request_id_header\": \"correlation_id_value\"\n    }\n}\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"location\": \"collect.handler:10\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n    \"service\": \"payment\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n    \"correlation_id\": \"correlation_id_value\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#set_correlation_id-method",
            "title": "set_correlation_id method",
            "text": "<p>You can also use <code>set_correlation_id</code> method to inject it anywhere else in your code. Example below uses Event Source Data Classes utility to easily access events properties.</p> set_correlation_id_method.pyset_correlation_id_method.jsonset_correlation_id_method_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import APIGatewayProxyEvent\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    request = APIGatewayProxyEvent(event)\n\n    logger.set_correlation_id(request.request_context.request_id)\n    logger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n    \"requestContext\": {\n        \"requestId\": \"correlation_id_value\"\n    }\n}\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"location\": \"collect.handler:13\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n    \"service\": \"payment\",\n    \"correlation_id\": \"correlation_id_value\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#known-correlation-ids",
            "title": "Known correlation IDs",
            "text": "<p>To ease routine tasks like extracting correlation ID from popular event sources, we provide built-in JMESPath expressions.</p> set_correlation_id_jmespath.pyset_correlation_id_jmespath.jsonset_correlation_id_jmespath_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.debug(f\"Correlation ID =&gt; {logger.get_correlation_id()}\")\n    logger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n    \"requestContext\": {\n        \"requestId\": \"correlation_id_value\"\n    }\n}\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"location\": \"collect.handler:11\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n    \"service\": \"payment\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n    \"correlation_id\": \"correlation_id_value\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#appending-additional-keys",
            "title": "Appending additional keys",
            "text": "Info: Custom keys are persisted across warm invocations <p>Always set additional keys as part of your handler to ensure they have the latest value, or explicitly clear them with <code>clear_state=True</code>.</p> <p>You can append additional keys using either mechanism:</p> <ul> <li>New keys persist across all future log messages via <code>append_keys</code> method</li> <li>Add additional keys on a per log message basis as a keyword=value, or via <code>extra</code> parameter</li> <li>New keys persist across all future logs in a specific thread via <code>thread_safe_append_keys</code> method. Check Working with thread-safe keys section.</li> </ul>"
        },
        {
            "location": "core/logger/#append_keys-method",
            "title": "append_keys method",
            "text": "Warning <p><code>append_keys</code> is not thread-safe, use thread_safe_append_keys instead</p> <p>You can append your own keys to your existing Logger via <code>append_keys(**additional_key_values)</code> method.</p> append_keys.pyappend_keys_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    order_id = event.get(\"order_id\")\n\n    # this will ensure order_id key always has the latest value before logging\n    # alternative, you can use `clear_state=True` parameter in @inject_lambda_context\n    logger.append_keys(order_id=order_id)\n    logger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"location\": \"collect.handler:11\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n    \"service\": \"payment\",\n    \"order_id\": \"order_id_value\"\n}\n</code></pre> Tip: Logger will automatically reject any key with a None value <p>If you conditionally add keys depending on the payload, you can follow the example above.</p> <p>This example will add <code>order_id</code> if its value is not empty, and in subsequent invocations where <code>order_id</code> might not be present it'll remove it from the Logger.</p>"
        },
        {
            "location": "core/logger/#append_context_keys-method",
            "title": "append_context_keys method",
            "text": "Warning <p><code>append_context_keys</code> is not thread-safe.</p> <p>The append_context_keys method allows temporary modification of a Logger instance's context without creating a new logger. It's useful for adding context keys to specific workflows while maintaining the logger's overall state and simplicity.</p> append_context_keys.pyappend_context_keys_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger(service=\"example_service\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    with logger.append_context_keys(user_id=\"123\", operation=\"process\"):\n        logger.info(\"Log with context\")\n\n    logger.info(\"Log without context\")\n\n    return \"hello world\"\n</code></pre> <pre><code>[\n    {\n        \"level\": \"INFO\",\n        \"location\": \"lambda_handler:8\",\n        \"message\": \"Log with context\",\n        \"timestamp\": \"2024-03-21T10:30:00.123Z\",\n        \"service\": \"example_service\",\n        \"user_id\": \"123\",\n        \"operation\": \"process\"\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"lambda_handler:10\",\n        \"message\": \"Log without context\",\n        \"timestamp\": \"2024-03-21T10:30:00.124Z\",\n        \"service\": \"example_service\"\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/logger/#ephemeral-metadata",
            "title": "ephemeral metadata",
            "text": "<p>You can pass an arbitrary number of keyword arguments (kwargs) to all log level's methods, e.g. <code>logger.info, logger.warning</code>.</p> <p>Two common use cases for this feature is to enrich log statements with additional metadata, or only add certain keys conditionally.</p> <p>Any keyword argument added will not be persisted in subsequent messages.</p> append_keys_kwargs.pyappend_keys_kwargs_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.info(\"Collecting payment\", request_id=\"1123\")\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"location\": \"collect.handler:8\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2022-11-26 11:47:12,494+0000\",\n    \"service\": \"payment\",\n    \"request_id\": \"1123\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#extra-parameter",
            "title": "extra parameter",
            "text": "<p>Extra parameter is available for all log levels' methods, as implemented in the standard logging library - e.g. <code>logger.info, logger.warning</code>.</p> <p>It accepts any dictionary, and all keyword arguments will be added as part of the root structure of the logs for that log statement.</p> <p>Any keyword argument added using <code>extra</code> will not be persisted in subsequent messages.</p> append_keys_extra.pyappend_keys_extra_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    fields = {\"request_id\": \"1123\"}\n    logger.info(\"Collecting payment\", extra=fields)\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"location\": \"collect.handler:9\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n    \"service\": \"payment\",\n    \"request_id\": \"1123\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#removing-additional-keys",
            "title": "Removing additional keys",
            "text": "<p>You can remove additional keys using either mechanism:</p> <ul> <li>Remove new keys across all future log messages via <code>remove_keys</code> method</li> <li>Remove keys persist across all future logs in a specific thread via <code>thread_safe_remove_keys</code> method. Check Working with thread-safe keys section.</li> </ul> Danger <p>Keys added by <code>append_keys</code> can only be removed by <code>remove_keys</code> and thread-local keys added by <code>thread_safe_append_keys</code> can only be removed by <code>thread_safe_remove_keys</code> or <code>thread_safe_clear_keys</code>. Thread-local and normal logger keys are distinct values and can't be manipulated interchangeably.</p>"
        },
        {
            "location": "core/logger/#remove_keys-method",
            "title": "remove_keys method",
            "text": "<p>You can remove any additional key from Logger state using <code>remove_keys</code>.</p> remove_keys.pyremove_keys_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.append_keys(sample_key=\"value\")\n    logger.info(\"Collecting payment\")\n\n    logger.remove_keys([\"sample_key\"])\n    logger.info(\"Collecting payment without sample key\")\n\n    return \"hello world\"\n</code></pre> <pre><code>[\n    {\n        \"level\": \"INFO\",\n        \"location\": \"collect.handler:9\",\n        \"message\": \"Collecting payment\",\n        \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n        \"service\": \"payment\",\n        \"sample_key\": \"value\"\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"collect.handler:12\",\n        \"message\": \"Collecting payment without sample key\",\n        \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n        \"service\": \"payment\"\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/logger/#clearing-all-state",
            "title": "Clearing all state",
            "text": ""
        },
        {
            "location": "core/logger/#decorator-with-clear_state",
            "title": "Decorator with clear_state",
            "text": "<p>Logger is commonly initialized in the global scope. Due to Lambda Execution Context reuse, this means that custom keys can be persisted across invocations. If you want all custom keys to be deleted, you can use <code>clear_state=True</code> param in <code>inject_lambda_context</code> decorator.</p> Tip: When is this useful? <p>It is useful when you add multiple custom keys conditionally, instead of setting a default <code>None</code> value if not present. Any key with <code>None</code> value is automatically removed by Logger.</p> Danger: This can have unintended side effects if you use Layers <p>Lambda Layers code is imported before the Lambda handler. When a Lambda function starts, it first imports and executes all code in the Layers (including any global scope code) before proceeding to the function's own code.</p> <p>This means that <code>clear_state=True</code> will instruct Logger to remove any keys previously added before Lambda handler execution proceeds.</p> <p>You can either avoid running any code as part of Lambda Layers global scope, or override keys with their latest value as part of handler's execution.</p> clear_state.pyclear_state_event_one.jsonclear_state_event_two.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context(clear_state=True)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    if event.get(\"special_key\"):\n        # Should only be available in the first request log\n        # as the second request doesn't contain `special_key`\n        logger.append_keys(debugging_key=\"value\")\n\n    logger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"location\": \"collect.handler:10\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n    \"service\": \"payment\",\n    \"special_key\": \"debug_key\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"location\": \"collect.handler:10\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n    \"service\": \"payment\",\n    \"cold_start\": false,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#clear_state-method",
            "title": "clear_state method",
            "text": "<p>You can call <code>clear_state()</code> as a method explicitly within your code to clear appended keys at any point during the execution of your Lambda invocation.</p> clear_state_method.pyOutput before clear_state()Output after clear_state() <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger(service=\"payment\", level=\"DEBUG\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    try:\n        logger.append_keys(order_id=\"12345\")\n        logger.info(\"Starting order processing\")\n    finally:\n        logger.info(\"Final state before clearing\")\n        logger.clear_state()\n        logger.info(\"State after clearing - only show default keys\")\n    return \"Completed\"\n</code></pre> <pre><code>{\n    \"logs\": [\n        {\n            \"level\": \"INFO\",\n            \"location\": \"lambda_handler:122\",\n            \"message\": \"Starting order processing\",\n            \"timestamp\": \"2025-01-30 13:56:03,157-0300\",\n            \"service\": \"payment\",\n            \"order_id\": \"12345\"\n        },\n        {\n            \"level\": \"INFO\",\n            \"location\": \"lambda_handler:124\",\n            \"message\": \"Final state before clearing\",\n            \"timestamp\": \"2025-01-30 13:56:03,157-0300\",\n            \"service\": \"payment\",\n            \"order_id\": \"12345\"\n        }\n    ]\n}\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"location\": \"lambda_handler:126\",\n    \"message\": \"State after clearing - only show default keys\",\n    \"timestamp\": \"2025-01-30 13:56:03,158-0300\",\n    \"service\": \"payment\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#accessing-currently-configured-keys",
            "title": "Accessing currently configured keys",
            "text": "<p>You can view all currently configured keys from the Logger state using the <code>get_current_keys()</code> method. This method is useful when you need to avoid overwriting keys that are already configured.</p> get_current_keys.py <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.info(\"Collecting payment\")\n\n    if \"order\" not in logger.get_current_keys():\n        logger.append_keys(order=event.get(\"order\"))\n\n    return \"hello world\"\n</code></pre> Info <p>For thread-local additional logging keys, use <code>get_current_thread_keys</code> instead</p>"
        },
        {
            "location": "core/logger/#log-levels",
            "title": "Log levels",
            "text": "<p>The default log level is <code>INFO</code>. It can be set using the <code>level</code> constructor option, <code>setLevel()</code> method or by using the <code>POWERTOOLS_LOG_LEVEL</code> environment variable.</p> <p>We support the following log levels:</p> Level Numeric value Standard logging <code>DEBUG</code> 10 <code>logging.DEBUG</code> <code>INFO</code> 20 <code>logging.INFO</code> <code>WARNING</code> 30 <code>logging.WARNING</code> <code>ERROR</code> 40 <code>logging.ERROR</code> <code>CRITICAL</code> 50 <code>logging.CRITICAL</code> <p>If you want to access the numeric value of the current log level, you can use the <code>log_level</code> property. For example, if the current log level is <code>INFO</code>, <code>logger.log_level</code> property will return <code>20</code>.</p> setting_log_level_constructor.pysetting_log_level_programmatically.py <pre><code>from aws_lambda_powertools import Logger\n\nlogger = Logger(level=\"ERROR\")\n\nprint(logger.log_level)  # returns 40 (ERROR)\n</code></pre> <pre><code>from aws_lambda_powertools import Logger\n\nlogger = Logger()\n\n# print default log level\nprint(logger.log_level)  # returns 20 (INFO)\n\n# Setting programmatic log level\nlogger.setLevel(\"DEBUG\")\n\n# print new log level\nprint(logger.log_level)  # returns 10 (DEBUG)\n</code></pre>"
        },
        {
            "location": "core/logger/#aws-lambda-advanced-logging-controls-alc",
            "title": "AWS Lambda Advanced Logging Controls (ALC)",
            "text": "<p>When is it useful?</p> <p>When you want to set a logging policy to drop informational or verbose logs for one or all AWS Lambda functions, regardless of runtime and logger used.</p> <p>With AWS Lambda Advanced Logging Controls (ALC), you can enforce a minimum log level that Lambda will accept from your application code.</p> <p>When enabled, you should keep <code>Logger</code> and ALC log level in sync to avoid data loss.</p> <p>Here's a sequence diagram to demonstrate how ALC will drop both <code>INFO</code> and <code>DEBUG</code> logs emitted from <code>Logger</code>, when ALC log level is stricter than <code>Logger</code>.</p> <pre><code>sequenceDiagram\n    title Lambda ALC allows WARN logs only\n    participant Lambda service\n    participant Lambda function\n    participant Application Logger\n\n    Note over Lambda service: AWS_LAMBDA_LOG_LEVEL=\"WARN\"\n    Note over Application Logger: POWERTOOLS_LOG_LEVEL=\"DEBUG\"\n\n    Lambda service-&gt;&gt;Lambda function: Invoke (event)\n    Lambda function-&gt;&gt;Lambda function: Calls handler\n    Lambda function-&gt;&gt;Application Logger: logger.error(\"Something happened\")\n    Lambda function--&gt;&gt;Application Logger: logger.debug(\"Something happened\")\n    Lambda function--&gt;&gt;Application Logger: logger.info(\"Something happened\")\n    Lambda service--xLambda service: DROP INFO and DEBUG logs\n    Lambda service-&gt;&gt;CloudWatch Logs: Ingest error logs</code></pre> <p>Priority of log level settings in Powertools for AWS Lambda</p> <p>We prioritise log level settings in this order:</p> <ol> <li><code>AWS_LAMBDA_LOG_LEVEL</code> environment variable</li> <li>Explicit log level in <code>Logger</code> constructor, or by calling the <code>logger.setLevel()</code> method</li> <li><code>POWERTOOLS_LOG_LEVEL</code> environment variable</li> </ol> <p>If you set <code>Logger</code> level lower than ALC, we will emit a warning informing you that your messages will be discarded by Lambda.</p> <p>NOTE</p> <p>With ALC enabled, we are unable to increase the minimum log level below the <code>AWS_LAMBDA_LOG_LEVEL</code> environment variable value, see AWS Lambda service documentation for more details.</p>"
        },
        {
            "location": "core/logger/#logging-exceptions",
            "title": "Logging exceptions",
            "text": "<p>Use <code>logger.exception</code> method to log contextual information about exceptions. Logger will include <code>exception_name</code> and <code>exception</code> keys to aid troubleshooting and error enumeration.</p> Tip <p>You can use your preferred Log Analytics tool to enumerate and visualize exceptions across all your services using <code>exception_name</code> key.</p> logging_exceptions.pylogging_exceptions_output.json <pre><code>import requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nENDPOINT = \"http://httpbin.org/status/500\"\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    try:\n        ret = requests.get(ENDPOINT)\n        ret.raise_for_status()\n    except requests.HTTPError as e:\n        logger.exception(\"Received a HTTP 5xx error\")\n        raise RuntimeError(\"Unable to fullfil request\") from e\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n    \"level\": \"ERROR\",\n    \"location\": \"collect.handler:15\",\n    \"message\": \"Received a HTTP 5xx error\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n    \"service\": \"payment\",\n    \"exception_name\": \"RuntimeError\",\n    \"exception\": \"Traceback (most recent call last):\\n  File \\\"&lt;input&gt;\\\", line 2, in &lt;module&gt; RuntimeError: Unable to fullfil request\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#uncaught-exceptions",
            "title": "Uncaught exceptions",
            "text": "<p>CAUTION: some users reported a problem that causes this functionality not to work in the Lambda runtime. We recommend that you don't use this feature for the time being.</p> <p>Logger can optionally log uncaught exceptions by setting <code>log_uncaught_exceptions=True</code> at initialization.</p> <p>Logger will replace any exception hook previously registered via sys.excepthook.</p> What are uncaught exceptions? <p>It's any raised exception that wasn't handled by the <code>except</code> statement, leading a Python program to a non-successful exit.</p> <p>They are typically raised intentionally to signal a problem (<code>raise ValueError</code>), or a propagated exception from elsewhere in your code that you didn't handle it willingly or not (<code>KeyError</code>, <code>jsonDecoderError</code>, etc.).</p> logging_uncaught_exceptions.pylogging_uncaught_exceptions_output.json <pre><code>import requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nENDPOINT = \"http://httpbin.org/status/500\"\nlogger = Logger(log_uncaught_exceptions=True)\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    ret = requests.get(ENDPOINT)\n    # HTTP 4xx/5xx status will lead to requests.HTTPError\n    # Logger will log this exception before this program exits non-successfully\n    ret.raise_for_status()\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n    \"level\": \"ERROR\",\n    \"location\": \"log_uncaught_exception_hook:756\",\n    \"message\": \"500 Server Error: INTERNAL SERVER ERROR for url: http://httpbin.org/status/500\",\n    \"timestamp\": \"2022-11-16 13:51:29,198+0000\",\n    \"service\": \"payment\",\n    \"exception\": \"Traceback (most recent call last):\\n  File \\\"&lt;input&gt;\\\", line 52, in &lt;module&gt;\\n    handler({}, {})\\n  File \\\"&lt;input&gt;\\\", line 17, in handler\\n    ret.raise_for_status()\\n  File \\\"&lt;input&gt;/lib/python3.9/site-packages/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\nrequests.exceptions.HTTPError: 500 Server Error: INTERNAL SERVER ERROR for url: http://httpbin.org/status/500\",\n    \"exception_name\": \"HTTPError\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#stack-trace-logging",
            "title": "Stack trace logging",
            "text": "<p>By default, the Logger will automatically include the full stack trace in JSON format when using <code>logger.exception</code>. If you want to disable this feature, set <code>serialize_stacktrace=False</code> during initialization.\"</p> logging_stacktrace.pylogging_stacktrace_output.json <pre><code>import requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nENDPOINT = \"http://httpbin.org/status/500\"\nlogger = Logger(serialize_stacktrace=True)\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    try:\n        ret = requests.get(ENDPOINT)\n        ret.raise_for_status()\n    except requests.HTTPError as e:\n        logger.exception(e)\n        raise RuntimeError(\"Unable to fullfil request\") from e\n\n    return \"hello world\"\n</code></pre> <pre><code>{\n    \"level\":\"ERROR\",\n    \"location\":\"lambda_handler:16\",\n    \"message\":\"500 Server Error: INTERNAL SERVER ERROR for url: http://httpbin.org/status/500\",\n    \"timestamp\":\"2023-10-09 17:47:50,191+0000\",\n    \"service\":\"service_undefined\",\n    \"exception\":\"Traceback (most recent call last):\\n  File \\\"/var/task/app.py\\\", line 14, in lambda_handler\\n    ret.raise_for_status()\\n  File \\\"/var/task/requests/models.py\\\", line 1021, in raise_for_status\\n    raise HTTPError(http_error_msg, response=self)\\nrequests.exceptions.HTTPError: 500 Server Error: INTERNAL SERVER ERROR for url: http://httpbin.org/status/500\",\n    \"exception_name\":\"HTTPError\",\n    \"stack_trace\":{\n       \"type\":\"HTTPError\",\n       \"value\":\"500 Server Error: INTERNAL SERVER ERROR for url: http://httpbin.org/status/500\",\n       \"module\":\"requests.exceptions\",\n       \"frames\":[\n          {\n             \"file\":\"/var/task/app.py\",\n             \"line\":14,\n             \"function\":\"lambda_handler\",\n             \"statement\":\"ret.raise_for_status()\"\n          },\n          {\n             \"file\":\"/var/task/requests/models.py\",\n             \"line\":1021,\n             \"function\":\"raise_for_status\",\n             \"statement\":\"raise HTTPError(http_error_msg, response=self)\"\n          }\n       ]\n    }\n }\n</code></pre>"
        },
        {
            "location": "core/logger/#date-formatting",
            "title": "Date formatting",
            "text": "<p>Logger uses Python's standard logging date format with the addition of timezone: <code>2021-05-03 11:47:12,494+0000</code>.</p> <p>You can easily change the date format using one of the following parameters:</p> <ul> <li><code>datefmt</code>. You can pass any strftime format codes. Use <code>%F</code> if you need milliseconds.</li> <li><code>use_rfc3339</code>. This flag will use a format compliant with both RFC3339 and ISO8601: <code>2022-10-27T16:27:43.738+00:00</code></li> </ul> Prefer using datetime string formats? <p>Use <code>use_datetime_directive</code> flag along with <code>datefmt</code> to instruct Logger to use <code>datetime</code> instead of <code>time.strftime</code>.</p> date_formatting.pydate_formatting_output.json <pre><code>from aws_lambda_powertools import Logger\n\ndate_format = \"%m/%d/%Y %I:%M:%S %p\"\n\nlogger = Logger(service=\"payment\", use_rfc3339=True)\nlogger.info(\"Collecting payment\")\n\nlogger_custom_format = Logger(service=\"loyalty\", datefmt=date_format)\nlogger_custom_format.info(\"Calculating points\")\n</code></pre> <pre><code>[\n    {\n        \"level\": \"INFO\",\n        \"location\": \"&lt;module&gt;:6\",\n        \"message\": \"Collecting payment\",\n        \"timestamp\": \"2022-10-28T14:35:03.210+00:00\",\n        \"service\": \"payment\"\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"&lt;module&gt;:9\",\n        \"message\": \"Calculating points\",\n        \"timestamp\": \"10/28/2022 02:35:03 PM\",\n        \"service\": \"loyalty\"\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/logger/#environment-variables",
            "title": "Environment variables",
            "text": "<p>The following environment variables are available to configure Logger at a global scope:</p> Setting Description Environment variable Default Event Logging Whether to log the incoming event. <code>POWERTOOLS_LOGGER_LOG_EVENT</code> <code>false</code> Debug Sample Rate Sets the debug log sampling. <code>POWERTOOLS_LOGGER_SAMPLE_RATE</code> <code>0</code> Disable Deduplication Disables log deduplication filter protection to use Pytest Live Log feature. <code>POWERTOOLS_LOG_DEDUPLICATION_DISABLED</code> <code>false</code> TZ Sets timezone when using Logger, e.g., <code>US/Eastern</code>. Timezone is defaulted to UTC when <code>TZ</code> is not set <code>TZ</code> <code>None</code> (UTC) <p><code>POWERTOOLS_LOGGER_LOG_EVENT</code> can also be set on a per-method basis, and <code>POWERTOOLS_LOGGER_SAMPLE_RATE</code> on a per-instance basis. These parameter values will override the environment variable value.</p>"
        },
        {
            "location": "core/logger/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/logger/#buffering-logs",
            "title": "Buffering logs",
            "text": "<p>Log buffering enables you to buffer logs for a specific request or invocation. Enable log buffering by passing <code>logger_buffer</code> when initializing a Logger instance. You can buffer logs at the <code>WARNING</code>, <code>INFO</code> or <code>DEBUG</code> level, and flush them automatically on error or manually as needed.</p> <p>This is useful when you want to reduce the number of log messages emitted while still having detailed logs when needed, such as when troubleshooting issues.</p> getting_started_with_buffering_logs.py <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.buffer import LoggerBufferConfig\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger_buffer_config = LoggerBufferConfig(max_bytes=20480, flush_on_error_log=True)\nlogger = Logger(level=\"INFO\", buffer_config=logger_buffer_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    logger.debug(\"a debug log\")  # this is buffered\n    logger.info(\"an info log\")  # this is not buffered\n\n    # do stuff\n\n    logger.flush_buffer()\n</code></pre>"
        },
        {
            "location": "core/logger/#configuring-the-buffer",
            "title": "Configuring the buffer",
            "text": "<p>When configuring log buffering, you have options to fine-tune how logs are captured, stored, and emitted. You can configure the following parameters in the <code>LoggerBufferConfig</code> constructor:</p> Parameter Description Configuration <code>max_bytes</code> Maximum size of the log buffer in bytes <code>int</code> (default: 20480 bytes) <code>buffer_at_verbosity</code> Minimum log level to buffer <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code> <code>flush_on_error_log</code> Automatically flush buffer when an error occurs <code>True</code> (default), <code>False</code> <p>When <code>flush_on_error_log</code> is enabled, it automatically flushes for <code>logger.exception()</code>, <code>logger.error()</code>, and <code>logger.critical()</code> statements.</p> working_with_buffering_logs_different_levels.pyworking_with_buffering_logs_disable_on_error.py <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.buffer import LoggerBufferConfig\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger_buffer_config = LoggerBufferConfig(buffer_at_verbosity=\"WARNING\")  # (1)!\nlogger = Logger(level=\"INFO\", buffer_config=logger_buffer_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    logger.warning(\"a warning log\")  # this is buffered\n    logger.info(\"an info log\")  # this is buffered\n    logger.debug(\"a debug log\")  # this is buffered\n\n    # do stuff\n\n    logger.flush_buffer()\n</code></pre> <ol> <li>Setting <code>minimum_log_level=\"WARNING\"</code> configures log buffering for <code>WARNING</code> and lower severity levels (<code>INFO</code>, <code>DEBUG</code>).</li> </ol> <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.buffer import LoggerBufferConfig\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger_buffer_config = LoggerBufferConfig(flush_on_error_log=False)  # (1)!\nlogger = Logger(level=\"INFO\", buffer_config=logger_buffer_config)\n\n\nclass MyException(Exception):\n    pass\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    logger.debug(\"a debug log\")  # this is buffered\n\n    # do stuff\n\n    try:\n        raise MyException\n    except MyException as error:\n        logger.error(\"An error ocurrend\", exc_info=error)  # Logs won't be flushed here\n\n    # Need to flush logs manually\n    logger.flush_buffer()\n</code></pre> <ol> <li>Disabling <code>flush_on_error_log</code> will not flush the buffer when logging an error. This is useful when you want to control when the buffer is flushed by calling the <code>logger.flush_buffer()</code> method.</li> </ol>"
        },
        {
            "location": "core/logger/#flushing-on-exceptions",
            "title": "Flushing on exceptions",
            "text": "<p>Use the <code>@logger.inject_lambda_context</code> decorator to automatically flush buffered logs when an exception is raised in your Lambda function. This is done by setting the <code>flush_buffer_on_uncaught_error</code> option to <code>True</code> in the decorator.</p> working_with_buffering_logs_when_raise_exception.py <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.buffer import LoggerBufferConfig\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger_buffer_config = LoggerBufferConfig(max_bytes=20480, flush_on_error_log=False)\nlogger = Logger(level=\"INFO\", buffer_config=logger_buffer_config)\n\n\nclass MyException(Exception):\n    pass\n\n\n@logger.inject_lambda_context(flush_buffer_on_uncaught_error=True)\ndef lambda_handler(event: dict, context: LambdaContext):\n    logger.debug(\"a debug log\")  # this is buffered\n\n    # do stuff\n\n    raise MyException  # Logs will be flushed here\n</code></pre>"
        },
        {
            "location": "core/logger/#reutilizing-same-logger-instance",
            "title": "Reutilizing same logger instance",
            "text": "<p>If you are using log buffering, we recommend sharing the same log instance across your code/modules, so that the same buffer is also shared. Doing this you can centralize logger instance creation and prevent buffer configuration drift.</p> <p>Buffer Inheritance</p> <p>Loggers created with the same <code>service_name</code> automatically inherit the buffer configuration from the first initialized logger with a buffer configuration.</p> <p>Child loggers instances inherit their parent's buffer configuration but maintain a separate buffer.</p> working_with_buffering_logs_creating_instance.pyworking_with_buffering_logs_reusing_handler.pyworking_with_buffering_logs_reusing_function.py <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.buffer import LoggerBufferConfig\n\nlogger_buffer_config = LoggerBufferConfig(max_bytes=20480, buffer_at_verbosity=\"WARNING\")\nlogger = Logger(level=\"INFO\", buffer_config=logger_buffer_config)\n</code></pre> <pre><code>from working_with_buffering_logs_creating_instance import logger  # reusing same instance\nfrom working_with_buffering_logs_reusing_function import my_function\n\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    logger.debug(\"a debug log\")  # this is buffered\n\n    my_function()\n\n    logger.flush_buffer()\n</code></pre> <pre><code>from working_with_buffering_logs_creating_instance import logger  # reusing same instance\n\n\ndef my_function():\n    logger.debug(\"This will be buffered\")\n    # do stuff\n</code></pre>"
        },
        {
            "location": "core/logger/#buffering-workflows",
            "title": "Buffering workflows",
            "text": ""
        },
        {
            "location": "core/logger/#manual-flush",
            "title": "Manual flush",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Logger\n    participant CloudWatch\n    Client-&gt;&gt;Lambda: Invoke Lambda\n    Lambda-&gt;&gt;Logger: Initialize with DEBUG level buffering\n    Logger--&gt;&gt;Lambda: Logger buffer ready\n    Lambda-&gt;&gt;Logger: logger.debug(\"First debug log\")\n    Logger--&gt;&gt;Logger: Buffer first debug log\n    Lambda-&gt;&gt;Logger: logger.info(\"Info log\")\n    Logger-&gt;&gt;CloudWatch: Directly log info message\n    Lambda-&gt;&gt;Logger: logger.debug(\"Second debug log\")\n    Logger--&gt;&gt;Logger: Buffer second debug log\n    Lambda-&gt;&gt;Logger: logger.flush_buffer()\n    Logger-&gt;&gt;CloudWatch: Emit buffered logs to stdout\n    Lambda-&gt;&gt;Client: Return execution result</code></pre> Flushing buffer manually </p>"
        },
        {
            "location": "core/logger/#flushing-when-logging-an-error",
            "title": "Flushing when logging an error",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Logger\n    participant CloudWatch\n    Client-&gt;&gt;Lambda: Invoke Lambda\n    Lambda-&gt;&gt;Logger: Initialize with DEBUG level buffering\n    Logger--&gt;&gt;Lambda: Logger buffer ready\n    Lambda-&gt;&gt;Logger: logger.debug(\"First log\")\n    Logger--&gt;&gt;Logger: Buffer first debug log\n    Lambda-&gt;&gt;Logger: logger.debug(\"Second log\")\n    Logger--&gt;&gt;Logger: Buffer second debug log\n    Lambda-&gt;&gt;Logger: logger.debug(\"Third log\")\n    Logger--&gt;&gt;Logger: Buffer third debug log\n    Lambda-&gt;&gt;Lambda: Exception occurs\n    Lambda-&gt;&gt;Logger: logger.error(\"Error details\")\n    Logger-&gt;&gt;CloudWatch: Emit buffered debug logs\n    Logger-&gt;&gt;CloudWatch: Emit error log\n    Lambda-&gt;&gt;Client: Raise exception</code></pre> Flushing buffer when an error happens </p>"
        },
        {
            "location": "core/logger/#flushing-on-exception",
            "title": "Flushing on exception",
            "text": "<p>This works only when decorating your Lambda handler with the decorator <code>@logger.inject_lambda_context(flush_buffer_on_uncaught_error=True)</code></p> <p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Logger\n    participant CloudWatch\n    Client-&gt;&gt;Lambda: Invoke Lambda\n    Lambda-&gt;&gt;Logger: Using decorator\n    Logger--&gt;&gt;Lambda: Logger context injected\n    Lambda-&gt;&gt;Logger: logger.debug(\"First log\")\n    Logger--&gt;&gt;Logger: Buffer first debug log\n    Lambda-&gt;&gt;Logger: logger.debug(\"Second log\")\n    Logger--&gt;&gt;Logger: Buffer second debug log\n    Lambda-&gt;&gt;Lambda: Uncaught Exception\n    Lambda-&gt;&gt;CloudWatch: Automatically emit buffered debug logs\n    Lambda-&gt;&gt;Client: Raise uncaught exception</code></pre> Flushing buffer when an uncaught exception happens </p>"
        },
        {
            "location": "core/logger/#buffering-faqs",
            "title": "Buffering FAQs",
            "text": "<ol> <li> <p>Does the buffer persist across Lambda invocations? No, each Lambda invocation has its own buffer. The buffer is initialized when the Lambda function is invoked and is cleared after the function execution completes or when flushed manually.</p> </li> <li> <p>Are my logs buffered during cold starts? No, we never buffer logs during cold starts. This is because we want to ensure that logs emitted during this phase are always available for debugging and monitoring purposes. The buffer is only used during the execution of the Lambda function.</p> </li> <li> <p>How can I prevent log buffering from consuming excessive memory? You can limit the size of the buffer by setting the <code>max_bytes</code> option in the <code>LoggerBufferConfig</code> constructor parameter. This will ensure that the buffer does not grow indefinitely and consume excessive memory.</p> </li> <li> <p>What happens if the log buffer reaches its maximum size? Older logs are removed from the buffer to make room for new logs. This means that if the buffer is full, you may lose some logs if they are not flushed before the buffer reaches its maximum size. When this happens, we emit a warning when flushing the buffer to indicate that some logs have been dropped.</p> </li> <li> <p>How is the log size of a log line calculated? The log size is calculated based on the size of the log line in bytes. This includes the size of the log message, any exception (if present), the log line location, additional keys, and the timestamp.</p> </li> <li> <p>What timestamp is used when I flush the logs? The timestamp preserves the original time when the log record was created. If you create a log record at 11:00:10 and flush it at 11:00:25, the log line will retain its original timestamp of 11:00:10.</p> </li> <li> <p>What happens if I try to add a log line that is bigger than max buffer size? The log will be emitted directly to standard output and not buffered. When this happens, we emit a warning to indicate that the log line was too big to be buffered.</p> </li> <li> <p>What happens if Lambda times out without flushing the buffer? Logs that are still in the buffer will be lost.</p> </li> <li> <p>Do child loggers inherit the buffer?  No, child loggers do not inherit the buffer from their parent logger but only the buffer configuration. This means that if you create a child logger, it will have its own buffer and will not share the buffer with the parent logger.</p> </li> </ol>"
        },
        {
            "location": "core/logger/#built-in-correlation-id-expressions",
            "title": "Built-in Correlation ID expressions",
            "text": "<p>You can use any of the following built-in JMESPath expressions as part of inject_lambda_context decorator.</p> Note: Any object key named with <code>-</code> must be escaped <p>For example, <code>request.headers.\"x-amzn-trace-id\"</code>.</p> Name Expression Description API_GATEWAY_REST <code>\"requestContext.requestId\"</code> API Gateway REST API request ID API_GATEWAY_HTTP <code>\"requestContext.requestId\"</code> API Gateway HTTP API request ID APPSYNC_RESOLVER <code>'request.headers.\"x-amzn-trace-id\"'</code> AppSync X-Ray Trace ID APPLICATION_LOAD_BALANCER <code>'headers.\"x-amzn-trace-id\"'</code> ALB X-Ray Trace ID EVENT_BRIDGE <code>\"id\"</code> EventBridge Event ID"
        },
        {
            "location": "core/logger/#working-with-thread-safe-keys",
            "title": "Working with thread-safe keys",
            "text": ""
        },
        {
            "location": "core/logger/#appending-thread-safe-additional-keys",
            "title": "Appending thread-safe additional keys",
            "text": "<p>You can append your own thread-local keys in your existing Logger via the <code>thread_safe_append_keys</code> method</p> thread_safe_append_keys.pythread_safe_append_keys_output.json <pre><code>import threading\nfrom typing import List\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef threaded_func(order_id: str):\n    logger.thread_safe_append_keys(order_id=order_id, thread_id=threading.get_ident())\n    logger.info(\"Collecting payment\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    order_ids: List[str] = event[\"order_ids\"]\n\n    threading.Thread(target=threaded_func, args=(order_ids[0],)).start()\n    threading.Thread(target=threaded_func, args=(order_ids[1],)).start()\n\n    return \"hello world\"\n</code></pre> <pre><code>[\n    {\n        \"level\": \"INFO\",\n        \"location\": \"threaded_func:11\",\n        \"message\": \"Collecting payment\",\n        \"timestamp\": \"2024-09-08 03:04:11,316-0400\",\n        \"service\": \"payment\",\n        \"order_id\": \"order_id_value_1\",\n        \"thread_id\": \"3507187776085958\"\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"threaded_func:11\",\n        \"message\": \"Collecting payment\",\n        \"timestamp\": \"2024-09-08 03:04:11,316-0400\",\n        \"service\": \"payment\",\n        \"order_id\": \"order_id_value_2\",\n        \"thread_id\": \"140718447808512\"\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/logger/#removing-thread-safe-additional-keys",
            "title": "Removing thread-safe additional keys",
            "text": "<p>You can remove any additional thread-local keys from Logger using either <code>thread_safe_remove_keys</code> or <code>thread_safe_clear_keys</code>.</p> <p>Use the <code>thread_safe_remove_keys</code> method to remove a list of thread-local keys that were previously added using the <code>thread_safe_append_keys</code> method.</p> thread_safe_remove_keys.pythread_safe_remove_keys_output.json <pre><code>import threading\nfrom typing import List\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef threaded_func(order_id: str):\n    logger.thread_safe_append_keys(order_id=order_id, thread_id=threading.get_ident())\n    logger.info(\"Collecting payment\")\n    logger.thread_safe_remove_keys([\"order_id\"])\n    logger.info(\"Exiting thread\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    order_ids: List[str] = event[\"order_ids\"]\n\n    threading.Thread(target=threaded_func, args=(order_ids[0],)).start()\n    threading.Thread(target=threaded_func, args=(order_ids[1],)).start()\n\n    return \"hello world\"\n</code></pre> <pre><code>[\n    {\n        \"level\": \"INFO\",\n        \"location\": \"threaded_func:11\",\n        \"message\": \"Collecting payment\",\n        \"timestamp\": \"2024-09-08 12:26:10,648-0400\",\n        \"service\": \"payment\",\n        \"order_id\": \"order_id_value_1\",\n        \"thread_id\": 140077070292544\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"threaded_func:11\",\n        \"message\": \"Collecting payment\",\n        \"timestamp\": \"2024-09-08 12:26:10,649-0400\",\n        \"service\": \"payment\",\n        \"order_id\": \"order_id_value_2\",\n        \"thread_id\": 140077061899840\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"threaded_func:13\",\n        \"message\": \"Exiting thread\",\n        \"timestamp\": \"2024-09-08 12:26:10,649-0400\",\n        \"service\": \"payment\",\n        \"thread_id\": 140077070292544\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"threaded_func:13\",\n        \"message\": \"Exiting thread\",\n        \"timestamp\": \"2024-09-08 12:26:10,649-0400\",\n        \"service\": \"payment\",\n        \"thread_id\": 140077061899840\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/logger/#clearing-thread-safe-additional-keys",
            "title": "Clearing thread-safe additional keys",
            "text": "<p>Use the <code>thread_safe_clear_keys</code> method to remove all thread-local keys that were previously added using the <code>thread_safe_append_keys</code> method.</p> thread_safe_clear_keys.pythread_safe_clear_keys_output.json <pre><code>import threading\nfrom typing import List\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef threaded_func(order_id: str):\n    logger.thread_safe_append_keys(order_id=order_id, thread_id=threading.get_ident())\n    logger.info(\"Collecting payment\")\n    logger.thread_safe_clear_keys()\n    logger.info(\"Exiting thread\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    order_ids: List[str] = event[\"order_ids\"]\n\n    threading.Thread(target=threaded_func, args=(order_ids[0],)).start()\n    threading.Thread(target=threaded_func, args=(order_ids[1],)).start()\n\n    return \"hello world\"\n</code></pre> <pre><code>[\n    {\n        \"level\": \"INFO\",\n        \"location\": \"threaded_func:11\",\n        \"message\": \"Collecting payment\",\n        \"timestamp\": \"2024-09-08 12:26:10,648-0400\",\n        \"service\": \"payment\",\n        \"order_id\": \"order_id_value_1\",\n        \"thread_id\": 140077070292544\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"threaded_func:11\",\n        \"message\": \"Collecting payment\",\n        \"timestamp\": \"2024-09-08 12:26:10,649-0400\",\n        \"service\": \"payment\",\n        \"order_id\": \"order_id_value_2\",\n        \"thread_id\": 140077061899840\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"threaded_func:13\",\n        \"message\": \"Exiting thread\",\n        \"timestamp\": \"2024-09-08 12:26:10,649-0400\",\n        \"service\": \"payment\"\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"threaded_func:13\",\n        \"message\": \"Exiting thread\",\n        \"timestamp\": \"2024-09-08 12:26:10,649-0400\",\n        \"service\": \"payment\"\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/logger/#accessing-thread-safe-currently-keys",
            "title": "Accessing thread-safe currently keys",
            "text": "<p>You can view all currently thread-local keys from the Logger state using the <code>thread_safe_get_current_keys()</code> method. This method is useful when you need to avoid overwriting keys that are already configured.</p> thread_safe_get_current_keys.py <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.info(\"Collecting payment\")\n\n    if \"order\" not in logger.thread_safe_get_current_keys():\n        logger.thread_safe_append_keys(order=event.get(\"order\"))\n\n    return \"hello world\"\n</code></pre>"
        },
        {
            "location": "core/logger/#reusing-logger-across-your-code",
            "title": "Reusing Logger across your code",
            "text": "<p>Similar to Tracer, a new instance that uses the same <code>service</code> name will reuse a previous Logger instance.</p> <p>Notice in the CloudWatch Logs output how <code>payment_id</code> appears as expected when logging in <code>collect.py</code>.</p> logger_reuse.pylogger_reuse_payment.pylogger_reuse_output.json <pre><code>from logger_reuse_payment import inject_payment_id\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    inject_payment_id(context=event)\n    logger.info(\"Collecting payment\")\n    return \"hello world\"\n</code></pre> <pre><code>from aws_lambda_powertools import Logger\n\nlogger = Logger()\n\n\ndef inject_payment_id(context):\n    logger.append_keys(payment_id=context.get(\"payment_id\"))\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"location\": \"collect.handler:12\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n    \"service\": \"payment\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n    \"payment_id\": \"968adaae-a211-47af-bda3-eed3ca2c0ed0\"\n}\n</code></pre> Note: About Child Loggers <p>Coming from standard library, you might be used to use <code>logging.getLogger(__name__)</code>. This will create a new instance of a Logger with a different name.</p> <p>In Powertools, you can have the same effect by using <code>child=True</code> parameter: <code>Logger(child=True)</code>. This creates a new Logger instance named after <code>service.&lt;module&gt;</code>. All state changes will be propagated bi-directionally between Child and Parent.</p> <p>For that reason, there could be side effects depending on the order the Child Logger is instantiated, because Child Loggers don't have a handler.</p> <p>For example, if you instantiated a Child Logger and immediately used <code>logger.append_keys/remove_keys/set_correlation_id</code> to update logging state, this might fail if the Parent Logger wasn't instantiated.</p> <p>In this scenario, you can either ensure any calls manipulating state are only called when a Parent Logger is instantiated (example above), or refrain from using <code>child=True</code> parameter altogether.</p>"
        },
        {
            "location": "core/logger/#sampling-debug-logs",
            "title": "Sampling debug logs",
            "text": "<p>Use sampling when you want to dynamically change your log level to DEBUG based on a percentage of the Lambda function invocations.</p> <p>You can use values ranging from <code>0.0</code> to <code>1</code> (100%) when setting <code>POWERTOOLS_LOGGER_SAMPLE_RATE</code> env var, or <code>sampling_rate</code> parameter in Logger.</p> Tip: When is this useful? <p>Log sampling allows you to capture debug information for a fraction of your requests, helping you diagnose rare or intermittent issues without increasing the overall verbosity of your logs.</p> <p>Example: Imagine an e-commerce checkout process where you want to understand rare payment gateway errors. With 10% sampling, you'll log detailed information for a small subset of transactions, making troubleshooting easier without generating excessive logs.</p> <p>The sampling decision happens automatically with each invocation when using <code>@logger.inject_lambda_context</code> decorator.  When not using the decorator, you're in charge of refreshing it via <code>refresh_sample_rate_calculation</code> method. Skipping both may lead to unexpected sampling results.</p> sampling_debug_logs_with_decorator.pysampling_debug_logs_with_standalone_function.pysampling_debug_logs_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# Sample 10% of debug logs e.g. 0.1\nlogger = Logger(service=\"payment\", sample_rate=0.1)\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext):\n    logger.debug(\"Verifying whether order_id is present\")\n    logger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# Sample 10% of debug logs e.g. 0.1\nlogger = Logger(service=\"payment\", sample_rate=0.1)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    logger.debug(\"Verifying whether order_id is present\")\n    logger.info(\"Collecting payment\")\n\n    logger.refresh_sample_rate_calculation()\n\n    return \"hello world\"\n</code></pre> <pre><code>[\n    {\n        \"level\": \"DEBUG\",\n        \"location\": \"collect.handler:7\",\n        \"message\": \"Verifying whether order_id is present\",\n        \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n        \"service\": \"payment\",\n        \"cold_start\": true,\n        \"function_name\": \"test\",\n        \"function_memory_size\": 128,\n        \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n        \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n        \"sampling_rate\": 0.1\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"collect.handler:7\",\n        \"message\": \"Collecting payment\",\n        \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n        \"service\": \"payment\",\n        \"cold_start\": true,\n        \"function_name\": \"test\",\n        \"function_memory_size\": 128,\n        \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n        \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n        \"sampling_rate\": 0.1\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/logger/#lambdapowertoolsformatter",
            "title": "LambdaPowertoolsFormatter",
            "text": "<p>Logger propagates a few formatting configurations to the built-in <code>LambdaPowertoolsFormatter</code> logging formatter.</p> <p>If you prefer configuring it separately, or you'd want to bring this JSON Formatter to another application, these are the supported settings:</p> Parameter Description Default <code>json_serializer</code> function to serialize <code>obj</code> to a JSON formatted <code>str</code> <code>json.dumps</code> <code>json_deserializer</code> function to deserialize <code>str</code>, <code>bytes</code>, <code>bytearray</code> containing a JSON document to a Python obj <code>json.loads</code> <code>json_default</code> function to coerce unserializable values, when no custom serializer/deserializer is set <code>str</code> <code>datefmt</code> string directives (strftime) to format log timestamp <code>%Y-%m-%d %H:%M:%S,%F%z</code>, where <code>%F</code> is a custom ms directive <code>use_datetime_directive</code> format the <code>datefmt</code> timestamps using <code>datetime</code>, not <code>time</code>  (also supports the custom <code>%F</code> directive for milliseconds) <code>False</code> <code>utc</code> enforce logging timestamp to UTC (ignore <code>TZ</code> environment variable) <code>False</code> <code>log_record_order</code> set order of log keys when logging <code>[\"level\", \"location\", \"message\", \"timestamp\"]</code> <code>kwargs</code> key-value to be included in log messages <code>None</code> Info <p>When <code>POWERTOOLS_DEV</code> env var is present and set to <code>\"true\"</code>, Logger's default serializer (<code>json.dumps</code>) will pretty-print log messages for easier readability.</p> Pre-configuring Powertools for AWS Lambda (Python) Formatter<pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.formatter import LambdaPowertoolsFormatter\n\n# NOTE: Check docs for all available options\n# https://docs.powertools.aws.dev/lambda/python/latest/core/logger/#lambdapowertoolsformatter\n\nformatter = LambdaPowertoolsFormatter(utc=True, log_record_order=[\"message\"])\nlogger = Logger(service=\"example\", logger_formatter=formatter)\n</code></pre>"
        },
        {
            "location": "core/logger/#observability-providers",
            "title": "Observability providers",
            "text": "<p>In this context, an observability provider is an AWS Lambda Partner offering a platform for logging, metrics, traces, etc.</p> <p>You can send logs to the observability provider of your choice via Lambda Extensions. In most cases, you shouldn't need any custom Logger configuration, and logs will be shipped async without any performance impact.</p>"
        },
        {
            "location": "core/logger/#built-in-formatters",
            "title": "Built-in formatters",
            "text": "<p>In rare circumstances where JSON logs are not parsed correctly by your provider, we offer built-in formatters to make this transition easier.</p> Provider Formatter Notes Datadog <code>DatadogLogFormatter</code> Modifies default timestamp to use RFC3339 by default <p>You can use import and use them as any other Logger formatter via <code>logger_formatter</code> parameter:</p> Using built-in Logger Formatters<pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.formatters.datadog import DatadogLogFormatter\n\nlogger = Logger(service=\"payment\", logger_formatter=DatadogLogFormatter())\nlogger.info(\"hello\")\n</code></pre>"
        },
        {
            "location": "core/logger/#migrating-from-other-loggers",
            "title": "Migrating from other Loggers",
            "text": "<p>If you're migrating from other Loggers, there are few key points to be aware of: Service parameter, Child Loggers, Overriding Log records, and Logging exceptions.</p>"
        },
        {
            "location": "core/logger/#the-service-parameter",
            "title": "The service parameter",
            "text": "<p>Service is what defines the Logger name, including what the Lambda function is responsible for, or part of (e.g payment service).</p> <p>For Logger, the <code>service</code> is the logging key customers can use to search log operations for one or more functions - For example, search for all errors, or messages like X, where service is payment.</p>"
        },
        {
            "location": "core/logger/#child-loggers",
            "title": "Child Loggers",
            "text": "<p> <pre><code>stateDiagram-v2\n    direction LR\n    Parent: Logger()\n    Child: Logger(child=True)\n    Parent --&gt; Child: bi-directional updates\n    Note right of Child\n        Both have the same service\n    end note</code></pre> </p> <p>For inheritance, Logger uses <code>child</code> parameter to ensure we don't compete with its parents config. We name child Loggers following Python's convention: <code>{service}</code>.<code>{filename}</code>.</p> <p>Changes are bidirectional between parents and loggers. That is, appending a key in a child or parent will ensure both have them. This means, having the same <code>service</code> name is important when instantiating them.</p> logging_inheritance_good.pylogging_inheritance_module.py <pre><code>from logging_inheritance_module import inject_payment_id\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# NOTE: explicit service name matches any new Logger\n# because we're using POWERTOOLS_SERVICE_NAME env var\n# but we could equally use the same string as service value, e.g. \"payment\"\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    inject_payment_id(context=event)\n\n    return \"hello world\"\n</code></pre> <pre><code>from aws_lambda_powertools import Logger\n\nlogger = Logger(child=True)\n\n\ndef inject_payment_id(context):\n    logger.append_keys(payment_id=context.get(\"payment_id\"))\n</code></pre> <p>There are two important side effects when using child loggers:</p> <ol> <li>Service name mismatch. Logging messages will be dropped as child loggers don't have logging handlers.<ul> <li>Solution: use <code>POWERTOOLS_SERVICE_NAME</code> env var. Alternatively, use the same service explicit value.</li> </ul> </li> <li>Changing state before a parent instantiate. Using <code>logger.append_keys</code> or <code>logger.remove_keys</code> without a parent Logger will lead to <code>OrphanedChildLoggerError</code> exception.<ul> <li>Solution: always initialize parent Loggers first. Alternatively, move calls to <code>append_keys</code>/<code>remove_keys</code> from the child at a later stage.</li> </ul> </li> </ol> logging_inheritance_bad.pylogging_inheritance_module.py <pre><code>from logging_inheritance_module import inject_payment_id\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# NOTE: explicit service name differs from Child\n# meaning we will have two Logger instances with different state\n# and an orphan child logger who won't be able to manipulate state\nlogger = Logger(service=\"payment\")\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    inject_payment_id(context=event)\n\n    return \"hello world\"\n</code></pre> <pre><code>from aws_lambda_powertools import Logger\n\nlogger = Logger(child=True)\n\n\ndef inject_payment_id(context):\n    logger.append_keys(payment_id=context.get(\"payment_id\"))\n</code></pre>"
        },
        {
            "location": "core/logger/#overriding-log-records",
            "title": "Overriding Log records",
            "text": "<p>You might want to continue to use the same date formatting style, or override <code>location</code> to display the <code>package.function_name:line_number</code> as you previously had.</p> <p>Logger allows you to either change the format or suppress the following keys at initialization: <code>location</code>, <code>timestamp</code>, <code>xray_trace_id</code>.</p> overriding_log_records.pyoverriding_log_records_output.json <pre><code>from aws_lambda_powertools import Logger\n\nlocation_format = \"[%(funcName)s] %(module)s\"\n\n# override location and timestamp format\nlogger = Logger(service=\"payment\", location=location_format)\nlogger.info(\"Collecting payment\")\n\n# suppress keys with a None value\nlogger_two = Logger(service=\"loyalty\", location=None)\nlogger_two.info(\"Calculating points\")\n</code></pre> <pre><code>[\n    {\n        \"level\": \"INFO\",\n        \"location\": \"[&lt;module&gt;] overriding_log_records\",\n        \"message\": \"Collecting payment\",\n        \"timestamp\": \"2022-10-28 14:40:43,801+0000\",\n        \"service\": \"payment\"\n    },\n    {\n        \"level\": \"INFO\",\n        \"message\": \"Calculating points\",\n        \"timestamp\": \"2022-10-28 14:40:43,801+0000\",\n        \"service\": \"loyalty\"\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/logger/#reordering-log-keys-position",
            "title": "Reordering log keys position",
            "text": "<p>You can change the order of standard Logger keys or any keys that will be appended later at runtime via the <code>log_record_order</code> parameter.</p> reordering_log_keys.pyreordering_log_keys_output.json <pre><code>from aws_lambda_powertools import Logger\n\n# make message as the first key\nlogger = Logger(service=\"payment\", log_record_order=[\"message\"])\n\n# make request_id that will be added later as the first key\nlogger_two = Logger(service=\"order\", log_record_order=[\"request_id\"])\nlogger_two.append_keys(request_id=\"123\")\n\nlogger.info(\"hello world\")\nlogger_two.info(\"hello world\")\n</code></pre> <pre><code>[\n    {\n        \"message\": \"hello world\",\n        \"level\": \"INFO\",\n        \"location\": \"&lt;module&gt;:11\",\n        \"timestamp\": \"2022-06-24 11:25:40,143+0000\",\n        \"service\": \"payment\"\n    },\n    {\n        \"request_id\": \"123\",\n        \"level\": \"INFO\",\n        \"location\": \"&lt;module&gt;:12\",\n        \"timestamp\": \"2022-06-24 11:25:40,144+0000\",\n        \"service\": \"order\",\n        \"message\": \"hello universe\"\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/logger/#setting-timestamp-to-custom-timezone",
            "title": "Setting timestamp to custom Timezone",
            "text": "<p>By default, this Logger and the standard logging library emit records with the default AWS Lambda timestamp in UTC.</p> <p>If you prefer to log in a specific timezone, you can configure it by setting the <code>TZ</code> environment variable. You can do this either as an AWS Lambda environment variable or directly within your Lambda function settings. Click here for a comprehensive list of available Lambda environment variables.</p> Tip <p><code>TZ</code> environment variable will be ignored if <code>utc</code> is set to <code>True</code></p> setting_custom_timezone.pysetting_custom_timezone_output.json <pre><code>import os\nimport time\n\nfrom aws_lambda_powertools import Logger\n\nlogger_in_utc = Logger(service=\"payment\")\nlogger_in_utc.info(\"Logging with default AWS Lambda timezone: UTC time\")\n\nos.environ[\"TZ\"] = \"US/Eastern\"\ntime.tzset()  # (1)!\n\nlogger = Logger(service=\"order\")\nlogger.info(\"Logging with US Eastern timezone\")\n</code></pre> <ol> <li>if you set TZ in your Lambda function, <code>time.tzset()</code> need to be called. You don't need it when setting TZ in AWS Lambda environment variable</li> </ol> <pre><code>[\n    {\n        \"level\":\"INFO\",\n        \"location\":\"&lt;module&gt;:7\",\n        \"message\":\"Logging with default AWS Lambda timezone: UTC time\",\n        \"timestamp\":\"2023-10-09 21:33:55,733+0000\",\n        \"service\":\"payment\"\n    },\n    {\n        \"level\":\"INFO\",\n        \"location\":\"&lt;module&gt;:13\",\n        \"message\":\"Logging with US Eastern timezone\",\n        \"timestamp\":\"2023-10-09 17:33:55,734-0400\",\n        \"service\":\"order\"\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/logger/#custom-function-for-unserializable-values",
            "title": "Custom function for unserializable values",
            "text": "<p>By default, Logger uses <code>str</code> to handle values non-serializable by JSON. You can override this behavior via <code>json_default</code> parameter by passing a Callable:</p> unserializable_values.pyunserializable_values_output.json <pre><code>from datetime import date, datetime\n\nfrom aws_lambda_powertools import Logger\n\n\ndef custom_json_default(value: object) -&gt; str:\n    if isinstance(value, (datetime, date)):\n        return value.isoformat()\n\n    return f\"&lt;non-serializable: {type(value).__name__}&gt;\"\n\n\nclass Unserializable:\n    pass\n\n\nlogger = Logger(service=\"payment\", json_default=custom_json_default)\n\nlogger.info({\"ingestion_time\": datetime.utcnow(), \"serialize_me\": Unserializable()})\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"location\": \"&lt;module&gt;:19\",\n    \"message\": {\n        \"ingestion_time\": \"2022-06-24T10:12:09.526365\",\n        \"serialize_me\": \"&lt;non-serializable: Unserializable&gt;\"\n    },\n    \"timestamp\": \"2022-06-24 12:12:09,526+0000\",\n    \"service\": \"payment\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#bring-your-own-handler",
            "title": "Bring your own handler",
            "text": "<p>By default, Logger uses StreamHandler and logs to standard output. You can override this behavior via <code>logger_handler</code> parameter:</p> Configure Logger to output to a file<pre><code>import logging\nfrom pathlib import Path\n\nfrom aws_lambda_powertools import Logger\n\nlog_file = Path(\"/tmp/log.json\")\nlog_file_handler = logging.FileHandler(filename=log_file)\n\nlogger = Logger(service=\"payment\", logger_handler=log_file_handler)\n\nlogger.info(\"hello world\")\n</code></pre>"
        },
        {
            "location": "core/logger/#bring-your-own-formatter",
            "title": "Bring your own formatter",
            "text": "<p>By default, Logger uses LambdaPowertoolsFormatter that persists its custom structure between non-cold start invocations. There could be scenarios where the existing feature set isn't sufficient to your formatting needs.</p> Info <p>The most common use cases are remapping keys by bringing your existing schema, and redacting sensitive information you know upfront.</p> <p>For these, you can override the <code>serialize</code> method from LambdaPowertoolsFormatter.</p> bring_your_own_formatter.pybring_your_own_formatter_output.json <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.formatter import LambdaPowertoolsFormatter\nfrom aws_lambda_powertools.logging.types import LogRecord\n\n\nclass CustomFormatter(LambdaPowertoolsFormatter):\n    def serialize(self, log: LogRecord) -&gt; str:\n        \"\"\"Serialize final structured log dict to JSON str\"\"\"\n        # in this example, log[\"message\"] is a required field\n        # but we want to remap to \"event\" and delete \"message\", hence mypy ignore checks\n        log[\"event\"] = log.pop(\"message\")  # type: ignore[typeddict-unknown-key,misc]\n        return self.json_serializer(log)\n\n\nlogger = Logger(service=\"payment\", logger_formatter=CustomFormatter())\nlogger.info(\"hello\")\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"location\": \"&lt;module&gt;:16\",\n    \"timestamp\": \"2021-12-30 13:41:53,413+0000\",\n    \"service\": \"payment\",\n    \"event\": \"hello\"\n}\n</code></pre> <p>The <code>log</code> argument is the final log record containing our standard keys, optionally Lambda context keys, and any custom key you might have added via append_keys or the extra parameter.</p> <p>For exceptional cases where you want to completely replace our formatter logic, you can subclass <code>BasePowertoolsFormatter</code>.</p> Warning <p>You will need to implement <code>append_keys</code>, <code>clear_state</code>, override <code>format</code>, and optionally <code>get_current_keys</code>, and <code>remove_keys</code> to keep the same feature set Powertools for AWS Lambda (Python) Logger provides. This also means tracking the added logging keys.</p> bring_your_own_formatter_from_scratch.pybring_your_own_formatter_from_scratch_output.json <pre><code>import json\nimport logging\nfrom typing import Any, Dict, Iterable, List, Optional\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.formatter import BasePowertoolsFormatter\n\n\nclass CustomFormatter(BasePowertoolsFormatter):\n    def __init__(self, log_record_order: Optional[List[str]] = None, *args, **kwargs):\n        self.log_record_order = log_record_order or [\"level\", \"location\", \"message\", \"timestamp\"]\n        self.log_format = dict.fromkeys(self.log_record_order)\n        super().__init__(*args, **kwargs)\n\n    def append_keys(self, **additional_keys):\n        # also used by `inject_lambda_context` decorator\n        self.log_format.update(additional_keys)\n\n    def current_keys(self) -&gt; Dict[str, Any]:\n        return self.log_format\n\n    def remove_keys(self, keys: Iterable[str]):\n        for key in keys:\n            self.log_format.pop(key, None)\n\n    def clear_state(self):\n        self.log_format = dict.fromkeys(self.log_record_order)\n\n    def format(self, record: logging.LogRecord) -&gt; str:  # noqa: A003\n        \"\"\"Format logging record as structured JSON str\"\"\"\n        return json.dumps(\n            {\n                \"event\": super().format(record),\n                \"timestamp\": self.formatTime(record),\n                \"my_default_key\": \"test\",\n                **self.log_format,\n            },\n        )\n\n\nlogger = Logger(service=\"payment\", logger_formatter=CustomFormatter())\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event, context):\n    logger.info(\"Collecting payment\")\n</code></pre> <pre><code>{\n    \"event\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494\",\n    \"my_default_key\": \"test\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#bring-your-own-json-serializer",
            "title": "Bring your own JSON serializer",
            "text": "<p>By default, Logger uses <code>json.dumps</code> and <code>json.loads</code> as serializer and deserializer respectively. There could be scenarios where you are making use of alternative JSON libraries like orjson.</p> <p>As parameters don't always translate well between them, you can pass any callable that receives a <code>dict</code> and return a <code>str</code>:</p> Using Rust orjson library as serializer<pre><code>import functools\n\nimport orjson\n\nfrom aws_lambda_powertools import Logger\n\ncustom_serializer = orjson.dumps\ncustom_deserializer = orjson.loads\n\nlogger = Logger(service=\"payment\", json_serializer=custom_serializer, json_deserializer=custom_deserializer)\n\n# NOTE: when using parameters, you can pass a partial\ncustom_serializer_with_parameters = functools.partial(orjson.dumps, option=orjson.OPT_SERIALIZE_NUMPY)\n\nlogger_two = Logger(\n    service=\"payment\",\n    json_serializer=custom_serializer_with_parameters,\n    json_deserializer=custom_deserializer,\n)\n</code></pre>"
        },
        {
            "location": "core/logger/#testing-your-code",
            "title": "Testing your code",
            "text": ""
        },
        {
            "location": "core/logger/#inject-lambda-context",
            "title": "Inject Lambda Context",
            "text": "<p>When unit testing your code that makes use of <code>inject_lambda_context</code> decorator, you need to pass a dummy Lambda Context, or else Logger will fail.</p> <p>This is a Pytest sample that provides the minimum information necessary for Logger to succeed:</p> fake_lambda_context_for_logger.pyfake_lambda_context_for_logger_module.py <pre><code>from dataclasses import dataclass\n\nimport fake_lambda_context_for_logger_module  # sample module for completeness\nimport pytest\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n    aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef test_lambda_handler(lambda_context):\n    test_event = {\"test\": \"event\"}\n    fake_lambda_context_for_logger_module.handler(test_event, lambda_context)\n</code></pre> <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    logger.info(\"Collecting payment\")\n\n    return \"hello world\"\n</code></pre> Tip <p>Check out the built-in Pytest caplog fixture to assert plain log messages</p>"
        },
        {
            "location": "core/logger/#pytest-live-log-feature",
            "title": "Pytest live log feature",
            "text": "<p>Pytest Live Log feature duplicates emitted log messages in order to style log statements according to their levels, for this to work use <code>POWERTOOLS_LOG_DEDUPLICATION_DISABLED</code> env var.</p> Disabling log deduplication to use Pytest live log<pre><code>POWERTOOLS_LOG_DEDUPLICATION_DISABLED=\"1\" pytest -o log_cli=1\n</code></pre> Warning <p>This feature should be used with care, as it explicitly disables our ability to filter propagated messages to the root logger (if configured).</p>"
        },
        {
            "location": "core/logger/#faq",
            "title": "FAQ",
            "text": ""
        },
        {
            "location": "core/logger/#how-can-i-enable-boto3-and-botocore-library-logging",
            "title": "How can I enable boto3 and botocore library logging?",
            "text": "<p>You can enable the <code>botocore</code> and <code>boto3</code> logs by using the <code>set_stream_logger</code> method, this method will add a stream handler for the given name and level to the logging module. By default, this logs all boto3 messages to stdout.</p> Enabling AWS SDK logging<pre><code>from typing import Dict, List\n\nimport boto3\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nboto3.set_stream_logger()\nboto3.set_stream_logger(\"botocore\")\n\nlogger = Logger()\nclient = boto3.client(\"s3\")\n\n\ndef lambda_handler(event: Dict, context: LambdaContext) -&gt; List:\n    response = client.list_buckets()\n\n    return response.get(\"Buckets\", [])\n</code></pre>"
        },
        {
            "location": "core/logger/#how-can-i-enable-powertools-for-aws-lambda-python-logging-for-imported-libraries",
            "title": "How can I enable Powertools for AWS Lambda (Python) logging for imported libraries?",
            "text": "<p>You can copy the Logger setup to all or sub-sets of registered external loggers. Use the <code>copy_config_to_registered_logger</code> method to do this.</p> <p>We include the logger <code>name</code> attribute for all loggers we copied configuration to help you differentiate them.</p> <p>By default all registered loggers will be modified. You can change this behavior by providing <code>include</code> and <code>exclude</code> attributes.</p> <p>You can also provide optional <code>log_level</code> attribute external top-level loggers will be configured with, by default it'll use the source logger log level. You can opt-out by using <code>ignore_log_level=True</code> parameter.</p> Cloning Logger config to all other registered standard loggers<pre><code>import logging\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging import utils\n\nlogger = Logger()\n\nexternal_logger = logging.getLogger()\n\nutils.copy_config_to_registered_loggers(source_logger=logger)\nexternal_logger.info(\"test message\")\n</code></pre>"
        },
        {
            "location": "core/logger/#how-can-i-add-standard-library-logging-attributes-to-a-log-record",
            "title": "How can I add standard library logging attributes to a log record?",
            "text": "<p>The Python standard library log records contains a large set of attributes, however only a few are included in Powertools for AWS Lambda (Python) Logger log record by default.</p> <p>You can include any of these logging attributes as key value arguments (<code>kwargs</code>) when instantiating <code>Logger</code> or <code>LambdaPowertoolsFormatter</code>.</p> <p>You can also add them later anywhere in your code with <code>append_keys</code>, or remove them with <code>remove_keys</code> methods.</p> append_and_remove_keys.pyappend_and_remove_keys_output.json <pre><code>from aws_lambda_powertools import Logger\n\nlogger = Logger(service=\"payment\", name=\"%(name)s\")\n\nlogger.info(\"Name should be equal service value\")\n\nadditional_log_attributes = {\"process\": \"%(process)d\", \"processName\": \"%(processName)s\"}\nlogger.append_keys(**additional_log_attributes)\nlogger.info(\"This will include process ID and name\")\nlogger.remove_keys([\"processName\"])\n\n# further messages will not include processName\n</code></pre> <pre><code>[\n    {\n        \"level\": \"INFO\",\n        \"location\": \"&lt;module&gt;:16\",\n        \"message\": \"Name should be equal service value\",\n        \"name\": \"payment\",\n        \"service\": \"payment\",\n        \"timestamp\": \"2022-07-01 07:09:46,330+0000\"\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"&lt;module&gt;:23\",\n        \"message\": \"This will include process ID and name\",\n        \"name\": \"payment\",\n        \"process\": \"9\",\n        \"processName\": \"MainProcess\",\n        \"service\": \"payment\",\n        \"timestamp\": \"2022-07-01 07:09:46,330+0000\"\n    }\n]\n</code></pre> <p>For log records originating from Powertools for AWS Lambda (Python) Logger, the <code>name</code> attribute will be the same as <code>service</code>, for log records coming from standard library logger, it will be the name of the logger (i.e. what was used as name argument to <code>logging.getLogger</code>).</p>"
        },
        {
            "location": "core/logger/#whats-the-difference-between-append_keys-and-extra",
            "title": "What's the difference between <code>append_keys</code> and <code>extra</code>?",
            "text": "<p>Keys added with <code>append_keys</code> will persist across multiple log messages while keys added via <code>extra</code> will only be available in a given log message operation.</p> <p>Here's an example where we persist <code>payment_id</code> not <code>request_id</code>. Note that <code>payment_id</code> remains in both log messages while <code>booking_id</code> is only available in the first message.</p> append_keys_vs_extra.pyappend_keys_vs_extra_output.json <pre><code>import os\n\nimport requests\n\nfrom aws_lambda_powertools import Logger\n\nENDPOINT = os.getenv(\"PAYMENT_API\", \"\")\nlogger = Logger(service=\"payment\")\n\n\nclass PaymentError(Exception):\n    ...\n\n\ndef lambda_handler(event, context):\n    logger.append_keys(payment_id=\"123456789\")\n    charge_id = event.get(\"charge_id\", \"\")\n\n    try:\n        ret = requests.post(url=f\"{ENDPOINT}/collect\", data={\"charge_id\": charge_id})\n        ret.raise_for_status()\n\n        logger.info(\"Charge collected successfully\", extra={\"charge_id\": charge_id})\n        return ret.json()\n    except requests.HTTPError as e:\n        raise PaymentError(f\"Unable to collect payment for charge {charge_id}\") from e\n\n    logger.info(\"goodbye\")\n</code></pre> <pre><code>[\n    {\n        \"level\": \"INFO\",\n        \"location\": \"&lt;module&gt;:22\",\n        \"message\": \"Charge collected successfully\",\n        \"timestamp\": \"2021-01-12 14:09:10,859\",\n        \"service\": \"payment\",\n        \"sampling_rate\": 0.0,\n        \"payment_id\": \"123456789\",\n        \"charge_id\": \"75edbad0-0857-4fc9-b547-6180e2f7959b\"\n    },\n    {\n        \"level\": \"INFO\",\n        \"location\": \"&lt;module&gt;:27\",\n        \"message\": \"goodbye\",\n        \"timestamp\": \"2021-01-12 14:09:10,860\",\n        \"service\": \"payment\",\n        \"sampling_rate\": 0.0,\n        \"payment_id\": \"123456789\"\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/logger/#how-do-i-aggregate-and-search-powertools-for-aws-lambda-python-logs-across-accounts",
            "title": "How do I aggregate and search Powertools for AWS Lambda (Python) logs across accounts?",
            "text": "<p>As of now, ElasticSearch (ELK) or 3rd party solutions are best suited to this task. Please refer to this discussion for more details</p>"
        },
        {
            "location": "core/metrics/",
            "title": "Amazon CloudWatch EMF Metrics",
            "text": "<p>Metrics creates custom metrics asynchronously by logging metrics to standard output following Amazon CloudWatch Embedded Metric Format (EMF).</p> <p>These metrics can be visualized through Amazon CloudWatch Console.</p>"
        },
        {
            "location": "core/metrics/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Aggregate up to 100 metrics using a single CloudWatch EMF object (large JSON blob)</li> <li>Validate against common metric definitions mistakes (metric unit, values, max dimensions, max metrics, etc)</li> <li>Metrics are created asynchronously by CloudWatch service, no custom stacks needed</li> <li>Context manager to create a one off metric with a different dimension</li> </ul>"
        },
        {
            "location": "core/metrics/#terminologies",
            "title": "Terminologies",
            "text": "<p>If you're new to Amazon CloudWatch, there are five terminologies you must be aware of before using this utility:</p> <ul> <li>Namespace. It's the highest level container that will group multiple metrics from multiple services for a given application, for example <code>ServerlessEcommerce</code>.</li> <li>Dimensions. Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example <code>ColdStart</code> metric by Payment <code>service</code>.</li> <li>Metric. It's the name of the metric, for example: <code>SuccessfulBooking</code> or <code>UpdatedBooking</code>.</li> <li>Unit. It's a value representing the unit of measure for the corresponding metric, for example: <code>Count</code> or <code>Seconds</code>.</li> <li>Resolution. It's a value representing the storage resolution for the corresponding metric. Metrics can be either Standard or High resolution. Read more here.</li> </ul> Metric terminology, visually explained"
        },
        {
            "location": "core/metrics/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>Metric has two global settings that will be used across all metrics emitted:</p> Setting Description Environment variable Constructor parameter Metric namespace Logical container where all metrics will be placed e.g. <code>ServerlessAirline</code> <code>POWERTOOLS_METRICS_NAMESPACE</code> <code>namespace</code> Service Optionally, sets service metric dimension across all metrics e.g. <code>payment</code> <code>POWERTOOLS_SERVICE_NAME</code> <code>service</code> Info <p><code>POWERTOOLS_METRICS_DISABLED</code> will not disable default metrics created by AWS services.</p> Tip <p>Use your application or main service as the metric namespace to easily group all metrics.</p> AWS Serverless Application Model (SAM) example<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Powertools for AWS Lambda (Python) version\n\nGlobals:\n  Function:\n    Timeout: 5\n    Runtime: python3.12\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: booking\n        POWERTOOLS_METRICS_NAMESPACE: ServerlessAirline\n        POWERTOOLS_METRICS_FUNCTION_NAME: my-function-name\n\n    Layers:\n      # Find the latest Layer version in the official documentation\n      # https://docs.powertools.aws.dev/lambda/python/latest/#lambda-layer\n      - !Sub arn:aws:lambda:${AWS::Region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12\n\nResources:\n  CaptureLambdaHandlerExample:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: ../src\n      Handler: capture_lambda_handler.handler\n</code></pre> Note <p>For brevity, all code snippets in this page will rely on environment variables above being set.</p> <p>This ensures we instantiate <code>metrics = Metrics()</code> over <code>metrics = Metrics(service=\"booking\", namespace=\"ServerlessAirline\")</code>, etc.</p>"
        },
        {
            "location": "core/metrics/#creating-metrics",
            "title": "Creating metrics",
            "text": "<p>You can create metrics using <code>add_metric</code>, and you can create dimensions for all your aggregate metrics using <code>add_dimension</code> method.</p> Tip <p>You can initialize Metrics in any other module too. It'll keep track of your aggregate metrics in memory to optimize costs (one blob instead of multiples).</p> add_metrics.pyadd_dimension.py <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> <pre><code>import os\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_dimension(name=\"environment\", value=STAGE)\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> Tip: Autocomplete Metric Units <p><code>MetricUnit</code> enum facilitate finding a supported metric unit by CloudWatch. Alternatively, you can pass the value as a string if you already know them e.g. <code>unit=\"Count\"</code>.</p> Note: Metrics overflow <p>CloudWatch EMF supports a max of 100 metrics per batch. Metrics utility will flush all metrics when adding the 100th metric. Subsequent metrics (101th+) will be aggregated into a new EMF object, for your convenience.</p> Warning: Do not create metrics or dimensions outside the handler <p>Metrics or dimensions added in the global scope will only be added during cold start. Disregard if that's the intended behavior.</p>"
        },
        {
            "location": "core/metrics/#adding-high-resolution-metrics",
            "title": "Adding high-resolution metrics",
            "text": "<p>You can create high-resolution metrics passing <code>resolution</code> parameter to <code>add_metric</code>.</p> When is it useful? <p>High-resolution metrics are data with a granularity of one second and are very useful in several situations such as telemetry, time series, real-time incident management, and others.</p> add_high_resolution_metrics.py <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricResolution, MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1, resolution=MetricResolution.High)\n</code></pre> Tip: Autocomplete Metric Resolutions <p><code>MetricResolution</code> enum facilitates finding a supported metric resolution by CloudWatch. Alternatively, you can pass the values 1 or 60 (must be one of them) as an integer e.g. <code>resolution=1</code>.</p>"
        },
        {
            "location": "core/metrics/#adding-multi-value-metrics",
            "title": "Adding multi-value metrics",
            "text": "<p>You can call <code>add_metric()</code> with the same metric name multiple times. The values will be grouped together in a list.</p> add_multi_value_metrics.pyadd_multi_value_metrics_output.json <pre><code>import os\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_dimension(name=\"environment\", value=STAGE)\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=1)\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=8)\n</code></pre> <pre><code>{\n    \"_aws\": {\n        \"Timestamp\": 1656685750622,\n        \"CloudWatchMetrics\": [\n            {\n                \"Namespace\": \"ServerlessAirline\",\n                \"Dimensions\": [\n                    [\n                        \"environment\",\n                        \"service\"\n                    ]\n                ],\n                \"Metrics\": [\n                    {\n                        \"Name\": \"TurbineReads\",\n                        \"Unit\": \"Count\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"environment\": \"dev\",\n    \"service\": \"booking\",\n    \"TurbineReads\": [\n        1.0,\n        8.0\n    ]\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#adding-default-dimensions",
            "title": "Adding default dimensions",
            "text": "<p>You can use <code>set_default_dimensions</code> method, or <code>default_dimensions</code> parameter in <code>log_metrics</code> decorator, to persist dimensions across Lambda invocations.</p> <p>If you'd like to remove them at some point, you can use <code>clear_default_dimensions</code> method.</p> set_default_dimensions.pyset_default_dimensions_log_metrics.py <pre><code>import os\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\nmetrics = Metrics()\nmetrics.set_default_dimensions(environment=STAGE, another=\"one\")\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=1)\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=8)\n</code></pre> <pre><code>import os\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\nmetrics = Metrics()\nDEFAULT_DIMENSIONS = {\"environment\": STAGE, \"another\": \"one\"}\n\n\n# ensures metrics are flushed upon request completion/failure\n@metrics.log_metrics(default_dimensions=DEFAULT_DIMENSIONS)\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=1)\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=8)\n</code></pre> <p>Note: Dimensions with empty values will not be included.</p>"
        },
        {
            "location": "core/metrics/#changing-default-timestamp",
            "title": "Changing default timestamp",
            "text": "<p>When creating metrics, we use the current timestamp. If you want to change the timestamp of all the metrics you create, utilize the <code>set_timestamp</code> function. You can specify a datetime object or an integer representing an epoch timestamp in milliseconds.</p> <p>Note that when specifying the timestamp using an integer, it must adhere to the epoch timezone format in milliseconds.</p> Info <p>If you need to use different timestamps across multiple metrics, opt for single_metric.</p> set_custom_timestamp_log_metrics.py <pre><code>import datetime\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n\n    metric_timestamp = int((datetime.datetime.now() - datetime.timedelta(days=2)).timestamp() * 1000)\n    metrics.set_timestamp(metric_timestamp)\n</code></pre>"
        },
        {
            "location": "core/metrics/#flushing-metrics",
            "title": "Flushing metrics",
            "text": "<p>As you finish adding all your metrics, you need to serialize and flush them to standard output. You can do that automatically with the <code>log_metrics</code> decorator.</p> <p>This decorator also validates, serializes, and flushes all your metrics. During metrics validation, if no metrics are provided then a warning will be logged, but no exception will be raised.</p> add_metrics.pylog_metrics_output.json <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> <pre><code>{\n    \"_aws\": {\n        \"Timestamp\": 1656686788803,\n        \"CloudWatchMetrics\": [\n            {\n                \"Namespace\": \"ServerlessAirline\",\n                \"Dimensions\": [\n                    [\n                        \"service\"\n                    ]\n                ],\n                \"Metrics\": [\n                    {\n                        \"Name\": \"SuccessfulBooking\",\n                        \"Unit\": \"Count\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"service\": \"booking\",\n    \"SuccessfulBooking\": [\n        1.0\n    ]\n}\n</code></pre> Tip: Metric validation <p>If metrics are provided, and any of the following criteria are not met, <code>SchemaValidationError</code> exception will be raised:</p> <ul> <li>Maximum of 29 user-defined dimensions</li> <li>Namespace is set, and no more than one</li> <li>Metric units must be supported by CloudWatch</li> </ul>"
        },
        {
            "location": "core/metrics/#raising-schemavalidationerror-on-empty-metrics",
            "title": "Raising SchemaValidationError on empty metrics",
            "text": "<p>If you want to ensure at least one metric is always emitted, you can pass <code>raise_on_empty_metrics</code> to the log_metrics decorator:</p> Raising SchemaValidationError exception if no metrics are added<pre><code>from aws_lambda_powertools.metrics import Metrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics(raise_on_empty_metrics=True)\ndef lambda_handler(event: dict, context: LambdaContext):\n    # no metrics being created will now raise SchemaValidationError\n    ...\n</code></pre> Suppressing warning messages on empty metrics <p>If you expect your function to execute without publishing metrics every time, you can suppress the warning with <code>warnings.filterwarnings(\"ignore\", \"No application metrics to publish*\")</code>.</p>"
        },
        {
            "location": "core/metrics/#capturing-cold-start-metric",
            "title": "Capturing cold start metric",
            "text": "<p>You can optionally capture cold start metrics with <code>log_metrics</code> decorator via <code>capture_cold_start_metric</code> param.</p> capture_cold_start_metric.pycapture_cold_start_metric_output.json <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event: dict, context: LambdaContext):\n    ...\n</code></pre> <pre><code>{\n    \"_aws\": {\n        \"Timestamp\": 1656687493142,\n        \"CloudWatchMetrics\": [\n            {\n                \"Namespace\": \"ServerlessAirline\",\n                \"Dimensions\": [\n                    [\n                        \"function_name\",\n                        \"service\"\n                    ]\n                ],\n                \"Metrics\": [\n                    {\n                        \"Name\": \"ColdStart\",\n                        \"Unit\": \"Count\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"function_name\": \"test\",\n    \"service\": \"booking\",\n    \"ColdStart\": [\n        1.0\n    ]\n}\n</code></pre> <p>If it's a cold start invocation, this feature will:</p> <ul> <li>Create a separate EMF blob solely containing a metric named <code>ColdStart</code></li> <li>Add <code>function_name</code> and <code>service</code> dimensions</li> </ul> <p>This has the advantage of keeping cold start metric separate from your application metrics, where you might have unrelated dimensions.</p> Info <p>We do not emit 0 as a value for ColdStart metric for cost reasons. Let us know if you'd prefer a flag to override it.</p>"
        },
        {
            "location": "core/metrics/#customizing-function-name-for-cold-start-metrics",
            "title": "Customizing function name for cold start metrics",
            "text": "<p>When emitting cold start metrics, the <code>function_name</code> dimension defaults to <code>context.function_name</code>. If you want to change the value you can set the <code>function_name</code> parameter in the metrics constructor, or define the environment variable <code>POWERTOOLS_METRICS_FUNCTION_NAME</code>.</p> <p>The priority of the <code>function_name</code> dimension value is defined as:</p> <ol> <li><code>function_name</code> constructor option</li> <li><code>POWERTOOLS_METRICS_FUNCTION_NAME</code> environment variable</li> <li><code>context.function_name</code> property</li> </ol> working_with_custom_cold_start_function_name.py <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics(function_name=\"my-function-name\")\n\n\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event: dict, context: LambdaContext): ...\n</code></pre>"
        },
        {
            "location": "core/metrics/#environment-variables",
            "title": "Environment variables",
            "text": "<p>The following environment variable is available to configure Metrics at a global scope:</p> Setting Description Environment variable Default Namespace Name Sets namespace used for metrics. <code>POWERTOOLS_METRICS_NAMESPACE</code> <code>None</code> Service Sets service metric dimension across all metrics e.g. <code>payment</code> <code>POWERTOOLS_SERVICE_NAME</code> <code>None</code> Function Name Function name used as dimension for the ColdStart metric. <code>POWERTOOLS_METRICS_FUNCTION_NAME</code> <code>None</code> Disable Powertools Metrics Disables all metrics emitted by Powertools. <code>POWERTOOLS_METRICS_DISABLED</code> <code>None</code> <p><code>POWERTOOLS_METRICS_NAMESPACE</code> is also available on a per-instance basis with the <code>namespace</code> parameter, which will consequently override the environment variable value.</p>"
        },
        {
            "location": "core/metrics/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/metrics/#adding-metadata",
            "title": "Adding metadata",
            "text": "<p>You can add high-cardinality data as part of your Metrics log with <code>add_metadata</code> method. This is useful when you want to search highly contextual information along with your metrics in your logs.</p> Info <p>This will not be available during metrics visualization - Use dimensions for this purpose</p> add_metadata.pyadd_metadata_output.json <pre><code>from uuid import uuid4\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n    metrics.add_metadata(key=\"booking_id\", value=f\"{uuid4()}\")\n</code></pre> <pre><code>{\n    \"_aws\": {\n        \"Timestamp\": 1656688250155,\n        \"CloudWatchMetrics\": [\n            {\n                \"Namespace\": \"ServerlessAirline\",\n                \"Dimensions\": [\n                    [\n                        \"service\"\n                    ]\n                ],\n                \"Metrics\": [\n                    {\n                        \"Name\": \"SuccessfulBooking\",\n                        \"Unit\": \"Count\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"service\": \"booking\",\n    \"booking_id\": \"00347014-341d-4b8e-8421-a89d3d588ab3\",\n    \"SuccessfulBooking\": [\n        1.0\n    ]\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#single-metric",
            "title": "Single metric",
            "text": "<p>CloudWatch EMF uses the same dimensions and timestamp across all your metrics. Use <code>single_metric</code> if you have a metric that should have different dimensions or timestamp.</p>"
        },
        {
            "location": "core/metrics/#working-with-different-dimensions",
            "title": "Working with different dimensions",
            "text": "<p>Generally, using different dimensions would be an edge case since you pay for unique metric.</p> <p>Keep the following formula in mind: unique metric = (metric_name + dimension_name + dimension_value)</p> single_metric.pysingle_metric_output.json <pre><code>import os\n\nfrom aws_lambda_powertools import single_metric\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    with single_metric(name=\"MySingleMetric\", unit=MetricUnit.Count, value=1) as metric:\n        metric.add_dimension(name=\"environment\", value=STAGE)\n</code></pre> <pre><code>{\n    \"_aws\": {\n        \"Timestamp\": 1656689267834,\n        \"CloudWatchMetrics\": [\n            {\n                \"Namespace\": \"ServerlessAirline\",\n                \"Dimensions\": [\n                    [\n                        \"environment\",\n                        \"service\"\n                    ]\n                ],\n                \"Metrics\": [\n                    {\n                        \"Name\": \"MySingleMetric\",\n                        \"Unit\": \"Count\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"environment\": \"dev\",\n    \"service\": \"booking\",\n    \"MySingleMetric\": [\n        1.0\n    ]\n}\n</code></pre> <p>By default it will skip all previously defined dimensions including default dimensions. Use <code>default_dimensions</code> keyword argument if you want to reuse default dimensions or specify custom dimensions from a dictionary.</p> single_metric_default_dimensions_inherit.pysingle_metric_default_dimensions.py <pre><code>import os\n\nfrom aws_lambda_powertools import single_metric\nfrom aws_lambda_powertools.metrics import Metrics, MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\n\nmetrics = Metrics()\nmetrics.set_default_dimensions(environment=STAGE)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    with single_metric(\n        name=\"RecordsCount\",\n        unit=MetricUnit.Count,\n        value=10,\n        default_dimensions=metrics.default_dimensions,\n    ) as metric:\n        metric.add_dimension(name=\"TableName\", value=\"Users\")\n</code></pre> <pre><code>import os\n\nfrom aws_lambda_powertools import single_metric\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    with single_metric(\n        name=\"RecordsCount\",\n        unit=MetricUnit.Count,\n        value=10,\n        default_dimensions={\"environment\": STAGE},\n    ) as metric:\n        metric.add_dimension(name=\"TableName\", value=\"Users\")\n</code></pre>"
        },
        {
            "location": "core/metrics/#working-with-different-timestamp",
            "title": "Working with different timestamp",
            "text": "<p>When working with multiple metrics, customers may need different timestamps between them. In such cases, utilize <code>single_metric</code> to flush individual metrics with specific timestamps.</p> single_metric_with_different_timestamp.pysingle_metric_with_different_timestamp_payload.json <pre><code>from aws_lambda_powertools import Logger, single_metric\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    for record in event:\n\n        record_id: str = record.get(\"record_id\")\n        amount: int = record.get(\"amount\")\n        timestamp: int = record.get(\"timestamp\")\n\n        with single_metric(name=\"Orders\", unit=MetricUnit.Count, value=amount, namespace=\"Powertools\") as metric:\n            logger.info(f\"Processing record id {record_id}\")\n            metric.set_timestamp(timestamp)\n</code></pre> <pre><code>[\n    {\n        \"record_id\": \"6ba7b810-9dad-11d1-80b4-00c04fd430c8\",\n        \"amount\": 10,\n        \"timestamp\": 1648195200000\n    },\n    {\n        \"record_id\": \"6ba7b811-9dad-11d1-80b4-00c04fd430c8\",\n        \"amount\": 30,\n        \"timestamp\": 1648224000000\n    },\n    {\n        \"record_id\": \"6ba7b812-9dad-11d1-80b4-00c04fd430c8\",\n        \"amount\": 25,\n        \"timestamp\": 1648209600000\n    },\n    {\n        \"record_id\": \"6ba7b813-9dad-11d1-80b4-00c04fd430c8\",\n        \"amount\": 40,\n        \"timestamp\": 1648177200000\n    },\n    {\n        \"record_id\": \"6ba7b814-9dad-11d1-80b4-00c04fd430c8\",\n        \"amount\": 32,\n        \"timestamp\": 1648216800000\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/metrics/#flushing-metrics-manually",
            "title": "Flushing metrics manually",
            "text": "<p>If you are using the AWS Lambda Web Adapter project, or a middleware with custom metric logic, you can use <code>flush_metrics()</code>. This method will serialize, print metrics available to standard output, and clear in-memory metrics data.</p> Warning <p>This does not capture Cold Start metrics, and metric data validation still applies.</p> <p>Contrary to the <code>log_metrics</code> decorator, you are now also responsible to flush metrics in the event of an exception.</p> Manually flushing and clearing metrics from memory<pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\ndef book_flight(flight_id: str, **kwargs): \n    # logic to book flight\n    ...\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        book_flight(flight_id=event.get(\"flight_id\", \"\"))\n    finally:\n        metrics.flush_metrics()\n</code></pre>"
        },
        {
            "location": "core/metrics/#metrics-isolation",
            "title": "Metrics isolation",
            "text": "<p>You can use <code>EphemeralMetrics</code> class when looking to isolate multiple instances of metrics with distinct namespaces and/or dimensions.</p> <p>This is a typical use case is for multi-tenant, or emitting same metrics for distinct applications.</p> EphemeralMetrics usage<pre><code>from aws_lambda_powertools.metrics import EphemeralMetrics, MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = EphemeralMetrics()\n\n\n@metrics.log_metrics\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> <p>Differences between <code>EphemeralMetrics</code> and <code>Metrics</code></p> <p><code>EphemeralMetrics</code> has only one difference while keeping nearly the exact same set of features:</p> Feature Metrics EphemeralMetrics Share data across instances (metrics, dimensions, metadata, etc.) Yes - <p>Why not changing the default <code>Metrics</code> behaviour to not share data across instances?</p> <p>This is an intentional design to prevent accidental data deduplication or data loss issues due to CloudWatch EMF metric dimension constraint.</p> <p>In CloudWatch, there are two metric ingestion mechanisms: EMF (async) and <code>PutMetricData</code> API (sync).</p> <p>The former creates metrics asynchronously via CloudWatch Logs, and the latter uses a synchronous and more flexible ingestion API.</p> <p>Key concept</p> <p>CloudWatch considers a metric unique by a combination of metric name, metric namespace, and zero or more metric dimensions.</p> <p>With EMF, metric dimensions are shared with any metrics you define. With <code>PutMetricData</code> API, you can set a list defining one or more metrics with distinct dimensions.</p> <p>This is a subtle yet important distinction. Imagine you had the following metrics to emit:</p> Metric Name Dimension Intent SuccessfulBooking service=\"booking\", tenant_id=\"sample\" Application metric IntegrationLatency service=\"booking\", function_name=\"sample\" Operational metric ColdStart service=\"booking\", function_name=\"sample\" Operational metric <p>The <code>tenant_id</code> dimension could vary leading to two common issues:</p> <ol> <li><code>ColdStart</code> metric will be created multiple times (N * number of unique tenant_id dimension value), despite the <code>function_name</code> being the same</li> <li><code>IntegrationLatency</code> metric will be also created multiple times due to <code>tenant_id</code> as well as <code>function_name</code> (may or not be intentional)</li> </ol> <p>These issues are exacerbated when you create (A) metric dimensions conditionally, (B) multiple metrics' instances throughout your code  instead of reusing them (globals). Subsequent metrics' instances will have (or lack) different metric dimensions resulting in different metrics and data points with the same name.</p> <p>Intentional design to address these scenarios</p> <p>On 1, when you enable capture_start_metric feature, we transparently create and flush an additional EMF JSON Blob that is independent from your application metrics. This prevents data pollution.</p> <p>On 2, you can use <code>EphemeralMetrics</code> to create an additional EMF JSON Blob from your application metric (<code>SuccessfulBooking</code>). This ensures that <code>IntegrationLatency</code> operational metric data points aren't tied to any dynamic dimension values like <code>tenant_id</code>.</p> <p>That is why <code>Metrics</code> shares data across instances by default, as that covers 80% of use cases and different personas using Powertools. This allows them to instantiate <code>Metrics</code> in multiple places throughout their code - be a separate file, a middleware, or an abstraction that sets default dimensions.</p>"
        },
        {
            "location": "core/metrics/#observability-providers",
            "title": "Observability providers",
            "text": "<p>An observability provider is an AWS Lambda Partner offering a platform for logging, metrics, traces, etc.</p> <p>We provide a thin-wrapper on top of the most requested observability providers. We strive to keep a similar UX as close as possible while keeping our value add features.</p> <p>Missing your preferred provider? Please create a feature request.</p> <p>Current providers:</p> Provider Notes Datadog Uses Datadog SDK and Datadog Lambda Extension by default"
        },
        {
            "location": "core/metrics/#testing-your-code",
            "title": "Testing your code",
            "text": ""
        },
        {
            "location": "core/metrics/#setting-environment-variables",
            "title": "Setting environment variables",
            "text": "Tip <p>Ignore this section, if:</p> <ul> <li>You are explicitly setting namespace/default dimension via <code>namespace</code> and <code>service</code> parameters</li> <li>You're not instantiating <code>Metrics</code> in the global namespace</li> </ul> <p>For example, <code>Metrics(namespace=\"ServerlessAirline\", service=\"booking\")</code></p> <p>Make sure to set <code>POWERTOOLS_METRICS_NAMESPACE</code> and <code>POWERTOOLS_SERVICE_NAME</code> before running your tests to prevent failing on <code>SchemaValidation</code> exception. You can set it before you run tests or via pytest plugins like dotenv.</p> Injecting dummy Metric Namespace before running tests<pre><code>POWERTOOLS_SERVICE_NAME=\"booking\" POWERTOOLS_METRICS_NAMESPACE=\"ServerlessAirline\" python -m pytest\n</code></pre>"
        },
        {
            "location": "core/metrics/#clearing-metrics",
            "title": "Clearing metrics",
            "text": "<p><code>Metrics</code> keep metrics in memory across multiple instances. If you need to test this behavior, you can use the following Pytest fixture to ensure metrics are reset incl. cold start:</p> Clearing metrics between tests<pre><code>import pytest\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics.provider import cold_start\n\n\n@pytest.fixture(scope=\"function\", autouse=True)\ndef reset_metric_set():\n    # Clear out every metric data prior to every test\n    metrics = Metrics()\n    metrics.clear_metrics()\n    cold_start.is_cold_start = True  # ensure each test has cold start\n    metrics.clear_default_dimensions()  # remove persisted default dimensions, if any\n    yield\n</code></pre>"
        },
        {
            "location": "core/metrics/#functional-testing",
            "title": "Functional testing",
            "text": "<p>You can read standard output and assert whether metrics have been flushed. Here's an example using <code>pytest</code> with <code>capsys</code> built-in fixture:</p> assert_single_emf_blob.pyadd_metrics.pyassert_multiple_emf_blobs.pyassert_multiple_emf_blobs_module.py <pre><code>import json\n\nimport add_metrics\n\n\ndef test_log_metrics(capsys):\n    add_metrics.lambda_handler({}, {})\n\n    log = capsys.readouterr().out.strip()  # remove any extra line\n    metrics_output = json.loads(log)  # deserialize JSON str\n\n    # THEN we should have no exceptions\n    # and a valid EMF object should be flushed correctly\n    assert \"SuccessfulBooking\" in log  # basic string assertion in JSON str\n    assert \"SuccessfulBooking\" in metrics_output[\"_aws\"][\"CloudWatchMetrics\"][0][\"Metrics\"][0][\"Name\"]\n</code></pre> <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> <p>This will be needed when using <code>capture_cold_start_metric=True</code>, or when both <code>Metrics</code> and <code>single_metric</code> are used.</p> <pre><code>import json\nfrom dataclasses import dataclass\n\nimport assert_multiple_emf_blobs_module\nimport pytest\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n    aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef capture_metrics_output_multiple_emf_objects(capsys):\n    return [json.loads(line.strip()) for line in capsys.readouterr().out.split(\"\\n\") if line]\n\n\ndef test_log_metrics(capsys, lambda_context: LambdaContext):\n    assert_multiple_emf_blobs_module.lambda_handler({}, lambda_context)\n\n    cold_start_blob, custom_metrics_blob = capture_metrics_output_multiple_emf_objects(capsys)\n\n    # Since `capture_cold_start_metric` is used\n    # we should have one JSON blob for cold start metric and one for the application\n    assert cold_start_blob[\"ColdStart\"] == [1.0]\n    assert cold_start_blob[\"function_name\"] == \"test\"\n\n    assert \"SuccessfulBooking\" in custom_metrics_blob\n</code></pre> <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> Tip <p>For more elaborate assertions and comparisons, check out our functional testing for Metrics utility.</p>"
        },
        {
            "location": "core/tracer/",
            "title": "Tracer",
            "text": "<p>Tracer is an opinionated thin wrapper for AWS X-Ray Python SDK.</p> <p></p>"
        },
        {
            "location": "core/tracer/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Auto capture cold start as annotation, and responses or full exceptions as metadata</li> <li>Auto-disable when not running in AWS Lambda environment</li> <li>Support tracing async methods, generators, and context managers</li> <li>Auto patch supported modules by AWS X-Ray</li> </ul>"
        },
        {
            "location": "core/tracer/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>Tracer relies on AWS X-Ray SDK over OpenTelememetry Distro (ADOT) for optimal cold start (lower latency).</p>"
        },
        {
            "location": "core/tracer/#install",
            "title": "Install",
            "text": "<p>This is not necessary if you're installing Powertools for AWS Lambda (Python) via Lambda Layer/SAR</p> <p>Add <code>aws-lambda-powertools[tracer]</code> as a dependency in your preferred tool: e.g., requirements.txt, pyproject.toml. This will ensure you have the required dependencies before using Tracer.</p>"
        },
        {
            "location": "core/tracer/#permissions",
            "title": "Permissions",
            "text": "<p>Before your use this utility, your AWS Lambda function must have permissions to send traces to AWS X-Ray.</p> AWS Serverless Application Model (SAM) example<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Powertools for AWS Lambda (Python) version\n\nGlobals:\n  Function:\n    Timeout: 5\n    Runtime: python3.12\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: payment\n    Layers:\n      # Find the latest Layer version in the official documentation\n      # https://docs.powertools.aws.dev/lambda/python/latest/#lambda-layer\n      - !Sub arn:aws:lambda:${AWS::Region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12\n\nResources:\n  CaptureLambdaHandlerExample:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: ../src\n      Handler: capture_lambda_handler.handler\n</code></pre>"
        },
        {
            "location": "core/tracer/#lambda-handler",
            "title": "Lambda handler",
            "text": "<p>You can quickly start by initializing <code>Tracer</code> and use <code>capture_lambda_handler</code> decorator for your Lambda handler.</p> Tracing Lambda handler with capture_lambda_handler<pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()  # Sets service via POWERTOOLS_SERVICE_NAME env var\n# OR tracer = Tracer(service=\"example\")\n\n\ndef collect_payment(charge_id: str) -&gt; str:\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return collect_payment(charge_id=charge_id)\n</code></pre> <p><code>capture_lambda_handler</code> performs these additional tasks to ease operations:</p> <ul> <li>Creates a <code>ColdStart</code> annotation to easily filter traces that have had an initialization overhead</li> <li>Creates a <code>Service</code> annotation if <code>service</code> parameter or <code>POWERTOOLS_SERVICE_NAME</code> is set</li> <li>Captures any response, or full exceptions generated by the handler, and include as tracing metadata</li> </ul>"
        },
        {
            "location": "core/tracer/#annotations-metadata",
            "title": "Annotations &amp; Metadata",
            "text": "<p>Annotations are key-values associated with traces and indexed by AWS X-Ray. You can use them to filter traces and to create Trace Groups to slice and dice your transactions.</p> Adding annotations with put_annotation method<pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\ndef collect_payment(charge_id: str) -&gt; str:\n    tracer.put_annotation(key=\"PaymentId\", value=charge_id)\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return collect_payment(charge_id=charge_id)\n</code></pre> <p>Metadata are key-values also associated with traces but not indexed by AWS X-Ray. You can use them to add additional context for an operation using any native object.</p> Adding arbitrary metadata with put_metadata method<pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\ndef collect_payment(charge_id: str) -&gt; str:\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    payment_context = {\n        \"charge_id\": event.get(\"charge_id\", \"\"),\n        \"merchant_id\": event.get(\"merchant_id\", \"\"),\n        \"request_id\": context.aws_request_id,\n    }\n    payment_context[\"receipt_id\"] = collect_payment(charge_id=payment_context[\"charge_id\"])\n    tracer.put_metadata(key=\"payment_response\", value=payment_context)\n\n    return payment_context[\"receipt_id\"]\n</code></pre>"
        },
        {
            "location": "core/tracer/#synchronous-functions",
            "title": "Synchronous functions",
            "text": "<p>You can trace synchronous functions using the <code>capture_method</code> decorator.</p> Tracing an arbitrary function with capture_method<pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\n@tracer.capture_method\ndef collect_payment(charge_id: str) -&gt; str:\n    tracer.put_annotation(key=\"PaymentId\", value=charge_id)\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return collect_payment(charge_id=charge_id)\n</code></pre> Note: Function responses are auto-captured and stored as JSON, by default. <p>Use capture_response parameter to override this behaviour.</p> <p>The serialization is performed by aws-xray-sdk via <code>jsonpickle</code> module. This can cause side effects for file-like objects like boto S3 <code>StreamingBody</code>, where its response will be read only once during serialization.</p>"
        },
        {
            "location": "core/tracer/#asynchronous-and-generator-functions",
            "title": "Asynchronous and generator functions",
            "text": "Warning <p>We do not support asynchronous Lambda handler</p> <p>You can trace asynchronous functions and generator functions (including context managers) using <code>capture_method</code>.</p> capture_method_async.pycapture_method_context_manager.pycapture_method_generators.py <pre><code>import asyncio\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\n@tracer.capture_method\nasync def collect_payment(charge_id: str) -&gt; str:\n    tracer.put_annotation(key=\"PaymentId\", value=charge_id)\n    await asyncio.sleep(0.5)\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return asyncio.run(collect_payment(charge_id=charge_id))\n</code></pre> <pre><code>import contextlib\nfrom collections.abc import Generator\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\n\n\n@contextlib.contextmanager\n@tracer.capture_method\ndef collect_payment(charge_id: str) -&gt; Generator[str, None, None]:\n    try:\n        yield f\"dummy payment collected for charge: {charge_id}\"\n    finally:\n        tracer.put_annotation(key=\"PaymentId\", value=charge_id)\n\n\n@tracer.capture_lambda_handler\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    with collect_payment(charge_id=charge_id) as receipt_id:\n        logger.info(f\"Processing payment collection for charge {charge_id} with receipt {receipt_id}\")\n\n    return receipt_id\n</code></pre> <pre><code>from collections.abc import Generator\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\n@tracer.capture_method\ndef collect_payment(charge_id: str) -&gt; Generator[str, None, None]:\n    yield f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return next(collect_payment(charge_id=charge_id))\n</code></pre>"
        },
        {
            "location": "core/tracer/#environment-variables",
            "title": "Environment variables",
            "text": "<p>The following environment variables are available to configure Tracer at a global scope:</p> Setting Description Environment variable Default Disable Tracing Explicitly disables all tracing. <code>POWERTOOLS_TRACE_DISABLED</code> <code>false</code> Response Capture Captures Lambda or method return as metadata. <code>POWERTOOLS_TRACER_CAPTURE_RESPONSE</code> <code>true</code> Exception Capture Captures Lambda or method exception as metadata. <code>POWERTOOLS_TRACER_CAPTURE_ERROR</code> <code>true</code> <p>Both <code>POWERTOOLS_TRACER_CAPTURE_RESPONSE</code> and <code>POWERTOOLS_TRACER_CAPTURE_ERROR</code> can be set on a per-method basis, consequently overriding the environment variable value.</p>"
        },
        {
            "location": "core/tracer/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/tracer/#patching-modules",
            "title": "Patching modules",
            "text": "<p>Tracer automatically patches all supported libraries by X-Ray during initialization, by default. Underneath, AWS X-Ray SDK checks whether a supported library has been imported before patching.</p> <p>If you're looking to shave a few microseconds, or milliseconds depending on your function memory configuration, you can patch specific modules using <code>patch_modules</code> param:</p> Example of explicitly patching requests only<pre><code>import requests\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nMODULES = [\"requests\"]\n\ntracer = Tracer(patch_modules=MODULES)\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    ret = requests.get(\"https://httpbin.org/get\")\n    ret.raise_for_status()\n\n    return ret.json()\n</code></pre>"
        },
        {
            "location": "core/tracer/#disabling-response-auto-capture",
            "title": "Disabling response auto-capture",
            "text": "<p>Use <code>capture_response=False</code> parameter in both <code>capture_lambda_handler</code> and <code>capture_method</code> decorators to instruct Tracer not to serialize function responses as metadata.</p> Info: This is useful in three common scenarios <ol> <li>You might return sensitive information you don't want it to be added to your traces</li> <li>You might manipulate streaming objects that can be read only once; this prevents subsequent calls from being empty</li> <li>You might return more than 64K of data e.g., <code>message too long</code> error</li> </ol> disable_capture_response.pydisable_capture_response_streaming_body.py <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method(capture_response=False)\ndef collect_payment(charge_id: str) -&gt; str:\n    tracer.put_annotation(key=\"PaymentId\", value=charge_id)\n    logger.debug(\"Returning sensitive information....\")\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler(capture_response=False)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return collect_payment(charge_id=charge_id)\n</code></pre> <pre><code>import os\n\nimport boto3\nfrom botocore.response import StreamingBody\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nBUCKET = os.getenv(\"BUCKET_NAME\", \"\")\nREPORT_KEY = os.getenv(\"REPORT_KEY\", \"\")\n\ntracer = Tracer()\nlogger = Logger()\n\nsession = boto3.session.Session()\ns3 = session.client(\"s3\")\n\n\n@tracer.capture_method(capture_response=False)\ndef fetch_payment_report(payment_id: str) -&gt; StreamingBody:\n    ret = s3.get_object(Bucket=BUCKET, Key=f\"{REPORT_KEY}/{payment_id}\")\n    logger.debug(\"Returning streaming body from S3 object....\")\n    return ret[\"Body\"]\n\n\n@tracer.capture_lambda_handler(capture_response=False)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    payment_id = event.get(\"payment_id\", \"\")\n    report = fetch_payment_report(payment_id=payment_id)\n    return report.read().decode()\n</code></pre>"
        },
        {
            "location": "core/tracer/#disabling-exception-auto-capture",
            "title": "Disabling exception auto-capture",
            "text": "<p>Use <code>capture_error=False</code> parameter in both <code>capture_lambda_handler</code> and <code>capture_method</code> decorators to instruct Tracer not to serialize exceptions as metadata.</p> Info <p>Useful when returning sensitive information in exceptions/stack traces you don't control</p> Disabling exception auto-capture for tracing metadata<pre><code>import os\n\nimport requests\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nENDPOINT = os.getenv(\"PAYMENT_API\", \"\")\n\n\nclass PaymentError(Exception):\n    ...\n\n\n@tracer.capture_method(capture_error=False)\ndef collect_payment(charge_id: str) -&gt; dict:\n    try:\n        ret = requests.post(url=f\"{ENDPOINT}/collect\", data={\"charge_id\": charge_id})\n        ret.raise_for_status()\n        return ret.json()\n    except requests.HTTPError as e:\n        raise PaymentError(f\"Unable to collect payment for charge {charge_id}\") from e\n\n\n@tracer.capture_lambda_handler(capture_error=False)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    ret = collect_payment(charge_id=charge_id)\n\n    return ret.get(\"receipt_id\", \"\")\n</code></pre>"
        },
        {
            "location": "core/tracer/#ignoring-certain-http-endpoints",
            "title": "Ignoring certain HTTP endpoints",
            "text": "<p>You might have endpoints you don't want requests to be traced, perhaps due to the volume of calls or sensitive URLs.</p> <p>You can use <code>ignore_endpoint</code> method with the hostname and/or URLs you'd like it to be ignored - globs (<code>*</code>) are allowed.</p> Ignoring certain HTTP endpoints from being traced<pre><code>import os\n\nimport requests\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nENDPOINT = os.getenv(\"PAYMENT_API\", \"\")\nIGNORE_URLS = [\"/collect\", \"/refund\"]\n\ntracer = Tracer()\ntracer.ignore_endpoint(hostname=ENDPOINT, urls=IGNORE_URLS)\ntracer.ignore_endpoint(hostname=f\"*.{ENDPOINT}\", urls=IGNORE_URLS)  # `&lt;stage&gt;.ENDPOINT`\n\n\nclass PaymentError(Exception):\n    ...\n\n\n@tracer.capture_method(capture_error=False)\ndef collect_payment(charge_id: str) -&gt; dict:\n    try:\n        ret = requests.post(url=f\"{ENDPOINT}/collect\", data={\"charge_id\": charge_id})\n        ret.raise_for_status()\n        return ret.json()\n    except requests.HTTPError as e:\n        raise PaymentError(f\"Unable to collect payment for charge {charge_id}\") from e\n\n\n@tracer.capture_lambda_handler(capture_error=False)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    ret = collect_payment(charge_id=charge_id)\n\n    return ret.get(\"receipt_id\", \"\")\n</code></pre>"
        },
        {
            "location": "core/tracer/#tracing-aiohttp-requests",
            "title": "Tracing aiohttp requests",
            "text": "Info <p>This snippet assumes you have aiohttp as a dependency</p> <p>You can use <code>aiohttp_trace_config</code> function to create a valid aiohttp trace_config object. This is necessary since X-Ray utilizes aiohttp trace hooks to capture requests end-to-end.</p> Tracing aiohttp requests<pre><code>import asyncio\nimport os\n\nimport aiohttp\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.tracing import aiohttp_trace_config\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nENDPOINT = os.getenv(\"PAYMENT_API\", \"\")\n\ntracer = Tracer()\n\n\n@tracer.capture_method\nasync def collect_payment(charge_id: str) -&gt; dict:\n    async with aiohttp.ClientSession(trace_configs=[aiohttp_trace_config()]) as session:\n        async with session.get(f\"{ENDPOINT}/collect\") as resp:\n            return await resp.json()\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    charge_id = event.get(\"charge_id\", \"\")\n    return asyncio.run(collect_payment(charge_id=charge_id))\n</code></pre>"
        },
        {
            "location": "core/tracer/#escape-hatch-mechanism",
            "title": "Escape hatch mechanism",
            "text": "<p>You can use <code>tracer.provider</code> attribute to access all methods provided by AWS X-Ray <code>xray_recorder</code> object.</p> <p>This is useful when you need a feature available in X-Ray that is not available in the Tracer utility, for example thread-safe, or context managers.</p> Tracing a code block with in_subsegment escape hatch<pre><code>from aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\ndef collect_payment(charge_id: str) -&gt; str:\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    with tracer.provider.in_subsegment(\"## collect_payment\") as subsegment:\n        subsegment.put_annotation(key=\"PaymentId\", value=charge_id)\n        ret = collect_payment(charge_id=charge_id)\n        subsegment.put_metadata(key=\"payment_response\", value=ret)\n\n    return ret\n</code></pre>"
        },
        {
            "location": "core/tracer/#concurrent-asynchronous-functions",
            "title": "Concurrent asynchronous functions",
            "text": "Warning <p>X-Ray SDK will raise an exception when async functions are run and traced concurrently</p> <p>A safe workaround mechanism is to use <code>in_subsegment_async</code> available via Tracer escape hatch (<code>tracer.provider</code>).</p> Workaround to safely trace async concurrent functions<pre><code>import asyncio\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\nasync def another_async_task():\n    async with tracer.provider.in_subsegment_async(\"## another_async_task\") as subsegment:\n        subsegment.put_annotation(key=\"key\", value=\"value\")\n        subsegment.put_metadata(key=\"key\", value=\"value\", namespace=\"namespace\")\n        ...\n\n\nasync def another_async_task_2():\n    async with tracer.provider.in_subsegment_async(\"## another_async_task_2\") as subsegment:\n        subsegment.put_annotation(key=\"key\", value=\"value\")\n        subsegment.put_metadata(key=\"key\", value=\"value\", namespace=\"namespace\")\n        ...\n\n\nasync def collect_payment(charge_id: str) -&gt; str:\n    await asyncio.gather(another_async_task(), another_async_task_2())\n    return f\"dummy payment collected for charge: {charge_id}\"\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return asyncio.run(collect_payment(charge_id=charge_id))\n</code></pre>"
        },
        {
            "location": "core/tracer/#reusing-tracer-across-your-code",
            "title": "Reusing Tracer across your code",
            "text": "<p>Tracer keeps a copy of its configuration after the first initialization. This is useful for scenarios where you want to use Tracer in more than one location across your code base.</p> Warning: Import order matters when using Lambda Layers or multiple modules <p>Do not set <code>auto_patch=False</code> when reusing Tracer in Lambda Layers, or in multiple modules.</p> <p>This can result in the first Tracer config being inherited by new instances, and their modules not being patched.</p> <p>Tracer will automatically ignore imported modules that have been patched.</p> tracer_reuse.pytracer_reuse_module.py <pre><code>from tracer_reuse_module import collect_payment\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\n\n\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    charge_id = event.get(\"charge_id\", \"\")\n    return collect_payment(charge_id=charge_id)\n</code></pre> <p>A new instance of Tracer will be created but will reuse the previous Tracer instance configuration, similar to a Singleton.</p> <pre><code>from aws_lambda_powertools import Tracer\n\ntracer = Tracer()\n\n\n@tracer.capture_method\ndef collect_payment(charge_id: str) -&gt; str:\n    return f\"dummy payment collected for charge: {charge_id}\"\n</code></pre>"
        },
        {
            "location": "core/tracer/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>Tracer is disabled by default when not running in the AWS Lambda environment, including AWS SAM CLI and Chalice environments. This means no code changes or environment variables to be set.</p>"
        },
        {
            "location": "core/tracer/#tips",
            "title": "Tips",
            "text": "<ul> <li>Use annotations on key operations to slice and dice traces, create unique views, and create metrics from it via Trace Groups</li> <li>Use a namespace when adding metadata to group data more easily</li> <li>Annotations and metadata are added to the current subsegment opened. If you want them in a specific subsegment, use a context manager via the escape hatch mechanism</li> </ul>"
        },
        {
            "location": "core/event_handler/_openapi_customization_metadata/",
            "title": "openapi customization metadata",
            "text": "<p>Defining and customizing OpenAPI metadata gives detailed, top-level information about your API. Use the method <code>app.configure_openapi</code> to set and tailor this metadata:</p> Field Name Type Description <code>title</code> <code>str</code> The title for your API. It should be a concise, specific name that can be used to identify the API in documentation or listings. <code>version</code> <code>str</code> The version of the API you are documenting. This could reflect the release iteration of the API and helps clients understand the evolution of the API. <code>openapi_version</code> <code>str</code> Specifies the version of the OpenAPI Specification on which your API is based. When using Pydantic v1 it defaults to 3.0.3, and when using Pydantic v2, it defaults to 3.1.0. <code>summary</code> <code>str</code> A short and informative summary that can provide an overview of what the API does. This can be the same as or different from the title but should add context or information. <code>description</code> <code>str</code> A verbose description that can include Markdown formatting, providing a full explanation of the API's purpose, functionalities, and general usage instructions. <code>tags</code> <code>List[str]</code> A collection of tags that categorize endpoints for better organization and navigation within the documentation. This can group endpoints by their functionality or other criteria. <code>servers</code> <code>List[Server]</code> An array of Server objects, which specify the URL to the server and a description for its environment (production, staging, development, etc.), providing connectivity information. <code>terms_of_service</code> <code>str</code> A URL that points to the terms of service for your API. This could provide legal information and user responsibilities related to the usage of the API. <code>contact</code> <code>Contact</code> A Contact object containing contact details of the organization or individuals maintaining the API. This may include fields such as name, URL, and email. <code>license_info</code> <code>License</code> A License object providing the license details for the API, typically including the name of the license and the URL to the full license text."
        },
        {
            "location": "core/event_handler/_openapi_customization_operations/",
            "title": "openapi customization operations",
            "text": "<p>Customize your API endpoints by adding metadata to endpoint definitions.</p> <p>Here's a breakdown of various customizable fields:</p> Field Name Type Description <code>summary</code> <code>str</code> A concise overview of the main functionality of the endpoint. This brief introduction is usually displayed in autogenerated API documentation and helps consumers quickly understand what the endpoint does. <code>description</code> <code>str</code> A more detailed explanation of the endpoint, which can include information about the operation's behavior, including side effects, error states, and other operational guidelines. <code>responses</code> <code>Dict[int, Dict[str, OpenAPIResponse]]</code> A dictionary that maps each HTTP status code to a Response Object as defined by the OpenAPI Specification. This allows you to describe expected responses, including default or error messages, and their corresponding schemas or models for different status codes. <code>response_description</code> <code>str</code> Provides the default textual description of the response sent by the endpoint when the operation is successful. It is intended to give a human-readable understanding of the result. <code>tags</code> <code>List[str]</code> Tags are a way to categorize and group endpoints within the API documentation. They can help organize the operations by resources or other heuristic. <code>operation_id</code> <code>str</code> A unique identifier for the operation, which can be used for referencing this operation in documentation or code. This ID must be unique across all operations described in the API. <code>include_in_schema</code> <code>bool</code> A boolean value that determines whether or not this operation should be included in the OpenAPI schema. Setting it to <code>False</code> can hide the endpoint from generated documentation and schema exports, which might be useful for private or experimental endpoints. <code>deprecated</code> <code>bool</code> A boolean value that determines whether or not this operation should be marked as deprecated in the OpenAPI schema."
        },
        {
            "location": "core/event_handler/_openapi_customization_parameters/",
            "title": "openapi customization parameters",
            "text": "<p>Whenever you use OpenAPI parameters to validate query strings or path parameters, you can enhance validation and OpenAPI documentation by using any of these parameters:</p> Field name Type Description <code>alias</code> <code>str</code> Alternative name for a field, used when serializing and deserializing data <code>validation_alias</code> <code>str</code> Alternative name for a field during validation (but not serialization) <code>serialization_alias</code> <code>str</code> Alternative name for a field during serialization (but not during validation) <code>description</code> <code>str</code> Human-readable description <code>gt</code> <code>float</code> Greater than. If set, value must be greater than this. Only applicable to numbers <code>ge</code> <code>float</code> Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers <code>lt</code> <code>float</code> Less than. If set, value must be less than this. Only applicable to numbers <code>le</code> <code>float</code> Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers <code>min_length</code> <code>int</code> Minimum length for strings <code>max_length</code> <code>int</code> Maximum length for strings <code>pattern</code> <code>string</code> A regular expression that the string must match. <code>strict</code> <code>bool</code> If <code>True</code>, strict validation is applied to the field. See Strict Mode for details <code>multiple_of</code> <code>float</code> Value must be a multiple of this. Only applicable to numbers <code>allow_inf_nan</code> <code>bool</code> Allow <code>inf</code>, <code>-inf</code>, <code>nan</code>. Only applicable to numbers <code>max_digits</code> <code>int</code> Maximum number of allow digits for strings <code>decimal_places</code> <code>int</code> Maximum number of decimal places allowed for numbers <code>openapi_examples</code> <code>dict[str, Example]</code> A list of examples to be displayed in the SwaggerUI interface. Avoid using the <code>examples</code> field for this purpose. <code>deprecated</code> <code>bool</code> Marks the field as deprecated <code>include_in_schema</code> <code>bool</code> If <code>False</code> the field will not be part of the exported OpenAPI schema <code>json_schema_extra</code> <code>JsonDict</code> Any additional JSON schema data for the schema property"
        },
        {
            "location": "core/event_handler/api_gateway/",
            "title": "REST API",
            "text": "<p>Event handler for Amazon API Gateway REST and HTTP APIs, Application Load Balancer (ALB), Lambda Function URLs, and VPC Lattice.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#key-features",
            "title": "Key Features",
            "text": "<ul> <li>Lightweight routing to reduce boilerplate for API Gateway REST/HTTP API, ALB and Lambda Function URLs</li> <li>Support for CORS, binary and Gzip compression, Decimals JSON encoding and bring your own JSON serializer</li> <li>Built-in integration with Event Source Data Classes utilities for self-documented event schema</li> <li>Works with micro function (one or a few routes) and monolithic functions (all routes)</li> <li>Support for OpenAPI and data validation for requests/responses</li> </ul>"
        },
        {
            "location": "core/event_handler/api_gateway/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#install",
            "title": "Install",
            "text": "<p>This is not necessary if you're installing Powertools for AWS Lambda (Python) via Lambda Layer/SAR.</p> <p>When using the data validation feature, you need to add <code>pydantic</code> as a dependency in your preferred tool e.g., requirements.txt, pyproject.toml.</p> <p>As of now, both Pydantic V1 and V2 are supported. For a future major version, we will only support Pydantic V2.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#required-resources",
            "title": "Required resources",
            "text": "<p>If you're using any API Gateway integration, you must have an existing API Gateway Proxy integration or ALB configured to invoke your Lambda function.</p> <p>In case of using VPC Lattice, you must have a service network configured to invoke your Lambda function.</p> <p>This is the sample infrastructure for API Gateway and Lambda Function URLs we are using for the examples in this documentation.</p> There is no additional permissions or dependencies required to use this utility. API Gateway SAM TemplateLambda Function URL SAM Template AWS Serverless Application Model (SAM) example<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Hello world event handler API Gateway\n\nGlobals:\n  Api:\n    TracingEnabled: true\n    Cors: # see CORS section\n      AllowOrigin: \"'https://example.com'\"\n      AllowHeaders: \"'Content-Type,Authorization,X-Amz-Date'\"\n      MaxAge: \"'300'\"\n    BinaryMediaTypes: # see Binary responses section\n      - \"*~1*\" # converts to */* for any binary type\n      # NOTE: use this stricter version if you're also using CORS; */* doesn't work with CORS\n      # see: https://github.com/aws-powertools/powertools-lambda-python/issues/3373#issuecomment-1821144779\n      # - \"image~1*\" # converts to image/*\n      # - \"*~1csv\" # converts to */csv, eg text/csv, application/csv\n\n  Function:\n    Timeout: 5\n    Runtime: python3.12\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_LOG_LEVEL: INFO\n        POWERTOOLS_LOGGER_SAMPLE_RATE: 0.1\n        POWERTOOLS_LOGGER_LOG_EVENT: true\n        POWERTOOLS_SERVICE_NAME: example\n\nResources:\n  ApiFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: getting_started_rest_api_resolver.lambda_handler\n      CodeUri: ../src\n      Description: API handler function\n      Events:\n        AnyApiEvent:\n          Type: Api\n          Properties:\n            # NOTE: this is a catch-all rule to simplify the documentation.\n            # explicit routes and methods are recommended for prod instead (see below)\n            Path: /{proxy+} # Send requests on any path to the lambda function\n            Method: ANY # Send requests using any http method to the lambda function\n\n\n        # GetAllTodos:\n        #   Type: Api\n        #   Properties:\n        #     Path: /todos\n        #     Method: GET\n        # GetTodoById:\n        #   Type: Api\n        #   Properties:\n        #     Path: /todos/{todo_id}\n        #     Method: GET\n        # CreateTodo:\n        #   Type: Api\n        #   Properties:\n        #     Path: /todos\n        #     Method: POST\n\n        ## Swagger UI specific routes\n\n        # SwaggerUI:\n        #     Type: Api\n        #     Properties:\n        #         Path: /swagger\n        #         Method: GET\n</code></pre> AWS Serverless Application Model (SAM) example<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Hello world event handler Lambda Function URL\n\nGlobals:\n  Function:\n    Timeout: 5\n    Runtime: python3.12\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_LOG_LEVEL: INFO\n        POWERTOOLS_LOGGER_SAMPLE_RATE: 0.1\n        POWERTOOLS_LOGGER_LOG_EVENT: true\n        POWERTOOLS_SERVICE_NAME: example\n    FunctionUrlConfig:\n      Cors: # see CORS section\n        # Notice that values here are Lists of Strings, vs comma-separated values on API Gateway\n        AllowOrigins: [\"https://example.com\"]\n        AllowHeaders: [\"Content-Type\", \"Authorization\", \"X-Amz-Date\"]\n        MaxAge: 300\n\nResources:\n  ApiFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: getting_started_lambda_function_url_resolver.lambda_handler\n      CodeUri: ../src\n      Description: API handler function\n      FunctionUrlConfig:\n        AuthType: NONE # AWS_IAM for added security beyond sample documentation\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#event-resolvers",
            "title": "Event Resolvers",
            "text": "<p>Before you decorate your functions to handle a given path and HTTP method(s), you need to initialize a resolver. A resolver will handle request resolution, including one or more routers, and give you access to the current event via typed properties.</p> <p>By default, we will use <code>APIGatewayRestResolver</code> throughout the documentation. You can use any of the following:</p> Resolver AWS service <code>APIGatewayRestResolver</code> Amazon API Gateway REST API <code>APIGatewayHttpResolver</code> Amazon API Gateway HTTP API <code>ALBResolver</code> Amazon Application Load Balancer (ALB) <code>LambdaFunctionUrlResolver</code> AWS Lambda Function URL <code>VPCLatticeResolver</code> Amazon VPC Lattice"
        },
        {
            "location": "core/event_handler/api_gateway/#response-auto-serialization",
            "title": "Response auto-serialization",
            "text": "<p>Want full control of the response, headers and status code? Read about <code>Response</code> object here.</p> <p>For your convenience, we automatically perform these if you return a dictionary response:</p> <ol> <li>Auto-serialize <code>dictionary</code> responses to JSON and trim it</li> <li>Include the response under each resolver's equivalent of a <code>body</code></li> <li>Set <code>Content-Type</code> to <code>application/json</code></li> <li>Set <code>status_code</code> to 200 (OK)</li> </ol> getting_started_resolvers_response_serialization.pygetting_started_resolvers_response_serialization_output.json <pre><code>from aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.utilities.typing.lambda_context import LambdaContext\n\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/ping\")\ndef ping():\n    return {\"message\": \"pong\"}  # (1)!\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>This dictionary will be serialized, trimmed, and included under the <code>body</code> key</li> </ol> <pre><code>{\n    \"statusCode\": 200,\n    \"multiValueHeaders\": {\n        \"Content-Type\": [\n            \"application/json\"\n        ]\n    },\n    \"body\": \"{'message':'pong'}\",\n    \"isBase64Encoded\": false\n}\n</code></pre> Coming from Flask? We also support tuple response <p>You can optionally set a different HTTP status code as the second argument of the tuple.</p> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools.event_handler import ALBResolver\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = ALBResolver()\n\n\n@app.post(\"/todo\")\ndef create_todo():\n    data: dict = app.current_event.json_body\n    todo: Response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", data=data)\n\n    # Returns the created todo object, with a HTTP 201 Created status\n    return {\"todo\": todo.json()}, 201\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#api-gateway-rest-api",
            "title": "API Gateway REST API",
            "text": "<p>When using Amazon API Gateway REST API to front your Lambda functions, you can use <code>APIGatewayRestResolver</code>.</p> <p>Here's an example on how we can handle the <code>/todos</code> path.</p> Trailing slash in routes <p>For <code>APIGatewayRestResolver</code>, we seamless handle routes with a trailing slash (<code>/todos/</code>).</p> getting_started_rest_api_resolver.pygetting_started_rest_api_resolver.jsongetting_started_rest_api_resolver_output.json <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <p>This utility uses <code>path</code> and <code>httpMethod</code> to route to the right function. This helps make unit tests and local invocation easier too.</p> <pre><code>{\n    \"body\": \"\",\n    \"resource\": \"/todos\",\n    \"path\": \"/todos\",\n    \"httpMethod\": \"GET\",\n    \"isBase64Encoded\": false,\n    \"queryStringParameters\": {},\n    \"multiValueQueryStringParameters\": {},\n    \"pathParameters\": {},\n    \"stageVariables\": {},\n    \"headers\": {\n        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n        \"Accept-Encoding\": \"gzip, deflate, sdch\",\n        \"Accept-Language\": \"en-US,en;q=0.8\",\n        \"Cache-Control\": \"max-age=0\",\n        \"CloudFront-Forwarded-Proto\": \"https\",\n        \"CloudFront-Is-Desktop-Viewer\": \"true\",\n        \"CloudFront-Is-Mobile-Viewer\": \"false\",\n        \"CloudFront-Is-SmartTV-Viewer\": \"false\",\n        \"CloudFront-Is-Tablet-Viewer\": \"false\",\n        \"CloudFront-Viewer-Country\": \"US\",\n        \"Host\": \"1234567890.execute-api.us-east-1.amazonaws.com\",\n        \"Upgrade-Insecure-Requests\": \"1\",\n        \"User-Agent\": \"Custom User Agent String\",\n        \"Via\": \"1.1 08f323deadbeefa7af34d5feb414ce27.cloudfront.net (CloudFront)\",\n        \"X-Amz-Cf-Id\": \"cDehVQoZnx43VYQb9j2-nvCh-9z396Uhbp027Y2JvkCPNLmGJHqlaA==\",\n        \"X-Forwarded-For\": \"127.0.0.1, 127.0.0.2\",\n        \"X-Forwarded-Port\": \"443\",\n        \"X-Forwarded-Proto\": \"https\"\n    },\n    \"multiValueHeaders\": {},\n    \"requestContext\": {\n        \"accountId\": \"123456789012\",\n        \"resourceId\": \"123456\",\n        \"stage\": \"Prod\",\n        \"requestId\": \"c6af9ac6-7b61-11e6-9a41-93e8deadbeef\",\n        \"requestTime\": \"25/Jul/2020:12:34:56 +0000\",\n        \"requestTimeEpoch\": 1428582896000,\n        \"identity\": {\n            \"cognitoIdentityPoolId\": null,\n            \"accountId\": null,\n            \"cognitoIdentityId\": null,\n            \"caller\": null,\n            \"accessKey\": null,\n            \"sourceIp\": \"127.0.0.1\",\n            \"cognitoAuthenticationType\": null,\n            \"cognitoAuthenticationProvider\": null,\n            \"userArn\": null,\n            \"userAgent\": \"Custom User Agent String\",\n            \"user\": null\n        },\n        \"path\": \"/Prod/todos\",\n        \"resourcePath\": \"/todos\",\n        \"httpMethod\": \"GET\",\n        \"apiId\": \"1234567890\",\n        \"protocol\": \"HTTP/1.1\"\n    }\n}\n</code></pre> <pre><code>{\n    \"statusCode\": 200,\n    \"multiValueHeaders\": {\n        \"Content-Type\": [\"application/json\"]\n    },\n    \"body\": \"{\\\"todos\\\":[{\\\"userId\\\":1,\\\"id\\\":1,\\\"title\\\":\\\"delectus aut autem\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":2,\\\"title\\\":\\\"quis ut nam facilis et officia qui\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":3,\\\"title\\\":\\\"fugiat veniam minus\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":4,\\\"title\\\":\\\"et porro tempora\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":5,\\\"title\\\":\\\"laboriosam mollitia et enim quasi adipisci quia provident illum\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":6,\\\"title\\\":\\\"qui ullam ratione quibusdam voluptatem quia omnis\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":7,\\\"title\\\":\\\"illo expedita consequatur quia in\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":8,\\\"title\\\":\\\"quo adipisci enim quam ut ab\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":9,\\\"title\\\":\\\"molestiae perspiciatis ipsa\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":10,\\\"title\\\":\\\"illo est ratione doloremque quia maiores aut\\\",\\\"completed\\\":true}]}\",\n    \"isBase64Encoded\": false\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#api-gateway-http-api",
            "title": "API Gateway HTTP API",
            "text": "<p>When using Amazon API Gateway HTTP API to front your Lambda functions, you can use <code>APIGatewayHttpResolver</code>.</p> Note <p>Using HTTP API v1 payload? Use <code>APIGatewayRestResolver</code> instead. <code>APIGatewayHttpResolver</code> defaults to v2 payload.</p> <p>If you're using Terraform to deploy a HTTP API, note that it defaults the payload_format_version value to 1.0 if not specified.</p> Using HTTP API resolver<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayHttpResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayHttpResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#application-load-balancer",
            "title": "Application Load Balancer",
            "text": "<p>When using Amazon Application Load Balancer (ALB) to front your Lambda functions, you can use <code>ALBResolver</code>.</p> Using ALB resolver<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import ALBResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = ALBResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPLICATION_LOAD_BALANCER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#lambda-function-url",
            "title": "Lambda Function URL",
            "text": "<p>When using AWS Lambda Function URL, you can use <code>LambdaFunctionUrlResolver</code>.</p> getting_started_lambda_function_url_resolver.pygetting_started_lambda_function_url_resolver.json Using Lambda Function URL resolver<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import LambdaFunctionUrlResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = LambdaFunctionUrlResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.LAMBDA_FUNCTION_URL)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> Example payload delivered to the handler<pre><code>{\n  \"version\": \"2.0\",\n  \"routeKey\": \"$default\",\n  \"rawPath\": \"/todos\",\n  \"rawQueryString\": \"\",\n  \"headers\": {\n    \"x-amz-content-sha256\": \"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\",\n    \"x-amzn-tls-version\": \"TLSv1.2\",\n    \"x-amz-date\": \"20220803T092917Z\",\n    \"x-forwarded-proto\": \"https\",\n    \"x-forwarded-port\": \"443\",\n    \"x-forwarded-for\": \"123.123.123.123\",\n    \"accept\": \"application/xml\",\n    \"x-amzn-tls-cipher-suite\": \"ECDHE-RSA-AES128-GCM-SHA256\",\n    \"x-amzn-trace-id\": \"Root=1-63ea3fee-51ba94542feafa3928745ba3\",\n    \"host\": \"xxxxxxxxxxxxx.lambda-url.eu-central-1.on.aws\",\n    \"content-type\": \"application/json\",\n    \"accept-encoding\": \"gzip, deflate\",\n    \"user-agent\": \"Custom User Agent\"\n  },\n  \"requestContext\": {\n    \"accountId\": \"123457890\",\n    \"apiId\": \"xxxxxxxxxxxxxxxxxxxx\",\n    \"authorizer\": {\n      \"iam\": {\n        \"accessKey\": \"AAAAAAAAAAAAAAAAAA\",\n        \"accountId\": \"123457890\",\n        \"callerId\": \"AAAAAAAAAAAAAAAAAA\",\n        \"cognitoIdentity\": null,\n        \"principalOrgId\": \"o-xxxxxxxxxxxx\",\n        \"userArn\": \"arn:aws:iam::AAAAAAAAAAAAAAAAAA:user/user\",\n        \"userId\": \"AAAAAAAAAAAAAAAAAA\"\n      }\n    },\n    \"domainName\": \"xxxxxxxxxxxxx.lambda-url.eu-central-1.on.aws\",\n    \"domainPrefix\": \"xxxxxxxxxxxxx\",\n    \"http\": {\n      \"method\": \"GET\",\n      \"path\": \"/todos\",\n      \"protocol\": \"HTTP/1.1\",\n      \"sourceIp\": \"123.123.123.123\",\n      \"userAgent\": \"Custom User Agent\"\n    },\n    \"requestId\": \"24f9ef37-8eb7-45fe-9dbc-a504169fd2f8\",\n    \"routeKey\": \"$default\",\n    \"stage\": \"$default\",\n    \"time\": \"03/Aug/2022:09:29:18 +0000\",\n    \"timeEpoch\": 1659518958068\n  },\n  \"isBase64Encoded\": false\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#vpc-lattice",
            "title": "VPC Lattice",
            "text": "<p>When using VPC Lattice with AWS Lambda, you can use <code>VPCLatticeV2Resolver</code>.</p> Payload v2 (Recommended)Payload v2 (Recommended) - Sample EventPayload v1Payload v1 - Sample Event Using VPC Lattice resolver<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import VPCLatticeV2Resolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = VPCLatticeV2Resolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPLICATION_LOAD_BALANCER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> Example payload delivered to the handler<pre><code>{\n  \"version\": \"2.0\",\n  \"path\": \"/todos\",\n  \"method\": \"GET\",\n  \"headers\": {\n    \"user_agent\": \"curl/7.64.1\",\n    \"x-forwarded-for\": \"10.213.229.10\",\n    \"host\": \"test-lambda-service-3908sdf9u3u.dkfjd93.vpc-lattice-svcs.us-east-2.on.aws\",\n    \"accept\": \"*/*\"\n  },\n  \"queryStringParameters\": {\n    \"order-id\": \"1\"\n  },\n  \"body\": \"{\\\"message\\\": \\\"Hello from Lambda!\\\"}\",\n  \"requestContext\": {\n      \"serviceNetworkArn\": \"arn:aws:vpc-lattice:us-east-2:123456789012:servicenetwork/sn-0bf3f2882e9cc805a\",\n      \"serviceArn\": \"arn:aws:vpc-lattice:us-east-2:123456789012:service/svc-0a40eebed65f8d69c\",\n      \"targetGroupArn\": \"arn:aws:vpc-lattice:us-east-2:123456789012:targetgroup/tg-6d0ecf831eec9f09\",\n      \"identity\": {\n        \"sourceVpcArn\": \"arn:aws:ec2:region:123456789012:vpc/vpc-0b8276c84697e7339\",\n        \"type\" : \"AWS_IAM\",\n        \"principal\": \"arn:aws:sts::123456789012:assumed-role/example-role/057d00f8b51257ba3c853a0f248943cf\",\n        \"sessionName\": \"057d00f8b51257ba3c853a0f248943cf\",\n        \"x509SanDns\": \"example.com\"\n      },\n      \"region\": \"us-east-2\",\n      \"timeEpoch\": \"1696331543569073\"\n  }\n}\n</code></pre> Using VPC Lattice resolver<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import VPCLatticeResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = VPCLatticeResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPLICATION_LOAD_BALANCER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> Example payload delivered to the handler<pre><code>{\n    \"raw_path\": \"/testpath\",\n    \"method\": \"GET\",\n    \"headers\": {\n      \"user_agent\": \"curl/7.64.1\",\n      \"x-forwarded-for\": \"10.213.229.10\",\n      \"host\": \"test-lambda-service-3908sdf9u3u.dkfjd93.vpc-lattice-svcs.us-east-2.on.aws\",\n      \"accept\": \"*/*\"\n    },\n    \"query_string_parameters\": {\n      \"order-id\": \"1\"\n    },\n    \"body\": \"eyJ0ZXN0IjogImV2ZW50In0=\",\n    \"is_base64_encoded\": true\n  }\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#dynamic-routes",
            "title": "Dynamic routes",
            "text": "<p>You can use <code>/todos/&lt;todo_id&gt;</code> to configure dynamic URL paths, where <code>&lt;todo_id&gt;</code> will be resolved at runtime.</p> <p>Each dynamic route you set must be part of your function signature. This allows us to call your function using keyword arguments when matching your dynamic route.</p> Note <p>For brevity, we will only include the necessary keys for each sample request for the example to work.</p> dynamic_routes.pydynamic_routes.json <pre><code>from urllib.parse import quote\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/todos/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: str):  # value come as str\n    todo_id = quote(todo_id, safe=\"\")\n    todos: Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"resource\": \"/todos/{id}\",\n    \"path\": \"/todos/1\",\n    \"httpMethod\": \"GET\"\n}\n</code></pre> Tip <p>You can also nest dynamic paths, for example <code>/todos/&lt;todo_id&gt;/&lt;todo_status&gt;</code>.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#catch-all-routes",
            "title": "Catch-all routes",
            "text": "Note <p>We recommend having explicit routes whenever possible; use catch-all routes sparingly.</p> <p>You can use a regex string to handle an arbitrary number of paths within a request, for example <code>.+</code>.</p> <p>You can also combine nested paths with greedy regex to catch in between routes.</p> Warning <p>We choose the most explicit registered route that matches an incoming event.</p> dynamic_routes_catch_all.pydynamic_routes_catch_all.json <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\".+\")\n@tracer.capture_method\ndef catch_any_route_get_method():\n    return {\"path_received\": app.current_event.path}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"resource\": \"/{proxy+}\",\n    \"path\": \"/any/route/should/work\",\n    \"httpMethod\": \"GET\"\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#http-methods",
            "title": "HTTP Methods",
            "text": "<p>You can use named decorators to specify the HTTP method that should be handled in your functions. That is, <code>app.&lt;http_method&gt;</code>, where the HTTP method could be <code>get</code>, <code>post</code>, <code>put</code>, <code>patch</code> and <code>delete</code>.</p> http_methods.pyhttp_methods.json <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.post(\"/todos\")\n@tracer.capture_method\ndef create_todo():\n    todo_data: dict = app.current_event.json_body  # deserialize json str to dict\n    todo: Response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", data=todo_data)\n    todo.raise_for_status()\n\n    return {\"todo\": todo.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"resource\": \"/todos\",\n    \"path\": \"/todos\",\n    \"httpMethod\": \"POST\",\n    \"body\": \"{\\\"title\\\": \\\"foo\\\", \\\"userId\\\": 1, \\\"completed\\\": false}\"\n}\n</code></pre> <p>If you need to accept multiple HTTP methods in a single function, or support a HTTP method for which no decorator exists (e.g. TRACE), you can use the <code>route</code> method and pass a list of HTTP methods.</p> Handling multiple HTTP Methods<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n# PUT and POST HTTP requests to the path /hello will route to this function\n@app.route(\"/todos\", method=[\"PUT\", \"POST\"])\n@tracer.capture_method\ndef create_todo():\n    todo_data: dict = app.current_event.json_body  # deserialize json str to dict\n    todo: Response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", data=todo_data)\n    todo.raise_for_status()\n\n    return {\"todo\": todo.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> Note <p>It is generally better to have separate functions for each HTTP method, as the functionality tends to differ depending on which method is used.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#data-validation",
            "title": "Data validation",
            "text": "<p>This changes the authoring experience by relying on Python's type annotations</p> <p>It's inspired by FastAPI framework for ergonomics and to ease migrations in either direction. We support both Pydantic models and Python's dataclass.</p> <p>For brevity, we'll focus on Pydantic only.</p> <p>All resolvers can optionally coerce and validate incoming requests by setting <code>enable_validation=True</code>.</p> <p>With this feature, we can now express how we expect our incoming data and response to look like. This moves data validation responsibilities to Event Handler resolvers, reducing a ton of boilerplate code.</p> <p>Let's rewrite the previous examples to signal our resolver what shape we expect our data to be.</p> data_validation.pydata_validation.jsondata_validation_output.json <pre><code>from typing import Optional\n\nimport requests\nfrom pydantic import BaseModel, Field\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(enable_validation=True)  # (1)!\n\n\nclass Todo(BaseModel):  # (2)!\n    userId: int\n    id_: Optional[int] = Field(alias=\"id\", default=None)\n    title: str\n    completed: bool\n\n\n@app.get(\"/todos/&lt;todo_id&gt;\")  # (3)!\n@tracer.capture_method\ndef get_todo_by_id(todo_id: int) -&gt; Todo:  # (4)!\n    todo = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todo.raise_for_status()\n\n    return todo.json()  # (5)!\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>This enforces data validation at runtime. Any validation error will return <code>HTTP 422: Unprocessable Entity error</code>.</li> <li>We create a Pydantic model to define how our data looks like.</li> <li>Defining a route remains exactly as before.</li> <li>By default, URL Paths will be <code>str</code>. Here, we are telling our resolver it should be <code>int</code>, so it converts it for us.  Lastly, we're also saying the return should be our <code>Todo</code>. This will help us later when we touch OpenAPI auto-documentation.</li> <li><code>todo.json()</code> returns a dictionary. However, Event Handler knows the response should be <code>Todo</code> so it converts and validates accordingly.</li> </ol> <pre><code>{\n  \"version\": \"1.0\",\n  \"resource\": \"/todos/1\",\n  \"path\": \"/todos/1\",\n  \"httpMethod\": \"GET\",\n  \"headers\": {\n    \"Origin\": \"https://aws.amazon.com\"\n  },\n  \"multiValueHeaders\": {},\n  \"queryStringParameters\": {},\n  \"multiValueQueryStringParameters\": {},\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"apiId\": \"id\",\n    \"authorizer\": {\n      \"claims\": null,\n      \"scopes\": null\n    },\n    \"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n    \"domainPrefix\": \"id\",\n    \"extendedRequestId\": \"request-id\",\n    \"httpMethod\": \"GET\",\n    \"path\": \"/todos/1\",\n    \"protocol\": \"HTTP/1.1\",\n    \"requestId\": \"id=\",\n    \"requestTime\": \"04/Mar/2020:19:15:17 +0000\",\n    \"requestTimeEpoch\": 1583349317135,\n    \"resourceId\": null,\n    \"resourcePath\": \"/todos/1\",\n    \"stage\": \"$default\"\n  },\n  \"pathParameters\": null,\n  \"stageVariables\": null,\n  \"body\": \"\",\n  \"isBase64Encoded\": false\n}\n</code></pre> <pre><code>{\n  \"statusCode\": 200,\n  \"body\": \"Hello world\",\n  \"isBase64Encoded\": false,\n  \"multiValueHeaders\": {\n    \"Content-Type\": [\n      \"application/json\"\n    ]\n  }\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#handling-validation-errors",
            "title": "Handling validation errors",
            "text": "<p>By default, we hide extended error details for security reasons (e.g., pydantic url, Pydantic code).</p> <p>Any incoming request or and outgoing response that fails validation will lead to a <code>HTTP 422: Unprocessable Entity error</code> response that will look similar to this:</p> data_validation_error_unsanitized_output.json<pre><code>{\n  \"statusCode\": 422,\n  \"body\": \"{\\\"statusCode\\\": 422, \\\"detail\\\": [{\\\"type\\\": \\\"int_parsing\\\", \\\"loc\\\": [\\\"path\\\", \\\"todo_id\\\"]}]}\",\n  \"isBase64Encoded\": false,\n  \"headers\": {\n    \"Content-Type\": \"application/json\"\n  },\n  \"cookies\": []\n}\n</code></pre> <p>You can customize the error message by catching the <code>RequestValidationError</code> exception. This is useful when you might have a security policy to return opaque validation errors, or have a company standard for API validation errors.</p> <p>Here's an example where we catch validation errors, log all details for further investigation, and return the same <code>HTTP 422</code> with an opaque error.</p> data_validation_sanitized_error.pydata_validation_sanitized_error_output.json <pre><code>from typing import Optional\n\nimport requests\nfrom pydantic import BaseModel, Field\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response, content_types\nfrom aws_lambda_powertools.event_handler.openapi.exceptions import RequestValidationError\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(enable_validation=True)\n\n\nclass Todo(BaseModel):\n    userId: int\n    id_: Optional[int] = Field(alias=\"id\", default=None)\n    title: str\n    completed: bool\n\n\n@app.exception_handler(RequestValidationError)  # (1)!\ndef handle_validation_error(ex: RequestValidationError):\n    logger.error(\"Request failed validation\", path=app.current_event.path, errors=ex.errors())\n\n    return Response(\n        status_code=422,\n        content_type=content_types.APPLICATION_JSON,\n        body=\"Invalid data\",\n    )\n\n\n@app.post(\"/todos\")\ndef create_todo(todo: Todo) -&gt; int:\n    response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", json=todo.dict(by_alias=True))\n    response.raise_for_status()\n\n    return response.json()[\"id\"]\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>We use exception handler decorator to catch any request validation errors.  Then, we log the detailed reason as to why it failed while returning a custom <code>Response</code> object to hide that from them.</li> </ol> <pre><code>{\n  \"statusCode\": 422,\n  \"body\": \"Invalid data\",\n  \"isBase64Encoded\": false,\n  \"headers\": {\n    \"Content-Type\": \"application/json\"\n  },\n  \"cookies\": []\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#validating-payloads",
            "title": "Validating payloads",
            "text": "<p>We will automatically validate, inject, and convert incoming request payloads based on models via type annotation.</p> <p>Let's improve our previous example by handling the creation of todo items via <code>HTTP POST</code>.</p> <p>What we want is for Event Handler to convert the incoming payload as an instance of our <code>Todo</code> model. We handle the creation of that <code>todo</code>, and then return the <code>ID</code> of the newly created <code>todo</code>.</p> <p>Even better, we can also let Event Handler validate and convert our response according to type annotations, further reducing boilerplate.</p> validating_payloads.pyvalidating_payloads.jsonvalidating_payloads_output.json <pre><code>from typing import List, Optional\n\nimport requests\nfrom pydantic import BaseModel, Field\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(enable_validation=True)  # (1)!\n\n\nclass Todo(BaseModel):  # (2)!\n    userId: int\n    id_: Optional[int] = Field(alias=\"id\", default=None)\n    title: str\n    completed: bool\n\n\n@app.post(\"/todos\")\ndef create_todo(todo: Todo) -&gt; str:  # (3)!\n    response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", json=todo.dict(by_alias=True))\n    response.raise_for_status()\n\n    return response.json()[\"id\"]  # (4)!\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos() -&gt; List[Todo]:\n    todo = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todo.raise_for_status()\n\n    return todo.json()  # (5)!\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>This enforces data validation at runtime. Any validation error will return <code>HTTP 422: Unprocessable Entity error</code>.</li> <li>We create a Pydantic model to define how our data looks like.</li> <li>We define <code>Todo</code> as our type annotation. Event Handler then uses this model to validate and inject the incoming request as <code>Todo</code>.</li> <li>Lastly, we return the ID of our newly created <code>todo</code> item.  Because we specify the return type (<code>str</code>), Event Handler will take care of serializing this as a JSON string.</li> <li>Note that the return type is <code>List[Todo]</code>.  Event Handler will take the return (<code>todo.json</code>), and validate each list item against <code>Todo</code> model before returning the response accordingly.</li> </ol> <pre><code>{\n  \"version\": \"1.0\",\n  \"body\": \"{\\\"title\\\": \\\"foo\\\", \\\"userId\\\": \\\"1\\\", \\\"completed\\\": false}\",\n  \"resource\": \"/todos\",\n  \"path\": \"/todos\",\n  \"httpMethod\": \"POST\",\n  \"headers\": {\n    \"Origin\": \"https://aws.amazon.com\"\n  },\n  \"multiValueHeaders\": {},\n  \"queryStringParameters\": {},\n  \"multiValueQueryStringParameters\": {},\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"apiId\": \"id\",\n    \"authorizer\": {\n      \"claims\": null,\n      \"scopes\": null\n    },\n    \"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n    \"domainPrefix\": \"id\",\n    \"extendedRequestId\": \"request-id\",\n    \"httpMethod\": \"POST\",\n    \"path\": \"/todos\",\n    \"protocol\": \"HTTP/1.1\",\n    \"requestId\": \"id=\",\n    \"requestTime\": \"04/Mar/2020:19:15:17 +0000\",\n    \"requestTimeEpoch\": 1583349317135,\n    \"resourceId\": null,\n    \"resourcePath\": \"/todos\",\n    \"stage\": \"$default\"\n  },\n  \"pathParameters\": null,\n  \"stageVariables\": null,\n  \"isBase64Encoded\": false\n}\n</code></pre> <pre><code>{\n  \"statusCode\": 200,\n  \"body\": \"2008821\",\n  \"isBase64Encoded\": false,\n  \"multiValueHeaders\": {\n    \"Content-Type\": [\n      \"application/json\"\n    ]\n  }\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#validating-payload-subset",
            "title": "Validating payload subset",
            "text": "<p>With the addition of the <code>Annotated</code> type starting in Python 3.9, types can contain additional metadata, allowing us to represent anything we want.</p> <p>We use the <code>Annotated</code> and OpenAPI <code>Body</code> type to instruct Event Handler that our payload is located in a particular JSON key.</p> <p>Event Handler will match the parameter name with the JSON key to validate and inject what you want.</p> validating_payload_subset.pyvalidating_payload_subset.jsonvalidating_payload_subset_output.json <pre><code>from typing import Optional\n\nimport requests\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import Annotated\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.openapi.params import Body  # (1)!\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver(enable_validation=True)\n\n\nclass Todo(BaseModel):\n    userId: int\n    id_: Optional[int] = Field(alias=\"id\", default=None)\n    title: str\n    completed: bool\n\n\n@app.post(\"/todos\")\ndef create_todo(todo: Annotated[Todo, Body(embed=True)]) -&gt; int:  # (2)!\n    response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", json=todo.dict(by_alias=True))\n    response.raise_for_status()\n\n    return response.json()[\"id\"]\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li><code>Body</code> is a special OpenAPI type that can add additional constraints to a request payload.</li> <li><code>Body(embed=True)</code> instructs Event Handler to look up inside the payload for a key. This means Event Handler will look up for a key named <code>todo</code>, validate the value against <code>Todo</code>, and inject it.</li> </ol> <pre><code>{\n  \"version\": \"1.0\",\n  \"body\": \"{ \\\"todo\\\": {\\\"title\\\": \\\"foo\\\", \\\"userId\\\": \\\"1\\\", \\\"completed\\\": false } }\",\n  \"resource\": \"/todos\",\n  \"path\": \"/todos\",\n  \"httpMethod\": \"POST\",\n  \"headers\": {\n    \"Origin\": \"https://aws.amazon.com\"\n  },\n  \"multiValueHeaders\": {},\n  \"queryStringParameters\": {},\n  \"multiValueQueryStringParameters\": {},\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"apiId\": \"id\",\n    \"authorizer\": {\n      \"claims\": null,\n      \"scopes\": null\n    },\n    \"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n    \"domainPrefix\": \"id\",\n    \"extendedRequestId\": \"request-id\",\n    \"httpMethod\": \"POST\",\n    \"path\": \"/todos\",\n    \"protocol\": \"HTTP/1.1\",\n    \"requestId\": \"id=\",\n    \"requestTime\": \"04/Mar/2020:19:15:17 +0000\",\n    \"requestTimeEpoch\": 1583349317135,\n    \"resourceId\": null,\n    \"resourcePath\": \"/todos\",\n    \"stage\": \"$default\"\n  },\n  \"pathParameters\": null,\n  \"stageVariables\": null,\n  \"isBase64Encoded\": false\n}\n</code></pre> <pre><code>{\n  \"statusCode\": 200,\n  \"body\": \"2008822\",\n  \"isBase64Encoded\": false,\n  \"multiValueHeaders\": {\n    \"Content-Type\": [\n      \"application/json\"\n    ]\n  }\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#validating-responses",
            "title": "Validating responses",
            "text": "<p>You can use <code>response_validation_error_http_code</code> to set a custom HTTP code for failed response validation. When this field is set, we will raise a <code>ResponseValidationError</code> instead of a <code>RequestValidationError</code>.</p> customizing_response_validation.pycustomizing_response_validation_exception.py <pre><code>from http import HTTPStatus\nfrom typing import Optional\n\nimport requests\nfrom pydantic import BaseModel, Field\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(\n    enable_validation=True,\n    response_validation_error_http_code=HTTPStatus.INTERNAL_SERVER_ERROR,  # (1)!\n)\n\n\nclass Todo(BaseModel):\n    userId: int\n    id_: Optional[int] = Field(alias=\"id\", default=None)\n    title: str\n    completed: bool\n\n\n@app.get(\"/todos_bad_response/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: int) -&gt; Todo:\n    todo = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todo.raise_for_status()\n\n    return todo.json()[\"title\"]  # (2)!\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>A response with status code set here will be returned if response data is not valid.</li> <li>Operation returns a string as oppose to a <code>Todo</code> object. This will lead to a <code>500</code> response as set in line 18.</li> </ol> <pre><code>from http import HTTPStatus\nfrom typing import Optional\n\nimport requests\nfrom pydantic import BaseModel, Field\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, content_types\nfrom aws_lambda_powertools.event_handler.api_gateway import Response\nfrom aws_lambda_powertools.event_handler.openapi.exceptions import ResponseValidationError\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(\n    enable_validation=True,\n    response_validation_error_http_code=HTTPStatus.INTERNAL_SERVER_ERROR,\n)\n\n\nclass Todo(BaseModel):\n    userId: int\n    id_: Optional[int] = Field(alias=\"id\", default=None)\n    title: str\n    completed: bool\n\n\n@app.get(\"/todos_bad_response/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: int) -&gt; Todo:\n    todo = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todo.raise_for_status()\n\n    return todo.json()[\"title\"]\n\n\n@app.exception_handler(ResponseValidationError)  # (1)!\ndef handle_response_validation_error(ex: ResponseValidationError):\n    logger.error(\"Request failed validation\", path=app.current_event.path, errors=ex.errors())\n\n    return Response(\n        status_code=500,\n        content_type=content_types.APPLICATION_JSON,\n        body=\"Unexpected response.\",\n    )\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>The distinct <code>ResponseValidationError</code> exception can be caught to customise the response.</li> </ol>"
        },
        {
            "location": "core/event_handler/api_gateway/#validating-query-strings",
            "title": "Validating query strings",
            "text": "<p>We will automatically validate and inject incoming query strings via type annotation.</p> <p>We use the <code>Annotated</code> type to tell the Event Handler that a particular parameter is not only an optional string, but also a query string with constraints.</p> <p>In the following example, we use a new <code>Query</code> OpenAPI type to add one out of many possible constraints, which should read as:</p> <ul> <li><code>completed</code> is a query string with a <code>None</code> as its default value</li> <li><code>completed</code>, when set, should have at minimum 4 characters</li> <li>No match? Event Handler will return a validation error response</li> </ul> validating_query_strings.pyskip_validating_query_strings.pyworking_with_multi_query_values.py <pre><code>from typing import List, Optional\n\nimport requests\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import Annotated  # (1)!\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.openapi.params import Query  # (2)!\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(enable_validation=True)\n\n\nclass Todo(BaseModel):\n    userId: int\n    id_: Optional[int] = Field(alias=\"id\", default=None)\n    title: str\n    completed: bool\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos(completed: Annotated[Optional[str], Query(min_length=4)] = None) -&gt; List[Todo]:  # (3)!\n    url = \"https://jsonplaceholder.typicode.com/todos\"\n\n    if completed is not None:\n        url = f\"{url}/?completed={completed}\"\n\n    todo = requests.get(url)\n    todo.raise_for_status()\n\n    return todo.json()\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>If you're not using Python 3.9 or higher, you can install and use <code>typing_extensions</code> to the same effect</li> <li><code>Query</code> is a special OpenAPI type that can add constraints to a query string as well as document them</li> <li>First time seeing <code>Annotated</code>?  This special type uses the first argument as the actual type, and subsequent arguments as metadata.  At runtime, static checkers will also see the first argument, but any receiver can inspect it to get the metadata.</li> </ol> <p>If you don't want to validate query strings but simply let Event Handler inject them as parameters, you can omit <code>Query</code> type annotation.</p> <p>This is merely for your convenience.</p> <pre><code>from typing import List, Optional\n\nimport requests\nfrom pydantic import BaseModel, Field\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(enable_validation=True)\n\n\nclass Todo(BaseModel):\n    userId: int\n    id_: Optional[int] = Field(alias=\"id\", default=None)\n    title: str\n    completed: bool\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos(completed: Optional[str] = None) -&gt; List[Todo]:  # (1)!\n    url = \"https://jsonplaceholder.typicode.com/todos\"\n\n    if completed is not None:\n        url = f\"{url}/?completed={completed}\"\n\n    todo = requests.get(url)\n    todo.raise_for_status()\n\n    return todo.json()\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li><code>completed</code> is still the same query string as before, except we simply state it's an string. No <code>Query</code> or <code>Annotated</code> to validate it.</li> </ol> <p>If you need to handle multi-value query parameters, you can create a list of the desired type.</p> <pre><code>from enum import Enum\nfrom typing import List\n\nfrom typing_extensions import Annotated\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.openapi.params import Query\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver(enable_validation=True)\n\n\nclass ExampleEnum(Enum):\n    \"\"\"Example of an Enum class.\"\"\"\n\n    ONE = \"value_one\"\n    TWO = \"value_two\"\n    THREE = \"value_three\"\n\n\n@app.get(\"/todos\")\ndef get(\n    example_multi_value_param: Annotated[\n        List[ExampleEnum],  # (1)!\n        Query(\n            description=\"This is multi value query parameter.\",\n        ),\n    ],\n):\n    \"\"\"Return validated multi-value param values.\"\"\"\n    return example_multi_value_param\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li><code>example_multi_value_param</code> is a list containing values from the <code>ExampleEnum</code> enumeration.</li> </ol>"
        },
        {
            "location": "core/event_handler/api_gateway/#validating-path-parameters",
            "title": "Validating path parameters",
            "text": "<p>Just like we learned in query string validation, we can use a new <code>Path</code> OpenAPI type to add constraints.</p> <p>For example, we could validate that <code>&lt;todo_id&gt;</code> dynamic path should be no greater than three digits.</p> validating_path.py<pre><code>from typing import Optional\n\nimport requests\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import Annotated\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.openapi.params import Path\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(enable_validation=True)\n\n\nclass Todo(BaseModel):\n    userId: int\n    id_: Optional[int] = Field(alias=\"id\", default=None)\n    title: str\n    completed: bool\n\n\n@app.get(\"/todos/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: Annotated[int, Path(lt=999)]) -&gt; Todo:  # (1)!\n    todo = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todo.raise_for_status()\n\n    return todo.json()\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li><code>Path</code> is a special OpenAPI type that allows us to constrain todo_id to be less than 999.</li> </ol>"
        },
        {
            "location": "core/event_handler/api_gateway/#validating-headers",
            "title": "Validating headers",
            "text": "<p>We use the <code>Annotated</code> type to tell the Event Handler that a particular parameter is a header that needs to be validated.</p> <p>We adhere to HTTP RFC standards, which means we treat HTTP headers as case-insensitive.</p> <p>In the following example, we use a new <code>Header</code> OpenAPI type to add one out of many possible constraints, which should read as:</p> <ul> <li><code>correlation_id</code> is a header that must be present in the request</li> <li><code>correlation_id</code> should have 16 characters</li> <li>No match? Event Handler will return a validation error response</li> </ul> validating_headers.pyworking_with_headers_multi_value.py <pre><code>from typing import List, Optional\n\nimport requests\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import Annotated  # (1)!\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.openapi.params import Header  # (2)!\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(enable_validation=True)\n\n\nclass Todo(BaseModel):\n    userId: int\n    id_: Optional[int] = Field(alias=\"id\", default=None)\n    title: str\n    completed: bool\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos(correlation_id: Annotated[str, Header(min_length=16, max_length=16)]) -&gt; List[Todo]:  # (3)!\n    url = \"https://jsonplaceholder.typicode.com/todos\"\n\n    todo = requests.get(url, headers={\"correlation_id\": correlation_id})\n    todo.raise_for_status()\n\n    return todo.json()\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>If you're not using Python 3.9 or higher, you can install and use <code>typing_extensions</code> to the same effect</li> <li><code>Header</code> is a special OpenAPI type that can add constraints and documentation to a header</li> <li>First time seeing <code>Annotated</code>?  This special type uses the first argument as the actual type, and subsequent arguments as metadata.  At runtime, static checkers will also see the first argument, but any receiver can inspect it to get the metadata.</li> </ol> <p>You can handle multi-value headers by declaring it as a list of the desired type.</p> <pre><code>from enum import Enum\nfrom typing import List\n\nfrom typing_extensions import Annotated\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.openapi.params import Header\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver(enable_validation=True)\n\n\nclass CountriesAllowed(Enum):\n    \"\"\"Example of an Enum class.\"\"\"\n\n    US = \"US\"\n    PT = \"PT\"\n    BR = \"BR\"\n\n\n@app.get(\"/hello\")\ndef get(\n    cloudfront_viewer_country: Annotated[\n        List[CountriesAllowed],  # (1)!\n        Header(\n            description=\"This is multi value header parameter.\",\n        ),\n    ],\n):\n    \"\"\"Return validated multi-value header values.\"\"\"\n    return cloudfront_viewer_country\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li><code>cloudfront_viewer_country</code> is a list that must contain values from the <code>CountriesAllowed</code> enumeration.</li> </ol>"
        },
        {
            "location": "core/event_handler/api_gateway/#supported-types-for-response-serialization",
            "title": "Supported types for response serialization",
            "text": "<p>With data validation enabled, we natively support serializing the following data types to JSON:</p> Data type Serialized type Pydantic models <code>dict</code> Python Dataclasses <code>dict</code> Enum Enum values Datetime Datetime ISO format string Decimal <code>int</code> if no exponent, or <code>float</code> Path <code>str</code> UUID <code>str</code> Set <code>list</code> Python primitives (dict, string, sequences, numbers, booleans) Python's default JSON serializable types See custom serializer section for bringing your own. <p>Otherwise, we will raise <code>SerializationError</code> for any unsupported types e.g., SQLAlchemy models.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#accessing-request-details",
            "title": "Accessing request details",
            "text": "<p>Event Handler integrates with Event Source Data Classes utilities, and it exposes their respective resolver request details and convenient methods under <code>app.current_event</code>.</p> <p>That is why you see <code>app.resolve(event, context)</code> in every example. This allows Event Handler to resolve requests, and expose data like <code>app.lambda_context</code> and  <code>app.current_event</code>.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#query-strings-and-payload",
            "title": "Query strings and payload",
            "text": "<p>Within <code>app.current_event</code> property, you can access all available query strings as a dictionary via <code>query_string_parameters</code>.</p> <p>You can access the raw payload via <code>body</code> property, or if it's a JSON string you can quickly deserialize it via <code>json_body</code> property - like the earlier example in the HTTP Methods section.</p> Accessing query strings and raw payload<pre><code>from typing import List, Optional\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todo_id: str = app.current_event.query_string_parameters[\"id\"]\n    # alternatively\n    _: Optional[str] = app.current_event.query_string_parameters.get(\"id\")\n\n    # or multi-value query string parameters; ?category=\"red\"&amp;?category=\"blue\"\n    _: List[str] = app.current_event.multi_value_query_string_parameters[\"category\"]\n\n    # Payload\n    _: Optional[str] = app.current_event.body  # raw str | None\n\n    endpoint = \"https://jsonplaceholder.typicode.com/todos\"\n    if todo_id:\n        endpoint = f\"{endpoint}/{todo_id}\"\n\n    todos: Response = requests.get(endpoint)\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#headers",
            "title": "Headers",
            "text": "<p>Similarly to Query strings, you can access headers as dictionary via <code>app.current_event.headers</code>. Specifically for headers, it's a case-insensitive dictionary, so all lookups are case-insensitive.</p> Accessing HTTP Headers<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    endpoint = \"https://jsonplaceholder.typicode.com/todos\"\n\n    api_key = app.current_event.headers.get(\"X-Api-Key\")\n    todos: Response = requests.get(endpoint, headers={\"X-Api-Key\": api_key})\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#handling-not-found-routes",
            "title": "Handling not found routes",
            "text": "<p>By default, we return <code>404</code> for any unmatched route.</p> <p>You can use <code>not_found</code> decorator to override this behavior, and return a custom <code>Response</code>.</p> Handling not found<pre><code>import requests\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import (\n    APIGatewayRestResolver,\n    Response,\n    content_types,\n)\nfrom aws_lambda_powertools.event_handler.exceptions import NotFoundError\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.not_found\n@tracer.capture_method\ndef handle_not_found_errors(exc: NotFoundError) -&gt; Response:\n    logger.info(f\"Not found route: {app.current_event.path}\")\n    return Response(status_code=418, content_type=content_types.TEXT_PLAIN, body=\"I'm a teapot!\")\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#exception-handling",
            "title": "Exception handling",
            "text": "<p>You can use <code>exception_handler</code> decorator with any Python exception. This allows you to handle a common exception outside your route, for example validation errors.</p> Exception handling<pre><code>import requests\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import (\n    APIGatewayRestResolver,\n    Response,\n    content_types,\n)\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.exception_handler(ValueError)\ndef handle_invalid_limit_qs(ex: ValueError):  # receives exception raised\n    metadata = {\"path\": app.current_event.path, \"query_strings\": app.current_event.query_string_parameters}\n    logger.error(f\"Malformed request: {ex}\", extra=metadata)\n\n    return Response(\n        status_code=400,\n        content_type=content_types.TEXT_PLAIN,\n        body=\"Invalid request parameters.\",\n    )\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    # educational purpose only: we should receive a `ValueError`\n    # if a query string value for `limit` cannot be coerced to int\n    max_results = int(app.current_event.query_string_parameters.get(\"limit\", 0))\n\n    todos: requests.Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos?limit={max_results}\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> Info <p>The <code>exception_handler</code> also supports passing a list of exception types you wish to handle with one handler.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#raising-http-errors",
            "title": "Raising HTTP errors",
            "text": "<p>You can easily raise any HTTP Error back to the client using <code>ServiceError</code> exception. This ensures your Lambda function doesn't fail but return the correct HTTP response signalling the error.</p> Info <p>If you need to send custom headers, use Response class instead.</p> <p>We provide pre-defined errors for the most popular ones such as HTTP 400, 401, 404, 500.</p> Raising common HTTP Status errors (4xx, 5xx)<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.exceptions import (\n    BadRequestError,\n    InternalServerError,\n    NotFoundError,\n    ServiceError,\n    UnauthorizedError,\n)\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(rule=\"/bad-request-error\")\ndef bad_request_error():\n    raise BadRequestError(\"Missing required parameter\")  # HTTP  400\n\n\n@app.get(rule=\"/unauthorized-error\")\ndef unauthorized_error():\n    raise UnauthorizedError(\"Unauthorized\")  # HTTP 401\n\n\n@app.get(rule=\"/not-found-error\")\ndef not_found_error():\n    raise NotFoundError  # HTTP 404\n\n\n@app.get(rule=\"/internal-server-error\")\ndef internal_server_error():\n    raise InternalServerError(\"Internal server error\")  # HTTP 500\n\n\n@app.get(rule=\"/service-error\", cors=True)\ndef service_error():\n    raise ServiceError(502, \"Something went wrong!\")\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#enabling-swaggerui",
            "title": "Enabling SwaggerUI",
            "text": "<p>This feature requires data validation feature to be enabled.</p> <p>Behind the scenes, the data validation feature auto-generates an OpenAPI specification from your routes and type annotations. You can use Swagger UI to visualize and interact with your newly auto-documented API.</p> <p>There are some important caveats that you should know before enabling it:</p> Caveat Description Swagger UI is publicly accessible by default When using <code>enable_swagger</code> method, you can protect sensitive API endpoints by implementing a custom middleware using your preferred authorization mechanism. No micro-functions support yet Swagger UI is enabled on a per resolver instance which will limit its accuracy here. You need to expose a new route You'll need to expose the following path to Lambda: <code>/swagger</code>; ignore if you're routing this path already. JS and CSS  files are embedded within Swagger HTML If you are not using an external CDN to serve Swagger UI assets, we embed JS and CSS directly into the HTML. To enhance performance, please consider enabling the <code>compress</code> option to minimize the size of HTTP requests. Authorization data is lost on browser close/refresh Use <code>enable_swagger(persist_authorization=True)</code> to persist authorization data, like OAuath 2.0 access tokens. enabling_swagger.py<pre><code>from typing import List\n\nimport requests\nfrom pydantic import BaseModel, Field\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(enable_validation=True)\napp.enable_swagger(path=\"/swagger\")  # (1)!\n\n\nclass Todo(BaseModel):\n    userId: int\n    id_: int = Field(alias=\"id\")\n    title: str\n    completed: bool\n\n\n@app.post(\"/todos\")\ndef create_todo(todo: Todo) -&gt; str:\n    response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", json=todo.dict(by_alias=True))\n    response.raise_for_status()\n\n    return response.json()[\"id\"]\n\n\n@app.get(\"/todos\")\ndef get_todos() -&gt; List[Todo]:\n    todo = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todo.raise_for_status()\n\n    return todo.json()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li><code>enable_swagger</code> creates a route to serve Swagger UI and allows quick customizations.  You can also include  middlewares to protect or enhance the overall experience.</li> </ol> <p>Here's an example of what it looks like by default:</p> <p></p>"
        },
        {
            "location": "core/event_handler/api_gateway/#custom-domain-api-mappings",
            "title": "Custom Domain API Mappings",
            "text": "<p>When using Custom Domain API Mappings feature, you must use <code>strip_prefixes</code> param in the <code>APIGatewayRestResolver</code> constructor.</p> <p>Scenario: You have a custom domain <code>api.mydomain.dev</code>. Then you set <code>/payment</code> API Mapping to forward any payment requests to your Payments API.</p> <p>Challenge: This means your <code>path</code> value for any API requests will always contain <code>/payment/&lt;actual_request&gt;</code>, leading to HTTP 404 as Event Handler is trying to match what's after <code>payment/</code>. This gets further complicated with an arbitrary level of nesting.</p> <p>To address this API Gateway behavior, we use <code>strip_prefixes</code> parameter to account for these prefixes that are now injected into the path regardless of which type of API Gateway you're using.</p> custom_api_mapping.pycustom_api_mapping.json <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(strip_prefixes=[\"/payment\"])\n\n\n@app.get(\"/subscriptions/&lt;subscription&gt;\")\n@tracer.capture_method\ndef get_subscription(subscription):\n    return {\"subscription_id\": subscription}\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"resource\": \"/subscriptions/{subscription}\",\n    \"path\": \"/payment/subscriptions/123\",\n    \"httpMethod\": \"GET\"\n}\n</code></pre> Note <p>After removing a path prefix with <code>strip_prefixes</code>, the new root path will automatically be mapped to the path argument of <code>/</code>.</p> <p>For example, when using <code>strip_prefixes</code> value of <code>/pay</code>, there is no difference between a request path of <code>/pay</code> and <code>/pay/</code>; and the path argument would be defined as <code>/</code>.</p> <p>For added flexibility, you can use regexes to strip a prefix. This is helpful when you have many options due to different combinations of prefixes (e.g: multiple environments, multiple versions).</p> strip_route_prefix_regex.py <pre><code>import re\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# This will support:\n# /v1/dev/subscriptions/&lt;subscription&gt;\n# /v1/stg/subscriptions/&lt;subscription&gt;\n# /v1/qa/subscriptions/&lt;subscription&gt;\n# /v2/dev/subscriptions/&lt;subscription&gt;\n# ...\napp = APIGatewayRestResolver(strip_prefixes=[re.compile(r\"/v[1-3]+/(dev|stg|qa)\")])\n\n\n@app.get(\"/subscriptions/&lt;subscription&gt;\")\ndef get_subscription(subscription):\n    return {\"subscription_id\": subscription}\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/event_handler/api_gateway/#cors",
            "title": "CORS",
            "text": "<p>You can configure CORS at the <code>APIGatewayRestResolver</code> constructor via <code>cors</code> parameter using the <code>CORSConfig</code> class.</p> <p>This will ensure that CORS headers are returned as part of the response when your functions match the path invoked and the <code>Origin</code> matches one of the allowed values.</p> Tip <p>Optionally disable CORS on a per path basis with <code>cors=False</code> parameter.</p> setting_cors.pysetting_cors_output.jsonsetting_cors_extra_origins.pysetting_cors_extra_origins_output.json <pre><code>from urllib.parse import quote\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, CORSConfig\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\n# CORS will match when Origin is only https://www.example.com\ncors_config = CORSConfig(allow_origin=\"https://www.example.com\", max_age=300)\napp = APIGatewayRestResolver(cors=cors_config)\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@app.get(\"/todos/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: str):  # value come as str\n    todo_id = quote(todo_id, safe=\"\")\n    todos: Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n@app.get(\"/healthcheck\", cors=False)  # optionally removes CORS for a given route\n@tracer.capture_method\ndef am_i_alive():\n    return {\"am_i_alive\": \"yes\"}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"statusCode\": 200,\n    \"multiValueHeaders\": {\n        \"Content-Type\": [\"application/json\"],\n        \"Access-Control-Allow-Origin\": [\"https://www.example.com\"],\n        \"Access-Control-Allow-Headers\": [\"Authorization,Content-Type,X-Amz-Date,X-Amz-Security-Token,X-Api-Key\"]\n    },\n    \"body\": \"{\\\"todos\\\":[{\\\"userId\\\":1,\\\"id\\\":1,\\\"title\\\":\\\"delectus aut autem\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":2,\\\"title\\\":\\\"quis ut nam facilis et officia qui\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":3,\\\"title\\\":\\\"fugiat veniam minus\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":4,\\\"title\\\":\\\"et porro tempora\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":5,\\\"title\\\":\\\"laboriosam mollitia et enim quasi adipisci quia provident illum\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":6,\\\"title\\\":\\\"qui ullam ratione quibusdam voluptatem quia omnis\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":7,\\\"title\\\":\\\"illo expedita consequatur quia in\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":8,\\\"title\\\":\\\"quo adipisci enim quam ut ab\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":9,\\\"title\\\":\\\"molestiae perspiciatis ipsa\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":10,\\\"title\\\":\\\"illo est ratione doloremque quia maiores aut\\\",\\\"completed\\\":true}]}\",\n    \"isBase64Encoded\": false\n}\n</code></pre> <pre><code>from urllib.parse import quote\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, CORSConfig\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\n# CORS will match when Origin is https://www.example.com OR https://dev.example.com\ncors_config = CORSConfig(allow_origin=\"https://www.example.com\", extra_origins=[\"https://dev.example.com\"], max_age=300)\napp = APIGatewayRestResolver(cors=cors_config)\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@app.get(\"/todos/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: str):  # value come as str\n    todo_id = quote(todo_id, safe=\"\")\n    todos: Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n@app.get(\"/healthcheck\", cors=False)  # optionally removes CORS for a given route\n@tracer.capture_method\ndef am_i_alive():\n    return {\"am_i_alive\": \"yes\"}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"statusCode\": 200,\n    \"multiValueHeaders\": {\n        \"Content-Type\": [\"application/json\"],\n        \"Access-Control-Allow-Origin\": [\"https://www.example.com\",\"https://dev.example.com\"],\n        \"Access-Control-Allow-Headers\": [\"Authorization,Content-Type,X-Amz-Date,X-Amz-Security-Token,X-Api-Key\"]\n    },\n    \"body\": \"{\\\"todos\\\":[{\\\"userId\\\":1,\\\"id\\\":1,\\\"title\\\":\\\"delectus aut autem\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":2,\\\"title\\\":\\\"quis ut nam facilis et officia qui\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":3,\\\"title\\\":\\\"fugiat veniam minus\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":4,\\\"title\\\":\\\"et porro tempora\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":5,\\\"title\\\":\\\"laboriosam mollitia et enim quasi adipisci quia provident illum\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":6,\\\"title\\\":\\\"qui ullam ratione quibusdam voluptatem quia omnis\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":7,\\\"title\\\":\\\"illo expedita consequatur quia in\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":8,\\\"title\\\":\\\"quo adipisci enim quam ut ab\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":9,\\\"title\\\":\\\"molestiae perspiciatis ipsa\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":10,\\\"title\\\":\\\"illo est ratione doloremque quia maiores aut\\\",\\\"completed\\\":true}]}\",\n    \"isBase64Encoded\": false\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#pre-flight",
            "title": "Pre-flight",
            "text": "<p>Pre-flight (OPTIONS) calls are typically handled at the API Gateway or Lambda Function URL level as per our sample infrastructure, no Lambda integration is necessary. However, ALB expects you to handle pre-flight requests.</p> <p>For convenience, we automatically handle that for you as long as you setup CORS in the constructor level.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#defaults",
            "title": "Defaults",
            "text": "<p>For convenience, these are the default values when using <code>CORSConfig</code> to enable CORS:</p> Warning <p>Always configure <code>allow_origin</code> when using in production.</p> Multiple origins? <p>If you need to allow multiple origins, pass the additional origins using the <code>extra_origins</code> key.</p> Key Value Note allow_origin: <code>str</code> <code>*</code> Only use the default value for development. Never use <code>*</code> for production unless your use case requires it extra_origins: <code>List[str]</code> <code>[]</code> Additional origins to be allowed, in addition to the one specified in <code>allow_origin</code> allow_headers: <code>List[str]</code> <code>[Authorization, Content-Type, X-Amz-Date, X-Api-Key, X-Amz-Security-Token]</code> Additional headers will be appended to the default list for your convenience expose_headers: <code>List[str]</code> <code>[]</code> Any additional header beyond the safe listed by CORS specification. max_age: <code>int</code> `` Only for pre-flight requests if you choose to have your function to handle it instead of API Gateway allow_credentials: <code>bool</code> <code>False</code> Only necessary when you need to expose cookies, authorization headers or TLS client certificates."
        },
        {
            "location": "core/event_handler/api_gateway/#middleware",
            "title": "Middleware",
            "text": "<pre><code>stateDiagram\n    direction LR\n\n    EventHandler: GET /todo\n    Before: Before response\n    Next: next_middleware()\n    MiddlewareLoop: Middleware loop\n    AfterResponse: After response\n    MiddlewareFinished: Modified response\n    Response: Final response\n\n    EventHandler --&gt; Middleware: Has middleware?\n    state MiddlewareLoop {\n        direction LR\n        Middleware --&gt; Before\n        Before --&gt; Next\n        Next --&gt; Middleware: More middlewares?\n        Next --&gt; AfterResponse\n    }\n    AfterResponse --&gt; MiddlewareFinished\n    MiddlewareFinished --&gt; Response\n    EventHandler --&gt; Response: No middleware</code></pre> <p>A middleware is a function you register per route to intercept or enrich a request before or after any response.</p> <p>Each middleware function receives the following arguments:</p> <ol> <li>app. An Event Handler instance so you can access incoming request information, Lambda context, etc.</li> <li>next_middleware. A function to get the next middleware or route's response.</li> </ol> <p>Here's a sample middleware that extracts and injects correlation ID, using <code>APIGatewayRestResolver</code> (works for any Resolver):</p> middleware_getting_started.pymiddleware_getting_started_output.json Your first middleware to extract and inject correlation ID<pre><code>import requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\nfrom aws_lambda_powertools.event_handler.middlewares import NextMiddleware\n\napp = APIGatewayRestResolver()\nlogger = Logger()\n\n\ndef inject_correlation_id(app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:\n    request_id = app.current_event.request_context.request_id  # (1)!\n\n    # Use API Gateway REST API request ID if caller didn't include a correlation ID\n    correlation_id = logger.get_correlation_id() or request_id  # (2)!\n\n    # Inject correlation ID in shared context and Logger\n    app.append_context(correlation_id=correlation_id)  # (3)!\n    logger.set_correlation_id(correlation_id)\n\n    # Get response from next middleware OR /todos route\n    result = next_middleware(app)  # (4)!\n\n    # Include Correlation ID in the response back to caller\n    result.headers[\"x-correlation-id\"] = correlation_id  # (5)!\n    return result\n\n\n@app.get(\"/todos\", middlewares=[inject_correlation_id])  # (6)!\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@logger.inject_lambda_context(correlation_id_path='headers.\"x-correlation-id\"')  # (7)!\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <ol> <li>You can access current request like you normally would.</li> <li>Logger extracts it first in the request path, so we can use it.  If this was available before, we'd use <code>app.context.get(\"correlation_id\")</code>.</li> <li>Shared context is available to any middleware, Router and App instances.  For example, another middleware can now use <code>app.context.get(\"correlation_id\")</code> to retrieve it.</li> <li>Get response from the next middleware (if any) or from <code>/todos</code> route.</li> <li>You can manipulate headers, body, or status code before returning it.</li> <li>Register one or more middlewares in order of execution.</li> <li>Logger extracts correlation ID from header and makes it available under <code>correlation_id</code> key, and <code>get_correlation_id()</code> method.</li> </ol> <pre><code>{\n    \"statusCode\": 200,\n    \"body\": \"{\\\"todos\\\":[{\\\"userId\\\":1,\\\"id\\\":1,\\\"title\\\":\\\"delectus aut autem\\\",\\\"completed\\\":false}]}\",\n    \"isBase64Encoded\": false,\n    \"multiValueHeaders\": {\n        \"Content-Type\": [\n            \"application/json\"\n        ],\n        \"x-correlation-id\": [\n            \"ccd87d70-7a3f-4aec-b1a8-a5a558c239b2\"\n        ]\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#global-middlewares",
            "title": "Global middlewares",
            "text": "<p> <p>Request flowing through multiple registered middlewares </p> <p>You can use <code>app.use</code> to register middlewares that should always run regardless of the route, also known as global middlewares.</p> <p>Event Handler calls global middlewares first, then middlewares defined at the route level. Here's an example with both middlewares:</p> middleware_global_middlewares.pymiddleware_global_middlewares_module.py <p>Use debug mode if you need to log request/response.</p> <pre><code>import middleware_global_middlewares_module  # (1)!\nimport requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\n\napp = APIGatewayRestResolver()\nlogger = Logger()\n\napp.use(middlewares=[middleware_global_middlewares_module.log_request_response])  # (2)!\n\n\n@app.get(\"/todos\", middlewares=[middleware_global_middlewares_module.inject_correlation_id])\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <ol> <li>A separate file where our middlewares are to keep this example focused.</li> <li>We register <code>log_request_response</code> as a global middleware to run before middleware.    <pre><code>stateDiagram\n    direction LR\n\n    GlobalMiddleware: Log request response\n    RouteMiddleware: Inject correlation ID\n    EventHandler: Event Handler\n\n    EventHandler --&gt; GlobalMiddleware\n    GlobalMiddleware --&gt; RouteMiddleware</code></pre></li> </ol> <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\nfrom aws_lambda_powertools.event_handler.middlewares import NextMiddleware\n\nlogger = Logger()\n\n\ndef log_request_response(app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:\n    logger.info(\"Incoming request\", path=app.current_event.path, request=app.current_event.raw_event)\n\n    result = next_middleware(app)\n    logger.info(\"Response received\", response=result.__dict__)\n\n    return result\n\n\ndef inject_correlation_id(app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:\n    request_id = app.current_event.request_context.request_id\n\n    # Use API Gateway REST API request ID if caller didn't include a correlation ID\n    correlation_id = logger.get_correlation_id() or request_id  # elsewhere becomes app.context.get(\"correlation_id\")\n\n    # Inject correlation ID in shared context and Logger\n    app.append_context(correlation_id=correlation_id)\n    logger.set_correlation_id(correlation_id)\n\n    # Get response from next middleware OR /todos route\n    result = next_middleware(app)\n\n    # Include Correlation ID in the response back to caller\n    result.headers[\"x-correlation-id\"] = correlation_id\n    return result\n\n\ndef enforce_correlation_id(app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:\n    # If missing mandatory header raise an error\n    if not app.current_event.headers.get(\"x-correlation-id\"):\n        return Response(status_code=400, body=\"Correlation ID header is now mandatory.\")  # (1)!\n\n    # Get the response from the next middleware and return it\n    return next_middleware(app)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#returning-early",
            "title": "Returning early",
            "text": "<p> <p>Interrupting request flow by returning early </p> <p>Imagine you want to stop processing a request if something is missing, or return immediately if you've seen this request before.</p> <p>In these scenarios, you short-circuit the middleware processing logic by returning a Response object, or raising a HTTP Error. This signals to Event Handler to stop and run each <code>After</code> logic left in the chain all the way back.</p> <p>Here's an example where we prevent any request that doesn't include a correlation ID header:</p> middleware_early_return.pymiddleware_global_middlewares_module.pymiddleware_early_return_output.json <pre><code>import middleware_global_middlewares_module\nimport requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\n\napp = APIGatewayRestResolver()\nlogger = Logger()\napp.use(\n    middlewares=[\n        middleware_global_middlewares_module.log_request_response,\n        middleware_global_middlewares_module.enforce_correlation_id,  # (1)!\n    ],\n)\n\n\n@app.get(\"/todos\")\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")  # (2)!\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <ol> <li>This middleware will raise an exception if correlation ID header is missing.</li> <li>This code section will not run if <code>enforce_correlation_id</code> returns early.</li> </ol> <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\nfrom aws_lambda_powertools.event_handler.middlewares import NextMiddleware\n\nlogger = Logger()\n\n\ndef log_request_response(app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:\n    logger.info(\"Incoming request\", path=app.current_event.path, request=app.current_event.raw_event)\n\n    result = next_middleware(app)\n    logger.info(\"Response received\", response=result.__dict__)\n\n    return result\n\n\ndef inject_correlation_id(app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:\n    request_id = app.current_event.request_context.request_id\n\n    # Use API Gateway REST API request ID if caller didn't include a correlation ID\n    correlation_id = logger.get_correlation_id() or request_id  # elsewhere becomes app.context.get(\"correlation_id\")\n\n    # Inject correlation ID in shared context and Logger\n    app.append_context(correlation_id=correlation_id)\n    logger.set_correlation_id(correlation_id)\n\n    # Get response from next middleware OR /todos route\n    result = next_middleware(app)\n\n    # Include Correlation ID in the response back to caller\n    result.headers[\"x-correlation-id\"] = correlation_id\n    return result\n\n\ndef enforce_correlation_id(app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:\n    # If missing mandatory header raise an error\n    if not app.current_event.headers.get(\"x-correlation-id\"):\n        return Response(status_code=400, body=\"Correlation ID header is now mandatory.\")  # (1)!\n\n    # Get the response from the next middleware and return it\n    return next_middleware(app)\n</code></pre> <ol> <li>Raising an exception OR returning a Response object early will short-circuit the middleware chain.</li> </ol> <pre><code>{\n    \"statusCode\": 400,\n    \"body\": \"Correlation ID header is now mandatory\",\n    \"isBase64Encoded\": false,\n    \"multiValueHeaders\": {}\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#handling-exceptions",
            "title": "Handling exceptions",
            "text": "<p>For catching exceptions more broadly, we recommend you use the exception_handler decorator.</p> <p>By default, any unhandled exception in the middleware chain is eventually propagated as a HTTP 500 back to the client.</p> <p>While there isn't anything special on how to use <code>try/catch</code> for middlewares, it is important to visualize how Event Handler deals with them under the following scenarios:</p> Unhandled exception from route handlerRoute handler exception caught by a middlewareMiddleware short-circuit by raising exception <p>An exception wasn't caught by any middleware during <code>next_middleware()</code> block, therefore it propagates all the way back to the client as HTTP 500.</p> <p> <p>Unhandled route exceptions propagate back to the client </p> <p>An exception was only caught by the third middleware, resuming the normal execution of each <code>After</code> logic for the second and first middleware.</p> <p> <p>Unhandled route exceptions propagate back to the client </p> <p>The third middleware short-circuited the chain by raising an exception and completely skipping the fourth middleware. Because we only caught it in  the first middleware, it skipped the <code>After</code> logic in the second middleware.</p> <p> <p>Middleware handling short-circuit exceptions </p>"
        },
        {
            "location": "core/event_handler/api_gateway/#extending-middlewares",
            "title": "Extending middlewares",
            "text": "<p>You can implement <code>BaseMiddlewareHandler</code> interface to create middlewares that accept configuration, or perform complex operations (see being a good citizen section).</p> <p>As a practical example, let's refactor our correlation ID middleware so it accepts a custom HTTP Header to look for.</p> Authoring class-based middlewares with BaseMiddlewareHandler<pre><code>import requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\nfrom aws_lambda_powertools.event_handler.middlewares import BaseMiddlewareHandler, NextMiddleware\n\napp = APIGatewayRestResolver()\nlogger = Logger()\n\n\nclass CorrelationIdMiddleware(BaseMiddlewareHandler):\n    def __init__(self, header: str):  # (1)!\n        \"\"\"Extract and inject correlation ID in response\n\n        Parameters\n        ----------\n        header : str\n            HTTP Header to extract correlation ID\n        \"\"\"\n        super().__init__()\n        self.header = header\n\n    def handler(self, app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:  # (2)!\n        request_id = app.current_event.request_context.request_id\n        correlation_id = app.current_event.headers.get(self.header, request_id)\n\n        response = next_middleware(app)  # (3)!\n        response.headers[self.header] = correlation_id\n\n        return response\n\n\n@app.get(\"/todos\", middlewares=[CorrelationIdMiddleware(header=\"x-correlation-id\")])  # (4)!\ndef get_todos():\n    todos: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <ol> <li>You can add any constructor argument like you normally would</li> <li>We implement <code>handler</code> just like we did before with the only exception of the <code>self</code> argument, since it's a method.</li> <li>Get response from the next middleware (if any) or from <code>/todos</code> route.</li> <li>Register an instance of <code>CorrelationIdMiddleware</code>.</li> </ol> <p>Class-based vs function-based middlewares</p> <p>When registering a middleware, we expect a callable in both cases. For class-based middlewares, <code>BaseMiddlewareHandler</code> is doing the work of calling your <code>handler</code> method with the correct parameters, hence why we expect an instance of it.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#native-middlewares",
            "title": "Native middlewares",
            "text": "<p>These are native middlewares that may become native features depending on customer demand.</p> Middleware Purpose SchemaValidationMiddleware Validates API request body and response against JSON Schema, using Validation utility"
        },
        {
            "location": "core/event_handler/api_gateway/#being-a-good-citizen",
            "title": "Being a good citizen",
            "text": "<p>Middlewares can add subtle improvements to request/response processing, but also add significant complexity if you're not careful.</p> <p>Keep the following in mind when authoring middlewares for Event Handler:</p> <ol> <li>Use built-in features over middlewares. We include built-in features like CORS, compression, binary responses, global exception handling, and debug mode to reduce the need for middlewares.</li> <li>Call the next middleware. Return the result of <code>next_middleware(app)</code>, or a Response object when you want to return early.</li> <li>Keep a lean scope. Focus on a single task per middleware to ease composability and maintenance. In debug mode, we also print out the order middlewares will be triggered to ease operations.</li> <li>Catch your own exceptions. Catch and handle known exceptions to your logic. Unless you want to raise HTTP Errors, or propagate specific exceptions to the client. To catch all and any exceptions, we recommend you use the exception_handler decorator.</li> <li>Use context to share data. Use <code>app.append_context</code> to share contextual data between middlewares and route handlers, and <code>app.context.get(key)</code> to fetch them. We clear all contextual data at the end of every request.</li> </ol>"
        },
        {
            "location": "core/event_handler/api_gateway/#fine-grained-responses",
            "title": "Fine grained responses",
            "text": "<p>You can use the <code>Response</code> class to have full control over the response. For example, you might want to add additional headers, cookies, or set a custom Content-type.</p> Info <p>Powertools for AWS Lambda (Python) serializes headers and cookies according to the type of input event. Some event sources require headers and cookies to be encoded as <code>multiValueHeaders</code>.</p> Using multiple values for HTTP headers in ALB? <p>Make sure you enable the multi value headers feature to serialize response headers correctly.</p> fine_grained_responses.pyfine_grained_responses_output.json <pre><code>from http import HTTPStatus\nfrom uuid import uuid4\n\nimport requests\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import (\n    APIGatewayRestResolver,\n    Response,\n    content_types,\n)\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.shared.cookies import Cookie\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    custom_headers = {\"X-Transaction-Id\": [f\"{uuid4()}\"]}\n\n    return Response(\n        status_code=HTTPStatus.OK.value,  # 200\n        content_type=content_types.APPLICATION_JSON,\n        body=todos.json()[:10],\n        headers=custom_headers,\n        cookies=[Cookie(name=\"session_id\", value=\"12345\")],\n    )\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"statusCode\": 200,\n    \"multiValueHeaders\": {\n        \"Content-Type\": [\"application/json\"],\n        \"X-Transaction-Id\": [\"3490eea9-791b-47a0-91a4-326317db61a9\"],\n        \"Set-Cookie\": [\"session_id=12345; Secure\"]\n    },\n    \"body\": \"{\\\"todos\\\":[{\\\"userId\\\":1,\\\"id\\\":1,\\\"title\\\":\\\"delectus aut autem\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":2,\\\"title\\\":\\\"quis ut nam facilis et officia qui\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":3,\\\"title\\\":\\\"fugiat veniam minus\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":4,\\\"title\\\":\\\"et porro tempora\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":5,\\\"title\\\":\\\"laboriosam mollitia et enim quasi adipisci quia provident illum\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":6,\\\"title\\\":\\\"qui ullam ratione quibusdam voluptatem quia omnis\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":7,\\\"title\\\":\\\"illo expedita consequatur quia in\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":8,\\\"title\\\":\\\"quo adipisci enim quam ut ab\\\",\\\"completed\\\":true},{\\\"userId\\\":1,\\\"id\\\":9,\\\"title\\\":\\\"molestiae perspiciatis ipsa\\\",\\\"completed\\\":false},{\\\"userId\\\":1,\\\"id\\\":10,\\\"title\\\":\\\"illo est ratione doloremque quia maiores aut\\\",\\\"completed\\\":true}]}\",\n    \"isBase64Encoded\": false\n}\n</code></pre> Using <code>Response</code> with data validation? <p>When using the data validation feature with <code>enable_validation=True</code>, you must specify the concrete type for the <code>Response</code> class. This allows the validation middleware to infer the underlying type and perform validation correctly.</p> <pre><code>from http import HTTPStatus\nfrom typing import Optional\n\nimport requests\nfrom pydantic import BaseModel, Field\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response, content_types\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(enable_validation=True)\n\n\nclass Todo(BaseModel):\n    userId: int\n    id_: Optional[int] = Field(alias=\"id\", default=None)\n    title: str\n    completed: bool\n\n\n@app.get(\"/todos/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: int) -&gt; Response[Todo]:\n    todo = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todo.raise_for_status()\n    return Response(\n        status_code=HTTPStatus.OK.value,\n        content_type=content_types.APPLICATION_JSON,\n        body=todo.json(),\n    )\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#compress",
            "title": "Compress",
            "text": "<p>You can compress with gzip and base64 encode your responses via <code>compress</code> parameter. You have the option to pass the <code>compress</code> parameter when working with a specific route or using the Response object.</p> Info <p>The <code>compress</code> parameter used in the Response object takes precedence over the one used in the route.</p> Warning <p>The client must send the <code>Accept-Encoding</code> header, otherwise a normal response will be sent.</p> compressing_responses_using_route.pycompressing_responses_using_response.pycompressing_responses.jsoncompressing_responses_output.json <pre><code> from urllib.parse import quote\n\n import requests\n\n from aws_lambda_powertools import Logger, Tracer\n from aws_lambda_powertools.event_handler import (\n     APIGatewayRestResolver,\n     Response,\n     content_types,\n )\n from aws_lambda_powertools.logging import correlation_paths\n from aws_lambda_powertools.utilities.typing import LambdaContext\n\n tracer = Tracer()\n logger = Logger()\n app = APIGatewayRestResolver()\n\n\n @app.get(\"/todos\", compress=True)\n @tracer.capture_method\n def get_todos():\n     todos: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n     todos.raise_for_status()\n\n     # for brevity, we'll limit to the first 10 only\n     return {\"todos\": todos.json()[:10]}\n\n\n @app.get(\"/todos/&lt;todo_id&gt;\", compress=True)\n @tracer.capture_method\n def get_todo_by_id(todo_id: str):  # same example using Response class\n     todo_id = quote(todo_id, safe=\"\")\n     todos: requests.Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n     todos.raise_for_status()\n\n     return Response(status_code=200, content_type=content_types.APPLICATION_JSON, body=todos.json())\n\n\n # You can continue to use other utilities just as before\n @logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n @tracer.capture_lambda_handler\n def lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n     return app.resolve(event, context)\n</code></pre> <pre><code> import requests\n\n from aws_lambda_powertools import Logger, Tracer\n from aws_lambda_powertools.event_handler import (\n     APIGatewayRestResolver,\n     Response,\n     content_types,\n )\n from aws_lambda_powertools.logging import correlation_paths\n from aws_lambda_powertools.utilities.typing import LambdaContext\n\n tracer = Tracer()\n logger = Logger()\n app = APIGatewayRestResolver()\n\n\n @app.get(\"/todos\")\n @tracer.capture_method\n def get_todos():\n     todos: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n     todos.raise_for_status()\n\n     # for brevity, we'll limit to the first 10 only\n     return Response(status_code=200, content_type=content_types.APPLICATION_JSON, body=todos.json()[:10], compress=True)\n\n\n # You can continue to use other utilities just as before\n @logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n @tracer.capture_lambda_handler\n def lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n     return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"headers\": {\n        \"Accept-Encoding\": \"gzip\"\n    },\n    \"resource\": \"/todos\",\n    \"path\": \"/todos\",\n    \"httpMethod\": \"GET\"\n}\n</code></pre> <pre><code>{\n    \"statusCode\": 200,\n    \"multiValueHeaders\": {\n        \"Content-Type\": [\"application/json\"],\n        \"Content-Encoding\": [\"gzip\"]\n    },\n    \"body\": \"H4sIAAAAAAACE42STU4DMQyFrxJl3QXln96AMyAW7sSDLCVxiJ0Kqerd8TCCUOgii1EmP/783pOPXjmw+N3L0TfB+hz8brvxtC5KGtHvfMCIkzZx0HT5MPmNnziViIr2dIYoeNr8Q1x3xHsjcVadIbkZJoq2RXU8zzQROLseQ9505NzeCNQdMJNBE+UmY4zbzjAJhWtlZ57sB84BWtul+rteH2HPlVgWARwjqXkxpklK5gmEHAQqJBMtFsGVygcKmNVRjG0wxvuzGF2L0dpVUOKMC3bfJNjJgWMrCuZk7cUp02AiD72D6WKHHwUDKbiJs6AZ0VZXKOUx4uNvzdxT+E4mLcMA+6G8nzrLQkaxkNEVrFKW2VGbJCoCY7q2V3+tiv5kGThyxfTecDWbgGz/NfYXhL6ePgF9PnFdPgMAAA==\",\n    \"isBase64Encoded\": true\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#binary-responses",
            "title": "Binary responses",
            "text": "Amazon API Gateway does not support <code>*/*</code> binary media type when CORS is also configured. <p>This feature requires API Gateway to configure binary media types, see our sample infrastructure for reference.</p> <p>For convenience, we automatically base64 encode binary responses. You can also use in combination with <code>compress</code> parameter if your client supports gzip.</p> <p>Like <code>compress</code> feature, the client must send the <code>Accept</code> header with the correct media type.</p> <p>Lambda Function URLs handle binary media types automatically.</p> binary_responses.pybinary_responses_logo.svgbinary_responses.jsonbinary_responses_output.json <pre><code>import os\nfrom pathlib import Path\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler.api_gateway import (\n    APIGatewayRestResolver,\n    Response,\n)\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\n\n\napp = APIGatewayRestResolver()\nlogo_file: bytes = Path(f\"{os.getenv('LAMBDA_TASK_ROOT')}/logo.svg\").read_bytes()\n\n\n@app.get(\"/logo\")\n@tracer.capture_method\ndef get_logo():\n    return Response(status_code=200, content_type=\"image/svg+xml\", body=logo_file)\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;svg width=\"256px\" height=\"256px\" viewBox=\"0 0 256 256\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" preserveAspectRatio=\"xMidYMid\"&gt;\n    &lt;title&gt;AWS Lambda&lt;/title&gt;\n    &lt;defs&gt;\n        &lt;linearGradient x1=\"0%\" y1=\"100%\" x2=\"100%\" y2=\"0%\" id=\"linearGradient-1\"&gt;\n            &lt;stop stop-color=\"#C8511B\" offset=\"0%\"&gt;&lt;/stop&gt;\n            &lt;stop stop-color=\"#FF9900\" offset=\"100%\"&gt;&lt;/stop&gt;\n        &lt;/linearGradient&gt;\n    &lt;/defs&gt;\n    &lt;g&gt;\n        &lt;rect fill=\"url(#linearGradient-1)\" x=\"0\" y=\"0\" width=\"256\" height=\"256\"&gt;&lt;/rect&gt;\n        &lt;path d=\"M89.6241126,211.2 L49.8903277,211.2 L93.8354832,119.3472 L113.74728,160.3392 L89.6241126,211.2 Z M96.7029357,110.5696 C96.1640858,109.4656 95.0414813,108.7648 93.8162384,108.7648 L93.8066163,108.7648 C92.5717514,108.768 91.4491466,109.4752 90.9199187,110.5856 L41.9134208,213.0208 C41.4387197,214.0128 41.5060758,215.1776 42.0962451,216.1088 C42.6799994,217.0368 43.7063805,217.6 44.8065331,217.6 L91.654423,217.6 C92.8957027,217.6 94.0215149,216.8864 94.5539501,215.7696 L120.203859,161.6896 C120.617619,160.8128 120.614412,159.7984 120.187822,158.928 L96.7029357,110.5696 Z M207.985117,211.2 L168.507928,211.2 L105.173789,78.624 C104.644561,77.5104 103.515541,76.8 102.277469,76.8 L76.447943,76.8 L76.4768099,44.8 L127.103066,44.8 L190.145328,177.3728 C190.674556,178.4864 191.803575,179.2 193.041647,179.2 L207.985117,179.2 L207.985117,211.2 Z M211.192558,172.8 L195.071958,172.8 L132.029696,40.2272 C131.500468,39.1136 130.371449,38.4 129.130169,38.4 L73.272576,38.4 C71.5052758,38.4 70.0683421,39.8304 70.0651344,41.5968 L70.0298528,79.9968 C70.0298528,80.848 70.3634266,81.6608 70.969633,82.2624 C71.5694246,82.864 72.3841146,83.2 73.2372941,83.2 L100.253573,83.2 L163.59092,215.776 C164.123355,216.8896 165.24596,217.6 166.484032,217.6 L211.192558,217.6 C212.966274,217.6 214.4,216.1664 214.4,214.4 L214.4,176 C214.4,174.2336 212.966274,172.8 211.192558,172.8 L211.192558,172.8 Z\" fill=\"#FFFFFF\"&gt;&lt;/path&gt;\n    &lt;/g&gt;\n&lt;/svg&gt;\n</code></pre> <pre><code>{\n    \"headers\": {\n        \"Accept\": \"image/svg+xml\"\n    },\n    \"resource\": \"/logo\",\n    \"path\": \"/logo\",\n    \"httpMethod\": \"GET\"\n}\n</code></pre> <pre><code>{\n    \"body\": \"PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLTgiPz4KPHN2ZyB3aWR0aD0iMjU2cHgiIGhlaWdodD0iMjU2cHgiIHZpZXdCb3g9IjAgMCAyNTYgMjU2IiB2ZXJzaW9uPSIxLjEiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGxpbmsiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4KICAgIDx0aXRsZT5BV1MgTGFtYmRhPC90aXRsZT4KICAgIDxkZWZzPgogICAgICAgIDxsaW5lYXJHcmFkaWVudCB4MT0iMCUiIHkxPSIxMDAlIiB4Mj0iMTAwJSIgeTI9IjAlIiBpZD0ibGluZWFyR3JhZGllbnQtMSI+CiAgICAgICAgICAgIDxzdG9wIHN0b3AtY29sb3I9IiNDODUxMUIiIG9mZnNldD0iMCUiPjwvc3RvcD4KICAgICAgICAgICAgPHN0b3Agc3RvcC1jb2xvcj0iI0ZGOTkwMCIgb2Zmc2V0PSIxMDAlIj48L3N0b3A+CiAgICAgICAgPC9saW5lYXJHcmFkaWVudD4KICAgIDwvZGVmcz4KICAgIDxnPgogICAgICAgIDxyZWN0IGZpbGw9InVybCgjbGluZWFyR3JhZGllbnQtMSkiIHg9IjAiIHk9IjAiIHdpZHRoPSIyNTYiIGhlaWdodD0iMjU2Ij48L3JlY3Q+CiAgICAgICAgPHBhdGggZD0iTTg5LjYyNDExMjYsMjExLjIgTDQ5Ljg5MDMyNzcsMjExLjIgTDkzLjgzNTQ4MzIsMTE5LjM0NzIgTDExMy43NDcyOCwxNjAuMzM5MiBMODkuNjI0MTEyNiwyMTEuMiBaIE05Ni43MDI5MzU3LDExMC41Njk2IEM5Ni4xNjQwODU4LDEwOS40NjU2IDk1LjA0MTQ4MTMsMTA4Ljc2NDggOTMuODE2MjM4NCwxMDguNzY0OCBMOTMuODA2NjE2MywxMDguNzY0OCBDOTIuNTcxNzUxNCwxMDguNzY4IDkxLjQ0OTE0NjYsMTA5LjQ3NTIgOTAuOTE5OTE4NywxMTAuNTg1NiBMNDEuOTEzNDIwOCwyMTMuMDIwOCBDNDEuNDM4NzE5NywyMTQuMDEyOCA0MS41MDYwNzU4LDIxNS4xNzc2IDQyLjA5NjI0NTEsMjE2LjEwODggQzQyLjY3OTk5OTQsMjE3LjAzNjggNDMuNzA2MzgwNSwyMTcuNiA0NC44MDY1MzMxLDIxNy42IEw5MS42NTQ0MjMsMjE3LjYgQzkyLjg5NTcwMjcsMjE3LjYgOTQuMDIxNTE0OSwyMTYuODg2NCA5NC41NTM5NTAxLDIxNS43Njk2IEwxMjAuMjAzODU5LDE2MS42ODk2IEMxMjAuNjE3NjE5LDE2MC44MTI4IDEyMC42MTQ0MTIsMTU5Ljc5ODQgMTIwLjE4NzgyMiwxNTguOTI4IEw5Ni43MDI5MzU3LDExMC41Njk2IFogTTIwNy45ODUxMTcsMjExLjIgTDE2OC41MDc5MjgsMjExLjIgTDEwNS4xNzM3ODksNzguNjI0IEMxMDQuNjQ0NTYxLDc3LjUxMDQgMTAzLjUxNTU0MSw3Ni44IDEwMi4yNzc0NjksNzYuOCBMNzYuNDQ3OTQzLDc2LjggTDc2LjQ3NjgwOTksNDQuOCBMMTI3LjEwMzA2Niw0NC44IEwxOTAuMTQ1MzI4LDE3Ny4zNzI4IEMxOTAuNjc0NTU2LDE3OC40ODY0IDE5MS44MDM1NzUsMTc5LjIgMTkzLjA0MTY0NywxNzkuMiBMMjA3Ljk4NTExNywxNzkuMiBMMjA3Ljk4NTExNywyMTEuMiBaIE0yMTEuMTkyNTU4LDE3Mi44IEwxOTUuMDcxOTU4LDE3Mi44IEwxMzIuMDI5Njk2LDQwLjIyNzIgQzEzMS41MDA0NjgsMzkuMTEzNiAxMzAuMzcxNDQ5LDM4LjQgMTI5LjEzMDE2OSwzOC40IEw3My4yNzI1NzYsMzguNCBDNzEuNTA1Mjc1OCwzOC40IDcwLjA2ODM0MjEsMzkuODMwNCA3MC4wNjUxMzQ0LDQxLjU5NjggTDcwLjAyOTg1MjgsNzkuOTk2OCBDNzAuMDI5ODUyOCw4MC44NDggNzAuMzYzNDI2Niw4MS42NjA4IDcwLjk2OTYzMyw4Mi4yNjI0IEM3MS41Njk0MjQ2LDgyLjg2NCA3Mi4zODQxMTQ2LDgzLjIgNzMuMjM3Mjk0MSw4My4yIEwxMDAuMjUzNTczLDgzLjIgTDE2My41OTA5MiwyMTUuNzc2IEMxNjQuMTIzMzU1LDIxNi44ODk2IDE2NS4yNDU5NiwyMTcuNiAxNjYuNDg0MDMyLDIxNy42IEwyMTEuMTkyNTU4LDIxNy42IEMyMTIuOTY2Mjc0LDIxNy42IDIxNC40LDIxNi4xNjY0IDIxNC40LDIxNC40IEwyMTQuNCwxNzYgQzIxNC40LDE3NC4yMzM2IDIxMi45NjYyNzQsMTcyLjggMjExLjE5MjU1OCwxNzIuOCBMMjExLjE5MjU1OCwxNzIuOCBaIiBmaWxsPSIjRkZGRkZGIj48L3BhdGg+CiAgICA8L2c+Cjwvc3ZnPg==\",\n    \"multiValueHeaders\": {\n        \"Content-Type\": [\"image/svg+xml\"]\n    },\n    \"isBase64Encoded\": true,\n    \"statusCode\": 200\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#debug-mode",
            "title": "Debug mode",
            "text": "<p>You can enable debug mode via <code>debug</code> param, or via <code>POWERTOOLS_DEV</code> environment variable.</p> <p>This will enable full tracebacks errors in the response, print request and responses, and set CORS in development mode.</p> Danger <p>This might reveal sensitive information in your logs and relax CORS restrictions, use it sparingly.</p> <p>It's best to use for local development only!</p> Enabling debug mode<pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver(debug=True)\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#openapi",
            "title": "OpenAPI",
            "text": "<p>When you enable Data Validation, we use a combination of Pydantic Models and OpenAPI type annotations to add constraints to your API's parameters.</p> OpenAPI schema version depends on the installed version of Pydantic <p>Pydantic v1 generates valid OpenAPI 3.0.3 schemas, and Pydantic v2 generates valid OpenAPI 3.1.0 schemas.</p> <p>In OpenAPI documentation tools like SwaggerUI, these annotations become readable descriptions, offering a self-explanatory API interface. This reduces boilerplate code while improving functionality and enabling auto-documentation.</p> Note <p>We don't have support for files, form data, and header parameters at the moment. If you're interested in this, please open an issue.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#customizing-openapi-parameters",
            "title": "Customizing OpenAPI parameters",
            "text": "<p>Whenever you use OpenAPI parameters to validate query strings or path parameters, you can enhance validation and OpenAPI documentation by using any of these parameters:</p> Field name Type Description <code>alias</code> <code>str</code> Alternative name for a field, used when serializing and deserializing data <code>validation_alias</code> <code>str</code> Alternative name for a field during validation (but not serialization) <code>serialization_alias</code> <code>str</code> Alternative name for a field during serialization (but not during validation) <code>description</code> <code>str</code> Human-readable description <code>gt</code> <code>float</code> Greater than. If set, value must be greater than this. Only applicable to numbers <code>ge</code> <code>float</code> Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers <code>lt</code> <code>float</code> Less than. If set, value must be less than this. Only applicable to numbers <code>le</code> <code>float</code> Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers <code>min_length</code> <code>int</code> Minimum length for strings <code>max_length</code> <code>int</code> Maximum length for strings <code>pattern</code> <code>string</code> A regular expression that the string must match. <code>strict</code> <code>bool</code> If <code>True</code>, strict validation is applied to the field. See Strict Mode for details <code>multiple_of</code> <code>float</code> Value must be a multiple of this. Only applicable to numbers <code>allow_inf_nan</code> <code>bool</code> Allow <code>inf</code>, <code>-inf</code>, <code>nan</code>. Only applicable to numbers <code>max_digits</code> <code>int</code> Maximum number of allow digits for strings <code>decimal_places</code> <code>int</code> Maximum number of decimal places allowed for numbers <code>openapi_examples</code> <code>dict[str, Example]</code> A list of examples to be displayed in the SwaggerUI interface. Avoid using the <code>examples</code> field for this purpose. <code>deprecated</code> <code>bool</code> Marks the field as deprecated <code>include_in_schema</code> <code>bool</code> If <code>False</code> the field will not be part of the exported OpenAPI schema <code>json_schema_extra</code> <code>JsonDict</code> Any additional JSON schema data for the schema property"
        },
        {
            "location": "core/event_handler/api_gateway/#customizing-api-operations",
            "title": "Customizing API operations",
            "text": "<p>Customize your API endpoints by adding metadata to endpoint definitions.</p> <p>Here's a breakdown of various customizable fields:</p> Field Name Type Description <code>summary</code> <code>str</code> A concise overview of the main functionality of the endpoint. This brief introduction is usually displayed in autogenerated API documentation and helps consumers quickly understand what the endpoint does. <code>description</code> <code>str</code> A more detailed explanation of the endpoint, which can include information about the operation's behavior, including side effects, error states, and other operational guidelines. <code>responses</code> <code>Dict[int, Dict[str, OpenAPIResponse]]</code> A dictionary that maps each HTTP status code to a Response Object as defined by the OpenAPI Specification. This allows you to describe expected responses, including default or error messages, and their corresponding schemas or models for different status codes. <code>response_description</code> <code>str</code> Provides the default textual description of the response sent by the endpoint when the operation is successful. It is intended to give a human-readable understanding of the result. <code>tags</code> <code>List[str]</code> Tags are a way to categorize and group endpoints within the API documentation. They can help organize the operations by resources or other heuristic. <code>operation_id</code> <code>str</code> A unique identifier for the operation, which can be used for referencing this operation in documentation or code. This ID must be unique across all operations described in the API. <code>include_in_schema</code> <code>bool</code> A boolean value that determines whether or not this operation should be included in the OpenAPI schema. Setting it to <code>False</code> can hide the endpoint from generated documentation and schema exports, which might be useful for private or experimental endpoints. <code>deprecated</code> <code>bool</code> A boolean value that determines whether or not this operation should be marked as deprecated in the OpenAPI schema. <p>To implement these customizations, include extra parameters when defining your routes:</p> customizing_api_operations.py<pre><code>import requests\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver(enable_validation=True)\n\n\n@app.get(\n    \"/todos/&lt;todo_id&gt;\",\n    summary=\"Retrieves a todo item\",\n    description=\"Loads a todo item identified by the `todo_id`\",\n    response_description=\"The todo object\",\n    responses={\n        200: {\"description\": \"Todo item found\"},\n        404: {\n            \"description\": \"Item not found\",\n        },\n    },\n    tags=[\"Todos\"],\n)\ndef get_todo_title(todo_id: int) -&gt; str:\n    todo = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todo.raise_for_status()\n\n    return todo.json()[\"title\"]\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#customizing-openapi-metadata",
            "title": "Customizing OpenAPI metadata",
            "text": "<p>Defining and customizing OpenAPI metadata gives detailed, top-level information about your API. Use the method <code>app.configure_openapi</code> to set and tailor this metadata:</p> Field Name Type Description <code>title</code> <code>str</code> The title for your API. It should be a concise, specific name that can be used to identify the API in documentation or listings. <code>version</code> <code>str</code> The version of the API you are documenting. This could reflect the release iteration of the API and helps clients understand the evolution of the API. <code>openapi_version</code> <code>str</code> Specifies the version of the OpenAPI Specification on which your API is based. When using Pydantic v1 it defaults to 3.0.3, and when using Pydantic v2, it defaults to 3.1.0. <code>summary</code> <code>str</code> A short and informative summary that can provide an overview of what the API does. This can be the same as or different from the title but should add context or information. <code>description</code> <code>str</code> A verbose description that can include Markdown formatting, providing a full explanation of the API's purpose, functionalities, and general usage instructions. <code>tags</code> <code>List[str]</code> A collection of tags that categorize endpoints for better organization and navigation within the documentation. This can group endpoints by their functionality or other criteria. <code>servers</code> <code>List[Server]</code> An array of Server objects, which specify the URL to the server and a description for its environment (production, staging, development, etc.), providing connectivity information. <code>terms_of_service</code> <code>str</code> A URL that points to the terms of service for your API. This could provide legal information and user responsibilities related to the usage of the API. <code>contact</code> <code>Contact</code> A Contact object containing contact details of the organization or individuals maintaining the API. This may include fields such as name, URL, and email. <code>license_info</code> <code>License</code> A License object providing the license details for the API, typically including the name of the license and the URL to the full license text. <p>Include extra parameters when exporting your OpenAPI specification to apply these customizations:</p> customizing_api_metadata.py <pre><code>import requests\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.openapi.models import Contact, Server\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver(enable_validation=True)\napp.configure_openapi(\n    title=\"TODO's API\",\n    version=\"1.21.3\",\n    summary=\"API to manage TODOs\",\n    description=\"This API implements all the CRUD operations for the TODO app\",\n    tags=[\"todos\"],\n    servers=[Server(url=\"https://stg.example.org/orders\", description=\"Staging server\")],\n    contact=Contact(name=\"John Smith\", email=\"john@smith.com\"),\n)\n\n\n@app.get(\"/todos/&lt;todo_id&gt;\")\ndef get_todo_title(todo_id: int) -&gt; str:\n    todo = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todo.raise_for_status()\n\n    return todo.json()[\"title\"]\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n\n\nif __name__ == \"__main__\":\n    print(app.get_openapi_json_schema())\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#customizing-swagger-ui",
            "title": "Customizing Swagger UI",
            "text": "Customizing the Swagger metadata <p>The <code>enable_swagger</code> method accepts the same metadata as described at Customizing OpenAPI metadata.</p> <p>The Swagger UI appears by default at the <code>/swagger</code> path, but you can customize this to serve the documentation from another path and specify the source for Swagger UI assets.</p> <p>Below is an example configuration for serving Swagger UI from a custom path or CDN, with assets like CSS and JavaScript loading from a chosen CDN base URL.</p> customizing_swagger.pycustomizing_swagger_middlewares.py <pre><code>from typing import List\n\nimport requests\nfrom pydantic import BaseModel, EmailStr, Field\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver(enable_validation=True)\napp.enable_swagger(path=\"/_swagger\", swagger_base_url=\"https://cdn.example.com/path/to/assets/\")\n\n\nclass Todo(BaseModel):\n    userId: int\n    id_: int = Field(alias=\"id\")\n    title: str\n    completed: bool\n\n\n@app.get(\"/todos\")\ndef get_todos_by_email(email: EmailStr) -&gt; List[Todo]:\n    todos = requests.get(f\"https://jsonplaceholder.typicode.com/todos?email={email}\")\n    todos.raise_for_status()\n\n    return todos.json()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <p>A Middleware can handle tasks such as adding security headers, user authentication, or other request processing for serving the Swagger UI.</p> <pre><code>from typing import List\n\nimport requests\nfrom pydantic import BaseModel, EmailStr, Field\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\nfrom aws_lambda_powertools.event_handler.middlewares import NextMiddleware\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver(enable_validation=True)\n\n\ndef swagger_middleware(app: APIGatewayRestResolver, next_middleware: NextMiddleware) -&gt; Response:\n    is_authenticated = ...\n    if not is_authenticated:\n        return Response(status_code=400, body=\"Unauthorized\")\n\n    return next_middleware(app)\n\n\napp.enable_swagger(middlewares=[swagger_middleware])\n\n\nclass Todo(BaseModel):\n    userId: int\n    id_: int = Field(alias=\"id\")\n    title: str\n    completed: bool\n\n\n@app.get(\"/todos\")\ndef get_todos_by_email(email: EmailStr) -&gt; List[Todo]:\n    todos = requests.get(f\"https://jsonplaceholder.typicode.com/todos?email={email}\")\n    todos.raise_for_status()\n\n    return todos.json()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#security-schemes",
            "title": "Security schemes",
            "text": "Does Powertools implement any of the security schemes? <p>No. Powertools adds support for generating OpenAPI documentation with security schemes, but it doesn't implement any of the security schemes itself, so you must implement the security mechanisms separately.</p> <p>Security schemes are declared at the top-level first. You can reference them globally or on a per path (operation) level. However, if you reference security schemes that are not defined at the top-level it will lead to a <code>SchemaValidationError</code> (invalid OpenAPI spec).</p> Global OpenAPI security schemesPer Operation securityGlobal security schemes and optional security per route security_schemes_global.py<pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import (\n    APIGatewayRestResolver,\n)\nfrom aws_lambda_powertools.event_handler.openapi.models import (\n    OAuth2,\n    OAuthFlowAuthorizationCode,\n    OAuthFlows,\n)\n\ntracer = Tracer()\nlogger = Logger()\n\napp = APIGatewayRestResolver(enable_validation=True)\napp.configure_openapi(\n    title=\"My API\",\n    security_schemes={\n        \"oauth\": OAuth2(\n            flows=OAuthFlows(\n                authorizationCode=OAuthFlowAuthorizationCode(\n                    authorizationUrl=\"https://xxx.amazoncognito.com/oauth2/authorize\",\n                    tokenUrl=\"https://xxx.amazoncognito.com/oauth2/token\",\n                ),\n            ),\n        ),\n    },\n    security=[{\"oauth\": [\"admin\"]}],  # (1)!)\n)\n\n\n@app.get(\"/\")\ndef helloworld() -&gt; dict:\n    return {\"hello\": \"world\"}\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n\n\nif __name__ == \"__main__\":\n    print(app.get_openapi_json_schema())\n</code></pre> <ol> <li>Using the oauth security scheme defined earlier, scoped to the \"admin\" role.</li> </ol> security_schemes_per_operation.py<pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import (\n    APIGatewayRestResolver,\n)\nfrom aws_lambda_powertools.event_handler.openapi.models import (\n    OAuth2,\n    OAuthFlowAuthorizationCode,\n    OAuthFlows,\n)\n\ntracer = Tracer()\nlogger = Logger()\n\napp = APIGatewayRestResolver(enable_validation=True)\napp.configure_openapi(\n    title=\"My API\",\n    security_schemes={\n        \"oauth\": OAuth2(\n            flows=OAuthFlows(\n                authorizationCode=OAuthFlowAuthorizationCode(\n                    authorizationUrl=\"https://xxx.amazoncognito.com/oauth2/authorize\",\n                    tokenUrl=\"https://xxx.amazoncognito.com/oauth2/token\",\n                ),\n            ),\n        ),\n    },\n)\n\n\n@app.get(\"/\", security=[{\"oauth\": [\"admin\"]}])  # (1)!\ndef helloworld() -&gt; dict:\n    return {\"hello\": \"world\"}\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n\n\nif __name__ == \"__main__\":\n    print(app.get_openapi_json_schema())\n</code></pre> <ol> <li>Using the oauth security scheme defined bellow, scoped to the \"admin\" role.</li> </ol> security_schemes_global_and_optional.py<pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import (\n    APIGatewayRestResolver,\n)\nfrom aws_lambda_powertools.event_handler.openapi.models import (\n    OAuth2,\n    OAuthFlowAuthorizationCode,\n    OAuthFlows,\n)\n\ntracer = Tracer()\nlogger = Logger()\n\napp = APIGatewayRestResolver(enable_validation=True)\napp.configure_openapi(\n    title=\"My API\",\n    security_schemes={\n        \"oauth\": OAuth2(\n            flows=OAuthFlows(\n                authorizationCode=OAuthFlowAuthorizationCode(\n                    authorizationUrl=\"https://xxx.amazoncognito.com/oauth2/authorize\",\n                    tokenUrl=\"https://xxx.amazoncognito.com/oauth2/token\",\n                ),\n            ),\n        ),\n    },\n)\n\n\n@app.get(\"/protected\", security=[{\"oauth\": [\"admin\"]}])\ndef protected() -&gt; dict:\n    return {\"hello\": \"world\"}\n\n\n@app.get(\"/unprotected\", security=[{}])  # (1)!\ndef unprotected() -&gt; dict:\n    return {\"hello\": \"world\"}\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n\n\nif __name__ == \"__main__\":\n    print(app.get_openapi_json_schema())\n</code></pre> <ol> <li>To make security optional in a specific route, an empty security requirement ({}) can be included in the array.</li> </ol> <p>OpenAPI 3 lets you describe APIs protected using the following security schemes:</p> Security Scheme Type Description HTTP auth <code>HTTPBase</code> HTTP authentication schemes using the Authorization header (e.g: Basic auth, Bearer) API keys (e.g: query strings, cookies) <code>APIKey</code> API keys in headers, query strings or cookies. OAuth 2 <code>OAuth2</code> Authorization protocol that gives an API client limited access to user data on a web server. OpenID Connect Discovery <code>OpenIdConnect</code> Identity layer built on top of the OAuth 2.0 protocol and supported by some OAuth 2.0. Mutual TLS. <code>MutualTLS</code> Client/server certificate mutual authentication scheme. Using OAuth2 with the Swagger UI? <p>You can use the <code>OAuth2Config</code> option to configure a default OAuth2 app on the generated Swagger UI.</p> <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import (\n    APIGatewayRestResolver,\n)\nfrom aws_lambda_powertools.event_handler.openapi.models import (\n    OAuth2,\n    OAuthFlowAuthorizationCode,\n    OAuthFlows,\n)\nfrom aws_lambda_powertools.event_handler.openapi.swagger_ui import OAuth2Config\n\ntracer = Tracer()\nlogger = Logger()\n\noauth2 = OAuth2Config(\n    client_id=\"xxxxxxxxxxxxxxxxxxxxxxxxxxxx\",\n    app_name=\"OAuth2 app\",\n)\n\napp = APIGatewayRestResolver(enable_validation=True)\napp.enable_swagger(\n    oauth2_config=oauth2,\n    security_schemes={\n        \"oauth\": OAuth2(\n            flows=OAuthFlows(\n                authorizationCode=OAuthFlowAuthorizationCode(\n                    authorizationUrl=\"https://xxx.amazoncognito.com/oauth2/authorize\",\n                    tokenUrl=\"https://xxx.amazoncognito.com/oauth2/token\",\n                ),\n            ),\n        ),\n    },\n    security=[{\"oauth\": []}],\n)\n\n\n@app.get(\"/\")\ndef hello() -&gt; str:\n    return \"world\"\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#openapi-extensions",
            "title": "OpenAPI extensions",
            "text": "<p>For a better experience when working with Lambda and Amazon API Gateway, customers can define extensions using the <code>openapi_extensions</code> parameter. We support defining OpenAPI extensions at the following levels of the OpenAPI JSON Schema: Root, Servers, Operation, and Security Schemes.</p> Warning <p>We do not support the <code>x-amazon-apigateway-any-method</code> and <code>x-amazon-apigateway-integrations</code> extensions.</p> Adding OpenAPI extensions<pre><code>from aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.openapi.models import APIKey, APIKeyIn, Server\n\napp = APIGatewayRestResolver(enable_validation=True)\n\nservers = Server(\n    url=\"http://example.com\",\n    description=\"Example server\",\n    openapi_extensions={\"x-amazon-apigateway-endpoint-configuration\": {\"vpcEndpoint\": \"myendpointid\"}},  # (1)!\n)\n\n\n@app.get(\n    \"/hello\",\n    openapi_extensions={\"x-amazon-apigateway-integration\": {\"type\": \"aws\", \"uri\": \"my_lambda_arn\"}},  # (2)!\n)\ndef hello():\n    return app.get_openapi_json_schema(\n        servers=[servers],\n        security_schemes={\n            \"apikey\": APIKey(\n                name=\"X-API-KEY\",\n                description=\"API KeY\",\n                in_=APIKeyIn.header,\n                openapi_extensions={\"x-amazon-apigateway-authorizer\": \"custom\"},  # (3)!\n            ),\n        },\n        openapi_extensions={\"x-amazon-apigateway-gateway-responses\": {\"DEFAULT_4XX\"}},  # (4)!\n    )\n\n\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <ol> <li>Server level</li> <li>Operation level</li> <li>Security scheme level</li> <li>Root level</li> </ol>"
        },
        {
            "location": "core/event_handler/api_gateway/#custom-serializer",
            "title": "Custom serializer",
            "text": "<p>You can instruct event handler to use a custom serializer to best suit your needs, for example take into account Enums when serializing.</p> Using a custom JSON serializer for responses<pre><code>import json\nfrom dataclasses import asdict, dataclass, is_dataclass\nfrom json import JSONEncoder\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@dataclass\nclass Todo:\n    userId: str\n    id: str  # noqa: A003 VNE003 \"id\" field is reserved\n    title: str\n    completed: bool\n\n\nclass DataclassCustomEncoder(JSONEncoder):\n    \"\"\"A custom JSON encoder to serialize dataclass obj\"\"\"\n\n    def default(self, obj):\n        # Only called for values that aren't JSON serializable\n        # where `obj` will be an instance of Todo in this example\n        return asdict(obj) if is_dataclass(obj) else super().default(obj)\n\n\ndef custom_serializer(obj) -&gt; str:\n    \"\"\"Your custom serializer function APIGatewayRestResolver will use\"\"\"\n    return json.dumps(obj, separators=(\",\", \":\"), cls=DataclassCustomEncoder)\n\n\napp = APIGatewayRestResolver(serializer=custom_serializer)\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    ret: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    ret.raise_for_status()\n    todos = [Todo(**todo) for todo in ret.json()]\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#split-routes-with-router",
            "title": "Split routes with Router",
            "text": "<p>As you grow the number of routes a given Lambda function should handle, it is natural to either break into smaller Lambda functions, or split routes into separate files to ease maintenance - that's where the <code>Router</code> feature is useful.</p> <p>Let's assume you have <code>split_route.py</code> as your Lambda function entrypoint and routes in <code>split_route_module.py</code>. This is how you'd use the <code>Router</code> feature.</p> split_route_module.pysplit_route.py <p>We import Router instead of APIGatewayRestResolver; syntax wise is exactly the same.</p> <p>Info</p> <p>This means all methods, including middleware will work as usual.</p> <pre><code>from urllib.parse import quote\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler.api_gateway import Router\n\ntracer = Tracer()\nrouter = Router()\n\nendpoint = \"https://jsonplaceholder.typicode.com/todos\"\n\n\n@router.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    api_key = router.current_event.headers[\"X-Api-Key\"]\n\n    todos: Response = requests.get(endpoint, headers={\"X-Api-Key\": api_key})\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@router.get(\"/todos/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: str):  # value come as str\n    api_key = router.current_event.headers[\"X-Api-Key\"]\n\n    todo_id = quote(todo_id, safe=\"\")\n    todos: Response = requests.get(f\"{endpoint}/{todo_id}\", headers={\"X-Api-Key\": api_key})\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n</code></pre> <p>We use <code>include_router</code> method and include all user routers registered in the <code>router</code> global object.</p> <p>Note</p> <p>This method merges routes, context and middleware from <code>Router</code> into the main resolver instance (<code>APIGatewayRestResolver()</code>).</p> <pre><code>import split_route_module\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\napp.include_router(split_route_module.router)  # (1)!\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>When using middleware in both <code>Router</code> and main resolver, you can make <code>Router</code> middlewares to take precedence by using <code>include_router</code> before <code>app.use()</code>.</li> </ol>"
        },
        {
            "location": "core/event_handler/api_gateway/#route-prefix",
            "title": "Route prefix",
            "text": "<p>In the previous example, <code>split_route_module.py</code> routes had a <code>/todos</code> prefix. This might grow over time and become repetitive.</p> <p>When necessary, you can set a prefix when including a router object. This means you could remove <code>/todos</code> prefix altogether.</p> split_route_prefix.pysplit_route_prefix_module.py <pre><code>import split_route_module\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n# prefix '/todos' to any route in `split_route_module.router`\napp.include_router(split_route_module.router, prefix=\"/todos\")\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>from urllib.parse import quote\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler.api_gateway import Router\n\ntracer = Tracer()\nrouter = Router()\n\nendpoint = \"https://jsonplaceholder.typicode.com/todos\"\n\n\n@router.get(\"/\")\n@tracer.capture_method\ndef get_todos():\n    api_key = router.current_event.headers[\"X-Api-Key\"]\n\n    todos: Response = requests.get(endpoint, headers={\"X-Api-Key\": api_key})\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos.json()[:10]}\n\n\n@router.get(\"/&lt;todo_id&gt;\")\n@tracer.capture_method\ndef get_todo_by_id(todo_id: str):  # value come as str\n    api_key = router.current_event.headers[\"X-Api-Key\"]\n\n    todo_id = quote(todo_id, safe=\"\")\n    todos: Response = requests.get(f\"{endpoint}/{todo_id}\", headers={\"X-Api-Key\": api_key})\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()}\n\n\n# many more routes\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#specialized-router-types",
            "title": "Specialized router types",
            "text": "<p>You can use specialized router classes according to the type of event that you are resolving. This way you'll get type hints from your IDE as you access the <code>current_event</code> property.</p> Router Resolver <code>current_event</code> type APIGatewayRouter APIGatewayRestResolver APIGatewayProxyEvent APIGatewayHttpRouter APIGatewayHttpResolver APIGatewayProxyEventV2 ALBRouter ALBResolver ALBEvent LambdaFunctionUrlRouter LambdaFunctionUrlResolver LambdaFunctionUrlEvent <pre><code>from aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.router import APIGatewayRouter\n\napp = APIGatewayRestResolver()\nrouter = APIGatewayRouter()\n\n\n@router.get(\"/me\")\ndef get_self():\n    # router.current_event is a APIGatewayProxyEvent\n    account_id = router.current_event.request_context.account_id\n\n    return {\"account_id\": account_id}\n\n\napp.include_router(router)\n\n\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#sharing-contextual-data",
            "title": "Sharing contextual data",
            "text": "<p>You can use <code>append_context</code> when you want to share data between your App and Router instances. Any data you share will be available via the <code>context</code> dictionary available in your App or Router context.</p> We always clear data available in <code>context</code> after each invocation. <p>This can be useful for middlewares injecting contextual information before a request is processed.</p> split_route_append_context.pysplit_route_append_context_module.py <pre><code>import split_route_append_context_module\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\napp.include_router(split_route_append_context_module.router)\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    app.append_context(is_admin=True)  # arbitrary number of key=value data\n    return app.resolve(event, context)\n</code></pre> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler.api_gateway import Router\n\ntracer = Tracer()\nrouter = Router()\n\nendpoint = \"https://jsonplaceholder.typicode.com/todos\"\n\n\n@router.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    is_admin: bool = router.context.get(\"is_admin\", False)\n    todos = {}\n\n    if is_admin:\n        todos: Response = requests.get(endpoint)\n        todos.raise_for_status()\n        todos = todos.json()[:10]\n\n    # for brevity, we'll limit to the first 10 only\n    return {\"todos\": todos}\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#sample-layout",
            "title": "Sample layout",
            "text": "<p>This is a sample project layout for a monolithic function with routes split in different files (<code>/todos</code>, <code>/health</code>).</p> Sample project layout<pre><code>.\n├── pyproject.toml            # project app &amp; dev dependencies; poetry, pipenv, etc.\n├── poetry.lock\n├── src\n│       ├── __init__.py\n│       ├── requirements.txt  # sam build detect it automatically due to CodeUri: src. poetry export --format src/requirements.txt\n│       └── todos\n│           ├── __init__.py\n│           ├── main.py       # this will be our todos Lambda fn; it could be split in folders if we want separate fns same code base\n│           └── routers       # routers module\n│               ├── __init__.py\n│               ├── health.py # /health routes. from routers import todos; health.router\n│               └── todos.py  # /todos routes. from .routers import todos; todos.router\n├── template.yml              # SAM. CodeUri: src, Handler: todos.main.lambda_handler\n└── tests\n    ├── __init__.py\n    ├── unit\n    │   ├── __init__.py\n    │   └── test_todos.py     # unit tests for the todos router\n    │   └── test_health.py    # unit tests for the health router\n    └── functional\n        ├── __init__.py\n        ├── conftest.py       # pytest fixtures for the functional tests\n        └── test_main.py      # functional tests for the main lambda handler\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#considerations",
            "title": "Considerations",
            "text": "<p>This utility is optimized for fast startup, minimal feature set, and to quickly on-board customers familiar with frameworks like Flask — it's not meant to be a fully fledged framework.</p> <p>Event Handler naturally leads to a single Lambda function handling multiple routes for a given service, which can be eventually broken into multiple functions.</p> <p>Both single (monolithic) and multiple functions (micro) offer different set of trade-offs worth knowing.</p> Tip <p>TL;DR. Start with a monolithic function, add additional functions with new handlers, and possibly break into micro functions if necessary.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#monolithic-function",
            "title": "Monolithic function",
            "text": "<p>A monolithic function means that your final code artifact will be deployed to a single function. This is generally the best approach to start.</p> <p>Benefits</p> <ul> <li>Code reuse. It's easier to reason about your service, modularize it and reuse code as it grows. Eventually, it can be turned into a standalone library.</li> <li>No custom tooling. Monolithic functions are treated just like normal Python packages; no upfront investment in tooling.</li> <li>Faster deployment and debugging. Whether you use all-at-once, linear, or canary deployments, a monolithic function is a single deployable unit. IDEs like PyCharm and VSCode have tooling to quickly profile, visualize, and step through debug any Python package.</li> </ul> <p>Downsides</p> <ul> <li>Cold starts. Frequent deployments and/or high load can diminish the benefit of monolithic functions depending on your latency requirements, due to Lambda scaling model. Always load test to pragmatically balance between your customer experience and development cognitive load.</li> <li>Granular security permissions. The micro function approach enables you to use fine-grained permissions &amp; access controls, separate external dependencies &amp; code signing at the function level. Conversely, you could have multiple functions while duplicating the final code artifact in a monolithic approach.<ul> <li>Regardless, least privilege can be applied to either approaches.</li> </ul> </li> <li>Higher risk per deployment. A misconfiguration or invalid import can cause disruption if not caught earlier in automated testing. Multiple functions can mitigate misconfigurations but they would still share the same code artifact. You can further minimize risks with multiple environments in your CI/CD pipeline.</li> </ul>"
        },
        {
            "location": "core/event_handler/api_gateway/#micro-function",
            "title": "Micro function",
            "text": "<p>A micro function means that your final code artifact will be different to each function deployed. This is generally the approach to start if you're looking for fine-grain control and/or high load on certain parts of your service.</p> <p>Benefits</p> <ul> <li>Granular scaling. A micro function can benefit from the Lambda scaling model to scale differently depending on each part of your application. Concurrency controls and provisioned concurrency can also be used at a granular level for capacity management.</li> <li>Discoverability. Micro functions are easier to visualize when using distributed tracing. Their high-level architectures can be self-explanatory, and complexity is highly visible — assuming each function is named to the business purpose it serves.</li> <li>Package size. An independent function can be significant smaller (KB vs MB) depending on external dependencies it require to perform its purpose. Conversely, a monolithic approach can benefit from Lambda Layers to optimize builds for external dependencies.</li> </ul> <p>Downsides</p> <ul> <li>Upfront investment. You need custom build tooling to bundle assets, including C bindings for runtime compatibility. Operations become more elaborate — you need to standardize tracing labels/annotations, structured logging, and metrics to pinpoint root causes.<ul> <li>Engineering discipline is necessary for both approaches. Micro-function approach however requires further attention in consistency as the number of functions grow, just like any distributed system.</li> </ul> </li> <li>Harder to share code. Shared code must be carefully evaluated to avoid unnecessary deployments when that changes. Equally, if shared code isn't a library, your development, building, deployment tooling need to accommodate the distinct layout.</li> <li>Slower safe deployments. Safely deploying multiple functions require coordination — AWS CodeDeploy deploys and verifies each function sequentially. This increases lead time substantially (minutes to hours) depending on the deployment strategy you choose. You can mitigate it by selectively enabling it in prod-like environments only, and where the risk profile is applicable.<ul> <li>Automated testing, operational and security reviews are essential to stability in either approaches.</li> </ul> </li> </ul> <p>Example</p> <p>Consider a simplified micro function structured REST API that has two routes:</p> <ul> <li><code>/users</code> - an endpoint that will return all users of the application on <code>GET</code> requests</li> <li><code>/users/&lt;id&gt;</code> - an endpoint that looks up a single users details by ID on <code>GET</code> requests</li> </ul> <p>Each endpoint will be it's own Lambda function that is configured as a Lambda integration. This allows you to set different configurations for each lambda (memory size, layers, etc.).</p> <code>/users</code> Endpoint<code>/users/&lt;id&gt;</code> EndpointMicro Function Example SAM Template <pre><code>import json\nfrom dataclasses import dataclass\nfrom http import HTTPStatus\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n# This would likely be a db lookup\nusers = [\n    {\n        \"user_id\": \"b0b2a5bf-ee1e-4c5e-9a86-91074052739e\",\n        \"email\": \"john.doe@example.com\",\n        \"active\": True,\n    },\n    {\n        \"user_id\": \"3a9df6b1-938c-4e80-bd4a-0c966f4b1c1e\",\n        \"email\": \"jane.smith@example.com\",\n        \"active\": False,\n    },\n    {\n        \"user_id\": \"aa0d3d09-9cb9-42b9-9e63-1fb17ea52981\",\n        \"email\": \"alex.wilson@example.com\",\n        \"active\": True,\n    },\n]\n\n\n@dataclass\nclass User:\n    user_id: str\n    email: str\n    active: bool\n\n\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/users\")\ndef all_active_users():\n    \"\"\"HTTP Response for all active users\"\"\"\n    all_users = [User(**user) for user in users]\n    all_active_users = [user.__dict__ for user in all_users if user.active]\n\n    return Response(\n        status_code=HTTPStatus.OK.value,\n        content_type=\"application/json\",\n        body=json.dumps(all_active_users),\n    )\n\n\n@logger.inject_lambda_context()\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>import json\nfrom dataclasses import dataclass\nfrom http import HTTPStatus\nfrom typing import Union\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver, Response\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n# This would likely be a db lookup\nusers = [\n    {\n        \"user_id\": \"b0b2a5bf-ee1e-4c5e-9a86-91074052739e\",\n        \"email\": \"john.doe@example.com\",\n        \"active\": True,\n    },\n    {\n        \"user_id\": \"3a9df6b1-938c-4e80-bd4a-0c966f4b1c1e\",\n        \"email\": \"jane.smith@example.com\",\n        \"active\": False,\n    },\n    {\n        \"user_id\": \"aa0d3d09-9cb9-42b9-9e63-1fb17ea52981\",\n        \"email\": \"alex.wilson@example.com\",\n        \"active\": True,\n    },\n]\n\n\n@dataclass\nclass User:\n    user_id: str\n    email: str\n    active: bool\n\n\ndef get_user_by_id(user_id: str) -&gt; Union[User, None]:\n    for user_data in users:\n        if user_data[\"user_id\"] == user_id:\n            return User(\n                user_id=str(user_data[\"user_id\"]),\n                email=str(user_data[\"email\"]),\n                active=bool(user_data[\"active\"]),\n            )\n\n    return None\n\n\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/users/&lt;user_id&gt;\")\ndef all_active_users(user_id: str):\n    \"\"\"HTTP Response for all active users\"\"\"\n    user = get_user_by_id(user_id)\n\n    if user:\n        return Response(\n            status_code=HTTPStatus.OK.value,\n            content_type=\"application/json\",\n            body=json.dumps(user.__dict__),\n        )\n\n    else:\n        return Response(status_code=HTTPStatus.NOT_FOUND)\n\n\n@logger.inject_lambda_context()\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: &gt;\n    micro-function-example\n\nGlobals:\n    Api:\n        TracingEnabled: true\n        Cors: # see CORS section\n            AllowOrigin: \"'https://example.com'\"\n            AllowHeaders: \"'Content-Type,Authorization,X-Amz-Date'\"\n            MaxAge: \"'300'\"\n        BinaryMediaTypes: # see Binary responses section\n            - \"*~1*\" # converts to */* for any binary type\n            # NOTE: use this stricter version if you're also using CORS; */* doesn't work with CORS\n            # see: https://github.com/aws-powertools/powertools-lambda-python/issues/3373#issuecomment-1821144779\n            # - \"image~1*\" # converts to image/*\n            # - \"*~1csv\" # converts to */csv, eg text/csv, application/csv\n\n    Function:\n        Timeout: 5\n        Runtime: python3.12\n\nResources:\n    # Lambda Function Solely For /users endpoint\n    AllUsersFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n            Handler: app.lambda_handler\n            CodeUri: users\n            Description: Function for /users endpoint\n            Architectures:\n                - x86_64\n            Tracing: Active\n            Events:\n                UsersPath:\n                    Type: Api\n                    Properties:\n                        Path: /users\n                        Method: GET\n            MemorySize: 128 # Each Lambda Function can have it's own memory configuration\n            Environment:\n                Variables:\n                    POWERTOOLS_LOG_LEVEL: INFO\n            Tags:\n                LambdaPowertools: python\n\n    # Lambda Function Solely For /users/{id} endpoint\n    UserByIdFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n            Handler: app.lambda_handler\n            CodeUri: users_by_id\n            Description: Function for /users/{id} endpoint\n            Architectures:\n                - x86_64\n            Tracing: Active\n            Events:\n                UsersByIdPath:\n                    Type: Api\n                    Properties:\n                        Path: /users/{id+}\n                        Method: GET\n            MemorySize: 128 # Each Lambda Function can have it's own memory configuration\n            Environment:\n                Variables:\n                    POWERTOOLS_LOG_LEVEL: INFO\n</code></pre> Note <p>You can see some of the downsides in this example such as some code reuse. If set up with proper build tooling, the <code>User</code> class could be shared across functions. This could be accomplished by packaging shared code as a Lambda Layer or Pants.</p>"
        },
        {
            "location": "core/event_handler/api_gateway/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>You can test your routes by passing a proxy event request with required params.</p> API Gateway REST APIAPI Gateway HTTP APIApplication Load BalancerLambda Function URL assert_rest_api_resolver_response.pyassert_rest_api_response_module.py <pre><code>from dataclasses import dataclass\n\nimport assert_rest_api_resolver_response\nimport pytest\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n    aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef test_lambda_handler(lambda_context):\n    minimal_event = {\n        \"path\": \"/todos\",\n        \"httpMethod\": \"GET\",\n        \"requestContext\": {\"requestId\": \"227b78aa-779d-47d4-a48e-ce62120393b8\"},  # correlation ID\n    }\n    # Example of API Gateway REST API request event:\n    # https://docs.aws.amazon.com/lambda/latest/dg/services-apigateway.html#apigateway-example-event\n    ret = assert_rest_api_resolver_response.lambda_handler(minimal_event, lambda_context)\n    assert ret[\"statusCode\"] == 200\n    assert ret[\"body\"] != \"\"\n</code></pre> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> assert_http_api_resolver_response.pyassert_http_api_response_module.py <pre><code>from dataclasses import dataclass\n\nimport assert_http_api_response_module\nimport pytest\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n    aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef test_lambda_handler(lambda_context: LambdaContext):\n    minimal_event = {\n        \"rawPath\": \"/todos\",\n        \"requestContext\": {\n            \"requestContext\": {\"requestId\": \"227b78aa-779d-47d4-a48e-ce62120393b8\"},  # correlation ID\n            \"http\": {\n                \"method\": \"GET\",\n            },\n            \"stage\": \"$default\",\n        },\n    }\n    # Example of API Gateway HTTP API request event:\n    # https://docs.aws.amazon.com/apigateway/latest/developerguide/http-api-develop-integrations-lambda.html\n\n    ret = assert_http_api_response_module.lambda_handler(minimal_event, lambda_context)\n    assert ret[\"statusCode\"] == 200\n    assert ret[\"body\"] != \"\"\n</code></pre> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayHttpResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = APIGatewayHttpResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_HTTP)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> assert_alb_api_resolver_response.pyassert_alb_api_response_module.py <pre><code>from dataclasses import dataclass\n\nimport assert_alb_api_response_module\nimport pytest\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n    aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef test_lambda_handler(lambda_context: LambdaContext):\n    minimal_event = {\n        \"path\": \"/todos\",\n        \"httpMethod\": \"GET\",\n        \"headers\": {\"x-amzn-trace-id\": \"b25827e5-0e30-4d52-85a8-4df449ee4c5a\"},\n    }\n    # Example of Application Load Balancer request event:\n    # https://docs.aws.amazon.com/lambda/latest/dg/services-alb.html\n\n    ret = assert_alb_api_response_module.lambda_handler(minimal_event, lambda_context)\n    assert ret[\"statusCode\"] == 200\n    assert ret[\"body\"] != \"\"\n</code></pre> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import ALBResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = ALBResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPLICATION_LOAD_BALANCER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> assert_function_url_api_resolver_response.pyassert_function_url_api_response_module.py <pre><code>from dataclasses import dataclass\n\nimport assert_function_url_api_response_module\nimport pytest\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n    aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef test_lambda_handler(lambda_context: LambdaContext):\n    minimal_event = {\n        \"rawPath\": \"/todos\",\n        \"requestContext\": {\n            \"requestContext\": {\"requestId\": \"227b78aa-779d-47d4-a48e-ce62120393b8\"},  # correlation ID\n            \"http\": {\n                \"method\": \"GET\",\n            },\n            \"stage\": \"$default\",\n        },\n    }\n    # Example of Lambda Function URL request event:\n    # https://docs.aws.amazon.com/lambda/latest/dg/urls-invocation.html#urls-payloads\n\n    ret = assert_function_url_api_response_module.lambda_handler(minimal_event, lambda_context)\n    assert ret[\"statusCode\"] == 200\n    assert ret[\"body\"] != \"\"\n</code></pre> <pre><code>import requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import LambdaFunctionUrlResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = LambdaFunctionUrlResolver()\n\n\n@app.get(\"/todos\")\n@tracer.capture_method\ndef get_todos():\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    return {\"todos\": todos.json()[:10]}\n\n\n# You can continue to use other utilities just as before\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.LAMBDA_FUNCTION_URL)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/api_gateway/#faq",
            "title": "FAQ",
            "text": "<p>What's the difference between this utility and frameworks like Chalice?</p> <p>Chalice is a full featured microframework that manages application and infrastructure. This utility, however, is largely focused on routing to reduce boilerplate and expects you to setup and manage infrastructure with your framework of choice.</p> <p>That said, Chalice has native integration with Lambda Powertools if you're looking for a more opinionated and web framework feature set.</p> <p>What happened to <code>ApiGatewayResolver</code>?</p> <p>It's been superseded by more explicit resolvers like <code>APIGatewayRestResolver</code>, <code>APIGatewayHttpResolver</code>, and <code>ALBResolver</code>.</p> <p><code>ApiGatewayResolver</code> handled multiple types of event resolvers for convenience via <code>proxy_type</code> param. However, it made it impossible for static checkers like Mypy and IDEs IntelliSense to know what properties a <code>current_event</code> would have due to late bound resolution.</p> <p>This provided a suboptimal experience for customers not being able to find all properties available besides common ones between API Gateway REST, HTTP, and ALB - while manually annotating <code>app.current_event</code> would work it is not the experience we want to provide to customers.</p> <p><code>ApiGatewayResolver</code> will be deprecated in v2 and have appropriate warnings as soon as we have a v2 draft.</p>"
        },
        {
            "location": "core/event_handler/appsync/",
            "title": "GraphQL API",
            "text": "<p>Event Handler for AWS AppSync and Amplify GraphQL Transformer.</p> <pre><code>stateDiagram-v2\n    direction LR\n    EventSource: AWS Lambda Event Sources\n    EventHandlerResolvers: AWS AppSync Direct invocation&lt;br/&gt;&lt;br/&gt; AWS AppSync Batch invocation\n    LambdaInit: Lambda invocation\n    EventHandler: Event Handler\n    EventHandlerResolver: Route event based on GraphQL type/field keys\n    YourLogic: Run your registered resolver function\n    EventHandlerResolverBuilder: Adapts response to Event Source contract\n    LambdaResponse: Lambda response\n\n    state EventSource {\n        EventHandlerResolvers\n    }\n\n    EventHandlerResolvers --&gt; LambdaInit\n\n    LambdaInit --&gt; EventHandler\n    EventHandler --&gt; EventHandlerResolver\n\n    state EventHandler {\n        [*] --&gt; EventHandlerResolver: app.resolve(event, context)\n        EventHandlerResolver --&gt; YourLogic\n        YourLogic --&gt; EventHandlerResolverBuilder\n    }\n\n    EventHandler --&gt; LambdaResponse</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#key-features",
            "title": "Key Features",
            "text": "<ul> <li>Choose between strictly match a GraphQL field name or all of them to a function</li> <li>Automatically parse API arguments to function arguments</li> <li>Integrates with Event Source Data classes utilities to access resolver and identity information</li> <li>Support async Python 3.8+ functions and generators</li> </ul>"
        },
        {
            "location": "core/event_handler/appsync/#terminology",
            "title": "Terminology",
            "text": "<p>Direct Lambda Resolver. A custom AppSync Resolver to bypass the use of Apache Velocity Template (VTL) and automatically map your function's response to a GraphQL field.</p> <p>Amplify GraphQL Transformer. Custom GraphQL directives to define your application's data model using Schema Definition Language (SDL), e.g., <code>@function</code>. Amplify CLI uses these directives to convert GraphQL SDL into full descriptive AWS CloudFormation templates.</p>"
        },
        {
            "location": "core/event_handler/appsync/#getting-started",
            "title": "Getting started",
            "text": "Tip: Designing GraphQL Schemas for the first time? <p>Visit AWS AppSync schema documentation to understand how to define types, nesting, and pagination.</p>"
        },
        {
            "location": "core/event_handler/appsync/#required-resources",
            "title": "Required resources",
            "text": "<p>You must have an existing AppSync GraphQL API and IAM permissions to invoke your Lambda function. That said, there is no additional permissions to use Event Handler as routing requires no dependency (standard library).</p> <p>This is the sample infrastructure we are using for the initial examples with a AppSync Direct Lambda Resolver.</p> getting_started_schema.graphqltemplate.yaml <pre><code>schema {\n    query: Query\n    mutation: Mutation\n}\n\ntype Query {\n    # these are fields you can attach resolvers to (type_name: Query, field_name: getTodo)\n    getTodo(id: ID!): Todo\n    listTodos: [Todo]\n}\n\ntype Mutation {\n    createTodo(title: String!): Todo\n}\n\ntype Todo {\n    id: ID!\n    userId: String\n    title: String\n    completed: Boolean\n}\n</code></pre> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Hello world Direct Lambda Resolver\n\nGlobals:\n  Function:\n    Timeout: 5\n    Runtime: python3.12\n    Tracing: Active\n    Environment:\n      Variables:\n        # Powertools for AWS Lambda (Python) env vars: https://docs.powertools.aws.dev/lambda/python/latest/#environment-variables\n        POWERTOOLS_LOG_LEVEL: INFO\n        POWERTOOLS_LOGGER_SAMPLE_RATE: 0.1\n        POWERTOOLS_LOGGER_LOG_EVENT: true\n        POWERTOOLS_SERVICE_NAME: example\n\nResources:\n  TodosFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: getting_started_graphql_api_resolver.lambda_handler\n      CodeUri: ../src\n      Description: Sample Direct Lambda Resolver\n\n  # IAM Permissions and Roles\n\n  AppSyncServiceRole:\n    Type: \"AWS::IAM::Role\"\n    Properties:\n      AssumeRolePolicyDocument:\n        Version: \"2012-10-17\"\n        Statement:\n          - Effect: \"Allow\"\n            Principal:\n              Service:\n                - \"appsync.amazonaws.com\"\n            Action:\n              - \"sts:AssumeRole\"\n\n  InvokeLambdaResolverPolicy:\n    Type: \"AWS::IAM::Policy\"\n    Properties:\n      PolicyName: \"DirectAppSyncLambda\"\n      PolicyDocument:\n        Version: \"2012-10-17\"\n        Statement:\n          - Effect: \"Allow\"\n            Action: \"lambda:invokeFunction\"\n            Resource:\n              - !GetAtt TodosFunction.Arn\n      Roles:\n        - !Ref AppSyncServiceRole\n\n  # GraphQL API\n\n  TodosApi:\n    Type: \"AWS::AppSync::GraphQLApi\"\n    Properties:\n      Name: TodosApi\n      AuthenticationType: \"API_KEY\"\n      XrayEnabled: true\n\n  TodosApiKey:\n    Type: AWS::AppSync::ApiKey\n    Properties:\n      ApiId: !GetAtt TodosApi.ApiId\n\n  TodosApiSchema:\n    Type: \"AWS::AppSync::GraphQLSchema\"\n    Properties:\n      ApiId: !GetAtt TodosApi.ApiId\n      DefinitionS3Location: ../src/getting_started_schema.graphql\n    Metadata:\n      cfn-lint:\n        config:\n          ignore_checks:\n            - W3002 # allow relative path in DefinitionS3Location\n\n  # Lambda Direct Data Source and Resolver\n\n  TodosFunctionDataSource:\n    Type: \"AWS::AppSync::DataSource\"\n    Properties:\n      ApiId: !GetAtt TodosApi.ApiId\n      Name: \"HelloWorldLambdaDirectResolver\"\n      Type: \"AWS_LAMBDA\"\n      ServiceRoleArn: !GetAtt AppSyncServiceRole.Arn\n      LambdaConfig:\n        LambdaFunctionArn: !GetAtt TodosFunction.Arn\n\n  ListTodosResolver:\n    Type: \"AWS::AppSync::Resolver\"\n    Properties:\n      ApiId: !GetAtt TodosApi.ApiId\n      TypeName: \"Query\"\n      FieldName: \"listTodos\"\n      DataSourceName: !GetAtt TodosFunctionDataSource.Name\n\n  GetTodoResolver:\n    Type: \"AWS::AppSync::Resolver\"\n    Properties:\n      ApiId: !GetAtt TodosApi.ApiId\n      TypeName: \"Query\"\n      FieldName: \"getTodo\"\n      DataSourceName: !GetAtt TodosFunctionDataSource.Name\n\n  CreateTodoResolver:\n    Type: \"AWS::AppSync::Resolver\"\n    Properties:\n      ApiId: !GetAtt TodosApi.ApiId\n      TypeName: \"Mutation\"\n      FieldName: \"createTodo\"\n      DataSourceName: !GetAtt TodosFunctionDataSource.Name\n\nOutputs:\n  TodosFunction:\n    Description: \"Hello World Lambda Function ARN\"\n    Value: !GetAtt TodosFunction.Arn\n\n  TodosApi:\n    Value: !GetAtt TodosApi.GraphQLUrl\n</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#resolver-decorator",
            "title": "Resolver decorator",
            "text": "<p>You can define your functions to match GraphQL types and fields with the <code>app.resolver()</code> decorator.</p> What is a type and field? <p>A type would be a top-level GraphQL Type like <code>Query</code>, <code>Mutation</code>, <code>Todo</code>. A GraphQL Field would be <code>listTodos</code> under <code>Query</code>, <code>createTodo</code> under <code>Mutation</code>, etc.</p> <p>Here's an example with two separate functions to resolve <code>getTodo</code> and <code>listTodos</code> fields within the <code>Query</code> type. For completion, we use Scalar type utilities to generate the right output based on our schema definition.</p> Important <p>GraphQL arguments are passed as function keyword arguments.</p> <p>Example</p> <p>The GraphQL Query <code>getTodo(id: \"todo_id_value\")</code> will call <code>get_todo</code> as <code>get_todo(id=\"todo_id_value\")</code>.</p> getting_started_graphql_api_resolver.pygetting_started_schema.graphqlsample events <pre><code>from typing import List, TypedDict\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.data_classes.appsync import scalar_types_utils\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\n\n\nclass Todo(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    userId: str\n    title: str\n    completed: bool\n\n\n@app.resolver(type_name=\"Query\", field_name=\"getTodo\")\n@tracer.capture_method\ndef get_todo(\n    id: str = \"\",  # noqa AA03 VNE003 shadows built-in id to match query argument, e.g., getTodo(id: \"some_id\")\n) -&gt; Todo:\n    logger.info(f\"Fetching Todo {id}\")\n    todos: Response = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{id}\")\n    todos.raise_for_status()\n\n    return todos.json()\n\n\n@app.resolver(type_name=\"Query\", field_name=\"listTodos\")\n@tracer.capture_method\ndef list_todos() -&gt; List[Todo]:\n    todos: Response = requests.get(\"https://jsonplaceholder.typicode.com/todos\")\n    todos.raise_for_status()\n\n    # for brevity, we'll limit to the first 10 only\n    return todos.json()[:10]\n\n\n@app.resolver(type_name=\"Mutation\", field_name=\"createTodo\")\n@tracer.capture_method\ndef create_todo(title: str) -&gt; Todo:\n    payload = {\"userId\": scalar_types_utils.make_id(), \"title\": title, \"completed\": False}  # dummy UUID str\n    todo: Response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", json=payload)\n    todo.raise_for_status()\n\n    return todo.json()\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>schema {\n    query: Query\n    mutation: Mutation\n}\n\ntype Query {\n    # these are fields you can attach resolvers to (type_name: Query, field_name: getTodo)\n    getTodo(id: ID!): Todo\n    listTodos: [Todo]\n}\n\ntype Mutation {\n    createTodo(title: String!): Todo\n}\n\ntype Todo {\n    id: ID!\n    userId: String\n    title: String\n    completed: Boolean\n}\n</code></pre> getting_started_get_todo.jsongetting_started_list_todos.jsongetting_started_create_todo.json <pre><code>{\n    \"arguments\": {\n        \"id\": \"7e362732-c8cd-4405-b090-144ac9b38960\"\n    },\n    \"identity\": null,\n    \"source\": null,\n    \"request\": {\n        \"headers\": {\n            \"x-forwarded-for\": \"1.2.3.4, 5.6.7.8\",\n            \"accept-encoding\": \"gzip, deflate, br\",\n            \"cloudfront-viewer-country\": \"NL\",\n            \"cloudfront-is-tablet-viewer\": \"false\",\n            \"referer\": \"https://eu-west-1.console.aws.amazon.com/appsync/home?region=eu-west-1\",\n            \"via\": \"2.0 9fce949f3749407c8e6a75087e168b47.cloudfront.net (CloudFront)\",\n            \"cloudfront-forwarded-proto\": \"https\",\n            \"origin\": \"https://eu-west-1.console.aws.amazon.com\",\n            \"x-api-key\": \"da1-c33ullkbkze3jg5hf5ddgcs4fq\",\n            \"content-type\": \"application/json\",\n            \"x-amzn-trace-id\": \"Root=1-606eb2f2-1babc433453a332c43fb4494\",\n            \"x-amz-cf-id\": \"SJw16ZOPuMZMINx5Xcxa9pB84oMPSGCzNOfrbJLvd80sPa0waCXzYQ==\",\n            \"content-length\": \"114\",\n            \"x-amz-user-agent\": \"AWS-Console-AppSync/\",\n            \"x-forwarded-proto\": \"https\",\n            \"host\": \"ldcvmkdnd5az3lm3gnf5ixvcyy.appsync-api.eu-west-1.amazonaws.com\",\n            \"accept-language\": \"en-US,en;q=0.5\",\n            \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0\",\n            \"cloudfront-is-desktop-viewer\": \"true\",\n            \"cloudfront-is-mobile-viewer\": \"false\",\n            \"accept\": \"*/*\",\n            \"x-forwarded-port\": \"443\",\n            \"cloudfront-is-smarttv-viewer\": \"false\"\n        }\n    },\n    \"prev\": null,\n    \"info\": {\n        \"parentTypeName\": \"Query\",\n        \"selectionSetList\": [\n            \"title\",\n            \"id\"\n        ],\n        \"selectionSetGraphQL\": \"{\\n  title\\n  id\\n}\",\n        \"fieldName\": \"getTodo\",\n        \"variables\": {}\n    },\n    \"stash\": {}\n}\n</code></pre> <pre><code>{\n    \"arguments\": {},\n    \"identity\": null,\n    \"source\": null,\n    \"request\": {\n        \"headers\": {\n            \"x-forwarded-for\": \"1.2.3.4, 5.6.7.8\",\n            \"accept-encoding\": \"gzip, deflate, br\",\n            \"cloudfront-viewer-country\": \"NL\",\n            \"cloudfront-is-tablet-viewer\": \"false\",\n            \"referer\": \"https://eu-west-1.console.aws.amazon.com/appsync/home?region=eu-west-1\",\n            \"via\": \"2.0 9fce949f3749407c8e6a75087e168b47.cloudfront.net (CloudFront)\",\n            \"cloudfront-forwarded-proto\": \"https\",\n            \"origin\": \"https://eu-west-1.console.aws.amazon.com\",\n            \"x-api-key\": \"da1-c33ullkbkze3jg5hf5ddgcs4fq\",\n            \"content-type\": \"application/json\",\n            \"x-amzn-trace-id\": \"Root=1-606eb2f2-1babc433453a332c43fb4494\",\n            \"x-amz-cf-id\": \"SJw16ZOPuMZMINx5Xcxa9pB84oMPSGCzNOfrbJLvd80sPa0waCXzYQ==\",\n            \"content-length\": \"114\",\n            \"x-amz-user-agent\": \"AWS-Console-AppSync/\",\n            \"x-forwarded-proto\": \"https\",\n            \"host\": \"ldcvmkdnd5az3lm3gnf5ixvcyy.appsync-api.eu-west-1.amazonaws.com\",\n            \"accept-language\": \"en-US,en;q=0.5\",\n            \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0\",\n            \"cloudfront-is-desktop-viewer\": \"true\",\n            \"cloudfront-is-mobile-viewer\": \"false\",\n            \"accept\": \"*/*\",\n            \"x-forwarded-port\": \"443\",\n            \"cloudfront-is-smarttv-viewer\": \"false\"\n        }\n    },\n    \"prev\": null,\n    \"info\": {\n        \"parentTypeName\": \"Query\",\n        \"selectionSetList\": [\n            \"id\",\n            \"title\"\n        ],\n        \"selectionSetGraphQL\": \"{\\n  id\\n  title\\n}\",\n        \"fieldName\": \"listTodos\",\n        \"variables\": {}\n    },\n    \"stash\": {}\n}\n</code></pre> <pre><code> {\n    \"arguments\": {\n      \"title\": \"Sample todo mutation\"\n    },\n    \"identity\": null,\n    \"source\": null,\n    \"request\": {\n      \"headers\": {\n        \"x-forwarded-for\": \"203.0.113.1, 203.0.113.18\",\n        \"cloudfront-viewer-country\": \"NL\",\n        \"cloudfront-is-tablet-viewer\": \"false\",\n        \"x-amzn-requestid\": \"fdc4f30b-44c2-475d-b2f9-9da0778d5275\",\n        \"via\": \"2.0 f655cacd0d6f7c5dc935ea687af6f3c0.cloudfront.net (CloudFront)\",\n        \"cloudfront-forwarded-proto\": \"https\",\n        \"origin\": \"https://eu-west-1.console.aws.amazon.com\",\n        \"content-length\": \"166\",\n        \"x-forwarded-proto\": \"https\",\n        \"accept-language\": \"en-US,en;q=0.5\",\n        \"host\": \"kiuqayvn4jhhzio6whpnk7xj3a.appsync-api.eu-west-1.amazonaws.com\",\n        \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:102.0) Gecko/20100101 Firefox/102.0\",\n        \"cloudfront-is-mobile-viewer\": \"false\",\n        \"accept\": \"application/json, text/plain, */*\",\n        \"cloudfront-viewer-asn\": \"1136\",\n        \"cloudfront-is-smarttv-viewer\": \"false\",\n        \"accept-encoding\": \"gzip, deflate, br\",\n        \"referer\": \"https://eu-west-1.console.aws.amazon.com/\",\n        \"content-type\": \"application/json\",\n        \"x-api-key\": \"da2-vsqnxwyzgzf4nh6kvoaidtvs7y\",\n        \"sec-fetch-mode\": \"cors\",\n        \"x-amz-cf-id\": \"0kxqijFPsbGSWJ1u3Z_sUS4Wu2hRoG_2T77aJPuoh_Q4bXAB3x0a3g==\",\n        \"x-amzn-trace-id\": \"Root=1-63fef2cf-6d566e9f4a35b99e6212388e\",\n        \"sec-fetch-dest\": \"empty\",\n        \"x-amz-user-agent\": \"AWS-Console-AppSync/\",\n        \"cloudfront-is-desktop-viewer\": \"true\",\n        \"sec-fetch-site\": \"cross-site\",\n        \"x-forwarded-port\": \"443\"\n      },\n      \"domainName\": null\n    },\n    \"prev\": null,\n    \"info\": {\n      \"selectionSetList\": [\n        \"id\",\n        \"title\",\n        \"completed\"\n      ],\n      \"selectionSetGraphQL\": \"{\\n  id\\n  title\\n  completed\\n}\",\n      \"fieldName\": \"createTodo\",\n      \"parentTypeName\": \"Mutation\",\n      \"variables\": {}\n    },\n    \"stash\": {}\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#scalar-functions",
            "title": "Scalar functions",
            "text": "<p>When working with AWS AppSync Scalar types, you might want to generate the same values for data validation purposes.</p> <p>For convenience, the most commonly used values are available as functions within <code>scalar_types_utils</code> module.</p> Creating key scalar values with scalar_types_utils<pre><code>from aws_lambda_powertools.utilities.data_classes.appsync.scalar_types_utils import (\n    aws_date,\n    aws_datetime,\n    aws_time,\n    aws_timestamp,\n    make_id,\n)\n\n# Scalars: https://docs.aws.amazon.com/appsync/latest/devguide/scalars.html\n\nmy_id: str = make_id()  # Scalar: ID!\nmy_date: str = aws_date()  # Scalar: AWSDate\nmy_timestamp: str = aws_time()  # Scalar: AWSTime\nmy_datetime: str = aws_datetime()  # Scalar: AWSDateTime\nmy_epoch_timestamp: int = aws_timestamp()  # Scalar: AWSTimestamp\n</code></pre> <p>Here's a table with their related scalar as a quick reference:</p> Scalar type Scalar function Sample value ID <code>scalar_types_utils.make_id</code> <code>e916c84d-48b6-484c-bef3-cee3e4d86ebf</code> AWSDate <code>scalar_types_utils.aws_date</code> <code>2022-07-08Z</code> AWSTime <code>scalar_types_utils.aws_time</code> <code>15:11:00.189Z</code> AWSDateTime <code>scalar_types_utils.aws_datetime</code> <code>2022-07-08T15:11:00.189Z</code> AWSTimestamp <code>scalar_types_utils.aws_timestamp</code> <code>1657293060</code>"
        },
        {
            "location": "core/event_handler/appsync/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/event_handler/appsync/#nested-mappings",
            "title": "Nested mappings",
            "text": "Note <p>The following examples use a more advanced schema. These schemas differ from initial sample infrastructure we used earlier.</p> <p>You can nest <code>app.resolver()</code> decorator multiple times when resolving fields with the same return value.</p> nested_mappings.pynested_mappings_schema.graphql <pre><code>from typing import List, TypedDict\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\n\n\nclass Location(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    address: str\n\n\n@app.resolver(field_name=\"listLocations\")\n@app.resolver(field_name=\"locations\")\n@tracer.capture_method\ndef get_locations(name: str, description: str = \"\") -&gt; List[Location]:  # match GraphQL Query arguments\n    return [{\"name\": name, \"description\": description}]\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>schema {\n    query: Query\n}\n\ntype Query {\n    listLocations: [Location]\n}\n\ntype Location {\n    id: ID!\n    name: String!\n    description: String\n    address: String\n}\n\ntype Merchant {\n    id: String!\n    name: String!\n    description: String\n    locations: [Location]\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#async-functions",
            "title": "Async functions",
            "text": "<p>For Lambda Python3.8+ runtime, this utility supports async functions when you use in conjunction with <code>asyncio.run</code>.</p> Resolving GraphQL resolvers async<pre><code>import asyncio\nfrom typing import List, TypedDict\n\nimport aiohttp\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.tracing import aiohttp_trace_config\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\n\n\nclass Todo(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    userId: str\n    title: str\n    completed: bool\n\n\n@app.resolver(type_name=\"Query\", field_name=\"listTodos\")\nasync def list_todos() -&gt; List[Todo]:\n    async with aiohttp.ClientSession(trace_configs=[aiohttp_trace_config()]) as session:\n        async with session.get(\"https://jsonplaceholder.typicode.com/todos\") as resp:\n            return await resp.json()\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    result = app.resolve(event, context)\n\n    return asyncio.run(result)\n</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#amplify-graphql-transformer",
            "title": "Amplify GraphQL Transformer",
            "text": "<p>Assuming you have Amplify CLI installed, create a new API using <code>amplify add api</code> and use the following GraphQL Schema.</p> Example GraphQL Schema<pre><code>@model\ntype Merchant {\n    id: String!\n    name: String!\n    description: String\n    # Resolves to `common_field`\n    commonField: String  @function(name: \"merchantInfo-${env}\")\n}\n\ntype Location {\n    id: ID!\n    name: String!\n    address: String\n    # Resolves to `common_field`\n    commonField: String  @function(name: \"merchantInfo-${env}\")\n}\n\ntype Query {\n  # List of locations resolves to `list_locations`\n  listLocations(page: Int, size: Int): [Location] @function(name: \"merchantInfo-${env}\")\n  # List of locations resolves to `list_locations`\n  findMerchant(search: str): [Merchant] @function(name: \"searchMerchant-${env}\")\n}\n</code></pre> <p>Create two new basic Python functions via <code>amplify add function</code>.</p> Note <p>Amplify CLI generated functions use <code>Pipenv</code> as a dependency manager. Your function source code is located at <code>amplify/backend/function/your-function-name</code>.</p> <p>Within your function's folder, add Powertools for AWS Lambda (Python) as a dependency with <code>pipenv install aws-lambda-powertools</code>.</p> <p>Use the following code for <code>merchantInfo</code> and <code>searchMerchant</code> functions respectively.</p> graphql_transformer_merchant_info.pygraphql_transformer_search_merchant.pygraphql_transformer_list_locations.jsongraphql_transformer_common_field.jsongraphql_transformer_find_merchant.json <pre><code>from typing import List, TypedDict\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.data_classes.appsync import scalar_types_utils\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\n\n\nclass Location(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    address: str\n    commonField: str\n\n\n@app.resolver(type_name=\"Query\", field_name=\"listLocations\")\ndef list_locations(page: int = 0, size: int = 10) -&gt; List[Location]:\n    return [{\"id\": scalar_types_utils.make_id(), \"name\": \"Smooth Grooves\"}]\n\n\n@app.resolver(field_name=\"commonField\")\ndef common_field() -&gt; str:\n    # Would match all fieldNames matching 'commonField'\n    return scalar_types_utils.make_id()\n\n\n@tracer.capture_lambda_handler\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>from typing import List, TypedDict\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.data_classes.appsync import scalar_types_utils\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = AppSyncResolver()\ntracer = Tracer()\nlogger = Logger()\n\n\nclass Merchant(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    commonField: str\n\n\n@app.resolver(type_name=\"Query\", field_name=\"findMerchant\")\ndef find_merchant(search: str) -&gt; List[Merchant]:\n    merchants: List[Merchant] = [\n        {\n            \"id\": scalar_types_utils.make_id(),\n            \"name\": \"Parry-Wood\",\n            \"description\": \"Possimus doloremque tempora harum deleniti eum.\",\n        },\n        {\n            \"id\": scalar_types_utils.make_id(),\n            \"name\": \"Shaw, Owen and Jones\",\n            \"description\": \"Aliquam iste architecto suscipit in.\",\n        },\n    ]\n\n    return [merchant for merchant in merchants if search == merchant[\"name\"]]\n\n\n@tracer.capture_lambda_handler\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"typeName\": \"Query\",\n    \"fieldName\": \"listLocations\",\n    \"arguments\": {\n        \"page\": 2,\n        \"size\": 1\n    },\n    \"identity\": {\n        \"claims\": {\n            \"iat\": 1615366261\n        },\n        \"username\": \"treid\"\n    },\n    \"request\": {\n        \"headers\": {\n            \"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n            \"x-forwarded-for\": \"127.0.0.1\",\n            \"cloudfront-viewer-country\": \"NL\",\n            \"x-api-key\": \"da1-c33ullkbkze3jg5hf5ddgcs4fq\"\n        }\n    }\n}\n</code></pre> <pre><code>{\n    \"typeName\": \"Merchant\",\n    \"fieldName\": \"commonField\",\n    \"arguments\": {},\n    \"identity\": {\n        \"claims\": {\n            \"iat\": 1615366261\n        },\n        \"username\": \"marieellis\"\n    },\n    \"request\": {\n        \"headers\": {\n            \"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n            \"x-forwarded-for\": \"127.0.0.1\"\n        }\n    },\n}\n</code></pre> <pre><code>{\n    \"typeName\": \"Query\",\n    \"fieldName\": \"findMerchant\",\n    \"arguments\": {\n        \"search\": \"Parry-Wood\"\n    },\n    \"identity\": {\n        \"claims\": {\n            \"iat\": 1615366261\n        },\n        \"username\": \"wwilliams\"\n    },\n    \"request\": {\n        \"headers\": {\n            \"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n            \"x-forwarded-for\": \"127.0.0.1\"\n        }\n    },\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#custom-data-models",
            "title": "Custom data models",
            "text": "<p>You can subclass AppSyncResolverEvent to bring your own set of methods to handle incoming events, by using <code>data_model</code> param in the <code>resolve</code> method.</p> custom_models.py.pynested_mappings_schema.graphqlgraphql_transformer_list_locations.json <pre><code>from typing import List, TypedDict\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.data_classes.appsync import scalar_types_utils\nfrom aws_lambda_powertools.utilities.data_classes.appsync_resolver_event import (\n    AppSyncResolverEvent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\n\n\nclass Location(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    address: str\n    commonField: str\n\n\nclass MyCustomModel(AppSyncResolverEvent):\n    @property\n    def country_viewer(self) -&gt; str:\n        return self.request_headers.get(\"cloudfront-viewer-country\", \"\")\n\n    @property\n    def api_key(self) -&gt; str:\n        return self.request_headers.get(\"x-api-key\", \"\")\n\n\n@app.resolver(type_name=\"Query\", field_name=\"listLocations\")\ndef list_locations(page: int = 0, size: int = 10) -&gt; List[Location]:\n    # additional properties/methods will now be available under current_event\n    if app.current_event:\n        logger.debug(f\"Request country origin: {app.current_event.country_viewer}\")  # type: ignore[attr-defined]\n    return [{\"id\": scalar_types_utils.make_id(), \"name\": \"Perry, James and Carroll\"}]\n\n\n@tracer.capture_lambda_handler\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context, data_model=MyCustomModel)\n</code></pre> <pre><code>schema {\n    query: Query\n}\n\ntype Query {\n    listLocations: [Location]\n}\n\ntype Location {\n    id: ID!\n    name: String!\n    description: String\n    address: String\n}\n\ntype Merchant {\n    id: String!\n    name: String!\n    description: String\n    locations: [Location]\n}\n</code></pre> <pre><code> {\n     \"typeName\": \"Query\",\n     \"fieldName\": \"listLocations\",\n     \"arguments\": {\n         \"page\": 2,\n         \"size\": 1\n     },\n     \"identity\": {\n         \"claims\": {\n             \"iat\": 1615366261\n         },\n         \"username\": \"treid\"\n     },\n     \"request\": {\n         \"headers\": {\n             \"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n             \"x-forwarded-for\": \"127.0.0.1\",\n             \"cloudfront-viewer-country\": \"NL\",\n             \"x-api-key\": \"da1-c33ullkbkze3jg5hf5ddgcs4fq\"\n         }\n     }\n }\n</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#split-operations-with-router",
            "title": "Split operations with Router",
            "text": "Tip <p>Read the considerations section for trade-offs between monolithic and micro functions, as it's also applicable here.</p> <p>As you grow the number of related GraphQL operations a given Lambda function should handle, it is natural to split them into separate files to ease maintenance - That's when the <code>Router</code> feature comes handy.</p> <p>Let's assume you have <code>split_operation.py</code> as your Lambda function entrypoint and routes in <code>split_operation_module.py</code>. This is how you'd use the <code>Router</code> feature.</p> split_operation_module.pysplit_operation.py <p>We import Router instead of AppSyncResolver; syntax wise is exactly the same.</p> <pre><code>from typing import List, TypedDict\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler.graphql_appsync.router import Router\n\ntracer = Tracer()\nlogger = Logger()\nrouter = Router()\n\n\nclass Location(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    address: str\n\n\n@router.resolver(field_name=\"listLocations\")\n@router.resolver(field_name=\"locations\")\n@tracer.capture_method\ndef get_locations(name: str, description: str = \"\") -&gt; List[Location]:  # match GraphQL Query arguments\n    return [{\"name\": name, \"description\": description}]\n</code></pre> <p>We use <code>include_router</code> method and include all <code>location</code> operations registered in the <code>router</code> global object.</p> <pre><code>import split_operation_module\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\napp.include_router(split_operation_module.router)\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#sharing-contextual-data",
            "title": "Sharing contextual data",
            "text": "<p>You can use <code>append_context</code> when you want to share data between your App and Router instances. Any data you share will be available via the <code>context</code> dictionary available in your App or Router context.</p> Warning <p>For safety, we clear the context after each invocation, except for async single resolvers. For these, use <code>app.context.clear()</code> before returning the function.</p> Tip <p>This can also be useful for middlewares injecting contextual information before a request is processed.</p> split_route_append_context.pysplit_route_append_context_module.py <pre><code>import split_operation_append_context_module\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\napp.include_router(split_operation_append_context_module.router)\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    app.append_context(is_admin=True)  # arbitrary number of key=value data\n    return app.resolve(event, context)\n</code></pre> <pre><code>from typing import List, TypedDict\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler.appsync import Router\n\ntracer = Tracer()\nlogger = Logger()\nrouter = Router()\n\n\nclass Location(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    address: str\n\n\n@router.resolver(field_name=\"listLocations\")\n@router.resolver(field_name=\"locations\")\n@tracer.capture_method\ndef get_locations(name: str, description: str = \"\") -&gt; List[Location]:  # match GraphQL Query arguments\n    is_admin: bool = router.context.get(\"is_admin\", False)\n    return [{\"name\": name, \"description\": description}] if is_admin else []\n</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#exception-handling",
            "title": "Exception handling",
            "text": "<p>You can use <code>exception_handler</code> decorator with any Python exception. This allows you to handle a common exception outside your resolver, for example validation errors.</p> <p>The <code>exception_handler</code> function also supports passing a list of exception types you wish to handle with one handler.</p> Exception handling<pre><code>from aws_lambda_powertools.event_handler import AppSyncResolver\n\napp = AppSyncResolver()\n\n\n@app.exception_handler(ValueError)\ndef handle_value_error(ex: ValueError):\n    return {\"message\": \"error\"}\n\n\n@app.resolver(field_name=\"createSomething\")\ndef create_something():\n    raise ValueError(\"Raising an exception\")\n\n\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> Warning <p>This is not supported when using async single resolvers.</p>"
        },
        {
            "location": "core/event_handler/appsync/#batch-processing",
            "title": "Batch processing",
            "text": "<pre><code>stateDiagram-v2\n    direction LR\n    LambdaInit: Lambda invocation\n    EventHandler: Event Handler\n    EventHandlerResolver: Route event based on GraphQL type/field keys\n    Client: Client query (listPosts)\n    YourLogic: Run your registered resolver function\n    EventHandlerResolverBuilder: Verifies response is a list\n    AppSyncBatchPostsResolution: query listPosts\n    AppSyncBatchPostsItems: get all posts data &lt;em&gt;(id, title, relatedPosts)&lt;/em&gt;\n    AppSyncBatchRelatedPosts: get related posts &lt;em&gt;(id, title, relatedPosts)&lt;/em&gt;\n    AppSyncBatchAggregate: aggregate batch resolver event\n    AppSyncBatchLimit: reached batch size limit\n    LambdaResponse: Lambda response\n\n    Client --&gt; AppSyncBatchResolverMode\n    state AppSyncBatchResolverMode {\n        [*] --&gt; AppSyncBatchPostsResolution\n        AppSyncBatchPostsResolution --&gt; AppSyncBatchPostsItems\n        AppSyncBatchPostsItems --&gt; AppSyncBatchRelatedPosts: &lt;strong&gt;N additional queries&lt;/strong&gt;\n        AppSyncBatchRelatedPosts --&gt; AppSyncBatchRelatedPosts\n        AppSyncBatchRelatedPosts --&gt; AppSyncBatchAggregate\n        AppSyncBatchRelatedPosts --&gt; AppSyncBatchAggregate\n        AppSyncBatchRelatedPosts --&gt; AppSyncBatchAggregate\n        AppSyncBatchAggregate --&gt; AppSyncBatchLimit\n    }\n\n    AppSyncBatchResolverMode --&gt; LambdaInit: 1x Invoke with N events\n    LambdaInit --&gt; EventHandler\n\n    state EventHandler {\n        [*] --&gt; EventHandlerResolver: app.resolve(event, context)\n        EventHandlerResolver --&gt; YourLogic\n        YourLogic --&gt; EventHandlerResolverBuilder\n        EventHandlerResolverBuilder --&gt; LambdaResponse\n    }</code></pre> <p>Batch resolvers mechanics: visualizing N+1 in <code>relatedPosts</code> field.</p>"
        },
        {
            "location": "core/event_handler/appsync/#understanding-n1-problem",
            "title": "Understanding N+1 problem",
            "text": "<p>When AWS AppSync has batching enabled for Lambda Resolvers, it will group as many requests as possible before invoking your Lambda invocation. Effectively solving the N+1 problem in GraphQL.</p> <p>For example, say you have a query named <code>listPosts</code>. For each post, you also want <code>relatedPosts</code>. Without batching, AppSync will:</p> <ol> <li>Invoke your Lambda function to get the first post</li> <li>Invoke your Lambda function for each related post</li> <li>Repeat 1 until done</li> </ol> <pre><code>sequenceDiagram\n    participant Client\n    participant AppSync\n    participant Lambda\n    participant Database\n\n    Client-&gt;&gt;AppSync: GraphQL Query\n    Note over Client,AppSync: query listPosts { &lt;br/&gt;id &lt;br/&gt;title &lt;br/&gt;relatedPosts { id title } &lt;br/&gt; }\n\n    AppSync-&gt;&gt;Lambda: Fetch N posts (listPosts)\n    Lambda-&gt;&gt;Database: Query\n    Database-&gt;&gt;Lambda: Posts\n    Lambda--&gt;&gt;AppSync: Return posts (id, title)\n    loop Fetch N related posts (relatedPosts)\n        AppSync-&gt;&gt;Lambda: Invoke function (N times)\n        Lambda-&gt;&gt;Database: Query\n        Database--&gt;&gt;Lambda: Return related posts\n        Lambda--&gt;&gt;AppSync: Return related posts\n    end\n    AppSync--&gt;&gt;Client: Return posts and their related posts</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#batch-resolvers",
            "title": "Batch resolvers",
            "text": "<p>You can use <code>@batch_resolver</code> or <code>@async_batch_resolver</code> decorators to receive the entire batch of requests.</p> <p>In this mode, you must return results in the same order of your batch items, so AppSync can associate the results back to the client.</p> advanced_batch_resolver.pyadvanced_batch_resolver_payload.jsonadvanced_batch_query.graphql <pre><code>from __future__ import annotations\n\nfrom typing import Any\n\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.utilities.data_classes import AppSyncResolverEvent\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = AppSyncResolver()\n\n# mimic DB data for simplicity\nposts_related = {\n    \"1\": {\"title\": \"post1\"},\n    \"2\": {\"title\": \"post2\"},\n    \"3\": {\"title\": \"post3\"},\n}\n\n\ndef search_batch_posts(posts: list) -&gt; dict[str, Any]:\n    return {post_id: posts_related.get(post_id) for post_id in posts}\n\n\n@app.batch_resolver(type_name=\"Query\", field_name=\"relatedPosts\")\ndef related_posts(event: list[AppSyncResolverEvent]) -&gt; list[Any]:  # (1)!\n    # Extract all post_ids in order\n    post_ids: list = [record.source.get(\"post_id\") for record in event]  # (2)!\n\n    # Get unique post_ids while preserving order\n    unique_post_ids = list(dict.fromkeys(post_ids))\n\n    # Fetch posts in a single batch operation\n    fetched_posts = search_batch_posts(unique_post_ids)\n\n    # Return results in original order\n    return [fetched_posts.get(post_id) for post_id in post_ids]\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>The entire batch is sent to the resolver. You need to iterate through it to process all records.</li> <li>We use <code>post_id</code> as our unique identifier of the GraphQL request.</li> </ol> <pre><code>[\n   {\n      \"arguments\":{},\n      \"identity\":\"None\",\n      \"source\":{\n         \"post_id\":\"1\",\n         \"author\":\"Author1\"\n      },\n      \"prev\":\"None\",\n      \"info\":{\n         \"selectionSetList\":[\n            \"post_id\",\n            \"author\"\n         ],\n         \"selectionSetGraphQL\":\"{\\n  post_id\\n  author\\n}\",\n         \"fieldName\":\"relatedPosts\",\n         \"parentTypeName\":\"Post\",\n         \"variables\":{}\n      }\n   },\n   {\n      \"arguments\":{},\n      \"identity\":\"None\",\n      \"source\":{\n         \"post_id\":\"2\",\n         \"author\":\"Author2\"\n      },\n      \"prev\":\"None\",\n      \"info\":{\n         \"selectionSetList\":[\n            \"post_id\",\n            \"author\"\n         ],\n         \"selectionSetGraphQL\":\"{\\n  post_id\\n  author\\n}\",\n         \"fieldName\":\"relatedPosts\",\n         \"parentTypeName\":\"Post\",\n         \"variables\":{}\n      }\n   },\n   {\n      \"arguments\":{},\n      \"identity\":\"None\",\n      \"source\":{\n         \"post_id\":\"1\",\n         \"author\":\"Author1\"\n      },\n      \"prev\":\"None\",\n      \"info\":{\n         \"selectionSetList\":[\n            \"post_id\",\n            \"author\"\n         ],\n         \"selectionSetGraphQL\":\"{\\n  post_id\\n  author\\n}\",\n         \"fieldName\":\"relatedPosts\",\n         \"parentTypeName\":\"Post\",\n         \"variables\":{}\n      }\n   }\n]\n</code></pre> <pre><code>query MyQuery {\n  getPost(post_id: \"2\") {\n    relatedPosts {\n      post_id\n      author\n      relatedPosts {\n        post_id\n        author\n      }\n    }\n  }\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#processing-items-individually",
            "title": "Processing items individually",
            "text": "<pre><code>stateDiagram-v2\n    direction LR\n    LambdaInit: Lambda invocation\n    EventHandler: Event Handler\n    EventHandlerResolver: Route event based on GraphQL type/field keys\n    Client: Client query (listPosts)\n    YourLogic: Call your registered resolver function &lt;strong&gt;N times&lt;/strong&gt;\n    EventHandlerResolverErrorHandling: Gracefully &lt;strong&gt;handle errors&lt;/strong&gt; with null response\n    EventHandlerResolverBuilder: Aggregate responses to match batch size\n    AppSyncBatchPostsResolution: query listPosts\n    AppSyncBatchPostsItems: get all posts data &lt;em&gt;(id, title, relatedPosts)&lt;/em&gt;\n    AppSyncBatchRelatedPosts: get related posts &lt;em&gt;(id, title, relatedPosts)&lt;/em&gt;\n    AppSyncBatchAggregate: aggregate batch resolver event\n    AppSyncBatchLimit: reached batch size limit\n    LambdaResponse: Lambda response\n\n    Client --&gt; AppSyncBatchResolverMode\n    state AppSyncBatchResolverMode {\n        [*] --&gt; AppSyncBatchPostsResolution\n        AppSyncBatchPostsResolution --&gt; AppSyncBatchPostsItems\n        AppSyncBatchPostsItems --&gt; AppSyncBatchRelatedPosts: &lt;strong&gt;N additional queries&lt;/strong&gt;\n        AppSyncBatchRelatedPosts --&gt; AppSyncBatchRelatedPosts\n        AppSyncBatchRelatedPosts --&gt; AppSyncBatchAggregate\n        AppSyncBatchRelatedPosts --&gt; AppSyncBatchAggregate\n        AppSyncBatchRelatedPosts --&gt; AppSyncBatchAggregate\n        AppSyncBatchAggregate --&gt; AppSyncBatchLimit\n    }\n\n    AppSyncBatchResolverMode --&gt; LambdaInit: 1x Invoke with N events\n    LambdaInit --&gt; EventHandler\n\n    state EventHandler {\n        [*] --&gt; EventHandlerResolver: app.resolve(event, context)\n        EventHandlerResolver --&gt; YourLogic\n        YourLogic --&gt; EventHandlerResolverErrorHandling\n        EventHandlerResolverErrorHandling --&gt; EventHandlerResolverBuilder\n        EventHandlerResolverBuilder --&gt; LambdaResponse\n    }</code></pre> <p>Batch resolvers: reducing Lambda invokes but fetching data N times (similar to single resolver).</p> <p>In rare scenarios, you might want to process each item individually, trading ease of use for increased latency as you handle one batch item at a time.</p> <p>You can toggle <code>aggregate</code> parameter in <code>@batch_resolver</code> decorator for your resolver function to be called N times.</p> <p>This does not resolve the N+1 problem, but shifts it to the Lambda runtime.</p> <p>In this mode, we will:</p> <ol> <li>Aggregate each response we receive from your function in the exact order it receives</li> <li>Gracefully handle errors by adding <code>None</code> in the final response for each batch item that failed processing<ul> <li>You can customize <code>nul</code> or error responses back to the client in the AppSync resolver mapping templates</li> </ul> </li> </ol> advanced_batch_resolver_individual.pyadvanced_batch_resolver_payload.jsonadvanced_batch_query.graphql <pre><code>from typing import Any, Dict\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.utilities.data_classes import AppSyncResolverEvent\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\napp = AppSyncResolver()\n\n\nposts_related = {\n    \"1\": {\"title\": \"post1\"},\n    \"2\": {\"title\": \"post2\"},\n    \"3\": {\"title\": \"post3\"},\n}\n\n\n@app.batch_resolver(type_name=\"Query\", field_name=\"relatedPosts\", aggregate=False)  # (1)!\ndef related_posts(event: AppSyncResolverEvent, post_id: str = \"\") -&gt; Dict[str, Any]:\n    return posts_related[post_id]\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>You need to disable the aggregated event by using <code>aggregate</code> flag.     The resolver receives and processes each record one at a time.</li> </ol> <pre><code>[\n   {\n      \"arguments\":{},\n      \"identity\":\"None\",\n      \"source\":{\n         \"post_id\":\"1\",\n         \"author\":\"Author1\"\n      },\n      \"prev\":\"None\",\n      \"info\":{\n         \"selectionSetList\":[\n            \"post_id\",\n            \"author\"\n         ],\n         \"selectionSetGraphQL\":\"{\\n  post_id\\n  author\\n}\",\n         \"fieldName\":\"relatedPosts\",\n         \"parentTypeName\":\"Post\",\n         \"variables\":{}\n      }\n   },\n   {\n      \"arguments\":{},\n      \"identity\":\"None\",\n      \"source\":{\n         \"post_id\":\"2\",\n         \"author\":\"Author2\"\n      },\n      \"prev\":\"None\",\n      \"info\":{\n         \"selectionSetList\":[\n            \"post_id\",\n            \"author\"\n         ],\n         \"selectionSetGraphQL\":\"{\\n  post_id\\n  author\\n}\",\n         \"fieldName\":\"relatedPosts\",\n         \"parentTypeName\":\"Post\",\n         \"variables\":{}\n      }\n   },\n   {\n      \"arguments\":{},\n      \"identity\":\"None\",\n      \"source\":{\n         \"post_id\":\"1\",\n         \"author\":\"Author1\"\n      },\n      \"prev\":\"None\",\n      \"info\":{\n         \"selectionSetList\":[\n            \"post_id\",\n            \"author\"\n         ],\n         \"selectionSetGraphQL\":\"{\\n  post_id\\n  author\\n}\",\n         \"fieldName\":\"relatedPosts\",\n         \"parentTypeName\":\"Post\",\n         \"variables\":{}\n      }\n   }\n]\n</code></pre> <pre><code>query MyQuery {\n  getPost(post_id: \"2\") {\n    relatedPosts {\n      post_id\n      author\n      relatedPosts {\n        post_id\n        author\n      }\n    }\n  }\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#raise-on-error",
            "title": "Raise on error",
            "text": "<pre><code>stateDiagram-v2\n    direction LR\n    LambdaInit: Lambda invocation\n    EventHandler: Event Handler\n    EventHandlerResolver: Route event based on GraphQL type/field keys\n    Client: Client query (listPosts)\n    YourLogic: Call your registered resolver function &lt;strong&gt;N times&lt;/strong&gt;\n    EventHandlerResolverErrorHandling: &lt;strong&gt;Error?&lt;/strong&gt;\n    EventHandlerResolverHappyPath: &lt;strong&gt;No error?&lt;/strong&gt;\n    EventHandlerResolverUnhappyPath: Propagate any exception\n    EventHandlerResolverBuilder: Aggregate responses to match batch size\n    AppSyncBatchPostsResolution: query listPosts\n    AppSyncBatchPostsItems: get all posts data &lt;em&gt;(id, title, relatedPosts)&lt;/em&gt;\n    AppSyncBatchRelatedPosts: get related posts &lt;em&gt;(id, title, relatedPosts)&lt;/em&gt;\n    AppSyncBatchAggregate: aggregate batch resolver event\n    AppSyncBatchLimit: reached batch size limit\n    LambdaResponse: &lt;strong&gt;Lambda response&lt;/strong&gt;\n    LambdaErrorResponse: &lt;strong&gt;Lambda error&lt;/strong&gt;\n\n    Client --&gt; AppSyncBatchResolverMode\n    state AppSyncBatchResolverMode {\n        [*] --&gt; AppSyncBatchPostsResolution\n        AppSyncBatchPostsResolution --&gt; AppSyncBatchPostsItems\n        AppSyncBatchPostsItems --&gt; AppSyncBatchRelatedPosts: &lt;strong&gt;N additional queries&lt;/strong&gt;\n        AppSyncBatchRelatedPosts --&gt; AppSyncBatchRelatedPosts\n        AppSyncBatchRelatedPosts --&gt; AppSyncBatchAggregate\n        AppSyncBatchRelatedPosts --&gt; AppSyncBatchAggregate\n        AppSyncBatchRelatedPosts --&gt; AppSyncBatchAggregate\n        AppSyncBatchAggregate --&gt; AppSyncBatchLimit\n    }\n\n    AppSyncBatchResolverMode --&gt; LambdaInit: 1x Invoke with N events\n    LambdaInit --&gt; EventHandler\n\n    state EventHandler {\n        [*] --&gt; EventHandlerResolver: app.resolve(event, context)\n        EventHandlerResolver --&gt; YourLogic\n        YourLogic --&gt; EventHandlerResolverHappyPath\n        YourLogic --&gt; EventHandlerResolverErrorHandling\n        EventHandlerResolverHappyPath --&gt; EventHandlerResolverBuilder\n        EventHandlerResolverErrorHandling --&gt; EventHandlerResolverUnhappyPath\n        EventHandlerResolverUnhappyPath --&gt; LambdaErrorResponse\n\n        EventHandlerResolverBuilder --&gt; LambdaResponse\n    }</code></pre> <p>Batch resolvers: reducing Lambda invokes but fetching data N times (similar to single resolver).</p> <p>You can toggle <code>raise_on_error</code> parameter in <code>@batch_resolver</code> to propagate any exception instead of gracefully returning <code>None</code> for a given batch item.</p> <p>This is useful when you want to stop processing immediately in the event of an unhandled or unrecoverable exception.</p> advanced_batch_resolver_handling_error.pyadvanced_batch_resolver_payload.jsonadvanced_batch_query.graphql <pre><code>from typing import Any, Dict\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.utilities.data_classes import AppSyncResolverEvent\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\napp = AppSyncResolver()\n\n\nposts_related = {\n    \"1\": {\"title\": \"post1\"},\n    \"2\": {\"title\": \"post2\"},\n    \"3\": {\"title\": \"post3\"},\n}\n\n\n@app.batch_resolver(type_name=\"Query\", field_name=\"relatedPosts\", aggregate=False, raise_on_error=True)  # (1)!\ndef related_posts(event: AppSyncResolverEvent, post_id: str = \"\") -&gt; Dict[str, Any]:\n    return posts_related[post_id]\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>You can enable enable the error handling by using <code>raise_on_error</code> flag.</li> </ol> <pre><code>[\n   {\n      \"arguments\":{},\n      \"identity\":\"None\",\n      \"source\":{\n         \"post_id\":\"1\",\n         \"author\":\"Author1\"\n      },\n      \"prev\":\"None\",\n      \"info\":{\n         \"selectionSetList\":[\n            \"post_id\",\n            \"author\"\n         ],\n         \"selectionSetGraphQL\":\"{\\n  post_id\\n  author\\n}\",\n         \"fieldName\":\"relatedPosts\",\n         \"parentTypeName\":\"Post\",\n         \"variables\":{}\n      }\n   },\n   {\n      \"arguments\":{},\n      \"identity\":\"None\",\n      \"source\":{\n         \"post_id\":\"2\",\n         \"author\":\"Author2\"\n      },\n      \"prev\":\"None\",\n      \"info\":{\n         \"selectionSetList\":[\n            \"post_id\",\n            \"author\"\n         ],\n         \"selectionSetGraphQL\":\"{\\n  post_id\\n  author\\n}\",\n         \"fieldName\":\"relatedPosts\",\n         \"parentTypeName\":\"Post\",\n         \"variables\":{}\n      }\n   },\n   {\n      \"arguments\":{},\n      \"identity\":\"None\",\n      \"source\":{\n         \"post_id\":\"1\",\n         \"author\":\"Author1\"\n      },\n      \"prev\":\"None\",\n      \"info\":{\n         \"selectionSetList\":[\n            \"post_id\",\n            \"author\"\n         ],\n         \"selectionSetGraphQL\":\"{\\n  post_id\\n  author\\n}\",\n         \"fieldName\":\"relatedPosts\",\n         \"parentTypeName\":\"Post\",\n         \"variables\":{}\n      }\n   }\n]\n</code></pre> <pre><code>query MyQuery {\n  getPost(post_id: \"2\") {\n    relatedPosts {\n      post_id\n      author\n      relatedPosts {\n        post_id\n        author\n      }\n    }\n  }\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#async-batch-resolver",
            "title": "Async batch resolver",
            "text": "<p>Similar to <code>@batch_resolver</code> explained in batch resolvers, you can use <code>async_batch_resolver</code> to handle async functions.</p> advanced_batch_async_resolver.pyadvanced_batch_resolver_payload.jsonadvanced_batch_query.graphql <pre><code>from __future__ import annotations\n\nfrom typing import Any\n\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.utilities.data_classes import AppSyncResolverEvent\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = AppSyncResolver()\n\n# mimic DB data for simplicity\nposts_related = {\n    \"1\": {\"title\": \"post1\"},\n    \"2\": {\"title\": \"post2\"},\n    \"3\": {\"title\": \"post3\"},\n}\n\n\nasync def search_batch_posts(posts: list) -&gt; dict[str, Any]:\n    return {post_id: posts_related.get(post_id) for post_id in posts}\n\n\n@app.async_batch_resolver(type_name=\"Query\", field_name=\"relatedPosts\")\nasync def related_posts(event: list[AppSyncResolverEvent]) -&gt; list[Any]:\n    # Extract all post_ids in order\n    post_ids: list = [record.source.get(\"post_id\") for record in event]\n\n    # Get unique post_ids while preserving order\n    unique_post_ids = list(dict.fromkeys(post_ids))\n\n    # Fetch posts in a single batch operation\n    fetched_posts = await search_batch_posts(unique_post_ids)\n\n    # Return results in original order\n    return [fetched_posts.get(post_id) for post_id in post_ids]\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)  # (1)!\n</code></pre> <ol> <li><code>async_batch_resolver</code> takes care of running and waiting for coroutine completion.</li> </ol> <pre><code>[\n   {\n      \"arguments\":{},\n      \"identity\":\"None\",\n      \"source\":{\n         \"post_id\":\"1\",\n         \"author\":\"Author1\"\n      },\n      \"prev\":\"None\",\n      \"info\":{\n         \"selectionSetList\":[\n            \"post_id\",\n            \"author\"\n         ],\n         \"selectionSetGraphQL\":\"{\\n  post_id\\n  author\\n}\",\n         \"fieldName\":\"relatedPosts\",\n         \"parentTypeName\":\"Post\",\n         \"variables\":{}\n      }\n   },\n   {\n      \"arguments\":{},\n      \"identity\":\"None\",\n      \"source\":{\n         \"post_id\":\"2\",\n         \"author\":\"Author2\"\n      },\n      \"prev\":\"None\",\n      \"info\":{\n         \"selectionSetList\":[\n            \"post_id\",\n            \"author\"\n         ],\n         \"selectionSetGraphQL\":\"{\\n  post_id\\n  author\\n}\",\n         \"fieldName\":\"relatedPosts\",\n         \"parentTypeName\":\"Post\",\n         \"variables\":{}\n      }\n   },\n   {\n      \"arguments\":{},\n      \"identity\":\"None\",\n      \"source\":{\n         \"post_id\":\"1\",\n         \"author\":\"Author1\"\n      },\n      \"prev\":\"None\",\n      \"info\":{\n         \"selectionSetList\":[\n            \"post_id\",\n            \"author\"\n         ],\n         \"selectionSetGraphQL\":\"{\\n  post_id\\n  author\\n}\",\n         \"fieldName\":\"relatedPosts\",\n         \"parentTypeName\":\"Post\",\n         \"variables\":{}\n      }\n   }\n]\n</code></pre> <pre><code>query MyQuery {\n  getPost(post_id: \"2\") {\n    relatedPosts {\n      post_id\n      author\n      relatedPosts {\n        post_id\n        author\n      }\n    }\n  }\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/appsync/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>You can test your resolvers by passing a mocked or actual AppSync Lambda event that you're expecting.</p> <p>You can use either <code>app.resolve(event, context)</code> or simply <code>app(event, context)</code>.</p> <p>Here's an example of how you can test your synchronous resolvers:</p> assert_graphql_response.pyassert_graphql_response_module.pyassert_graphql_response.json <pre><code>from __future__ import annotations\n\nimport json\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\nimport pytest\nfrom assert_graphql_response_module import Location, app  # instance of AppSyncResolver\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n    aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef test_direct_resolver(lambda_context):\n    # GIVEN\n    fake_event = json.loads(Path(\"assert_graphql_response.json\").read_text())\n\n    # WHEN\n    result: list[Location] = app(fake_event, lambda_context)\n\n    # THEN\n    assert result[0][\"name\"] == \"Perkins-Reed\"\n</code></pre> <pre><code>from typing import List, TypedDict\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\n\n\nclass Location(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    name: str\n    description: str\n    address: str\n\n\n@app.resolver(field_name=\"listLocations\")\n@app.resolver(field_name=\"locations\")\n@tracer.capture_method\ndef get_locations(name: str, description: str = \"\") -&gt; List[Location]:  # match GraphQL Query arguments\n    return [{\"name\": name, \"description\": description}]\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"typeName\": \"Query\",\n    \"fieldName\": \"listLocations\",\n    \"arguments\": {\n        \"name\": \"Perkins-Reed\",\n        \"description\": \"Nulla sed amet. Earum libero qui sunt perspiciatis. Non aliquid accusamus.\"\n    },\n    \"selectionSetList\": [\n        \"id\",\n        \"name\"\n    ],\n    \"identity\": {\n        \"claims\": {\n            \"sub\": \"192879fc-a240-4bf1-ab5a-d6a00f3063f9\",\n            \"email_verified\": true,\n            \"iss\": \"https://cognito-idp.us-west-2.amazonaws.com/us-west-xxxxxxxxxxx\",\n            \"phone_number_verified\": false,\n            \"cognito:username\": \"jdoe\",\n            \"aud\": \"7471s60os7h0uu77i1tk27sp9n\",\n            \"event_id\": \"bc334ed8-a938-4474-b644-9547e304e606\",\n            \"token_use\": \"id\",\n            \"auth_time\": 1599154213,\n            \"phone_number\": \"+19999999999\",\n            \"exp\": 1599157813,\n            \"iat\": 1599154213,\n            \"email\": \"jdoe@email.com\"\n        },\n        \"defaultAuthStrategy\": \"ALLOW\",\n        \"groups\": null,\n        \"issuer\": \"https://cognito-idp.us-west-2.amazonaws.com/us-west-xxxxxxxxxxx\",\n        \"sourceIp\": [\n            \"1.1.1.1\"\n        ],\n        \"sub\": \"192879fc-a240-4bf1-ab5a-d6a00f3063f9\",\n        \"username\": \"jdoe\"\n    },\n    \"request\": {\n        \"headers\": {\n            \"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n            \"x-forwarded-for\": \"127.0.0.1\",\n            \"cloudfront-viewer-country\": \"NL\",\n            \"x-api-key\": \"da1-c33ullkbkze3jg5hf5ddgcs4fq\"\n        }\n    }\n}\n</code></pre> <p>And an example for testing asynchronous resolvers. Note that this requires the <code>pytest-asyncio</code> package. This tests a specific async GraphQL operation.</p> Note <p>Alternatively, you can continue call <code>lambda_handler</code> function synchronously as it'd run <code>asyncio.run</code> to await for the coroutine to complete.</p> assert_async_graphql_response.pyassert_async_graphql_response_module.pyassert_async_graphql_response.json <pre><code>import json\nfrom dataclasses import dataclass\nfrom pathlib import Path\nfrom typing import List\n\nimport pytest\nfrom assert_async_graphql_response_module import (  # instance of AppSyncResolver\n    Todo,\n    app,\n)\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n    aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\n@pytest.mark.asyncio\nasync def test_async_direct_resolver(lambda_context):\n    # GIVEN\n    fake_event = json.loads(Path(\"assert_async_graphql_response.json\").read_text())\n\n    # WHEN\n    result: List[Todo] = await app(fake_event, lambda_context)\n    # alternatively, you can also run a sync test against `lambda_handler`\n    # since `lambda_handler` awaits the coroutine to complete\n\n    # THEN\n    assert result[0][\"userId\"] == 1\n    assert result[0][\"id\"] == 1\n    assert result[0][\"completed\"] is False\n</code></pre> <pre><code>import asyncio\nfrom typing import List, TypedDict\n\nimport aiohttp\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import AppSyncResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.tracing import aiohttp_trace_config\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = AppSyncResolver()\n\n\nclass Todo(TypedDict, total=False):\n    id: str  # noqa AA03 VNE003, required due to GraphQL Schema\n    userId: str\n    title: str\n    completed: bool\n\n\n@app.resolver(type_name=\"Query\", field_name=\"listTodos\")\nasync def list_todos() -&gt; List[Todo]:\n    async with aiohttp.ClientSession(trace_configs=[aiohttp_trace_config()]) as session:\n        async with session.get(\"https://jsonplaceholder.typicode.com/todos\") as resp:\n            result: List[Todo] = await resp.json()\n            return result[:2]  # first two results to demo assertion\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_RESOLVER)\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    result = app.resolve(event, context)\n\n    return asyncio.run(result)\n</code></pre> <pre><code>{\n    \"typeName\": \"Query\",\n    \"fieldName\": \"listTodos\",\n    \"arguments\": {},\n    \"selectionSetList\": [\n        \"id\",\n        \"userId\",\n        \"completed\"\n    ],\n    \"identity\": {\n        \"claims\": {\n            \"sub\": \"192879fc-a240-4bf1-ab5a-d6a00f3063f9\",\n            \"email_verified\": true,\n            \"iss\": \"https://cognito-idp.us-west-2.amazonaws.com/us-west-xxxxxxxxxxx\",\n            \"phone_number_verified\": false,\n            \"cognito:username\": \"jdoe\",\n            \"aud\": \"7471s60os7h0uu77i1tk27sp9n\",\n            \"event_id\": \"bc334ed8-a938-4474-b644-9547e304e606\",\n            \"token_use\": \"id\",\n            \"auth_time\": 1599154213,\n            \"phone_number\": \"+19999999999\",\n            \"exp\": 1599157813,\n            \"iat\": 1599154213,\n            \"email\": \"jdoe@email.com\"\n        },\n        \"defaultAuthStrategy\": \"ALLOW\",\n        \"groups\": null,\n        \"issuer\": \"https://cognito-idp.us-west-2.amazonaws.com/us-west-xxxxxxxxxxx\",\n        \"sourceIp\": [\n            \"1.1.1.1\"\n        ],\n        \"sub\": \"192879fc-a240-4bf1-ab5a-d6a00f3063f9\",\n        \"username\": \"jdoe\"\n    },\n    \"request\": {\n        \"headers\": {\n            \"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n            \"x-forwarded-for\": \"127.0.0.1\",\n            \"cloudfront-viewer-country\": \"NL\",\n            \"x-api-key\": \"da1-c33ullkbkze3jg5hf5ddgcs4fq\"\n        }\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/bedrock_agents/",
            "title": "Agents for Amazon Bedrock",
            "text": "<p>Create Agents for Amazon Bedrock using event handlers and auto generation of OpenAPI schemas.</p> <p> <pre><code>flowchart LR\n    Bedrock[LLM] &lt;-- uses --&gt; Agent\n    You[User input] --&gt; Agent\n    Agent -- consults --&gt; OpenAPI\n    Agent[Agents for Amazon Bedrock] -- invokes --&gt; Lambda\n\n    subgraph OpenAPI\n        Schema\n    end\n\n    subgraph Lambda[Lambda Function]\n        direction TB\n        Parsing[Parameter Parsing] --&gt; Validation\n        Validation[Parameter Validation] --&gt; Routing\n        Routing --&gt; Code[Your code]\n        Code --&gt; ResponseValidation[Response Validation]\n        ResponseValidation --&gt; ResponseBuilding[Response Building]\n    end\n\n    subgraph ActionGroup[Action Group]\n        OpenAPI -. generated from .-&gt; Lambda\n    end\n\n    style Code fill:#ffa500,color:black,font-weight:bold,stroke-width:3px\n    style You stroke:#0F0,stroke-width:2px\n\n\n\n</code></pre> </p>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Minimal boilerplate to build Agents for Amazon Bedrock</li> <li>Automatic generation of OpenAPI schemas from your business logic code</li> <li>Built-in data validation for requests and responses</li> <li>Similar experience to authoring REST and HTTP APIs</li> </ul>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#terminology",
            "title": "Terminology",
            "text": "<p>Data validation automatically validates the user input and the response of your AWS Lambda function against a set of constraints defined by you.</p> <p>Event handler is a Powertools for AWS feature that processes an event, runs data parsing and validation, routes the request to a specific function, and returns a response to the caller in the proper format.</p> <p>OpenAPI schema is an industry standard JSON-serialized string that represents the structure and parameters of your API.</p> <p>Action group is a collection of two resources where you define the actions that the agent should carry out: an OpenAPI schema to define the APIs that the agent can invoke to carry out its tasks, and a Lambda function to execute those actions.</p> <p>Large Language Models (LLM) are very large deep learning models that are pre-trained on vast amounts of data, capable of extracting meanings from a sequence of text and understanding the relationship between words and phrases on it.</p> <p>Agent for Amazon Bedrock is an Amazon Bedrock feature to build and deploy conversational agents that can interact with your customers using Large Language Models (LLM) and AWS Lambda functions.</p>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#getting-started",
            "title": "Getting started",
            "text": "<p>All examples shared in this documentation are available within the project repository</p>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#install",
            "title": "Install",
            "text": "<p>This is unnecessary if you're installing Powertools for AWS Lambda (Python) via Lambda Layer/SAR.</p> <p>You need to add <code>pydantic</code> as a dependency in your preferred tool e.g., requirements.txt, pyproject.toml. At this time, we only support Pydantic V1, due to an incompatibility with Pydantic V2 generated schemas and the Agents' API.</p>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#required-resources",
            "title": "Required resources",
            "text": "<p>To build Agents for Amazon Bedrock, you will need:</p> Requirement Description SAM Supported CDK Supported Lambda Function Defines your business logic for the action group ✅ ✅ OpenAPI Schema API description, structure, and action group parameters ❌ ✅ Bedrock Service Role Allows Amazon Bedrock to invoke foundation models ✅ ✅ Agents for Bedrock The service that will combine all the above to create the conversational agent ❌ ✅ Using AWS Serverless Application Model (SAM)Using AWS Cloud Developer Kit (CDK) <p>Using AWS SAM you can create your Lambda function and the necessary permissions. However, you still have to create your Agent for Amazon Bedrock using the AWS console.</p> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: &gt;\n  Agents for Amazon Bedrock example with Powertools for AWS Lambda (Python)\n\nGlobals: # https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-specification-template-anatomy-globals.html\n  Function:\n    Timeout: 30\n    Runtime: python3.12\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: PowertoolsHelloWorld\n        POWERTOOLS_LOG_LEVEL: INFO\n\nResources:\n  ApiFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: getting_started.lambda_handler\n      Description: Agent for Amazon Bedrock handler function\n      CodeUri: ../src\n\n\n  BedrockPermission: # (1)!\n    Type: AWS::Lambda::Permission\n    Properties:\n      Action: lambda:InvokeFunction\n      FunctionName: !GetAtt ApiFunction.Arn\n      Principal: bedrock.amazonaws.com\n      SourceAccount: !Sub ${AWS::AccountId}\n\n  BedrockServiceRole:\n    Type: AWS::IAM::Role\n    Properties:\n      AssumeRolePolicyDocument:\n        Version: \"2012-10-17\"\n        Statement:\n          - Effect: Allow\n            Principal:\n              Action:\n                - sts:assumeRole\n              Service:\n                - bedrock.amazonaws.com\n      Policies:\n        - PolicyName: bedrock\n          PolicyDocument:\n            Version: \"2012-10-17\"\n            Statement:\n              - Effect: Allow\n                Action:\n                  - bedrock:InvokeModel\n                Resource: # (2)!\n                  - !Sub arn:aws:${AWS::Region}:region::foundation-model/anthropic.claude-v2\n                  - !Sub arn:aws:${AWS::Region}:region::foundation-model/anthropic.claude-v2:1\n                  - !Sub arn:aws:${AWS::Region}:region::foundation-model/anthropic.claude-instant-v1\n\nOutputs:\n  BedrockServiceRole:\n    Description: The role ARN to be used by Amazon Bedrock\n    Value: !GetAtt BedrockServiceRole.Arn  # (3)!\n</code></pre> <ol> <li>Amazon Bedrock needs permissions to invoke this Lambda function</li> <li>Check the supported foundational models</li> <li>You need the role ARN when creating the Agent for Amazon Bedrock</li> </ol> <p>This example uses the Generative AI CDK constructs to create your Agent with AWS CDK. These constructs abstract the underlying permission setup and code bundling of your Lambda function.</p> <pre><code>from aws_cdk import (\n    Stack,\n)\nfrom aws_cdk.aws_lambda import Runtime\nfrom aws_cdk.aws_lambda_python_alpha import PythonFunction\nfrom cdklabs.generative_ai_cdk_constructs import bedrock\nfrom constructs import Construct\n\n\nclass AgentsCdkStack(Stack):\n\n    def __init__(self, scope: Construct, construct_id: str, **kwargs) -&gt; None:\n        super().__init__(scope, construct_id, **kwargs)\n\n        action_group_function = PythonFunction(\n            self,\n            \"LambdaFunction\",\n            runtime=Runtime.PYTHON_3_12,\n            entry=\"./lambda\",  # (1)!\n            index=\"app.py\",\n            handler=\"lambda_handler\",\n        )\n\n        agent = bedrock.Agent(\n            self,\n            \"Agent\",\n            foundation_model=bedrock.BedrockFoundationModel.ANTHROPIC_CLAUDE_INSTANT_V1_2,\n            instruction=\"You are a helpful and friendly agent that answers questions about insurance claims.\",\n        )\n\n        action_group: bedrock.AgentActionGroup = bedrock.AgentActionGroup(\n            name=\"InsureClaimsSupport\",\n            description=\"Use these functions for insurance claims support\",\n            executor=bedrock.ActionGroupExecutor.fromlambda_function(\n                lambda_function=action_group_function,\n            ),\n            enabled=True,\n            api_schema=bedrock.ApiSchema.from_local_asset(\"./lambda/openapi.json\"),  # (2)!\n        )\n        agent.add_action_group(action_group)\n</code></pre> <ol> <li>The path to your Lambda function handler</li> <li>The path to the OpenAPI schema describing your API</li> </ol>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#your-first-agent",
            "title": "Your first Agent",
            "text": "<p>To create an agent, use the <code>BedrockAgentResolver</code> to annotate your actions. This is similar to the way all the other Event Handler resolvers work.</p> <p>You are required to add a <code>description</code> parameter in each endpoint, doing so will improve Bedrock's understanding of your actions.</p> Lambda handlerOpenAPI schemaInput payloadOutput payload <p>The resolvers used by Agents for Amazon Bedrock are compatible with all Powertools for AWS Lambda features. For reference, we use Logger and Tracer in this example.</p> <pre><code>from time import time\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import BedrockAgentResolver\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = BedrockAgentResolver()\n\n\n@app.get(\"/current_time\", description=\"Gets the current time in seconds\")  # (1)!\n@tracer.capture_method\ndef current_time() -&gt; int:\n    return int(time())\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext):\n    return app.resolve(event, context)  # (2)!\n</code></pre> <ol> <li><code>description</code> is a required field that should contain a human readable description of your action</li> <li>We take care of parsing, validating, routing and responding to the request.</li> </ol> <p>Powertools for AWS Lambda generates this automatically from the Lambda handler.</p> <pre><code>{\n  \"openapi\": \"3.0.3\",\n  \"info\": {\n    \"title\": \"Powertools API\",\n    \"version\": \"1.0.0\"\n  },\n  \"servers\": [\n    {\n      \"url\": \"/\"\n    }\n  ],\n  \"paths\": {\n    \"/current_time\": {\n      \"get\": {\n        \"summary\": \"GET /current_time\",\n        \"description\": \"Gets the current time in seconds\",\n        \"operationId\": \"current_time_current_time_get\",\n        \"responses\": {\n          \"200\": {\n            \"description\": \"Successful Response\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"type\": \"integer\",\n                  \"title\": \"Return\"\n                }\n              }\n            }\n          },\n          \"422\": {\n            \"description\": \"Validation Error\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/HTTPValidationError\"\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  },\n  \"components\": {\n    \"schemas\": {\n      \"HTTPValidationError\": {\n        \"properties\": {\n          \"detail\": {\n            \"items\": {\n              \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"type\": \"array\",\n            \"title\": \"Detail\"\n          }\n        },\n        \"type\": \"object\",\n        \"title\": \"HTTPValidationError\"\n      },\n      \"ValidationError\": {\n        \"properties\": {\n          \"loc\": {\n            \"items\": {\n              \"anyOf\": [\n                {\n                  \"type\": \"string\"\n                },\n                {\n                  \"type\": \"integer\"\n                }\n              ]\n            },\n            \"type\": \"array\",\n            \"title\": \"Location\"\n          },\n          \"msg\": {\n            \"type\": \"string\",\n            \"title\": \"Message\"\n          },\n          \"type\": {\n            \"type\": \"string\",\n            \"title\": \"Error Type\"\n          }\n        },\n        \"type\": \"object\",\n        \"required\": [\n          \"loc\",\n          \"msg\",\n          \"type\"\n        ],\n        \"title\": \"ValidationError\"\n      }\n    }\n  }\n}\n</code></pre> <pre><code>{\n  \"sessionId\": \"123456789012345\",\n  \"sessionAttributes\": {},\n  \"inputText\": \"What is the current time?\",\n  \"promptSessionAttributes\": {},\n  \"apiPath\": \"/current_time\",\n  \"agent\": {\n    \"name\": \"TimeAgent\",\n    \"version\": \"DRAFT\",\n    \"id\": \"XLHH72XNF2\",\n    \"alias\": \"TSTALIASID\"\n  },\n  \"httpMethod\": \"GET\",\n  \"messageVersion\": \"1.0\",\n  \"actionGroup\": \"CurrentTime\"\n}\n</code></pre> <pre><code>{\n  \"messageVersion\": \"1.0\",\n  \"response\": {\n    \"actionGroup\": \"CurrentTime\",\n    \"apiPath\": \"/current_time\",\n    \"httpMethod\": \"GET\",\n    \"httpStatusCode\": 200,\n    \"responseBody\": {\n      \"application/json\": {\n        \"body\": \"1704708165\"\n      }\n    }\n  }\n}\n</code></pre> What happens under the hood? <p>Powertools will handle the request from the Agent, parse, validate, and route it to the correct method in your code. The response is then validated and formatted back to the Agent.</p> <p> <pre><code>sequenceDiagram\n    actor User\n\n    User-&gt;&gt;Agent: What is the current time?\n    Agent-&gt;&gt;OpenAPI schema: consults\n    OpenAPI schema--&gt;&gt;Agent: GET /current_time\n    Agent--&gt;&gt;Agent: LLM interaction\n\n    box Powertools\n        participant Lambda\n        participant Parsing\n        participant Validation\n        participant Routing\n        participant Your Code\n    end\n\n    Agent-&gt;&gt;Lambda: GET /current_time\n    activate Lambda\n    Lambda-&gt;&gt;Parsing: parses parameters\n    Parsing-&gt;&gt;Validation: validates input\n    Validation-&gt;&gt;Routing: finds method to call\n    Routing-&gt;&gt;Your Code: executes\n    activate Your Code\n    Your Code-&gt;&gt;Routing: 1709215709\n    deactivate Your Code\n    Routing-&gt;&gt;Validation: returns output\n    Validation-&gt;&gt;Parsing: validates output\n    Parsing-&gt;&gt;Lambda: formats response\n    Lambda-&gt;&gt;Agent: 1709215709\n    deactivate Lambda\n\n    Agent--&gt;&gt;Agent: LLM interaction\n    Agent-&gt;&gt;User: \"The current time is 14:08:29 GMT\"\n</code></pre> </p>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#validating-input-and-output",
            "title": "Validating input and output",
            "text": "<p>You can define the expected format for incoming data and responses by using type annotations. Define constraints using standard Python types, dataclasses or Pydantic models. Pydantic is a popular library for data validation using Python type annotations.</p> Lambda handlerOpenAPI schemaInput payloadOutput payload <p>This example uses Pydantic's EmailStr to validate the email address passed to the <code>schedule_meeting</code> function. The function then returns a boolean indicating if the meeting was successfully scheduled.</p> <pre><code>from pydantic import EmailStr\nfrom typing_extensions import Annotated\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import BedrockAgentResolver\nfrom aws_lambda_powertools.event_handler.openapi.params import Body, Query\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = BedrockAgentResolver()  # (1)!\n\n\n@app.get(\"/schedule_meeting\", description=\"Schedules a meeting with the team\")\n@tracer.capture_method\ndef schedule_meeting(\n    email: Annotated[EmailStr, Query(description=\"The email address of the customer\")],  # (2)!\n) -&gt; Annotated[bool, Body(description=\"Whether the meeting was scheduled successfully\")]:  # (3)!\n    logger.info(\"Scheduling a meeting\", email=email)\n    return True\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext):\n    return app.resolve(event, context)\n</code></pre> <ol> <li>No need to add the <code>enable_validation</code> parameter, as it's enabled by default.</li> <li>Describe each input using human-readable descriptions</li> <li>Add the typing annotations to your parameters and return types, and let the event handler take care of the rest</li> </ol> <pre><code>{\n  \"openapi\": \"3.0.3\",\n  \"info\": {\n    \"title\": \"Powertools API\",\n    \"version\": \"1.0.0\"\n  },\n  \"servers\": [\n    {\n      \"url\": \"/\"\n    }\n  ],\n  \"paths\": {\n    \"/schedule_meeting\": {\n      \"get\": {\n        \"summary\": \"GET /schedule_meeting\",\n        \"description\": \"Schedules a meeting with the team\",\n        \"operationId\": \"schedule_meeting_schedule_meeting_get\",\n        \"parameters\": [\n          {\n            \"description\": \"The email address of the customer\",\n            \"required\": true,\n            \"schema\": {\n              \"type\": \"string\",\n              \"format\": \"email\",\n              \"title\": \"Email\",\n              \"description\": \"The email address of the customer\"\n            },\n            \"name\": \"email\",\n            \"in\": \"query\"\n          }\n        ],\n        \"responses\": {\n          \"200\": {\n            \"description\": \"Successful Response\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"type\": \"boolean\",\n                  \"title\": \"Return\",\n                  \"description\": \"Whether the meeting was scheduled successfully\"\n                }\n              }\n            }\n          },\n          \"422\": {\n            \"description\": \"Validation Error\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/HTTPValidationError\"\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  },\n  \"components\": {\n    \"schemas\": {\n      \"HTTPValidationError\": {\n        \"properties\": {\n          \"detail\": {\n            \"items\": {\n              \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"type\": \"array\",\n            \"title\": \"Detail\"\n          }\n        },\n        \"type\": \"object\",\n        \"title\": \"HTTPValidationError\"\n      },\n      \"ValidationError\": {\n        \"properties\": {\n          \"loc\": {\n            \"items\": {\n              \"anyOf\": [\n                {\n                  \"type\": \"string\"\n                },\n                {\n                  \"type\": \"integer\"\n                }\n              ]\n            },\n            \"type\": \"array\",\n            \"title\": \"Location\"\n          },\n          \"msg\": {\n            \"type\": \"string\",\n            \"title\": \"Message\"\n          },\n          \"type\": {\n            \"type\": \"string\",\n            \"title\": \"Error Type\"\n          }\n        },\n        \"type\": \"object\",\n        \"required\": [\n          \"loc\",\n          \"msg\",\n          \"type\"\n        ],\n        \"title\": \"ValidationError\"\n      }\n    }\n  }\n}\n</code></pre> <pre><code>{\n  \"sessionId\": \"123456789012345\",\n  \"sessionAttributes\": {},\n  \"inputText\": \"Schedule a meeting with the team. My email is foo@example.org\",\n  \"promptSessionAttributes\": {},\n  \"apiPath\": \"/schedule_meeting\",\n  \"parameters\": [\n    {\n      \"name\": \"email\",\n      \"type\": \"string\",\n      \"value\": \"foo@example.org\"\n    }\n  ],\n  \"agent\": {\n    \"name\": \"TimeAgent\",\n    \"version\": \"DRAFT\",\n    \"id\": \"XLHH72XNF2\",\n    \"alias\": \"TSTALIASID\"\n  },\n  \"httpMethod\": \"GET\",\n  \"messageVersion\": \"1.0\",\n  \"actionGroup\": \"SupportAssistant\"\n}\n</code></pre> <pre><code>{\n  \"messageVersion\": \"1.0\",\n  \"response\": {\n    \"actionGroup\": \"SupportAssistant\",\n    \"apiPath\": \"/schedule_meeting\",\n    \"httpMethod\": \"GET\",\n    \"httpStatusCode\": 200,\n    \"responseBody\": {\n      \"application/json\": {\n        \"body\": \"true\"\n      }\n    }\n  }\n}\n</code></pre>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#when-validation-fails",
            "title": "When validation fails",
            "text": "<p>If the request validation fails, your event handler will not be called, and an error message is returned to Bedrock. Similarly, if the response fails validation, your handler will abort the response.</p> What does this mean for my Agent? <p>The event handler will always return a response according to the OpenAPI schema. A validation failure always results in a 422 response. However, how Amazon Bedrock interprets that failure is non-deterministic, since it depends on the characteristics of the LLM being used.</p> Input payloadOutput payload <pre><code>{\n  \"sessionId\": \"123456789012345\",\n  \"sessionAttributes\": {},\n  \"inputText\": \"Schedule a meeting with the team. My email is foo@example@org\",\n  \"promptSessionAttributes\": {},\n  \"apiPath\": \"/schedule_meeting\",\n  \"parameters\": [\n    {\n      \"name\": \"email\",\n      \"type\": \"string\",\n      \"value\": \"foo@example@org\"\n    }\n  ],\n  \"agent\": {\n    \"name\": \"TimeAgent\",\n    \"version\": \"DRAFT\",\n    \"id\": \"XLHH72XNF2\",\n    \"alias\": \"TSTALIASID\"\n  },\n  \"httpMethod\": \"GET\",\n  \"messageVersion\": \"1.0\",\n  \"actionGroup\": \"SupportAssistant\"\n}\n</code></pre> <pre><code>{\n  \"messageVersion\": \"1.0\",\n  \"response\": {\n    \"actionGroup\": \"SupportAssistant\",\n    \"apiPath\": \"/schedule_meeting\",\n    \"httpMethod\": \"GET\",\n    \"httpStatusCode\": 200,\n    \"responseBody\": {\n      \"application/json\": {\n        \"body\": \"{\\\"statusCode\\\":422,\\\"detail\\\":[{\\\"loc\\\":[\\\"query\\\",\\\"email\\\"],\\\"type\\\":\\\"value_error.email\\\"}]}\"\n      }\n    }\n  }\n}\n</code></pre> <p> <pre><code>sequenceDiagram\n    Agent-&gt;&gt;Lambda: input payload\n    activate Lambda\n    Lambda-&gt;&gt;Parsing: parses input parameters\n    Parsing-&gt;&gt;Validation: validates input\n    Validation--&gt;Validation: failure\n    box BedrockAgentResolver\n    participant Lambda\n    participant Parsing\n    participant Validation\n    participant Routing\n    participant Your Code\n    end\n    Note right of Validation: Your code is never called\n    Validation-&gt;&gt;Agent: 422 response\n    deactivate Lambda\n</code></pre> </p>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#generating-openapi-schemas",
            "title": "Generating OpenAPI schemas",
            "text": "<p>Use the <code>get_openapi_json_schema</code> function provided by the resolver to produce a JSON-serialized string that represents your OpenAPI schema. You can print this string or save it to a file. You'll use the file later when creating the Agent.</p> <p>You'll need to regenerate the OpenAPI schema and update your Agent everytime your API changes.</p> app.pyOpenAPI schema <pre><code>from time import time\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import BedrockAgentResolver\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = BedrockAgentResolver()\n\n\n@app.get(\"/current_time\", description=\"Gets the current time in seconds\")\n@tracer.capture_method\ndef current_time() -&gt; int:\n    return int(time())\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext):\n    return app.resolve(event, context)\n\n\nif __name__ == \"__main__\":  # (1)!\n    print(app.get_openapi_json_schema())  # (2)!\n</code></pre> <ol> <li>This ensures that it's only executed when running the file directly, and not when running on the Lambda runtime.</li> <li>You can use additional options to customize the OpenAPI schema.</li> </ol> <pre><code>{\n  \"openapi\": \"3.0.3\",\n  \"info\": {\n    \"title\": \"Powertools API\",\n    \"version\": \"1.0.0\"\n  },\n  \"servers\": [\n    {\n      \"url\": \"/\"\n    }\n  ],\n  \"paths\": {\n    \"/current_time\": {\n      \"get\": {\n        \"summary\": \"GET /current_time\",\n        \"description\": \"Gets the current time in seconds\",\n        \"operationId\": \"current_time_current_time_get\",\n        \"responses\": {\n          \"200\": {\n            \"description\": \"Successful Response\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"type\": \"integer\",\n                  \"title\": \"Return\"\n                }\n              }\n            }\n          },\n          \"422\": {\n            \"description\": \"Validation Error\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"$ref\": \"#/components/schemas/HTTPValidationError\"\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  },\n  \"components\": {\n    \"schemas\": {\n      \"HTTPValidationError\": {\n        \"properties\": {\n          \"detail\": {\n            \"items\": {\n              \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"type\": \"array\",\n            \"title\": \"Detail\"\n          }\n        },\n        \"type\": \"object\",\n        \"title\": \"HTTPValidationError\"\n      },\n      \"ValidationError\": {\n        \"properties\": {\n          \"loc\": {\n            \"items\": {\n              \"anyOf\": [\n                {\n                  \"type\": \"string\"\n                },\n                {\n                  \"type\": \"integer\"\n                }\n              ]\n            },\n            \"type\": \"array\",\n            \"title\": \"Location\"\n          },\n          \"msg\": {\n            \"type\": \"string\",\n            \"title\": \"Message\"\n          },\n          \"type\": {\n            \"type\": \"string\",\n            \"title\": \"Error Type\"\n          }\n        },\n        \"type\": \"object\",\n        \"required\": [\n          \"loc\",\n          \"msg\",\n          \"type\"\n        ],\n        \"title\": \"ValidationError\"\n      }\n    }\n  }\n}\n</code></pre> <p>To get the OpenAPI schema, run the Python script from your terminal. The script will generate the schema directly to standard output, which you can redirect to a file.</p> <pre><code>python3 app.py &gt; schema.json\n</code></pre>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#crafting-effective-openapi-schemas",
            "title": "Crafting effective OpenAPI schemas",
            "text": "<p>Working with Agents for Amazon Bedrock will introduce non-deterministic behaviour to your system.</p> Why is that? <p>Amazon Bedrock uses LLMs to understand and respond to user input. These models are trained on vast amounts of data and are capable of extracting meanings from a sequence of text and understanding the relationship between words and phrases on it. However, this means that the same input can result in different outputs, depending on the characteristics of the LLM being used.</p> <p>The OpenAPI schema provides context and semantics to the Agent that will support the decision process for invoking our Lambda function. Sparse or ambiguous schemas can result in unexpected outcomes.</p> <p>We recommend enriching your OpenAPI schema with as many details as possible to help the Agent understand your functions, and make correct invocations. To achieve that, keep the following suggestions in mind:</p> <ul> <li>Always describe your function behaviour using the <code>description</code> field in your annotations</li> <li>When refactoring, update your description field to match the function outcomes</li> <li>Use distinct <code>description</code> for each function to have clear separation of semantics</li> </ul>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#video-walkthrough",
            "title": "Video walkthrough",
            "text": "<p>To create an Agent for Amazon Bedrock, refer to the official documentation provided by AWS.</p> <p>The following video demonstrates the end-to-end process:</p> <p> <p></p> <p>During the creation process, you should use the schema previously generated when prompted for an OpenAPI specification.</p>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/event_handler/bedrock_agents/#accessing-custom-request-fields",
            "title": "Accessing custom request fields",
            "text": "<p>The event sent by Agents for Amazon Bedrock into your Lambda function contains a number of extra event fields, exposed in the <code>app.current_event</code> field.</p> Why is this useful? <p>You can for instance identify new conversations (<code>session_id</code>) or store and analyze entire conversations (<code>input_text</code>).</p> Accessing request fields <p>In this example, we append correlation data to all generated logs. This can be used to aggregate logs by <code>session_id</code> and observe the entire conversation between a user and the Agent.</p> <pre><code>from time import time\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import BedrockAgentResolver\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\napp = BedrockAgentResolver()\n\n\n@app.get(\"/current_time\", description=\"Gets the current time in seconds\")  # (1)!\ndef current_time() -&gt; int:\n    logger.append_keys(\n        session_id=app.current_event.session_id,\n        action_group=app.current_event.action_group,\n        input_text=app.current_event.input_text,\n    )\n\n    logger.info(\"Serving current_time\")\n    return int(time())\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext):\n    return app.resolve(event, context)\n</code></pre> <p> The input event fields are:</p> Name Type Description message_version <code>str</code> The version of the message that identifies the format of the event data going into the Lambda function and the expected format of the response from a Lambda function. Amazon Bedrock only supports version 1.0. agent <code>BedrockAgentInfo</code> Contains information about the name, ID, alias, and version of the agent that the action group belongs to. input_text <code>str</code> The user input for the conversation turn. session_id <code>str</code> The unique identifier of the agent session. action_group <code>str</code> The name of the action group. api_path <code>str</code> The path to the API operation, as defined in the OpenAPI schema. http_method <code>str</code> The method of the API operation, as defined in the OpenAPI schema. parameters <code>List[BedrockAgentProperty]</code> Contains a list of objects. Each object contains the name, type, and value of a parameter in the API operation, as defined in the OpenAPI schema. request_body <code>BedrockAgentRequestBody</code> Contains the request body and its properties, as defined in the OpenAPI schema. session_attributes <code>Dict[str, str]</code> Contains session attributes and their values. prompt_session_attributes <code>Dict[str, str]</code> Contains prompt attributes and their values."
        },
        {
            "location": "core/event_handler/bedrock_agents/#additional-metadata",
            "title": "Additional metadata",
            "text": "<p>To enrich the view that Agents for Amazon Bedrock has of your Lambda functions, use a combination of Pydantic Models and OpenAPI type annotations to add constraints to your APIs parameters.</p> When is this useful? <p>Adding constraints to your function parameters can help you to enforce data validation and improve the understanding of your APIs by Amazon Bedrock.</p>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#customizing-openapi-parameters",
            "title": "Customizing OpenAPI parameters",
            "text": "<p>Whenever you use OpenAPI parameters to validate query strings or path parameters, you can enhance validation and OpenAPI documentation by using any of these parameters:</p> Field name Type Description <code>alias</code> <code>str</code> Alternative name for a field, used when serializing and deserializing data <code>validation_alias</code> <code>str</code> Alternative name for a field during validation (but not serialization) <code>serialization_alias</code> <code>str</code> Alternative name for a field during serialization (but not during validation) <code>description</code> <code>str</code> Human-readable description <code>gt</code> <code>float</code> Greater than. If set, value must be greater than this. Only applicable to numbers <code>ge</code> <code>float</code> Greater than or equal. If set, value must be greater than or equal to this. Only applicable to numbers <code>lt</code> <code>float</code> Less than. If set, value must be less than this. Only applicable to numbers <code>le</code> <code>float</code> Less than or equal. If set, value must be less than or equal to this. Only applicable to numbers <code>min_length</code> <code>int</code> Minimum length for strings <code>max_length</code> <code>int</code> Maximum length for strings <code>pattern</code> <code>string</code> A regular expression that the string must match. <code>strict</code> <code>bool</code> If <code>True</code>, strict validation is applied to the field. See Strict Mode for details <code>multiple_of</code> <code>float</code> Value must be a multiple of this. Only applicable to numbers <code>allow_inf_nan</code> <code>bool</code> Allow <code>inf</code>, <code>-inf</code>, <code>nan</code>. Only applicable to numbers <code>max_digits</code> <code>int</code> Maximum number of allow digits for strings <code>decimal_places</code> <code>int</code> Maximum number of decimal places allowed for numbers <code>openapi_examples</code> <code>dict[str, Example]</code> A list of examples to be displayed in the SwaggerUI interface. Avoid using the <code>examples</code> field for this purpose. <code>deprecated</code> <code>bool</code> Marks the field as deprecated <code>include_in_schema</code> <code>bool</code> If <code>False</code> the field will not be part of the exported OpenAPI schema <code>json_schema_extra</code> <code>JsonDict</code> Any additional JSON schema data for the schema property <p>To implement these customizations, include extra constraints when defining your parameters:</p> Customizing API parameters<pre><code>import requests\nfrom typing_extensions import Annotated\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import BedrockAgentResolver\nfrom aws_lambda_powertools.event_handler.openapi.params import Body, Query\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = BedrockAgentResolver()\n\nlogger = Logger()\n\n\n@app.post(\n    \"/todos\",\n    description=\"Creates a TODO\",\n)\ndef create_todo(\n    title: Annotated[str, Query(max_length=200, strict=True, description=\"The TODO title\")],  # (1)!\n) -&gt; Annotated[bool, Body(description=\"Was the TODO created correctly?\")]:\n    todo = requests.post(\"https://jsonplaceholder.typicode.com/todos\", data={\"title\": title})\n    try:\n        todo.raise_for_status()\n        return True\n    except Exception:\n        logger.exception(\"Error creating TODO\")\n        return False\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <ol> <li>Title should not be larger than 200 characters and strict mode is activated</li> </ol>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#customizing-api-operations",
            "title": "Customizing API operations",
            "text": "<p>Customize your API endpoints by adding metadata to endpoint definitions.</p> <p>Here's a breakdown of various customizable fields:</p> Field Name Type Description <code>summary</code> <code>str</code> A concise overview of the main functionality of the endpoint. This brief introduction is usually displayed in autogenerated API documentation and helps consumers quickly understand what the endpoint does. <code>description</code> <code>str</code> A more detailed explanation of the endpoint, which can include information about the operation's behavior, including side effects, error states, and other operational guidelines. <code>responses</code> <code>Dict[int, Dict[str, OpenAPIResponse]]</code> A dictionary that maps each HTTP status code to a Response Object as defined by the OpenAPI Specification. This allows you to describe expected responses, including default or error messages, and their corresponding schemas or models for different status codes. <code>response_description</code> <code>str</code> Provides the default textual description of the response sent by the endpoint when the operation is successful. It is intended to give a human-readable understanding of the result. <code>tags</code> <code>List[str]</code> Tags are a way to categorize and group endpoints within the API documentation. They can help organize the operations by resources or other heuristic. <code>operation_id</code> <code>str</code> A unique identifier for the operation, which can be used for referencing this operation in documentation or code. This ID must be unique across all operations described in the API. <code>include_in_schema</code> <code>bool</code> A boolean value that determines whether or not this operation should be included in the OpenAPI schema. Setting it to <code>False</code> can hide the endpoint from generated documentation and schema exports, which might be useful for private or experimental endpoints. <code>deprecated</code> <code>bool</code> A boolean value that determines whether or not this operation should be marked as deprecated in the OpenAPI schema. <p>To implement these customizations, include extra parameters when defining your routes:</p> Customzing API operations<pre><code>import requests\nfrom typing_extensions import Annotated\n\nfrom aws_lambda_powertools.event_handler import BedrockAgentResolver\nfrom aws_lambda_powertools.event_handler.openapi.params import Body, Path\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = BedrockAgentResolver()\n\n\n@app.get(\n    \"/todos/&lt;todo_id&gt;\",\n    summary=\"Retrieves a TODO item, returning it's title\",\n    description=\"Loads a TODO item identified by the `todo_id`\",\n    response_description=\"The TODO title\",\n    responses={\n        200: {\"description\": \"TODO item found\"},\n        404: {\n            \"description\": \"TODO not found\",\n        },\n    },\n    tags=[\"todos\"],\n)\ndef get_todo_title(\n    todo_id: Annotated[int, Path(description=\"The ID of the TODO item from which to retrieve the title\")],\n) -&gt; Annotated[str, Body(description=\"The TODO title\")]:\n    todo = requests.get(f\"https://jsonplaceholder.typicode.com/todos/{todo_id}\")\n    todo.raise_for_status()\n\n    return todo.json()[\"title\"]\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/event_handler/bedrock_agents/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>Test your routes by passing an Agent for Amazon Bedrock proxy event request:</p> assert_bedrock_agent_response.pyassert_bedrock_agent_response_module.py <pre><code>from dataclasses import dataclass\n\nimport assert_bedrock_agent_response_module\nimport pytest\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:123456789012:function:test\"\n    aws_request_id: str = \"da658bd3-2d6f-4e7b-8ec2-937234644fdc\"\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef test_lambda_handler(lambda_context: LambdaContext):\n    minimal_event = {\n        \"apiPath\": \"/current_time\",\n        \"httpMethod\": \"GET\",\n        \"inputText\": \"What is the current time?\",\n    }\n    # Example of Bedrock Agent API request event:\n    # https://docs.aws.amazon.com/bedrock/latest/userguide/agents-lambda.html#agents-lambda-input\n    ret = assert_bedrock_agent_response_module.lambda_handler(minimal_event, lambda_context)\n    assert ret[\"response\"][\"httpStatuScode\"] == 200\n    assert ret[\"response\"][\"responseBody\"][\"application/json\"][\"body\"] != \"\"\n</code></pre> <pre><code>import time\n\nfrom typing_extensions import Annotated\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import BedrockAgentResolver\nfrom aws_lambda_powertools.event_handler.openapi.params import Body\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\nlogger = Logger()\napp = BedrockAgentResolver()\n\n\n@app.get(\"/current_time\", description=\"Gets the current time\")\n@tracer.capture_method\ndef current_time() -&gt; Annotated[int, Body(description=\"Current time in milliseconds\")]:\n    return round(time.time() * 1000)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre>"
        },
        {
            "location": "core/metrics/",
            "title": "Metrics",
            "text": "<p>Metrics creates custom metrics asynchronously by logging metrics to standard output following Amazon CloudWatch Embedded Metric Format (EMF).</p> <p>These metrics can be visualized through Amazon CloudWatch Console.</p>"
        },
        {
            "location": "core/metrics/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Aggregate up to 100 metrics using a single CloudWatch EMF object (large JSON blob)</li> <li>Validate against common metric definitions mistakes (metric unit, values, max dimensions, max metrics, etc)</li> <li>Metrics are created asynchronously by CloudWatch service, no custom stacks needed</li> <li>Context manager to create a one off metric with a different dimension</li> </ul>"
        },
        {
            "location": "core/metrics/#terminologies",
            "title": "Terminologies",
            "text": "<p>If you're new to Amazon CloudWatch, there are five terminologies you must be aware of before using this utility:</p> <ul> <li>Namespace. It's the highest level container that will group multiple metrics from multiple services for a given application, for example <code>ServerlessEcommerce</code>.</li> <li>Dimensions. Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example <code>ColdStart</code> metric by Payment <code>service</code>.</li> <li>Metric. It's the name of the metric, for example: <code>SuccessfulBooking</code> or <code>UpdatedBooking</code>.</li> <li>Unit. It's a value representing the unit of measure for the corresponding metric, for example: <code>Count</code> or <code>Seconds</code>.</li> <li>Resolution. It's a value representing the storage resolution for the corresponding metric. Metrics can be either Standard or High resolution. Read more here.</li> </ul> Metric terminology, visually explained"
        },
        {
            "location": "core/metrics/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>Metric has two global settings that will be used across all metrics emitted:</p> Setting Description Environment variable Constructor parameter Metric namespace Logical container where all metrics will be placed e.g. <code>ServerlessAirline</code> <code>POWERTOOLS_METRICS_NAMESPACE</code> <code>namespace</code> Service Optionally, sets service metric dimension across all metrics e.g. <code>payment</code> <code>POWERTOOLS_SERVICE_NAME</code> <code>service</code> Info <p><code>POWERTOOLS_METRICS_DISABLED</code> will not disable default metrics created by AWS services.</p> Tip <p>Use your application or main service as the metric namespace to easily group all metrics.</p> AWS Serverless Application Model (SAM) example<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Powertools for AWS Lambda (Python) version\n\nGlobals:\n  Function:\n    Timeout: 5\n    Runtime: python3.12\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: booking\n        POWERTOOLS_METRICS_NAMESPACE: ServerlessAirline\n        POWERTOOLS_METRICS_FUNCTION_NAME: my-function-name\n\n    Layers:\n      # Find the latest Layer version in the official documentation\n      # https://docs.powertools.aws.dev/lambda/python/latest/#lambda-layer\n      - !Sub arn:aws:lambda:${AWS::Region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12\n\nResources:\n  CaptureLambdaHandlerExample:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: ../src\n      Handler: capture_lambda_handler.handler\n</code></pre> Note <p>For brevity, all code snippets in this page will rely on environment variables above being set.</p> <p>This ensures we instantiate <code>metrics = Metrics()</code> over <code>metrics = Metrics(service=\"booking\", namespace=\"ServerlessAirline\")</code>, etc.</p>"
        },
        {
            "location": "core/metrics/#creating-metrics",
            "title": "Creating metrics",
            "text": "<p>You can create metrics using <code>add_metric</code>, and you can create dimensions for all your aggregate metrics using <code>add_dimension</code> method.</p> Tip <p>You can initialize Metrics in any other module too. It'll keep track of your aggregate metrics in memory to optimize costs (one blob instead of multiples).</p> add_metrics.pyadd_dimension.py <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> <pre><code>import os\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_dimension(name=\"environment\", value=STAGE)\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> Tip: Autocomplete Metric Units <p><code>MetricUnit</code> enum facilitate finding a supported metric unit by CloudWatch. Alternatively, you can pass the value as a string if you already know them e.g. <code>unit=\"Count\"</code>.</p> Note: Metrics overflow <p>CloudWatch EMF supports a max of 100 metrics per batch. Metrics utility will flush all metrics when adding the 100th metric. Subsequent metrics (101th+) will be aggregated into a new EMF object, for your convenience.</p> Warning: Do not create metrics or dimensions outside the handler <p>Metrics or dimensions added in the global scope will only be added during cold start. Disregard if that's the intended behavior.</p>"
        },
        {
            "location": "core/metrics/#adding-high-resolution-metrics",
            "title": "Adding high-resolution metrics",
            "text": "<p>You can create high-resolution metrics passing <code>resolution</code> parameter to <code>add_metric</code>.</p> When is it useful? <p>High-resolution metrics are data with a granularity of one second and are very useful in several situations such as telemetry, time series, real-time incident management, and others.</p> add_high_resolution_metrics.py <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricResolution, MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1, resolution=MetricResolution.High)\n</code></pre> Tip: Autocomplete Metric Resolutions <p><code>MetricResolution</code> enum facilitates finding a supported metric resolution by CloudWatch. Alternatively, you can pass the values 1 or 60 (must be one of them) as an integer e.g. <code>resolution=1</code>.</p>"
        },
        {
            "location": "core/metrics/#adding-multi-value-metrics",
            "title": "Adding multi-value metrics",
            "text": "<p>You can call <code>add_metric()</code> with the same metric name multiple times. The values will be grouped together in a list.</p> add_multi_value_metrics.pyadd_multi_value_metrics_output.json <pre><code>import os\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_dimension(name=\"environment\", value=STAGE)\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=1)\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=8)\n</code></pre> <pre><code>{\n    \"_aws\": {\n        \"Timestamp\": 1656685750622,\n        \"CloudWatchMetrics\": [\n            {\n                \"Namespace\": \"ServerlessAirline\",\n                \"Dimensions\": [\n                    [\n                        \"environment\",\n                        \"service\"\n                    ]\n                ],\n                \"Metrics\": [\n                    {\n                        \"Name\": \"TurbineReads\",\n                        \"Unit\": \"Count\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"environment\": \"dev\",\n    \"service\": \"booking\",\n    \"TurbineReads\": [\n        1.0,\n        8.0\n    ]\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#adding-default-dimensions",
            "title": "Adding default dimensions",
            "text": "<p>You can use <code>set_default_dimensions</code> method, or <code>default_dimensions</code> parameter in <code>log_metrics</code> decorator, to persist dimensions across Lambda invocations.</p> <p>If you'd like to remove them at some point, you can use <code>clear_default_dimensions</code> method.</p> set_default_dimensions.pyset_default_dimensions_log_metrics.py <pre><code>import os\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\nmetrics = Metrics()\nmetrics.set_default_dimensions(environment=STAGE, another=\"one\")\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=1)\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=8)\n</code></pre> <pre><code>import os\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\nmetrics = Metrics()\nDEFAULT_DIMENSIONS = {\"environment\": STAGE, \"another\": \"one\"}\n\n\n# ensures metrics are flushed upon request completion/failure\n@metrics.log_metrics(default_dimensions=DEFAULT_DIMENSIONS)\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=1)\n    metrics.add_metric(name=\"TurbineReads\", unit=MetricUnit.Count, value=8)\n</code></pre> <p>Note: Dimensions with empty values will not be included.</p>"
        },
        {
            "location": "core/metrics/#changing-default-timestamp",
            "title": "Changing default timestamp",
            "text": "<p>When creating metrics, we use the current timestamp. If you want to change the timestamp of all the metrics you create, utilize the <code>set_timestamp</code> function. You can specify a datetime object or an integer representing an epoch timestamp in milliseconds.</p> <p>Note that when specifying the timestamp using an integer, it must adhere to the epoch timezone format in milliseconds.</p> Info <p>If you need to use different timestamps across multiple metrics, opt for single_metric.</p> set_custom_timestamp_log_metrics.py <pre><code>import datetime\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n\n    metric_timestamp = int((datetime.datetime.now() - datetime.timedelta(days=2)).timestamp() * 1000)\n    metrics.set_timestamp(metric_timestamp)\n</code></pre>"
        },
        {
            "location": "core/metrics/#flushing-metrics",
            "title": "Flushing metrics",
            "text": "<p>As you finish adding all your metrics, you need to serialize and flush them to standard output. You can do that automatically with the <code>log_metrics</code> decorator.</p> <p>This decorator also validates, serializes, and flushes all your metrics. During metrics validation, if no metrics are provided then a warning will be logged, but no exception will be raised.</p> add_metrics.pylog_metrics_output.json <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> <pre><code>{\n    \"_aws\": {\n        \"Timestamp\": 1656686788803,\n        \"CloudWatchMetrics\": [\n            {\n                \"Namespace\": \"ServerlessAirline\",\n                \"Dimensions\": [\n                    [\n                        \"service\"\n                    ]\n                ],\n                \"Metrics\": [\n                    {\n                        \"Name\": \"SuccessfulBooking\",\n                        \"Unit\": \"Count\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"service\": \"booking\",\n    \"SuccessfulBooking\": [\n        1.0\n    ]\n}\n</code></pre> Tip: Metric validation <p>If metrics are provided, and any of the following criteria are not met, <code>SchemaValidationError</code> exception will be raised:</p> <ul> <li>Maximum of 29 user-defined dimensions</li> <li>Namespace is set, and no more than one</li> <li>Metric units must be supported by CloudWatch</li> </ul>"
        },
        {
            "location": "core/metrics/#raising-schemavalidationerror-on-empty-metrics",
            "title": "Raising SchemaValidationError on empty metrics",
            "text": "<p>If you want to ensure at least one metric is always emitted, you can pass <code>raise_on_empty_metrics</code> to the log_metrics decorator:</p> Raising SchemaValidationError exception if no metrics are added<pre><code>from aws_lambda_powertools.metrics import Metrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics(raise_on_empty_metrics=True)\ndef lambda_handler(event: dict, context: LambdaContext):\n    # no metrics being created will now raise SchemaValidationError\n    ...\n</code></pre> Suppressing warning messages on empty metrics <p>If you expect your function to execute without publishing metrics every time, you can suppress the warning with <code>warnings.filterwarnings(\"ignore\", \"No application metrics to publish*\")</code>.</p>"
        },
        {
            "location": "core/metrics/#capturing-cold-start-metric",
            "title": "Capturing cold start metric",
            "text": "<p>You can optionally capture cold start metrics with <code>log_metrics</code> decorator via <code>capture_cold_start_metric</code> param.</p> capture_cold_start_metric.pycapture_cold_start_metric_output.json <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event: dict, context: LambdaContext):\n    ...\n</code></pre> <pre><code>{\n    \"_aws\": {\n        \"Timestamp\": 1656687493142,\n        \"CloudWatchMetrics\": [\n            {\n                \"Namespace\": \"ServerlessAirline\",\n                \"Dimensions\": [\n                    [\n                        \"function_name\",\n                        \"service\"\n                    ]\n                ],\n                \"Metrics\": [\n                    {\n                        \"Name\": \"ColdStart\",\n                        \"Unit\": \"Count\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"function_name\": \"test\",\n    \"service\": \"booking\",\n    \"ColdStart\": [\n        1.0\n    ]\n}\n</code></pre> <p>If it's a cold start invocation, this feature will:</p> <ul> <li>Create a separate EMF blob solely containing a metric named <code>ColdStart</code></li> <li>Add <code>function_name</code> and <code>service</code> dimensions</li> </ul> <p>This has the advantage of keeping cold start metric separate from your application metrics, where you might have unrelated dimensions.</p> Info <p>We do not emit 0 as a value for ColdStart metric for cost reasons. Let us know if you'd prefer a flag to override it.</p>"
        },
        {
            "location": "core/metrics/#customizing-function-name-for-cold-start-metrics",
            "title": "Customizing function name for cold start metrics",
            "text": "<p>When emitting cold start metrics, the <code>function_name</code> dimension defaults to <code>context.function_name</code>. If you want to change the value you can set the <code>function_name</code> parameter in the metrics constructor, or define the environment variable <code>POWERTOOLS_METRICS_FUNCTION_NAME</code>.</p> <p>The priority of the <code>function_name</code> dimension value is defined as:</p> <ol> <li><code>function_name</code> constructor option</li> <li><code>POWERTOOLS_METRICS_FUNCTION_NAME</code> environment variable</li> <li><code>context.function_name</code> property</li> </ol> working_with_custom_cold_start_function_name.py <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics(function_name=\"my-function-name\")\n\n\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event: dict, context: LambdaContext): ...\n</code></pre>"
        },
        {
            "location": "core/metrics/#environment-variables",
            "title": "Environment variables",
            "text": "<p>The following environment variable is available to configure Metrics at a global scope:</p> Setting Description Environment variable Default Namespace Name Sets namespace used for metrics. <code>POWERTOOLS_METRICS_NAMESPACE</code> <code>None</code> Service Sets service metric dimension across all metrics e.g. <code>payment</code> <code>POWERTOOLS_SERVICE_NAME</code> <code>None</code> Function Name Function name used as dimension for the ColdStart metric. <code>POWERTOOLS_METRICS_FUNCTION_NAME</code> <code>None</code> Disable Powertools Metrics Disables all metrics emitted by Powertools. <code>POWERTOOLS_METRICS_DISABLED</code> <code>None</code> <p><code>POWERTOOLS_METRICS_NAMESPACE</code> is also available on a per-instance basis with the <code>namespace</code> parameter, which will consequently override the environment variable value.</p>"
        },
        {
            "location": "core/metrics/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/metrics/#adding-metadata",
            "title": "Adding metadata",
            "text": "<p>You can add high-cardinality data as part of your Metrics log with <code>add_metadata</code> method. This is useful when you want to search highly contextual information along with your metrics in your logs.</p> Info <p>This will not be available during metrics visualization - Use dimensions for this purpose</p> add_metadata.pyadd_metadata_output.json <pre><code>from uuid import uuid4\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n    metrics.add_metadata(key=\"booking_id\", value=f\"{uuid4()}\")\n</code></pre> <pre><code>{\n    \"_aws\": {\n        \"Timestamp\": 1656688250155,\n        \"CloudWatchMetrics\": [\n            {\n                \"Namespace\": \"ServerlessAirline\",\n                \"Dimensions\": [\n                    [\n                        \"service\"\n                    ]\n                ],\n                \"Metrics\": [\n                    {\n                        \"Name\": \"SuccessfulBooking\",\n                        \"Unit\": \"Count\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"service\": \"booking\",\n    \"booking_id\": \"00347014-341d-4b8e-8421-a89d3d588ab3\",\n    \"SuccessfulBooking\": [\n        1.0\n    ]\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#single-metric",
            "title": "Single metric",
            "text": "<p>CloudWatch EMF uses the same dimensions and timestamp across all your metrics. Use <code>single_metric</code> if you have a metric that should have different dimensions or timestamp.</p>"
        },
        {
            "location": "core/metrics/#working-with-different-dimensions",
            "title": "Working with different dimensions",
            "text": "<p>Generally, using different dimensions would be an edge case since you pay for unique metric.</p> <p>Keep the following formula in mind: unique metric = (metric_name + dimension_name + dimension_value)</p> single_metric.pysingle_metric_output.json <pre><code>import os\n\nfrom aws_lambda_powertools import single_metric\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    with single_metric(name=\"MySingleMetric\", unit=MetricUnit.Count, value=1) as metric:\n        metric.add_dimension(name=\"environment\", value=STAGE)\n</code></pre> <pre><code>{\n    \"_aws\": {\n        \"Timestamp\": 1656689267834,\n        \"CloudWatchMetrics\": [\n            {\n                \"Namespace\": \"ServerlessAirline\",\n                \"Dimensions\": [\n                    [\n                        \"environment\",\n                        \"service\"\n                    ]\n                ],\n                \"Metrics\": [\n                    {\n                        \"Name\": \"MySingleMetric\",\n                        \"Unit\": \"Count\"\n                    }\n                ]\n            }\n        ]\n    },\n    \"environment\": \"dev\",\n    \"service\": \"booking\",\n    \"MySingleMetric\": [\n        1.0\n    ]\n}\n</code></pre> <p>By default it will skip all previously defined dimensions including default dimensions. Use <code>default_dimensions</code> keyword argument if you want to reuse default dimensions or specify custom dimensions from a dictionary.</p> single_metric_default_dimensions_inherit.pysingle_metric_default_dimensions.py <pre><code>import os\n\nfrom aws_lambda_powertools import single_metric\nfrom aws_lambda_powertools.metrics import Metrics, MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\n\nmetrics = Metrics()\nmetrics.set_default_dimensions(environment=STAGE)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    with single_metric(\n        name=\"RecordsCount\",\n        unit=MetricUnit.Count,\n        value=10,\n        default_dimensions=metrics.default_dimensions,\n    ) as metric:\n        metric.add_dimension(name=\"TableName\", value=\"Users\")\n</code></pre> <pre><code>import os\n\nfrom aws_lambda_powertools import single_metric\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nSTAGE = os.getenv(\"STAGE\", \"dev\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    with single_metric(\n        name=\"RecordsCount\",\n        unit=MetricUnit.Count,\n        value=10,\n        default_dimensions={\"environment\": STAGE},\n    ) as metric:\n        metric.add_dimension(name=\"TableName\", value=\"Users\")\n</code></pre>"
        },
        {
            "location": "core/metrics/#working-with-different-timestamp",
            "title": "Working with different timestamp",
            "text": "<p>When working with multiple metrics, customers may need different timestamps between them. In such cases, utilize <code>single_metric</code> to flush individual metrics with specific timestamps.</p> single_metric_with_different_timestamp.pysingle_metric_with_different_timestamp_payload.json <pre><code>from aws_lambda_powertools import Logger, single_metric\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    for record in event:\n\n        record_id: str = record.get(\"record_id\")\n        amount: int = record.get(\"amount\")\n        timestamp: int = record.get(\"timestamp\")\n\n        with single_metric(name=\"Orders\", unit=MetricUnit.Count, value=amount, namespace=\"Powertools\") as metric:\n            logger.info(f\"Processing record id {record_id}\")\n            metric.set_timestamp(timestamp)\n</code></pre> <pre><code>[\n    {\n        \"record_id\": \"6ba7b810-9dad-11d1-80b4-00c04fd430c8\",\n        \"amount\": 10,\n        \"timestamp\": 1648195200000\n    },\n    {\n        \"record_id\": \"6ba7b811-9dad-11d1-80b4-00c04fd430c8\",\n        \"amount\": 30,\n        \"timestamp\": 1648224000000\n    },\n    {\n        \"record_id\": \"6ba7b812-9dad-11d1-80b4-00c04fd430c8\",\n        \"amount\": 25,\n        \"timestamp\": 1648209600000\n    },\n    {\n        \"record_id\": \"6ba7b813-9dad-11d1-80b4-00c04fd430c8\",\n        \"amount\": 40,\n        \"timestamp\": 1648177200000\n    },\n    {\n        \"record_id\": \"6ba7b814-9dad-11d1-80b4-00c04fd430c8\",\n        \"amount\": 32,\n        \"timestamp\": 1648216800000\n    }\n]\n</code></pre>"
        },
        {
            "location": "core/metrics/#flushing-metrics-manually",
            "title": "Flushing metrics manually",
            "text": "<p>If you are using the AWS Lambda Web Adapter project, or a middleware with custom metric logic, you can use <code>flush_metrics()</code>. This method will serialize, print metrics available to standard output, and clear in-memory metrics data.</p> Warning <p>This does not capture Cold Start metrics, and metric data validation still applies.</p> <p>Contrary to the <code>log_metrics</code> decorator, you are now also responsible to flush metrics in the event of an exception.</p> Manually flushing and clearing metrics from memory<pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\ndef book_flight(flight_id: str, **kwargs): \n    # logic to book flight\n    ...\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        book_flight(flight_id=event.get(\"flight_id\", \"\"))\n    finally:\n        metrics.flush_metrics()\n</code></pre>"
        },
        {
            "location": "core/metrics/#metrics-isolation",
            "title": "Metrics isolation",
            "text": "<p>You can use <code>EphemeralMetrics</code> class when looking to isolate multiple instances of metrics with distinct namespaces and/or dimensions.</p> <p>This is a typical use case is for multi-tenant, or emitting same metrics for distinct applications.</p> EphemeralMetrics usage<pre><code>from aws_lambda_powertools.metrics import EphemeralMetrics, MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = EphemeralMetrics()\n\n\n@metrics.log_metrics\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> <p>Differences between <code>EphemeralMetrics</code> and <code>Metrics</code></p> <p><code>EphemeralMetrics</code> has only one difference while keeping nearly the exact same set of features:</p> Feature Metrics EphemeralMetrics Share data across instances (metrics, dimensions, metadata, etc.) Yes - <p>Why not changing the default <code>Metrics</code> behaviour to not share data across instances?</p> <p>This is an intentional design to prevent accidental data deduplication or data loss issues due to CloudWatch EMF metric dimension constraint.</p> <p>In CloudWatch, there are two metric ingestion mechanisms: EMF (async) and <code>PutMetricData</code> API (sync).</p> <p>The former creates metrics asynchronously via CloudWatch Logs, and the latter uses a synchronous and more flexible ingestion API.</p> <p>Key concept</p> <p>CloudWatch considers a metric unique by a combination of metric name, metric namespace, and zero or more metric dimensions.</p> <p>With EMF, metric dimensions are shared with any metrics you define. With <code>PutMetricData</code> API, you can set a list defining one or more metrics with distinct dimensions.</p> <p>This is a subtle yet important distinction. Imagine you had the following metrics to emit:</p> Metric Name Dimension Intent SuccessfulBooking service=\"booking\", tenant_id=\"sample\" Application metric IntegrationLatency service=\"booking\", function_name=\"sample\" Operational metric ColdStart service=\"booking\", function_name=\"sample\" Operational metric <p>The <code>tenant_id</code> dimension could vary leading to two common issues:</p> <ol> <li><code>ColdStart</code> metric will be created multiple times (N * number of unique tenant_id dimension value), despite the <code>function_name</code> being the same</li> <li><code>IntegrationLatency</code> metric will be also created multiple times due to <code>tenant_id</code> as well as <code>function_name</code> (may or not be intentional)</li> </ol> <p>These issues are exacerbated when you create (A) metric dimensions conditionally, (B) multiple metrics' instances throughout your code  instead of reusing them (globals). Subsequent metrics' instances will have (or lack) different metric dimensions resulting in different metrics and data points with the same name.</p> <p>Intentional design to address these scenarios</p> <p>On 1, when you enable capture_start_metric feature, we transparently create and flush an additional EMF JSON Blob that is independent from your application metrics. This prevents data pollution.</p> <p>On 2, you can use <code>EphemeralMetrics</code> to create an additional EMF JSON Blob from your application metric (<code>SuccessfulBooking</code>). This ensures that <code>IntegrationLatency</code> operational metric data points aren't tied to any dynamic dimension values like <code>tenant_id</code>.</p> <p>That is why <code>Metrics</code> shares data across instances by default, as that covers 80% of use cases and different personas using Powertools. This allows them to instantiate <code>Metrics</code> in multiple places throughout their code - be a separate file, a middleware, or an abstraction that sets default dimensions.</p>"
        },
        {
            "location": "core/metrics/#observability-providers",
            "title": "Observability providers",
            "text": "<p>An observability provider is an AWS Lambda Partner offering a platform for logging, metrics, traces, etc.</p> <p>We provide a thin-wrapper on top of the most requested observability providers. We strive to keep a similar UX as close as possible while keeping our value add features.</p> <p>Missing your preferred provider? Please create a feature request.</p> <p>Current providers:</p> Provider Notes Datadog Uses Datadog SDK and Datadog Lambda Extension by default"
        },
        {
            "location": "core/metrics/#testing-your-code",
            "title": "Testing your code",
            "text": ""
        },
        {
            "location": "core/metrics/#setting-environment-variables",
            "title": "Setting environment variables",
            "text": "Tip <p>Ignore this section, if:</p> <ul> <li>You are explicitly setting namespace/default dimension via <code>namespace</code> and <code>service</code> parameters</li> <li>You're not instantiating <code>Metrics</code> in the global namespace</li> </ul> <p>For example, <code>Metrics(namespace=\"ServerlessAirline\", service=\"booking\")</code></p> <p>Make sure to set <code>POWERTOOLS_METRICS_NAMESPACE</code> and <code>POWERTOOLS_SERVICE_NAME</code> before running your tests to prevent failing on <code>SchemaValidation</code> exception. You can set it before you run tests or via pytest plugins like dotenv.</p> Injecting dummy Metric Namespace before running tests<pre><code>POWERTOOLS_SERVICE_NAME=\"booking\" POWERTOOLS_METRICS_NAMESPACE=\"ServerlessAirline\" python -m pytest\n</code></pre>"
        },
        {
            "location": "core/metrics/#clearing-metrics",
            "title": "Clearing metrics",
            "text": "<p><code>Metrics</code> keep metrics in memory across multiple instances. If you need to test this behavior, you can use the following Pytest fixture to ensure metrics are reset incl. cold start:</p> Clearing metrics between tests<pre><code>import pytest\n\nfrom aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics.provider import cold_start\n\n\n@pytest.fixture(scope=\"function\", autouse=True)\ndef reset_metric_set():\n    # Clear out every metric data prior to every test\n    metrics = Metrics()\n    metrics.clear_metrics()\n    cold_start.is_cold_start = True  # ensure each test has cold start\n    metrics.clear_default_dimensions()  # remove persisted default dimensions, if any\n    yield\n</code></pre>"
        },
        {
            "location": "core/metrics/#functional-testing",
            "title": "Functional testing",
            "text": "<p>You can read standard output and assert whether metrics have been flushed. Here's an example using <code>pytest</code> with <code>capsys</code> built-in fixture:</p> assert_single_emf_blob.pyadd_metrics.pyassert_multiple_emf_blobs.pyassert_multiple_emf_blobs_module.py <pre><code>import json\n\nimport add_metrics\n\n\ndef test_log_metrics(capsys):\n    add_metrics.lambda_handler({}, {})\n\n    log = capsys.readouterr().out.strip()  # remove any extra line\n    metrics_output = json.loads(log)  # deserialize JSON str\n\n    # THEN we should have no exceptions\n    # and a valid EMF object should be flushed correctly\n    assert \"SuccessfulBooking\" in log  # basic string assertion in JSON str\n    assert \"SuccessfulBooking\" in metrics_output[\"_aws\"][\"CloudWatchMetrics\"][0][\"Metrics\"][0][\"Name\"]\n</code></pre> <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> <p>This will be needed when using <code>capture_cold_start_metric=True</code>, or when both <code>Metrics</code> and <code>single_metric</code> are used.</p> <pre><code>import json\nfrom dataclasses import dataclass\n\nimport assert_multiple_emf_blobs_module\nimport pytest\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n    aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef capture_metrics_output_multiple_emf_objects(capsys):\n    return [json.loads(line.strip()) for line in capsys.readouterr().out.split(\"\\n\") if line]\n\n\ndef test_log_metrics(capsys, lambda_context: LambdaContext):\n    assert_multiple_emf_blobs_module.lambda_handler({}, lambda_context)\n\n    cold_start_blob, custom_metrics_blob = capture_metrics_output_multiple_emf_objects(capsys)\n\n    # Since `capture_cold_start_metric` is used\n    # we should have one JSON blob for cold start metric and one for the application\n    assert cold_start_blob[\"ColdStart\"] == [1.0]\n    assert cold_start_blob[\"function_name\"] == \"test\"\n\n    assert \"SuccessfulBooking\" in custom_metrics_blob\n</code></pre> <pre><code>from aws_lambda_powertools import Metrics\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = Metrics()\n\n\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", unit=MetricUnit.Count, value=1)\n</code></pre> Tip <p>For more elaborate assertions and comparisons, check out our functional testing for Metrics utility.</p>"
        },
        {
            "location": "core/metrics/datadog/",
            "title": "Datadog",
            "text": "<p>This observability provider creates custom metrics by flushing metrics to Datadog Lambda extension, or to standard output via Datadog Forwarder. These metrics can be visualized in the Datadog console.</p> <pre><code>stateDiagram-v2\n    direction LR\n    LambdaFn: Your Lambda function\n    LambdaCode: DatadogMetrics\n    DatadogSDK: Datadog SDK\n    DatadogExtension: Datadog Lambda Extension\n    Datadog: Datadog Dashboard\n    LambdaExtension: Lambda Extension\n\n    LambdaFn --&gt; LambdaCode\n    LambdaCode --&gt; DatadogSDK\n    DatadogSDK --&gt; DatadogExtension\n    DatadogExtension --&gt; Datadog: async\n\n    state LambdaExtension {\n        DatadogExtension\n    }\n</code></pre>"
        },
        {
            "location": "core/metrics/datadog/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Flush metrics to Datadog extension or standard output</li> <li>Validate against common metric definitions mistakes</li> <li>Support to add default tags</li> </ul>"
        },
        {
            "location": "core/metrics/datadog/#terminologies",
            "title": "Terminologies",
            "text": "<p>If you're new to Datadog Metrics, there are three terminologies you must be aware of before using this utility:</p> <ul> <li>Namespace. It's the highest level container that will group multiple metrics from multiple services for a given application, for example <code>ServerlessEcommerce</code>.</li> <li>Metric. It's the name of the metric, for example: SuccessfulBooking or UpdatedBooking.</li> <li>Tags. Metrics metadata in key-value pair format. They help provide contextual information, and filter org organize metrics.</li> </ul> <p>You can read more details in the Datadog official documentation.</p>"
        },
        {
            "location": "core/metrics/datadog/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p>"
        },
        {
            "location": "core/metrics/datadog/#install",
            "title": "Install",
            "text": "<p>Using Datadog Forwarder? You can skip this step.</p> <p>We recommend using Datadog SDK and Datadog Lambda Extension with this feature for optimal results.</p> <p>For Datadog SDK, you can add <code>aws-lambda-powertools[datadog]</code> as a dependency in your preferred tool, or as a Lambda Layer in the following example:</p> AWS Serverless Application Model (SAM) example<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Powertools for AWS Lambda (Python) version\n\nGlobals:\n  Function:\n    Timeout: 5\n    Runtime: python3.12\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_METRICS_NAMESPACE: ServerlessAirline\n        # [Production setup]\n        # DATADOG_API_KEY_SECRET_ARN: \"&lt;AWS Secrets Manager Secret ARN containing Datadog API key&gt;\"\n        # [Development only]\n        DD_API_KEY: \"&lt;YOUR DATADOG API KEY&gt;\"\n        # Configuration details: https://docs.datadoghq.com/serverless/installation/python/?tab=datadogcli\n        DD_SITE: datadoghq.com\n\n    Layers:\n      # Find the latest Layer version in the official documentation\n      # https://docs.powertools.aws.dev/lambda/python/latest/#lambda-layer\n      - !Sub arn:aws:lambda:${AWS::Region}:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12\n      # Find the latest Layer version in the Datadog official documentation\n\n      # Datadog SDK\n      # Latest versions: https://github.com/DataDog/datadog-lambda-python/releases\n      - !Sub arn:aws:lambda:${AWS::Region}:464622532012:layer:Datadog-Python312:78\n\n      # Datadog Lambda Extension\n      # Latest versions: https://github.com/DataDog/datadog-lambda-extension/releases\n      - !Sub arn:aws:lambda:${AWS::Region}:464622532012:layer:Datadog-Extension:45\n\nResources:\n  CaptureLambdaHandlerExample:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: ../src\n      Handler: capture_lambda_handler.handler\n</code></pre>"
        },
        {
            "location": "core/metrics/datadog/#creating-metrics",
            "title": "Creating metrics",
            "text": "<p>You can create metrics using <code>add_metric</code>.</p> <p>By default, we will generate the current timestamp for you. Alternatively, you can use the <code>timestamp</code> parameter to set a custom one in epoch time.</p> add_datadog_metrics.pyadd_metrics_with_timestamp.py <pre><code>from aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = DatadogMetrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", value=1)\n</code></pre> <pre><code>import time\n\nfrom aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = DatadogMetrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", value=1, timestamp=int(time.time()))\n</code></pre> Warning: Do not create metrics outside the handler <p>Metrics added in the global scope will only be added during cold start. Disregard if you that's the intended behavior.</p>"
        },
        {
            "location": "core/metrics/datadog/#adding-tags",
            "title": "Adding tags",
            "text": "<p>You can add any number of tags to your metrics via keyword arguments (<code>key=value</code>). They are helpful to filter, organize, and aggregate your metrics later.</p> <p>We will emit a warning for tags beyond the 200 chars limit.</p> add_metrics_with_tags.py <pre><code>from aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = DatadogMetrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", value=1, tag1=\"powertools\", tag2=\"python\")\n</code></pre>"
        },
        {
            "location": "core/metrics/datadog/#adding-default-tags",
            "title": "Adding default tags",
            "text": "<p>You can persist tags across Lambda invocations and <code>DatadogMetrics</code> instances via <code>set_default_tags</code> method, or <code>default_tags</code> parameter in the <code>log_metrics</code> decorator.</p> <p>If you'd like to remove them at some point, you can use the <code>clear_default_tags</code> method.</p> Metric tag takes precedence over default tags of the same name <p>When adding tags with the same name via <code>add_metric</code> and <code>set_default_tags</code>, <code>add_metric</code> takes precedence.</p> set_default_tags.pyset_default_tags_log_metrics.py <pre><code>from aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = DatadogMetrics()\nmetrics.set_default_tags(tag1=\"powertools\", tag2=\"python\")\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", value=1)\n</code></pre> <pre><code>from aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = DatadogMetrics()\n\ndefault_tags = {\"tag1\": \"powertools\", \"tag2\": \"python\"}\n\n\n@metrics.log_metrics(default_tags=default_tags)  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", value=1)\n</code></pre>"
        },
        {
            "location": "core/metrics/datadog/#flushing-metrics",
            "title": "Flushing metrics",
            "text": "<p>Use <code>log_metrics</code> decorator to automatically serialize and flush your metrics (SDK or Forwarder) at the end of your invocation.</p> <p>This decorator also ensures metrics are flushed in the event of an exception, including warning you in case you forgot to add metrics.</p> add_metrics.pylog_metrics_output.json <pre><code>from aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = DatadogMetrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", value=1, tag1=\"powertools\", tag2=\"python\")\n</code></pre> <pre><code>{\n   \"m\":\"SuccessfulBooking\",\n   \"v\":1,\n   \"e\":1691707076,\n   \"t\":[\n      \"tag1:powertools\",\n      \"tag2:python\"\n   ]\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/datadog/#raising-schemavalidationerror-on-empty-metrics",
            "title": "Raising SchemaValidationError on empty metrics",
            "text": "<p>Use <code>raise_on_empty_metrics=True</code> if you want to ensure at least one metric is always emitted.</p> Failing fast if no metrics are added<pre><code>from aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = DatadogMetrics()\n\n\n@metrics.log_metrics(raise_on_empty_metrics=True)  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    # no metrics being created will now raise SchemaValidationError\n    return\n</code></pre> Suppressing warning messages on empty metrics <p>If you expect your function to execute without publishing metrics every time, you can suppress the warning with <code>warnings.filterwarnings(\"ignore\", \"No application metrics to publish*\")</code>.</p>"
        },
        {
            "location": "core/metrics/datadog/#capturing-cold-start-metric",
            "title": "Capturing cold start metric",
            "text": "<p>You can optionally capture cold start metrics with <code>log_metrics</code> decorator via <code>capture_cold_start_metric</code> param.</p> capture_cold_start_metric.pycapture_cold_start_metric_output.json <pre><code>from aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = DatadogMetrics()\n\n\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event: dict, context: LambdaContext):\n    return\n</code></pre> <pre><code>{\n    \"m\":\"ColdStart\",\n    \"v\":1,\n    \"e\":1691707488,\n    \"t\":[\n       \"function_name:HelloWorldFunction\"\n    ]\n }\n</code></pre> <p>If it's a cold start invocation, this feature will:</p> <ul> <li>Create a separate Datadog metric solely containing a metric named <code>ColdStart</code></li> <li>Add <code>function_name</code> metric tag</li> </ul> <p>This has the advantage of keeping cold start metric separate from your application metrics, where you might have unrelated tags.</p> Info <p>We do not emit 0 as a value for ColdStart metric for cost reasons. Let us know if you'd prefer a flag to override it.</p>"
        },
        {
            "location": "core/metrics/datadog/#environment-variables",
            "title": "Environment variables",
            "text": "<p>You can use any of the following environment variables to configure <code>DatadogMetrics</code>:</p> Setting Description Environment variable Constructor parameter Metric namespace Logical container where all metrics will be placed e.g. <code>ServerlessAirline</code> <code>POWERTOOLS_METRICS_NAMESPACE</code> <code>namespace</code> Flush to log Use this when you want to flush metrics to be exported through Datadog Forwarder <code>DD_FLUSH_TO_LOG</code> <code>flush_to_log</code> Disable Powertools Metrics Optionally, disables all Powertools metrics. <code>POWERTOOLS_METRICS_DISABLED</code> N/A Info <p><code>POWERTOOLS_METRICS_DISABLED</code> will not disable default metrics created by AWS services.</p>"
        },
        {
            "location": "core/metrics/datadog/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/metrics/datadog/#flushing-metrics-manually",
            "title": "Flushing metrics manually",
            "text": "<p>If you are using the AWS Lambda Web Adapter project, or a middleware with custom metric logic, you can use <code>flush_metrics()</code>. This method will serialize, print metrics available to standard output, and clear in-memory metrics data.</p> Warning <p>This does not capture Cold Start metrics, and metric data validation still applies.</p> <p>Contrary to the <code>log_metrics</code> decorator, you are now also responsible to flush metrics in the event of an exception.</p> Manually flushing and clearing metrics from memory<pre><code>from aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = DatadogMetrics()\n\n\ndef book_flight(flight_id: str, **kwargs):\n    # logic to book flight\n    ...\n    metrics.add_metric(name=\"SuccessfulBooking\", value=1)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        book_flight(flight_id=event.get(\"flight_id\", \"\"))\n    finally:\n        metrics.flush_metrics()\n</code></pre>"
        },
        {
            "location": "core/metrics/datadog/#integrating-with-datadog-forwarder",
            "title": "Integrating with Datadog Forwarder",
            "text": "<p>Use <code>flush_to_log=True</code> in <code>DatadogMetrics</code> to integrate with the legacy Datadog Forwarder.</p> <p>This will serialize and flush metrics to standard output.</p> flush_metrics_to_standard_output.pylog_metrics_standard_output.json <pre><code>from aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = DatadogMetrics(flush_to_log=True)\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", value=1)\n</code></pre> <pre><code>{\n   \"m\":\"SuccessfulBooking\",\n   \"v\":1,\n   \"e\":1691768022,\n   \"t\":[\n\n   ]\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/datadog/#testing-your-code",
            "title": "Testing your code",
            "text": ""
        },
        {
            "location": "core/metrics/datadog/#setting-environment-variables",
            "title": "Setting environment variables",
            "text": "Tip <p>Ignore this section, if:</p> <ul> <li>You are explicitly setting namespace via <code>namespace</code> parameter</li> <li>You're not instantiating <code>DatadogMetrics</code> in the global namespace</li> </ul> <p>For example, <code>DatadogMetrics(namespace=\"ServerlessAirline\")</code></p> <p>Make sure to set <code>POWERTOOLS_METRICS_NAMESPACE</code> before running your tests to prevent failing on <code>SchemaValidation</code> exception. You can set it before you run tests or via pytest plugins like dotenv.</p> Injecting dummy metric namespace before running tests<pre><code>POWERTOOLS_METRICS_NAMESPACE=\"ServerlessAirline\" DD_FLUSH_TO_LOG=\"True\" python -m pytest # (1)!\n</code></pre> <ol> <li><code>DD_FLUSH_TO_LOG=True</code> makes it easier to test by flushing final metrics to standard output.</li> </ol>"
        },
        {
            "location": "core/metrics/datadog/#clearing-metrics",
            "title": "Clearing metrics",
            "text": "<p><code>DatadogMetrics</code> keep metrics in memory across multiple instances. If you need to test this behavior, you can use the following Pytest fixture to ensure metrics are reset incl. cold start:</p> Clearing metrics between tests<pre><code>import pytest\n\nfrom aws_lambda_powertools.metrics.provider import cold_start\nfrom aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\n\n\n@pytest.fixture(scope=\"function\", autouse=True)\ndef reset_metric_set():\n    # Clear out every metric data prior to every test\n    metrics = DatadogMetrics()\n    metrics.clear_metrics()\n    cold_start.is_cold_start = True  # ensure each test has cold start\n    yield\n</code></pre>"
        },
        {
            "location": "core/metrics/datadog/#functional-testing",
            "title": "Functional testing",
            "text": "<p>You can read standard output and assert whether metrics have been flushed. Here's an example using <code>pytest</code> with <code>capsys</code> built-in fixture:</p> assert_single_datadog_metric.pyadd_datadog_metrics.py <pre><code>import add_datadog_metrics\n\n\ndef test_log_metrics(capsys):\n    add_datadog_metrics.lambda_handler({}, {})\n\n    log = capsys.readouterr().out.strip()  # remove any extra line\n\n    assert \"SuccessfulBooking\" in log  # basic string assertion in JSON str\n</code></pre> <pre><code>from aws_lambda_powertools.metrics.provider.datadog import DatadogMetrics\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nmetrics = DatadogMetrics()\n\n\n@metrics.log_metrics  # ensures metrics are flushed upon request completion/failure\ndef lambda_handler(event: dict, context: LambdaContext):\n    metrics.add_metric(name=\"SuccessfulBooking\", value=1)\n</code></pre> Tip <p>For more elaborate assertions and comparisons, check out our functional testing for DatadogMetrics utility.</p>"
        },
        {
            "location": "diagram_src/cicd_steps/",
            "title": "Cicd steps",
            "text": "<pre><code>timeline\n    title Powertools for AWS Lambda (Python) CI/CD pipeline\n\n    section Continuous Integration\n    Project setup &lt;br&gt; (make dev)   : Code checkout\n                                    : Virtual environment\n                                    : Dependencies\n                                    : Git pre-commit hooks\n                                    : Local branch\n                                    : Local changes\n                                    : Local tests\n\n    Pre-commit checks &lt;br&gt; (git commit)     : Merge conflict check\n                                            : Trailing whitespaces\n                                            : TOML checks\n                                            : Code linting (standards)\n                                            : Markdown linting\n                                            : CloudFormation linting\n                                            : GitHub Actions linting\n                                            : Terraform linting\n                                            : Secrets linting\n\n    Pre-Pull Request &lt;br&gt; (make pr)     : Code linting\n                                        : Docs linting\n                                        : Static typing analysis\n                                        : Tests (unit|functional|perf)\n                                        : Security baseline\n                                        : Complexity baseline\n                                        : +pre-commit checks\n\n    Pull Request &lt;br&gt; (CI checks)   : Semantic PR title check\n                                    : Related issue check\n                                    : Acknowledgment check\n                                    : Code coverage diff\n                                    : Contribution size check\n                                    : Contribution category check\n                                    : Dependency vulnerability check\n                                    : GitHub Actions security check\n                                    : +pre-pull request checks\n\n    After merge &lt;br&gt; (CI checks)    : End-to-end tests\n                                    : Longer SAST check\n                                    : Security posture check (scorecard)\n                                    : GitHub Actions security check\n                                    : Rebuild Changelog\n                                    : Deploy staging docs\n                                    : Update draft release\n\n    section Continuous Delivery\n\n    Source code anti-tampering  : Checkout release commit code\n                                : Bump release version\n                                : Seal and upload artifact\n\n    Quality Assurance           : Restore sealed code\n                                : +Continuous Integration checks\n\n    Build                       : Restore sealed code\n                                : Integrity check\n                                : Build release artifact\n                                : Seal and upload artifact\n\n    Provenance                  : Detect build environment\n                                : Generate SLSA Builder\n                                : Verify SLSA Builder provenance\n                                : Create and sign provenance\n                                : Seal and upload artifact\n                                : Write to public ledger\n\n    Release                     : Restore sealed build\n                                : Integrity check\n                                : PyPi ephemeral credentials\n                                : Publish PyPi\n                                : Baking time\n\n    Git tagging                 : Restore sealed code\n                                : Integrity check\n                                : Bump git tag\n                                : Create temporary branch\n                                : Create PR\n\n    Lambda Layers               : Fetch PyPi release\n                                : Build x86_64 architecture\n                                : Build ARM architecture\n                                : Deploy Beta\n                                : Canary testing\n                                : Deploy Prod\n\n    Lambda Layers SAR           : Deploy Beta\n                                : Deploy Prod\n\n    Documentation               : Update Lambda Layer ARNs\n                                : Build User Guide\n                                : Build API Guide\n                                : Rebuild Changelog\n                                : Release new version\n                                : Update latest alias\n                                : Create temporary branch\n                                : Create PR\n\n    Post-release                : Close pending-release issues\n                                : Notify customers</code></pre>"
        },
        {
            "location": "includes/_layer_homepage_arm64/",
            "title": "layer homepage arm64",
            "text": "Click to expand and copy any regional Lambda Layer ARN Python 3.9Python 3.10Python 3.11Python 3.12Python 3.13 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-arm64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-arm64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-arm64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-arm64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-arm64:12"
        },
        {
            "location": "includes/_layer_homepage_x86/",
            "title": "layer homepage x86",
            "text": "Click to expand and copy any regional Lambda Layer ARN Python 3.9Python 3.10Python 3.11Python 3.12Python 3.13 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>ca-west-1</code> arn:aws:lambda:ca-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python39-x86_64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>ca-west-1</code> arn:aws:lambda:ca-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python310-x86_64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>ca-west-1</code> arn:aws:lambda:ca-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python311-x86_64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>ca-west-1</code> arn:aws:lambda:ca-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python312-x86_64:12 Region Layer ARN <code>af-south-1</code> arn:aws:lambda:af-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>ca-west-1</code> arn:aws:lambda:ca-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-central-2</code> arn:aws:lambda:eu-central-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>il-central-1</code> arn:aws:lambda:il-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>me-central-1</code> arn:aws:lambda:me-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>me-south-1</code> arn:aws:lambda:me-south-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>us-east-1</code> arn:aws:lambda:us-east-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>us-east-2</code> arn:aws:lambda:us-east-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>us-west-1</code> arn:aws:lambda:us-west-1:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12 <code>us-west-2</code> arn:aws:lambda:us-west-2:017000801446:layer:AWSLambdaPowertoolsPythonV3-python313-x86_64:12"
        },
        {
            "location": "tutorial/",
            "title": "Tutorial",
            "text": "<p>This tutorial progressively introduces Powertools for AWS Lambda (Python) core utilities by using one feature at a time.</p>"
        },
        {
            "location": "tutorial/#requirements",
            "title": "Requirements",
            "text": "<ul> <li>AWS CLI and configured with your credentials.</li> <li>AWS SAM CLI installed.</li> </ul>"
        },
        {
            "location": "tutorial/#getting-started",
            "title": "Getting started",
            "text": "<p>Let's clone our sample project before we add one feature at a time.</p> Tip: Want to skip to the final project? <p>Bootstrap directly via SAM CLI:</p> <pre><code>sam init --app-template hello-world-powertools-python --name sam-app --package-type Zip --runtime python3.13 --no-tracing\n</code></pre> Use SAM CLI to initialize the sample project<pre><code>sam init --runtime python3.13 --dependency-manager pip --app-template hello-world --name powertools-quickstart\n</code></pre>"
        },
        {
            "location": "tutorial/#project-structure",
            "title": "Project structure",
            "text": "<p>As we move forward, we will modify the following files within the <code>powertools-quickstart</code> folder:</p> <ul> <li>app.py - Application code.</li> <li>template.yaml - AWS infrastructure configuration using SAM.</li> <li>requirements.txt - List of extra Python packages needed.</li> </ul>"
        },
        {
            "location": "tutorial/#code-example",
            "title": "Code example",
            "text": "<p>Let's configure our base application to look like the following code snippet.</p> app.pytemplate.yaml <pre><code>import json\n\n\ndef hello():\n    return {\"statusCode\": 200, \"body\": json.dumps({\"message\": \"hello unknown!\"})}\n\n\ndef lambda_handler(event, context):\n    return hello()\n</code></pre> <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: Sample SAM Template for powertools-quickstart\nGlobals:\n    Function:\n        Timeout: 3\nResources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n            CodeUri: hello_world/\n            Handler: app.lambda_handler\n            Runtime: python3.9\n            Architectures:\n                - x86_64\n            Events:\n                HelloWorld:\n                    Type: Api\n                    Properties:\n                        Path: /hello\n                        Method: get\nOutputs:\n    HelloWorldApi:\n        Description: \"API Gateway endpoint URL for Prod stage for Hello World function\"\n        Value: !Sub \"https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/\"\n</code></pre> <p>Our Lambda code consists of an entry point function named <code>lambda_handler</code>, and a <code>hello</code> function.</p> <p>When API Gateway receives a HTTP GET request on <code>/hello</code> route, Lambda will call our <code>lambda_handler</code> function, subsequently calling the <code>hello</code> function. API Gateway will use this response to return the correct HTTP Status Code and payload back to the caller.</p> Warning <p>For simplicity, we do not set up authentication and authorization! You can find more information on how to implement it on AWS SAM documentation.</p>"
        },
        {
            "location": "tutorial/#run-your-code",
            "title": "Run your code",
            "text": "<p>At each point, you have two ways to run your code: locally and within your AWS account.</p>"
        },
        {
            "location": "tutorial/#local-test",
            "title": "Local test",
            "text": "<p>AWS SAM allows you to execute a serverless application locally by running <code>sam build &amp;&amp; sam local start-api</code> in your preferred shell.</p> Build and run API Gateway locally<pre><code>&gt; sam build &amp;&amp; sam local start-api\n...\n2021-11-26 17:43:08  * Running on http://127.0.0.1:3000/ (Press CTRL+C to quit)\n</code></pre> <p>As a result, a local API endpoint will be exposed and you can invoke it using your browser, or your preferred HTTP API client e.g., Postman, httpie, etc.</p> Invoking our function locally via curl<pre><code>&gt; curl http://127.0.0.1:3000/hello\n{\"message\": \"hello unknown!\"}\n</code></pre> Info <p>To learn more about local testing, please visit the AWS SAM CLI local testing documentation.</p>"
        },
        {
            "location": "tutorial/#live-test",
            "title": "Live test",
            "text": "<p>First, you need to deploy your application into your AWS Account by issuing <code>sam build &amp;&amp; sam deploy --guided</code> command. This command builds a ZIP package of your source code, and deploy it to your AWS Account.</p> Build and deploy your serverless application<pre><code>&gt; sam build &amp;&amp; sam deploy --guided\n...\nCloudFormation outputs from deployed stack\n------------------------------------------------------------------------------------------------------------------------------------------\nOutputs\n------------------------------------------------------------------------------------------------------------------------------------------\nKey                 HelloWorldFunctionIamRole\nDescription         Implicit IAM Role created for Hello World function\nValue               arn:aws:iam::123456789012:role/sam-app-HelloWorldFunctionRole-1T2W3H9LZHGGV\n\nKey                 HelloWorldApi\nDescription         API Gateway endpoint URL for Prod stage for Hello World function\nValue               https://1234567890.execute-api.eu-central-1.amazonaws.com/Prod/hello/\n\nKey                 HelloWorldFunction\nDescription         Hello World Lambda Function ARN\nValue               arn:aws:lambda:eu-central-1:123456789012:function:sam-app-HelloWorldFunction-dOcfAtYoEiGo\n------------------------------------------------------------------------------------------------------------------------------------------\nSuccessfully created/updated stack - sam-app in eu-central-1\n</code></pre> <p>At the end of the deployment, you will find the API endpoint URL within <code>Outputs</code> section. You can use this URL to test your serverless application.</p> Invoking our application via API endpoint<pre><code>&gt; curl https://1234567890.execute-api.eu-central-1.amazonaws.com/Prod/hello\n{\"message\": \"hello unknown!\"}%\n</code></pre> Info <p>For more details on AWS SAM deployment mechanism, see SAM Deploy reference docs.</p>"
        },
        {
            "location": "tutorial/#routing",
            "title": "Routing",
            "text": ""
        },
        {
            "location": "tutorial/#adding-a-new-route",
            "title": "Adding a new route",
            "text": "<p>Let's expand our application with a new route - <code>/hello/{name}</code>. It will accept an username as a path input and return it in the response.</p> <p>For this to work, we could create a new Lambda function to handle incoming requests for <code>/hello/{name}</code> - It'd look like this:</p> hello_by_name.pytemplate.yaml <pre><code>import json\n\n\ndef hello_name(name):\n    return {\"statusCode\": 200, \"body\": json.dumps({\"message\": f\"hello {name}!\"})}\n\n\ndef lambda_handler(event, context):\n    name = event[\"pathParameters\"][\"name\"]\n    return hello_name(name)\n</code></pre> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Sample SAM Template for powertools-quickstart\nGlobals:\n    Function:\n        Timeout: 3\nResources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n            CodeUri: hello_world/\n            Handler: app.lambda_handler\n            Runtime: python3.9\n            Events:\n                HelloWorld:\n                    Type: Api\n                    Properties:\n                        Path: /hello\n                        Method: get\n\n    HelloWorldByNameFunctionName:\n        Type: AWS::Serverless::Function\n        Properties:\n            CodeUri: hello_world/\n            Handler: hello_by_name.lambda_handler\n            Runtime: python3.9\n            Events:\n                HelloWorldName:\n                    Type: Api\n                    Properties:\n                        Path: /hello/{name}\n                        Method: get\nOutputs:\n    HelloWorldApi:\n        Description: \"API Gateway endpoint URL for Prod stage for Hello World function\"\n        Value: !Sub \"https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/\"\n</code></pre> Question <p>But what happens if your application gets bigger and we need to cover numerous URL paths and HTTP methods for them?</p> <p>This would quickly become non-trivial to maintain. Adding new Lambda function for each path, or multiple if/else to handle several routes &amp; HTTP Methods can be error prone.</p>"
        },
        {
            "location": "tutorial/#creating-our-own-router",
            "title": "Creating our own router",
            "text": "Question <p>What if we create a simple router to reduce boilerplate?</p> <p>We could group similar routes and intents, separate read and write operations resulting in fewer functions. It doesn't address the boilerplate routing code, but maybe it will be easier to add additional URLs.</p> Info: You might be already asking yourself about mono vs micro-functions <p>If you want a more detailed explanation of these two approaches, head over to the trade-offs on each approach later.</p> <p>A first attempt at the routing logic might look similar to the following code snippet.</p> app.pytemplate.yaml <pre><code>import json\n\n\ndef hello_name(event, **kargs):\n    username = event[\"pathParameters\"][\"name\"]\n    return {\"statusCode\": 200, \"body\": json.dumps({\"message\": f\"hello {username}!\"})}\n\n\ndef hello(**kargs):\n    return {\"statusCode\": 200, \"body\": json.dumps({\"message\": \"hello unknown!\"})}\n\n\nclass Router:\n    def __init__(self):\n        self.routes = {}\n\n    def set(self, path, method, handler):\n        self.routes[f\"{path}-{method}\"] = handler\n\n    def get(self, path, method):\n        try:\n            route = self.routes[f\"{path}-{method}\"]\n        except KeyError:\n            raise RuntimeError(f\"Cannot route request to the correct method. path={path}, method={method}\")\n        return route\n\nrouter = Router()\nrouter.set(path=\"/hello\", method=\"GET\", handler=hello)\nrouter.set(path=\"/hello/{name}\", method=\"GET\", handler=hello_name)\n\n\ndef lambda_handler(event, context):\n    path = event[\"resource\"]\n    http_method = event[\"httpMethod\"]\n    method = router.get(path=path, method=http_method)\n    return method(event=event)\n</code></pre> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Sample SAM Template for powertools-quickstart\nGlobals:\n    Function:\n        Timeout: 3\nResources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n            CodeUri: hello_world/\n            Handler: app.lambda_handler\n            Runtime: python3.9\n            Events:\n                HelloWorld:\n                    Type: Api\n                    Properties:\n                        Path: /hello\n                        Method: get\n                HelloWorldName:\n                    Type: Api\n                    Properties:\n                        Path: /hello/{name}\n                        Method: get\nOutputs:\n    HelloWorldApi:\n        Description: \"API Gateway endpoint URL for Prod stage for Hello World function\"\n        Value: !Sub \"https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/\"\n</code></pre> <p>Let's break this down:</p> <ul> <li>L4,9: We defined two <code>hello_name</code> and <code>hello</code> functions to handle <code>/hello/{name}</code> and <code>/hello</code> routes.</li> <li>L13: We added a <code>Router</code> class to map a path, a method, and the function to call.</li> <li>L27-29: We create a <code>Router</code> instance and map both <code>/hello</code> and <code>/hello/{name}</code>.</li> <li>L35: We use Router's <code>get</code> method to retrieve a reference to the processing method (<code>hello</code> or <code>hello_name</code>).</li> <li>L36: Finally, we run this method and send the results back to API Gateway.</li> </ul> <p>This approach simplifies the configuration of our infrastructure since we have added all API Gateway paths in the <code>HelloWorldFunction</code> event section.</p> <p>However, it forces us to understand the internal structure of the API Gateway request events, responses, and it could lead to other errors such as CORS not being handled properly, error handling, etc.</p>"
        },
        {
            "location": "tutorial/#simplifying-with-event-handler",
            "title": "Simplifying with Event Handler",
            "text": "<p>We can massively simplify cross-cutting concerns while keeping it lightweight by using Event Handler.</p> Tip <p>This is available for both REST API (API Gateway, ALB) and GraphQL API (AppSync).</p> <p>Let's include Powertools for AWS Lambda (Python) as a dependency in <code>requirement.txt</code>, and use Event Handler to refactor our previous example.</p> app.pyrequirements.txt <pre><code>from aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\ndef hello_name(name):\n    return {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\ndef hello():\n    return {\"message\": \"hello unknown!\"}\n\n\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <pre><code>aws-lambda-powertools[tracer]  # Tracer requires AWS X-Ray SDK dependency\n</code></pre> <p>Use <code>sam build &amp;&amp; sam local start-api</code> and try run it locally again.</p> Note <p>If you're coming from Flask, you will be familiar with this experience already. Event Handler for API Gateway uses <code>APIGatewayRestResolver</code> to give a Flask-like experience while staying true to our tenet <code>Keep it lean</code>.</p> <p>We have added the route annotation as the decorator for our methods. It enables us to use the parameters passed in the request directly, and our responses are simply dictionaries.</p> <p>Lastly, we used <code>return app.resolve(event, context)</code> so Event Handler can resolve routes, inject the current request, handle serialization, route validation, etc.</p> <p>From here, we could handle 404 routes, error handling, access query strings, payload, etc.</p> Tip <p>If you'd like to learn how python decorators work under the hood, you can follow Real Python's article.</p>"
        },
        {
            "location": "tutorial/#structured-logging",
            "title": "Structured Logging",
            "text": "<p>Over time, you realize that searching logs as text results in poor observability, it's hard to create metrics from, enumerate common exceptions, etc.</p> <p>Then, you decided to propose production quality logging capabilities to your Lambda code. You found out that by having logs as <code>JSON</code> you can structure them, so that you can use any Log Analytics tool out there to quickly analyze them.</p> <p>This helps not only in searching, but produces consistent logs containing enough context and data to ask arbitrary questions on the status of your system. We can take advantage of CloudWatch Logs and Cloudwatch Insight for this purpose.</p>"
        },
        {
            "location": "tutorial/#json-as-output",
            "title": "JSON as output",
            "text": "<p>The first option could be to use the standard Python Logger, and use a specialized library like <code>pythonjsonlogger</code> to create a JSON Formatter.</p> app.pyrequirements.txt <pre><code>import logging\nimport os\n\nfrom pythonjsonlogger import jsonlogger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\n\nlogger = logging.getLogger(\"APP\")\nlogHandler = logging.StreamHandler()\nformatter = jsonlogger.JsonFormatter(fmt=\"%(asctime)s %(levelname)s %(name)s %(message)s\")\nlogHandler.setFormatter(formatter)\nlogger.addHandler(logHandler)\nlogger.setLevel(os.getenv(\"POWERTOOLS_LOG_LEVEL\", \"INFO\"))\n\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\ndef hello_name(name):\n    logger.info(f\"Request from {name} received\")\n    return {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\ndef hello():\n    logger.info(\"Request from unknown received\")\n    return {\"message\": \"hello unknown!\"}\n\n\ndef lambda_handler(event, context):\n    logger.debug(event)\n    return app.resolve(event, context)\n</code></pre> <pre><code>aws-lambda-powertools\npython-json-logger\n</code></pre> <p>With just a few lines our logs will now output to <code>JSON</code> format. We've taken the following steps to make that work:</p> <ul> <li>L7: Creates an application logger named <code>APP</code>.</li> <li>L8-11: Configures handler and formatter.</li> <li>L12: Sets the logging level set in the <code>POWERTOOLS_LOG_LEVEL</code> environment variable, or <code>INFO</code> as a sentinel value.</li> </ul> <p>After that, we use this logger in our application code to record the required information. We see logs structured as follows:</p> JSON outputNormal output <pre><code>{\n    \"asctime\": \"2021-11-22 15:32:02,145\",\n    \"levelname\": \"INFO\",\n    \"name\": \"APP\",\n    \"message\": \"Request from unknown received\"\n}\n</code></pre> <pre><code>[INFO]  2021-11-22T15:32:02.145Z        ba3bea3d-fe3a-45db-a2ce-72e813d55b91    Request from unknown received\n</code></pre> <p>So far, so good! We can take a step further now by adding additional context to the logs.</p> <p>We could start by creating a dictionary with Lambda context information or something from the incoming event, which should always be logged. Additional attributes could be added on every <code>logger.info</code> using <code>extra</code> keyword like in any standard Python logger.</p>"
        },
        {
            "location": "tutorial/#simplifying-with-logger",
            "title": "Simplifying with Logger",
            "text": "Surely this could be easier, right? <p>Yes! Powertools for AWS Lambda (Python) Logger to the rescue :-)</p> <p>As we already have Powertools for AWS Lambda (Python) as a dependency, we can simply import Logger.</p> Refactoring with Powertools for AWS Lambda (Python) Logger<pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\n\nlogger = Logger(service=\"APP\")\n\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\ndef hello_name(name):\n    logger.info(f\"Request from {name} received\")\n    return {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\ndef hello():\n    logger.info(\"Request from unknown received\")\n    return {\"message\": \"hello unknown!\"}\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST, log_event=True)\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <p>Let's break this down:</p> <ul> <li>L5: We add Powertools for AWS Lambda (Python) Logger; the boilerplate is now done for you. By default, we set <code>INFO</code> as the logging level if <code>POWERTOOLS_LOG_LEVEL</code> env var isn't set.</li> <li>L22: We use <code>logger.inject_lambda_context</code> decorator to inject key information from Lambda context into every log.</li> <li>L22: We also instruct Logger to use the incoming API Gateway Request ID as a correlation id automatically.</li> <li>L22: Since we're in dev, we also use <code>log_event=True</code> to automatically log each incoming request for debugging. This can be also set via environment variables.</li> </ul> <p>This is how the logs would look like now:</p> Our logs are now structured consistently<pre><code>{\n    \"level\":\"INFO\",\n    \"location\":\"hello:17\",\n    \"message\":\"Request from unknown received\",\n    \"timestamp\":\"2021-10-22 16:29:58,367+0000\",\n    \"service\":\"APP\",\n    \"cold_start\":true,\n    \"function_name\":\"HelloWorldFunction\",\n    \"function_memory_size\":\"256\",\n    \"function_arn\":\"arn:aws:lambda:us-east-1:123456789012:function:HelloWorldFunction\",\n    \"function_request_id\":\"d50bb07a-7712-4b2d-9f5d-c837302221a2\",\n    \"correlation_id\":\"bf9b584c-e5d9-4ad5-af3d-db953f2b10dc\"\n}\n</code></pre> <p>We can now search our logs by the request ID to find a specific operation. Additionally, we can also search our logs for function name, Lambda request ID, Lambda function ARN, find out whether an operation was a cold start, etc.</p> <p>From here, we could set specific keys to add additional contextual information about a given operation, log exceptions to easily enumerate them later, sample debug logs, etc.</p> <p>By having structured logs like this, we can easily search and analyse them in CloudWatch Logs Insight.</p> CloudWatch Logs Insight Example <p></p>"
        },
        {
            "location": "tutorial/#tracing",
            "title": "Tracing",
            "text": "Note <p>You won't see any traces in AWS X-Ray when executing your function locally.</p> <p>The next improvement is to add distributed tracing to your stack. Traces help you visualize end-to-end transactions or parts of it to easily debug upstream/downstream anomalies.</p> <p>Combined with structured logs, it is an important step to be able to observe how your application runs in production.</p>"
        },
        {
            "location": "tutorial/#generating-traces",
            "title": "Generating traces",
            "text": "<p>AWS X-Ray is the distributed tracing service we're going to use. But how do we generate application traces in the first place?</p> <p>It's a two-step process:</p> <ol> <li>Enable tracing in your Lambda function.</li> <li>Instrument your application code.</li> </ol> <p>Let's explore how we can instrument our code with AWS X-Ray SDK, and then simplify it with Powertools for AWS Lambda (Python) Tracer feature.</p> app.pytemplate.yamlrequirements.txt <pre><code>from aws_xray_sdk.core import xray_recorder\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\n\nlogger = Logger(service=\"APP\")\n\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\n@xray_recorder.capture('hello_name')\ndef hello_name(name):\n    logger.info(f\"Request from {name} received\")\n    return {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\n@xray_recorder.capture('hello')\ndef hello():\n    logger.info(\"Request from unknown received\")\n    return {\"message\": \"hello unknown!\"}\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST, log_event=True)\n@xray_recorder.capture('handler')\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Sample SAM Template for powertools-quickstart\nGlobals:\n    Function:\n        Timeout: 3\n    Api:\n      TracingEnabled: true\nResources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n            CodeUri: hello_world/\n            Handler: app.lambda_handler\n            Runtime: python3.9\n            Tracing: Active\n            Events:\n                HelloWorld:\n                    Type: Api\n                    Properties:\n                        Path: /hello\n                        Method: get\n                HelloWorldName:\n                    Type: Api\n                    Properties:\n                        Path: /hello/{name}\n                        Method: get\nOutputs:\n    HelloWorldApi:\n        Description: \"API Gateway endpoint URL for Prod stage for Hello World function\"\n        Value: !Sub \"https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/\"\n</code></pre> <pre><code>aws-lambda-powertools\naws-xray-sdk\n</code></pre> <p>Let's break it down:</p> <ul> <li>L1: First, we import AWS X-Ray SDK. <code>xray_recorder</code> records blocks of code being traced (subsegment). It also sends generated traces to the AWS X-Ray daemon running in the Lambda service who subsequently forwards them to AWS X-Ray service.</li> <li>L13,20,27: We decorate our function so the SDK traces the end-to-end execution, and the argument names the generated block being traced.</li> </ul> Question <p>But how do I enable tracing for the Lambda function and what permissions do I need?</p> <p>We've made the following changes in <code>template.yaml</code> for this to work seamless:</p> <ul> <li>L7-8: Enables tracing for Amazon API Gateway.</li> <li>L16: Enables tracing for our Serverless Function. This will also add a managed IAM Policy named AWSXRayDaemonWriteAccess to allow Lambda to send traces to AWS X-Ray.</li> </ul> <p>You can now build and deploy our updates with <code>sam build &amp;&amp; sam deploy</code>. Once deployed, try invoking the application via the API endpoint, and visit AWS X-Ray Console to see how much progress we've made so far!!</p> <p></p>"
        },
        {
            "location": "tutorial/#enriching-our-generated-traces",
            "title": "Enriching our generated traces",
            "text": "<p>What we've done helps bring an initial visibility, but we can do so much more.</p> Question <p>You're probably asking yourself at least the following questions:</p> <ul> <li>What if I want to search traces by customer name?</li> <li>What about grouping traces with cold starts?</li> <li>Better yet, what if we want to include the request or response of our functions as part of the trace?</li> </ul> <p>Within AWS X-Ray, we can answer these questions by using two features: tracing Annotations and Metadata.</p> <p>Annotations are simple key-value pairs that are indexed for use with filter expressions. Metadata are key-value pairs with values of any type, including objects and lists, but that are not indexed.</p> <p>Let's put them into action.</p> Enriching traces with annotations and metadata<pre><code>from aws_xray_sdk.core import patch_all, xray_recorder\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\n\nlogger = Logger(service=\"APP\")\n\napp = APIGatewayRestResolver()\ncold_start = True\npatch_all()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\n@xray_recorder.capture('hello_name')\ndef hello_name(name):\n    subsegment = xray_recorder.current_subsegment()\n    subsegment.put_annotation(key=\"User\", value=name)\n    logger.info(f\"Request from {name} received\")\n    return {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\n@xray_recorder.capture('hello')\ndef hello():\n    subsegment = xray_recorder.current_subsegment()\n    subsegment.put_annotation(key=\"User\", value=\"unknown\")\n    logger.info(\"Request from unknown received\")\n    return {\"message\": \"hello unknown!\"}\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST, log_event=True)\n@xray_recorder.capture('handler')\ndef lambda_handler(event, context):\n    global cold_start\n\n    subsegment = xray_recorder.current_subsegment()\n    subsegment.put_annotation(key=\"ColdStart\", value=cold_start)\n\n    if cold_start:\n        cold_start = False\n\n    result = app.resolve(event, context)\n    subsegment.put_metadata(\"response\", result)\n\n    return result\n</code></pre> <p>Let's break it down:</p> <ul> <li>L10: We track Lambda cold start by setting global variable outside the handler; this is executed once per sandbox Lambda creates. This information provides an overview of how often the sandbox is reused by Lambda, which directly impacts the performance of each transaction.</li> <li>L17-18: We use AWS X-Ray SDK to add <code>User</code> annotation on <code>hello_name</code> subsegment. This will allow us to filter traces using the <code>User</code> value.</li> <li>L26-27: We repeat what we did in L17-18 except we use the value <code>unknown</code> since we don't have that information.</li> <li>L35: We use <code>global</code> to modify our global variable defined in the outer scope.</li> <li>37-41: We add <code>ColdStart</code> annotation and set <code>cold_start</code> variable to <code>false</code>, so that subsequent requests annotates the value <code>false</code> when the sandbox is reused.</li> <li>L44: We include the final response under <code>response</code> key as part of the <code>handler</code> subsegment.</li> </ul> Info <p>If you want to understand how the Lambda execution environment (sandbox) works and why cold starts can occur, see this blog series on Lambda performance.</p> <p>Repeat the process of building, deploying, and invoking your application via the API endpoint.</p> <p>Within the AWS X-Ray Console, you should now be able to group traces by the <code>User</code> and <code>ColdStart</code> annotation.</p> <p></p> <p>If you choose any of the traces available, try opening the <code>handler</code> subsegment and you should see the response of your Lambda function under the <code>Metadata</code> tab.</p> <p></p>"
        },
        {
            "location": "tutorial/#simplifying-with-tracer",
            "title": "Simplifying with Tracer",
            "text": "<p>Cross-cutting concerns like filtering traces by Cold Start, including response as well as exceptions as tracing metadata can take a considerable amount of boilerplate.</p> <p>We can simplify our previous patterns by using Powertools for AWS Lambda (Python) Tracer; a thin wrapper on top of X-Ray SDK.</p> Note <p>You can now safely remove <code>aws-xray-sdk</code> from <code>requirements.txt</code>; keep <code>aws-lambda-powertools[tracer]</code> only.</p> Refactoring with Powertools for AWS Lambda (Python) Tracer<pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\n\nlogger = Logger(service=\"APP\")\ntracer = Tracer(service=\"APP\")\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\n@tracer.capture_method\ndef hello_name(name):\n    tracer.put_annotation(key=\"User\", value=name)\n    logger.info(f\"Request from {name} received\")\n    return {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\n@tracer.capture_method\ndef hello():\n    tracer.put_annotation(key=\"User\", value=\"unknown\")\n    logger.info(\"Request from unknown received\")\n    return {\"message\": \"hello unknown!\"}\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST, log_event=True)\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <p>Decorators, annotations and metadata are largely the same, except we now have a much cleaner code as the boilerplate is gone. Here's what's changed compared to AWS X-Ray SDK approach:</p> <ul> <li>L6: We initialize <code>Tracer</code> and define the name of our service (<code>APP</code>). We automatically run <code>patch_all</code> from AWS X-Ray SDK on your behalf. Any previously patched or non-imported library is simply ignored.</li> <li>L11: We use <code>@tracer.capture_method</code> decorator instead of <code>xray_recorder.capture</code>. We automatically create a subsegment named after the function name (<code>## hello_name</code>), and add the response/exception as tracing metadata.</li> <li>L13: Putting annotations remain exactly the same UX.</li> <li>L27: We use <code>@tracer.lambda_handler</code> so we automatically add <code>ColdStart</code> annotation within Tracer itself. We also add a new <code>Service</code> annotation using the value of <code>Tracer(service=\"APP\")</code>, so that you can filter traces by the service your function(s) represent.</li> </ul> <p>Another subtle difference is that you can now run your Lambda functions and unit test them locally without having to explicitly disable Tracer.</p> <p>Powertools for AWS Lambda (Python) optimizes for Lambda compute environment. As such, we add these and other common approaches to accelerate your development, so you don't worry about implementing every cross-cutting concern.</p> Tip <p>You can opt-out some of these behaviours like disabling response capturing,  explicitly patching only X modules, etc.</p> <p>Repeat the process of building, deploying, and invoking your application via the API endpoint. Within the AWS X-Ray Console, you should see a similar view:</p> <p></p> Tip <p>Consider using Amazon CloudWatch ServiceLens view as it aggregates AWS X-Ray traces and CloudWatch metrics and logs in one view.</p> <p>From here, you can browse to specific logs in CloudWatch Logs Insight, Metrics Dashboard or AWS X-Ray traces.</p> <p></p> Info <p>For more information on Amazon CloudWatch ServiceLens, please visit link.</p>"
        },
        {
            "location": "tutorial/#custom-metrics",
            "title": "Custom Metrics",
            "text": ""
        },
        {
            "location": "tutorial/#creating-metrics",
            "title": "Creating metrics",
            "text": "<p>Let's add custom metrics to better understand our application and business behavior (e.g. number of reservations, etc.).</p> <p>By default, AWS Lambda adds invocation and performance metrics, and Amazon API Gateway adds latency and some HTTP metrics.</p> Tip <p>You can optionally enable detailed metrics per each API route, stage, and method in API Gateway.</p> <p>Let's expand our application with custom metrics using AWS SDK to see how it works, then let's upgrade it with Powertools for AWS Lambda (Python) :-)</p> app.pytemplate.yaml <pre><code>import os\n\nimport boto3\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\n\ncold_start = True\nmetric_namespace = \"MyApp\"\n\nlogger = Logger(service=\"APP\")\ntracer = Tracer(service=\"APP\")\nmetrics = boto3.client(\"cloudwatch\")\napp = APIGatewayRestResolver()\n\n\n@tracer.capture_method\ndef add_greeting_metric(service: str = \"APP\"):\n    function_name = os.getenv(\"AWS_LAMBDA_FUNCTION_NAME\", \"undefined\")\n    service_dimension = {\"Name\": \"service\", \"Value\": service}\n    function_dimension = {\"Name\": \"function_name\", \"Value\": function_name}\n    is_cold_start = True\n\n    global cold_start\n    if cold_start:\n        cold_start = False\n    else:\n        is_cold_start = False\n\n    return metrics.put_metric_data(\n        MetricData=[\n            {\n                \"MetricName\": \"SuccessfulGreetings\",\n                \"Dimensions\": [service_dimension],\n                \"Unit\": \"Count\",\n                \"Value\": 1,\n            },\n            {\n                \"MetricName\": \"ColdStart\",\n                \"Dimensions\": [service_dimension, function_dimension],\n                \"Unit\": \"Count\",\n                \"Value\": int(is_cold_start)\n            }\n        ],\n        Namespace=metric_namespace,\n    )\n\n\n@app.get(\"/hello/&lt;name&gt;\")\n@tracer.capture_method\ndef hello_name(name):\n    tracer.put_annotation(key=\"User\", value=name)\n    logger.info(f\"Request from {name} received\")\n    add_greeting_metric()\n    return {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\n@tracer.capture_method\ndef hello():\n    tracer.put_annotation(key=\"User\", value=\"unknown\")\n    logger.info(\"Request from unknown received\")\n    add_greeting_metric()\n    return {\"message\": \"hello unknown!\"}\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST, log_event=True)\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context):\n    return app.resolve(event, context)\n</code></pre> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Sample SAM Template for powertools-quickstart\nGlobals:\n    Function:\n        Timeout: 3\nResources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n            CodeUri: hello_world/\n            Handler: app.lambda_handler\n            Runtime: python3.9\n            Tracing: Active\n            Events:\n                HelloWorld:\n                    Type: Api\n                    Properties:\n                        Path: /hello\n                        Method: get\n                HelloWorldName:\n                    Type: Api\n                    Properties:\n                        Path: /hello/{name}\n                        Method: get\n            Policies:\n                - CloudWatchPutMetricPolicy: {}\nOutputs:\n    HelloWorldApi:\n        Description: \"API Gateway endpoint URL for Prod stage for Hello World function\"\n        Value: !Sub \"https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/\"\n</code></pre> <p>There's a lot going on, let's break this down:</p> <ul> <li>L10: We define a container where all of our application metrics will live <code>MyApp</code>, a.k.a Metrics Namespace.</li> <li>L14: We initialize a CloudWatch client to send metrics later.</li> <li>L19-47: We create a custom function to prepare and send <code>ColdStart</code> and <code>SuccessfulGreetings</code> metrics using CloudWatch expected data structure. We also set dimensions of these metrics.<ul> <li>Think of them as metadata to define to slice and dice them later; an unique metric is a combination of metric name + metric dimension(s).</li> </ul> </li> <li>L55,64: We call our custom function to create metrics for every greeting received.</li> </ul> Question <p>But what permissions do I need to send metrics to CloudWatch?</p> <p>Within <code>template.yaml</code>, we add CloudWatchPutMetricPolicy policy in SAM.</p> Adding metrics via AWS SDK gives a lot of flexibility at a cost <p><code>put_metric_data</code> is a synchronous call to CloudWatch Metrics API. This means establishing a connection to CloudWatch endpoint, sending metrics payload, and waiting from a response.</p> <p>It will be visible in your AWS X-RAY traces as additional external call. Given your architecture scale, this approach might lead to disadvantages such as increased cost of measuring data collection and increased Lambda latency.</p>"
        },
        {
            "location": "tutorial/#simplifying-with-metrics",
            "title": "Simplifying with Metrics",
            "text": "<p>Powertools for AWS Lambda (Python) Metrics uses Amazon CloudWatch Embedded Metric Format (EMF) to create custom metrics asynchronously via a native integration with Lambda.</p> <p>In general terms, EMF is a specification that expects metrics in a JSON payload within CloudWatch Logs. Lambda ingests all logs emitted by a given function into CloudWatch Logs. CloudWatch automatically looks up for log entries that follow the EMF format and transforms them into a CloudWatch metric.</p> Info <p>If you are interested in the details of the EMF mechanism, follow blog post.</p> <p>Let's implement that using Metrics:</p> Refactoring with Powertools for AWS Lambda (Python) Metrics<pre><code>from aws_lambda_powertools import Logger, Tracer, Metrics\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.metrics import MetricUnit\n\n\nlogger = Logger(service=\"APP\")\ntracer = Tracer(service=\"APP\")\nmetrics = Metrics(namespace=\"MyApp\", service=\"APP\")\napp = APIGatewayRestResolver()\n\n\n@app.get(\"/hello/&lt;name&gt;\")\n@tracer.capture_method\ndef hello_name(name):\n    tracer.put_annotation(key=\"User\", value=name)\n    logger.info(f\"Request from {name} received\")\n    metrics.add_metric(name=\"SuccessfulGreetings\", unit=MetricUnit.Count, value=1)\n    return {\"message\": f\"hello {name}!\"}\n\n\n@app.get(\"/hello\")\n@tracer.capture_method\ndef hello():\n    tracer.put_annotation(key=\"User\", value=\"unknown\")\n    logger.info(\"Request from unknown received\")\n    metrics.add_metric(name=\"SuccessfulGreetings\", unit=MetricUnit.Count, value=1)\n    return {\"message\": \"hello unknown!\"}\n\n\n@tracer.capture_lambda_handler\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.API_GATEWAY_REST, log_event=True)\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event, context):\n    try:\n        return app.resolve(event, context)\n    except Exception as e:\n        logger.exception(e)\n        raise\n</code></pre> <p>That's a lot less boilerplate code! Let's break this down:</p> <ul> <li>L9: We initialize <code>Metrics</code> with our service name (<code>APP</code>) and metrics namespace (<code>MyApp</code>), reducing the need to add the <code>service</code> dimension for every metric and setting the namespace later</li> <li>L18, 27: We use <code>add_metric</code> similarly to our custom function, except we now have an enum <code>MetricCount</code> to help us understand which Metric Units we have at our disposal</li> <li>L33: We use <code>@metrics.log_metrics</code> decorator to ensure that our metrics are aligned with the EMF output and validated before-hand, like in case we forget to set namespace, or accidentally use a metric unit as a string that doesn't exist in CloudWatch.</li> <li>L33: We also use <code>capture_cold_start_metric=True</code> so we don't have to handle that logic either. Note that Metrics does not publish a warm invocation metric (ColdStart=0) for cost reasons. As such, treat the absence (sparse metric) as a non-cold start invocation.</li> </ul> <p>Repeat the process of building, deploying, and invoking your application via the API endpoint a few times to generate metrics - Artillery and K6.io are quick ways to generate some load.</p> <p>Within CloudWatch Metrics view, you should see <code>MyApp</code> custom namespace with your custom metrics there and <code>SuccessfulGreetings</code> available to graph.</p> <p></p> <p>If you're curious about how the EMF portion of your function logs look like, you can quickly go to CloudWatch ServiceLens view, choose your function and open logs. You will see a similar entry that looks like this:</p> <pre><code>{\n  \"_aws\": {\n    \"Timestamp\": 1638115724269,\n    \"CloudWatchMetrics\": [\n      {\n        \"Namespace\": \"CustomMetrics\",\n        \"Dimensions\": [\n          [\n            \"method\",\n            \"service\"\n          ]\n        ],\n        \"Metrics\": [\n          {\n            \"Name\": \"AppMethodsInvocations\",\n            \"Unit\": \"Count\"\n          }\n        ]\n      }\n    ]\n  },\n  \"method\": \"/hello/&lt;name&gt;\",\n  \"service\": \"APP\",\n  \"AppMethodsInvocations\": [\n    1\n  ]\n}\n</code></pre>"
        },
        {
            "location": "tutorial/#final-considerations",
            "title": "Final considerations",
            "text": "<p>We covered a lot of ground here and we only scratched the surface of the feature set available within Powertools for AWS Lambda (Python).</p> <p>When it comes to the observability features (Tracer, Metrics, Logging), don't stop there! The goal here is to ensure you can ask arbitrary questions to assess your system's health; these features are only part of the wider story!</p> <p>This requires a change in mindset to ensure operational excellence is part of the software development lifecycle.</p> Tip <p>You can find more details on other leading practices described in the Well-Architected Serverless Lens.</p> <p>Powertools for AWS Lambda (Python) is largely designed to make some of these practices easier to adopt from day 1.</p> Have ideas for other tutorials? <p>You can open up a documentation issue, or via e-mail aws-powertools-maintainers@amazon.com.</p>"
        },
        {
            "location": "utilities/batch/",
            "title": "Batch Processing",
            "text": "<p>The batch processing utility handles partial failures when processing batches from Amazon SQS, Amazon Kinesis Data Streams, and Amazon DynamoDB Streams.</p> <pre><code>stateDiagram-v2\n    direction LR\n    BatchSource: Amazon SQS &lt;br/&gt;&lt;br/&gt; Amazon Kinesis Data Streams &lt;br/&gt;&lt;br/&gt; Amazon DynamoDB Streams &lt;br/&gt;&lt;br/&gt;\n    LambdaInit: Lambda invocation\n    BatchProcessor: Batch Processor\n    RecordHandler: Record Handler function\n    YourLogic: Your logic to process each batch item\n    LambdaResponse: Lambda response\n\n    BatchSource --&gt; LambdaInit\n\n    LambdaInit --&gt; BatchProcessor\n    BatchProcessor --&gt; RecordHandler\n\n    state BatchProcessor {\n        [*] --&gt; RecordHandler: Your function\n        RecordHandler --&gt; YourLogic\n    }\n\n    RecordHandler --&gt; BatchProcessor: Collect results\n    BatchProcessor --&gt; LambdaResponse: Report items that failed processing</code></pre>"
        },
        {
            "location": "utilities/batch/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Reports batch item failures to reduce number of retries for a record upon errors</li> <li>Simple interface to process each batch record</li> <li>Integrates with Event Source Data Classes and Parser (Pydantic) for self-documenting record schema</li> <li>Build your own batch processor by extending primitives</li> </ul>"
        },
        {
            "location": "utilities/batch/#background",
            "title": "Background",
            "text": "<p>When using SQS, Kinesis Data Streams, or DynamoDB Streams as a Lambda event source, your Lambda functions are triggered with a batch of messages.</p> <p>If your function fails to process any message from the batch, the entire batch returns to your queue or stream. This same batch is then retried until either condition happens first: a) your Lambda function returns a successful response, b) record reaches maximum retry attempts, or c) records expire.</p> <pre><code>journey\n  section Conditions\n    Successful response: 5: Success\n    Maximum retries: 3: Failure\n    Records expired: 1: Failure</code></pre> <p>This behavior changes when you enable Report Batch Item Failures feature in your Lambda function event source configuration:</p> <ul> <li>SQS queues. Only messages reported as failure will return to the queue for a retry, while successful ones will be deleted.</li> <li>Kinesis data streams and DynamoDB streams. Single reported failure will use its sequence number as the stream checkpoint. Multiple  reported failures will use the lowest sequence number as checkpoint.</li> </ul> Warning: This utility lowers the chance of processing records more than once; it does not guarantee it <p>We recommend implementing processing logic in an idempotent manner wherever possible.</p> <p>You can find more details on how Lambda works with either SQS, Kinesis, or DynamoDB in the AWS Documentation.</p>"
        },
        {
            "location": "utilities/batch/#getting-started",
            "title": "Getting started",
            "text": "<p>For this feature to work, you need to (1) configure your Lambda function event source to use <code>ReportBatchItemFailures</code>, and (2) return a specific response to report which records failed to be processed.</p> <p>You use your preferred deployment framework to set the correct configuration while this utility handles the correct response to be returned.</p>"
        },
        {
            "location": "utilities/batch/#required-resources",
            "title": "Required resources",
            "text": "<p>The remaining sections of the documentation will rely on these samples. For completeness, this demonstrates IAM permissions and Dead Letter Queue where batch records will be sent after 2 retries were attempted.</p> <p>You do not need any additional IAM permissions to use this utility, except for what each event source requires.</p> SQSKinesis Data StreamsDynamoDB Streams template.yaml<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: partial batch response sample\n\nGlobals:\n  Function:\n    Timeout: 5\n    MemorySize: 256\n    Runtime: python3.12\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_LOG_LEVEL: INFO\n        POWERTOOLS_SERVICE_NAME: hello\n\nResources:\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: app.lambda_handler\n      CodeUri: hello_world\n      Policies:\n        - SQSPollerPolicy:\n            QueueName: !GetAtt SampleQueue.QueueName\n      Events:\n        Batch:\n          Type: SQS\n          Properties:\n            Queue: !GetAtt SampleQueue.Arn\n            FunctionResponseTypes:\n              - ReportBatchItemFailures\n\n  SampleDLQ:\n    Type: AWS::SQS::Queue\n\n  SampleQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      VisibilityTimeout: 30 # Fn timeout * 6\n      SqsManagedSseEnabled: true\n      RedrivePolicy:\n        maxReceiveCount: 2\n        deadLetterTargetArn: !GetAtt SampleDLQ.Arn\n</code></pre> template.yaml<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: partial batch response sample\n\nGlobals:\n  Function:\n    Timeout: 5\n    MemorySize: 256\n    Runtime: python3.12\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_LOG_LEVEL: INFO\n        POWERTOOLS_SERVICE_NAME: hello\n\nResources:\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: app.lambda_handler\n      CodeUri: hello_world\n      Policies:\n        # Lambda Destinations require additional permissions\n        # to send failure records to DLQ from Kinesis/DynamoDB\n        - Version: \"2012-10-17\"\n          Statement:\n            Effect: \"Allow\"\n            Action:\n              - sqs:GetQueueAttributes\n              - sqs:GetQueueUrl\n              - sqs:SendMessage\n            Resource: !GetAtt SampleDLQ.Arn\n      Events:\n        KinesisStream:\n          Type: Kinesis\n          Properties:\n            Stream: !GetAtt SampleStream.Arn\n            BatchSize: 100\n            StartingPosition: LATEST\n            MaximumRetryAttempts: 2\n            DestinationConfig:\n              OnFailure:\n                Destination: !GetAtt SampleDLQ.Arn\n            FunctionResponseTypes:\n              - ReportBatchItemFailures\n\n  SampleDLQ:\n    Type: AWS::SQS::Queue\n\n  SampleStream:\n    Type: AWS::Kinesis::Stream\n    Properties:\n      ShardCount: 1\n      StreamEncryption:\n        EncryptionType: KMS\n        KeyId: alias/aws/kinesis\n</code></pre> template.yaml<pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: partial batch response sample\n\nGlobals:\n  Function:\n    Timeout: 5\n    MemorySize: 256\n    Runtime: python3.12\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_LOG_LEVEL: INFO\n        POWERTOOLS_SERVICE_NAME: hello\n\nResources:\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: app.lambda_handler\n      CodeUri: hello_world\n      Policies:\n        # Lambda Destinations require additional permissions\n        # to send failure records from Kinesis/DynamoDB\n        - Version: \"2012-10-17\"\n          Statement:\n            Effect: \"Allow\"\n            Action:\n              - sqs:GetQueueAttributes\n              - sqs:GetQueueUrl\n              - sqs:SendMessage\n            Resource: !GetAtt SampleDLQ.Arn\n      Events:\n        DynamoDBStream:\n          Type: DynamoDB\n          Properties:\n            Stream: !GetAtt SampleTable.StreamArn\n            StartingPosition: LATEST\n            MaximumRetryAttempts: 2\n            DestinationConfig:\n              OnFailure:\n                Destination: !GetAtt SampleDLQ.Arn\n            FunctionResponseTypes:\n              - ReportBatchItemFailures\n\n  SampleDLQ:\n    Type: AWS::SQS::Queue\n\n  SampleTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      BillingMode: PAY_PER_REQUEST\n      AttributeDefinitions:\n        - AttributeName: pk\n          AttributeType: S\n        - AttributeName: sk\n          AttributeType: S\n      KeySchema:\n        - AttributeName: pk\n          KeyType: HASH\n        - AttributeName: sk\n          KeyType: RANGE\n      SSESpecification:\n        SSEEnabled: true\n      StreamSpecification:\n        StreamViewType: NEW_AND_OLD_IMAGES\n</code></pre>"
        },
        {
            "location": "utilities/batch/#processing-messages-from-sqs",
            "title": "Processing messages from SQS",
            "text": "<p>Processing batches from SQS works in three stages:</p> <ol> <li>Instantiate <code>BatchProcessor</code> and choose <code>EventType.SQS</code> for the event type</li> <li>Define your function to handle each batch record, and use <code>SQSRecord</code> type annotation for autocompletion</li> <li>Use <code>process_partial_response</code> to kick off processing</li> </ol> <p>This code example uses Tracer and Logger for completion.</p> RecommendedAs a context managerSample responseSample event <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)  # (1)!\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):  # (2)!\n    payload: str = record.json_body  # if json string data, otherwise record.body for str\n    logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(  # (3)!\n        event=event,\n        record_handler=record_handler,\n        processor=processor,\n        context=context,\n    )\n</code></pre> <ol> <li>Step 1. Creates a partial failure batch processor for SQS queues. See partial failure mechanics for details</li> <li>Step 2. Defines a function to receive one record at a time from the batch</li> <li>Step 3. Kicks off processing</li> </ol> <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    batch = event[\"Records\"]\n    with processor(records=batch, handler=record_handler):\n        processed_messages = processor.process()  # kick off processing, return list[tuple]\n        logger.info(f\"Processed ${len(processed_messages)} messages\")\n\n    return processor.response()\n</code></pre> <p>The second record failed to be processed, therefore the processor added its message ID in the response.</p> <pre><code>{\n  \"batchItemFailures\": [\n    {\n      \"itemIdentifier\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\"\n    }\n  ]\n}\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n      \"body\": \"{\\\"Message\\\": \\\"success\\\"}\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082649183\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n      \"awsRegion\": \"us-east-1\"\n    },\n    {\n      \"messageId\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n      \"body\": \"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082649183\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n      \"awsRegion\": \"us-east-1\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch/#fifo-queues",
            "title": "FIFO queues",
            "text": "<p>When working with SQS FIFO queues, a batch may include messages from different group IDs.</p> <p>By default, we will stop processing at the first failure and mark unprocessed messages as failed to preserve ordering. However, this behavior may not be optimal for customers who wish to proceed with processing messages from a different group ID.</p> <p>Enable the <code>skip_group_on_error</code> option for seamless processing of messages from various group IDs. This setup ensures that messages from a failed group ID are sent back to SQS, enabling uninterrupted processing of messages from the subsequent group ID.</p> RecommendedAs a context managerEnabling skip_group_on_error flag <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    SqsFifoPartialProcessor,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = SqsFifoPartialProcessor()  # (1)!\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.json_body  # if json string data, otherwise record.body for str\n    logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <ol> <li>Step 1. Creates a partial failure batch processor for SQS FIFO queues. See partial failure mechanics for details</li> </ol> <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import SqsFifoPartialProcessor\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = SqsFifoPartialProcessor()\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    batch = event[\"Records\"]\n    with processor(records=batch, handler=record_handler):\n        processor.process()  # kick off processing, return List[Tuple]\n\n    return processor.response()\n</code></pre> <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    SqsFifoPartialProcessor,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = SqsFifoPartialProcessor(skip_group_on_error=True)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.json_body  # if json string data, otherwise record.body for str\n    logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre>"
        },
        {
            "location": "utilities/batch/#processing-messages-from-kinesis",
            "title": "Processing messages from Kinesis",
            "text": "<p>Processing batches from Kinesis works in three stages:</p> <ol> <li>Instantiate <code>BatchProcessor</code> and choose <code>EventType.KinesisDataStreams</code> for the event type</li> <li>Define your function to handle each batch record, and use <code>KinesisStreamRecord</code> type annotation for autocompletion</li> <li>Use <code>process_partial_response</code> to kick off processing</li> </ol> <p>This code example uses Tracer and Logger for completion.</p> RecommendedAs a context managerSample responseSample event <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import (\n    KinesisStreamRecord,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.KinesisDataStreams)  # (1)!\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: KinesisStreamRecord):\n    logger.info(record.kinesis.data_as_text)\n    payload: dict = record.kinesis.data_as_json()\n    logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <ol> <li>Step 1. Creates a partial failure batch processor for Kinesis Data Streams. See partial failure mechanics for details</li> </ol> <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType\nfrom aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import (\n    KinesisStreamRecord,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.KinesisDataStreams)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: KinesisStreamRecord):\n    logger.info(record.kinesis.data_as_text)\n    payload: dict = record.kinesis.data_as_json()\n    logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    batch = event[\"Records\"]\n    with processor(records=batch, handler=record_handler):\n        processed_messages = processor.process()  # kick off processing, return list[tuple]\n        logger.info(f\"Processed ${len(processed_messages)} messages\")\n\n    return processor.response()\n</code></pre> <p>The second record failed to be processed, therefore the processor added its sequence number in the response.</p> <pre><code>{\n  \"batchItemFailures\": [\n    {\n      \"itemIdentifier\": \"6006958808509702859251049540584488075644979031228738\"\n    }\n  ]\n}\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"kinesis\": {\n        \"kinesisSchemaVersion\": \"1.0\",\n        \"partitionKey\": \"1\",\n        \"sequenceNumber\": \"4107859083838847772757075850904226111829882106684065\",\n        \"data\": \"eyJNZXNzYWdlIjogInN1Y2Nlc3MifQ==\",\n        \"approximateArrivalTimestamp\": 1545084650.987\n      },\n      \"eventSource\": \"aws:kinesis\",\n      \"eventVersion\": \"1.0\",\n      \"eventID\": \"shardId-000000000006:4107859083838847772757075850904226111829882106684065\",\n      \"eventName\": \"aws:kinesis:record\",\n      \"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n      \"awsRegion\": \"us-east-2\",\n      \"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n    },\n    {\n      \"kinesis\": {\n        \"kinesisSchemaVersion\": \"1.0\",\n        \"partitionKey\": \"1\",\n        \"sequenceNumber\": \"6006958808509702859251049540584488075644979031228738\",\n        \"data\": \"c3VjY2Vzcw==\",\n        \"approximateArrivalTimestamp\": 1545084650.987\n      },\n      \"eventSource\": \"aws:kinesis\",\n      \"eventVersion\": \"1.0\",\n      \"eventID\": \"shardId-000000000006:6006958808509702859251049540584488075644979031228738\",\n      \"eventName\": \"aws:kinesis:record\",\n      \"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n      \"awsRegion\": \"us-east-2\",\n      \"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch/#processing-messages-from-dynamodb",
            "title": "Processing messages from DynamoDB",
            "text": "<p>Processing batches from DynamoDB Streams works in three stages:</p> <ol> <li>Instantiate <code>BatchProcessor</code> and choose <code>EventType.DynamoDBStreams</code> for the event type</li> <li>Define your function to handle each batch record, and use <code>DynamoDBRecord</code> type annotation for autocompletion</li> <li>Use <code>process_partial_response</code> to kick off processing</li> </ol> <p>This code example uses Tracer and Logger for completion.</p> RecommendedAs a context managerSample responseSample event <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import (\n    DynamoDBRecord,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.DynamoDBStreams)  # (1)!\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: DynamoDBRecord):\n    if record.dynamodb and record.dynamodb.new_image:\n        logger.info(record.dynamodb.new_image)\n        message = record.dynamodb.new_image.get(\"Message\")\n        if message:\n            payload: dict = json.loads(message)\n            logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <ol> <li>Step 1. Creates a partial failure batch processor for DynamoDB Streams. See partial failure mechanics for details</li> </ol> <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType\nfrom aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import (\n    DynamoDBRecord,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.DynamoDBStreams)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: DynamoDBRecord):\n    if record.dynamodb and record.dynamodb.new_image:\n        logger.info(record.dynamodb.new_image)\n        message = record.dynamodb.new_image.get(\"Message\")\n        if message:\n            payload: dict = json.loads(message)\n            logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    batch = event[\"Records\"]\n    with processor(records=batch, handler=record_handler):\n        processed_messages = processor.process()  # kick off processing, return list[tuple]\n        logger.info(f\"Processed ${len(processed_messages)} messages\")\n\n    return processor.response()\n</code></pre> <p>The second record failed to be processed, therefore the processor added its sequence number in the response.</p> <pre><code>{\n  \"batchItemFailures\": [\n    {\n      \"itemIdentifier\": \"8640712661\"\n    }\n  ]\n}\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"eventID\": \"1\",\n      \"eventVersion\": \"1.0\",\n      \"dynamodb\": {\n        \"Keys\": {\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"NewImage\": {\n          \"Message\": {\n            \"S\": \"failure\"\n          }\n        },\n        \"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n        \"SequenceNumber\": \"3275880929\",\n        \"SizeBytes\": 26\n      },\n      \"awsRegion\": \"us-west-2\",\n      \"eventName\": \"INSERT\",\n      \"eventSourceARN\": \"eventsource_arn\",\n      \"eventSource\": \"aws:dynamodb\"\n    },\n    {\n      \"eventID\": \"1\",\n      \"eventVersion\": \"1.0\",\n      \"dynamodb\": {\n        \"Keys\": {\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"NewImage\": {\n          \"SomethingElse\": {\n            \"S\": \"success\"\n          }\n        },\n        \"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n        \"SequenceNumber\": \"8640712661\",\n        \"SizeBytes\": 26\n      },\n      \"awsRegion\": \"us-west-2\",\n      \"eventName\": \"INSERT\",\n      \"eventSourceARN\": \"eventsource_arn\",\n      \"eventSource\": \"aws:dynamodb\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch/#error-handling",
            "title": "Error handling",
            "text": "<p>By default, we catch any exception raised by your record handler function. This allows us to (1) continue processing the batch, (2) collect each batch item that failed processing, and (3) return the appropriate  response correctly without failing your Lambda function execution.</p> Sample error handling with custom exceptionSample response <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\nclass InvalidPayload(Exception):\n    ...\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    logger.info(payload)\n    if not payload:\n        raise InvalidPayload(\"Payload does not contain minimum information to be processed.\")  # (1)!\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(  # (2)!\n        event=event,\n        record_handler=record_handler,\n        processor=processor,\n        context=context,\n    )\n</code></pre> <ol> <li> <p>Any exception works here. See extending BatchProcessor section, if you want to override this behavior.</p> </li> <li> <p>Exceptions raised in <code>record_handler</code> will propagate to <code>process_partial_response</code>.  We catch them and include each failed batch item identifier in the response dictionary (see <code>Sample response</code> tab).</p> </li> </ol> <pre><code>{\n  \"batchItemFailures\": [\n    {\n      \"itemIdentifier\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch/#partial-failure-mechanics",
            "title": "Partial failure mechanics",
            "text": "<p>All batch items will be passed to the record handler for processing, even if exceptions are thrown - Here's the behavior after completing the batch:</p> <ul> <li>All records successfully processed. We will return an empty list of item failures <code>{'batchItemFailures': []}</code></li> <li>Partial success with some exceptions. We will return a list of all item IDs/sequence numbers that failed processing</li> <li>All records failed to be processed. We will raise <code>BatchProcessingError</code> exception with a list of all exceptions raised when processing</li> </ul> <p>The following sequence diagrams explain how each Batch processor behaves under different scenarios.</p>"
        },
        {
            "location": "utilities/batch/#sqs-standard",
            "title": "SQS Standard",
            "text": "<p>Read more about Batch Failure Reporting feature in AWS Lambda.</p> <p>Sequence diagram to explain how <code>BatchProcessor</code> works with SQS Standard queues.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant SQS queue\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;SQS queue: Poll\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    Lambda function-&gt;&gt;Lambda service: Report some failed messages\n    activate SQS queue\n    Lambda service-&gt;&gt;SQS queue: Delete successful messages\n    SQS queue--&gt;&gt;SQS queue: Failed messages return\n    Note over SQS queue,Lambda service: Process repeat\n    deactivate SQS queue</code></pre> SQS mechanism with Batch Item Failures </p>"
        },
        {
            "location": "utilities/batch/#sqs-fifo",
            "title": "SQS FIFO",
            "text": "<p>Read more about Batch Failure Reporting feature in AWS Lambda.</p> <p>Sequence diagram to explain how <code>SqsFifoPartialProcessor</code> works with SQS FIFO queues without <code>skip_group_on_error</code> flag.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant SQS queue\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;SQS queue: Poll\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    activate Lambda function\n    Lambda function--&gt;Lambda function: Process 2 out of 10 batch items\n    Lambda function--xLambda function: Fail on 3rd batch item\n    Lambda function-&gt;&gt;Lambda service: Report 3rd batch item and unprocessed messages as failure\n    deactivate Lambda function\n    activate SQS queue\n    Lambda service-&gt;&gt;SQS queue: Delete successful messages (1-2)\n    SQS queue--&gt;&gt;SQS queue: Failed messages return (3-10)\n    deactivate SQS queue</code></pre> SQS FIFO mechanism with Batch Item Failures </p> <p>Sequence diagram to explain how <code>SqsFifoPartialProcessor</code> works with SQS FIFO queues with <code>skip_group_on_error</code> flag.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant SQS queue\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;SQS queue: Poll\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    activate Lambda function\n    Lambda function--&gt;Lambda function: Process 2 out of 10 batch items\n    Lambda function--xLambda function: Fail on 3rd batch item\n    Lambda function--&gt;Lambda function: Process messages from another MessageGroupID\n    Lambda function-&gt;&gt;Lambda service: Report 3rd batch item and all messages within the same MessageGroupID as failure\n    deactivate Lambda function\n    activate SQS queue\n    Lambda service-&gt;&gt;SQS queue: Delete successful messages processed\n    SQS queue--&gt;&gt;SQS queue: Failed messages return\n    deactivate SQS queue</code></pre> SQS FIFO mechanism with Batch Item Failures </p>"
        },
        {
            "location": "utilities/batch/#kinesis-and-dynamodb-streams",
            "title": "Kinesis and DynamoDB Streams",
            "text": "<p>Read more about Batch Failure Reporting feature.</p> <p>Sequence diagram to explain how <code>BatchProcessor</code> works with both Kinesis Data Streams and DynamoDB Streams.</p> <p>For brevity, we will use <code>Streams</code> to refer to either services. For theory on stream checkpoints, see this blog post</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Streams\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;Streams: Poll latest records\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    activate Lambda function\n    Lambda function--&gt;Lambda function: Process 2 out of 10 batch items\n    Lambda function--xLambda function: Fail on 3rd batch item\n    Lambda function--&gt;Lambda function: Continue processing batch items (4-10)\n    Lambda function-&gt;&gt;Lambda service: Report batch item as failure (3)\n    deactivate Lambda function\n    activate Streams\n    Lambda service-&gt;&gt;Streams: Checkpoints to sequence number from 3rd batch item\n    Lambda service-&gt;&gt;Streams: Poll records starting from updated checkpoint\n    deactivate Streams</code></pre> Kinesis and DynamoDB streams mechanism with single batch item failure </p> <p>The behavior changes slightly when there are multiple item failures. Stream checkpoint is updated to the lowest sequence number reported.</p> <p>Note that the batch item sequence number could be different from batch item number in the illustration.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Streams\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;Streams: Poll latest records\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    activate Lambda function\n    Lambda function--&gt;Lambda function: Process 2 out of 10 batch items\n    Lambda function--xLambda function: Fail on 3-5 batch items\n    Lambda function--&gt;Lambda function: Continue processing batch items (6-10)\n    Lambda function-&gt;&gt;Lambda service: Report batch items as failure (3-5)\n    deactivate Lambda function\n    activate Streams\n    Lambda service-&gt;&gt;Streams: Checkpoints to lowest sequence number\n    Lambda service-&gt;&gt;Streams: Poll records starting from updated checkpoint\n    deactivate Streams</code></pre> Kinesis and DynamoDB streams mechanism with multiple batch item failures </p>"
        },
        {
            "location": "utilities/batch/#processing-messages-asynchronously",
            "title": "Processing messages asynchronously",
            "text": "<p>New to AsyncIO? Read this comprehensive guide first.</p> <p>You can use <code>AsyncBatchProcessor</code> class and <code>async_process_partial_response</code> function to process messages concurrently.</p> When is this useful? <p>Your use case might be able to process multiple records at the same time without conflicting with one another.</p> <p>For example, imagine you need to process multiple loyalty points and incrementally save them in the database. While you await the database to confirm your records are saved, you could start processing another request concurrently.</p> <p>The reason this is not the default behaviour is that not all use cases can handle concurrency safely (e.g., loyalty points must be updated in order).</p> High-concurrency with AsyncBatchProcessor<pre><code>import httpx  # external dependency\n\nfrom aws_lambda_powertools.utilities.batch import (\n    AsyncBatchProcessor,\n    EventType,\n    async_process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = AsyncBatchProcessor(event_type=EventType.SQS)\n\n\nasync def async_record_handler(record: SQSRecord):\n    # Yield control back to the event loop to schedule other tasks\n    # while you await from a response from httpbin.org\n    async with httpx.AsyncClient() as client:\n        ret = await client.get(\"https://httpbin.org/get\")\n\n    return ret.status_code\n\n\ndef lambda_handler(event, context: LambdaContext):\n    return async_process_partial_response(\n        event=event,\n        record_handler=async_record_handler,\n        processor=processor,\n        context=context,\n    )\n</code></pre> Using tracer? <p><code>AsyncBatchProcessor</code> uses <code>asyncio.gather</code>. This might cause side effects and reach trace limits at high concurrency.</p>"
        },
        {
            "location": "utilities/batch/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/batch/#pydantic-integration",
            "title": "Pydantic integration",
            "text": "<p>You can bring your own Pydantic models via <code>model</code> parameter when inheriting from <code>SqsRecordModel</code>, <code>KinesisDataStreamRecord</code>, or <code>DynamoDBStreamRecordModel</code></p> <p>Inheritance is importance because we need to access message IDs and sequence numbers from these records in the event of failure. Mypy is fully integrated with this utility, so it should identify whether you're passing the incorrect Model.</p> SQSSQS - Sample Event Kinesis Data StreamsKinesis - Sample Event DynamoDB StreamsDynamoDB - Sample Event  <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.parser import BaseModel\nfrom aws_lambda_powertools.utilities.parser.models import SqsRecordModel\nfrom aws_lambda_powertools.utilities.parser.types import Json\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass Order(BaseModel):\n    item: dict\n\n\nclass OrderSqsRecord(SqsRecordModel):  # type: ignore[override]\n    body: Json[Order]  # deserialize order data from JSON string\n\n\nprocessor = BatchProcessor(event_type=EventType.SQS, model=OrderSqsRecord)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: OrderSqsRecord):\n    logger.info(record.body.item)\n    return record.body.item\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>{\n    \"Records\": [\n      {\n        \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n        \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n        \"body\": \"{\\\"item\\\": {\\\"laptop\\\": \\\"amd\\\"}}\",\n        \"attributes\": {\n          \"ApproximateReceiveCount\": \"1\",\n          \"SentTimestamp\": \"1545082649183\",\n          \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n          \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n        },\n        \"messageAttributes\": {},\n        \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n        \"eventSource\": \"aws:sqs\",\n        \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n        \"awsRegion\": \"us-east-1\"\n      },\n      {\n        \"messageId\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\",\n        \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n        \"body\": \"{\\\"item\\\": {\\\"keyboard\\\": \\\"classic\\\"}}\",\n        \"attributes\": {\n          \"ApproximateReceiveCount\": \"1\",\n          \"SentTimestamp\": \"1545082649183\",\n          \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n          \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n        },\n        \"messageAttributes\": {},\n        \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n        \"eventSource\": \"aws:sqs\",\n        \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n        \"awsRegion\": \"us-east-1\"\n      }\n    ]\n  }\n</code></pre> <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.parser import BaseModel\nfrom aws_lambda_powertools.utilities.parser.models import (\n    KinesisDataStreamRecord,\n    KinesisDataStreamRecordPayload,\n)\nfrom aws_lambda_powertools.utilities.parser.types import Json\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass Order(BaseModel):\n    item: dict\n\n\nclass OrderKinesisPayloadRecord(KinesisDataStreamRecordPayload):  # type: ignore[override]\n    data: Json[Order]\n\n\nclass OrderKinesisRecord(KinesisDataStreamRecord):  # type: ignore[override]\n    kinesis: OrderKinesisPayloadRecord\n\n\nprocessor = BatchProcessor(event_type=EventType.KinesisDataStreams, model=OrderKinesisRecord)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: OrderKinesisRecord):\n    logger.info(record.kinesis.data.item)\n    return record.kinesis.data.item\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>{\n    \"Records\": [\n      {\n        \"kinesis\": {\n          \"kinesisSchemaVersion\": \"1.0\",\n          \"partitionKey\": \"1\",\n          \"sequenceNumber\": \"4107859083838847772757075850904226111829882106684065\",\n          \"data\": \"eyJpdGVtIjogeyJsYXB0b3AiOiAiYW1kIn19Cg==\",\n          \"approximateArrivalTimestamp\": 1545084650.987\n        },\n        \"eventSource\": \"aws:kinesis\",\n        \"eventVersion\": \"1.0\",\n        \"eventID\": \"shardId-000000000006:4107859083838847772757075850904226111829882106684065\",\n        \"eventName\": \"aws:kinesis:record\",\n        \"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n        \"awsRegion\": \"us-east-2\",\n        \"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n      },\n      {\n        \"kinesis\": {\n          \"kinesisSchemaVersion\": \"1.0\",\n          \"partitionKey\": \"1\",\n          \"sequenceNumber\": \"6006958808509702859251049540584488075644979031228738\",\n          \"data\": \"eyJpdGVtIjogeyJrZXlib2FyZCI6ICJjbGFzc2ljIn19Cg==\",\n          \"approximateArrivalTimestamp\": 1545084650.987\n        },\n        \"eventSource\": \"aws:kinesis\",\n        \"eventVersion\": \"1.0\",\n        \"eventID\": \"shardId-000000000006:6006958808509702859251049540584488075644979031228738\",\n        \"eventName\": \"aws:kinesis:record\",\n        \"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n        \"awsRegion\": \"us-east-2\",\n        \"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n      }\n    ]\n  }\n</code></pre> <pre><code>import json\nfrom typing import Dict, Optional\n\nfrom typing_extensions import Literal\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.parser import BaseModel, field_validator\nfrom aws_lambda_powertools.utilities.parser.models import (\n    DynamoDBStreamChangedRecordModel,\n    DynamoDBStreamRecordModel,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass Order(BaseModel):\n    item: dict\n\n\nclass OrderDynamoDB(BaseModel):\n    Message: Order\n\n    # auto transform json string\n    # so Pydantic can auto-initialize nested Order model\n    @field_validator(\"Message\", mode=\"before\")\n    def transform_message_to_dict(cls, value: Dict[Literal[\"S\"], str]):\n        return json.loads(value[\"S\"])\n\n\nclass OrderDynamoDBChangeRecord(DynamoDBStreamChangedRecordModel):  # type: ignore[override]\n    NewImage: Optional[OrderDynamoDB]\n    OldImage: Optional[OrderDynamoDB]\n\n\nclass OrderDynamoDBRecord(DynamoDBStreamRecordModel):  # type: ignore[override]\n    dynamodb: OrderDynamoDBChangeRecord\n\n\nprocessor = BatchProcessor(event_type=EventType.DynamoDBStreams, model=OrderDynamoDBRecord)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: OrderDynamoDBRecord):\n    if record.dynamodb.NewImage and record.dynamodb.NewImage.Message:\n        logger.info(record.dynamodb.NewImage.Message.item)\n        return record.dynamodb.NewImage.Message.item\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>{\n    \"Records\": [\n      {\n        \"eventID\": \"1\",\n        \"eventVersion\": \"1.0\",\n        \"dynamodb\": {\n          \"Keys\": {\n            \"Id\": {\n              \"N\": \"101\"\n            }\n          },\n          \"NewImage\": {\n            \"Message\": {\n              \"S\": \"{\\\"item\\\": {\\\"laptop\\\": \\\"amd\\\"}}\"\n            }\n          },\n          \"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n          \"SequenceNumber\": \"3275880929\",\n          \"SizeBytes\": 26\n        },\n        \"awsRegion\": \"us-west-2\",\n        \"eventName\": \"INSERT\",\n        \"eventSourceARN\": \"eventsource_arn\",\n        \"eventSource\": \"aws:dynamodb\"\n      },\n      {\n        \"eventID\": \"1\",\n        \"eventVersion\": \"1.0\",\n        \"dynamodb\": {\n          \"Keys\": {\n            \"Id\": {\n              \"N\": \"101\"\n            }\n          },\n          \"NewImage\": {\n            \"SomethingElse\": {\n              \"S\": \"success\"\n            }\n          },\n          \"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n          \"SequenceNumber\": \"8640712661\",\n          \"SizeBytes\": 26\n        },\n        \"awsRegion\": \"us-west-2\",\n        \"eventName\": \"INSERT\",\n        \"eventSourceARN\": \"eventsource_arn\",\n        \"eventSource\": \"aws:dynamodb\"\n      }\n    ]\n  }\n</code></pre>"
        },
        {
            "location": "utilities/batch/#working-with-full-batch-failures",
            "title": "Working with full batch failures",
            "text": "<p>By default, the <code>BatchProcessor</code> will raise <code>BatchProcessingError</code> if all records in the batch fail to process, we do this to reflect the failure in your operational metrics.</p> <p>When working with functions that handle batches with a small number of records, or when you use errors as a flow control mechanism, this behavior might not be desirable as your function might generate an unnaturally high number of errors. When this happens, the Lambda service will scale down the concurrency of your function, potentially impacting performance.</p> <p>For these scenarios, you can set the <code>raise_on_entire_batch_failure</code> option to <code>False</code>.</p> working_with_entire_batch_fail.py <pre><code>from aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS, raise_on_entire_batch_failure=False)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.json_body  # if json string data, otherwise record.body for str\n    logger.info(payload)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(\n        event=event,\n        record_handler=record_handler,\n        processor=processor,\n        context=context,\n    )\n</code></pre>"
        },
        {
            "location": "utilities/batch/#accessing-processed-messages",
            "title": "Accessing processed messages",
            "text": "<p>Use the context manager to access a list of all returned values from your <code>record_handler</code> function.</p> <ul> <li>When successful. We include a tuple with 1/ <code>success</code>, 2/ the result of <code>record_handler</code>, and 3/ the batch item</li> <li>When failed. We include a tuple with 1/ <code>fail</code>, 2/ exception as a string, and 3/ the batch item serialized as Event Source Data Class or Pydantic model.</li> </ul> <p>If a Pydantic model fails validation early, we serialize its failure record as Event Source Data Class to be able to collect message ID/sequence numbers etc.</p> Accessing raw processed messagesSample processed messagesSample processed messages (Pydantic) <pre><code>from __future__ import annotations\n\nimport json\n\nfrom typing_extensions import Literal\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    batch = event[\"Records\"]  # (1)!\n    with processor(records=batch, handler=record_handler):\n        processed_messages: list[tuple] = processor.process()\n\n    for message in processed_messages:\n        status: Literal[\"success\", \"fail\"] = message[0]\n        cause: str = message[1]  # (2)!\n        record: SQSRecord = message[2]\n\n        logger.info(status, record=record, cause=cause)\n\n    return processor.response()\n</code></pre> <ol> <li>Context manager requires the records list. This is typically handled by <code>process_partial_response</code>.</li> <li>Cause contains <code>exception</code> str if failed, or <code>success</code> otherwise.</li> </ol> <pre><code>[\n    (\n        \"fail\",\n        \"&lt;class 'Exception': Failed to process record\",  # (1)!\n        &lt;aws_lambda_powertools.utilities.data_classes.sqs_event.SQSRecord object at 0x103c590a0&gt;\n    ),\n    (\n        \"success\",\n        \"success\",\n        {'messageId': '88891c36-32eb-4a25-9905-654a32916893', 'receiptHandle': 'AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a', 'body': 'success', 'attributes': {'ApproximateReceiveCount': '1', 'SentTimestamp': '1545082649183', 'SenderId': 'AIDAIENQZJOLO23YVJ4VO', 'ApproximateFirstReceiveTimestamp': '1545082649185'}, 'messageAttributes': {}, 'md5OfBody': 'e4e68fb7bd0e697a0ae8f1bb342846b3', 'eventSource': 'aws:sqs', 'eventSourceARN': 'arn:aws:sqs:us-east-2:123456789012:my-queue', 'awsRegion': 'us-east-1'}\n    )\n]\n</code></pre> <ol> <li>Sample exception could have raised from within <code>record_handler</code> function.</li> </ol> <pre><code>[\n    (\n        \"fail\", # (1)!\n        \"&lt;class 'pydantic.error_wrappers.ValidationError'&gt;:1 validation error for OrderSqs\\nbody\\n  JSON object must be str, bytes or bytearray (type=type_error.json)\",\n        &lt;aws_lambda_powertools.utilities.data_classes.sqs_event.SQSRecord object at 0x103c590a0&gt;\n    ),\n    (\n        \"success\",\n        \"success\",\n        {'messageId': '88891c36-32eb-4a25-9905-654a32916893', 'receiptHandle': 'AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a', 'body': 'success', 'attributes': {'ApproximateReceiveCount': '1', 'SentTimestamp': '1545082649183', 'SenderId': 'AIDAIENQZJOLO23YVJ4VO', 'ApproximateFirstReceiveTimestamp': '1545082649185'}, 'messageAttributes': {}, 'md5OfBody': 'e4e68fb7bd0e697a0ae8f1bb342846b3', 'eventSource': 'aws:sqs', 'eventSourceARN': 'arn:aws:sqs:us-east-2:123456789012:my-queue', 'awsRegion': 'us-east-1'}\n    ),\n    (\n        \"fail\",  # (2)!\n        \"&lt;class 'Exception'&gt;:Failed to process record.\",\n        OrderSqs(messageId='9d0bfba5-d213-4b64-89bd-f4fbd7e58358', receiptHandle='AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a', body=Order(item={'type': 'fail'}), attributes=SqsAttributesModel(ApproximateReceiveCount='1', ApproximateFirstReceiveTimestamp=datetime.datetime(2018, 12, 17, 21, 37, 29, 185000, tzinfo=datetime.timezone.utc), MessageDeduplicationId=None, MessageGroupId=None, SenderId='AIDAIENQZJOLO23YVJ4VO', SentTimestamp=datetime.datetime(2018, 12, 17, 21, 37, 29, 183000, tzinfo=datetime.timezone.utc), SequenceNumber=None, AWSTraceHeader=None), messageAttributes={}, md5OfBody='e4e68fb7bd0e697a0ae8f1bb342846b3', md5OfMessageAttributes=None, eventSource='aws:sqs', eventSourceARN='arn:aws:sqs:us-east-2:123456789012:my-queue', awsRegion='us-east-1')\n    )\n]\n</code></pre> <ol> <li>Sample when a model fails validation early.  Batch item (3rd item) is serialized to the respective Event Source Data Class event type.</li> <li>Sample when model validated successfully but another exception was raised during processing.</li> </ol>"
        },
        {
            "location": "utilities/batch/#accessing-lambda-context",
            "title": "Accessing Lambda Context",
            "text": "<p>Within your <code>record_handler</code> function, you might need access to the Lambda context to determine how much time you have left before your function times out.</p> <p>We can automatically inject the Lambda context into your <code>record_handler</code> if your function signature has a parameter named <code>lambda_context</code>. When using a context manager, you also need to pass the Lambda context object like in the example below.</p> RecommendedAs a context manager <pre><code>from typing import Optional\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord, lambda_context: Optional[LambdaContext] = None):\n    if lambda_context is not None:\n        remaining_time = lambda_context.get_remaining_time_in_millis()\n        logger.info(remaining_time)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>from typing import Optional\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord, lambda_context: Optional[LambdaContext] = None):\n    if lambda_context is not None:\n        remaining_time = lambda_context.get_remaining_time_in_millis()\n        logger.info(remaining_time)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    batch = event[\"Records\"]\n    with processor(records=batch, handler=record_handler, lambda_context=context):\n        result = processor.process()\n\n    return result\n</code></pre>"
        },
        {
            "location": "utilities/batch/#extending-batchprocessor",
            "title": "Extending BatchProcessor",
            "text": "<p>You might want to bring custom logic to the existing <code>BatchProcessor</code> to slightly override how we handle successes and failures.</p> <p>For these scenarios, you can subclass <code>BatchProcessor</code> and quickly override <code>success_handler</code> and <code>failure_handler</code> methods:</p> <ul> <li><code>success_handler()</code> is called for each successfully processed record</li> <li><code>failure_handler()</code> is called for each failed record</li> </ul> Note <p>These functions have a common <code>record</code> argument. For backward compatibility reasons, their type is not the same:</p> <ul> <li><code>success_handler</code>: <code>record</code> type is <code>dict[str, Any]</code>, the raw record data.</li> <li><code>failure_handler</code>: <code>record</code> type can be an Event Source Data Class or your Pydantic model. During Pydantic validation errors, we fall back and serialize <code>record</code> to Event Source Data Class to not break the processing pipeline.</li> </ul> <p>Let's suppose you'd like to add metrics to track successes and failures of your batch records.</p> Extending failure handling mechanism in BatchProcessor<pre><code>import json\nfrom typing import Any, Dict\n\nfrom aws_lambda_powertools import Logger, Metrics, Tracer\nfrom aws_lambda_powertools.metrics import MetricUnit\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    ExceptionInfo,\n    FailureResponse,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.batch.base import SuccessResponse\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass MyProcessor(BatchProcessor):\n    def success_handler(self, record: Dict[str, Any], result: Any) -&gt; SuccessResponse:\n        metrics.add_metric(name=\"BatchRecordSuccesses\", unit=MetricUnit.Count, value=1)\n        return super().success_handler(record, result)\n\n    def failure_handler(self, record: SQSRecord, exception: ExceptionInfo) -&gt; FailureResponse:\n        metrics.add_metric(name=\"BatchRecordFailures\", unit=MetricUnit.Count, value=1)\n        return super().failure_handler(record, exception)\n\n\nprocessor = MyProcessor(event_type=EventType.SQS)\nmetrics = Metrics(namespace=\"test\")\nlogger = Logger()\ntracer = Tracer()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@metrics.log_metrics(capture_cold_start_metric=True)\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre>"
        },
        {
            "location": "utilities/batch/#create-your-own-partial-processor",
            "title": "Create your own partial processor",
            "text": "<p>You can create your own partial batch processor from scratch by inheriting the <code>BasePartialProcessor</code> class, and implementing <code>_prepare()</code>, <code>_clean()</code>, <code>_process_record()</code> and <code>_async_process_record()</code>.</p> <p> <pre><code>classDiagram\n    direction LR\n    class BasePartialProcessor {\n        &lt;&lt;interface&gt;&gt;\n        +_prepare()\n        +_clean()\n        +_process_record_(record: Dict)\n        +_async_process_record_()\n    }\n\n    class YourCustomProcessor {\n        +_prepare()\n        +_clean()\n        +_process_record_(record: Dict)\n        +_async_process_record_()\n    }\n\n    BasePartialProcessor &lt;|-- YourCustomProcessor : implement</code></pre> Visual representation to bring your own processor </p> <ul> <li><code>_process_record()</code> – handles all processing logic for each individual message of a batch, including calling the <code>record_handler</code> (self.handler)</li> <li><code>_prepare()</code> – called once as part of the processor initialization</li> <li><code>_clean()</code> – teardown logic called once after <code>_process_record</code> completes</li> <li><code>_async_process_record()</code> – If you need to implement asynchronous logic, use this method, otherwise define it in your class with empty logic</li> <li><code>response()</code> - called upon completion of processing</li> </ul> <p>You can utilize this class to instantiate a new processor and then pass it to the <code>process_partial_response</code> function.</p> Creating a custom batch processorDynamoDB table used for storing processed records.Sample event <pre><code>import copy\nimport os\nimport sys\nfrom random import randint\nfrom typing import Any\n\nimport boto3\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.batch import (\n    BasePartialProcessor,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.batch.types import PartialItemFailureResponse\n\ntable_name = os.getenv(\"TABLE_NAME\", \"table_store_batch\")\n\nlogger = Logger()\n\n\nclass MyPartialProcessor(BasePartialProcessor):\n    DEFAULT_RESPONSE: PartialItemFailureResponse = {\"batchItemFailures\": []}\n    \"\"\"\n    Process a record and stores successful results at a Amazon DynamoDB Table\n\n    Parameters\n    ----------\n    table_name: str\n        DynamoDB table name to write results to\n    \"\"\"\n\n    def __init__(self, table_name: str):\n        self.table_name = table_name\n        self.batch_response: PartialItemFailureResponse = copy.deepcopy(self.DEFAULT_RESPONSE)\n        super().__init__()\n\n    def _prepare(self):\n        # It's called once, *before* processing\n        # Creates table resource and clean previous results\n        self.ddb_table = boto3.resource(\"dynamodb\").Table(self.table_name)\n        self.success_messages.clear()\n\n    def response(self) -&gt; PartialItemFailureResponse:\n        return self.batch_response\n\n    def _clean(self):\n        # It's called once, *after* closing processing all records (closing the context manager)\n        # Here we're sending, at once, all successful messages to a ddb table\n        with self.ddb_table.batch_writer() as batch:\n            for result in self.success_messages:\n                batch.put_item(Item=result)\n\n    def _process_record(self, record):\n        # It handles how your record is processed\n        # Here we're keeping the status of each run\n        # where self.handler is the record_handler function passed as an argument\n        try:\n            result = self.handler(record)  # record_handler passed to decorator/context manager\n            return self.success_handler(record, result)\n        except Exception as exc:\n            logger.error(exc)\n            return self.failure_handler(record, sys.exc_info())\n\n    def success_handler(self, record, result: Any):\n        entry = (\"success\", result, record)\n        self.success_messages.append(record)\n        return entry\n\n    async def _async_process_record(self, record: dict):\n        raise NotImplementedError()\n\n\nprocessor = MyPartialProcessor(table_name)\n\n\ndef record_handler(record):\n    return randint(0, 100)\n\n\ndef lambda_handler(event, context):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> <pre><code>Transform: AWS::Serverless-2016-10-31\nResources:\n  IdempotencyTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      AttributeDefinitions:\n        - AttributeName: messageId\n          AttributeType: S\n      KeySchema:\n        - AttributeName: messageId\n          KeyType: HASH\n      TimeToLiveSpecification:\n        AttributeName: expiration\n        Enabled: true\n      BillingMode: PAY_PER_REQUEST\n</code></pre> <pre><code>{\n    \"Records\": [\n      {\n        \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n        \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n        \"body\": \"{\\\"Message\\\": \\\"success\\\"}\"\n      },\n      {\n        \"messageId\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\",\n        \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n        \"body\": \"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\"\n      }\n    ]\n  }\n</code></pre>"
        },
        {
            "location": "utilities/batch/#caveats",
            "title": "Caveats",
            "text": ""
        },
        {
            "location": "utilities/batch/#tracer-response-auto-capture-for-large-batch-sizes",
            "title": "Tracer response auto-capture for large batch sizes",
            "text": "<p>When using Tracer to capture responses for each batch record processing, you might exceed 64K of tracing data depending on what you return from your <code>record_handler</code> function, or how big is your batch size.</p> <p>If that's the case, you can configure Tracer to disable response auto-capturing.</p> Disabling Tracer response auto-capturing<pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method(capture_response=False)\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre>"
        },
        {
            "location": "utilities/batch/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>As there is no external calls, you can unit test your code with <code>BatchProcessor</code> quite easily.</p> <p>Example:</p> <p>Given a SQS batch where the first batch record succeeds and the second fails processing, we should have a single item reported in the function response.</p> getting_started_with_test.pygetting_started_with_test_app.pySample SQS event <pre><code>import json\nfrom dataclasses import dataclass\nfrom pathlib import Path\n\nimport pytest\nfrom getting_started_with_test_app import lambda_handler, processor\n\n\ndef load_event(path: Path):\n    with path.open() as f:\n        return json.load(f)\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n    aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\n@pytest.fixture()\ndef sqs_event():\n    \"\"\"Generates API GW Event\"\"\"\n    return load_event(path=Path(\"events/sqs_event.json\"))\n\n\ndef test_app_batch_partial_response(sqs_event, lambda_context: LambdaContext):\n    # GIVEN\n    processor_result = processor  # access processor for additional assertions\n    successful_record = sqs_event[\"Records\"][0]\n    failed_record = sqs_event[\"Records\"][1]\n    expected_response = {\"batchItemFailures\": [{\"itemIdentifier\": failed_record[\"messageId\"]}]}\n\n    # WHEN\n    ret = lambda_handler(sqs_event, lambda_context)\n\n    # THEN\n    assert ret == expected_response\n    assert len(processor_result.fail_messages) == 1\n    assert processor_result.success_messages[0] == successful_record\n</code></pre> <pre><code>import json\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\ntracer = Tracer()\nlogger = Logger()\n\n\n@tracer.capture_method\ndef record_handler(record: SQSRecord):\n    payload: str = record.body\n    if payload:\n        item: dict = json.loads(payload)\n        logger.info(item)\n\n\n@logger.inject_lambda_context\n@tracer.capture_lambda_handler\ndef lambda_handler(event, context: LambdaContext):\n    return process_partial_response(event=event, record_handler=record_handler, processor=processor, context=context)\n</code></pre> events/sqs_event.json<pre><code>{\n  \"Records\": [\n    {\n      \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n      \"body\": \"{\\\"Message\\\": \\\"success\\\"}\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082649183\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n      \"awsRegion\": \"us-east-1\"\n    },\n    {\n      \"messageId\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n      \"body\": \"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082649183\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n      \"awsRegion\": \"us-east-1\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch/#faq",
            "title": "FAQ",
            "text": ""
        },
        {
            "location": "utilities/batch/#choosing-between-method-and-context-manager",
            "title": "Choosing between method and context manager",
            "text": "<p>Use context manager when you want access to the processed messages or handle <code>BatchProcessingError</code> exception when all records within the batch fail to be processed.</p>"
        },
        {
            "location": "utilities/batch/#integrating-exception-handling-with-sentryio",
            "title": "Integrating exception handling with Sentry.io",
            "text": "<p>When using Sentry.io for error monitoring, you can override <code>failure_handler</code> to capture each processing exception with Sentry SDK:</p> <p>Credits to Charles-Axel Dein</p> Integrating error tracking with Sentry.io<pre><code>from sentry_sdk import capture_exception\n\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, FailureResponse\n\n\nclass MyProcessor(BatchProcessor):\n    def failure_handler(self, record, exception) -&gt; FailureResponse:\n        capture_exception()  # send exception to Sentry\n        return super().failure_handler(record, exception)\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/",
            "title": "Event Source Data Classes",
            "text": "<p>Event Source Data Classes provides self-describing and strongly-typed classes for various AWS Lambda event sources.</p>"
        },
        {
            "location": "utilities/data_classes/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Type hinting and code completion for common event types</li> <li>Helper functions for decoding/deserializing nested fields</li> <li>Docstrings for fields contained in event schemas</li> <li>Standardized attribute-based access to event properties</li> </ul>"
        },
        {
            "location": "utilities/data_classes/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>There are two ways to use Event Source Data Classes in your Lambda functions.</p> <p>Method 1: Direct Initialization</p> <p>You can initialize the appropriate data class by passing the Lambda event object to its constructor.</p> app.pyAPI Gateway Proxy Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import APIGatewayProxyEvent\n\n\ndef lambda_handler(event: dict, context):\n    api_event = APIGatewayProxyEvent(event)\n    if \"hello\" in api_event.path and api_event.http_method == \"GET\":\n        return {\"statusCode\": 200, \"body\": f\"Hello from path: {api_event.path}\"}\n    else:\n        return {\"statusCode\": 400, \"body\": \"No Hello from path\"}\n</code></pre> <pre><code>{\n    \"resource\": \"/helloworld\",\n    \"path\": \"/hello\",\n    \"httpMethod\": \"GET\",\n    \"headers\": {\n        \"Accept\": \"*/*\",\n        \"Host\": \"api.example.com\"\n    },\n    \"queryStringParameters\": {\n        \"name\": \"John\"\n    },\n    \"pathParameters\": null,\n    \"stageVariables\": null,\n    \"requestContext\": {\n        \"requestId\": \"c6af9ac6-7b61-11e6-9a41-93e8deadbeef\",\n        \"stage\": \"prod\"\n    },\n    \"body\": null,\n    \"isBase64Encoded\": false\n}\n</code></pre> <p>Method 2: Using the event_source Decorator</p> <p>Alternatively, you can use the <code>event_source</code> decorator to automatically parse the event.</p> app.pyAPI Gateway Proxy Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import APIGatewayProxyEvent, event_source\n\n\n@event_source(data_class=APIGatewayProxyEvent)\ndef lambda_handler(event: APIGatewayProxyEvent, context):\n    if \"hello\" in event.path and event.http_method == \"GET\":\n        return {\"statusCode\": 200, \"body\": f\"Hello from path: {event.path}\"}\n    else:\n        return {\"statusCode\": 400, \"body\": \"No Hello from path\"}\n</code></pre> <pre><code>{\n    \"resource\": \"/helloworld\",\n    \"path\": \"/hello\",\n    \"httpMethod\": \"GET\",\n    \"headers\": {\n        \"Accept\": \"*/*\",\n        \"Host\": \"api.example.com\"\n    },\n    \"queryStringParameters\": {\n        \"name\": \"John\"\n    },\n    \"pathParameters\": null,\n    \"stageVariables\": null,\n    \"requestContext\": {\n        \"requestId\": \"c6af9ac6-7b61-11e6-9a41-93e8deadbeef\",\n        \"stage\": \"prod\"\n    },\n    \"body\": null,\n    \"isBase64Encoded\": false\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#autocomplete-with-self-documented-properties-and-methods",
            "title": "Autocomplete with self-documented properties and methods",
            "text": "<p>Event Source Data Classes has the ability to leverage IDE autocompletion and inline documentation. When using the APIGatewayProxyEvent class, for example, the IDE will offer autocomplete suggestions for various properties and methods.</p> <p></p>"
        },
        {
            "location": "utilities/data_classes/#supported-event-sources",
            "title": "Supported event sources",
            "text": "<p>Each event source is linked to its corresponding GitHub file with the full set of properties, methods, and docstrings specific to each event type.</p> Event Source Data_class Properties Active MQ <code>ActiveMQEvent</code> Github API Gateway Authorizer <code>APIGatewayAuthorizerRequestEvent</code> Github API Gateway Authorizer V2 <code>APIGatewayAuthorizerEventV2</code> Github API Gateway Proxy <code>APIGatewayProxyEvent</code> Github API Gateway Proxy V2 <code>APIGatewayProxyEventV2</code> Github Application Load Balancer <code>ALBEvent</code> Github AppSync Authorizer <code>AppSyncAuthorizerEvent</code> Github AppSync Resolver <code>AppSyncResolverEvent</code> Github AWS Config Rule <code>AWSConfigRuleEvent</code> Github Bedrock Agent <code>BedrockAgent</code> Github CloudFormation Custom Resource <code>CloudFormationCustomResourceEvent</code> Github CloudWatch Alarm State Change Action <code>CloudWatchAlarmEvent</code> Github CloudWatch Dashboard Custom Widget <code>CloudWatchDashboardCustomWidgetEvent</code> Github CloudWatch Logs <code>CloudWatchLogsEvent</code> Github CodeDeploy Lifecycle Hook <code>CodeDeployLifecycleHookEvent</code> Github CodePipeline Job Event <code>CodePipelineJobEvent</code> Github Cognito User Pool Multiple available under <code>cognito_user_pool_event</code> Github Connect Contact Flow <code>ConnectContactFlowEvent</code> Github DynamoDB streams <code>DynamoDBStreamEvent</code>, <code>DynamoDBRecordEventName</code> Github EventBridge <code>EventBridgeEvent</code> Github Kafka <code>KafkaEvent</code> Github Kinesis Data Stream <code>KinesisStreamEvent</code> Github Kinesis Firehose Delivery Stream <code>KinesisFirehoseEvent</code> Github Lambda Function URL <code>LambdaFunctionUrlEvent</code> Github Rabbit MQ <code>RabbitMQEvent</code> Github S3 <code>S3Event</code> Github S3 Batch Operations <code>S3BatchOperationEvent</code> Github S3 Object Lambda <code>S3ObjectLambdaEvent</code> Github S3 EventBridge Notification <code>S3EventBridgeNotificationEvent</code> Github SES <code>SESEvent</code> Github SNS <code>SNSEvent</code> Github SQS <code>SQSEvent</code> Github [TransferFamilyAuthorizer] <code>TransferFamilyAuthorizer</code> Github [TransferFamilyAuthorizerResponse] <code>TransferFamilyAuthorizerResponse</code> Github VPC Lattice V2 <code>VPCLatticeV2Event</code> Github VPC Lattice V1 <code>VPCLatticeEvent</code> Github IoT Core Thing Created/Updated/Deleted <code>IoTCoreThingEvent</code> GitHub IoT Core Thing Type Created/Updated/Deprecated/Undeprecated/Deleted <code>IoTCoreThingTypeEvent</code> GitHub IoT Core Thing Type Associated/Disassociated with a Thing <code>IoTCoreThingTypeAssociationEvent</code> GitHub IoT Core Thing Group Created/Updated/Deleted <code>IoTCoreThingGroupEvent</code> GitHub IoT Thing Added/Removed from Thing Group <code>IoTCoreAddOrRemoveFromThingGroupEvent</code> GitHub IoT Child Group Added/Deleted from Parent Group <code>IoTCoreAddOrDeleteFromThingGroupEvent</code> GitHub Info <p>The examples showcase a subset of Event Source Data Classes capabilities - for comprehensive details, leverage your IDE's autocompletion, refer to type hints and docstrings, and explore the full API reference for complete property listings of each event source.</p>"
        },
        {
            "location": "utilities/data_classes/#active-mq",
            "title": "Active MQ",
            "text": "<p>It is used for Active MQ payloads, also see the AWS blog post for more details.</p> app.pyActive MQ Example Event <pre><code>import json\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.active_mq_event import ActiveMQEvent\n\nlogger = Logger()\n\n\n@event_source(data_class=ActiveMQEvent)\ndef lambda_handler(event: ActiveMQEvent, context):\n    for message in event.messages:\n        msg = message.message_id\n        msg_pn = message.destination_physicalname\n\n        logger.info(f\"Message ID: {msg} and physical name: {msg_pn}\")\n\n    return {\"statusCode\": 200, \"body\": json.dumps(\"Processing complete\")}\n</code></pre> <pre><code>{\n  \"eventSource\": \"aws:amq\",\n  \"eventSourceArn\": \"arn:aws:mq:us-west-2:112556298976:broker:test:b-9bcfa592-423a-4942-879d-eb284b418fc8\",\n  \"messages\": [\n    {\n      \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-west-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\",\n      \"messageType\": \"jms/text-message\",\n      \"data\": \"QUJDOkFBQUE=\",\n      \"connectionId\": \"myJMSCoID\",\n      \"redelivered\": false,\n      \"destination\": {\n        \"physicalName\": \"testQueue\"\n      },\n      \"timestamp\": 1598827811958,\n      \"brokerInTime\": 1598827811958,\n      \"brokerOutTime\": 1598827811959,\n      \"properties\": {\n        \"testKey\": \"testValue\"\n      }\n    },\n    {\n      \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-west-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\",\n      \"messageType\": \"jms/text-message\",\n      \"data\": \"eyJ0aW1lb3V0IjowLCJkYXRhIjoiQ1pybWYwR3c4T3Y0YnFMUXhENEUifQ==\",\n      \"connectionId\": \"myJMSCoID2\",\n      \"redelivered\": false,\n      \"destination\": {\n        \"physicalName\": \"testQueue\"\n      },\n      \"timestamp\": 1598827811958,\n      \"brokerInTime\": 1598827811958,\n      \"brokerOutTime\": 1598827811959,\n      \"properties\": {\n        \"testKey\": \"testValue\"\n      }\n\n    },\n    {\n      \"messageID\": \"ID:b-9bcfa592-423a-4942-879d-eb284b418fc8-1.mq.us-west-2.amazonaws.com-37557-1234520418293-4:1:1:1:1\",\n      \"messageType\": \"jms/bytes-message\",\n      \"data\": \"3DTOOW7crj51prgVLQaGQ82S48k=\",\n      \"connectionId\": \"myJMSCoID1\",\n      \"persistent\": false,\n      \"destination\": {\n        \"physicalName\": \"testQueue\"\n      },\n      \"timestamp\": 1598827811958,\n      \"brokerInTime\": 1598827811958,\n      \"brokerOutTime\": 1598827811959,\n      \"properties\": {\n        \"testKey\": \"testValue\"\n      }\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#api-gateway-authorizer",
            "title": "API Gateway Authorizer",
            "text": "<p>It is used for API Gateway Rest API Lambda Authorizer payload.</p> <p>Use <code>APIGatewayAuthorizerRequestEvent</code> for type <code>REQUEST</code> and <code>APIGatewayAuthorizerTokenEvent</code> for type <code>TOKEN</code>.</p> Rest APIsWebSocket APIsAPI Gateway Authorizer Request Example Eventapp_token.pyAPI Gateway Authorizer Token Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.api_gateway_authorizer_event import (\n    APIGatewayAuthorizerRequestEvent,\n    APIGatewayAuthorizerResponse,\n)\n\n\n@event_source(data_class=APIGatewayAuthorizerRequestEvent)\ndef lambda_handler(event: APIGatewayAuthorizerRequestEvent, context):\n    # Simple auth check (replace with your actual auth logic)\n    is_authorized = event.headers.get(\"HeaderAuth1\") == \"headerValue1\"\n\n    if not is_authorized:\n        return {\"principalId\": \"\", \"policyDocument\": {\"Version\": \"2012-10-17\", \"Statement\": []}}\n\n    arn = event.parsed_arn\n\n    policy = APIGatewayAuthorizerResponse(\n        principal_id=\"user\",\n        context={\"user\": \"example\"},\n        region=arn.region,\n        aws_account_id=arn.aws_account_id,\n        api_id=arn.api_id,\n        stage=arn.stage,\n    )\n\n    policy.allow_all_routes()\n\n    return policy.asdict()\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.api_gateway_authorizer_event import (\n    APIGatewayAuthorizerRequestEvent,\n    APIGatewayAuthorizerResponseWebSocket,\n)\n\n\n@event_source(data_class=APIGatewayAuthorizerRequestEvent)\ndef lambda_handler(event: APIGatewayAuthorizerRequestEvent, context):\n    # Simple auth check (replace with your actual auth logic)\n    is_authorized = event.headers.get(\"HeaderAuth1\") == \"headerValue1\"\n\n    if not is_authorized:\n        return {\"principalId\": \"\", \"policyDocument\": {\"Version\": \"2012-10-17\", \"Statement\": []}}\n\n    arn = event.parsed_arn\n\n    policy = APIGatewayAuthorizerResponseWebSocket(\n        principal_id=\"user\",\n        context={\"user\": \"example\"},\n        region=arn.region,\n        aws_account_id=arn.aws_account_id,\n        api_id=arn.api_id,\n        stage=arn.stage,\n    )\n\n    policy.allow_all_routes()\n\n    return policy.asdict()\n</code></pre> <pre><code>{\n  \"version\": \"1.0\",\n  \"type\": \"REQUEST\",\n  \"methodArn\": \"arn:aws:execute-api:us-east-1:123456789012:abcdef123/test/GET/request\",\n  \"identitySource\": \"user1,123\",\n  \"authorizationToken\": \"user1,123\",\n  \"resource\": \"/request\",\n  \"path\": \"/request\",\n  \"httpMethod\": \"GET\",\n  \"headers\": {\n    \"X-AMZ-Date\": \"20170718T062915Z\",\n    \"Accept\": \"*/*\",\n    \"HeaderAuth1\": \"headerValue1\",\n    \"CloudFront-Viewer-Country\": \"US\",\n    \"CloudFront-Forwarded-Proto\": \"https\",\n    \"CloudFront-Is-Tablet-Viewer\": \"false\",\n    \"CloudFront-Is-Mobile-Viewer\": \"false\",\n    \"User-Agent\": \"...\"\n  },\n  \"multiValueHeaders\": {\n    \"Header1\": [\n      \"value1\"\n    ],\n    \"Origin\": [\n      \"https://aws.amazon.com\"\n    ],\n    \"Header2\": [\n      \"value1\",\n      \"value2\"\n    ]\n  },\n  \"queryStringParameters\": {\n    \"QueryString1\": \"queryValue1\"\n  },\n  \"pathParameters\": {},\n  \"stageVariables\": {\n    \"StageVar1\": \"stageValue1\"\n  },\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"apiId\": \"abcdef123\",\n    \"domainName\": \"3npb9j1tlk.execute-api.us-west-1.amazonaws.com\",\n    \"domainPrefix\": \"3npb9j1tlk\",\n    \"extendedRequestId\": \"EXqgWgXxSK4EJug=\",\n    \"httpMethod\": \"GET\",\n    \"identity\": {\n      \"accessKey\": null,\n      \"accountId\": null,\n      \"caller\": null,\n      \"cognitoAmr\": null,\n      \"cognitoAuthenticationProvider\": null,\n      \"cognitoAuthenticationType\": null,\n      \"cognitoIdentityId\": null,\n      \"cognitoIdentityPoolId\": null,\n      \"principalOrgId\": null,\n      \"apiKey\": \"...\",\n      \"sourceIp\": \"test-invoke-source-ip\",\n      \"user\": null,\n      \"userAgent\": \"PostmanRuntime/7.28.3\",\n      \"userArn\": null,\n      \"clientCert\": {\n        \"clientCertPem\": \"CERT_CONTENT\",\n        \"subjectDN\": \"www.example.com\",\n        \"issuerDN\": \"Example issuer\",\n        \"serialNumber\": \"a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1\",\n        \"validity\": {\n          \"notBefore\": \"May 28 12:30:02 2019 GMT\",\n          \"notAfter\": \"Aug  5 09:36:04 2021 GMT\"\n        }\n      }\n    },\n    \"path\": \"/request\",\n    \"protocol\": \"HTTP/1.1\",\n    \"requestId\": \"EXqgWgXxSK4EJug=\",\n    \"requestTime\": \"20/Aug/2021:14:36:50 +0000\",\n    \"requestTimeEpoch\": 1629470210043,\n    \"resourceId\": \"ANY /request\",\n    \"resourcePath\": \"/request\",\n    \"stage\": \"test\"\n  }\n}\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.api_gateway_authorizer_event import (\n    APIGatewayAuthorizerResponse,\n    APIGatewayAuthorizerTokenEvent,\n)\n\n\n@event_source(data_class=APIGatewayAuthorizerTokenEvent)\ndef lambda_handler(event: APIGatewayAuthorizerTokenEvent, context):\n    # Simple token check (replace with your actual token validation logic)\n    is_valid_token = event.authorization_token == \"allow\"\n\n    if not is_valid_token:\n        return {\"principalId\": \"\", \"policyDocument\": {\"Version\": \"2012-10-17\", \"Statement\": []}}\n\n    arn = event.parsed_arn\n\n    policy = APIGatewayAuthorizerResponse(\n        principal_id=\"user\",\n        context={\"user\": \"example\"},\n        region=arn.region,\n        aws_account_id=arn.aws_account_id,\n        api_id=arn.api_id,\n        stage=arn.stage,\n    )\n\n    policy.allow_all_routes()\n\n    return policy.asdict()\n</code></pre> <pre><code>{\n  \"type\": \"TOKEN\",\n  \"authorizationToken\": \"allow\",\n  \"methodArn\": \"arn:aws:execute-api:us-west-2:123456789012:ymy8tbxw7b/*/GET/\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#api-gateway-authorizer-v2",
            "title": "API Gateway Authorizer V2",
            "text": "<p>It is used for API Gateway HTTP API Lambda Authorizer payload version 2. See also this blog post for more details.</p> app.pyAPI Gateway Authorizer V2 Example Event <pre><code>from secrets import compare_digest\n\nfrom aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.api_gateway_authorizer_event import (\n    APIGatewayAuthorizerEventV2,\n    APIGatewayAuthorizerResponseV2,\n)\n\n\ndef get_user_by_token(token):\n    if compare_digest(token, \"value\"):\n        return {\"name\": \"Foo\"}\n    return None\n\n\n@event_source(data_class=APIGatewayAuthorizerEventV2)\ndef lambda_handler(event: APIGatewayAuthorizerEventV2, context):\n    user = get_user_by_token(event.headers.get(\"Authorization\"))\n\n    if user is None:\n        # No user was found, so we return not authorized\n        return APIGatewayAuthorizerResponseV2(authorize=False).asdict()\n\n    # Found the user and setting the details in the context\n    response = APIGatewayAuthorizerResponseV2(\n        authorize=True,\n        context=user,\n    )\n\n    return response.asdict()\n</code></pre> <pre><code>{\n  \"version\": \"2.0\",\n  \"type\": \"REQUEST\",\n  \"routeArn\": \"arn:aws:execute-api:us-east-1:123456789012:abcdef123/test/GET/request\",\n  \"identitySource\": [\"user1\", \"123\"],\n  \"routeKey\": \"GET /merchants\",\n  \"rawPath\": \"/merchants\",\n  \"rawQueryString\": \"parameter1=value1&amp;parameter1=value2&amp;parameter2=value\",\n  \"cookies\": [\"cookie1\", \"cookie2\"],\n  \"headers\": {\n    \"x-amzn-trace-id\": \"Root=1-611cc4a7-0746ebee281cfd967db97b64\",\n    \"Header1\": \"value1\",\n    \"Header2\": \"value2\",\n    \"Authorization\": \"value\"\n  },\n  \"queryStringParameters\": {\n    \"parameter1\": \"value1,value2\",\n    \"parameter2\": \"value\"\n  },\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"apiId\": \"api-id\",\n    \"authentication\": {\n      \"clientCert\": {\n        \"clientCertPem\": \"CERT_CONTENT\",\n        \"subjectDN\": \"www.example.com\",\n        \"issuerDN\": \"Example issuer\",\n        \"serialNumber\": \"a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1\",\n        \"validity\": {\n          \"notBefore\": \"May 28 12:30:02 2019 GMT\",\n          \"notAfter\": \"Aug  5 09:36:04 2021 GMT\"\n        }\n      }\n    },\n    \"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n    \"domainPrefix\": \"id\",\n    \"http\": {\n      \"method\": \"POST\",\n      \"path\": \"/merchants\",\n      \"protocol\": \"HTTP/1.1\",\n      \"sourceIp\": \"10.10.10.10\",\n      \"userAgent\": \"agent\"\n    },\n    \"requestId\": \"id\",\n    \"routeKey\": \"GET /merchants\",\n    \"stage\": \"$default\",\n    \"time\": \"12/Mar/2020:19:03:58 +0000\",\n    \"timeEpoch\": 1583348638390\n  },\n  \"pathParameters\": { \"parameter1\": \"value1\" },\n  \"stageVariables\": { \"stageVariable1\": \"value1\", \"stageVariable2\": \"value2\" }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#api-gateway-proxy",
            "title": "API Gateway Proxy",
            "text": "<p>It is used for either API Gateway REST API or HTTP API using v1 proxy event.</p> app.pyAPI Gateway Proxy Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import APIGatewayProxyEvent, event_source\n\n\n@event_source(data_class=APIGatewayProxyEvent)\ndef lambda_handler(event: APIGatewayProxyEvent, context):\n    if \"hello\" in event.path and event.http_method == \"GET\":\n        return {\"statusCode\": 200, \"body\": f\"Hello from path: {event.path}\"}\n    else:\n        return {\"statusCode\": 400, \"body\": \"No Hello from path\"}\n</code></pre> <pre><code>{\n    \"resource\": \"/helloworld\",\n    \"path\": \"/hello\",\n    \"httpMethod\": \"GET\",\n    \"headers\": {\n        \"Accept\": \"*/*\",\n        \"Host\": \"api.example.com\"\n    },\n    \"queryStringParameters\": {\n        \"name\": \"John\"\n    },\n    \"pathParameters\": null,\n    \"stageVariables\": null,\n    \"requestContext\": {\n        \"requestId\": \"c6af9ac6-7b61-11e6-9a41-93e8deadbeef\",\n        \"stage\": \"prod\"\n    },\n    \"body\": null,\n    \"isBase64Encoded\": false\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#api-gateway-proxy-v2",
            "title": "API Gateway Proxy V2",
            "text": "<p>It is used for HTTP API using v2 proxy event.</p> app.pyAPI Gateway Proxy V2 Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import APIGatewayProxyEventV2, event_source\n\n\n@event_source(data_class=APIGatewayProxyEventV2)\ndef lambda_handler(event: APIGatewayProxyEventV2, context):\n    if \"hello\" in event.path and event.http_method == \"POST\":\n        return {\"statusCode\": 200, \"body\": f\"Hello from path: {event.path}\"}\n    else:\n        return {\"statusCode\": 400, \"body\": \"No Hello from path\"}\n</code></pre> <pre><code>{\n  \"version\": \"2.0\",\n  \"routeKey\": \"$default\",\n  \"rawPath\": \"/my/path\",\n  \"rawQueryString\": \"parameter1=value1&amp;parameter1=value2&amp;parameter2=value\",\n  \"cookies\": [\n    \"cookie1\",\n    \"cookie2\"\n  ],\n  \"headers\": {\n    \"Header1\": \"value1\",\n    \"Header2\": \"value1,value2\"\n  },\n  \"queryStringParameters\": {\n    \"parameter1\": \"value1,value2\",\n    \"parameter2\": \"value\"\n  },\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"apiId\": \"api-id\",\n    \"authentication\": {\n      \"clientCert\": {\n        \"clientCertPem\": \"CERT_CONTENT\",\n        \"subjectDN\": \"www.example.com\",\n        \"issuerDN\": \"Example issuer\",\n        \"serialNumber\": \"a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1\",\n        \"validity\": {\n          \"notBefore\": \"May 28 12:30:02 2019 GMT\",\n          \"notAfter\": \"Aug  5 09:36:04 2021 GMT\"\n        }\n      }\n    },\n    \"authorizer\": {\n      \"jwt\": {\n        \"claims\": {\n          \"claim1\": \"value1\",\n          \"claim2\": \"value2\"\n        },\n        \"scopes\": [\n          \"scope1\",\n          \"scope2\"\n        ]\n      }\n    },\n    \"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n    \"domainPrefix\": \"id\",\n    \"http\": {\n      \"method\": \"POST\",\n      \"path\": \"/my/path\",\n      \"protocol\": \"HTTP/1.1\",\n      \"sourceIp\": \"192.168.0.1/32\",\n      \"userAgent\": \"agent\"\n    },\n    \"requestId\": \"id\",\n    \"routeKey\": \"$default\",\n    \"stage\": \"$default\",\n    \"time\": \"12/Mar/2020:19:03:58 +0000\",\n    \"timeEpoch\": 1583348638390\n  },\n  \"body\": \"{\\\"message\\\": \\\"hello world\\\", \\\"username\\\": \\\"tom\\\"}\",\n  \"pathParameters\": {\n    \"parameter1\": \"value1\"\n  },\n  \"isBase64Encoded\": false,\n  \"stageVariables\": {\n    \"stageVariable1\": \"value1\",\n    \"stageVariable2\": \"value2\"\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#application-load-balancer",
            "title": "Application Load Balancer",
            "text": "<p>Is it used for Application load balancer event.</p> app.pyApplication Load Balancer Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import ALBEvent, event_source\n\n\n@event_source(data_class=ALBEvent)\ndef lambda_handler(event: ALBEvent, context):\n    if \"lambda\" in event.path and event.http_method == \"GET\":\n        return {\"statusCode\": 200, \"body\": f\"Hello from path: {event.path}\"}\n    else:\n        return {\"statusCode\": 400, \"body\": \"No Hello from path\"}\n</code></pre> <pre><code>{\n  \"requestContext\": {\n    \"elb\": {\n      \"targetGroupArn\": \"arn:aws:elasticloadbalancing:us-east-2:123456789012:targetgroup/lambda-279XGJDqGZ5rsrHC2Fjr/49e9d65c45c6791a\"\n    }\n  },\n  \"httpMethod\": \"GET\",\n  \"path\": \"/lambda\",\n  \"queryStringParameters\": {\n    \"query\": \"1234ABCD\"\n  },\n  \"headers\": {\n    \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n    \"accept-encoding\": \"gzip\",\n    \"accept-language\": \"en-US,en;q=0.9\",\n    \"connection\": \"keep-alive\",\n    \"host\": \"lambda-alb-123578498.us-east-2.elb.amazonaws.com\",\n    \"upgrade-insecure-requests\": \"1\",\n    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\",\n    \"x-amzn-trace-id\": \"Root=1-5c536348-3d683b8b04734faae651f476\",\n    \"x-forwarded-for\": \"72.12.164.125\",\n    \"x-forwarded-port\": \"80\",\n    \"x-forwarded-proto\": \"http\",\n    \"x-imforwards\": \"20\"\n  },\n  \"body\": \"Test\",\n  \"isBase64Encoded\": false\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#appsync-authorizer",
            "title": "AppSync Authorizer",
            "text": "<p>Used when building an AWS_LAMBDA Authorization with AppSync. See blog post Introducing Lambda authorization for AWS AppSync GraphQL APIs or read the Amplify documentation on using AWS Lambda for authorization with AppSync.</p> app.pyAppSync Authorizer Example Event <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.logging import correlation_paths\nfrom aws_lambda_powertools.logging.logger import Logger\nfrom aws_lambda_powertools.utilities.data_classes.appsync_authorizer_event import (\n    AppSyncAuthorizerEvent,\n    AppSyncAuthorizerResponse,\n)\nfrom aws_lambda_powertools.utilities.data_classes.event_source import event_source\n\nlogger = Logger()\n\n\ndef get_user_by_token(token: str):\n    \"\"\"Look a user by token\"\"\"\n    ...\n\n\n@logger.inject_lambda_context(correlation_id_path=correlation_paths.APPSYNC_AUTHORIZER)\n@event_source(data_class=AppSyncAuthorizerEvent)\ndef lambda_handler(event: AppSyncAuthorizerEvent, context) -&gt; Dict:\n    user = get_user_by_token(event.authorization_token)\n\n    if not user:\n        # No user found, return not authorized\n        return AppSyncAuthorizerResponse().asdict()\n\n    return AppSyncAuthorizerResponse(\n        authorize=True,\n        resolver_context={\"id\": user.id},\n        # Only allow admins to delete events\n        deny_fields=None if user.is_admin else [\"Mutation.deleteEvent\"],\n    ).asdict()\n</code></pre> <pre><code>{\n    \"authorizationToken\": \"BE9DC5E3-D410-4733-AF76-70178092E681\",\n    \"requestContext\": {\n        \"apiId\": \"giy7kumfmvcqvbedntjwjvagii\",\n        \"accountId\": \"254688921111\",\n        \"requestId\": \"b80ed838-14c6-4500-b4c3-b694c7bef086\",\n        \"queryString\": \"mutation MyNewTask($desc: String!) {\\n  createTask(description: $desc, owner: \\\"ccc\\\", taskStatus: \\\"cc\\\", title: \\\"ccc\\\") {\\n    id\\n  }\\n}\\n\",\n        \"operationName\": \"MyNewTask\",\n        \"variables\": {\n            \"desc\": \"Foo\"\n        }\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#appsync-resolver",
            "title": "AppSync Resolver",
            "text": "<p>Used when building Lambda GraphQL Resolvers with Amplify GraphQL Transform Library (<code>@function</code>), and AppSync Direct Lambda Resolvers.</p> <p>The example serves as an AppSync resolver for the <code>locations</code> field of the <code>Merchant</code> type. It uses the <code>@event_source</code> decorator to parse the AppSync event, handles pagination and filtering for locations, and demonstrates <code>AppSyncIdentityCognito</code>.</p> app.pyAppSync Resolver Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.appsync_resolver_event import (\n    AppSyncIdentityCognito,\n    AppSyncResolverEvent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@event_source(data_class=AppSyncResolverEvent)\ndef lambda_handler(event: AppSyncResolverEvent, context: LambdaContext):\n    # Access the AppSync event details\n    type_name = event.type_name\n    field_name = event.field_name\n    arguments = event.arguments\n    source = event.source\n\n    print(f\"Resolving field '{field_name}' for type '{type_name}'\")\n    print(f\"Arguments: {arguments}\")\n    print(f\"Source: {source}\")\n\n    # Check if the identity is Cognito-based\n    if isinstance(event.identity, AppSyncIdentityCognito):\n        user_id = event.identity.sub\n        username = event.identity.username\n        print(f\"Request from Cognito user: {username} (ID: {user_id})\")\n    else:\n        print(\"Request is not from a Cognito-authenticated user\")\n\n    if type_name == \"Merchant\" and field_name == \"locations\":\n        page = arguments.get(\"page\", 1)\n        size = arguments.get(\"size\", 10)\n        name_filter = arguments.get(\"name\")\n\n        # Here you would typically fetch locations from a database\n        # This is a mock implementation\n        locations = [\n            {\"id\": \"1\", \"name\": \"Location 1\", \"address\": \"123 Main St\"},\n            {\"id\": \"2\", \"name\": \"Location 2\", \"address\": \"456 Elm St\"},\n            {\"id\": \"3\", \"name\": \"Location 3\", \"address\": \"789 Oak St\"},\n        ]\n\n        # Apply name filter if provided\n        if name_filter:\n            locations = [loc for loc in locations if name_filter.lower() in loc[\"name\"].lower()]\n\n        # Apply pagination\n        start = (page - 1) * size\n        end = start + size\n        paginated_locations = locations[start:end]\n\n        return {\n            \"items\": paginated_locations,\n            \"totalCount\": len(locations),\n            \"nextToken\": str(page + 1) if end &lt; len(locations) else None,\n        }\n    else:\n        raise Exception(f\"Unhandled field: {field_name} for type: {type_name}\")\n</code></pre> <pre><code>{\n  \"typeName\": \"Merchant\",\n  \"fieldName\": \"locations\",\n  \"arguments\": {\n    \"page\": 2,\n    \"size\": 1,\n    \"name\": \"value\"\n  },\n  \"identity\": {\n    \"claims\": {\n      \"sub\": \"07920713-4526-4642-9c88-2953512de441\",\n      \"iss\": \"https://cognito-idp.us-east-1.amazonaws.com/us-east-1_POOL_ID\",\n      \"aud\": \"58rc9bf5kkti90ctmvioppukm9\",\n      \"event_id\": \"7f4c9383-abf6-48b7-b821-91643968b755\",\n      \"token_use\": \"id\",\n      \"auth_time\": 1615366261,\n      \"name\": \"Michael Brewer\",\n      \"exp\": 1615369861,\n      \"iat\": 1615366261\n    },\n    \"defaultAuthStrategy\": \"ALLOW\",\n    \"groups\": null,\n    \"issuer\": \"https://cognito-idp.us-east-1.amazonaws.com/us-east-1_POOL_ID\",\n    \"sourceIp\": [\n      \"11.215.2.22\"\n    ],\n    \"sub\": \"07920713-4526-4642-9c88-2953512de441\",\n    \"username\": \"mike\"\n  },\n  \"source\": {\n    \"name\": \"Value\",\n    \"nested\": {\n      \"name\": \"value\",\n      \"list\": []\n    }\n  },\n  \"request\": {\n    \"headers\": {\n      \"x-forwarded-for\": \"11.215.2.22, 64.44.173.11\",\n      \"cloudfront-viewer-country\": \"US\",\n      \"cloudfront-is-tablet-viewer\": \"false\",\n      \"via\": \"2.0 SOMETHING.cloudfront.net (CloudFront)\",\n      \"cloudfront-forwarded-proto\": \"https\",\n      \"origin\": \"https://console.aws.amazon.com\",\n      \"content-length\": \"156\",\n      \"accept-language\": \"en-US,en;q=0.9\",\n      \"host\": \"SOMETHING.appsync-api.us-east-1.amazonaws.com\",\n      \"x-forwarded-proto\": \"https\",\n      \"sec-gpc\": \"1\",\n      \"user-agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) etc.\",\n      \"accept\": \"*/*\",\n      \"cloudfront-is-mobile-viewer\": \"false\",\n      \"cloudfront-is-smarttv-viewer\": \"false\",\n      \"accept-encoding\": \"gzip, deflate, br\",\n      \"referer\": \"https://console.aws.amazon.com/\",\n      \"content-type\": \"application/json\",\n      \"sec-fetch-mode\": \"cors\",\n      \"x-amz-cf-id\": \"Fo5VIuvP6V6anIEt62WzFDCK45mzM4yEdpt5BYxOl9OFqafd-WR0cA==\",\n      \"x-amzn-trace-id\": \"Root=1-60488877-0b0c4e6727ab2a1c545babd0\",\n      \"authorization\": \"AUTH-HEADER\",\n      \"sec-fetch-dest\": \"empty\",\n      \"x-amz-user-agent\": \"AWS-Console-AppSync/\",\n      \"cloudfront-is-desktop-viewer\": \"true\",\n      \"sec-fetch-site\": \"cross-site\",\n      \"x-forwarded-port\": \"443\"\n    }\n  },\n  \"prev\": {\n    \"result\": {}\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#aws-config-rule",
            "title": "AWS Config Rule",
            "text": "<p>The example utilizes AWSConfigRuleEvent to parse the incoming event. The function logs the message type of the invoking event and returns a simple success response. The example event receives a Scheduled Event Notification, but could also be ItemChanged and Oversized.</p> app.pyScheduledNotification Example Event <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import (\n    AWSConfigRuleEvent,\n    event_source,\n)\n\nlogger = Logger()\n\n\n@event_source(data_class=AWSConfigRuleEvent)\ndef lambda_handler(event: AWSConfigRuleEvent, context):\n    message_type = event.invoking_event.message_type\n\n    logger.info(f\"Logging {message_type} event rule\", invoke_event=event.raw_invoking_event)\n\n    return {\"Success\": \"OK\"}\n</code></pre> <pre><code>{\n    \"version\":\"1.0\",\n    \"invokingEvent\":\"{\\\"awsAccountId\\\":\\\"0123456789012\\\",\\\"notificationCreationTime\\\":\\\"2023-04-27T13:26:17.741Z\\\",\\\"messageType\\\":\\\"ScheduledNotification\\\",\\\"recordVersion\\\":\\\"1.0\\\"}\",\n    \"ruleParameters\":\"{\\\"test\\\":\\\"x\\\"}\",\n    \"resultToken\":\"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\",\n    \"eventLeftScope\":false,\n    \"executionRoleArn\":\"arn:aws:iam::0123456789012:role/aws-service-role/config.amazonaws.com/AWSServiceRoleForConfig\",\n    \"configRuleArn\":\"arn:aws:config:us-east-1:0123456789012:config-rule/config-rule-pdmyw1\",\n    \"configRuleName\":\"rule-ec2-test\",\n    \"configRuleId\":\"config-rule-pdmyw1\",\n    \"accountId\":\"0123456789012\",\n    \"evaluationMode\":\"DETECTIVE\"\n }\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#bedrock-agent",
            "title": "Bedrock Agent",
            "text": "<p>The example handles Bedrock Agent event with <code>BedrockAgentEvent</code> to parse the incoming event. The function logs the action group and input text, then returns a structured response compatible with Bedrock Agent's expected format, including a mock response body.</p> app.pyBedrock Agent Example Event <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import BedrockAgentEvent, event_source\n\nlogger = Logger()\n\n\n@event_source(data_class=BedrockAgentEvent)\ndef lambda_handler(event: BedrockAgentEvent, context) -&gt; dict:\n    input_text = event.input_text\n\n    logger.info(f\"Bedrock Agent {event.action_group} invoked with input\", input_text=input_text)\n\n    return {\n        \"message_version\": \"1.0\",\n        \"responses\": [\n            {\n                \"action_group\": event.action_group,\n                \"api_path\": event.api_path,\n                \"http_method\": event.http_method,\n                \"http_status_code\": 200,\n                \"response_body\": {\"application/json\": {\"body\": \"This is the response\"}},\n            },\n        ],\n    }\n</code></pre> <pre><code>{\n  \"actionGroup\": \"ClaimManagementActionGroup\",\n  \"messageVersion\": \"1.0\",\n  \"sessionId\": \"12345678912345\",\n  \"sessionAttributes\": {},\n  \"promptSessionAttributes\": {},\n  \"inputText\": \"I want to claim my insurance\",\n  \"agent\": {\n    \"alias\": \"TSTALIASID\",\n    \"name\": \"test\",\n    \"version\": \"DRAFT\",\n    \"id\": \"8ZXY0W8P1H\"\n  },\n  \"httpMethod\": \"GET\",\n  \"apiPath\": \"/claims\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#cloudformation-custom-resource",
            "title": "CloudFormation Custom Resource",
            "text": "<p>The example focuses on the <code>Create</code> request type, generating a unique physical resource ID and logging the process. The function is structured to potentially handle <code>Update</code> and <code>Delete</code> operations as well.</p> app.pyCloudFormation Custom Resource Example Event <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import (\n    CloudFormationCustomResourceEvent,\n    event_source,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@event_source(data_class=CloudFormationCustomResourceEvent)\ndef lambda_handler(event: CloudFormationCustomResourceEvent, context: LambdaContext):\n    request_type = event.request_type\n\n    if request_type == \"Create\":\n        return on_create(event, context)\n    else:\n        raise ValueError(f\"Invalid request type: {request_type}\")\n\n\ndef on_create(event: CloudFormationCustomResourceEvent, context: LambdaContext):\n    props = event.resource_properties\n    logger.info(f\"Create new resource with props {props}.\")\n\n    physical_id = f\"MyResource-{context.aws_request_id}\"\n\n    return {\"PhysicalResourceId\": physical_id, \"Data\": {\"Message\": \"Resource created successfully\"}}\n</code></pre> <pre><code>{\n  \"RequestType\": \"Create\",\n  \"ServiceToken\": \"arn:aws:lambda:us-east-1:xxx:function:xxxx-CrbuiltinfunctionidProvi-2vKAalSppmKe\",\n  \"ResponseURL\": \"https://cloudformation-custom-resource-response-useast1.s3.amazonaws.com/7F%7Cb1f50fdfc25f3b\",\n  \"StackId\": \"arn:aws:cloudformation:us-east-1:xxxx:stack/xxxx/271845b0-f2e8-11ed-90ac-0eeb25b8ae21\",\n  \"RequestId\": \"xxxxx-d2a0-4dfb-ab1f-xxxxxx\",\n  \"LogicalResourceId\": \"xxxxxxxxx\",\n  \"ResourceType\": \"Custom::MyType\",\n  \"ResourceProperties\": {\n    \"ServiceToken\": \"arn:aws:lambda:us-east-1:xxxxx:function:xxxxx\",\n    \"MyProps\": \"ss\"\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#cloudwatch-dashboard-custom-widget",
            "title": "CloudWatch Dashboard Custom Widget",
            "text": "<p>Thie example for <code>CloudWatchDashboardCustomWidgetEvent</code> logs the dashboard name, extracts key information like widget ID and time range, and returns a formatted response with a title and markdown content. Read more about custom widgets for Cloudwatch dashboard.</p> app.pyCloudWatch Dashboard Example Event <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import CloudWatchDashboardCustomWidgetEvent, event_source\n\nlogger = Logger()\n\n\n@event_source(data_class=CloudWatchDashboardCustomWidgetEvent)\ndef lambda_handler(event: CloudWatchDashboardCustomWidgetEvent, context):\n    if event.widget_context is None:\n        logger.warning(\"No widget context provided\")\n        return {\"title\": \"Error\", \"markdown\": \"Widget context is missing\"}\n\n    logger.info(f\"Processing custom widget for dashboard: {event.widget_context.dashboard_name}\")\n\n    # Access specific event properties\n    widget_id = event.widget_context.widget_id\n    time_range = event.widget_context.time_range\n\n    if time_range is None:\n        logger.warning(\"No time range provided\")\n        return {\"title\": f\"Custom Widget {widget_id}\", \"markdown\": \"Time range is missing\"}\n\n    # Your custom widget logic here\n    return {\n        \"title\": f\"Custom Widget {widget_id}\",\n        \"markdown\": f\"\"\"\n        Dashboard: {event.widget_context.dashboard_name}\n        Time Range: {time_range.start} to {time_range.end}\n        Theme: {event.widget_context.theme or 'default'}\n        \"\"\",\n    }\n</code></pre> <pre><code>{\n  \"original\": \"param-to-widget\",\n  \"widgetContext\": {\n    \"dashboardName\": \"Name-of-current-dashboard\",\n    \"widgetId\": \"widget-16\",\n    \"domain\": \"https://us-east-1.console.aws.amazon.com\",\n    \"accountId\": \"123456789123\",\n    \"locale\": \"en\",\n    \"timezone\": {\n      \"label\": \"UTC\",\n      \"offsetISO\": \"+00:00\",\n      \"offsetInMinutes\": 0\n    },\n    \"period\": 300,\n    \"isAutoPeriod\": true,\n    \"timeRange\": {\n      \"mode\": \"relative\",\n      \"start\": 1627236199729,\n      \"end\": 1627322599729,\n      \"relativeStart\": 86400012,\n      \"zoom\": {\n        \"start\": 1627276030434,\n        \"end\": 1627282956521\n      }\n    },\n    \"theme\": \"light\",\n    \"linkCharts\": true,\n    \"title\": \"Tweets for Amazon website problem\",\n    \"forms\": {\n      \"all\": {}\n    },\n    \"params\": {\n      \"original\": \"param-to-widget\"\n    },\n    \"width\": 588,\n    \"height\": 369\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#cloudwatch-alarm-state-change-action",
            "title": "CloudWatch Alarm State Change Action",
            "text": "<p>CloudWatch supports Lambda as an alarm state change action. You can use the <code>CloudWathAlarmEvent</code> data class to access the fields containing such data as alarm information, current state, and previous state.</p> app.pyCloudWatch Alarm Example Event <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import CloudWatchAlarmEvent, event_source\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@event_source(data_class=CloudWatchAlarmEvent)\ndef lambda_handler(event: CloudWatchAlarmEvent, context: LambdaContext) -&gt; dict:\n    logger.info(f\"Alarm {event.alarm_data.alarm_name} state is {event.alarm_data.state.value}\")\n\n    # You can now work with event. For example, you can enrich the received data, and\n    # decide on how you want to route the alarm.\n\n    return {\n        \"name\": event.alarm_data.alarm_name,\n        \"arn\": event.alarm_arn,\n        \"urgent\": \"Priority: P1\" in (event.alarm_data.configuration.description or \"\"),\n    }\n</code></pre> <pre><code>{\n  \"source\": \"aws.cloudwatch\",\n  \"alarmArn\": \"arn:aws:cloudwatch:eu-west-1:912397435824:alarm:test_alarm\",\n  \"accountId\": \"123456789012\",\n  \"time\": \"2024-02-17T11:53:08.431+0000\",\n  \"region\": \"eu-west-1\",\n  \"alarmData\": {\n    \"alarmName\": \"Test alert\",\n    \"state\": {\n      \"value\": \"ALARM\",\n      \"reason\": \"Threshold Crossed: 1 out of the last 1 datapoints [1.0 (17/02/24 11:51:00)] was less than the threshold (10.0) (minimum 1 datapoint for OK -&gt; ALARM transition).\",\n      \"reasonData\": \"{\\\"version\\\":\\\"1.0\\\",\\\"queryDate\\\":\\\"2024-02-17T11:53:08.423+0000\\\",\\\"startDate\\\":\\\"2024-02-17T11:51:00.000+0000\\\",\\\"statistic\\\":\\\"SampleCount\\\",\\\"period\\\":60,\\\"recentDatapoints\\\":[1.0],\\\"threshold\\\":10.0,\\\"evaluatedDatapoints\\\":[{\\\"timestamp\\\":\\\"2024-02-17T11:51:00.000+0000\\\",\\\"sampleCount\\\":1.0,\\\"value\\\":1.0}]}\",\n      \"timestamp\": \"2024-02-17T11:53:08.431+0000\"\n    },\n    \"previousState\": {\n      \"value\": \"OK\",\n      \"reason\": \"Threshold Crossed: 1 out of the last 1 datapoints [1.0 (17/02/24 11:50:00)] was not greater than the threshold (10.0) (minimum 1 datapoint for ALARM -&gt; OK transition).\",\n      \"reasonData\": \"{\\\"version\\\":\\\"1.0\\\",\\\"queryDate\\\":\\\"2024-02-17T11:51:31.460+0000\\\",\\\"startDate\\\":\\\"2024-02-17T11:50:00.000+0000\\\",\\\"statistic\\\":\\\"SampleCount\\\",\\\"period\\\":60,\\\"recentDatapoints\\\":[1.0],\\\"threshold\\\":10.0,\\\"evaluatedDatapoints\\\":[{\\\"timestamp\\\":\\\"2024-02-17T11:50:00.000+0000\\\",\\\"sampleCount\\\":1.0,\\\"value\\\":1.0}]}\",\n      \"timestamp\": \"2024-02-17T11:51:31.462+0000\"\n    },\n    \"configuration\": {\n      \"description\": \"This is description **here**\",\n      \"metrics\": [\n        {\n          \"id\": \"e1\",\n          \"expression\": \"m1/m2\",\n          \"label\": \"Expression1\",\n          \"returnData\": true\n        },\n        {\n          \"id\": \"m1\",\n          \"metricStat\": {\n            \"metric\": {\n              \"namespace\": \"AWS/Lambda\",\n              \"name\": \"Invocations\",\n              \"dimensions\": {}\n            },\n            \"period\": 60,\n            \"stat\": \"SampleCount\"\n          },\n          \"returnData\": false\n        },\n        {\n          \"id\": \"m2\",\n          \"metricStat\": {\n            \"metric\": {\n              \"namespace\": \"AWS/Lambda\",\n              \"name\": \"Duration\",\n              \"dimensions\": {}\n            },\n            \"period\": 60,\n            \"stat\": \"SampleCount\"\n          },\n          \"returnData\": false\n        }\n      ]\n    }\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#cloudwatch-logs",
            "title": "CloudWatch Logs",
            "text": "<p>CloudWatch Logs events by default are compressed and base64 encoded. You can use the helper function provided to decode, decompress and parse json data from the event.</p> app.pyCloudWatch Logs Example Event <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import CloudWatchLogsEvent, event_source\nfrom aws_lambda_powertools.utilities.data_classes.cloud_watch_logs_event import CloudWatchLogsDecodedData\n\nlogger = Logger()\n\n\n@event_source(data_class=CloudWatchLogsEvent)\ndef lambda_handler(event: CloudWatchLogsEvent, context):\n    decompressed_log: CloudWatchLogsDecodedData = event.parse_logs_data()\n\n    logger.info(f\"Log group: {decompressed_log.log_group}\")\n    logger.info(f\"Log stream: {decompressed_log.log_stream}\")\n\n    for log_event in decompressed_log.log_events:\n        logger.info(f\"Timestamp: {log_event.timestamp}, Message: {log_event.message}\")\n\n    return {\"statusCode\": 200, \"body\": f\"Processed {len(decompressed_log.log_events)} log events\"}\n</code></pre> <pre><code>{\n  \"awslogs\": {\n    \"data\": \"H4sIAAAAAAAAAHWPwQqCQBCGX0Xm7EFtK+smZBEUgXoLCdMhFtKV3akI8d0bLYmibvPPN3wz00CJxmQnTO41whwWQRIctmEcB6sQbFC3CjW3XW8kxpOpP+OC22d1Wml1qZkQGtoMsScxaczKN3plG8zlaHIta5KqWsozoTYw3/djzwhpLwivWFGHGpAFe7DL68JlBUk+l7KSN7tCOEJ4M3/qOI49vMHj+zCKdlFqLaU2ZHV2a4Ct/an0/ivdX8oYc1UVX860fQDQiMdxRQEAAA==\"\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#kinesis-integration",
            "title": "Kinesis integration",
            "text": "<p>When streaming CloudWatch Logs to a Kinesis Data Stream (cross-account or not), you can use <code>extract_cloudwatch_logs_from_event</code> to decode, decompress and extract logs as <code>CloudWatchLogsDecodedData</code> to ease log processing.</p> app.pyKinesis Stream CloudWatch Logs Example Event <pre><code>from typing import List\n\nfrom aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.cloud_watch_logs_event import CloudWatchLogsDecodedData\nfrom aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import (\n    KinesisStreamEvent,\n    extract_cloudwatch_logs_from_event,\n)\n\n\n@event_source(data_class=KinesisStreamEvent)\ndef lambda_handler(event: KinesisStreamEvent, context):\n    logs: List[CloudWatchLogsDecodedData] = extract_cloudwatch_logs_from_event(event)\n    for log in logs:\n        if log.message_type == \"DATA_MESSAGE\":\n            return \"success\"\n    return \"nothing to be processed\"\n</code></pre> <pre><code>{\n    \"Records\": [\n        {\n            \"kinesis\": {\n                \"kinesisSchemaVersion\": \"1.0\",\n                \"partitionKey\": \"da10bf66b1f54bff5d96eae99149ad1f\",\n                \"sequenceNumber\": \"49635052289529725553291405521504870233219489715332317186\",\n                \"data\": \"H4sIAAAAAAAAAK2Sa2vbMBSG/4ox+xg3Oror39IlvaztVmJv7WjCUGwl8+ZLZstts5L/vuOsZYUyWGEgJHiP9J7nvOghLF3b2rVLthsXjsLJOBl/uZjG8fh4Gg7C+q5yDcqUAWcSONHEoFzU6+Om7jZYGdq7dljYcpnZ4cZHwLWOJl1Zbs/r9cR6e9RVqc/rKlpXV9eXt+fy27vt8W+L2DfOlr07oXQIMAQyvHlzPk6mcbKgciktF5lQfMU5dZZqzrShLF2uFC60aLtlmzb5prc/ygvvmjYc3YRPFG+LusuurE+/Ikqb1Gd55dq8jV+8isT6+317Rk42J5PTcLFnm966yvd2D2GeISJTYIwCJSQ1BE9OtWZCABWaKMIJAMdDMyU5MYZLhmkxBhQxfY4Re1tiWiAlBsgIVQTE4Cl6tI+T8SwJZu5Hh1dPs1FApOMSDI9WVKmIC+4irTMWQZYpx7QkztrgE06MU4yCx9DmVbgbvABmQJTGtkYAB0NwEwyYQUBpqEFuSbkGrThTRKi/AlP+HHj6fvJa3P9Ap/+Rbja9/PD6POd+0jXW7xM1B8CDsp37w7woXBb8qQDZ6xeurJttEOc/HWpUBxeHKNr74LHwsXXYlsm9flrl/rmFIQeS7m3m1fVs/DlIGpu6nhMiyWQGXNKIMbcCIgkhElKbaZnZpYJUz33s1iV+z/6+StMlR3yphHNcCyxiNEXf2zed6xuEu8XuF2wb6krnAwAA\",\n                \"approximateArrivalTimestamp\": 1668093033.744\n            },\n            \"eventSource\": \"aws:kinesis\",\n            \"eventVersion\": \"1.0\",\n            \"eventID\": \"shardId-000000000000:49635052289529725553291405521504870233219489715332317186\",\n            \"eventName\": \"aws:kinesis:record\",\n            \"invokeIdentityArn\": \"arn:aws:iam::231436140809:role/pt-1488-CloudWatchKinesisLogsFunctionRole-1M4G2TIWIE49\",\n            \"awsRegion\": \"eu-west-1\",\n            \"eventSourceARN\": \"arn:aws:kinesis:eu-west-1:231436140809:stream/pt-1488-KinesisStreamCloudWatchLogs-D8tHs0im0aJG\"\n        },\n        {\n            \"kinesis\": {\n                \"kinesisSchemaVersion\": \"1.0\",\n                \"partitionKey\": \"cf4c4c2c9a49bdfaf58d7dbbc2b06081\",\n                \"sequenceNumber\": \"49635052289529725553291405520881064510298312199003701250\",\n                \"data\": \"H4sIAAAAAAAAAK2SW2/TQBCF/4pl8ViTvc7u5i0laVraQhUbWtREaG1PgsGXYK/bhqr/nXVoBRIgUYnXc2bPfHO092GFXWc3mOy2GI7D6SSZfDyfxfFkPgsPwua2xtbLjFPBgQqiifFy2WzmbdNvvTOyt92otFWa29HWRVRoHU37qtqdNZupdfaorzNXNHW0qS+vLm7O4PPr3fxHROxatNWQThgbUTqiZHT94mySzOJkBUqYLOWY8ZQLbaTRkEvDciUYzWzKfETXp13WFtsh/qgoHbZdOL4OnyhelU2fX1qXffIoXdKcFjV2RRf/9iqSmy933Sk53h5PT8LVnm12g7Ub4u7DIveIXFFjFNGUKUlAaMY0EUJKLjkQbxhKGCWeknMKoAGUkYoJ7TFd4St2tvJtDRYxDAg3VB08Ve/j42SySIIFfu396Ek+DkS+xkwAiYhM00isgUV6jXmEMrM5EmMsh+C9v9hfMQ4eS1vW4cPBH4CZVpoTJkEIAp5RUMo8vGFae3JNCCdUccMVgPw7sP4VePZm+lzc/0AH/0i3mF28fX6fSzftW+v2jZKXRgVVt3SHRVliHvx06F4+x6ppd0FcfEMvMR2cH3rR3gWPxrsO/Vau9vqyvlpMPgRJazMcYGgEHHLKBhLGJaBA0JLxNc0JppoS9Cwxbir/B4d5QDBAQSnfFFGp8aa/vxw2uLbHYUH4sHr4Dj5RJxfMAwAA\",\n                \"approximateArrivalTimestamp\": 1668092612.992\n            },\n            \"eventSource\": \"aws:kinesis\",\n            \"eventVersion\": \"1.0\",\n            \"eventID\": \"shardId-000000000000:49635052289529725553291405520881064510298312199003701250\",\n            \"eventName\": \"aws:kinesis:record\",\n            \"invokeIdentityArn\": \"arn:aws:iam::231436140809:role/pt-1488-CloudWatchKinesisLogsFunctionRole-1M4G2TIWIE49\",\n            \"awsRegion\": \"eu-west-1\",\n            \"eventSourceARN\": \"arn:aws:kinesis:eu-west-1:231436140809:stream/pt-1488-KinesisStreamCloudWatchLogs-D8tHs0im0aJG\"\n        }\n    ]\n}\n</code></pre> <p>Alternatively, you can use <code>extract_cloudwatch_logs_from_record</code> to seamless integrate with the Batch utility for more robust log processing.</p> app.pyKinesis Stream CloudWatch Logs Example Event <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.batch import (\n    BatchProcessor,\n    EventType,\n    process_partial_response,\n)\nfrom aws_lambda_powertools.utilities.data_classes.kinesis_stream_event import (\n    KinesisStreamRecord,\n    extract_cloudwatch_logs_from_record,\n)\n\nlogger = Logger()\n\nprocessor = BatchProcessor(event_type=EventType.KinesisDataStreams)\n\n\ndef record_handler(record: KinesisStreamRecord):\n    log = extract_cloudwatch_logs_from_record(record)\n    logger.info(f\"Message type: {log.message_type}\")\n    return log.message_type == \"DATA_MESSAGE\"\n\n\ndef lambda_handler(event, context):\n    return process_partial_response(\n        event=event,\n        record_handler=record_handler,\n        processor=processor,\n        context=context,\n    )\n</code></pre> <pre><code>{\n    \"Records\": [\n        {\n            \"kinesis\": {\n                \"kinesisSchemaVersion\": \"1.0\",\n                \"partitionKey\": \"da10bf66b1f54bff5d96eae99149ad1f\",\n                \"sequenceNumber\": \"49635052289529725553291405521504870233219489715332317186\",\n                \"data\": \"H4sIAAAAAAAAAK2Sa2vbMBSG/4ox+xg3Oror39IlvaztVmJv7WjCUGwl8+ZLZstts5L/vuOsZYUyWGEgJHiP9J7nvOghLF3b2rVLthsXjsLJOBl/uZjG8fh4Gg7C+q5yDcqUAWcSONHEoFzU6+Om7jZYGdq7dljYcpnZ4cZHwLWOJl1Zbs/r9cR6e9RVqc/rKlpXV9eXt+fy27vt8W+L2DfOlr07oXQIMAQyvHlzPk6mcbKgciktF5lQfMU5dZZqzrShLF2uFC60aLtlmzb5prc/ygvvmjYc3YRPFG+LusuurE+/Ikqb1Gd55dq8jV+8isT6+317Rk42J5PTcLFnm966yvd2D2GeISJTYIwCJSQ1BE9OtWZCABWaKMIJAMdDMyU5MYZLhmkxBhQxfY4Re1tiWiAlBsgIVQTE4Cl6tI+T8SwJZu5Hh1dPs1FApOMSDI9WVKmIC+4irTMWQZYpx7QkztrgE06MU4yCx9DmVbgbvABmQJTGtkYAB0NwEwyYQUBpqEFuSbkGrThTRKi/AlP+HHj6fvJa3P9Ap/+Rbja9/PD6POd+0jXW7xM1B8CDsp37w7woXBb8qQDZ6xeurJttEOc/HWpUBxeHKNr74LHwsXXYlsm9flrl/rmFIQeS7m3m1fVs/DlIGpu6nhMiyWQGXNKIMbcCIgkhElKbaZnZpYJUz33s1iV+z/6+StMlR3yphHNcCyxiNEXf2zed6xuEu8XuF2wb6krnAwAA\",\n                \"approximateArrivalTimestamp\": 1668093033.744\n            },\n            \"eventSource\": \"aws:kinesis\",\n            \"eventVersion\": \"1.0\",\n            \"eventID\": \"shardId-000000000000:49635052289529725553291405521504870233219489715332317186\",\n            \"eventName\": \"aws:kinesis:record\",\n            \"invokeIdentityArn\": \"arn:aws:iam::231436140809:role/pt-1488-CloudWatchKinesisLogsFunctionRole-1M4G2TIWIE49\",\n            \"awsRegion\": \"eu-west-1\",\n            \"eventSourceARN\": \"arn:aws:kinesis:eu-west-1:231436140809:stream/pt-1488-KinesisStreamCloudWatchLogs-D8tHs0im0aJG\"\n        },\n        {\n            \"kinesis\": {\n                \"kinesisSchemaVersion\": \"1.0\",\n                \"partitionKey\": \"cf4c4c2c9a49bdfaf58d7dbbc2b06081\",\n                \"sequenceNumber\": \"49635052289529725553291405520881064510298312199003701250\",\n                \"data\": \"H4sIAAAAAAAAAK2SW2/TQBCF/4pl8ViTvc7u5i0laVraQhUbWtREaG1PgsGXYK/bhqr/nXVoBRIgUYnXc2bPfHO092GFXWc3mOy2GI7D6SSZfDyfxfFkPgsPwua2xtbLjFPBgQqiifFy2WzmbdNvvTOyt92otFWa29HWRVRoHU37qtqdNZupdfaorzNXNHW0qS+vLm7O4PPr3fxHROxatNWQThgbUTqiZHT94mySzOJkBUqYLOWY8ZQLbaTRkEvDciUYzWzKfETXp13WFtsh/qgoHbZdOL4OnyhelU2fX1qXffIoXdKcFjV2RRf/9iqSmy933Sk53h5PT8LVnm12g7Ub4u7DIveIXFFjFNGUKUlAaMY0EUJKLjkQbxhKGCWeknMKoAGUkYoJ7TFd4St2tvJtDRYxDAg3VB08Ve/j42SySIIFfu396Ek+DkS+xkwAiYhM00isgUV6jXmEMrM5EmMsh+C9v9hfMQ4eS1vW4cPBH4CZVpoTJkEIAp5RUMo8vGFae3JNCCdUccMVgPw7sP4VePZm+lzc/0AH/0i3mF28fX6fSzftW+v2jZKXRgVVt3SHRVliHvx06F4+x6ppd0FcfEMvMR2cH3rR3gWPxrsO/Vau9vqyvlpMPgRJazMcYGgEHHLKBhLGJaBA0JLxNc0JppoS9Cwxbir/B4d5QDBAQSnfFFGp8aa/vxw2uLbHYUH4sHr4Dj5RJxfMAwAA\",\n                \"approximateArrivalTimestamp\": 1668092612.992\n            },\n            \"eventSource\": \"aws:kinesis\",\n            \"eventVersion\": \"1.0\",\n            \"eventID\": \"shardId-000000000000:49635052289529725553291405520881064510298312199003701250\",\n            \"eventName\": \"aws:kinesis:record\",\n            \"invokeIdentityArn\": \"arn:aws:iam::231436140809:role/pt-1488-CloudWatchKinesisLogsFunctionRole-1M4G2TIWIE49\",\n            \"awsRegion\": \"eu-west-1\",\n            \"eventSourceARN\": \"arn:aws:kinesis:eu-west-1:231436140809:stream/pt-1488-KinesisStreamCloudWatchLogs-D8tHs0im0aJG\"\n        }\n    ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#codedeploy-lifecycle-hook",
            "title": "CodeDeploy LifeCycle Hook",
            "text": "<p>CodeDeploy triggers Lambdas with this event when defined in AppSpec definitions to test applications at different stages of deployment.</p> app.pyCodeDeploy LifeCycle Hook Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import CodeDeployLifecycleHookEvent, event_source\n\n\n@event_source(data_class=CodeDeployLifecycleHookEvent)\ndef lambda_handler(event: CodeDeployLifecycleHookEvent, context):\n    deployment_id = event.deployment_id\n    lifecycle_event_hook_execution_id = event.lifecycle_event_hook_execution_id\n\n    return {\"deployment_id\": deployment_id, \"lifecycle_event_hook_execution_id\": lifecycle_event_hook_execution_id}\n</code></pre> <pre><code>{\n    \"DeploymentId\": \"d-ABCDEF\",\n    \"LifecycleEventHookExecutionId\": \"xxxxxxxxxxxxxxxxxxxxxxxx\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#codepipeline-job",
            "title": "CodePipeline Job",
            "text": "<p>Data classes and utility functions to help create continuous delivery pipelines tasks with AWS Lambda.</p> app.pyCodePipeline Job Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import CodePipelineJobEvent, event_source\n\n\n@event_source(data_class=CodePipelineJobEvent)\ndef lambda_handler(event: CodePipelineJobEvent, context):\n    job_id = event.get_id\n\n    input_bucket = event.input_bucket_name\n\n    return {\"statusCode\": 200, \"body\": f\"Processed job {job_id} from bucket {input_bucket}\"}\n</code></pre> <pre><code>{\n    \"CodePipeline.job\": {\n        \"id\": \"11111111-abcd-1111-abcd-111111abcdef\",\n        \"accountId\": \"111111111111\",\n        \"data\": {\n            \"actionConfiguration\": {\n                \"configuration\": {\n                    \"FunctionName\": \"MyLambdaFunctionForAWSCodePipeline\",\n                    \"UserParameters\": \"some-input-such-as-a-URL\"\n                }\n            },\n            \"inputArtifacts\": [\n                {\n                    \"name\": \"ArtifactName\",\n                    \"revision\": null,\n                    \"location\": {\n                        \"type\": \"S3\",\n                        \"s3Location\": {\n                            \"bucketName\": \"the name of the bucket configured as the pipeline artifact store in Amazon S3, for example codepipeline-us-east-2-1234567890\",\n                            \"objectKey\": \"the name of the application, for example CodePipelineDemoApplication.zip\"\n                        }\n                    }\n                }\n            ],\n            \"outputArtifacts\": [],\n            \"artifactCredentials\": {\n                \"accessKeyId\": \"AKIAIOSFODNN7EXAMPLE\",\n                \"secretAccessKey\": \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\",\n                \"sessionToken\": \"MIICiTCCAfICCQD6m7oRw0uXOjANBgkqhkiG9w0BAQUFADCBiDELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAldBMRAwDgYDVQQHEwdTZWF0dGxlMQ8wDQYDVQQKEwZBbWF6b24xFDASBgNVBAsTC0lBTSBDb25zb2xlMRIwEAYDVQQDEwlUZXN0Q2lsYWMxHzAdBgkqhkiG9w0BCQEWEG5vb25lQGFtYXpvbi5jb20wHhcNMTEwNDI1MjA0NTIxWhcNMTIwNDI0MjA0NTIxWjCBiDELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAldBMRAwDgYDVQQHEwdTZWF0dGxlMQ8wDQYDVQQKEwZBbWF6b24xFDASBgNVBAsTC0lBTSBDb25zb2xlMRIwEAYDVQQDEwlUZXN0Q2lsYWMxHzAdBgkqhkiG9w0BCQEWEG5vb25lQGFtYXpvbi5jb20wgZ8wDQYJKoZIhvcNAQEBBQADgY0AMIGJAoGBAMaK0dn+a4GmWIWJ21uUSfwfEvySWtC2XADZ4nB+BLYgVIk60CpiwsZ3G93vUEIO3IyNoH/f0wYK8m9TrDHudUZg3qX4waLG5M43q7Wgc/MbQITxOUSQv7c7ugFFDzQGBzZswY6786m86gpEIbb3OhjZnzcvQAaRHhdlQWIMm2nrAgMBAAEwDQYJKoZIhvcNAQEFBQADgYEAtCu4nUhVVxYUntneD9+h8Mg9q6q+auNKyExzyLwaxlAoo7TJHidbtS4J5iNmZgXL0FkbFFBjvSfpJIlJ00zbhNYS5f6GuoEDmFJl0ZxBHjJnyp378OD8uTs7fLvjx79LjSTbNYiytVbZPQUQ5Yaxu2jXnimvw3rrszlaEXAMPLE=\"\n            },\n            \"continuationToken\": \"A continuation token if continuing job\"\n        }\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#cognito-user-pool",
            "title": "Cognito User Pool",
            "text": "<p>Cognito User Pools have several different Lambda trigger sources, all of which map to a different data class, which can be imported from <code>aws_lambda_powertools.data_classes.cognito_user_pool_event</code>:</p> Trigger/Event Source Data Class Custom message event <code>data_classes.cognito_user_pool_event.CustomMessageTriggerEvent</code> Post authentication <code>data_classes.cognito_user_pool_event.PostAuthenticationTriggerEvent</code> Post confirmation <code>data_classes.cognito_user_pool_event.PostConfirmationTriggerEvent</code> Pre authentication <code>data_classes.cognito_user_pool_event.PreAuthenticationTriggerEvent</code> Pre sign-up <code>data_classes.cognito_user_pool_event.PreSignUpTriggerEvent</code> Pre token generation <code>data_classes.cognito_user_pool_event.PreTokenGenerationTriggerEvent</code> Pre token generation V2 <code>data_classes.cognito_user_pool_event.PreTokenGenerationV2TriggerEvent</code> User migration <code>data_classes.cognito_user_pool_event.UserMigrationTriggerEvent</code> Define Auth Challenge <code>data_classes.cognito_user_pool_event.DefineAuthChallengeTriggerEvent</code> Create Auth Challenge <code>data_classes.cognito_user_pool_event.CreateAuthChallengeTriggerEvent</code> Verify Auth Challenge <code>data_classes.cognito_user_pool_event.VerifyAuthChallengeResponseTriggerEvent</code> Custom Email Sender <code>data_classes.cognito_user_pool_event.CustomEmailSenderTriggerEvent</code> Custom SMS Sender <code>data_classes.cognito_user_pool_event.CustomSMSSenderTriggerEvent</code> <p>Some examples for the Cognito User Pools Lambda triggers sources:</p>"
        },
        {
            "location": "utilities/data_classes/#post-confirmation-example",
            "title": "Post Confirmation Example",
            "text": "app.pyCognito Post Confirmation Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes.cognito_user_pool_event import PostConfirmationTriggerEvent\n\n\ndef lambda_handler(event, context):\n    event: PostConfirmationTriggerEvent = PostConfirmationTriggerEvent(event)\n\n    user_attributes = event.request.user_attributes\n\n    return {\"statusCode\": 200, \"body\": f\"User attributes: {user_attributes}\"}\n</code></pre> <pre><code>{\n  \"version\": \"string\",\n  \"triggerSource\": \"PostConfirmation_ConfirmSignUp\",\n  \"region\": \"us-east-1\",\n  \"userPoolId\": \"string\",\n  \"userName\": \"userName\",\n  \"callerContext\": {\n    \"awsSdkVersion\": \"awsSdkVersion\",\n    \"clientId\": \"clientId\"\n  },\n  \"request\": {\n    \"userAttributes\": {\n      \"email\": \"user@example.com\",\n      \"email_verified\": true\n    }\n  },\n  \"response\": {}\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#define-auth-challenge-example",
            "title": "Define Auth Challenge Example",
            "text": "Note <p>In this example we are modifying the wrapped dict response fields, so we need to return the json serializable wrapped event in <code>event.raw_event</code>.</p> <p>This example is based on the AWS Cognito docs for Define Auth Challenge Lambda Trigger.</p> app.pyCognito Define Auth Challengen Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes.cognito_user_pool_event import DefineAuthChallengeTriggerEvent\n\n\ndef lambda_handler(event, context) -&gt; dict:\n    event_obj: DefineAuthChallengeTriggerEvent = DefineAuthChallengeTriggerEvent(event)\n\n    if len(event_obj.request.session) == 1 and event_obj.request.session[0].challenge_name == \"SRP_A\":\n        event_obj.response.issue_tokens = False\n        event_obj.response.fail_authentication = False\n        event_obj.response.challenge_name = \"PASSWORD_VERIFIER\"\n    elif (\n        len(event_obj.request.session) == 2\n        and event_obj.request.session[1].challenge_name == \"PASSWORD_VERIFIER\"\n        and event_obj.request.session[1].challenge_result\n    ):\n        event_obj.response.issue_tokens = False\n        event_obj.response.fail_authentication = False\n        event_obj.response.challenge_name = \"CUSTOM_CHALLENGE\"\n    elif (\n        len(event_obj.request.session) == 3\n        and event_obj.request.session[2].challenge_name == \"CUSTOM_CHALLENGE\"\n        and event_obj.request.session[2].challenge_result\n    ):\n        event_obj.response.issue_tokens = True\n        event_obj.response.fail_authentication = False\n    else:\n        event_obj.response.issue_tokens = False\n        event_obj.response.fail_authentication = True\n\n    return event_obj.raw_event\n</code></pre> <pre><code>{\n  \"version\": \"1\",\n  \"region\": \"us-east-1\",\n  \"userPoolId\": \"us-east-1_example\",\n  \"userName\": \"UserName\",\n  \"callerContext\": {\n    \"awsSdkVersion\": \"awsSdkVersion\",\n    \"clientId\": \"clientId\"\n  },\n  \"triggerSource\": \"DefineAuthChallenge_Authentication\",\n  \"request\": {\n    \"userAttributes\": {\n      \"sub\": \"4A709A36-7D63-4785-829D-4198EF10EBDA\",\n      \"email_verified\": \"true\",\n      \"name\": \"First Last\",\n      \"email\": \"define-auth@mail.com\"\n    },\n    \"session\" : [\n      {\n        \"challengeName\": \"PASSWORD_VERIFIER\",\n        \"challengeResult\": true\n      },\n      {\n        \"challengeName\": \"CUSTOM_CHALLENGE\",\n        \"challengeResult\": true,\n        \"challengeMetadata\": \"CAPTCHA_CHALLENGE\"\n      }\n    ],\n    \"userNotFound\": true\n  },\n  \"response\": {}\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#create-auth-challenge-example",
            "title": "Create Auth Challenge Example",
            "text": "<p>This example is based on the AWS Cognito docs for Create Auth Challenge Lambda Trigger.</p> app.pyCognito Create Auth Challengen Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.cognito_user_pool_event import CreateAuthChallengeTriggerEvent\n\n\n@event_source(data_class=CreateAuthChallengeTriggerEvent)\ndef handler(event: CreateAuthChallengeTriggerEvent, context) -&gt; dict:\n    if event.request.challenge_name == \"CUSTOM_CHALLENGE\":\n        event.response.public_challenge_parameters = {\"captchaUrl\": \"url/123.jpg\"}\n        event.response.private_challenge_parameters = {\"answer\": \"5\"}\n        event.response.challenge_metadata = \"CAPTCHA_CHALLENGE\"\n    return event.raw_event\n</code></pre> <pre><code>{\n  \"version\": \"1\",\n  \"region\": \"us-east-1\",\n  \"userPoolId\": \"us-east-1_example\",\n  \"userName\": \"UserName\",\n  \"callerContext\": {\n    \"awsSdkVersion\": \"awsSdkVersion\",\n    \"clientId\": \"clientId\"\n  },\n  \"triggerSource\": \"CreateAuthChallenge_Authentication\",\n  \"request\": {\n    \"userAttributes\": {\n      \"sub\": \"4A709A36-7D63-4785-829D-4198EF10EBDA\",\n      \"email_verified\": \"true\",\n      \"name\": \"First Last\",\n      \"email\": \"create-auth@mail.com\"\n    },\n    \"challengeName\": \"PASSWORD_VERIFIER\",\n    \"session\" : [\n      {\n        \"challengeName\": \"CUSTOM_CHALLENGE\",\n        \"challengeResult\": true,\n        \"challengeMetadata\": \"CAPTCHA_CHALLENGE\"\n      }\n    ],\n    \"userNotFound\": false\n  },\n  \"response\": {}\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#verify-auth-challenge-response-example",
            "title": "Verify Auth Challenge Response Example",
            "text": "<p>This example is based on the AWS Cognito docs for Verify Auth Challenge Response Lambda Trigger.</p> app.pyCognito Verify Auth Challengen Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.cognito_user_pool_event import VerifyAuthChallengeResponseTriggerEvent\n\n\n@event_source(data_class=VerifyAuthChallengeResponseTriggerEvent)\ndef lambda_handler(event: VerifyAuthChallengeResponseTriggerEvent, context) -&gt; dict:\n    event.response.answer_correct = (\n        event.request.private_challenge_parameters.get(\"answer\") == event.request.challenge_answer\n    )\n    return event.raw_event\n</code></pre> <pre><code>{\n  \"version\": \"1\",\n  \"region\": \"us-east-1\",\n  \"userPoolId\": \"us-east-1_example\",\n  \"userName\": \"UserName\",\n  \"callerContext\": {\n    \"awsSdkVersion\": \"awsSdkVersion\",\n    \"clientId\": \"clientId\"\n  },\n  \"triggerSource\": \"VerifyAuthChallengeResponse_Authentication\",\n  \"request\": {\n    \"userAttributes\": {\n      \"sub\": \"4A709A36-7D63-4785-829D-4198EF10EBDA\",\n      \"email_verified\": \"true\",\n      \"name\": \"First Last\",\n      \"email\": \"verify-auth@mail.com\"\n    },\n    \"privateChallengeParameters\": {\n      \"answer\": \"challengeAnswer\"\n    },\n    \"clientMetadata\" : {\n      \"foo\": \"value\"\n    },\n    \"challengeAnswer\": \"challengeAnswer\",\n    \"userNotFound\": true\n  },\n  \"response\": {}\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#connect-contact-flow",
            "title": "Connect Contact Flow",
            "text": "<p>The example integrates with Amazon Connect by handling contact flow events. The function converts the event into a <code>ConnectContactFlowEvent</code> object, providing a structured representation of the contact flow data.</p> app.pyConnect Contact Flow Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes.connect_contact_flow_event import (\n    ConnectContactFlowChannel,\n    ConnectContactFlowEndpointType,\n    ConnectContactFlowEvent,\n    ConnectContactFlowInitiationMethod,\n)\n\n\ndef lambda_handler(event, context):\n    event: ConnectContactFlowEvent = ConnectContactFlowEvent(event)\n    assert event.contact_data.attributes == {\"Language\": \"en-US\"}\n    assert event.contact_data.channel == ConnectContactFlowChannel.VOICE\n    assert event.contact_data.customer_endpoint.endpoint_type == ConnectContactFlowEndpointType.TELEPHONE_NUMBER\n    assert event.contact_data.initiation_method == ConnectContactFlowInitiationMethod.API\n</code></pre> <pre><code>{\n    \"Name\": \"ContactFlowEvent\",\n    \"Details\": {\n        \"ContactData\": {\n            \"Attributes\": {\n                \"Language\": \"en-US\"\n            },\n            \"Channel\": \"VOICE\",\n            \"ContactId\": \"5ca32fbd-8f92-46af-92a5-6b0f970f0efe\",\n            \"CustomerEndpoint\": {\n                \"Address\": \"+11234567890\",\n                \"Type\": \"TELEPHONE_NUMBER\"\n            },\n            \"InitialContactId\": \"5ca32fbd-8f92-46af-92a5-6b0f970f0efe\",\n            \"InitiationMethod\": \"API\",\n            \"InstanceARN\": \"arn:aws:connect:eu-central-1:123456789012:instance/9308c2a1-9bc6-4cea-8290-6c0b4a6d38fa\",\n            \"MediaStreams\": {\n                \"Customer\": {\n                    \"Audio\": {\n                        \"StartFragmentNumber\": \"91343852333181432392682062622220590765191907586\",\n                        \"StartTimestamp\": \"1565781909613\",\n                        \"StreamARN\": \"arn:aws:kinesisvideo:eu-central-1:123456789012:stream/connect-contact-a3d73b84-ce0e-479a-a9dc-5637c9d30ac9/1565272947806\"\n                    }\n                }\n            },\n            \"PreviousContactId\": \"5ca32fbd-8f92-46af-92a5-6b0f970f0efe\",\n            \"Queue\": {\n                \"ARN\": \"arn:aws:connect:eu-central-1:123456789012:instance/9308c2a1-9bc6-4cea-8290-6c0b4a6d38fa/queue/5cba7cbf-1ecb-4b6d-b8bd-fe91079b3fc8\",\n                \"Name\": \"QueueOne\"\n            },\n            \"SystemEndpoint\": {\n                \"Address\": \"+11234567890\",\n                \"Type\": \"TELEPHONE_NUMBER\"\n            }\n        },\n        \"Parameters\": {\n            \"ParameterOne\": \"One\",\n            \"ParameterTwo\": \"Two\"\n        }\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#dynamodb-streams",
            "title": "DynamoDB Streams",
            "text": "<p>The DynamoDB data class utility provides the base class for <code>DynamoDBStreamEvent</code>, as well as enums for stream view type (<code>StreamViewType</code>) and event type. (<code>DynamoDBRecordEventName</code>). The class automatically deserializes DynamoDB types into their equivalent Python types.</p> app.pyapp_multiple_records.pyDynamoDB Streams Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes.dynamo_db_stream_event import (\n    DynamoDBRecordEventName,\n    DynamoDBStreamEvent,\n)\n\n\ndef lambda_handler(event, context):\n    event: DynamoDBStreamEvent = DynamoDBStreamEvent(event)\n\n    # Multiple records can be delivered in a single event\n    for record in event.records:\n        if record.event_name == DynamoDBRecordEventName.MODIFY:\n            pass\n        elif record.event_name == DynamoDBRecordEventName.INSERT:\n            pass\n    return \"success\"\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.data_classes import DynamoDBStreamEvent, event_source\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@event_source(data_class=DynamoDBStreamEvent)\ndef lambda_handler(event: DynamoDBStreamEvent, context: LambdaContext):\n    processed_keys = []\n    for record in event.records:\n        if record.dynamodb and record.dynamodb.keys and \"Id\" in record.dynamodb.keys:\n            key = record.dynamodb.keys[\"Id\"]\n            processed_keys.append(key)\n\n    return {\"statusCode\": 200, \"body\": f\"Processed keys: {processed_keys}\"}\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"eventID\": \"1\",\n      \"eventVersion\": \"1.0\",\n      \"dynamodb\": {\n        \"ApproximateCreationDateTime\": 1693997155.0,\n        \"Keys\": {\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"NewImage\": {\n          \"Message\": {\n            \"S\": \"New item!\"\n          },\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n        \"SequenceNumber\": \"111\",\n        \"SizeBytes\": 26\n      },\n      \"awsRegion\": \"us-west-2\",\n      \"eventName\": \"INSERT\",\n      \"eventSourceARN\": \"eventsource_arn\",\n      \"eventSource\": \"aws:dynamodb\"\n    },\n    {\n      \"eventID\": \"2\",\n      \"eventVersion\": \"1.0\",\n      \"dynamodb\": {\n        \"OldImage\": {\n          \"Message\": {\n            \"S\": \"New item!\"\n          },\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"SequenceNumber\": \"222\",\n        \"Keys\": {\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"SizeBytes\": 59,\n        \"NewImage\": {\n          \"Message\": {\n            \"S\": \"This item has changed\"\n          },\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"StreamViewType\": \"NEW_AND_OLD_IMAGES\"\n      },\n      \"awsRegion\": \"us-west-2\",\n      \"eventName\": \"MODIFY\",\n      \"eventSourceARN\": \"source_arn\",\n      \"eventSource\": \"aws:dynamodb\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#eventbridge",
            "title": "EventBridge",
            "text": "<p>When an event matching a defined rule occurs in EventBridge, it can automatically trigger a Lambda function, passing the event data as input.</p> app.pyEventBridge Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import EventBridgeEvent, event_source\n\n\n@event_source(data_class=EventBridgeEvent)\ndef lambda_handler(event: EventBridgeEvent, context):\n    detail_type = event.detail_type\n    state = event.detail.get(\"state\")\n\n    # Do something\n\n    return {\"detail_type\": detail_type, \"state\": state}\n</code></pre> <pre><code>{\n  \"version\": \"0\",\n  \"id\": \"6a7e8feb-b491-4cf7-a9f1-bf3703467718\",\n  \"detail-type\": \"EC2 Instance State-change Notification\",\n  \"source\": \"aws.ec2\",\n  \"account\": \"111122223333\",\n  \"time\": \"2017-12-22T18:43:48Z\",\n  \"region\": \"us-west-1\",\n  \"resources\": [\n    \"arn:aws:ec2:us-west-1:123456789012:instance/i-1234567890abcdef0\"\n  ],\n  \"detail\": {\n    \"instance_id\": \"i-1234567890abcdef0\",\n    \"state\": \"terminated\"\n  },\n  \"replay-name\": \"replay_archive\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#kafka",
            "title": "Kafka",
            "text": "<p>This example is based on the AWS docs for Amazon MSK and self-managed Apache Kafka.</p> app.pyKafka Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import KafkaEvent, event_source\n\n\ndef do_something_with(key: str, value: str):\n    print(f\"key: {key}, value: {value}\")\n\n\n@event_source(data_class=KafkaEvent)\ndef lambda_handler(event: KafkaEvent, context):\n    for record in event.records:\n        do_something_with(record.topic, record.value)\n    return \"success\"\n</code></pre> <pre><code>{\n  \"eventSource\":\"aws:kafka\",\n  \"eventSourceArn\":\"arn:aws:kafka:us-east-1:0123456789019:cluster/SalesCluster/abcd1234-abcd-cafe-abab-9876543210ab-4\",\n  \"bootstrapServers\":\"b-2.demo-cluster-1.a1bcde.c1.kafka.us-east-1.amazonaws.com:9092,b-1.demo-cluster-1.a1bcde.c1.kafka.us-east-1.amazonaws.com:9092\",\n  \"records\":{\n     \"mytopic-0\":[\n        {\n           \"topic\":\"mytopic\",\n           \"partition\":0,\n           \"offset\":15,\n           \"timestamp\":1545084650987,\n           \"timestampType\":\"CREATE_TIME\",\n           \"key\":\"cmVjb3JkS2V5\",\n           \"value\":\"eyJrZXkiOiJ2YWx1ZSJ9\",\n           \"headers\":[\n              {\n                 \"headerKey\":[\n                    104,\n                    101,\n                    97,\n                    100,\n                    101,\n                    114,\n                    86,\n                    97,\n                    108,\n                    117,\n                    101\n                 ]\n              }\n           ]\n        }\n     ]\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#kinesis-streams",
            "title": "Kinesis streams",
            "text": "<p>Kinesis events by default contain base64 encoded data. You can use the helper function to access the data either as json or plain text, depending on the original payload.</p> app.pyKinesis streams Example Event <pre><code>import json\nfrom typing import Any, Dict, Union\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import KinesisStreamEvent, event_source\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@event_source(data_class=KinesisStreamEvent)\ndef lambda_handler(event: KinesisStreamEvent, context: LambdaContext):\n    for record in event.records:\n        kinesis_record = record.kinesis\n\n        payload: Union[Dict[str, Any], str]\n\n        try:\n            # Try to parse as JSON first\n            payload = kinesis_record.data_as_json()\n            logger.info(\"Received JSON data from Kinesis\")\n        except json.JSONDecodeError:\n            # If JSON parsing fails, get as text\n            payload = kinesis_record.data_as_text()\n            logger.info(\"Received text data from Kinesis\")\n\n        process_data(payload)\n\n    return {\"statusCode\": 200, \"body\": \"Processed all records successfully\"}\n\n\ndef process_data(data: Union[Dict[str, Any], str]) -&gt; None:\n    if isinstance(data, dict):\n        # Handle JSON data\n        logger.info(f\"Processing JSON data: {data}\")\n        # Add your JSON processing logic here\n    else:\n        # Handle text data\n        logger.info(f\"Processing text data: {data}\")\n        # Add your text processing logic here\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"kinesis\": {\n        \"kinesisSchemaVersion\": \"1.0\",\n        \"partitionKey\": \"1\",\n        \"sequenceNumber\": \"49590338271490256608559692538361571095921575989136588898\",\n        \"data\": \"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",\n        \"approximateArrivalTimestamp\": 1545084650.987\n      },\n      \"eventSource\": \"aws:kinesis\",\n      \"eventVersion\": \"1.0\",\n      \"eventID\": \"shardId-000000000006:49590338271490256608559692538361571095921575989136588898\",\n      \"eventName\": \"aws:kinesis:record\",\n      \"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n      \"awsRegion\": \"us-east-2\",\n      \"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n    },\n    {\n      \"kinesis\": {\n        \"kinesisSchemaVersion\": \"1.0\",\n        \"partitionKey\": \"1\",\n        \"sequenceNumber\": \"49590338271490256608559692540925702759324208523137515618\",\n        \"data\": \"VGhpcyBpcyBvbmx5IGEgdGVzdC4=\",\n        \"approximateArrivalTimestamp\": 1545084711.166\n      },\n      \"eventSource\": \"aws:kinesis\",\n      \"eventVersion\": \"1.0\",\n      \"eventID\": \"shardId-000000000006:49590338271490256608559692540925702759324208523137515618\",\n      \"eventName\": \"aws:kinesis:record\",\n      \"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n      \"awsRegion\": \"us-east-2\",\n      \"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#kinesis-firehose-delivery-stream",
            "title": "Kinesis Firehose delivery stream",
            "text": "<p>When using Kinesis Firehose, you can use a Lambda function to perform data transformation. For each transformed record, you can choose to either:</p> <ul> <li>A) Put them back to the delivery stream (default)</li> <li>B) Drop them so consumers don't receive them (e.g., data validation)</li> <li>C) Indicate a record failed data transformation and should be retried</li> </ul> <p>To do that, you can use <code>KinesisFirehoseDataTransformationResponse</code> class along with helper functions to make it easier to decode and encode base64 data in the stream.</p> Transforming streaming recordsDropping invalid recordsIndicating a processing failurekinesisFirehoseEvent.json <pre><code>from aws_lambda_powertools.utilities.data_classes import (\n    KinesisFirehoseDataTransformationResponse,\n    KinesisFirehoseEvent,\n    event_source,\n)\nfrom aws_lambda_powertools.utilities.serialization import base64_from_json\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@event_source(data_class=KinesisFirehoseEvent)\ndef lambda_handler(event: KinesisFirehoseEvent, context: LambdaContext):\n    result = KinesisFirehoseDataTransformationResponse()\n\n    for record in event.records:\n        # get original data using data_as_text property\n        data = record.data_as_text  # (1)!\n\n        ## generate data to return\n        transformed_data = {\"new_data\": \"transformed data using Powertools\", \"original_payload\": data}\n\n        processed_record = record.build_data_transformation_response(\n            data=base64_from_json(transformed_data),  # (2)!\n        )\n\n        result.add_record(processed_record)\n\n    # return transformed records\n    return result.asdict()\n</code></pre> <ol> <li>Ingesting JSON payloads?  Use <code>record.data_as_json</code> to easily deserialize them.</li> <li>For your convenience, <code>base64_from_json</code> serializes a dict to JSON, then encode as base64 data.</li> </ol> <pre><code>from json import JSONDecodeError\nfrom typing import Dict\n\nfrom aws_lambda_powertools.utilities.data_classes import (\n    KinesisFirehoseDataTransformationRecord,\n    KinesisFirehoseDataTransformationResponse,\n    KinesisFirehoseEvent,\n    event_source,\n)\nfrom aws_lambda_powertools.utilities.serialization import base64_from_json\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@event_source(data_class=KinesisFirehoseEvent)\ndef lambda_handler(event: KinesisFirehoseEvent, context: LambdaContext):\n    result = KinesisFirehoseDataTransformationResponse()\n\n    for record in event.records:\n        try:\n            payload: Dict = record.data_as_json  # decodes and deserialize base64 JSON string\n\n            ## generate data to return\n            transformed_data = {\"tool_used\": \"powertools_dataclass\", \"original_payload\": payload}\n\n            processed_record = KinesisFirehoseDataTransformationRecord(\n                record_id=record.record_id,\n                data=base64_from_json(transformed_data),\n            )\n        except JSONDecodeError:  # (1)!\n            # our producers ingest JSON payloads only; drop malformed records from the stream\n            processed_record = KinesisFirehoseDataTransformationRecord(\n                record_id=record.record_id,\n                data=record.data,\n                result=\"Dropped\",\n            )\n\n        result.add_record(processed_record)\n\n    # return transformed records\n    return result.asdict()\n</code></pre> <ol> <li>This exception would be generated from <code>record.data_as_json</code> if invalid payload.</li> </ol> <pre><code>from aws_lambda_powertools.utilities.data_classes import (\n    KinesisFirehoseDataTransformationRecord,\n    KinesisFirehoseDataTransformationResponse,\n    KinesisFirehoseEvent,\n    event_source,\n)\nfrom aws_lambda_powertools.utilities.serialization import base64_from_json\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@event_source(data_class=KinesisFirehoseEvent)\ndef lambda_handler(event: dict, context: LambdaContext):\n    firehose_event = KinesisFirehoseEvent(event)\n    result = KinesisFirehoseDataTransformationResponse()\n\n    for record in firehose_event.records:\n        try:\n            payload = record.data_as_text  # base64 decoded data as str\n\n            # generate data to return\n            transformed_data = {\"tool_used\": \"powertools_dataclass\", \"original_payload\": payload}\n\n            # Default result is Ok\n            processed_record = KinesisFirehoseDataTransformationRecord(\n                record_id=record.record_id,\n                data=base64_from_json(transformed_data),\n            )\n        except Exception:\n            # add Failed result to processing results, send back to kinesis for retry\n            processed_record = KinesisFirehoseDataTransformationRecord(\n                record_id=record.record_id,\n                data=record.data,\n                result=\"ProcessingFailed\",  # (1)!\n            )\n\n        result.add_record(processed_record)\n\n    # return transformed records\n    return result.asdict()\n</code></pre> <ol> <li>This record will now be sent to your S3 bucket in the <code>processing-failed</code> folder.</li> </ol> <pre><code>{\n    \"invocationId\": \"2b4d1ad9-2f48-94bd-a088-767c317e994a\",\n    \"sourceKinesisStreamArn\":\"arn:aws:kinesis:us-east-1:123456789012:stream/kinesis-source\",\n    \"deliveryStreamArn\": \"arn:aws:firehose:us-east-2:123456789012:deliverystream/delivery-stream-name\",\n    \"region\": \"us-east-2\",\n    \"records\": [\n        {\n            \"data\": \"SGVsbG8gV29ybGQ=\",\n            \"recordId\": \"record1\",\n            \"approximateArrivalTimestamp\": 1664028820148,\n            \"kinesisRecordMetadata\": {\n                \"shardId\": \"shardId-000000000000\",\n                \"partitionKey\": \"4d1ad2b9-24f8-4b9d-a088-76e9947c317a\",\n                \"approximateArrivalTimestamp\": 1664028820148,\n                \"sequenceNumber\": \"49546986683135544286507457936321625675700192471156785154\",\n                \"subsequenceNumber\": 0\n            }\n        },\n        {\n            \"data\": \"eyJIZWxsbyI6ICJXb3JsZCJ9\",\n            \"recordId\": \"record2\",\n            \"approximateArrivalTimestamp\": 1664028793294,\n            \"kinesisRecordMetadata\": {\n                \"shardId\": \"shardId-000000000001\",\n                \"partitionKey\": \"4d1ad2b9-24f8-4b9d-a088-76e9947c318a\",\n                \"approximateArrivalTimestamp\": 1664028793294,\n                \"sequenceNumber\": \"49546986683135544286507457936321625675700192471156785155\",\n                \"subsequenceNumber\": 0\n            }\n        }\n    ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#lambda-function-url",
            "title": "Lambda Function URL",
            "text": "<p>Lambda Function URLs provide a direct HTTP endpoint for invoking Lambda functions. This feature allows functions to receive and process HTTP requests without the need for additional services like API Gateway.</p> app.pyLambda Function URL Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import LambdaFunctionUrlEvent, event_source\n\n\n@event_source(data_class=LambdaFunctionUrlEvent)\ndef lambda_handler(event: LambdaFunctionUrlEvent, context):\n    if event.request_context.http.method == \"GET\":\n        return {\"statusCode\": 200, \"body\": \"Hello World!\"}\n</code></pre> <pre><code>{\n   \"version\":\"2.0\",\n   \"routeKey\":\"$default\",\n   \"rawPath\":\"/\",\n   \"rawQueryString\":\"\",\n   \"headers\":{\n      \"sec-fetch-mode\":\"navigate\",\n      \"x-amzn-tls-version\":\"TLSv1.2\",\n      \"sec-fetch-site\":\"cross-site\",\n      \"accept-language\":\"pt-BR,pt;q=0.9\",\n      \"x-forwarded-proto\":\"https\",\n      \"x-forwarded-port\":\"443\",\n      \"x-forwarded-for\":\"123.123.123.123\",\n      \"sec-fetch-user\":\"?1\",\n      \"accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n      \"x-amzn-tls-cipher-suite\":\"ECDHE-RSA-AES128-GCM-SHA256\",\n      \"sec-ch-ua\":\"\\\" Not A;Brand\\\";v=\\\"99\\\", \\\"Chromium\\\";v=\\\"102\\\", \\\"Google Chrome\\\";v=\\\"102\\\"\",\n      \"sec-ch-ua-mobile\":\"?0\",\n      \"x-amzn-trace-id\":\"Root=1-62ecd163-5f302e550dcde3b12402207d\",\n      \"sec-ch-ua-platform\":\"\\\"Linux\\\"\",\n      \"host\":\"&lt;url-id&gt;.lambda-url.us-east-1.on.aws\",\n      \"upgrade-insecure-requests\":\"1\",\n      \"cache-control\":\"max-age=0\",\n      \"accept-encoding\":\"gzip, deflate, br\",\n      \"sec-fetch-dest\":\"document\",\n      \"user-agent\":\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36\"\n   },\n   \"requestContext\":{\n      \"accountId\":\"anonymous\",\n      \"apiId\":\"&lt;url-id&gt;\",\n      \"domainName\":\"&lt;url-id&gt;.lambda-url.us-east-1.on.aws\",\n      \"domainPrefix\":\"&lt;url-id&gt;\",\n      \"http\":{\n         \"method\":\"GET\",\n         \"path\":\"/\",\n         \"protocol\":\"HTTP/1.1\",\n         \"sourceIp\":\"123.123.123.123\",\n         \"userAgent\":\"agent\"\n      },\n      \"requestId\":\"id\",\n      \"routeKey\":\"$default\",\n      \"stage\":\"$default\",\n      \"time\":\"05/Aug/2022:08:14:39 +0000\",\n      \"timeEpoch\":1659687279885\n   },\n   \"isBase64Encoded\":false\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#rabbit-mq",
            "title": "Rabbit MQ",
            "text": "<p>It is used for Rabbit MQ payloads. See the blog post for more details.</p> app.pyRabbit MQ Example Event <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.rabbit_mq_event import RabbitMQEvent\n\nlogger = Logger()\n\n\n@event_source(data_class=RabbitMQEvent)\ndef lambda_handler(event: RabbitMQEvent, context):\n    for queue_name, messages in event.rmq_messages_by_queue.items():\n        logger.debug(f\"Messages for queue: {queue_name}\")\n        for message in messages:\n            logger.debug(f\"MessageID: {message.basic_properties.message_id}\")\n            data: Dict = message.json_data\n            logger.debug(f\"Process json in base64 encoded data str {data}\")\n    return {\n        \"queue_name\": queue_name,\n        \"message_id\": message.basic_properties.message_id,\n    }\n</code></pre> <pre><code>{\n  \"eventSource\": \"aws:rmq\",\n  \"eventSourceArn\": \"arn:aws:mq:us-west-2:112556298976:broker:pizzaBroker:b-9bcfa592-423a-4942-879d-eb284b418fc8\",\n  \"rmqMessagesByQueue\": {\n    \"pizzaQueue::/\": [\n      {\n        \"basicProperties\": {\n          \"contentType\": \"text/plain\",\n          \"contentEncoding\": null,\n          \"headers\": {\n            \"header1\": {\n              \"bytes\": [\n                118,\n                97,\n                108,\n                117,\n                101,\n                49\n              ]\n            },\n            \"header2\": {\n              \"bytes\": [\n                118,\n                97,\n                108,\n                117,\n                101,\n                50\n              ]\n            },\n            \"numberInHeader\": 10\n          },\n          \"deliveryMode\": 1,\n          \"priority\": 34,\n          \"correlationId\": null,\n          \"replyTo\": null,\n          \"expiration\": \"60000\",\n          \"messageId\": null,\n          \"timestamp\": \"Jan 1, 1970, 12:33:41 AM\",\n          \"type\": null,\n          \"userId\": \"AIDACKCEVSQ6C2EXAMPLE\",\n          \"appId\": null,\n          \"clusterId\": null,\n          \"bodySize\": 80\n        },\n        \"redelivered\": false,\n        \"data\": \"eyJ0aW1lb3V0IjowLCJkYXRhIjoiQ1pybWYwR3c4T3Y0YnFMUXhENEUifQ==\"\n      }\n    ]\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#s3",
            "title": "S3",
            "text": "<p>Integration with Amazon S3 enables automatic, serverless processing of object-level events in S3 buckets. When triggered by actions like object creation or deletion, Lambda functions receive detailed event information, allowing for real-time file processing, data transformations, and automated workflows.</p> app.pyS3 Example Event <pre><code>from urllib.parse import unquote_plus\n\nfrom aws_lambda_powertools.utilities.data_classes import S3Event, event_source\n\n\n@event_source(data_class=S3Event)\ndef lambda_handler(event: S3Event, context):\n    bucket_name = event.bucket_name\n\n    # Multiple records can be delivered in a single event\n    for record in event.records:\n        object_key = unquote_plus(record.s3.get_object.key)\n        object_etag = record.s3.get_object.etag\n    return {\n        \"bucket\": bucket_name,\n        \"object_key\": object_key,\n        \"object_etag\": object_etag,\n    }\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"eventVersion\": \"2.1\",\n      \"eventSource\": \"aws:s3\",\n      \"awsRegion\": \"us-east-2\",\n      \"eventTime\": \"2019-09-03T19:37:27.192Z\",\n      \"eventName\": \"ObjectCreated:Put\",\n      \"userIdentity\": {\n        \"principalId\": \"AWS:AIDAINPONIXQXHT3IKHL2\"\n      },\n      \"requestParameters\": {\n        \"sourceIPAddress\": \"205.255.255.255\"\n      },\n      \"responseElements\": {\n        \"x-amz-request-id\": \"D82B88E5F771F645\",\n        \"x-amz-id-2\": \"vlR7PnpV2Ce81l0PRw6jlUpck7Jo5ZsQjryTjKlc5aLWGVHPZLj5NeC6qMa0emYBDXOo6QBU0Wo=\"\n      },\n      \"s3\": {\n        \"s3SchemaVersion\": \"1.0\",\n        \"configurationId\": \"828aa6fc-f7b5-4305-8584-487c791949c1\",\n        \"bucket\": {\n          \"name\": \"lambda-artifacts-deafc19498e3f2df\",\n          \"ownerIdentity\": {\n            \"principalId\": \"A3I5XTEXAMAI3E\"\n          },\n          \"arn\": \"arn:aws:s3:::lambda-artifacts-deafc19498e3f2df\"\n        },\n        \"object\": {\n          \"key\": \"b21b84d653bb07b05b1e6b33684dc11b\",\n          \"size\": 1305107,\n          \"eTag\": \"b21b84d653bb07b05b1e6b33684dc11b\",\n          \"sequencer\": \"0C0F6F405D6ED209E1\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#s3-batch-operations",
            "title": "S3 Batch Operations",
            "text": "<p>This example is based on the AWS S3 Batch Operations documentation Example Lambda function for S3 Batch Operations.</p> app.pyS3 Batch Operations Example Event <pre><code>import boto3\nfrom botocore.exceptions import ClientError\n\nfrom aws_lambda_powertools.utilities.data_classes import S3BatchOperationEvent, S3BatchOperationResponse, event_source\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@event_source(data_class=S3BatchOperationEvent)\ndef lambda_handler(event: S3BatchOperationEvent, context: LambdaContext):\n    response = S3BatchOperationResponse(event.invocation_schema_version, event.invocation_id, \"PermanentFailure\")\n\n    task = event.task\n    src_key: str = task.s3_key\n    src_bucket: str = task.s3_bucket\n\n    s3 = boto3.client(\"s3\", region_name=\"us-east-1\")\n\n    try:\n        dest_bucket, dest_key = do_some_work(s3, src_bucket, src_key)\n        result = task.build_task_batch_response(\"Succeeded\", f\"s3://{dest_bucket}/{dest_key}\")\n    except ClientError as e:\n        error_code = e.response[\"Error\"][\"Code\"]\n        error_message = e.response[\"Error\"][\"Message\"]\n        if error_code == \"RequestTimeout\":\n            result = task.build_task_batch_response(\"TemporaryFailure\", \"Retry request to Amazon S3 due to timeout.\")\n        else:\n            result = task.build_task_batch_response(\"PermanentFailure\", f\"{error_code}: {error_message}\")\n    except Exception as e:\n        result = task.build_task_batch_response(\"PermanentFailure\", str(e))\n    finally:\n        response.add_result(result)\n\n    return response.asdict()\n\n\ndef do_some_work(s3_client, src_bucket: str, src_key: str):\n    ...\n</code></pre> <pre><code>{\n  \"invocationSchemaVersion\": \"2.0\",\n  \"invocationId\": \"YXNkbGZqYWRmaiBhc2RmdW9hZHNmZGpmaGFzbGtkaGZza2RmaAo\",\n  \"job\": {\n    \"id\": \"f3cc4f60-61f6-4a2b-8a21-d07600c373ce\",\n    \"userArguments\": {\n      \"k1\": \"v1\",\n      \"k2\": \"v2\"\n    }\n  },\n  \"tasks\": [\n    {\n      \"taskId\": \"dGFza2lkZ29lc2hlcmUK\",\n      \"s3Key\": \"prefix/dataset/dataset.20231222.json.gz\",\n      \"s3VersionId\": null,\n      \"s3Bucket\": \"powertools-dataset\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#s3-object-lambda",
            "title": "S3 Object Lambda",
            "text": "<p>This example is based on the AWS Blog post Introducing Amazon S3 Object Lambda – Use Your Code to Process Data as It Is Being Retrieved from S3.</p> app.pyS3 Object Lambda Example Event <pre><code>import boto3\nimport requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.logging.correlation_paths import S3_OBJECT_LAMBDA\nfrom aws_lambda_powertools.utilities.data_classes.s3_object_event import S3ObjectLambdaEvent\n\nlogger = Logger()\nsession = boto3.session.Session()\ns3 = session.client(\"s3\")\n\n\n@logger.inject_lambda_context(correlation_id_path=S3_OBJECT_LAMBDA, log_event=True)\ndef lambda_handler(event, context):\n    event = S3ObjectLambdaEvent(event)\n\n    # Get object from S3\n    response = requests.get(event.input_s3_url)\n    original_object = response.content.decode(\"utf-8\")\n\n    # Make changes to the object about to be returned\n    transformed_object = original_object.upper()\n\n    # Write object back to S3 Object Lambda\n    s3.write_get_object_response(\n        Body=transformed_object,\n        RequestRoute=event.request_route,\n        RequestToken=event.request_token,\n    )\n\n    return {\"status_code\": 200}\n</code></pre> <pre><code>{\n    \"xAmzRequestId\": \"1a5ed718-5f53-471d-b6fe-5cf62d88d02a\",\n    \"getObjectContext\": {\n        \"inputS3Url\": \"https://myap-123412341234.s3-accesspoint.us-east-1.amazonaws.com/s3.txt?X-Amz-Security-Token=...\",\n        \"outputRoute\": \"io-iad-cell001\",\n        \"outputToken\": \"...\"\n    },\n    \"configuration\": {\n        \"accessPointArn\": \"arn:aws:s3-object-lambda:us-east-1:123412341234:accesspoint/myolap\",\n        \"supportingAccessPointArn\": \"arn:aws:s3:us-east-1:123412341234:accesspoint/myap\",\n        \"payload\": \"test\"\n    },\n    \"userRequest\": {\n        \"url\": \"/s3.txt\",\n        \"headers\": {\n            \"Host\": \"myolap-123412341234.s3-object-lambda.us-east-1.amazonaws.com\",\n            \"Accept-Encoding\": \"identity\",\n            \"X-Amz-Content-SHA256\": \"e3b0c44297fc1c149afbf4c8995fb92427ae41e4649b934ca495991b7852b855\"\n        }\n    },\n    \"userIdentity\": {\n        \"type\": \"IAMUser\",\n        \"principalId\": \"...\",\n        \"arn\": \"arn:aws:iam::123412341234:user/myuser\",\n        \"accountId\": \"123412341234\",\n        \"accessKeyId\": \"...\"\n    },\n    \"protocolVersion\": \"1.00\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#s3-eventbridge-notification",
            "title": "S3 EventBridge Notification",
            "text": "<p>S3 EventBridge notifications enhance Lambda's ability to process S3 events by routing them through Amazon EventBridge. This integration offers advanced filtering, multiple destination support, and standardized CloudEvents format.</p> app.pyS3 EventBridge Notification Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import S3EventBridgeNotificationEvent, event_source\n\n\n@event_source(data_class=S3EventBridgeNotificationEvent)\ndef lambda_handler(event: S3EventBridgeNotificationEvent, context):\n    bucket_name = event.detail.bucket.name\n    file_key = event.detail.object.key\n    if event.detail_type == \"Object Created\":\n        print(f\"Object {file_key} created in bucket {bucket_name}\")\n    return {\n        \"bucket\": bucket_name,\n        \"file_key\": file_key,\n    }\n</code></pre> <pre><code>{\n    \"version\": \"0\",\n    \"id\": \"f5f1e65c-dc3a-93ca-6c1e-b1647eac7963\",\n    \"detail-type\": \"Object Created\",\n    \"source\": \"aws.s3\",\n    \"account\": \"123456789012\",\n    \"time\": \"2023-03-08T17:50:14Z\",\n    \"region\": \"eu-west-1\",\n    \"resources\": [\n        \"arn:aws:s3:::example-bucket\"\n    ],\n    \"detail\": {\n        \"version\": \"0\",\n        \"bucket\": {\n            \"name\": \"example-bucket\"\n        },\n        \"object\": {\n            \"key\": \"IMG_m7fzo3.jpg\",\n            \"size\": 184662,\n            \"etag\": \"4e68adba0abe2dc8653dc3354e14c01d\",\n            \"sequencer\": \"006408CAD69598B05E\"\n        },\n        \"request-id\": \"57H08PA84AB1JZW0\",\n        \"requester\": \"123456789012\",\n        \"source-ip-address\": \"34.252.34.74\",\n        \"reason\": \"PutObject\"\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#secrets-manager",
            "title": "Secrets Manager",
            "text": "<p>AWS Secrets Manager rotation uses an AWS Lambda function to update the secret. Click here for more information about rotating AWS Secrets Manager secrets.</p> app.pySecrets Manager Example Event <pre><code>from aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.data_classes import SecretsManagerEvent, event_source\n\nsecrets_provider = parameters.SecretsProvider()\n\n\n@event_source(data_class=SecretsManagerEvent)\ndef lambda_handler(event: SecretsManagerEvent, context):\n    # Getting secret value using Parameter utility\n    # See https://docs.powertools.aws.dev/lambda/python/latest/utilities/parameters/\n    secret = secrets_provider.get(event.secret_id, VersionId=event.version_id, VersionStage=\"AWSCURRENT\")\n\n    # You need to work with secrets afterwards\n    # Check more examples: https://github.com/aws-samples/aws-secrets-manager-rotation-lambdas\n\n    return secret\n</code></pre> <pre><code>{\n    \"SecretId\":\"arn:aws:secretsmanager:us-west-2:123456789012:secret:MyTestDatabaseSecret-a1b2c3\",\n    \"ClientRequestToken\":\"550e8400-e29b-41d4-a716-446655440000\",\n    \"Step\":\"createSecret\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#ses",
            "title": "SES",
            "text": "<p>The integration with Simple Email Service (SES) enables serverless email processing. When configured, SES can trigger Lambda functions in response to incoming emails or delivery status notifications. The Lambda function receives an SES event containing details like sender, recipients, and email content.</p> app.pySES Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import SESEvent, event_source\n\n\n@event_source(data_class=SESEvent)\ndef lambda_handler(event: SESEvent, context):\n    # Multiple records can be delivered in a single event\n    for record in event.records:\n        mail = record.ses.mail\n        common_headers = mail.common_headers\n    return {\n        \"mail\": mail,\n        \"common_headers\": common_headers,\n    }\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"eventVersion\": \"1.0\",\n      \"ses\": {\n        \"mail\": {\n          \"commonHeaders\": {\n            \"from\": [\n              \"Jane Doe &lt;janedoe@example.com&gt;\"\n            ],\n            \"to\": [\n              \"johndoe@example.com\"\n            ],\n            \"returnPath\": \"janedoe@example.com\",\n            \"messageId\": \"&lt;0123456789example.com&gt;\",\n            \"date\": \"Wed, 7 Oct 2015 12:34:56 -0700\",\n            \"subject\": \"Test Subject\"\n          },\n          \"source\": \"janedoe@example.com\",\n          \"timestamp\": \"1970-01-01T00:00:00.000Z\",\n          \"destination\": [\n            \"johndoe@example.com\"\n          ],\n          \"headers\": [\n            {\n              \"name\": \"Return-Path\",\n              \"value\": \"&lt;janedoe@example.com&gt;\"\n            },\n            {\n              \"name\": \"Received\",\n              \"value\": \"from mailer.example.com (mailer.example.com [203.0.113.1]) by ...\"\n            },\n            {\n              \"name\": \"DKIM-Signature\",\n              \"value\": \"v=1; a=rsa-sha256; c=relaxed/relaxed; d=example.com; s=example; ...\"\n            },\n            {\n              \"name\": \"MIME-Version\",\n              \"value\": \"1.0\"\n            },\n            {\n              \"name\": \"From\",\n              \"value\": \"Jane Doe &lt;janedoe@example.com&gt;\"\n            },\n            {\n              \"name\": \"Date\",\n              \"value\": \"Wed, 7 Oct 2015 12:34:56 -0700\"\n            },\n            {\n              \"name\": \"Message-ID\",\n              \"value\": \"&lt;0123456789example.com&gt;\"\n            },\n            {\n              \"name\": \"Subject\",\n              \"value\": \"Test Subject\"\n            },\n            {\n              \"name\": \"To\",\n              \"value\": \"johndoe@example.com\"\n            },\n            {\n              \"name\": \"Content-Type\",\n              \"value\": \"text/plain; charset=UTF-8\"\n            }\n          ],\n          \"headersTruncated\": false,\n          \"messageId\": \"o3vrnil0e2ic28tr\"\n        },\n        \"receipt\": {\n          \"recipients\": [\n            \"johndoe@example.com\"\n          ],\n          \"timestamp\": \"1970-01-01T00:00:00.000Z\",\n          \"spamVerdict\": {\n            \"status\": \"PASS\"\n          },\n          \"dkimVerdict\": {\n            \"status\": \"PASS\"\n          },\n          \"dmarcPolicy\": \"reject\",\n          \"processingTimeMillis\": 574,\n          \"action\": {\n            \"type\": \"Lambda\",\n            \"invocationType\": \"Event\",\n            \"functionArn\": \"arn:aws:lambda:us-west-2:012345678912:function:Example\"\n          },\n          \"dmarcVerdict\": {\n            \"status\": \"PASS\"\n          },\n          \"spfVerdict\": {\n            \"status\": \"PASS\"\n          },\n          \"virusVerdict\": {\n            \"status\": \"PASS\"\n          }\n        }\n      },\n      \"eventSource\": \"aws:ses\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#sns",
            "title": "SNS",
            "text": "<p>The integration with Simple Notification Service (SNS) enables serverless message processing. When configured, SNS can trigger Lambda functions in response to published messages or notifications. The Lambda function receives an SNS event containing details like the message body, subject, and metadata.</p> app.pySNS Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import SNSEvent, event_source\n\n\n@event_source(data_class=SNSEvent)\ndef lambda_handler(event: SNSEvent, context):\n    # Multiple records can be delivered in a single event\n    for record in event.records:\n        message = record.sns.message\n        subject = record.sns.subject\n    return {\n        \"message\": message,\n        \"subject\": subject,\n    }\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"EventVersion\": \"1.0\",\n      \"EventSubscriptionArn\": \"arn:aws:sns:us-east-2:123456789012:sns-la ...\",\n      \"EventSource\": \"aws:sns\",\n      \"Sns\": {\n        \"SignatureVersion\": \"1\",\n        \"Timestamp\": \"2019-01-02T12:45:07.000Z\",\n        \"Signature\": \"tcc6faL2yUC6dgZdmrwh1Y4cGa/ebXEkAi6RibDsvpi+tE/1+82j...65r==\",\n        \"SigningCertUrl\": \"https://sns.us-east-2.amazonaws.com/SimpleNotification\",\n        \"MessageId\": \"95df01b4-ee98-5cb9-9903-4c221d41eb5e\",\n        \"Message\": \"Hello from SNS!\",\n        \"MessageAttributes\": {\n          \"Test\": {\n            \"Type\": \"String\",\n            \"Value\": \"TestString\"\n          },\n          \"TestBinary\": {\n            \"Type\": \"Binary\",\n            \"Value\": \"TestBinary\"\n          }\n        },\n        \"Type\": \"Notification\",\n        \"UnsubscribeUrl\": \"https://sns.us-east-2.amazonaws.com/?Action=Unsubscribe\",\n        \"TopicArn\": \"arn:aws:sns:us-east-2:123456789012:sns-lambda\",\n        \"Subject\": \"TestInvoke\"\n      }\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#sqs",
            "title": "SQS",
            "text": "<p>The integration with Simple Queue Service (SQS) enables serverless queue processing. When configured, SQS can trigger Lambda functions in response to messages in the queue. The Lambda function receives an SQS event containing details like message body, attributes, and metadata.</p> app.pySQS Example Event <pre><code>from aws_lambda_powertools.utilities.data_classes import SQSEvent, event_source\n\n\n@event_source(data_class=SQSEvent)\ndef lambda_handler(event: SQSEvent, context):\n    # Multiple records can be delivered in a single event\n    for record in event.records:\n        message = record.body\n        message_id = record.message_id\n    return {\n        \"message\": message,\n        \"message_id\": message_id,\n    }\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n      \"body\": \"Test message.\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082649183\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n      },\n      \"messageAttributes\": {\n        \"testAttr\": {\n          \"stringValue\": \"100\",\n          \"binaryValue\": \"base64Str\",\n          \"dataType\": \"Number\"\n        }\n      },\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:my-queue\",\n      \"awsRegion\": \"us-east-2\"\n    },\n    {\n      \"messageId\": \"2e1424d4-f796-459a-8184-9c92662be6da\",\n      \"receiptHandle\": \"AQEBzWwaftRI0KuVm4tP+/7q1rGgNqicHq...\",\n      \"body\": \"{\\\"message\\\": \\\"foo1\\\"}\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082650636\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082650649\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:my-queue\",\n      \"awsRegion\": \"us-east-2\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#vpc-lattice-v2",
            "title": "VPC Lattice V2",
            "text": "<p>You can register your Lambda functions as targets within an Amazon VPC Lattice service network. By doing this, your Lambda function becomes a service within the network, and clients that have access to the VPC Lattice service network can call your service using Payload V2.</p> <p>Click here for more information about using AWS Lambda with Amazon VPC Lattice.</p> app.pyLattice Example Event <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import VPCLatticeEventV2, event_source\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@event_source(data_class=VPCLatticeEventV2)\ndef lambda_handler(event: VPCLatticeEventV2, context: LambdaContext):\n    logger.info(event.body)\n\n    response = {\n        \"isBase64Encoded\": False,\n        \"statusCode\": 200,\n        \"statusDescription\": \"200 OK\",\n        \"headers\": {\"Content-Type\": \"application/text\"},\n        \"body\": \"VPC Lattice V2 Event ✨🎉✨\",\n    }\n\n    return response\n</code></pre> <pre><code>{\n  \"version\": \"2.0\",\n  \"path\": \"/todos\",\n  \"method\": \"GET\",\n  \"headers\": {\n    \"user_agent\": \"curl/7.64.1\",\n    \"x-forwarded-for\": \"10.213.229.10\",\n    \"host\": \"test-lambda-service-3908sdf9u3u.dkfjd93.vpc-lattice-svcs.us-east-2.on.aws\",\n    \"accept\": \"*/*\"\n  },\n  \"queryStringParameters\": {\n    \"order-id\": \"1\"\n  },\n  \"body\": \"{\\\"message\\\": \\\"Hello from Lambda!\\\"}\",\n  \"requestContext\": {\n      \"serviceNetworkArn\": \"arn:aws:vpc-lattice:us-east-2:123456789012:servicenetwork/sn-0bf3f2882e9cc805a\",\n      \"serviceArn\": \"arn:aws:vpc-lattice:us-east-2:123456789012:service/svc-0a40eebed65f8d69c\",\n      \"targetGroupArn\": \"arn:aws:vpc-lattice:us-east-2:123456789012:targetgroup/tg-6d0ecf831eec9f09\",\n      \"identity\": {\n        \"sourceVpcArn\": \"arn:aws:ec2:region:123456789012:vpc/vpc-0b8276c84697e7339\",\n        \"type\" : \"AWS_IAM\",\n        \"principal\": \"arn:aws:sts::123456789012:assumed-role/example-role/057d00f8b51257ba3c853a0f248943cf\",\n        \"sessionName\": \"057d00f8b51257ba3c853a0f248943cf\",\n        \"x509SanDns\": \"example.com\"\n      },\n      \"region\": \"us-east-2\",\n      \"timeEpoch\": \"1696331543569073\"\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#vpc-lattice-v1",
            "title": "VPC Lattice V1",
            "text": "<p>You can register your Lambda functions as targets within an Amazon VPC Lattice service network. By doing this, your Lambda function becomes a service within the network, and clients that have access to the VPC Lattice service network can call your service.</p> <p>Click here for more information about using AWS Lambda with Amazon VPC Lattice.</p> app.pyLattice Example Event <pre><code>from aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_classes import VPCLatticeEvent, event_source\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\n@event_source(data_class=VPCLatticeEvent)\ndef lambda_handler(event: VPCLatticeEvent, context: LambdaContext):\n    logger.info(event.body)\n\n    response = {\n        \"isBase64Encoded\": False,\n        \"statusCode\": 200,\n        \"headers\": {\"Content-Type\": \"application/text\"},\n        \"body\": \"Event Response to VPC Lattice 🔥🚀🔥\",\n    }\n\n    return response\n</code></pre> <pre><code>{\n    \"raw_path\": \"/testpath\",\n    \"method\": \"GET\",\n    \"headers\": {\n      \"user_agent\": \"curl/7.64.1\",\n      \"x-forwarded-for\": \"10.213.229.10\",\n      \"host\": \"test-lambda-service-3908sdf9u3u.dkfjd93.vpc-lattice-svcs.us-east-2.on.aws\",\n      \"accept\": \"*/*\"\n    },\n    \"query_string_parameters\": {\n      \"order-id\": \"1\"\n    },\n    \"body\": \"eyJ0ZXN0IjogImV2ZW50In0=\",\n    \"is_base64_encoded\": true\n  }\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#iot-core-events",
            "title": "IoT Core Events",
            "text": ""
        },
        {
            "location": "utilities/data_classes/#iot-core-thing-createdupdateddeleted",
            "title": "IoT Core Thing Created/Updated/Deleted",
            "text": "<p>You can use IoT Core registry events to trigger your lambda functions. More information on this specific one can be found here.</p> app.pyExample Event <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.iot_registry_event import IoTCoreThingEvent\n\n\n@event_source(data_class=IoTCoreThingEvent)\ndef lambda_handler(event: IoTCoreThingEvent, context):\n    print(f\"Received IoT Core event type {event.event_type}\")\n</code></pre> <pre><code>{\n  \"eventType\": \"THING_EVENT\",\n  \"eventId\": \"f5ae9b94-8b8e-4d8e-8c8f-b3266dd89853\",\n  \"timestamp\": 1234567890123,\n  \"operation\": \"CREATED\",\n  \"accountId\": \"123456789012\",\n  \"thingId\": \"b604f69c-aa9a-4d4a-829e-c480e958a0b5\",\n  \"thingName\": \"MyThing\",\n  \"versionNumber\": 1,\n  \"thingTypeName\": null,\n  \"attributes\": {\"attribute3\": \"value3\", \"attribute1\": \"value1\", \"attribute2\": \"value2\"}\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#iot-core-thing-type-createdupdateddeprecatedundeprecateddeleted",
            "title": "IoT Core Thing Type Created/Updated/Deprecated/Undeprecated/Deleted",
            "text": "<p>You can use IoT Core registry events to trigger your lambda functions. More information on this specific one can be found here.</p> app.pyExample Event <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.iot_registry_event import IoTCoreThingTypeEvent\n\n\n@event_source(data_class=IoTCoreThingTypeEvent)\ndef lambda_handler(event: IoTCoreThingTypeEvent, context):\n    print(f\"Received IoT Core event type {event.event_type}\")\n</code></pre> <pre><code>{\n  \"eventType\": \"THING_TYPE_EVENT\",\n  \"eventId\": \"8827376c-4b05-49a3-9b3b-733729df7ed5\",\n  \"timestamp\": 1234567890123,\n  \"operation\": \"CREATED\",\n  \"accountId\": \"123456789012\",\n  \"thingTypeId\": \"c530ae83-32aa-4592-94d3-da29879d1aac\",\n  \"thingTypeName\": \"MyThingType\",\n  \"isDeprecated\": false,\n  \"deprecationDate\": null,\n  \"searchableAttributes\": [\"attribute1\", \"attribute2\", \"attribute3\"],\n  \"propagatingAttributes\": [\n      {\"userPropertyKey\": \"key\", \"thingAttribute\": \"model\"},\n      {\"userPropertyKey\": \"key\", \"connectionAttribute\": \"iot:ClientId\"}\n  ],\n  \"description\": \"My thing type\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#iot-core-thing-type-associateddisassociated-with-a-thing",
            "title": "IoT Core Thing Type Associated/Disassociated with a Thing",
            "text": "<p>You can use IoT Core registry events to trigger your lambda functions. More information on this specific one can be found here.</p> app.pyExample Event <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.iot_registry_event import IoTCoreThingTypeAssociationEvent\n\n\n@event_source(data_class=IoTCoreThingTypeAssociationEvent)\ndef lambda_handler(event: IoTCoreThingTypeAssociationEvent, context):\n    print(f\"Received IoT Core event type {event.event_type}\")\n</code></pre> <pre><code>{\n  \"eventId\": \"87f8e095-531c-47b3-aab5-5171364d138d\",\n  \"eventType\": \"THING_TYPE_ASSOCIATION_EVENT\",\n  \"operation\": \"ADDED\",\n  \"thingId\": \"b604f69c-aa9a-4d4a-829e-c480e958a0b5\",\n  \"thingName\": \"myThing\",\n  \"thingTypeName\": \"MyThingType\",\n  \"timestamp\": 1234567890123\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#iot-core-thing-group-createdupdateddeleted",
            "title": "IoT Core Thing Group Created/Updated/Deleted",
            "text": "<p>You can use IoT Core registry events to trigger your lambda functions. More information on this specific one can be found here.</p> app.pyExample Event <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.iot_registry_event import IoTCoreThingGroupEvent\n\n\n@event_source(data_class=IoTCoreThingGroupEvent)\ndef lambda_handler(event: IoTCoreThingGroupEvent, context):\n    print(f\"Received IoT Core event type {event.event_type}\")\n</code></pre> <pre><code>{\n  \"eventType\": \"THING_GROUP_EVENT\",\n  \"eventId\": \"8b9ea8626aeaa1e42100f3f32b975899\",\n  \"timestamp\": 1603995417409,\n  \"operation\": \"UPDATED\",\n  \"accountId\": \"571EXAMPLE833\",\n  \"thingGroupId\": \"8757eec8-bb37-4cca-a6fa-403b003d139f\",\n  \"thingGroupName\": \"Tg_level5\",\n  \"versionNumber\": 3,\n  \"parentGroupName\": \"Tg_level4\",\n  \"parentGroupId\": \"5fce366a-7875-4c0e-870b-79d8d1dce119\",\n  \"description\": \"New description for Tg_level5\",\n  \"rootToParentThingGroups\": [\n      {\n          \"groupArn\": \"arn:aws:iot:us-west-2:571EXAMPLE833:thinggroup/TgTopLevel\",\n          \"groupId\": \"36aa0482-f80d-4e13-9bff-1c0a75c055f6\"\n      },\n      {\n          \"groupArn\": \"arn:aws:iot:us-west-2:571EXAMPLE833:thinggroup/Tg_level1\",\n          \"groupId\": \"bc1643e1-5a85-4eac-b45a-92509cbe2a77\"\n      },\n      {\n          \"groupArn\": \"arn:aws:iot:us-west-2:571EXAMPLE833:thinggroup/Tg_level2\",\n          \"groupId\": \"0476f3d2-9beb-48bb-ae2c-ea8bd6458158\"\n      },\n      {\n          \"groupArn\": \"arn:aws:iot:us-west-2:571EXAMPLE833:thinggroup/Tg_level3\",\n          \"groupId\": \"1d9d4ffe-a6b0-48d6-9de6-2e54d1eae78f\"\n      },\n      {\n          \"groupArn\": \"arn:aws:iot:us-west-2:571EXAMPLE833:thinggroup/Tg_level4\",\n          \"groupId\": \"5fce366a-7875-4c0e-870b-79d8d1dce119\"\n      }\n  ],\n  \"attributes\": {\"attribute1\": \"value1\", \"attribute3\": \"value3\", \"attribute2\": \"value2\"},\n  \"dynamicGroupMappingId\": null\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#iot-thing-addedremoved-from-thing-group",
            "title": "IoT Thing Added/Removed from Thing Group",
            "text": "<p>You can use IoT Core registry events to trigger your lambda functions. More information on this specific one can be found here.</p> app.pyExample Event <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.iot_registry_event import IoTCoreAddOrRemoveFromThingGroupEvent\n\n\n@event_source(data_class=IoTCoreAddOrRemoveFromThingGroupEvent)\ndef lambda_handler(event: IoTCoreAddOrRemoveFromThingGroupEvent, context):\n    print(f\"Received IoT Core event type {event.event_type}\")\n</code></pre> <pre><code>{\n    \"eventType\": \"THING_GROUP_MEMBERSHIP_EVENT\",\n    \"eventId\": \"d684bd5f-6f6e-48e1-950c-766ac7f02fd1\",\n    \"timestamp\": 1234567890123,\n    \"operation\": \"ADDED\",\n    \"accountId\": \"123456789012\",\n    \"groupArn\": \"arn:aws:iot:ap-northeast-2:123456789012:thinggroup/MyChildThingGroup\",\n    \"groupId\": \"06838589-373f-4312-b1f2-53f2192291c4\",\n    \"thingArn\": \"arn:aws:iot:ap-northeast-2:123456789012:thing/MyThing\",\n    \"thingId\": \"b604f69c-aa9a-4d4a-829e-c480e958a0b5\",\n    \"membershipId\": \"8505ebf8-4d32-4286-80e9-c23a4a16bbd8\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#iot-child-group-addeddeleted-from-parent-group",
            "title": "IoT Child Group Added/Deleted from Parent Group",
            "text": "<p>You can use IoT Core registry events to trigger your lambda functions. More information on this specific one can be found here.</p> app.pyExample Event <pre><code>from aws_lambda_powertools.utilities.data_classes import event_source\nfrom aws_lambda_powertools.utilities.data_classes.iot_registry_event import IoTCoreAddOrDeleteFromThingGroupEvent\n\n\n@event_source(data_class=IoTCoreAddOrDeleteFromThingGroupEvent)\ndef lambda_handler(event: IoTCoreAddOrDeleteFromThingGroupEvent, context):\n    print(f\"Received IoT Core event type {event.event_type}\")\n</code></pre> <pre><code>{\n    \"eventType\": \"THING_GROUP_HIERARCHY_EVENT\",\n    \"eventId\": \"264192c7-b573-46ef-ab7b-489fcd47da41\",\n    \"timestamp\": 1234567890123,\n    \"operation\": \"ADDED\",\n    \"accountId\": \"123456789012\",\n    \"thingGroupId\": \"8f82a106-6b1d-4331-8984-a84db5f6f8cb\",\n    \"thingGroupName\": \"MyRootThingGroup\",\n    \"childGroupId\": \"06838589-373f-4312-b1f2-53f2192291c4\",\n    \"childGroupName\": \"MyChildThingGroup\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_classes/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/data_classes/#debugging",
            "title": "Debugging",
            "text": "<p>Alternatively, you can print out the fields to obtain more information. All classes come with a <code>__str__</code> method that generates a dictionary string which can be quite useful for debugging.</p> <p>However, certain events may contain sensitive fields such as <code>secret_access_key</code> and <code>session_token</code>, which are labeled as <code>[SENSITIVE]</code> to prevent any accidental disclosure of confidential information.</p> <p>If we fail to deserialize a field value (e.g., JSON), they will appear as <code>[Cannot be deserialized]</code></p> debugging.pydebugging_event.jsondebugging_output.json <pre><code>from aws_lambda_powertools.utilities.data_classes import (\n    CodePipelineJobEvent,\n    event_source,\n)\n\n\n@event_source(data_class=CodePipelineJobEvent)\ndef lambda_handler(event, context):\n    print(event)\n</code></pre> <pre><code>{\n    \"CodePipeline.job\": {\n        \"id\": \"11111111-abcd-1111-abcd-111111abcdef\",\n        \"accountId\": \"111111111111\",\n        \"data\": {\n            \"actionConfiguration\": {\n                \"configuration\": {\n                    \"FunctionName\": \"MyLambdaFunctionForAWSCodePipeline\",\n                    \"UserParameters\": \"some-input-such-as-a-URL\"\n                }\n            },\n            \"inputArtifacts\": [\n                {\n                    \"name\": \"ArtifactName\",\n                    \"revision\": null,\n                    \"location\": {\n                        \"type\": \"S3\",\n                        \"s3Location\": {\n                            \"bucketName\": \"the name of the bucket configured as the pipeline artifact store in Amazon S3, for example codepipeline-us-east-2-1234567890\",\n                            \"objectKey\": \"the name of the application, for example CodePipelineDemoApplication.zip\"\n                        }\n                    }\n                }\n            ],\n            \"outputArtifacts\": [],\n            \"artifactCredentials\": {\n                \"accessKeyId\": \"AKIAIOSFODNN7EXAMPLE\",\n                \"secretAccessKey\": \"wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\",\n                \"sessionToken\": \"MIICiTCCAfICCQD6m7oRw0uXOjANBgkqhkiG9w0BAQUFADCBiDELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAldBMRAwDgYDVQQHEwdTZWF0dGxlMQ8wDQYDVQQKEwZBbWF6b24xFDASBgNVBAsTC0lBTSBDb25zb2xlMRIwEAYDVQQDEwlUZXN0Q2lsYWMxHzAdBgkqhkiG9w0BCQEWEG5vb25lQGFtYXpvbi5jb20wHhcNMTEwNDI1MjA0NTIxWhcNMTIwNDI0MjA0NTIxWjCBiDELMAkGA1UEBhMCVVMxCzAJBgNVBAgTAldBMRAwDgYDVQQHEwdTZWF0dGxlMQ8wDQYDVQQKEwZBbWF6b24xFDASBgNVBAsTC0lBTSBDb25zb2xlMRIwEAYDVQQDEwlUZXN0Q2lsYWMxHzAdBgkqhkiG9w0BCQEWEG5vb25lQGFtYXpvbi5jb20wgZ8wDQYJKoZIhvcNAQEBBQADgY0AMIGJAoGBAMaK0dn+a4GmWIWJ21uUSfwfEvySWtC2XADZ4nB+BLYgVIk60CpiwsZ3G93vUEIO3IyNoH/f0wYK8m9TrDHudUZg3qX4waLG5M43q7Wgc/MbQITxOUSQv7c7ugFFDzQGBzZswY6786m86gpEIbb3OhjZnzcvQAaRHhdlQWIMm2nrAgMBAAEwDQYJKoZIhvcNAQEFBQADgYEAtCu4nUhVVxYUntneD9+h8Mg9q6q+auNKyExzyLwaxlAoo7TJHidbtS4J5iNmZgXL0FkbFFBjvSfpJIlJ00zbhNYS5f6GuoEDmFJl0ZxBHjJnyp378OD8uTs7fLvjx79LjSTbNYiytVbZPQUQ5Yaxu2jXnimvw3rrszlaEXAMPLE=\"\n            },\n            \"continuationToken\": \"A continuation token if continuing job\"\n        }\n    }\n  }\n</code></pre> <pre><code>{\n    \"account_id\":\"111111111111\",\n    \"data\":{\n       \"action_configuration\":{\n          \"configuration\":{\n             \"decoded_user_parameters\":\"[Cannot be deserialized]\",\n             \"function_name\":\"MyLambdaFunctionForAWSCodePipeline\",\n             \"raw_event\":\"[SENSITIVE]\",\n             \"user_parameters\":\"some-input-such-as-a-URL\"\n          },\n          \"raw_event\":\"[SENSITIVE]\"\n       },\n       \"artifact_credentials\":{\n          \"access_key_id\":\"AKIAIOSFODNN7EXAMPLE\",\n          \"expiration_time\":\"None\",\n          \"raw_event\":\"[SENSITIVE]\",\n          \"secret_access_key\":\"[SENSITIVE]\",\n          \"session_token\":\"[SENSITIVE]\"\n       },\n       \"continuation_token\":\"A continuation token if continuing job\",\n       \"encryption_key\":\"None\",\n       \"input_artifacts\":[\n          {\n             \"location\":{\n                \"get_type\":\"S3\",\n                \"raw_event\":\"[SENSITIVE]\",\n                \"s3_location\":{\n                   \"bucket_name\":\"the name of the bucket configured as the pipeline artifact store in Amazon S3, for example codepipeline-us-east-2-1234567890\",\n                   \"key\":\"the name of the application, for example CodePipelineDemoApplication.zip\",\n                   \"object_key\":\"the name of the application, for example CodePipelineDemoApplication.zip\",\n                   \"raw_event\":\"[SENSITIVE]\"\n                }\n             },\n             \"name\":\"ArtifactName\",\n             \"raw_event\":\"[SENSITIVE]\",\n             \"revision\":\"None\"\n          }\n       ],\n       \"output_artifacts\":[\n\n       ],\n       \"raw_event\":\"[SENSITIVE]\"\n    },\n    \"decoded_user_parameters\":\"[Cannot be deserialized]\",\n    \"get_id\":\"11111111-abcd-1111-abcd-111111abcdef\",\n    \"input_bucket_name\":\"the name of the bucket configured as the pipeline artifact store in Amazon S3, for example codepipeline-us-east-2-1234567890\",\n    \"input_object_key\":\"the name of the application, for example CodePipelineDemoApplication.zip\",\n    \"raw_event\":\"[SENSITIVE]\",\n    \"user_parameters\":\"some-input-such-as-a-URL\"\n }\n</code></pre>"
        },
        {
            "location": "utilities/data_masking/",
            "title": "Data Masking",
            "text": "<p>The data masking utility can encrypt, decrypt, or irreversibly erase sensitive information to protect data confidentiality.</p> <pre><code>stateDiagram-v2\n    direction LR\n    LambdaFn: Your Lambda function\n    DataMasking: DataMasking\n    Operation: Possible operations\n    Input: Sensitive value\n    Erase: &lt;strong&gt;Erase&lt;/strong&gt;\n    Encrypt: &lt;strong&gt;Encrypt&lt;/strong&gt;\n    Decrypt: &lt;strong&gt;Decrypt&lt;/strong&gt;\n    Provider: AWS Encryption SDK provider\n    Result: Data transformed &lt;i&gt;(erased, encrypted, or decrypted)&lt;/i&gt;\n\n    LambdaFn --&gt; DataMasking\n    DataMasking --&gt; Operation\n\n    state Operation {\n        [*] --&gt; Input\n        Input --&gt; Erase: Irreversible\n        Input --&gt; Encrypt\n        Input --&gt; Decrypt\n        Encrypt --&gt; Provider\n        Decrypt --&gt; Provider\n    }\n\n    Operation --&gt; Result</code></pre>"
        },
        {
            "location": "utilities/data_masking/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Encrypt, decrypt, or irreversibly erase data with ease</li> <li>Erase sensitive information in one or more fields within nested data</li> <li>Seamless integration with AWS Encryption SDK for industry and AWS security best practices</li> </ul>"
        },
        {
            "location": "utilities/data_masking/#terminology",
            "title": "Terminology",
            "text": "<p>Erasing replaces sensitive information irreversibly with a non-sensitive placeholder (<code>*****</code>), or with a customized mask. This operation replaces data in-memory, making it a one-way action.</p> <p>Encrypting transforms plaintext into ciphertext using an encryption algorithm and a cryptographic key. It allows you to encrypt any sensitive data, so only allowed personnel to decrypt it. Learn more about encryption here.</p> <p>Decrypting transforms ciphertext back into plaintext using a decryption algorithm and the correct decryption key.</p> <p>Encryption context is a non-secret <code>key=value</code> data used for authentication like <code>tenant_id:&lt;id&gt;</code>. This adds extra security and confirms encrypted data relationship with a context.</p> <p>Encrypted message is a portable data structure that includes encrypted data along with copies of the encrypted data key. It includes everything Encryption SDK needs to validate authenticity, integrity, and to decrypt with the right master key.</p> <p>Envelope encryption uses two different keys to encrypt data safely: master and data key. The data key encrypts the plaintext, and the master key encrypts the data key. It simplifies key management (you own the master key), isolates compromises to data key, and scales better with large data volumes.</p> <p> <pre><code>graph LR\n    M(Master key) --&gt; |Encrypts| D(Data key)\n    D(Data key) --&gt; |Encrypts| S(Sensitive data)</code></pre> Envelope encryption visualized. </p>"
        },
        {
            "location": "utilities/data_masking/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p>"
        },
        {
            "location": "utilities/data_masking/#install",
            "title": "Install",
            "text": "<p>Add <code>aws-lambda-powertools[datamasking]</code> as a dependency in your preferred tool: e.g., requirements.txt, pyproject.toml. This will install the AWS Encryption SDK.</p> <p>AWS Encryption SDK contains non-Python dependencies. This means you should use AWS SAM CLI or official build container images when building your application for AWS Lambda. Local development should work as expected.</p>"
        },
        {
            "location": "utilities/data_masking/#required-resources",
            "title": "Required resources",
            "text": "<p>By default, we use Amazon Key Management Service (KMS) for encryption and decryption operations.</p> <p>Before you start, you will need a KMS symmetric key to encrypt and decrypt your data. Your Lambda function will need read and write access to it.</p> <p>NOTE. We recommend setting a minimum of 1024MB of memory (CPU intensive), and separate Lambda functions for encrypt and decrypt. For more information, you can see the full reports of our load tests and traces.</p> AWS Serverless Application Model (SAM) example <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: &gt;\n  Powertools for AWS Lambda (Python) data masking example\n\nGlobals: # https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-specification-template-anatomy-globals.html\n  Function:\n    Timeout: 5\n    Runtime: python3.11\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: PowertoolsHelloWorld\n        POWERTOOLS_LOG_LEVEL: INFO\n        KMS_KEY_ARN: !GetAtt DataMaskingMasterKey.Arn\n\n# In production, we recommend you split up the encrypt and decrypt for fine-grained security.\n# For example, one function can act as the encryption proxy via HTTP requests, data pipeline, etc.,\n# while only authorized personnel can call decrypt via a separate function.\nResources:\n  DataMaskingEncryptFunctionExample:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: data_masking_function_example.lambda_handler\n      CodeUri: ../src\n      Description: Data Masking encryption function\n      # Cryptographic operations demand more CPU. CPU is proportionally allocated based on memory size.\n      # We recommend allocating a minimum of 1024MB of memory.\n      MemorySize: 1024\n\n  # DataMaskingDecryptFunctionExample:\n  #   Type: AWS::Serverless::Function\n  #   Properties:\n  #     Handler: data_masking_function_decrypt.lambda_handler\n  #     CodeUri: ../src\n  #     Description: Data Masking decryption function\n  #     MemorySize: 1024\n\n  # KMS Key\n  DataMaskingMasterKey:\n    Type: \"AWS::KMS::Key\"\n    Properties:\n      Description: KMS Key for encryption and decryption using Powertools for AWS Lambda Data masking feature\n      # KMS Key support both IAM Resource Policies and Key Policies\n      # For more details: https://docs.aws.amazon.com/kms/latest/developerguide/key-policies.html\n      KeyPolicy:\n        Version: \"2012-10-17\"\n        Id: data-masking-enc-dec\n        Statement:\n          # For security reasons, ensure your KMS Key has at least one administrator.\n          # In this example, the root account is granted administrator permissions.\n          # However, we recommended configuring specific IAM Roles for enhanced security in production.\n          - Effect: Allow\n            Principal:\n              AWS: !Sub \"arn:aws:iam::${AWS::AccountId}:root\" # (1)!\n            Action: \"kms:*\"\n            Resource: \"*\"\n          # We must grant Lambda's IAM Role access to the KMS Key\n          - Effect: Allow\n            Principal:\n              AWS: !GetAtt DataMaskingEncryptFunctionExampleRole.Arn # (2)!\n            Action:\n              - kms:Decrypt # to decrypt encrypted data key\n              - kms:GenerateDataKey # to create an unique and random data key for encryption\n              # Encrypt permission is required only when using multiple keys\n              - kms:Encrypt  # (3)!\n            Resource: \"*\"\n</code></pre> <ol> <li>Key policy examples using IAM Roles</li> <li>SAM generated CloudFormation Resources</li> <li>Required only when using multiple keys</li> </ol>"
        },
        {
            "location": "utilities/data_masking/#erasing-data",
            "title": "Erasing data",
            "text": "<p>Erasing will remove the original data and replace it with a <code>*****</code>. This means you cannot recover erased data, and the data type will change to <code>str</code> for all data unless the data to be erased is of an Iterable type (<code>list</code>, <code>tuple</code>, <code>set</code>), in which case the method will return a new object of the same type as the input data but with each element replaced by the string <code>*****</code>.</p> getting_started_erase_data.pygeneric_data_input.jsongetting_started_erase_data_output.json <pre><code>from __future__ import annotations\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\ndata_masker = DataMasking()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    data: dict = event.get(\"body\", {})\n\n    logger.info(\"Erasing fields email, address.street, and company_address\")\n\n    erased = data_masker.erase(data, fields=[\"email\", \"address.street\", \"company_address\"])  # (1)!\n\n    return erased\n</code></pre> <ol> <li>See working with nested data to learn more about the <code>fields</code> parameter. If we omit <code>fields</code> parameter, the entire dictionary will be erased with <code>*****</code>.</li> </ol> <pre><code>{\n    \"body\": \n    {\n        \"id\": 1,\n        \"name\": \"John Doe\",\n        \"age\": 30,\n        \"email\": \"johndoe@example.com\",\n        \"address\": {\n            \"street\": \"123 Main St\", \n            \"city\": \"Anytown\", \n            \"state\": \"CA\", \n            \"zip\": \"12345\"\n        },\n        \"company_address\": {\n            \"street\": \"456 ACME Ave\", \n            \"city\": \"Anytown\", \n            \"state\": \"CA\", \n            \"zip\": \"12345\"\n        }\n    }\n}\n</code></pre> <pre><code>{\n    \"id\": 1,\n    \"name\": \"John Doe\",\n    \"age\": 30,\n    \"email\": \"*****\",\n    \"address\": {\n        \"street\": \"*****\",\n        \"city\": \"Anytown\",\n        \"state\": \"CA\",\n        \"zip\": \"12345\"\n    },\n    \"company_address\": \"*****\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_masking/#custom-masking",
            "title": "Custom masking",
            "text": "<p>The <code>erase</code> method also supports additional flags for more advanced and flexible masking:</p> dynamic_maskcustom_maskregex_pattern &amp; mask_formatmasking_rulesInput exampleMasking rules output example <p>(bool) Enables dynamic masking behavior when set to <code>True</code>, by maintaining the original length and structure of the text replacing with *.</p> <p>Expression: <code>data_masker.erase(data, fields=[\"address.zip\"], dynamic_mask=True)</code></p> <p>Field result: <code>'street': '*** **** **'</code></p> <p>(str) Specifies a simple pattern for masking data. This pattern is applied directly to the input string, replacing all the original characters. For example, with a <code>custom_mask</code> of \"XX-XX\" applied to \"12345\", the result would be \"XX-XX\".</p> <p>Expression: <code>data_masker.erase(data, fields=[\"address.zip\"], custom_mask=\"XX\")</code></p> <p>Field result: <code>'zip': 'XX'</code></p> <p>(str) <code>regex_pattern</code> defines a regular expression pattern used to identify parts of the input string that should be masked. This allows for more complex and flexible masking rules. It's used in conjunction with <code>mask_format</code>. <code>mask_format</code> specifies the format to use when replacing parts of the string matched by <code>regex_pattern</code>. It can include placeholders (like \\1, \\2) to refer to captured groups in the regex pattern, allowing some parts of the original string to be preserved.</p> <p>Expression: <code>data_masker.erase(data, fields=[\"email\"], regex_pattern=r\"(.)(.*)(@.*)\", mask_format=r\"\\1****\\3\")</code></p> <p>Field result: <code>'email': 'j****@example.com'</code></p> <p>(dict) Allows you to apply different masking rules (flags) for each data field. <pre><code>from __future__ import annotations\n\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ndata_masker = DataMasking()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    data: dict = event.get(\"body\", {})\n\n    # Masking rules for each field\n    masking_rules = {\n        \"email\": {\"regex_pattern\": \"(.)(.*)(@.*)\", \"mask_format\": r\"\\1****\\3\"},\n        \"age\": {\"dynamic_mask\": True},\n        \"address.zip\": {\"custom_mask\": \"xxx\"},\n        \"$.other_address[?(@.postcode &gt; 12000)]\": {\"custom_mask\": \"Masked\"},\n    }\n\n    result = data_masker.erase(data, masking_rules=masking_rules)\n\n    return result\n</code></pre></p> <pre><code>{\n    \"body\": {\n        \"id\": 1,\n        \"name\": \"Jane Doe\",\n        \"age\": 30,\n        \"email\": \"janedoe@example.com\",\n        \"address\": {\n            \"street\": \"123 Main St\",\n            \"city\": \"Anytown\",\n            \"state\": \"CA\",\n            \"zip\": \"12345\",\n            \"postcode\": 12345,\n            \"product\": {\n                \"name\": \"Car\"\n            }\n        },\n        \"other_address\": [\n            {\n                \"postcode\": 11345,\n                \"street\": \"123 Any Drive\"\n            },\n            {\n                \"postcode\": 67890,\n                \"street\": \"100 Main Street,\"\n            }\n        ],\n        \"company_address\": {\n            \"street\": \"456 ACME Ave\",\n            \"city\": \"Anytown\",\n            \"state\": \"CA\",\n            \"zip\": \"12345\"\n        }\n    }\n}\n</code></pre> <pre><code>{\n    \"id\": 1,\n    \"name\": \"John Doe\",\n    \"age\": \"**\",\n    \"email\": \"j****@example.com\",\n    \"address\": {\n        \"street\": \"123 Main St\",\n        \"city\": \"Anytown\",\n        \"state\": \"CA\",\n        \"zip\": \"xxx\",\n        \"postcode\": 12345,\n        \"product\": {\n            \"name\": \"Car\"\n        }\n    },\n    \"other_address\": [\n        {\n            \"postcode\": 11345,\n            \"street\": \"123 Any Drive\"\n        },\n        \"Masked\"\n    ],\n    \"company_address\": {\n        \"street\": \"456 ACME Ave\",\n        \"city\": \"Anytown\",\n        \"state\": \"CA\",\n        \"zip\": \"12345\"\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_masking/#encrypting-data",
            "title": "Encrypting data",
            "text": "About static typing and encryption <p>Encrypting data may lead to a different data type, as it always transforms into a string (<code>&lt;ciphertext&gt;</code>).</p> <p>To encrypt, you will need an encryption provider. Here, we will use <code>AWSEncryptionSDKProvider</code>.</p> <p>Under the hood, we delegate a number of operations to AWS Encryption SDK to authenticate, create a portable encryption message, and actual data encryption.</p> getting_started_encrypt_data.pygeneric_data_input.jsonencrypt_data_output.json <pre><code>from __future__ import annotations\n\nimport os\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk import (\n    AWSEncryptionSDKProvider,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nKMS_KEY_ARN = os.getenv(\"KMS_KEY_ARN\", \"\")\n\nencryption_provider = AWSEncryptionSDKProvider(keys=[KMS_KEY_ARN])  # (1)!\ndata_masker = DataMasking(provider=encryption_provider)\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    data: dict = event.get(\"body\", {})\n\n    logger.info(\"Encrypting the whole object\")\n\n    encrypted = data_masker.encrypt(data)\n\n    return {\"body\": encrypted}\n</code></pre> <ol> <li>You can use more than one KMS Key for higher availability but increased latency. Encryption SDK will ensure the data key is encrypted with both keys.</li> </ol> <pre><code>{\n    \"body\": \n    {\n        \"id\": 1,\n        \"name\": \"John Doe\",\n        \"age\": 30,\n        \"email\": \"johndoe@example.com\",\n        \"address\": {\n            \"street\": \"123 Main St\", \n            \"city\": \"Anytown\", \n            \"state\": \"CA\", \n            \"zip\": \"12345\"\n        },\n        \"company_address\": {\n            \"street\": \"456 ACME Ave\", \n            \"city\": \"Anytown\", \n            \"state\": \"CA\", \n            \"zip\": \"12345\"\n        }\n    }\n}\n</code></pre> <pre><code>{\n    \"body\": \"AgV4uF5K2YMtNhYrtviTwKNrUHhqQr73l/jNfukkh+qLOC8AXwABABVhd3MtY3J5cHRvLXB1YmxpYy1rZXkAREEvcjEyaFZHY1R5cjJuTDNKbTJ3UFA3R3ZjaytIdi9hekZqbXVUb25Ya3J5SzFBOUlJZDZxZXpSR1NTVnZDUUxoZz09AAEAB2F3cy1rbXMAS2Fybjphd3M6a21zOnVzLWVhc3QtMToyMDA5ODQxMTIzODY6a2V5LzZkODJiMzRlLTM2NjAtNDRlMi04YWJiLTdmMzA1OGJlYTIxMgC4AQIBAHjxYXAO7wQGd+7qxoyvXAajwqboF5FL/9lgYUNJTB8VtAHBP2hwVgw+zypp7GoMNTPAAAAAfjB8BgkqhkiG9w0BBwagbzBtAgEAMGgGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMx/B25MTgWwpL7CmuAgEQgDtan3orAOKFUfyNm3v6rFcglb+BVVVDV71fj4aRljhpg1ixsYFaKsoej8NcwRktIiWE+mw9XmTEVb6xFQIAABAA9DeLzlRaRQgTcXMJG0iBu/YTyyDKiROD+bU1Y09X9RBz5LA1nWIENJKq2seAhNSB/////wAAAAEAAAAAAAAAAAAAAAEAAAEBExLJ9wI4n7t+wyPEEP4kjYFBdkmNuLLsVC2Yt8mv9Y1iH2G+/g9SaIcdK57pkoW0ECpBxZVOxCuhmK2s74AJCUdem9McjS1waUKyzYTi9vv2ySNBsABIDwT990rE7jZJ3tEZAqcWZg/eWlxvnksFR/akBWZKsKzFz6lF57+cTgdISCEJRV0E7fcUeCuaMaQGK1Qw2OCmIeHEG5j5iztBkZG2IB2CVND/AbxmDUFHwgjsrJPTzaDYSufcGMoZW1A9X1sLVfqNVKvnOFP5tNY7kPF5eAI9FhGBw8SjTqODXz4k6zuqzy9no8HtXowP265U8NZ5VbVTd/zuVEbZyK5KBqzP1sExW4RhnlpXMoOs9WSuAGcwZQIxANTeEwb9V7CacV2Urt/oCqysUzhoV2AcT2ZjryFqY79Tsg+FRpIx7cBizL4ieRzbhQIwcRasNncO5OZOcmVr0MqHv+gCVznndMgjXJmWwUa7h6skJKmhhMPlN0CsugxtVWnD\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_masking/#decrypting-data",
            "title": "Decrypting data",
            "text": "About static typing and decryption <p>Decrypting data may lead to a different data type, as encrypted data is always a string (<code>&lt;ciphertext&gt;</code>).</p> <p>To decrypt, you will need an encryption provider. Here, we will use <code>AWSEncryptionSDKProvider</code>.</p> <p>Under the hood, we delegate a number of operations to AWS Encryption SDK to verify authentication, integrity, and actual ciphertext decryption.</p> getting_started_decrypt_data.pygetting_started_decrypt_data_input.jsongetting_started_decrypt_data_output.json <p>NOTE. Decryption only works with KMS Key ARN.</p> <pre><code>from __future__ import annotations\n\nimport os\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk import AWSEncryptionSDKProvider\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nKMS_KEY_ARN = os.getenv(\"KMS_KEY_ARN\", \"\")  # (1)!\n\nencryption_provider = AWSEncryptionSDKProvider(keys=[KMS_KEY_ARN])  # (2)!\ndata_masker = DataMasking(provider=encryption_provider)\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    data: dict = event.get(\"body\", {})\n\n    logger.info(\"Decrypting whole object\")\n\n    decrypted = data_masker.decrypt(data)\n\n    return decrypted\n</code></pre> <ol> <li>Note that KMS key alias or key ID won't work.</li> <li>You can use more than one KMS Key for higher availability but increased latency. Encryption SDK will call <code>Decrypt</code> API with all master keys when trying to decrypt the data key.</li> </ol> <pre><code>{\n    \"body\": \"AgV4uF5K2YMtNhYrtviTwKNrUHhqQr73l/jNfukkh+qLOC8AXwABABVhd3MtY3J5cHRvLXB1YmxpYy1rZXkAREEvcjEyaFZHY1R5cjJuTDNKbTJ3UFA3R3ZjaytIdi9hekZqbXVUb25Ya3J5SzFBOUlJZDZxZXpSR1NTVnZDUUxoZz09AAEAB2F3cy1rbXMAS2Fybjphd3M6a21zOnVzLWVhc3QtMToyMDA5ODQxMTIzODY6a2V5LzZkODJiMzRlLTM2NjAtNDRlMi04YWJiLTdmMzA1OGJlYTIxMgC4AQIBAHjxYXAO7wQGd+7qxoyvXAajwqboF5FL/9lgYUNJTB8VtAHBP2hwVgw+zypp7GoMNTPAAAAAfjB8BgkqhkiG9w0BBwagbzBtAgEAMGgGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMx/B25MTgWwpL7CmuAgEQgDtan3orAOKFUfyNm3v6rFcglb+BVVVDV71fj4aRljhpg1ixsYFaKsoej8NcwRktIiWE+mw9XmTEVb6xFQIAABAA9DeLzlRaRQgTcXMJG0iBu/YTyyDKiROD+bU1Y09X9RBz5LA1nWIENJKq2seAhNSB/////wAAAAEAAAAAAAAAAAAAAAEAAAEBExLJ9wI4n7t+wyPEEP4kjYFBdkmNuLLsVC2Yt8mv9Y1iH2G+/g9SaIcdK57pkoW0ECpBxZVOxCuhmK2s74AJCUdem9McjS1waUKyzYTi9vv2ySNBsABIDwT990rE7jZJ3tEZAqcWZg/eWlxvnksFR/akBWZKsKzFz6lF57+cTgdISCEJRV0E7fcUeCuaMaQGK1Qw2OCmIeHEG5j5iztBkZG2IB2CVND/AbxmDUFHwgjsrJPTzaDYSufcGMoZW1A9X1sLVfqNVKvnOFP5tNY7kPF5eAI9FhGBw8SjTqODXz4k6zuqzy9no8HtXowP265U8NZ5VbVTd/zuVEbZyK5KBqzP1sExW4RhnlpXMoOs9WSuAGcwZQIxANTeEwb9V7CacV2Urt/oCqysUzhoV2AcT2ZjryFqY79Tsg+FRpIx7cBizL4ieRzbhQIwcRasNncO5OZOcmVr0MqHv+gCVznndMgjXJmWwUa7h6skJKmhhMPlN0CsugxtVWnD\"\n}\n</code></pre> <pre><code>{\n    \"id\": 1,\n    \"name\": \"John Doe\",\n    \"age\": 30,\n    \"email\": \"johndoe@example.com\",\n    \"address\": {\n        \"street\": \"123 Main St\",\n        \"city\": \"Anytown\",\n        \"state\": \"CA\",\n        \"zip\": \"12345\"\n    },\n    \"company_address\": {\n        \"street\": \"456 ACME Ave\",\n        \"city\": \"Anytown\",\n        \"state\": \"CA\",\n        \"zip\": \"12345\"\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_masking/#encryption-context-for-integrity-and-authenticity",
            "title": "Encryption context for integrity and authenticity",
            "text": "<p>For a stronger security posture, you can add metadata to each encryption operation, and verify them during decryption. This is known as additional authenticated data (AAD). These are non-sensitive data that can help protect authenticity and integrity of your encrypted data, and even help to prevent a confused deputy situation.</p> Important considerations you should know <ol> <li>Exact match verification on decrypt. Be careful using random data like <code>timestamps</code> as encryption context if you can't provide them on decrypt.</li> <li>Only <code>string</code> values are supported. We will raise <code>DataMaskingUnsupportedTypeError</code> for non-string values.</li> <li>Use non-sensitive data only. When using KMS, encryption context is available as plaintext in AWS CloudTrail, unless you intentionally disabled KMS events.</li> </ol> getting_started_encryption_context.pygetting_started_decryption_context.py <pre><code>from __future__ import annotations\n\nimport os\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk import AWSEncryptionSDKProvider\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nKMS_KEY_ARN = os.getenv(\"KMS_KEY_ARN\", \"\")\n\nencryption_provider = AWSEncryptionSDKProvider(keys=[KMS_KEY_ARN])\ndata_masker = DataMasking(provider=encryption_provider)\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    data = event.get(\"body\", {})\n\n    logger.info(\"Encrypting whole object\")\n\n    encrypted: str = data_masker.encrypt(\n        data,\n        data_classification=\"confidential\",  # (1)!\n        data_type=\"customer-data\",\n        tenant_id=\"a06bf973-0734-4b53-9072-39d7ac5b2cba\",\n    )\n\n    return encrypted\n</code></pre> <ol> <li>They must match on <code>decrypt()</code> otherwise the operation will fail with <code>DataMaskingContextMismatchError</code>.</li> </ol> <pre><code>from __future__ import annotations\n\nimport os\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk import AWSEncryptionSDKProvider\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nKMS_KEY_ARN = os.getenv(\"KMS_KEY_ARN\", \"\")\n\nencryption_provider = AWSEncryptionSDKProvider(keys=[KMS_KEY_ARN])\ndata_masker = DataMasking(provider=encryption_provider)\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    data = event.get(\"body\", {})\n\n    logger.info(\"Decrypting whole object\")\n\n    decrypted: dict = data_masker.decrypt(\n        data,\n        data_classification=\"confidential\",  # (1)!\n        data_type=\"customer-data\",\n        tenant_id=\"a06bf973-0734-4b53-9072-39d7ac5b2cba\",\n    )\n\n    return decrypted\n</code></pre> <ol> <li>They must match otherwise the operation will fail with <code>DataMaskingContextMismatchError</code>.</li> </ol>"
        },
        {
            "location": "utilities/data_masking/#choosing-parts-of-your-data",
            "title": "Choosing parts of your data",
            "text": "Current limitations <ol> <li>The <code>fields</code> parameter is not yet supported in <code>encrypt</code> and <code>decrypt</code> operations.</li> <li>We support <code>JSON</code> data types only - see data serialization for more details.</li> </ol> <p>You can use the <code>fields</code> parameter with the dot notation <code>.</code> to choose one or more parts of your data to <code>erase</code>. This is useful when you want to keep data structure intact except the confidential fields.</p> <p>When <code>fields</code> is present, <code>erase</code> behaves differently:</p> Operation Behavior Example Result <code>erase</code> Replace data while keeping collections type intact. <code>{\"cards\": [\"a\", \"b\"]}</code> <code>{\"cards\": [\"*****\", \"*****\"]}</code> <p>Here are common scenarios to best visualize how to use <code>fields</code>.</p> Top keys onlyNested keyMultiple keysAll key itemsComplex nested keyAll fields in a listSlicing a listComplex expressions <p>You want to erase data in the <code>card_number</code> field.</p> DataResult <p>Expression: <code>data_masker.erase(data, fields=[\"card_number\"])</code></p> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\"\n}\n</code></pre> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"*****\"\n}\n</code></pre> <p>You want to erase data in the <code>postcode</code> field.</p> DataResult <p>Expression: <code>data_masker.erase(data, fields=[\"address.postcode\"])</code></p> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\",\n    \"address\": {\n        \"postcode\": 12345\n    }\n}\n</code></pre> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\",\n    \"address\": {\n        \"postcode\": \"*****\"\n    }\n}\n</code></pre> <p>You want to erase data in both <code>postcode</code> and <code>street</code> fields.</p> DataResult <p>Expression: <code>data_masker.erase(data, fields=[\"address.postcode\", \"address.street\"])</code></p> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\",\n    \"address\": {\n        \"postcode\": 12345,\n        \"street\": \"123 Any Street\"\n    }\n}\n</code></pre> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\",\n    \"address\": {\n        \"postcode\": \"*****\",\n        \"street\": \"*****\"\n    }\n}\n</code></pre> <p>You want to erase data under <code>address</code> field.</p> DataResult <p>Expression: <code>data_masker.erase(data, fields=[\"address\"])</code></p> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\",\n    \"address\": [\n        {\n            \"postcode\": 12345,\n            \"street\": \"123 Any Street\",\n            \"country\": \"United States\",\n            \"timezone\": \"America/La_Paz\"\n        },\n        {\n            \"postcode\": 67890,\n            \"street\": \"100 Main Street\",\n            \"country\": \"United States\",\n            \"timezone\": \"America/Mazatlan\"\n        }\n    ]\n}\n</code></pre> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\",\n    \"address\": [\n        \"*****\",\n        \"*****\"\n    ]\n}\n</code></pre> <p>You want to erase data under <code>name</code> field.</p> DataResult <p>Expression: <code>data_masker.erase(data, fields=[\"category..name\"])</code></p> <pre><code>{\n    \"category\": {\n        \"subcategory\": {\n            \"brand\" : {\n                \"product\": {\n                    \"name\": \"Car\"\n                }\n            }\n        }\n    }\n}\n</code></pre> <pre><code>{\n    \"category\": {\n        \"subcategory\": {\n            \"brand\" : {\n                \"product\": {\n                    \"name\": \"*****\"\n                }\n            }\n        }\n    }\n}\n</code></pre> <p>You want to erase data under <code>street</code> field located at the any index of the address list.</p> DataResult <p>Expression: <code>data_masker.erase(data, fields=[\"address[*].street\"])</code></p> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\",\n    \"address\": [\n        {\n            \"postcode\": 12345,\n            \"street\": \"123 Any Drive\"\n        },\n        {\n            \"postcode\": 67890,\n            \"street\": \"100 Main Street,\"\n        }\n    ]\n}\n</code></pre> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\",\n    \"address\": [\n        {\n            \"postcode\": 12345,\n            \"street\": \"*****\"\n        },\n        {\n            \"postcode\": 67890,\n            \"street\": \"*****\"\n        }\n    ]\n}\n</code></pre> <p>You want to erase data by slicing a list.</p> DataResult <p>Expression: <code>data_masker.erase(data, fields=[\"address[-1].street\"])</code></p> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\",\n    \"address\": [\n        {\n            \"postcode\": 12345,\n            \"street\": \"123 Any Street\"\n        },\n        {\n            \"postcode\": 67890,\n            \"street\": \"100 Main Street\"\n        },\n        {\n            \"postcode\": 78495,\n            \"street\": \"111 Any Drive\"\n        }\n    ]\n}\n</code></pre> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\",\n    \"address\": [\n        {\n            \"postcode\": 12345,\n            \"street\": \"123 Any Street\"\n        },\n        {\n            \"postcode\": 67890,\n            \"street\": \"100 Main Street\"\n        },\n        {\n            \"postcode\": 11111,\n            \"street\": \"*****\"\n        }\n    ]\n}\n</code></pre> <p>You want to erase data by finding for a field with conditional expression.</p> DataResult <p>Expression: <code>data_masker.erase(data, fields=[\"$.address[?(@.postcode &gt; 12000)]\"])</code></p> <p><code>$</code>: Represents the root of the JSON structure.</p> <p><code>.address</code>: Selects the \"address\" property within the JSON structure.</p> <p><code>(@.postcode &gt; 12000)</code>: Specifies the condition that elements should meet. It selects elements where the value of the <code>postcode</code> property is <code>greater than 12000</code>.</p> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\",\n    \"address\": [\n        {\n            \"postcode\": 12345,\n            \"street\": \"123 Any Drive\"\n        },\n        {\n            \"postcode\": 67890,\n            \"street\": \"111 Main Street\"\n        },\n        {\n            \"postcode\": 11111,\n            \"street\": \"100 Any Street\"\n        }\n    ]\n}\n</code></pre> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"1111 2222 3333 4444\",\n    \"address\": [\n        {\n            \"postcode\": 12345,\n            \"street\": \"*****\"\n        },\n        {\n            \"postcode\": 67890,\n            \"street\": \"*****\"\n        },\n        {\n            \"postcode\": 11111,\n            \"street\": \"100 Any Street\"\n        }\n    ]\n}\n</code></pre> <p>For comprehensive guidance on using JSONPath syntax, please refer to the official documentation available at jsonpath-ng</p>"
        },
        {
            "location": "utilities/data_masking/#json",
            "title": "JSON",
            "text": "<p>We also support data in JSON string format as input. We automatically deserialize it, then handle each field operation as expected.</p> <p>Note that the return will be a deserialized JSON and your desired fields updated.</p> DataResult <p>Expression: <code>data_masker.erase(data, fields=[\"card_number\", \"address.postcode\"])</code></p> <pre><code>'{\"name\": \"Carlos\", \"operation\": \"non sensitive\", \"card_number\": \"1111 2222 3333 4444\", \"address\": {\"postcode\": 12345}}'\n</code></pre> <pre><code>{\n    \"name\": \"Carlos\",\n    \"operation\": \"non sensitive\",\n    \"card_number\": \"*****\",\n    \"address\": {\n        \"postcode\": \"*****\"\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/data_masking/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/data_masking/#data-serialization",
            "title": "Data serialization",
            "text": "Current limitations <ol> <li>Python classes, <code>Dataclasses</code>, and <code>Pydantic models</code> are not supported yet.</li> </ol> <p>Before we traverse the data structure, we perform two important operations on input data:</p> <ol> <li>If <code>JSON string</code>, deserialize using default or provided deserializer.</li> <li>If <code>dictionary</code>, normalize into <code>JSON</code> to prevent traversing unsupported data types.</li> </ol> <p>When decrypting, we revert the operation to restore the original data structure.</p> <p>For compatibility or performance, you can optionally pass your own JSON serializer and deserializer to replace <code>json.dumps</code> and <code>json.loads</code> respectively:</p> advanced_custom_serializer.py<pre><code>from __future__ import annotations\n\nimport os\n\nimport ujson\n\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk import (\n    AWSEncryptionSDKProvider,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nKMS_KEY_ARN = os.getenv(\"KMS_KEY_ARN\", \"\")\n\nencryption_provider = AWSEncryptionSDKProvider(\n    keys=[KMS_KEY_ARN],\n    json_serializer=ujson.dumps,\n    json_deserializer=ujson.loads,\n)\ndata_masker = DataMasking(provider=encryption_provider)\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    data: dict = event.get(\"body\", {})\n\n    return data_masker.encrypt(data)\n</code></pre>"
        },
        {
            "location": "utilities/data_masking/#using-multiple-keys",
            "title": "Using multiple keys",
            "text": "<p>You can use multiple KMS keys from more than one AWS account for higher availability, when instantiating <code>AWSEncryptionSDKProvider</code>.</p> using_multiple_keys.py<pre><code>from __future__ import annotations\n\nimport os\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk import (\n    AWSEncryptionSDKProvider,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nKMS_KEY_ARN_1 = os.getenv(\"KMS_KEY_ARN_1\", \"\")\nKMS_KEY_ARN_2 = os.getenv(\"KMS_KEY_ARN_2\", \"\")\n\nencryption_provider = AWSEncryptionSDKProvider(keys=[KMS_KEY_ARN_1, KMS_KEY_ARN_2])\ndata_masker = DataMasking(provider=encryption_provider)\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    data: dict = event.get(\"body\", {})\n\n    logger.info(\"Encrypting the whole object\")\n\n    encrypted = data_masker.encrypt(data)\n\n    return {\"body\": encrypted}\n</code></pre>"
        },
        {
            "location": "utilities/data_masking/#providers",
            "title": "Providers",
            "text": ""
        },
        {
            "location": "utilities/data_masking/#aws-encryption-sdk",
            "title": "AWS Encryption SDK",
            "text": "<p>You can modify the following values when initializing the <code>AWSEncryptionSDKProvider</code> to best accommodate your security and performance thresholds.</p> Parameter Default Description local_cache_capacity <code>100</code> The maximum number of entries that can be retained in the local cryptographic materials cache max_cache_age_seconds <code>300</code> The maximum time (in seconds) that a cache entry may be kept in the cache max_messages_encrypted <code>4294967296</code> The maximum number of messages that may be encrypted under a cache entry max_bytes_encrypted <code>9223372036854775807</code> The maximum number of bytes that may be encrypted under a cache entry <p>If required, you can customize the default values when initializing the <code>AWSEncryptionSDKProvider</code> class.</p> aws_encryption_provider_example.py<pre><code>from __future__ import annotations\n\nimport os\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk import (\n    AWSEncryptionSDKProvider,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nKMS_KEY_ARN = os.getenv(\"KMS_KEY_ARN\", \"\")\n\nencryption_provider = AWSEncryptionSDKProvider(\n    keys=[KMS_KEY_ARN],\n    local_cache_capacity=200,\n    max_cache_age_seconds=400,\n    max_messages_encrypted=200,\n    max_bytes_encrypted=2000)\n\ndata_masker = DataMasking(provider=encryption_provider)\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    data: dict = event.get(\"body\", {})\n\n    logger.info(\"Encrypting the whole object\")\n\n    encrypted = data_masker.encrypt(data)\n\n    return {\"body\": encrypted}\n</code></pre>"
        },
        {
            "location": "utilities/data_masking/#passing-additional-sdk-arguments",
            "title": "Passing additional SDK arguments",
            "text": "<p>See the AWS Encryption SDK docs for more details</p> <p>As an escape hatch mechanism, you can pass additional arguments to the <code>AWSEncryptionSDKProvider</code> via the <code>provider_options</code> parameter.</p> <p>For example, the AWS Encryption SDK defaults to using the <code>AES_256_GCM_HKDF_SHA512_COMMIT_KEY_ECDSA_P384</code> algorithm for encrypting your Data Key. If you want, you have the flexibility to customize and choose a different encryption algorithm.</p> changing_default_algorithm.py<pre><code>from __future__ import annotations\n\nimport os\n\nfrom aws_encryption_sdk.identifiers import Algorithm\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.data_masking.provider.kms.aws_encryption_sdk import AWSEncryptionSDKProvider\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nKMS_KEY_ARN = os.getenv(\"KMS_KEY_ARN\", \"\")\n\nencryption_provider = AWSEncryptionSDKProvider(keys=[KMS_KEY_ARN])\ndata_masker = DataMasking(provider=encryption_provider)\n\nlogger = Logger()\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; str:\n    data: dict = event.get(\"body\", {})\n\n    logger.info(\"Encrypting whole object with a different algorithm\")\n\n    provider_options = {\"algorithm\": Algorithm.AES_256_GCM_HKDF_SHA512_COMMIT_KEY}\n\n    encrypted = data_masker.encrypt(\n        data,\n        provider_options=provider_options,\n    )\n\n    return encrypted\n</code></pre>"
        },
        {
            "location": "utilities/data_masking/#data-masking-request-flow",
            "title": "Data masking request flow",
            "text": "<p>The following sequence diagrams explain how <code>DataMasking</code> behaves under different scenarios.</p>"
        },
        {
            "location": "utilities/data_masking/#erase-operation",
            "title": "Erase operation",
            "text": "<p>Erasing operations occur in-memory and we cannot recover the original value.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Lambda\n    participant DataMasking as Data Masking (in memory)\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;DataMasking: erase(data)\n    DataMasking-&gt;&gt;DataMasking: replaces data with *****\n    Note over Lambda,DataMasking: No encryption providers involved.\n    DataMasking-&gt;&gt;Lambda: data masked\n    Lambda--&gt;&gt;Client: Return response</code></pre> Simple masking operation </p>"
        },
        {
            "location": "utilities/data_masking/#encrypt-operation-with-encryption-sdk-kms",
            "title": "Encrypt operation with Encryption SDK (KMS)",
            "text": "<p>We call KMS to generate an unique data key that can be used for multiple <code>encrypt</code> operation in-memory. It improves performance, cost and prevent throttling.</p> <p>To make this operation simpler to visualize, we keep caching details in a separate sequence diagram. Caching is enabled by default.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Lambda\n    participant DataMasking as Data Masking\n    participant EncryptionProvider as Encryption Provider\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;DataMasking: Init Encryption Provider with master key\n    Note over Lambda,DataMasking: AWSEncryptionSDKProvider([KMS_KEY])\n    Lambda-&gt;&gt;DataMasking: encrypt(data)\n    DataMasking-&gt;&gt;EncryptionProvider: Create unique data key\n    Note over DataMasking,EncryptionProvider: KMS GenerateDataKey API\n    DataMasking-&gt;&gt;DataMasking: Cache new unique data key\n    DataMasking-&gt;&gt;DataMasking: DATA_KEY.encrypt(data)\n    DataMasking-&gt;&gt;DataMasking: MASTER_KEY.encrypt(DATA_KEY)\n    DataMasking-&gt;&gt;DataMasking: Create encrypted message\n    Note over DataMasking: Encrypted message includes encrypted data, data key encrypted, algorithm, and more.\n    DataMasking-&gt;&gt;Lambda: Ciphertext from encrypted message\n    Lambda--&gt;&gt;Client: Return response</code></pre> Encrypting operation using envelope encryption. </p>"
        },
        {
            "location": "utilities/data_masking/#encrypt-operation-with-multiple-kms-keys",
            "title": "Encrypt operation with multiple KMS Keys",
            "text": "<p>When encrypting data with multiple KMS keys, the <code>aws_encryption_sdk</code> makes additional API calls to encrypt the data with each of the specified keys.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Lambda\n    participant DataMasking as Data Masking\n    participant EncryptionProvider as Encryption Provider\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;DataMasking: Init Encryption Provider with master key\n    Note over Lambda,DataMasking: AWSEncryptionSDKProvider([KEY_1, KEY_2])\n    Lambda-&gt;&gt;DataMasking: encrypt(data)\n    DataMasking-&gt;&gt;EncryptionProvider: Create unique data key\n    Note over DataMasking,EncryptionProvider: KMS GenerateDataKey API - KEY_1\n    DataMasking-&gt;&gt;DataMasking: Cache new unique data key\n    DataMasking-&gt;&gt;DataMasking: DATA_KEY.encrypt(data)\n    DataMasking-&gt;&gt;DataMasking: KEY_1.encrypt(DATA_KEY)\n    loop For every additional KMS Key\n        DataMasking-&gt;&gt;EncryptionProvider: Encrypt DATA_KEY\n        Note over DataMasking,EncryptionProvider: KMS Encrypt API - KEY_2\n    end\n    DataMasking-&gt;&gt;DataMasking: Create encrypted message\n    Note over DataMasking: Encrypted message includes encrypted data, all data keys encrypted, algorithm, and more.\n    DataMasking-&gt;&gt;Lambda: Ciphertext from encrypted message\n    Lambda--&gt;&gt;Client: Return response</code></pre> Encrypting operation using envelope encryption. </p>"
        },
        {
            "location": "utilities/data_masking/#decrypt-operation-with-encryption-sdk-kms",
            "title": "Decrypt operation with Encryption SDK (KMS)",
            "text": "<p>We call KMS to decrypt the encrypted data key available in the encrypted message. If successful, we run authentication (context) and integrity checks (algorithm, data key length, etc) to confirm its proceedings.</p> <p>Lastly, we decrypt the original encrypted data, throw away the decrypted data key for security reasons, and return the original plaintext data.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Lambda\n    participant DataMasking as Data Masking\n    participant EncryptionProvider as Encryption Provider\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;DataMasking: Init Encryption Provider with master key\n    Note over Lambda,DataMasking: AWSEncryptionSDKProvider([KMS_KEY])\n    Lambda-&gt;&gt;DataMasking: decrypt(data)\n    DataMasking-&gt;&gt;EncryptionProvider: Decrypt encrypted data key\n    Note over DataMasking,EncryptionProvider: KMS Decrypt API\n    DataMasking-&gt;&gt;DataMasking: Authentication and integrity checks\n    DataMasking-&gt;&gt;DataMasking: DATA_KEY.decrypt(data)\n    DataMasking-&gt;&gt;DataMasking: MASTER_KEY.encrypt(DATA_KEY)\n    DataMasking-&gt;&gt;DataMasking: Discards decrypted data key\n    DataMasking-&gt;&gt;Lambda: Plaintext\n    Lambda--&gt;&gt;Client: Return response</code></pre> Decrypting operation using envelope encryption. </p>"
        },
        {
            "location": "utilities/data_masking/#caching-encrypt-operations-with-encryption-sdk",
            "title": "Caching encrypt operations with Encryption SDK",
            "text": "<p>Without caching, every <code>encrypt()</code> operation would generate a new data key. It significantly increases latency and cost for ephemeral and short running environments like Lambda.</p> <p>With caching, we balance ephemeral Lambda environment performance characteristics with adjustable thresholds to meet your security needs.</p> <p>Data key recycling</p> <p>We request a new data key when a cached data key exceeds any of the following security thresholds:</p> <ol> <li>Max age in seconds</li> <li>Max number of encrypted messages</li> <li>Max bytes encrypted across all operations</li> </ol> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Lambda\n    participant DataMasking as Data Masking\n    participant EncryptionProvider as Encryption Provider\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;DataMasking: Init Encryption Provider with master key\n    Note over Lambda,DataMasking: AWSEncryptionSDKProvider([KMS_KEY])\n    Lambda-&gt;&gt;DataMasking: encrypt(data)\n    DataMasking-&gt;&gt;EncryptionProvider: Create unique data key\n    Note over DataMasking,EncryptionProvider: KMS GenerateDataKey API\n    DataMasking-&gt;&gt;DataMasking: Cache new unique data key\n    DataMasking-&gt;&gt;DataMasking: DATA_KEY.encrypt(data)\n    DataMasking-&gt;&gt;DataMasking: MASTER_KEY.encrypt(DATA_KEY)\n    DataMasking-&gt;&gt;DataMasking: Create encrypted message\n    Note over DataMasking: Encrypted message includes encrypted data, data key encrypted, algorithm, and more.\n    DataMasking-&gt;&gt;Lambda: Ciphertext from encrypted message\n    Lambda-&gt;&gt;DataMasking: encrypt(another_data)\n    DataMasking-&gt;&gt;DataMasking: Searches for data key in cache\n    alt Is Data key in cache?\n        DataMasking-&gt;&gt;DataMasking: Reuses data key\n    else Is Data key evicted from cache?\n        DataMasking-&gt;&gt;EncryptionProvider: Create unique data key\n        DataMasking-&gt;&gt;DataMasking: MASTER_KEY.encrypt(DATA_KEY)\n    end\n    DataMasking-&gt;&gt;DataMasking: DATA_KEY.encrypt(data)\n    DataMasking-&gt;&gt;DataMasking: Create encrypted message\n    DataMasking-&gt;&gt;Lambda: Ciphertext from encrypted message\n    Lambda--&gt;&gt;Client: Return response</code></pre> Caching data keys during encrypt operation. </p>"
        },
        {
            "location": "utilities/data_masking/#testing-your-code",
            "title": "Testing your code",
            "text": ""
        },
        {
            "location": "utilities/data_masking/#testing-erase-operation",
            "title": "Testing erase operation",
            "text": "<p>Testing your code with a simple erase operation</p> test_lambda_mask.py <pre><code>from dataclasses import dataclass\n\nimport pytest\nimport test_lambda_mask\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:111111111:function:test\"\n    aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n    def get_remaining_time_in_millis(self) -&gt; int:\n        return 5\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef test_encrypt_lambda(lambda_context):\n    # GIVEN: A sample event for testing\n    event = {\"testkey\": \"testvalue\"}\n\n    # WHEN: Invoking the lambda_handler function with the sample event and Lambda context\n    result = test_lambda_mask.lambda_handler(event, lambda_context)\n\n    # THEN: Assert that the result matches the expected output\n    assert result == {\"testkey\": \"*****\"}\n</code></pre> lambda_mask.py <pre><code>from __future__ import annotations\n\nfrom aws_lambda_powertools.utilities.data_masking import DataMasking\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ndata_masker = DataMasking()\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    data = event\n\n    erased = data_masker.erase(data, fields=[\"testkey\"])\n\n    return erased\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/",
            "title": "Feature flags",
            "text": "<p>The feature flags utility provides a simple rule engine to define when one or multiple features should be enabled depending on the input.</p> Info <p>When using <code>AppConfigStore</code>, we currently only support AppConfig using freeform configuration profile  .</p>"
        },
        {
            "location": "utilities/feature_flags/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Define simple feature flags to dynamically decide when to enable a feature</li> <li>Fetch one or all feature flags enabled for a given application context</li> <li>Support for static feature flags to simply turn on/off a feature without rules</li> <li>Support for time based feature flags</li> <li>Bring your own Feature Flags Store Provider</li> </ul>"
        },
        {
            "location": "utilities/feature_flags/#terminology",
            "title": "Terminology",
            "text": "<p>Feature flags are used to modify behaviour without changing the application's code. These flags can be static or dynamic.</p> <p>Static flags. Indicates something is simply <code>on</code> or <code>off</code>, for example <code>TRACER_ENABLED=True</code>.</p> <p>Dynamic flags. Indicates something can have varying states, for example enable a list of premium features for customer X not Y.</p> Tip <p>You can use Parameters utility for static flags while this utility can do both static and dynamic feature flags.</p> Warning <p>Be mindful that feature flags can increase the complexity of your application over time; use them sparingly.</p> <p>If you want to learn more about feature flags, their variations and trade-offs, check these articles:</p> <ul> <li>Feature Toggles (aka Feature Flags) - Pete Hodgson</li> <li>AWS Lambda Feature Toggles Made Simple - Ran Isenberg</li> <li>Feature Flags Getting Started - CloudBees</li> </ul> Note <p>AWS AppConfig requires two API calls to fetch configuration for the first time. You can improve latency by consolidating your feature settings in a single Configuration.</p>"
        },
        {
            "location": "utilities/feature_flags/#getting-started",
            "title": "Getting started",
            "text": ""
        },
        {
            "location": "utilities/feature_flags/#iam-permissions",
            "title": "IAM Permissions",
            "text": "<p>When using the default store <code>AppConfigStore</code>, your Lambda function IAM Role must have <code>appconfig:GetLatestConfiguration</code> and <code>appconfig:StartConfigurationSession</code> IAM permissions before using this feature.</p>"
        },
        {
            "location": "utilities/feature_flags/#required-resources",
            "title": "Required resources",
            "text": "<p>By default, this utility provides AWS AppConfig as a configuration store.</p> <p>The following sample infrastructure will be used throughout this documentation:</p> template.yamlCDK <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nDescription: Lambda Powertools for Python Feature flags sample template\nResources:\n  FeatureStoreApp:\n    Type: AWS::AppConfig::Application\n    Properties:\n      Description: \"AppConfig Application for feature toggles\"\n      Name: product-catalogue\n\n  FeatureStoreDevEnv:\n    Type: AWS::AppConfig::Environment\n    Properties:\n      ApplicationId: !Ref FeatureStoreApp\n      Description: \"Development Environment for the App Config Store\"\n      Name: dev\n\n  FeatureStoreConfigProfile:\n    Type: AWS::AppConfig::ConfigurationProfile\n    Properties:\n      ApplicationId: !Ref FeatureStoreApp\n      Name: features\n      LocationUri: \"hosted\"\n\n  HostedConfigVersion:\n    Type: AWS::AppConfig::HostedConfigurationVersion\n    Properties:\n      ApplicationId: !Ref FeatureStoreApp\n      ConfigurationProfileId: !Ref FeatureStoreConfigProfile\n      Description: 'A sample hosted configuration version'\n      Content: |\n        {\n              \"premium_features\": {\n                \"default\": false,\n                \"rules\": {\n                  \"customer tier equals premium\": {\n                    \"when_match\": true,\n                    \"conditions\": [\n                      {\n                        \"action\": \"EQUALS\",\n                        \"key\": \"tier\",\n                        \"value\": \"premium\"\n                      }\n                    ]\n                  }\n                }\n              },\n              \"ten_percent_off_campaign\": {\n                \"default\": false\n              }\n          }\n      ContentType: 'application/json'\n\n  ConfigDeployment:\n    Type: AWS::AppConfig::Deployment\n    Properties:\n      ApplicationId: !Ref FeatureStoreApp\n      ConfigurationProfileId: !Ref FeatureStoreConfigProfile\n      ConfigurationVersion: !Ref HostedConfigVersion\n      DeploymentStrategyId: \"AppConfig.AllAtOnce\"\n      EnvironmentId: !Ref FeatureStoreDevEnv\n</code></pre> <pre><code>import json\n\nimport aws_cdk.aws_appconfig as appconfig\nfrom aws_cdk import core\n\n\nclass SampleFeatureFlagStore(core.Construct):\n    def __init__(self, scope: core.Construct, id_: str) -&gt; None:\n        super().__init__(scope, id_)\n\n        features_config = {\n            \"premium_features\": {\n                \"default\": False,\n                \"rules\": {\n                    \"customer tier equals premium\": {\n                        \"when_match\": True,\n                        \"conditions\": [{\"action\": \"EQUALS\", \"key\": \"tier\", \"value\": \"premium\"}],\n                    }\n                },\n            },\n            \"ten_percent_off_campaign\": {\"default\": True},\n        }\n\n        self.config_app = appconfig.CfnApplication(\n            self,\n            id=\"app\",\n            name=\"product-catalogue\",\n        )\n        self.config_env = appconfig.CfnEnvironment(\n            self,\n            id=\"env\",\n            application_id=self.config_app.ref,\n            name=\"dev-env\",\n        )\n        self.config_profile = appconfig.CfnConfigurationProfile(\n            self,\n            id=\"profile\",\n            application_id=self.config_app.ref,\n            location_uri=\"hosted\",\n            name=\"features\",\n        )\n        self.hosted_cfg_version = appconfig.CfnHostedConfigurationVersion(\n            self,\n            \"version\",\n            application_id=self.config_app.ref,\n            configuration_profile_id=self.config_profile.ref,\n            content=json.dumps(features_config),\n            content_type=\"application/json\",\n        )\n        self.app_config_deployment = appconfig.CfnDeployment(\n            self,\n            id=\"deploy\",\n            application_id=self.config_app.ref,\n            configuration_profile_id=self.config_profile.ref,\n            configuration_version=self.hosted_cfg_version.ref,\n            deployment_strategy_id=\"AppConfig.AllAtOnce\",\n            environment_id=self.config_env.ref,\n        )\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#evaluating-a-single-feature-flag",
            "title": "Evaluating a single feature flag",
            "text": "<p>To get started, you'd need to initialize <code>AppConfigStore</code> and <code>FeatureFlags</code>. Then call <code>FeatureFlags</code> <code>evaluate</code> method to fetch, validate, and evaluate your feature.</p> <p>The <code>evaluate</code> method supports two optional parameters:</p> <ul> <li>context: Value to be evaluated against each rule defined for the given feature</li> <li>default: Sentinel value to use in case we experience any issues with our store, or feature doesn't exist</li> </ul> getting_started_single_feature_flag.pygetting_started_single_feature_flag_payload.jsongetting_started_single_feature_flag_features.json <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    \"\"\"\n    This feature flag is enabled under the following conditions:\n    - The request payload contains a field 'tier' with the value 'premium'.\n\n    Rule condition to be evaluated:\n        \"conditions\": [\n            {\n                \"action\": \"EQUALS\",\n                \"key\": \"tier\",\n                \"value\": \"premium\"\n            }\n        ]\n    \"\"\"\n\n    # Get customer's tier from incoming request\n    ctx = {\"tier\": event.get(\"tier\", \"standard\")}\n\n    # Evaluate whether customer's tier has access to premium features\n    # based on `has_premium_features` rules\n    has_premium_features: Any = feature_flags.evaluate(name=\"premium_features\", context=ctx, default=False)\n    if has_premium_features:\n        # enable premium features\n        ...\n</code></pre> <pre><code>{\n    \"username\": \"lessa\",\n    \"tier\": \"premium\",\n    \"basked_id\": \"random_id\"\n}\n</code></pre> <pre><code>{\n    \"premium_features\": {\n        \"default\": false,\n        \"rules\": {\n            \"customer tier equals premium\": {\n                \"when_match\": true,\n                \"conditions\": [\n                    {\n                        \"action\": \"EQUALS\",\n                        \"key\": \"tier\",\n                        \"value\": \"premium\"\n                    }\n                ]\n            }\n        }\n    },\n    \"ten_percent_off_campaign\": {\n        \"default\": false\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#static-flags",
            "title": "Static flags",
            "text": "<p>We have a static flag named <code>ten_percent_off_campaign</code>. Meaning, there are no conditional rules, it's either ON or OFF for all customers.</p> <p>In this case, we could omit the <code>context</code> parameter and simply evaluate whether we should apply the 10% discount.</p> getting_started_static_flag.pygetting_started_static_flag_payload.jsongetting_started_static_flag_features.json <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    \"\"\"\n    This feature flag is enabled by default for all requests.\n    \"\"\"\n\n    apply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\n\n    price: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre> <pre><code>{\n    \"product\": \"laptop\",\n    \"price\": 1000\n}\n</code></pre> <pre><code>{\n    \"ten_percent_off_campaign\": {\n        \"default\": true\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#getting-all-enabled-features",
            "title": "Getting all enabled features",
            "text": "<p>As you might have noticed, each <code>evaluate</code> call means an API call to the Store and the more features you have the more costly this becomes.</p> <p>You can use <code>get_enabled_features</code> method for scenarios where you need a list of all enabled features according to the input context.</p> getting_all_enabled_features.pygetting_all_enabled_features_payload.jsongetting_all_enabled_features_features.json <pre><code>from __future__ import annotations\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver()\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\n@app.get(\"/products\")\ndef list_products():\n    # getting fields from request\n    # https://docs.powertools.aws.dev/lambda/python/latest/core/event_handler/api_gateway/#accessing-request-details\n    json_body = app.current_event.json_body\n    headers = app.current_event.headers\n\n    ctx = {**headers, **json_body}\n\n    # getting price from payload\n    price: float = float(json_body.get(\"price\"))\n    percent_discount: int = 0\n\n    # all_features is evaluated to [\"premium_features\", \"geo_customer_campaign\", \"ten_percent_off_campaign\"]\n    all_features: list[str] = feature_flags.get_enabled_features(context=ctx)\n\n    if \"geo_customer_campaign\" in all_features:\n        # apply 20% discounts for customers in NL\n        percent_discount += 20\n\n    if \"ten_percent_off_campaign\" in all_features:\n        # apply additional 10% for all customers\n        percent_discount += 10\n\n    price = price * (100 - percent_discount) / 100\n\n    return {\"price\": price}\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"body\": \"{\\\"username\\\": \\\"lessa\\\", \\\"tier\\\": \\\"premium\\\", \\\"basked_id\\\": \\\"random_id\\\", \\\"price\\\": 1000}\",\n    \"resource\": \"/products\",\n    \"path\": \"/products\",\n    \"httpMethod\": \"GET\",\n    \"isBase64Encoded\": false,\n    \"headers\": {\n        \"CloudFront-Viewer-Country\": \"NL\"\n    }\n}\n</code></pre> <pre><code>{\n    \"premium_features\": {\n      \"default\": false,\n      \"rules\": {\n        \"customer tier equals premium\": {\n          \"when_match\": true,\n          \"conditions\": [\n            {\n              \"action\": \"EQUALS\",\n              \"key\": \"tier\",\n              \"value\": \"premium\"\n            }\n          ]\n        }\n      }\n    },\n    \"ten_percent_off_campaign\": {\n      \"default\": true\n    },\n    \"geo_customer_campaign\": {\n      \"default\": false,\n      \"rules\": {\n        \"customer in temporary discount geo\": {\n          \"when_match\": true,\n          \"conditions\": [\n            {\n              \"action\": \"KEY_IN_VALUE\",\n              \"key\": \"CloudFront-Viewer-Country\",\n              \"value\": [\n                \"NL\",\n                \"IE\",\n                \"UK\",\n                \"PL\",\n                \"PT\"\n              ]\n            }\n          ]\n        }\n      }\n    }\n  }\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#time-based-feature-flags",
            "title": "Time based feature flags",
            "text": "<p>Feature flags can also return enabled features based on time or datetime ranges. This allows you to have features that are only enabled on certain days of the week, certain time intervals or between certain calendar dates.</p> <p>Use cases:</p> <ul> <li>Enable maintenance mode during a weekend</li> <li>Disable support/chat feature after working hours</li> <li>Launch a new feature on a specific date and time</li> </ul> <p>You can also have features enabled only at certain times of the day for premium tier customers</p> timebased_feature.pytimebased_feature_event.jsontimebased_features.json <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    \"\"\"\n    This feature flag is enabled under the following conditions:\n    - The request payload contains a field 'tier' with the value 'premium'.\n    - If the current day is either Saturday or Sunday in America/New_York timezone.\n\n    Rule condition to be evaluated:\n        \"conditions\": [\n          {\n            \"action\": \"EQUALS\",\n            \"key\": \"tier\",\n            \"value\": \"premium\"\n          },\n          {\n            \"action\": \"SCHEDULE_BETWEEN_DAYS_OF_WEEK\",\n            \"key\": \"CURRENT_DAY_OF_WEEK\",\n            \"value\": {\n              \"DAYS\": [\n                \"SATURDAY\",\n                \"SUNDAY\"\n              ],\n              \"TIMEZONE\": \"America/New_York\"\n            }\n          }\n        ]\n    \"\"\"\n\n    # Get customer's tier from incoming request\n    ctx = {\"tier\": event.get(\"tier\", \"standard\")}\n\n    # Checking if the weekend premum discount is enable\n    weekend_premium_discount = feature_flags.evaluate(name=\"weekend_premium_discount\", default=False, context=ctx)\n\n    if weekend_premium_discount:\n        # Enable special discount on weekend for premium users:\n        return {\"message\": \"The weekend premium discount is enabled.\"}\n\n    return {\"message\": \"The weekend premium discount is not enabled.\"}\n</code></pre> <pre><code>{\n  \"username\": \"rubefons\",\n  \"tier\": \"premium\",\n  \"basked_id\": \"random_id\"\n}\n</code></pre> <pre><code>{\n  \"weekend_premium_discount\": {\n    \"default\": false,\n    \"rules\": {\n      \"customer tier equals premium and its time for a discount\": {\n        \"when_match\": true,\n        \"conditions\": [\n          {\n            \"action\": \"EQUALS\",\n            \"key\": \"tier\",\n            \"value\": \"premium\"\n          },\n          {\n            \"action\": \"SCHEDULE_BETWEEN_DAYS_OF_WEEK\",\n            \"key\": \"CURRENT_DAY_OF_WEEK\",\n            \"value\": {\n              \"DAYS\": [\n                \"SATURDAY\",\n                \"SUNDAY\"\n              ],\n              \"TIMEZONE\": \"America/New_York\"\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n</code></pre> <p>You can also have features enabled only at certain times of the day.</p> timebased_happyhour_feature.pytimebased_happyhour_features.json <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    \"\"\"\n    This feature flag is enabled under the following conditions:\n    - Every day between 17:00 to 19:00 in Europe/Copenhagen timezone\n\n    Rule condition to be evaluated:\n        \"conditions\": [\n          {\n            \"action\": \"SCHEDULE_BETWEEN_TIME_RANGE\",\n            \"key\": \"CURRENT_TIME\",\n            \"value\": {\n              \"START\": \"17:00\",\n              \"END\": \"19:00\",\n              \"TIMEZONE\": \"Europe/Copenhagen\"\n            }\n          }\n        ]\n    \"\"\"\n\n    # Checking if the happy hour discount is enable\n    is_happy_hour = feature_flags.evaluate(name=\"happy_hour\", default=False)\n\n    if is_happy_hour:\n        # Enable special discount on happy hour:\n        return {\"message\": \"The happy hour discount is enabled.\"}\n\n    return {\"message\": \"The happy hour discount is not enabled.\"}\n</code></pre> <pre><code>{\n  \"happy_hour\": {\n    \"default\": false,\n    \"rules\": {\n      \"is happy hour\": {\n        \"when_match\": true,\n        \"conditions\": [\n          {\n            \"action\": \"SCHEDULE_BETWEEN_TIME_RANGE\",\n            \"key\": \"CURRENT_TIME\",\n            \"value\": {\n              \"START\": \"17:00\",\n              \"END\": \"19:00\",\n              \"TIMEZONE\": \"Europe/Copenhagen\"\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n</code></pre> <p>You can also have features enabled only at specific days, for example: enable christmas sale discount during specific dates.</p> datetime_feature.pydatetime_features.json <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    \"\"\"\n    This feature flag is enabled under the following conditions:\n    - Start date: December 25th, 2022 at 12:00:00 PM EST\n    - End date: December 31st, 2022 at 11:59:59 PM EST\n    - Timezone: America/New_York\n\n    Rule condition to be evaluated:\n        \"conditions\": [\n          {\n            \"action\": \"SCHEDULE_BETWEEN_DATETIME_RANGE\",\n            \"key\": \"CURRENT_DATETIME\",\n            \"value\": {\n              \"START\": \"2022-12-25T12:00:00\",\n              \"END\": \"2022-12-31T23:59:59\",\n              \"TIMEZONE\": \"America/New_York\"\n            }\n          }\n        ]\n    \"\"\"\n\n    # Checking if the Christmas discount is enable\n    xmas_discount = feature_flags.evaluate(name=\"christmas_discount\", default=False)\n\n    if xmas_discount:\n        # Enable special discount on christmas:\n        return {\"message\": \"The Christmas discount is enabled.\"}\n\n    return {\"message\": \"The Christmas discount is not enabled.\"}\n</code></pre> <pre><code>{\n  \"christmas_discount\": {\n    \"default\": false,\n    \"rules\": {\n      \"enable discount during christmas\": {\n        \"when_match\": true,\n        \"conditions\": [\n          {\n            \"action\": \"SCHEDULE_BETWEEN_DATETIME_RANGE\",\n            \"key\": \"CURRENT_DATETIME\",\n            \"value\": {\n              \"START\": \"2022-12-25T12:00:00\",\n              \"END\": \"2022-12-31T23:59:59\",\n              \"TIMEZONE\": \"America/New_York\"\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n</code></pre> How should I use timezones? <p>You can use any IANA time zone (as originally specified in PEP 615) as part of your rules definition. Powertools for AWS Lambda (Python) takes care of converting and calculate the correct timestamps for you.</p> <p>When using <code>SCHEDULE_BETWEEN_DATETIME_RANGE</code>, use timestamps without timezone information, and specify the timezone manually. This way, you'll avoid hitting problems with day light savings.</p>"
        },
        {
            "location": "utilities/feature_flags/#modulo-range-segmented-experimentation",
            "title": "Modulo Range Segmented Experimentation",
            "text": "<p>Feature flags can also be used to run experiments on a segment of users based on modulo range conditions on context variables. This allows you to have features that are only enabled for a certain segment of users, comparing across multiple variants of the same experiment.</p> <p>Use cases:</p> <ul> <li>Enable an experiment for a percentage of users</li> <li>Scale up an experiment incrementally in production - canary release</li> <li>Run multiple experiments or variants simultaneously by assigning a spectrum segment to each experiment variant.</li> </ul> <p>The modulo range condition takes three values - <code>BASE</code>, <code>START</code> and <code>END</code>.</p> <p>The condition evaluates <code>START &lt;= CONTEXT_VALUE % BASE &lt;= END</code>.</p> modulo_range_feature.pymodulo_range_feature_event.jsonmodulo_range_features.json <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    \"\"\"\n    This feature flag is enabled under the following conditions:\n    - The request payload contains a field 'tier' with the value 'standard'.\n    - If the user_id belongs to the spectrum 0-19 modulo 100, (20% users) on whom we want to run the sale experiment.\n\n    Rule condition to be evaluated:\n        \"conditions\": [\n          {\n            \"action\": \"EQUALS\",\n            \"key\": \"tier\",\n            \"value\": \"standard\"\n          },\n          {\n            \"action\": \"MODULO_RANGE\",\n            \"key\": \"user_id\",\n            \"value\": {\n              \"BASE\": 100,\n              \"START\": 0,\n              \"END\": 19\n            }\n          }\n        ]\n    \"\"\"\n\n    # Get customer's tier and identifier from incoming request\n    ctx = {\"tier\": event.get(\"tier\", \"standard\"), \"user_id\": event.get(\"user_id\", 0)}\n\n    # Checking if the sale_experiment is enable\n    sale_experiment = feature_flags.evaluate(name=\"sale_experiment\", default=False, context=ctx)\n\n    if sale_experiment:\n        # Enable special discount for sale experiment segment users:\n        return {\"message\": \"The sale experiment is enabled.\"}\n\n    return {\"message\": \"The sale experiment is not enabled.\"}\n</code></pre> <pre><code>{\n  \"user_id\": 134532511,\n  \"tier\": \"standard\",\n  \"basked_id\": \"random_id\"\n}\n</code></pre> <pre><code>{\n  \"sale_experiment\": {\n    \"default\": false,\n    \"rules\": {\n      \"experiment 1 segment - 20% users\": {\n        \"when_match\": true,\n        \"conditions\": [\n          {\n            \"action\": \"EQUALS\",\n            \"key\": \"tier\",\n            \"value\": \"standard\"\n          },\n          {\n            \"action\": \"MODULO_RANGE\",\n            \"key\": \"user_id\",\n            \"value\": {\n              \"BASE\": 100,\n              \"START\": 0,\n              \"END\": 19\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n</code></pre> <p>You can run multiple experiments on your users with the spectrum of your choice.</p> modulo_range_multiple_feature.pymodulo_range_multiple_features.json <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\")\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    \"\"\"\n    This non-boolean feature flag returns the percentage discount depending on the sale experiment segment:\n    - 10% standard discount if the user_id belongs to the spectrum 0-3 modulo 10, (40% users).\n    - 15% experiment discount if the user_id belongs to the spectrum 4-6 modulo 10, (30% users).\n    - 18% experiment discount if the user_id belongs to the spectrum 7-9 modulo 10, (30% users).\n\n    Rule conditions to be evaluated:\n    \"rules\": {\n      \"control group - standard 10% discount segment\": {\n        \"when_match\": 10,\n        \"conditions\": [\n          {\n            \"action\": \"MODULO_RANGE\",\n            \"key\": \"user_id\",\n            \"value\": {\n              \"BASE\": 10,\n              \"START\": 0,\n              \"END\": 3\n            }\n          }\n        ]\n      },\n      \"test experiment 1 - 15% discount segment\": {\n        \"when_match\": 15,\n        \"conditions\": [\n          {\n            \"action\": \"MODULO_RANGE\",\n            \"key\": \"user_id\",\n            \"value\": {\n              \"BASE\": 10,\n              \"START\": 4,\n              \"END\": 6\n            }\n          }\n        ]\n      },\n      \"test experiment 2 - 18% discount segment\": {\n        \"when_match\": 18,\n        \"conditions\": [\n          {\n            \"action\": \"MODULO_RANGE\",\n            \"key\": \"user_id\",\n            \"value\": {\n              \"BASE\": 10,\n              \"START\": 7,\n              \"END\": 9\n            }\n          }\n        ]\n      }\n    }\n    \"\"\"\n\n    # Get customer's tier and identifier from incoming request\n    ctx = {\"tier\": event.get(\"tier\", \"standard\"), \"user_id\": event.get(\"user_id\", 0)}\n\n    # Get sale discount percentage from feature flag.\n    sale_experiment_discount = feature_flags.evaluate(name=\"sale_experiment_discount\", default=0, context=ctx)\n\n    return {\"message\": f\" {sale_experiment_discount}% discount applied.\"}\n</code></pre> <pre><code>{\n  \"sale_experiment_discount\": {\n    \"boolean_type\": false,\n    \"default\": 0,\n    \"rules\": {\n      \"control group - standard 10% discount segment\": {\n        \"when_match\": 10,\n        \"conditions\": [\n          {\n            \"action\": \"MODULO_RANGE\",\n            \"key\": \"user_id\",\n            \"value\": {\n              \"BASE\": 10,\n              \"START\": 0,\n              \"END\": 3\n            }\n          }\n        ]\n      },\n      \"test experiment 1 - 15% discount segment\": {\n        \"when_match\": 15,\n        \"conditions\": [\n          {\n            \"action\": \"MODULO_RANGE\",\n            \"key\": \"user_id\",\n            \"value\": {\n              \"BASE\": 10,\n              \"START\": 4,\n              \"END\": 6\n            }\n          }\n        ]\n      },\n      \"test experiment 2 - 18% discount segment\": {\n        \"when_match\": 18,\n        \"conditions\": [\n          {\n            \"action\": \"MODULO_RANGE\",\n            \"key\": \"user_id\",\n            \"value\": {\n              \"BASE\": 10,\n              \"START\": 7,\n              \"END\": 9\n            }\n          }\n        ]\n      }\n    }\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#beyond-boolean-feature-flags",
            "title": "Beyond boolean feature flags",
            "text": "When is this useful? <p>You might have a list of features to unlock for premium customers, unlock a specific set of features for admin users, etc.</p> <p>Feature flags can return any JSON values when <code>boolean_type</code> parameter is set to <code>false</code>. These can be dictionaries, list, string, integers, etc.</p> beyond_boolean.pybeyond_boolean_payload.jsonbeyond_boolean_features.json <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"comments\", name=\"config\")\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    # Get customer's tier from incoming request\n    ctx = {\"tier\": event.get(\"tier\", \"standard\")}\n\n    # Evaluate `has_premium_features` based on customer's tier\n    premium_features: Any = feature_flags.evaluate(name=\"premium_features\", context=ctx, default=[])\n\n    return {\"Premium features enabled\": premium_features}\n</code></pre> <pre><code>{\n    \"username\": \"lessa\",\n    \"tier\": \"premium\",\n    \"basked_id\": \"random_id\"\n}\n</code></pre> <pre><code>{\n    \"premium_features\": {\n      \"boolean_type\": false,\n      \"default\": [],\n      \"rules\": {\n        \"customer tier equals premium\": {\n          \"when_match\": [\n            \"no_ads\",\n            \"no_limits\",\n            \"chat\"\n          ],\n          \"conditions\": [\n            {\n              \"action\": \"EQUALS\",\n              \"key\": \"tier\",\n              \"value\": \"premium\"\n            }\n          ]\n        }\n      }\n    }\n  }\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/feature_flags/#adjusting-in-memory-cache",
            "title": "Adjusting in-memory cache",
            "text": "<p>By default, we cache configuration retrieved from the Store for 5 seconds for performance and reliability reasons.</p> <p>You can override <code>max_age</code> parameter when instantiating the store.</p> getting_started_with_cache.pygetting_started_with_cache_payload.jsongetting_started_with_cache_features.json <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(environment=\"dev\", application=\"product-catalogue\", name=\"features\", max_age=300)\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    \"\"\"\n    This feature flag is enabled by default for all requests.\n    \"\"\"\n\n    apply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\n\n    price: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre> <pre><code>{\n    \"product\": \"laptop\",\n    \"price\": 1000\n}\n</code></pre> <pre><code>{\n    \"ten_percent_off_campaign\": {\n        \"default\": true\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#getting-fetched-configuration",
            "title": "Getting fetched configuration",
            "text": "When is this useful? <p>You might have application configuration in addition to feature flags in your store.</p> <p>This means you don't need to make another call only to fetch app configuration.</p> <p>You can access the configuration fetched from the store via <code>get_raw_configuration</code> property within the store instance.</p> getting_stored_features.py <pre><code>from aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\n\napp_config = AppConfigStore(\n    environment=\"dev\",\n    application=\"product-catalogue\",\n    name=\"configuration\",\n    envelope=\"feature_flags\",\n)\n\nfeature_flags = FeatureFlags(store=app_config)\n\nconfig = app_config.get_raw_configuration\n...\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#schema",
            "title": "Schema",
            "text": "<p>This utility expects a certain schema to be stored as JSON within AWS AppConfig.</p>"
        },
        {
            "location": "utilities/feature_flags/#features",
            "title": "Features",
            "text": "<p>A feature can simply have its name and a <code>default</code> value. This is either on or off, also known as a static flag.</p> minimal_schema.json <pre><code>{\n    \"global_feature\": {\n        \"default\": true\n    },\n    \"non_boolean_global_feature\": {\n        \"default\": {\"group\": \"read-only\"},\n        \"boolean_type\": false\n    }\n}\n</code></pre> <p>If you need more control and want to provide context such as user group, permissions, location, etc., you need to add rules to your feature flag configuration.</p>"
        },
        {
            "location": "utilities/feature_flags/#rules",
            "title": "Rules",
            "text": "<p>When adding <code>rules</code> to a feature, they must contain:</p> <ol> <li>A rule name as a key</li> <li><code>when_match</code> boolean or JSON value that should be used when conditions match</li> <li>A list of <code>conditions</code> for evaluation</li> </ol> feature_with_rules.json <pre><code>{\n    \"premium_feature\": {\n        \"default\": false,\n        \"rules\": {\n            \"customer tier equals premium\": {\n                \"when_match\": true,\n                \"conditions\": [\n                    {\n                        \"action\": \"EQUALS\",\n                        \"key\": \"tier\",\n                        \"value\": \"premium\"\n                    }\n                ]\n            }\n        }\n    },\n    \"non_boolean_premium_feature\": {\n        \"default\": [],\n        \"rules\": {\n            \"customer tier equals premium\": {\n                \"when_match\": [\"remove_limits\", \"remove_ads\"],\n                \"conditions\": [\n                    {\n                        \"action\": \"EQUALS\",\n                        \"key\": \"tier\",\n                        \"value\": \"premium\"\n                    }\n                ]\n            }\n        }\n    }\n}\n</code></pre> <p>You can have multiple rules with different names. The rule engine will return the first result <code>when_match</code> of the matching rule configuration, or <code>default</code> value when none of the rules apply.</p>"
        },
        {
            "location": "utilities/feature_flags/#conditions",
            "title": "Conditions",
            "text": "<p>The <code>conditions</code> block is a list of conditions that contain <code>action</code>, <code>key</code>, and <code>value</code> keys:</p> conditions.json <pre><code>{\n    \"conditions\": [\n        {\n            \"action\": \"EQUALS\",\n            \"key\": \"tier\",\n            \"value\": \"premium\"\n        }\n    ]\n}\n</code></pre> <p>The <code>action</code> configuration can have the following values, where the expressions <code>a</code> is the <code>key</code> and <code>b</code> is the <code>value</code> above:</p> Action Equivalent expression EQUALS <code>lambda a, b: a == b</code> NOT_EQUALS <code>lambda a, b: a != b</code> KEY_GREATER_THAN_VALUE <code>lambda a, b: a &gt; b</code> KEY_GREATER_THAN_OR_EQUAL_VALUE <code>lambda a, b: a &gt;= b</code> KEY_LESS_THAN_VALUE <code>lambda a, b: a &lt; b</code> KEY_LESS_THAN_OR_EQUAL_VALUE <code>lambda a, b: a &lt;= b</code> STARTSWITH <code>lambda a, b: a.startswith(b)</code> ENDSWITH <code>lambda a, b: a.endswith(b)</code> KEY_IN_VALUE <code>lambda a, b: a in b</code> KEY_NOT_IN_VALUE <code>lambda a, b: a not in b</code> ANY_IN_VALUE <code>lambda a, b: any of a is in b</code> ALL_IN_VALUE <code>lambda a, b: all of a is in b</code> NONE_IN_VALUE <code>lambda a, b: none of a is in b</code> VALUE_IN_KEY <code>lambda a, b: b in a</code> VALUE_NOT_IN_KEY <code>lambda a, b: b not in a</code> SCHEDULE_BETWEEN_TIME_RANGE <code>lambda a, b: b.start &lt;= time(a) &lt;= b.end</code> SCHEDULE_BETWEEN_DATETIME_RANGE <code>lambda a, b: b.start &lt;= datetime(a) &lt;= b.end</code> SCHEDULE_BETWEEN_DAYS_OF_WEEK <code>lambda a, b: day_of_week(a) in b</code> MODULO_RANGE <code>lambda a, b: b.start &lt;= a % b.base &lt;= b.end</code> Info <p>The <code>key</code> and <code>value</code> will be compared to the input from the <code>context</code> parameter.</p> Time based keys <p>For time based keys, we provide a list of predefined keys. These will automatically get converted to the corresponding timestamp on each invocation of your Lambda function.</p> Key Meaning CURRENT_TIME The current time, 24 hour format (HH:mm) CURRENT_DATETIME The current datetime (ISO8601) CURRENT_DAY_OF_WEEK The current day of the week (Monday-Sunday) <p>If not specified, the timezone used for calculations will be UTC.</p> <p>For multiple conditions, we will evaluate the list of conditions as a logical <code>AND</code>, so all conditions needs to match to return <code>when_match</code> value.</p>"
        },
        {
            "location": "utilities/feature_flags/#rule-engine-flowchart",
            "title": "Rule engine flowchart",
            "text": "<p>Now that you've seen all properties of a feature flag schema, this flowchart describes how the rule engine decides what value to return.</p> <p></p>"
        },
        {
            "location": "utilities/feature_flags/#envelope",
            "title": "Envelope",
            "text": "<p>There are scenarios where you might want to include feature flags as part of an existing application configuration.</p> <p>For this to work, you need to use a JMESPath expression via the <code>envelope</code> parameter to extract that key as the feature flags configuration.</p> extracting_envelope.pyextracting_envelope_payload.jsonextracting_envelope_features.json <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp_config = AppConfigStore(\n    environment=\"dev\",\n    application=\"product-catalogue\",\n    name=\"feature_flags\",\n    envelope=\"features\",\n)\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    apply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\n\n    price: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre> <pre><code>{\n    \"product\": \"laptop\",\n    \"price\": 1000\n}\n</code></pre> <pre><code>{\n    \"logging\": {\n          \"level\": \"INFO\",\n          \"sampling_rate\": 0.1\n     },\n    \"features\": {\n      \"ten_percent_off_campaign\": {\n        \"default\": true\n      }\n    }\n  }\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#built-in-store-provider",
            "title": "Built-in store provider",
            "text": ""
        },
        {
            "location": "utilities/feature_flags/#appconfig",
            "title": "AppConfig",
            "text": "<p>AppConfig store provider fetches any JSON document from AWS AppConfig.</p> <p>These are the available options for further customization.</p> Parameter Default Description environment <code>\"\"</code> AWS AppConfig Environment, e.g. <code>dev</code> application <code>\"\"</code> AWS AppConfig Application, e.g. <code>product-catalogue</code> name <code>\"\"</code> AWS AppConfig Configuration name, e.g <code>features</code> envelope <code>None</code> JMESPath expression to use to extract feature flags configuration from AWS AppConfig configuration max_age <code>5</code> Number of seconds to cache feature flags configuration fetched from AWS AppConfig jmespath_options <code>None</code> For advanced use cases when you want to bring your own JMESPath functions logger <code>logging.Logger</code> Logger to use for debug.  You can optionally supply an instance of Powertools for AWS Lambda (Python) Logger. boto3_client <code>None</code> AppConfigData boto3 client boto3_session <code>None</code> Boto3 session boto_config <code>None</code> Botocore config appconfig_provider_options.pyappconfig_provider_options_payload.jsonappconfig_provider_options_features.json <pre><code>from typing import Any\n\nfrom botocore.config import Config\nfrom jmespath.functions import Functions, signature\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nboto_config = Config(read_timeout=10, retries={\"total_max_attempts\": 2})\n\n\n# Custom JMESPath functions\nclass CustomFunctions(Functions):\n    @signature({\"types\": [\"object\"]})\n    def _func_special_decoder(self, features):\n        # You can add some logic here\n        return features\n\n\ncustom_jmespath_options = {\"custom_functions\": CustomFunctions()}\n\n\napp_config = AppConfigStore(\n    environment=\"dev\",\n    application=\"product-catalogue\",\n    name=\"features\",\n    max_age=120,\n    envelope=\"special_decoder(features)\",  # using a custom function defined in CustomFunctions Class\n    boto_config=boto_config,\n    jmespath_options=custom_jmespath_options,\n)\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    apply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\n\n    price: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre> <pre><code>{\n    \"product\": \"laptop\",\n    \"price\": 1000\n}\n</code></pre> <pre><code>{\n    \"logging\": {\n          \"level\": \"INFO\",\n          \"sampling_rate\": 0.1\n     },\n    \"features\": {\n      \"ten_percent_off_campaign\": {\n        \"default\": true\n      }\n    }\n  }\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#customizing-boto-configuration",
            "title": "Customizing boto configuration",
            "text": "<p>The <code>boto_config</code> , <code>boto3_session</code>, and <code>boto3_client</code>  parameters enable you to pass in a custom botocore config object, boto3 session, or  a boto3 client when constructing the AppConfig store provider.</p> custom_boto_session_feature_flags.pycustom_boto_config_feature_flags.pycustom_boto_client_feature_flags.py <pre><code>from typing import Any\n\nimport boto3\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nboto3_session = boto3.session.Session()\n\napp_config = AppConfigStore(\n    environment=\"dev\",\n    application=\"product-catalogue\",\n    name=\"features\",\n    boto3_session=boto3_session,\n)\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    apply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\n\n    price: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre> <pre><code>from typing import Any\n\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nboto_config = Config(read_timeout=10, retries={\"total_max_attempts\": 2})\n\napp_config = AppConfigStore(\n    environment=\"dev\",\n    application=\"product-catalogue\",\n    name=\"features\",\n    boto_config=boto_config,\n)\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    apply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\n\n    price: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre> <pre><code>from typing import Any\n\nimport boto3\n\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nboto3_client = boto3.client(\"appconfigdata\")\n\napp_config = AppConfigStore(\n    environment=\"dev\",\n    application=\"product-catalogue\",\n    name=\"features\",\n    boto3_client=boto3_client,\n)\n\nfeature_flags = FeatureFlags(store=app_config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    apply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\n\n    price: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#create-your-own-store-provider",
            "title": "Create your own store provider",
            "text": "<p>You can create your own custom FeatureFlags store provider by inheriting the <code>StoreProvider</code> class, and implementing both <code>get_raw_configuration()</code> and <code>get_configuration()</code> methods to retrieve the configuration from your custom store.</p> <ul> <li><code>get_raw_configuration()</code> – get the raw configuration from the store provider and return the parsed JSON dictionary</li> <li><code>get_configuration()</code> – get the configuration from the store provider, parsing it as a JSON dictionary. If an envelope is set, extract the envelope data</li> </ul> <p>Here are an example of implementing a custom store provider using Amazon S3, a popular object storage.</p> Note <p>This is just one example of how you can create your own store provider. Before creating a custom store provider, carefully evaluate your requirements and consider factors such as performance, scalability, and ease of maintenance.</p> working_with_own_s3_store_provider.pycustom_s3_store_provider.pyworking_with_own_s3_store_provider_payload.jsonworking_with_own_s3_store_provider_features.json <pre><code>from typing import Any\n\nfrom custom_s3_store_provider import S3StoreProvider\n\nfrom aws_lambda_powertools.utilities.feature_flags import FeatureFlags\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ns3_config_store = S3StoreProvider(\"your-bucket-name\", \"working_with_own_s3_store_provider_features.json\")\n\nfeature_flags = FeatureFlags(store=s3_config_store)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    apply_discount: Any = feature_flags.evaluate(name=\"ten_percent_off_campaign\", default=False)\n\n    price: Any = event.get(\"price\")\n\n    if apply_discount:\n        # apply 10% discount to product\n        price = price * 0.9\n\n    return {\"price\": price}\n</code></pre> <pre><code>import json\nfrom typing import Any, Dict\n\nimport boto3\nfrom botocore.exceptions import ClientError\n\nfrom aws_lambda_powertools.utilities.feature_flags.base import StoreProvider\nfrom aws_lambda_powertools.utilities.feature_flags.exceptions import (\n    ConfigurationStoreError,\n)\n\n\nclass S3StoreProvider(StoreProvider):\n    def __init__(self, bucket_name: str, object_key: str):\n        # Initialize the client to your custom store provider\n\n        super().__init__()\n\n        self.bucket_name = bucket_name\n        self.object_key = object_key\n        self.client = boto3.client(\"s3\")\n\n    def _get_s3_object(self) -&gt; Dict[str, Any]:\n        # Retrieve the object content\n        try:\n            response = self.client.get_object(Bucket=self.bucket_name, Key=self.object_key)\n            return json.loads(response[\"Body\"].read().decode())\n        except ClientError as exc:\n            raise ConfigurationStoreError(\"Unable to get S3 Store Provider configuration file\") from exc\n\n    def get_configuration(self) -&gt; Dict[str, Any]:\n        return self._get_s3_object()\n\n    @property\n    def get_raw_configuration(self) -&gt; Dict[str, Any]:\n        return self._get_s3_object()\n</code></pre> <pre><code>{\n    \"product\": \"laptop\",\n    \"price\": 1000\n}\n</code></pre> <pre><code>{\n    \"ten_percent_off_campaign\": {\n        \"default\": true\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>You can unit test your feature flags locally and independently without setting up AWS AppConfig.</p> <p><code>AppConfigStore</code> only fetches a JSON document with a specific schema. This allows you to mock the response and use it to verify the rule evaluation.</p> Warning <p>This excerpt relies on <code>pytest</code> and <code>pytest-mock</code> dependencies.</p> Testing your code <pre><code>from aws_lambda_powertools.utilities.feature_flags import (\n    AppConfigStore,\n    FeatureFlags,\n    RuleAction,\n)\n\n\ndef init_feature_flags(mocker, mock_schema, envelope=\"\") -&gt; FeatureFlags:\n    \"\"\"Mock AppConfig Store get_configuration method to use mock schema instead\"\"\"\n\n    method_to_mock = \"aws_lambda_powertools.utilities.feature_flags.AppConfigStore.get_configuration\"\n    mocked_get_conf = mocker.patch(method_to_mock)\n    mocked_get_conf.return_value = mock_schema\n\n    app_conf_store = AppConfigStore(\n        environment=\"test_env\",\n        application=\"test_app\",\n        name=\"test_conf_name\",\n        envelope=envelope,\n    )\n\n    return FeatureFlags(store=app_conf_store)\n\n\ndef test_flags_condition_match(mocker):\n    # GIVEN\n    expected_value = True\n    mocked_app_config_schema = {\n        \"my_feature\": {\n            \"default\": False,\n            \"rules\": {\n                \"tenant id equals 12345\": {\n                    \"when_match\": expected_value,\n                    \"conditions\": [\n                        {\n                            \"action\": RuleAction.EQUALS.value,\n                            \"key\": \"tenant_id\",\n                            \"value\": \"12345\",\n                        },\n                    ],\n                },\n            },\n        },\n    }\n\n    # WHEN\n    ctx = {\"tenant_id\": \"12345\", \"username\": \"a\"}\n    feature_flags = init_feature_flags(mocker=mocker, mock_schema=mocked_app_config_schema)\n    flag = feature_flags.evaluate(name=\"my_feature\", context=ctx, default=False)\n\n    # THEN\n    assert flag == expected_value\n</code></pre>"
        },
        {
            "location": "utilities/feature_flags/#feature-flags-vs-parameters-vs-env-vars",
            "title": "Feature flags vs Parameters vs Env vars",
            "text": "Method When to use Requires new deployment on changes Supported services Environment variables Simple configuration that will rarely if ever change, because changing it requires a Lambda function deployment. Yes Lambda Parameters utility Access to secrets, or fetch parameters in different formats from AWS System Manager Parameter Store or Amazon DynamoDB. No Parameter Store, DynamoDB, Secrets Manager, AppConfig Feature flags utility Rule engine to define when one or multiple features should be enabled depending on the input. No AppConfig"
        },
        {
            "location": "utilities/idempotency/",
            "title": "Idempotency",
            "text": "<p>The idempotency utility allows you to retry operations within a time window with the same input, producing the same output.</p>"
        },
        {
            "location": "utilities/idempotency/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Produces the previous successful result when a function is called repeatedly with the same idempotency key</li> <li>Choose your idempotency key from one or more fields, or entire payload</li> <li>Safeguard concurrent requests, timeouts, missing idempotency keys, and payload tampering</li> <li>Support for Amazon DynamoDB, Redis, bring your own persistence layer, and in-memory caching</li> </ul>"
        },
        {
            "location": "utilities/idempotency/#terminology",
            "title": "Terminology",
            "text": "<p>The property of idempotency means that an operation does not cause additional side effects if it is called more than once with the same input parameters.</p> <p>Idempotency key By default, this is a combination of (a) Lambda function name, (b) fully qualified name of your function, and (c) a hash of the entire payload or part(s) of the payload you specify. However, you can customize the key generation by using (a) a custom prefix name, while still incorporating (c) a hash of the entire payload or part(s) of the payload you specify.</p> <p>Idempotent request is an operation with the same input previously processed that is not expired in your persistent storage or in-memory cache.</p> <p>Persistence layer is a storage we use to create, read, expire, and delete idempotency records.</p> <p>Idempotency record is the data representation of an idempotent request saved in the persistent layer and in its various status. We use it to coordinate  whether (a) a request is idempotent, (b) it's not expired, (c) JSON response to return, and more.</p> <p> <pre><code>classDiagram\n    direction LR\n    class IdempotencyRecord {\n        idempotency_key str\n        status Status\n        expiry_timestamp int\n        in_progress_expiry_timestamp int\n        response_data str~JSON~\n        payload_hash str\n    }\n    class Status {\n        &lt;&lt;Enumeration&gt;&gt;\n        INPROGRESS\n        COMPLETE\n        EXPIRED internal_only\n    }\n    IdempotencyRecord -- Status</code></pre> <p>Idempotency record representation </p>"
        },
        {
            "location": "utilities/idempotency/#getting-started",
            "title": "Getting started",
            "text": "<p>We use Amazon DynamoDB as the default persistence layer in the documentation. If you prefer Redis, you can learn more from this section.</p>"
        },
        {
            "location": "utilities/idempotency/#iam-permissions",
            "title": "IAM Permissions",
            "text": "<p>When using Amazon DynamoDB as the persistence layer, you will need the following IAM permissions:</p> IAM Permission Operation <code>dynamodb:GetItem</code> Retrieve idempotent record (strong consistency) <code>dynamodb:PutItem</code> New idempotent records, replace expired idempotent records <code>dynamodb:UpdateItem</code> Complete idempotency transaction, and/or update idempotent records state <code>dynamodb:DeleteItem</code> Delete idempotent records for unsuccessful idempotency transactions <p>First time setting it up?</p> <p>We provide Infrastrucure as Code examples with AWS Serverless Application Model (SAM), AWS Cloud Development Kit (CDK), and Terraform with the required permissions.</p>"
        },
        {
            "location": "utilities/idempotency/#required-resources",
            "title": "Required resources",
            "text": "<p>To start, you'll need:</p> <ul> <li> <p> Persistent storage</p> <p>Amazon DynamoDB or Redis</p> </li> <li> <p> AWS Lambda function</p> <p>With permissions to use your persistent storage</p> </li> </ul> <p>Primary key for any persistence storage</p> <p>We combine the Lambda function name and the fully qualified name for classes/functions to prevent accidental reuse for similar code sharing input/output.</p> <p>Primary key sample: <code>{lambda_fn_name}.{module_name}.{fn_qualified_name}#{idempotency_key_hash}</code></p>"
        },
        {
            "location": "utilities/idempotency/#dynamodb-table",
            "title": "DynamoDB table",
            "text": "<p>Unless you're looking to use an existing table or customize each attribute, you only need the following:</p> Configuration Value Notes Partition key <code>id</code> TTL attribute name <code>expiration</code> Using AWS Console? This is configurable after table creation <p>You can use a single DynamoDB table for all functions annotated with Idempotency.</p>"
        },
        {
            "location": "utilities/idempotency/#dynamodb-iac-examples",
            "title": "DynamoDB IaC examples",
            "text": "AWS Serverless Application Model (SAM) exampleAWS Cloud Development Kit (CDK)Terraform <pre><code>Transform: AWS::Serverless-2016-10-31\nResources:\n  IdempotencyTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      AttributeDefinitions:\n        - AttributeName: id\n          AttributeType: S\n      KeySchema:\n        - AttributeName: id\n          KeyType: HASH\n      TimeToLiveSpecification:\n        AttributeName: expiration\n        Enabled: true\n      BillingMode: PAY_PER_REQUEST\n\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Runtime: python3.12\n      Handler: app.py\n      Policies:\n        - Statement:\n            - Sid: AllowDynamodbReadWrite\n              Effect: Allow\n              Action:\n                - dynamodb:PutItem\n                - dynamodb:GetItem\n                - dynamodb:UpdateItem\n                - dynamodb:DeleteItem\n              Resource: !GetAtt IdempotencyTable.Arn\n      Environment:\n        Variables:\n          IDEMPOTENCY_TABLE: !Ref IdempotencyTable\n</code></pre> <pre><code>from aws_cdk import RemovalPolicy\nfrom aws_cdk import aws_dynamodb as dynamodb\nfrom aws_cdk import aws_iam as iam\nfrom constructs import Construct\n\n\nclass IdempotencyConstruct(Construct):\n    def __init__(self, scope: Construct, name: str, lambda_role: iam.Role) -&gt; None:\n        super().__init__(scope, name)\n        self.idempotency_table = dynamodb.Table(\n            self,\n            \"IdempotencyTable\",\n            partition_key=dynamodb.Attribute(name=\"id\", type=dynamodb.AttributeType.STRING),\n            billing_mode=dynamodb.BillingMode.PAY_PER_REQUEST,\n            removal_policy=RemovalPolicy.DESTROY,\n            time_to_live_attribute=\"expiration\",\n            point_in_time_recovery=True,\n        )\n        self.idempotency_table.grant(\n            lambda_role,\n            \"dynamodb:PutItem\",\n            \"dynamodb:GetItem\",\n            \"dynamodb:UpdateItem\",\n            \"dynamodb:DeleteItem\",\n        )\n</code></pre> <pre><code>terraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 4.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = \"us-east-1\" # Replace with your desired AWS region\n}\n\nresource \"aws_dynamodb_table\" \"IdempotencyTable\" {\n  name         = \"IdempotencyTable\"\n  billing_mode = \"PAY_PER_REQUEST\"\n  hash_key     = \"id\"\n  attribute {\n    name = \"id\"\n    type = \"S\"\n  }\n  ttl {\n    attribute_name = \"expiration\"\n    enabled        = true\n  }\n}\n\nresource \"aws_lambda_function\" \"IdempotencyFunction\" {\n  function_name = \"IdempotencyFunction\"\n  role          = aws_iam_role.IdempotencyFunctionRole.arn\n  runtime       = \"python3.12\"\n  handler       = \"app.lambda_handler\"\n  filename      = \"lambda.zip\"\n\n}\n\nresource \"aws_iam_role\" \"IdempotencyFunctionRole\" {\n  name = \"IdempotencyFunctionRole\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"lambda.amazonaws.com\"\n        }\n        Action = \"sts:AssumeRole\"\n      },\n    ]\n  })\n}\n\nresource \"aws_iam_policy\" \"LambdaDynamoDBPolicy\" {\n  name        = \"LambdaDynamoDBPolicy\"\n  description = \"IAM policy for Lambda function to access DynamoDB\"\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Sid    = \"AllowDynamodbReadWrite\"\n        Effect = \"Allow\"\n        Action = [\n          \"dynamodb:PutItem\",\n          \"dynamodb:GetItem\",\n          \"dynamodb:UpdateItem\",\n          \"dynamodb:DeleteItem\",\n        ]\n        Resource = aws_dynamodb_table.IdempotencyTable.arn\n      },\n    ]\n  })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"IdempotencyFunctionRoleAttachment\" {\n  role       = aws_iam_role.IdempotencyFunctionRole.name\n  policy_arn = aws_iam_policy.LambdaDynamoDBPolicy.arn\n}\n</code></pre> <p>`</p>"
        },
        {
            "location": "utilities/idempotency/#limitations",
            "title": "Limitations",
            "text": "<ul> <li> <p>DynamoDB restricts item sizes to 400KB. This means that if your annotated function's response must be smaller than 400KB, otherwise your function will fail. Consider Redis as an alternative.</p> </li> <li> <p>Expect 2 WCU per non-idempotent call. During the first invocation, we use <code>PutItem</code> for locking and <code>UpdateItem</code> for completion. Consider reviewing DynamoDB pricing documentation to estimate cost.</p> </li> <li> <p>Old boto3 versions can increase costs. For cost optimization, we use a conditional <code>PutItem</code> to always lock a new idempotency record. If locking fails, it means we already have an idempotency record saving us an additional <code>GetItem</code> call. However, this is only supported in boto3 <code>1.26.194</code> and higher (June 30th 2023).</p> </li> </ul>"
        },
        {
            "location": "utilities/idempotency/#redis-database",
            "title": "Redis database",
            "text": "<p>We recommend you start with a Redis compatible management services such as Amazon ElastiCache for Redis or Amazon MemoryDB for Redis.</p> <p>In both services, you'll need to configure VPC access to your AWS Lambda.</p>"
        },
        {
            "location": "utilities/idempotency/#redis-iac-examples",
            "title": "Redis IaC examples",
            "text": "AWS CloudFormation example <p>Prefer AWS Console/CLI?</p> <p>Follow the official tutorials for Amazon ElastiCache for Redis or Amazon MemoryDB for Redis</p> <pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\n\nResources:\n  RedisServerlessIdempotency:\n    Type: AWS::ElastiCache::ServerlessCache\n    Properties:\n      Engine: redis\n      ServerlessCacheName: redis-cache\n      SecurityGroupIds: # (1)!\n        - security-{your_sg_id}\n      SubnetIds:\n        - subnet-{your_subnet_id_1}\n        - subnet-{your_subnet_id_2}\n\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Runtime: python3.12\n      Handler: app.py\n      VpcConfig: # (1)!\n        SecurityGroupIds:\n          - security-{your_sg_id}\n        SubnetIds:\n          - subnet-{your_subnet_id_1}\n          - subnet-{your_subnet_id_2}\n      Environment:\n        Variables:\n          POWERTOOLS_SERVICE_NAME: sample\n          REDIS_HOST: !GetAtt RedisServerlessIdempotency.Endpoint.Address\n          REDIS_PORT: !GetAtt RedisServerlessIdempotency.Endpoint.Port\n</code></pre> <ol> <li>Replace the Security Group ID and Subnet ID to match your VPC settings.</li> <li>Replace the Security Group ID and Subnet ID to match your VPC settings.</li> </ol> <p>Once setup, you can find a quick start and advanced examples for Redis in the persistent layers section.</p>"
        },
        {
            "location": "utilities/idempotency/#idempotent-decorator",
            "title": "Idempotent decorator",
            "text": "<p>For simple use cases, you can use the <code>idempotent</code> decorator on your Lambda handler function.</p> <p>It will treat the entire event as an idempotency key. That is, the same event will return the previously stored result within a configurable time window (1 hour, by default).</p> Idempotent decoratorSample event <p>You can also choose one or more fields as an idempotency key.</p> getting_started_with_idempotency.py<pre><code>import os\nfrom dataclasses import dataclass, field\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(table_name=table)\n\n\n@dataclass\nclass Payment:\n    user_id: str\n    product_id: str\n    payment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass PaymentError(Exception): ...\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        payment: Payment = create_subscription_payment(event)\n        return {\n            \"payment_id\": payment.payment_id,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n    except Exception as exc:\n        raise PaymentError(f\"Error creating payment {str(exc)}\")\n\n\ndef create_subscription_payment(event: dict) -&gt; Payment:\n    return Payment(**event)\n</code></pre> getting_started_with_idempotency_payload.json<pre><code>{\n  \"user_id\": \"xyz\",\n  \"product_id\": \"123456789\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#idempotent_function-decorator",
            "title": "Idempotent_function decorator",
            "text": "<p>For full flexibility, you can use the <code>idempotent_function</code> decorator for any synchronous Python function.</p> <p>When using this decorator, you must call your decorated function using keyword arguments.</p> <p>You can use <code>data_keyword_argument</code> to tell us the argument to extract an idempotency key.  We support JSON serializable data, Dataclasses, Pydantic Models, and Event Source Data Classes</p> Using DataclassesUsing Pydantic working_with_idempotent_function_dataclass.py<pre><code>import os\nfrom dataclasses import dataclass\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\ndynamodb = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(event_key_jmespath=\"order_id\")  # see Choosing a payload subset section\n\n\n@dataclass\nclass OrderItem:\n    sku: str\n    description: str\n\n\n@dataclass\nclass Order:\n    item: OrderItem\n    order_id: int\n\n\n@idempotent_function(data_keyword_argument=\"order\", config=config, persistence_store=dynamodb)\ndef process_order(order: Order):  # (1)!\n    return f\"processed order {order.order_id}\"\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    # see Lambda timeouts section\n    config.register_lambda_context(context)  # (2)!\n\n    order_item = OrderItem(sku=\"fake\", description=\"sample\")\n    order = Order(item=order_item, order_id=1)\n\n    # `order` parameter must be called as a keyword argument to work\n    process_order(order=order)\n</code></pre> <ol> <li>Notice how <code>data_keyword_argument</code> matches the name of the parameter.  This allows us to extract one or all fields as idempotency key.</li> <li>Different from <code>idempotent</code> decorator, we must explicitly register the Lambda context to protect against timeouts.</li> </ol> working_with_idempotent_function_pydantic.py<pre><code>import os\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.parser import BaseModel\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\ndynamodb = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(event_key_jmespath=\"order_id\")  # see Choosing a payload subset section\n\n\nclass OrderItem(BaseModel):\n    sku: str\n    description: str\n\n\nclass Order(BaseModel):\n    item: OrderItem\n    order_id: int\n\n\n@idempotent_function(data_keyword_argument=\"order\", config=config, persistence_store=dynamodb)\ndef process_order(order: Order):\n    return f\"processed order {order.order_id}\"\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    config.register_lambda_context(context)  # see Lambda timeouts section\n    order_item = OrderItem(sku=\"fake\", description=\"sample\")\n    order = Order(item=order_item, order_id=1)\n\n    # `order` parameter must be called as a keyword argument to work\n    process_order(order=order)\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#output-serialization",
            "title": "Output serialization",
            "text": "<p>By default, <code>idempotent_function</code> serializes, stores, and returns your annotated function's result as a JSON object. You can change this behavior using <code>output_serializer</code> parameter.</p> <p>The output serializer supports any JSON serializable data, Python Dataclasses and Pydantic Models.</p> <p>Info</p> <p>When using the <code>output_serializer</code> parameter, the data will continue to be stored in your persistent storage as a JSON string.</p> <p>Function returns must be annotated with a single type, optionally wrapped in <code>Optional</code> or <code>Union</code> with <code>None</code>.</p> PydanticDataclassesAny type <p>Use <code>PydanticSerializer</code> to automatically serialize what's retrieved from the persistent storage based on the return type annotated.</p> Inferring via the return typeExplicit model type <pre><code>import os\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.idempotency.serialization.pydantic import PydanticSerializer\nfrom aws_lambda_powertools.utilities.parser import BaseModel\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\ndynamodb = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(event_key_jmespath=\"order_id\")  # see Choosing a payload subset section\n\n\nclass OrderItem(BaseModel):\n    sku: str\n    description: str\n\n\nclass Order(BaseModel):\n    item: OrderItem\n    order_id: int\n\n\nclass OrderOutput(BaseModel):\n    order_id: int\n\n\n@idempotent_function(\n    data_keyword_argument=\"order\",\n    config=config,\n    persistence_store=dynamodb,\n    output_serializer=PydanticSerializer,\n)\n# order output is inferred from return type\ndef process_order(order: Order) -&gt; OrderOutput:  # (1)!\n    return OrderOutput(order_id=order.order_id)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    config.register_lambda_context(context)  # see Lambda timeouts section\n    order_item = OrderItem(sku=\"fake\", description=\"sample\")\n    order = Order(item=order_item, order_id=1)\n\n    # `order` parameter must be called as a keyword argument to work\n    process_order(order=order)\n</code></pre> <ol> <li>We'll use <code>OrderOutput</code> to instantiate a new object using the data retrieved from persistent storage as input.  This ensures the return of the function is not impacted when <code>@idempotent_function</code> is used.</li> </ol> <p>Alternatively, you can provide an explicit model as an input to <code>PydanticSerializer</code>.</p> <pre><code>import os\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.idempotency.serialization.pydantic import PydanticSerializer\nfrom aws_lambda_powertools.utilities.parser import BaseModel\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\ndynamodb = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(event_key_jmespath=\"order_id\")  # see Choosing a payload subset section\n\n\nclass OrderItem(BaseModel):\n    sku: str\n    description: str\n\n\nclass Order(BaseModel):\n    item: OrderItem\n    order_id: int\n\n\nclass OrderOutput(BaseModel):\n    order_id: int\n\n\n@idempotent_function(\n    data_keyword_argument=\"order\",\n    config=config,\n    persistence_store=dynamodb,\n    output_serializer=PydanticSerializer(model=OrderOutput),\n)\ndef process_order(order: Order):\n    return OrderOutput(order_id=order.order_id)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    config.register_lambda_context(context)  # see Lambda timeouts section\n    order_item = OrderItem(sku=\"fake\", description=\"sample\")\n    order = Order(item=order_item, order_id=1)\n\n    # `order` parameter must be called as a keyword argument to work\n    process_order(order=order)\n</code></pre> <p>Use <code>DataclassSerializer</code> to automatically serialize what's retrieved from the persistent storage based on the return type annotated.</p> Inferring via the return typeExplicit model type <pre><code>import os\nfrom dataclasses import dataclass\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.idempotency.serialization.dataclass import DataclassSerializer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\ndynamodb = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(event_key_jmespath=\"order_id\")  # see Choosing a payload subset section\n\n\n@dataclass\nclass OrderItem:\n    sku: str\n    description: str\n\n\n@dataclass\nclass Order:\n    item: OrderItem\n    order_id: int\n\n\n@dataclass\nclass OrderOutput:\n    order_id: int\n\n\n@idempotent_function(\n    data_keyword_argument=\"order\",\n    config=config,\n    persistence_store=dynamodb,\n    output_serializer=DataclassSerializer,\n)\n# order output is inferred from return type\ndef process_order(order: Order) -&gt; OrderOutput:  # (1)!\n    return OrderOutput(order_id=order.order_id)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    config.register_lambda_context(context)  # see Lambda timeouts section\n    order_item = OrderItem(sku=\"fake\", description=\"sample\")\n    order = Order(item=order_item, order_id=1)\n\n    # `order` parameter must be called as a keyword argument to work\n    process_order(order=order)\n</code></pre> <ol> <li>We'll use <code>OrderOutput</code> to instantiate a new object using the data retrieved from persistent storage as input.  This ensures the return of the function is not impacted when <code>@idempotent_function</code> is used.</li> </ol> <p>Alternatively, you can provide an explicit model as an input to <code>DataclassSerializer</code>.</p> <pre><code>import os\nfrom dataclasses import dataclass\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.idempotency.serialization.dataclass import DataclassSerializer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\ndynamodb = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(event_key_jmespath=\"order_id\")  # see Choosing a payload subset section\n\n\n@dataclass\nclass OrderItem:\n    sku: str\n    description: str\n\n\n@dataclass\nclass Order:\n    item: OrderItem\n    order_id: int\n\n\n@dataclass\nclass OrderOutput:\n    order_id: int\n\n\n@idempotent_function(\n    data_keyword_argument=\"order\",\n    config=config,\n    persistence_store=dynamodb,\n    output_serializer=DataclassSerializer(model=OrderOutput),\n)\ndef process_order(order: Order):\n    return OrderOutput(order_id=order.order_id)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    config.register_lambda_context(context)  # see Lambda timeouts section\n    order_item = OrderItem(sku=\"fake\", description=\"sample\")\n    order = Order(item=order_item, order_id=1)\n\n    # `order` parameter must be called as a keyword argument to work\n    process_order(order=order)\n</code></pre> <p>Use <code>CustomDictSerializer</code> to have full control over the serialization process for any type. It expects two functions:</p> <ul> <li>to_dict. Function to convert any type to a JSON serializable dictionary before it saves into the persistent storage.</li> <li>from_dict. Function to convert from a dictionary retrieved from persistent storage and serialize in its original form.</li> </ul> <pre><code>import os\nfrom typing import Dict, Type\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.idempotency.serialization.custom_dict import CustomDictSerializer\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\ndynamodb = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(event_key_jmespath=\"order_id\")  # see Choosing a payload subset section\n\n\nclass OrderItem:\n    def __init__(self, sku: str, description: str):\n        self.sku = sku\n        self.description = description\n\n\nclass Order:\n    def __init__(self, item: OrderItem, order_id: int):\n        self.item = item\n        self.order_id = order_id\n\n\nclass OrderOutput:\n    def __init__(self, order_id: int):\n        self.order_id = order_id\n\n\ndef order_to_dict(x: Type[OrderOutput]) -&gt; Dict:  # (1)!\n    return dict(x.__dict__)\n\n\ndef dict_to_order(x: Dict) -&gt; OrderOutput:  # (2)!\n    return OrderOutput(**x)\n\n\norder_output_serializer = CustomDictSerializer(  # (3)!\n    to_dict=order_to_dict,\n    from_dict=dict_to_order,\n)\n\n\n@idempotent_function(\n    data_keyword_argument=\"order\",\n    config=config,\n    persistence_store=dynamodb,\n    output_serializer=order_output_serializer,\n)\ndef process_order(order: Order) -&gt; OrderOutput:\n    return OrderOutput(order_id=order.order_id)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    config.register_lambda_context(context)  # see Lambda timeouts section\n    order_item = OrderItem(sku=\"fake\", description=\"sample\")\n    order = Order(item=order_item, order_id=1)\n\n    # `order` parameter must be called as a keyword argument to work\n    process_order(order=order)\n</code></pre> <ol> <li>This function does the following 1. Receives the return from <code>process_order</code> 2. Converts to dictionary before it can be saved into the persistent storage.</li> <li>This function does the following 1. Receives the dictionary saved into the persistent storage 1 Serializes to <code>OrderOutput</code> before <code>@idempotent</code> returns back to the caller.</li> <li>This serializer receives both functions so it knows who to call when to serialize to and from dictionary.</li> </ol>"
        },
        {
            "location": "utilities/idempotency/#using-in-memory-cache",
            "title": "Using in-memory cache",
            "text": "<p>In-memory cache is local to each Lambda execution environment.</p> <p>You can enable caching with the <code>use_local_cache</code> parameter in <code>IdempotencyConfig</code>. When enabled, you can adjust cache capacity (256) with <code>local_cache_max_items</code>.</p> <p>By default, caching is disabled since we don't know how big your response could be in relation to your configured memory size.</p> Enabling cacheSample event <pre><code>import os\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(\n    event_key_jmespath=\"powertools_json(body)\",\n    # by default, it holds 256 items in a Least-Recently-Used (LRU) manner\n    use_local_cache=True,  # (1)!\n)\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event, context: LambdaContext):\n    return event\n</code></pre> <ol> <li>You can adjust cache capacity with <code>local_cache_max_items</code> parameter.</li> </ol> <pre><code>{\n  \"body\": \"{\\\"user_id\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#choosing-a-payload-subset",
            "title": "Choosing a payload subset",
            "text": "Tip: Dealing with always changing payloads <p>When dealing with a more elaborate payload, where parts of the payload always change, you should use <code>event_key_jmespath</code> parameter.</p> <p>Use <code>event_key_jmespath</code> parameter in <code>IdempotencyConfig</code> to select one or more payload parts as your idempotency key.</p> <p>Example scenario</p> <p>In this example, we have a Lambda handler that creates a payment for a user subscribing to a product. We want to ensure that we don't accidentally charge our customer by subscribing them more than once.</p> <p>Imagine the function runs successfully, but the client never receives the response due to a connection issue. It is safe to immediately retry in this instance, as the idempotent decorator will return a previously saved response.</p> <p>We want to use <code>user_id</code> and <code>product_id</code> fields as our idempotency key. If we were to treat the entire request as our idempotency key, a simple HTTP header change would cause our function to run again.</p> Deserializing JSON strings in payloads for increased accuracy. <p>The payload extracted by the <code>event_key_jmespath</code> is treated as a string by default. This means there could be differences in whitespace even when the JSON payload itself is identical.</p> <p>To alter this behaviour, we can use the JMESPath built-in function <code>powertools_json()</code> to treat the payload as a JSON object (dict) rather than a string.</p> Payment functionSample event <pre><code>import json\nimport os\nfrom dataclasses import dataclass, field\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(table_name=table)\n\n# Deserialize JSON string under the \"body\" key\n# then extract \"user\" and \"product_id\" data\nconfig = IdempotencyConfig(event_key_jmespath='powertools_json(body).[\"user_id\", \"product_id\"]')\n\n\n@dataclass\nclass Payment:\n    user_id: str\n    product_id: str\n    payment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass PaymentError(Exception): ...\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        payment_info: str = event.get(\"body\", \"\")\n        payment: Payment = create_subscription_payment(json.loads(payment_info))\n        return {\n            \"payment_id\": payment.payment_id,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n    except Exception as exc:\n        raise PaymentError(f\"Error creating payment {str(exc)}\")\n\n\ndef create_subscription_payment(event: dict) -&gt; Payment:\n    return Payment(**event)\n</code></pre> <pre><code>{\n  \"version\": \"2.0\",\n  \"routeKey\": \"ANY /createpayment\",\n  \"rawPath\": \"/createpayment\",\n  \"rawQueryString\": \"\",\n  \"headers\": {\n    \"Header1\": \"value1\",\n    \"Header2\": \"value2\"\n  },\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"apiId\": \"api-id\",\n    \"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n    \"domainPrefix\": \"id\",\n    \"http\": {\n      \"method\": \"POST\",\n      \"path\": \"/createpayment\",\n      \"protocol\": \"HTTP/1.1\",\n      \"sourceIp\": \"ip\",\n      \"userAgent\": \"agent\"\n    },\n    \"requestId\": \"id\",\n    \"routeKey\": \"ANY /createpayment\",\n    \"stage\": \"$default\",\n    \"time\": \"10/Feb/2021:13:40:43 +0000\",\n    \"timeEpoch\": 1612964443723\n  },\n  \"body\": \"{\\\"user_id\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\",\n  \"isBase64Encoded\": false\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#adjusting-expiration-window",
            "title": "Adjusting expiration window",
            "text": "<p>By default, we expire idempotency records after an hour (3600 seconds). After that, a transaction with the same payload will not be considered idempotent.</p> <p>You can change this expiration window with the <code>expires_after_seconds</code> parameter. There is no limit on how long this expiration window can be set to.</p> Adjusting expiration windowSample event <pre><code>import os\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(\n    event_key_jmespath=\"body\",\n    expires_after_seconds=24 * 60 * 60,  # 24 hours\n)\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event, context: LambdaContext):\n    return event\n</code></pre> <pre><code>{\n  \"body\": \"{\\\"user_id\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\"\n}\n</code></pre> Idempotency record expiration vs DynamoDB time-to-live (TTL) <p>DynamoDB TTL is a feature to remove items after a certain period of time, it may occur within 48 hours of expiration.</p> <p>We don't rely on DynamoDB or any persistence storage layer to determine whether a record is expired to avoid eventual inconsistency states.</p> <p>Instead, Idempotency records saved in the storage layer contain timestamps that can be verified upon retrieval and double checked within Idempotency feature.</p> <p>Why?</p> <p>A record might still be valid (<code>COMPLETE</code>) when we retrieved, but in some rare cases it might expire a second later. A record could also be cached in memory. You might also want to have idempotent transactions that should expire in seconds.</p>"
        },
        {
            "location": "utilities/idempotency/#customizing-the-idempotency-key-generation",
            "title": "Customizing the Idempotency key generation",
            "text": "<p>Warning: Changing the idempotency key generation will invalidate existing idempotency records</p> <p>Use <code>key_prefix</code> parameter in the <code>@idempotent</code> or <code>@idempotent_function</code> decorators to define a custom prefix for your Idempotency Key. This allows you to decouple idempotency key name from function names. It can be useful during application refactoring, for example.</p> Using a custom prefix in Lambda HandlerUsing a custom prefix in standalone functions <pre><code>import os\nfrom dataclasses import dataclass, field\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(table_name=table)\n\n\n@dataclass\nclass Payment:\n    user_id: str\n    product_id: str\n    payment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass PaymentError(Exception): ...\n\n\n@idempotent(persistence_store=persistence_layer, key_prefix=\"my_custom_prefix\") # (1)!\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        payment: Payment = create_subscription_payment(event)\n        return {\n            \"payment_id\": payment.payment_id,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n    except Exception as exc:\n        raise PaymentError(f\"Error creating payment {str(exc)}\")\n\n\ndef create_subscription_payment(event: dict) -&gt; Payment:\n    return Payment(**event)\n</code></pre> <ol> <li>The Idempotency record will be something like <code>my_custom_prefix#c4ca4238a0b923820dcc509a6f75849b</code></li> </ol> <pre><code>import os\nfrom dataclasses import dataclass\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\ndynamodb = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(event_key_jmespath=\"order_id\")  # see Choosing a payload subset section\n\n\n@dataclass\nclass OrderItem:\n    sku: str\n    description: str\n\n\n@dataclass\nclass Order:\n    item: OrderItem\n    order_id: int\n\n\n@idempotent_function(\n    data_keyword_argument=\"order\",\n    config=config,\n    persistence_store=dynamodb,\n    key_prefix=\"my_custom_prefix\", # (1)!\n)\ndef process_order(order: Order): \n    return f\"processed order {order.order_id}\"\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    # see Lambda timeouts section\n    config.register_lambda_context(context) \n\n    order_item = OrderItem(sku=\"fake\", description=\"sample\")\n    order = Order(item=order_item, order_id=1)\n\n    # `order` parameter must be called as a keyword argument to work\n    process_order(order=order)\n</code></pre> <ol> <li>The Idempotency record will be something like <code>my_custom_prefix#c4ca4238a0b923820dcc509a6f75849b</code></li> </ol>"
        },
        {
            "location": "utilities/idempotency/#lambda-timeouts",
            "title": "Lambda timeouts",
            "text": "<p>You can skip this section if you are using the <code>@idempotent</code> decorator</p> <p>By default, we protect against concurrent executions with the same payload using a locking mechanism. However, if your Lambda function times out before completing the first invocation it will only accept the same request when the idempotency record expire.</p> <p>To prevent extended failures, use <code>register_lambda_context</code> function from your idempotency config to calculate and include the remaining invocation time in your idempotency record.</p> working_with_lambda_timeout.py<pre><code>import os\n\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(table_name=table)\n\nconfig = IdempotencyConfig()\n\n\n@idempotent_function(data_keyword_argument=\"record\", persistence_store=persistence_layer, config=config)\ndef record_handler(record: SQSRecord):\n    return {\"message\": record[\"body\"]}\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    config.register_lambda_context(context)\n\n    return record_handler(event)\n</code></pre> Mechanics <p>If a second invocation happens after this timestamp, and the record is marked as <code>INPROGRESS</code>, we will run the invocation again as if it was in the <code>EXPIRED</code> state.</p> <p>This means that if an invocation expired during execution, it will be quickly executed again on the next retry.</p>"
        },
        {
            "location": "utilities/idempotency/#handling-exceptions",
            "title": "Handling exceptions",
            "text": "<p>There are two failure modes that can cause new invocations to execute your code again despite having the same payload:</p> <ul> <li>Unhandled exception. We catch them to delete the idempotency record to prevent inconsistencies, then propagate them.</li> <li>Persistent layer errors. We raise <code>IdempotencyPersistenceLayerError</code> for any persistence layer errors e.g., remove idempotency record.</li> </ul> <p>If an exception is handled or raised outside your decorated function, then idempotency will be maintained.</p> working_with_exceptions.py<pre><code>import os\n\nimport requests\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.idempotency.exceptions import IdempotencyPersistenceLayerError\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(table_name=table)\n\nconfig = IdempotencyConfig()\n\n\n@idempotent_function(data_keyword_argument=\"data\", config=config, persistence_store=persistence_layer)\ndef call_external_service(data: dict):\n    # Any exception raised will lead to idempotency record to be deleted\n    result: requests.Response = requests.post(\n        \"https://jsonplaceholder.typicode.com/comments/\",\n        json=data,\n    )\n    return result.json()\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        call_external_service(data=event)\n    except IdempotencyPersistenceLayerError as e:\n        # No idempotency, but you can decide to error differently.\n        raise RuntimeError(f\"Oops, can't talk to persistence layer. Permissions? error: {e}\")\n\n    # This exception will not impact the idempotency of 'call_external_service'\n    # because it happens in isolation, or outside their scope.\n    raise SyntaxError(\"Oops, this shouldn't be here.\")\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#persistence-layers",
            "title": "Persistence layers",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#dynamodbpersistencelayer",
            "title": "DynamoDBPersistenceLayer",
            "text": "<p>This persistence layer is built-in, allowing you to use an existing DynamoDB table or create a new one dedicated to idempotency state (recommended).</p> customize_persistence_layer.py<pre><code>import os\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(\n    table_name=table,\n    key_attr=\"idempotency_key\",\n    expiry_attr=\"expires_at\",\n    in_progress_expiry_attr=\"in_progress_expires_at\",\n    status_attr=\"current_status\",\n    data_attr=\"result_data\",\n    validation_key_attr=\"validation_key\",\n)\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return event\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#using-a-composite-primary-key",
            "title": "Using a composite primary key",
            "text": "<p>Use <code>sort_key_attr</code> parameter when your table is configured with a composite primary key (hash+range key).</p> <p>When enabled, we will save the idempotency key in the sort key instead. By default, the primary key will now be set to <code>idempotency#{LAMBDA_FUNCTION_NAME}</code>.</p> <p>You can optionally set a static value for the partition key using the <code>static_pk_value</code> parameter.</p> Reusing a DynamoDB table that uses a composite primary keySample Event <pre><code>import os\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(table_name=table, sort_key_attr=\"sort_key\")\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    user_id: str = event.get(\"body\", \"\")[\"user_id\"]\n    return {\"message\": \"success\", \"user_id\": user_id}\n</code></pre> <pre><code>{\n  \"body\": \"{\\\"user_id\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\"\n}\n</code></pre> Click to expand and learn how table items would look like id sort_key expiration status data idempotency#MyLambdaFunction 1e956ef7da78d0cb890be999aecc0c9e 1636549553 COMPLETED {\"user_id\": 12391, \"message\": \"success\"} idempotency#MyLambdaFunction 2b2cdb5f86361e97b4383087c1ffdf27 1636549571 COMPLETED {\"user_id\": 527212, \"message\": \"success\"} idempotency#MyLambdaFunction f091d2527ad1c78f05d54cc3f363be80 1636549585 IN_PROGRESS"
        },
        {
            "location": "utilities/idempotency/#dynamodb-attributes",
            "title": "DynamoDB attributes",
            "text": "<p>You can customize the attribute names during initialization:</p> Parameter Required Default Description table_name Table name to store state key_attr <code>id</code> Partition key of the table. Hashed representation of the payload (unless sort_key_attr is specified) expiry_attr <code>expiration</code> Unix timestamp of when record expires in_progress_expiry_attr <code>in_progress_expiration</code> Unix timestamp of when record expires while in progress (in case of the invocation times out) status_attr <code>status</code> Stores status of the lambda execution during and after invocation data_attr <code>data</code> Stores results of successfully executed Lambda handlers validation_key_attr <code>validation</code> Hashed representation of the parts of the event used for validation sort_key_attr Sort key of the table (if table is configured with a sort key). static_pk_value <code>idempotency#{LAMBDA_FUNCTION_NAME}</code> Static value to use as the partition key. Only used when sort_key_attr is set."
        },
        {
            "location": "utilities/idempotency/#redispersistencelayer",
            "title": "RedisPersistenceLayer",
            "text": "<p>We recommend Redis version 7 or higher for optimal performance.</p> <p>For simple setups, initialize <code>RedisCachePersistenceLayer</code> with your Redis endpoint and port to connect.</p> <p>For security, we enforce SSL connections by default; to disable it, set <code>ssl=False</code>.</p> Redis quick startUsing an existing Redis clientSample event getting_started_with_idempotency_redis_config.py<pre><code>import os\nfrom dataclasses import dataclass, field\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.idempotency.persistence.redis import (\n    RedisCachePersistenceLayer,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nredis_endpoint = os.getenv(\"REDIS_CLUSTER_ENDPOINT\", \"localhost\")\npersistence_layer = RedisCachePersistenceLayer(host=redis_endpoint, port=6379)\n\n\n@dataclass\nclass Payment:\n    user_id: str\n    product_id: str\n    payment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass PaymentError(Exception): ...\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        payment: Payment = create_subscription_payment(event)\n        return {\n            \"payment_id\": payment.payment_id,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n    except Exception as exc:\n        raise PaymentError(f\"Error creating payment {str(exc)}\")\n\n\ndef create_subscription_payment(event: dict) -&gt; Payment:\n    return Payment(**event)\n</code></pre> getting_started_with_idempotency_redis_client.py<pre><code>import os\nfrom dataclasses import dataclass, field\nfrom uuid import uuid4\n\nfrom redis import Redis\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.idempotency.persistence.redis import (\n    RedisCachePersistenceLayer,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nredis_endpoint = os.getenv(\"REDIS_CLUSTER_ENDPOINT\", \"localhost\")\nclient = Redis(\n    host=redis_endpoint,\n    port=6379,\n    socket_connect_timeout=5,\n    socket_timeout=5,\n    max_connections=1000,\n)\n\npersistence_layer = RedisCachePersistenceLayer(client=client)\n\n\n@dataclass\nclass Payment:\n    user_id: str\n    product_id: str\n    payment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass PaymentError(Exception): ...\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        payment: Payment = create_subscription_payment(event)\n        return {\n            \"payment_id\": payment.payment_id,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n    except Exception as exc:\n        raise PaymentError(f\"Error creating payment {str(exc)}\")\n\n\ndef create_subscription_payment(event: dict) -&gt; Payment:\n    return Payment(**event)\n</code></pre> getting_started_with_idempotency_payload.json<pre><code>{\n  \"user_id\": \"xyz\",\n  \"product_id\": \"123456789\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#redis-ssl-connections",
            "title": "Redis SSL connections",
            "text": "<p>We recommend using AWS Secrets Manager to store and rotate certificates safely, and the Parameters feature to fetch and cache optimally.</p> <p>For advanced configurations, we recommend using an existing Redis client for optimal compatibility like SSL certificates and timeout.</p> Advanced configuration using AWS SecretsAdvanced configuration with local certificates using_redis_client_with_aws_secrets.py<pre><code>from __future__ import annotations\n\nfrom typing import Any\n\nfrom redis import Redis\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.idempotency import IdempotencyConfig, idempotent\nfrom aws_lambda_powertools.utilities.idempotency.persistence.redis import (\n    RedisCachePersistenceLayer,\n)\n\nredis_values: dict[str, Any] = parameters.get_secret(\"redis_info\", transform=\"json\")  # (1)!\n\nredis_client = Redis(\n    host=redis_values.get(\"REDIS_HOST\", \"localhost\"),\n    port=redis_values.get(\"REDIS_PORT\", 6379),\n    password=redis_values.get(\"REDIS_PASSWORD\"),\n    decode_responses=True,\n    socket_timeout=10.0,\n    ssl=True,\n    retry_on_timeout=True,\n)\n\npersistence_layer = RedisCachePersistenceLayer(client=redis_client)\nconfig = IdempotencyConfig(\n    expires_after_seconds=2 * 60,  # 2 minutes\n)\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event, context):\n    return {\"message\": \"Hello\"}\n</code></pre> <ol> <li>JSON stored: <pre><code>{\n\"REDIS_ENDPOINT\": \"127.0.0.1\",\n\"REDIS_PORT\": \"6379\",\n\"REDIS_PASSWORD\": \"redis-secret\"\n}\n</code></pre></li> </ol> using_redis_client_with_local_certs.py<pre><code>from __future__ import annotations\n\nfrom typing import Any\n\nfrom redis import Redis\n\nfrom aws_lambda_powertools.shared.functions import abs_lambda_path\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.idempotency import IdempotencyConfig, idempotent\nfrom aws_lambda_powertools.utilities.idempotency.persistence.redis import (\n    RedisCachePersistenceLayer,\n)\n\nredis_values: dict[str, Any] = parameters.get_secret(\"redis_info\", transform=\"json\")  # (1)!\n\n\nredis_client = Redis(\n    host=redis_values.get(\"REDIS_HOST\", \"localhost\"),\n    port=redis_values.get(\"REDIS_PORT\", 6379),\n    password=redis_values.get(\"REDIS_PASSWORD\"),\n    decode_responses=True,\n    socket_timeout=10.0,\n    ssl=True,\n    retry_on_timeout=True,\n    ssl_certfile=f\"{abs_lambda_path()}/certs/redis_user.crt\",  # (2)!\n    ssl_keyfile=f\"{abs_lambda_path()}/certs/redis_user_private.key\",  # (3)!\n    ssl_ca_certs=f\"{abs_lambda_path()}/certs/redis_ca.pem\",  # (4)!\n)\n\npersistence_layer = RedisCachePersistenceLayer(client=redis_client)\nconfig = IdempotencyConfig(\n    expires_after_seconds=2 * 60,  # 2 minutes\n)\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event, context):\n    return {\"message\": \"Hello\"}\n</code></pre> <ol> <li>JSON stored: <pre><code>{\n\"REDIS_ENDPOINT\": \"127.0.0.1\",\n\"REDIS_PORT\": \"6379\",\n\"REDIS_PASSWORD\": \"redis-secret\"\n}\n</code></pre></li> <li>redis_user.crt file stored in the \"certs\" directory of your Lambda function</li> <li>redis_user_private.key file stored in the \"certs\" directory of your Lambda function</li> <li>redis_ca.pem file stored in the \"certs\" directory of your Lambda function</li> </ol>"
        },
        {
            "location": "utilities/idempotency/#redis-attributes",
            "title": "Redis attributes",
            "text": "<p>You can customize the attribute names during initialization:</p> Parameter Required Default Description in_progress_expiry_attr <code>in_progress_expiration</code> Unix timestamp of when record expires while in progress (in case of the invocation times out) status_attr <code>status</code> Stores status of the Lambda execution during and after invocation data_attr <code>data</code> Stores results of successfully executed Lambda handlers validation_key_attr <code>validation</code> Hashed representation of the parts of the event used for validation customize_persistence_layer_redis.py<pre><code>import os\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.idempotency.persistence.redis import (\n    RedisCachePersistenceLayer,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nredis_endpoint = os.getenv(\"REDIS_CLUSTER_ENDPOINT\", \"localhost\")\npersistence_layer = RedisCachePersistenceLayer(\n    host=redis_endpoint,\n    port=6379,\n    in_progress_expiry_attr=\"in_progress_expiration\",\n    status_attr=\"status\",\n    data_attr=\"data\",\n    validation_key_attr=\"validation\",\n)\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return event\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#common-use-cases",
            "title": "Common use cases",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#batch-processing",
            "title": "Batch processing",
            "text": "<p>You can can easily integrate with Batch using the idempotent_function decorator to handle idempotency per message/record in a given batch.</p> Choosing an unique batch record attribute <p>In this example, we choose <code>messageId</code> as our idempotency key since we know it'll be unique.</p> <p>Depending on your use case, it might be more accurate to choose another field your producer intentionally set to define uniqueness.</p> Integration with Batch ProcessorSample event integrate_idempotency_with_batch_processor.py<pre><code>import os\nfrom typing import Any, Dict\n\nfrom aws_lambda_powertools.utilities.batch import BatchProcessor, EventType, process_partial_response\nfrom aws_lambda_powertools.utilities.data_classes.sqs_event import SQSRecord\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nprocessor = BatchProcessor(event_type=EventType.SQS)\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\ndynamodb = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(event_key_jmespath=\"messageId\")\n\n\n@idempotent_function(data_keyword_argument=\"record\", config=config, persistence_store=dynamodb)\ndef record_handler(record: SQSRecord):\n    return {\"message\": record.body}\n\n\ndef lambda_handler(event: Dict[str, Any], context: LambdaContext):\n    config.register_lambda_context(context)  # see Lambda timeouts section\n\n    return process_partial_response(\n        event=event,\n        context=context,\n        processor=processor,\n        record_handler=record_handler,\n    )\n</code></pre> integrate_idempotency_with_batch_processor_payload.json<pre><code>{\n  \"Records\": [\n    {\n      \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n      \"body\": \"Test message.\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082649183\",\n        \"SenderId\": \"replace-to-pass-gitleak\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n      },\n      \"messageAttributes\": {\n        \"testAttr\": {\n          \"stringValue\": \"100\",\n          \"binaryValue\": \"base64Str\",\n          \"dataType\": \"Number\"\n        }\n      },\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:my-queue\",\n      \"awsRegion\": \"us-east-2\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#idempotency-request-flow",
            "title": "Idempotency request flow",
            "text": "<p>The following sequence diagrams explain how the Idempotency feature behaves under different scenarios.</p>"
        },
        {
            "location": "utilities/idempotency/#successful-request",
            "title": "Successful request",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Persistence Layer--&gt;&gt;Lambda: Already exists in persistence layer.\n        deactivate Persistence Layer\n        Note over Lambda,Persistence Layer: Record status is COMPLETE and not expired\n        Lambda--&gt;&gt;Client: Same response sent to client\n    end</code></pre> Idempotent successful request </p>"
        },
        {
            "location": "utilities/idempotency/#successful-request-with-cache-enabled",
            "title": "Successful request with cache enabled",
            "text": "<p>In-memory cache is disabled by default.</p> <p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n      Client-&gt;&gt;Lambda: Invoke (event)\n      Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n      activate Persistence Layer\n      Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n      Lambda--&gt;&gt;Lambda: Call your function\n      Lambda-&gt;&gt;Persistence Layer: Update record with result\n      deactivate Persistence Layer\n      Persistence Layer--&gt;&gt;Persistence Layer: Update record\n      Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n      Lambda--&gt;&gt;Lambda: Save record and result in memory\n      Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n      Client-&gt;&gt;Lambda: Invoke (event)\n      Lambda--&gt;&gt;Lambda: Get idempotency_key=hash(payload)\n      Note over Lambda,Persistence Layer: Record status is COMPLETE and not expired\n      Lambda--&gt;&gt;Client: Same response sent to client\n    end</code></pre> Idempotent successful request cached </p>"
        },
        {
            "location": "utilities/idempotency/#successful-request-with-response_hook-configured",
            "title": "Successful request with response_hook configured",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Response hook\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Persistence Layer--&gt;&gt;Response hook: Already exists in persistence layer.\n        deactivate Persistence Layer\n        Note over Response hook,Persistence Layer: Record status is COMPLETE and not expired\n        Response hook-&gt;&gt;Lambda: Response hook invoked\n        Lambda--&gt;&gt;Client: Manipulated idempotent response sent to client\n    end</code></pre> Successful idempotent request with a response hook </p>"
        },
        {
            "location": "utilities/idempotency/#expired-idempotency-records",
            "title": "Expired idempotency records",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Persistence Layer--&gt;&gt;Lambda: Already exists in persistence layer.\n        deactivate Persistence Layer\n        Note over Lambda,Persistence Layer: Record status is COMPLETE but expired hours ago\n        loop Repeat initial request process\n            Note over Lambda,Persistence Layer: 1. Set record to INPROGRESS, &lt;br&gt; 2. Call your function, &lt;br&gt; 3. Set record to COMPLETE\n        end\n        Lambda--&gt;&gt;Client: Same response sent to client\n    end</code></pre> Previous Idempotent request expired </p>"
        },
        {
            "location": "utilities/idempotency/#concurrent-identical-in-flight-requests",
            "title": "Concurrent identical in-flight requests",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n    activate Persistence Layer\n    Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n      par Second request\n          Client-&gt;&gt;Lambda: Invoke (event)\n          Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n          Lambda--xLambda: IdempotencyAlreadyInProgressError\n          Lambda-&gt;&gt;Client: Error sent to client if unhandled\n      end\n    Lambda--&gt;&gt;Lambda: Call your function\n    Lambda-&gt;&gt;Persistence Layer: Update record with result\n    deactivate Persistence Layer\n    Persistence Layer--&gt;&gt;Persistence Layer: Update record\n    Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n    Lambda--&gt;&gt;Client: Response sent to client</code></pre> Concurrent identical in-flight requests </p>"
        },
        {
            "location": "utilities/idempotency/#unhandled-exception",
            "title": "Unhandled exception",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;Persistence Layer: Get or set (id=event.search(payload))\n    activate Persistence Layer\n    Note right of Persistence Layer: Locked during this time. Prevents multiple&lt;br/&gt;Lambda invocations with the same&lt;br/&gt;payload running concurrently.\n    Lambda--xLambda: Call handler (event).&lt;br/&gt;Raises exception\n    Lambda-&gt;&gt;Persistence Layer: Delete record (id=event.search(payload))\n    deactivate Persistence Layer\n    Lambda--&gt;&gt;Client: Return error response</code></pre> Idempotent sequence exception </p>"
        },
        {
            "location": "utilities/idempotency/#lambda-request-timeout",
            "title": "Lambda request timeout",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Note right of Lambda: Time out\n        Lambda--xLambda: Time out error\n        Lambda--&gt;&gt;Client: Return error response\n        deactivate Persistence Layer\n    else retry after Lambda timeout elapses\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Reset in_progress_expiry attribute\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Lambda--&gt;&gt;Client: Response sent to client\n    end</code></pre> Idempotent request during and after Lambda timeouts </p>"
        },
        {
            "location": "utilities/idempotency/#optional-idempotency-key",
            "title": "Optional idempotency key",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt request with idempotency key\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else request(s) without idempotency key\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Note over Lambda: Idempotency key is missing\n        Note over Persistence Layer: Skips any operation to fetch, update, and delete\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda--&gt;&gt;Client: Response sent to client\n    end</code></pre> Optional idempotency key </p>"
        },
        {
            "location": "utilities/idempotency/#race-condition-with-redis",
            "title": "Race condition with Redis",
            "text": "<p> <pre><code>graph TD;\n    A(Existing orphan record in redis)--&gt;A1;\n    A1[Two Lambda invoke at same time]--&gt;B1[Lambda handler1];\n    B1--&gt;B2[Fetch from Redis];\n    B2--&gt;B3[Handler1 got orphan record];\n    B3--&gt;B4[Handler1 acquired lock];\n    B4--&gt;B5[Handler1 overwrite orphan record]\n    B5--&gt;B6[Handler1 continue to execution];\n    A1--&gt;C1[Lambda handler2];\n    C1--&gt;C2[Fetch from Redis];\n    C2--&gt;C3[Handler2 got orphan record];\n    C3--&gt;C4[Handler2 failed to acquire lock];\n    C4--&gt;C5[Handler2 wait and fetch from Redis];\n    C5--&gt;C6[Handler2 return without executing];\n    B6--&gt;D(Lambda handler executed only once);\n    C6--&gt;D;</code></pre> Race condition with Redis </p>"
        },
        {
            "location": "utilities/idempotency/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#customizing-the-default-behavior",
            "title": "Customizing the default behavior",
            "text": "<p>You can override and further extend idempotency behavior via <code>IdempotencyConfig</code> with the following options:</p> Parameter Default Description event_key_jmespath <code>\"\"</code> JMESPath expression to extract the idempotency key from the event record using built-in functions payload_validation_jmespath <code>\"\"</code> JMESPath expression to validate that the specified fields haven't changed across requests for the same idempotency key e.g., payload tampering. raise_on_no_idempotency_key <code>False</code> Raise exception if no idempotency key was found in the request expires_after_seconds 3600 The number of seconds to wait before a record is expired, allowing a new transaction with the same idempotency key use_local_cache <code>False</code> Whether to cache idempotency results in-memory to save on persistence storage latency and costs local_cache_max_items 256 Max number of items to store in local cache hash_function <code>md5</code> Function to use for calculating hashes, as provided by hashlib in the standard library. response_hook <code>None</code> Function to use for processing the stored Idempotent response. This function hook is called when an existing idempotent response is found. See Manipulating The Idempotent Response"
        },
        {
            "location": "utilities/idempotency/#handling-concurrent-executions-with-the-same-payload",
            "title": "Handling concurrent executions with the same payload",
            "text": "<p>This utility will raise an <code>IdempotencyAlreadyInProgressError</code> exception if you receive multiple invocations with the same payload while the first invocation hasn't completed yet.</p> Info <p>If you receive <code>IdempotencyAlreadyInProgressError</code>, you can safely retry the operation.</p> <p>This is a locking mechanism for correctness. Since we don't know the result from the first invocation yet, we can't safely allow another concurrent execution.</p>"
        },
        {
            "location": "utilities/idempotency/#payload-validation",
            "title": "Payload validation",
            "text": "Question: What if your function is invoked with the same payload except some outer parameters have changed? <p>Example: A payment transaction for a given productID was requested twice for the same customer, however the amount to be paid has changed in the second transaction.</p> <p>By default, we will return the same result as it returned before, however in this instance it may be misleading; we provide a fail fast payload validation to address this edge case.</p> <p>With <code>payload_validation_jmespath</code>, you can provide an additional JMESPath expression to specify which part of the event body should be validated against previous idempotent invocations</p> Payload validationSample event 1Sample event 2 <pre><code>import os\nfrom dataclasses import dataclass, field\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.idempotency.exceptions import IdempotencyValidationError\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(\n    event_key_jmespath='[\"user_id\", \"product_id\"]',\n    payload_validation_jmespath=\"amount\",\n)\n\n\n@dataclass\nclass Payment:\n    user_id: str\n    product_id: str\n    charge_type: str\n    amount: int\n    payment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass PaymentError(Exception): ...\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        payment: Payment = create_subscription_payment(event)\n        return {\n            \"payment_id\": payment.payment_id,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n    except IdempotencyValidationError:\n        logger.exception(\"Payload tampering detected\", payment=payment, failure_type=\"validation\")\n        return {\n            \"message\": \"Unable to process payment at this time. Try again later.\",\n            \"statusCode\": 500,\n        }\n    except Exception as exc:\n        raise PaymentError(f\"Error creating payment {str(exc)}\")\n\n\ndef create_subscription_payment(event: dict) -&gt; Payment:\n    return Payment(**event)\n</code></pre> <pre><code>{\n  \"user_id\": 1,\n  \"product_id\": 1500,\n  \"charge_type\": \"subscription\",\n  \"amount\": 500\n}\n</code></pre> <pre><code>{\n  \"user_id\": 1,\n  \"product_id\": 1500,\n  \"charge_type\": \"subscription\",\n  \"amount\": 10\n}\n</code></pre> <p>In this example, the <code>user_id</code> and <code>product_id</code> keys are used as the payload to generate the idempotency key, as per <code>event_key_jmespath</code> parameter.</p> Note <p>If we try to send the same request but with a different amount, we will raise <code>IdempotencyValidationError</code>.</p> <p>Without payload validation, we would have returned the same result as we did for the initial request. Since we're also returning an amount in the response, this could be quite confusing for the client.</p> <p>By using <code>payload_validation_jmespath=\"amount\"</code>, we prevent this potentially confusing behavior and instead raise an Exception.</p>"
        },
        {
            "location": "utilities/idempotency/#making-idempotency-key-required",
            "title": "Making idempotency key required",
            "text": "<p>If you want to enforce that an idempotency key is required, you can set <code>raise_on_no_idempotency_key</code> to <code>True</code>.</p> <p>This means that we will raise <code>IdempotencyKeyError</code> if the evaluation of <code>event_key_jmespath</code> is <code>None</code>.</p> Warning <p>To prevent errors, transactions will not be treated as idempotent if <code>raise_on_no_idempotency_key</code> is set to <code>False</code> and the evaluation of <code>event_key_jmespath</code> is <code>None</code>. Therefore, no data will be fetched, stored, or deleted in the idempotency storage layer.</p> Idempotency key requiredSuccess EventFailure Event <pre><code>import os\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(\n    event_key_jmespath='[\"user.uid\", \"order_id\"]',\n    raise_on_no_idempotency_key=True,\n)\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return event\n</code></pre> <pre><code>{\n  \"user\": {\n    \"uid\": \"BB0D045C-8878-40C8-889E-38B3CB0A61B1\",\n    \"name\": \"Foo\"\n  },\n  \"order_id\": 10000\n}\n</code></pre> <pre><code>{\n  \"user\": {\n    \"uid\": \"BB0D045C-8878-40C8-889E-38B3CB0A61B1\",\n    \"name\": \"Foo\",\n    \"order_id\": 10000\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#customizing-boto-configuration",
            "title": "Customizing boto configuration",
            "text": "<p>The <code>boto_config</code> and <code>boto3_session</code> parameters enable you to pass in a custom botocore config object or a custom boto3 session when constructing the persistence store.</p> Custom sessionCustom configSample Event <pre><code>import os\n\nimport boto3\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# See: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html#module-boto3.session\nboto3_session = boto3.session.Session()\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(table_name=table, boto3_session=boto3_session)\n\nconfig = IdempotencyConfig(event_key_jmespath=\"body\")\n\n\n@idempotent(persistence_store=persistence_layer, config=config)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return event\n</code></pre> <pre><code>import os\n\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# See: https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html#botocore-config\nboto_config = Config()\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\npersistence_layer = DynamoDBPersistenceLayer(table_name=table, boto_config=boto_config)\n\nconfig = IdempotencyConfig(event_key_jmespath=\"body\")\n\n\n@idempotent(persistence_store=persistence_layer, config=config)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return event\n</code></pre> <pre><code>{\n  \"body\": \"{\\\"user_id\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#bring-your-own-persistent-store",
            "title": "Bring your own persistent store",
            "text": "<p>This utility provides an abstract base class (ABC), so that you can implement your choice of persistent storage layer.</p> <p>You can create your own persistent store from scratch by inheriting the <code>BasePersistenceLayer</code> class, and implementing <code>_get_record()</code>, <code>_put_record()</code>, <code>_update_record()</code> and <code>_delete_record()</code>.</p> <ul> <li><code>_get_record()</code> – Retrieves an item from the persistence store using an idempotency key and returns it as a <code>DataRecord</code> instance.</li> <li><code>_put_record()</code> – Adds a <code>DataRecord</code> to the persistence store if it doesn't already exist with that key. Raises an <code>ItemAlreadyExists</code> exception if a non-expired entry already exists.</li> <li><code>_update_record()</code> – Updates an item in the persistence store.</li> <li><code>_delete_record()</code> – Removes an item from the persistence store.</li> </ul> bring_your_own_persistent_store.py<pre><code>import datetime\nimport logging\nfrom typing import Any, Dict, Optional\n\nimport boto3\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities.idempotency import BasePersistenceLayer\nfrom aws_lambda_powertools.utilities.idempotency.exceptions import (\n    IdempotencyItemAlreadyExistsError,\n    IdempotencyItemNotFoundError,\n)\nfrom aws_lambda_powertools.utilities.idempotency.persistence.base import DataRecord\n\nlogger = logging.getLogger(__name__)\n\n\nclass MyOwnPersistenceLayer(BasePersistenceLayer):\n    def __init__(\n        self,\n        table_name: str,\n        key_attr: str = \"id\",\n        expiry_attr: str = \"expiration\",\n        status_attr: str = \"status\",\n        data_attr: str = \"data\",\n        validation_key_attr: str = \"validation\",\n        boto_config: Optional[Config] = None,\n        boto3_session: Optional[boto3.session.Session] = None,\n    ):\n        boto3_session = boto3_session or boto3.session.Session()\n        self._ddb_resource = boto3_session.resource(\"dynamodb\", config=boto_config)\n        self.table_name = table_name\n        self.table = self._ddb_resource.Table(self.table_name)\n        self.key_attr = key_attr\n        self.expiry_attr = expiry_attr\n        self.status_attr = status_attr\n        self.data_attr = data_attr\n        self.validation_key_attr = validation_key_attr\n        super().__init__()\n\n    def _item_to_data_record(self, item: Dict[str, Any]) -&gt; DataRecord:\n        \"\"\"\n        Translate raw item records from DynamoDB to DataRecord\n\n        Parameters\n        ----------\n        item: Dict[str, Union[str, int]]\n                Item format from dynamodb response\n\n        Returns\n        -------\n        DataRecord\n                representation of item\n\n        \"\"\"\n        return DataRecord(\n            idempotency_key=item[self.key_attr],\n            status=item[self.status_attr],\n            expiry_timestamp=item[self.expiry_attr],\n            response_data=item.get(self.data_attr, \"\"),\n            payload_hash=item.get(self.validation_key_attr, \"\"),\n        )\n\n    def _get_record(self, idempotency_key) -&gt; DataRecord:\n        response = self.table.get_item(Key={self.key_attr: idempotency_key}, ConsistentRead=True)\n\n        try:\n            item = response[\"Item\"]\n        except KeyError:\n            raise IdempotencyItemNotFoundError\n        return self._item_to_data_record(item)\n\n    def _put_record(self, data_record: DataRecord) -&gt; None:\n        item = {\n            self.key_attr: data_record.idempotency_key,\n            self.expiry_attr: data_record.expiry_timestamp,\n            self.status_attr: data_record.status,\n        }\n\n        if self.payload_validation_enabled:\n            item[self.validation_key_attr] = data_record.payload_hash\n\n        now = datetime.datetime.now()\n        try:\n            logger.debug(f\"Putting record for idempotency key: {data_record.idempotency_key}\")\n            self.table.put_item(\n                Item=item,\n                ConditionExpression=f\"attribute_not_exists({self.key_attr}) OR {self.expiry_attr} &lt; :now\",\n                ExpressionAttributeValues={\":now\": int(now.timestamp())},\n            )\n        except self._ddb_resource.meta.client.exceptions.ConditionalCheckFailedException:\n            logger.debug(f\"Failed to put record for already existing idempotency key: {data_record.idempotency_key}\")\n            raise IdempotencyItemAlreadyExistsError\n\n    def _update_record(self, data_record: DataRecord):\n        logger.debug(f\"Updating record for idempotency key: {data_record.idempotency_key}\")\n        update_expression = \"SET #response_data = :response_data, #expiry = :expiry, #status = :status\"\n        expression_attr_values = {\n            \":expiry\": data_record.expiry_timestamp,\n            \":response_data\": data_record.response_data,\n            \":status\": data_record.status,\n        }\n        expression_attr_names = {\n            \"#response_data\": self.data_attr,\n            \"#expiry\": self.expiry_attr,\n            \"#status\": self.status_attr,\n        }\n\n        if self.payload_validation_enabled:\n            update_expression += \", #validation_key = :validation_key\"\n            expression_attr_values[\":validation_key\"] = data_record.payload_hash\n            expression_attr_names[\"#validation_key\"] = self.validation_key_attr\n\n        self.table.update_item(\n            Key={self.key_attr: data_record.idempotency_key},\n            UpdateExpression=update_expression,\n            ExpressionAttributeValues=expression_attr_values,\n            ExpressionAttributeNames=expression_attr_names,\n        )\n\n    def _delete_record(self, data_record: DataRecord) -&gt; None:\n        logger.debug(f\"Deleting record for idempotency key: {data_record.idempotency_key}\")\n        self.table.delete_item(\n            Key={self.key_attr: data_record.idempotency_key},\n        )\n</code></pre> Danger <p>Pay attention to the documentation for each - you may need to perform additional checks inside these methods to ensure the idempotency guarantees remain intact.</p> <p>For example, the <code>_put_record</code> method needs to raise an exception if a non-expired record already exists in the data store with a matching key.</p>"
        },
        {
            "location": "utilities/idempotency/#manipulating-the-idempotent-response",
            "title": "Manipulating the Idempotent Response",
            "text": "<p>You can set up a <code>response_hook</code> in the <code>IdempotentConfig</code> class to manipulate the returned data when an operation is idempotent. The hook function will be called with the current deserialized response object and the Idempotency record.</p> Using an Idempotent Response HookSample event <pre><code>import os\nimport uuid\nfrom typing import Dict\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent_function,\n)\nfrom aws_lambda_powertools.utilities.idempotency.persistence.datarecord import (\n    DataRecord,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef my_response_hook(response: Dict, idempotent_data: DataRecord) -&gt; Dict:\n    # Return inserted Header data into the Idempotent Response\n    response[\"x-idempotent-key\"] = idempotent_data.idempotency_key\n\n    # expiry_timestamp can be None so include if set\n    expiry_timestamp = idempotent_data.get_expiration_datetime()\n    if expiry_timestamp:\n        response[\"x-idempotent-expiration\"] = expiry_timestamp.isoformat()\n\n    # Must return the response here\n    return response\n\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\ndynamodb = DynamoDBPersistenceLayer(table_name=table)\nconfig = IdempotencyConfig(response_hook=my_response_hook)\n\n\n@idempotent_function(data_keyword_argument=\"order\", config=config, persistence_store=dynamodb)\ndef process_order(order: dict) -&gt; dict:\n    # create the order_id\n    order_id = str(uuid.uuid4())\n\n    # create your logic to save the order\n    # append the order_id created\n    order[\"order_id\"] = order_id\n\n    # return the order\n    return {\"order\": order}\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    config.register_lambda_context(context)  # see Lambda timeouts section\n    try:\n        logger.info(f\"Processing order id {event.get('order_id')}\")\n        return process_order(order=event.get(\"order\"))\n    except Exception as err:\n        return {\"status_code\": 400, \"error\": f\"Error processing {str(err)}\"}\n</code></pre> <pre><code>{\n  \"order\" : {\n    \"user_id\": \"xyz\",\n    \"product_id\": \"123456789\",\n    \"quantity\": 2,\n    \"value\": 30\n  }\n}\n</code></pre> Info: Using custom de-serialization? <p>The response_hook is called after the custom de-serialization so the payload you process will be the de-serialized version.</p>"
        },
        {
            "location": "utilities/idempotency/#being-a-good-citizen",
            "title": "Being a good citizen",
            "text": "<p>When using response hooks to manipulate returned data from idempotent operations, it's important to follow best practices to avoid introducing complexity or issues. Keep these guidelines in mind:</p> <ol> <li> <p>Response hook works exclusively when operations are idempotent. The hook will not be called when an operation is not idempotent, or when the idempotent logic fails.</p> </li> <li> <p>Catch and Handle Exceptions. Your response hook code should catch and handle any exceptions that may arise from your logic. Unhandled exceptions will cause the Lambda function to fail unexpectedly.</p> </li> <li> <p>Keep Hook Logic Simple Response hooks should consist of minimal and straightforward logic for manipulating response data. Avoid complex conditional branching and aim for hooks that are easy to reason about.</p> </li> </ol>"
        },
        {
            "location": "utilities/idempotency/#compatibility-with-other-utilities",
            "title": "Compatibility with other utilities",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#json-schema-validation",
            "title": "JSON Schema Validation",
            "text": "<p>The idempotency utility can be used with the <code>validator</code> decorator. Ensure that idempotency is the innermost decorator.</p> Warning <p>If you use an envelope with the validator, the event received by the idempotency utility will be the unwrapped event - not the \"raw\" event Lambda was invoked with.</p> <p>Make sure to account for this behavior, if you set the <code>event_key_jmespath</code>.</p> Using Idempotency with validation utilitySample Event <pre><code>import os\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import envelopes, validator\n\ntable = os.getenv(\"IDEMPOTENCY_TABLE\", \"\")\nconfig = IdempotencyConfig(event_key_jmespath='[\"message\", \"username\"]')\npersistence_layer = DynamoDBPersistenceLayer(table_name=table)\n\n\n@validator(envelope=envelopes.API_GATEWAY_HTTP)\n@idempotent(config=config, persistence_store=persistence_layer)\ndef lambda_handler(event, context: LambdaContext):\n    return {\"message\": event[\"message\"], \"statusCode\": 200}\n</code></pre> <pre><code>{\n  \"version\": \"2.0\",\n  \"routeKey\": \"$default\",\n  \"rawPath\": \"/my/path\",\n  \"rawQueryString\": \"parameter1=value1&amp;parameter1=value2&amp;parameter2=value\",\n  \"cookies\": [\n    \"cookie1\",\n    \"cookie2\"\n  ],\n  \"headers\": {\n    \"Header1\": \"value1\",\n    \"Header2\": \"value1,value2\"\n  },\n  \"queryStringParameters\": {\n    \"parameter1\": \"value1,value2\",\n    \"parameter2\": \"value\"\n  },\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"apiId\": \"api-id\",\n    \"authentication\": {\n      \"clientCert\": {\n        \"clientCertPem\": \"CERT_CONTENT\",\n        \"subjectDN\": \"www.example.com\",\n        \"issuerDN\": \"Example issuer\",\n        \"serialNumber\": \"a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1:a1\",\n        \"validity\": {\n          \"notBefore\": \"May 28 12:30:02 2019 GMT\",\n          \"notAfter\": \"Aug  5 09:36:04 2021 GMT\"\n        }\n      }\n    },\n    \"authorizer\": {\n      \"jwt\": {\n        \"claims\": {\n          \"claim1\": \"value1\",\n          \"claim2\": \"value2\"\n        },\n        \"scopes\": [\n          \"scope1\",\n          \"scope2\"\n        ]\n      }\n    },\n    \"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n    \"domainPrefix\": \"id\",\n    \"http\": {\n      \"method\": \"POST\",\n      \"path\": \"/my/path\",\n      \"protocol\": \"HTTP/1.1\",\n      \"sourceIp\": \"192.168.0.1/32\",\n      \"userAgent\": \"agent\"\n    },\n    \"requestId\": \"id\",\n    \"routeKey\": \"$default\",\n    \"stage\": \"$default\",\n    \"time\": \"12/Mar/2020:19:03:58 +0000\",\n    \"timeEpoch\": 1583348638390\n  },\n  \"body\": \"{\\\"message\\\": \\\"hello world\\\", \\\"username\\\": \\\"tom\\\"}\",\n  \"pathParameters\": {\n    \"parameter1\": \"value1\"\n  },\n  \"isBase64Encoded\": false,\n  \"stageVariables\": {\n    \"stageVariable1\": \"value1\",\n    \"stageVariable2\": \"value2\"\n  }\n}\n</code></pre> Tip: JMESPath Powertools for AWS Lambda (Python) functions are also available <p>Built-in functions known in the validation utility like <code>powertools_json</code>, <code>powertools_base64</code>, <code>powertools_base64_gzip</code> are also available to use in this utility.</p>"
        },
        {
            "location": "utilities/idempotency/#tracer",
            "title": "Tracer",
            "text": "<p>The idempotency utility can be used with the <code>tracer</code> decorator. Ensure that idempotency is the innermost decorator.</p>"
        },
        {
            "location": "utilities/idempotency/#first-execution",
            "title": "First execution",
            "text": "<p>During the first execution with a payload, Lambda performs a <code>PutItem</code> followed by an <code>UpdateItem</code> operation to persist the record in DynamoDB.</p> <p></p>"
        },
        {
            "location": "utilities/idempotency/#subsequent-executions",
            "title": "Subsequent executions",
            "text": "<p>On subsequent executions with the same payload, Lambda optimistically tries to save the record in DynamoDB. If the record already exists, DynamoDB returns the item.</p> <p>Explore how to handle conditional write errors in high-concurrency scenarios with DynamoDB in this blog post.</p> <p></p>"
        },
        {
            "location": "utilities/idempotency/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>The idempotency utility provides several routes to test your code.</p>"
        },
        {
            "location": "utilities/idempotency/#disabling-the-idempotency-utility",
            "title": "Disabling the idempotency utility",
            "text": "<p>When testing your code, you may wish to disable the idempotency logic altogether and focus on testing your business logic. To do this, you can set the environment variable <code>POWERTOOLS_IDEMPOTENCY_DISABLED</code> with a truthy value. If you prefer setting this for specific tests, and are using Pytest, you can use monkeypatch fixture:</p> test_disabling_idempotency_utility.pyapp_test_disabling_idempotency_utility.py <pre><code>from dataclasses import dataclass\n\nimport app_test_disabling_idempotency_utility\nimport pytest\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n    aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n    def get_remaining_time_in_millis(self) -&gt; int:\n        return 5\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef test_idempotent_lambda_handler(monkeypatch, lambda_context: LambdaContext):\n    # Set POWERTOOLS_IDEMPOTENCY_DISABLED before calling decorated functions\n    monkeypatch.setenv(\"POWERTOOLS_IDEMPOTENCY_DISABLED\", 1)\n\n    result = app_test_disabling_idempotency_utility.lambda_handler({}, lambda_context)\n\n    assert result\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    print(\"expensive operation\")\n    return {\n        \"payment_id\": 12345,\n        \"message\": \"success\",\n        \"statusCode\": 200,\n    }\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#testing-with-dynamodb-local",
            "title": "Testing with DynamoDB Local",
            "text": "<p>To test with DynamoDB Local, you can replace the <code>DynamoDB client</code> used by the persistence layer with one you create inside your tests. This allows you to set the endpoint_url.</p> test_with_dynamodb_local.pyapp_test_dynamodb_local.py <pre><code>from dataclasses import dataclass\n\nimport app_test_dynamodb_local\nimport boto3\nimport pytest\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n    aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n    def get_remaining_time_in_millis(self) -&gt; int:\n        return 5\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef test_idempotent_lambda(lambda_context):\n    # Configure the boto3 to use the endpoint for the DynamoDB Local instance\n    dynamodb_local_client = boto3.client(\"dynamodb\", endpoint_url=\"http://localhost:8000\")\n    app_test_dynamodb_local.persistence_layer.client = dynamodb_local_client\n\n    # If desired, you can use a different DynamoDB Local table name than what your code already uses\n    # app.persistence_layer.table_name = \"another table name\" # noqa: ERA001\n\n    result = app_test_dynamodb_local.handler({\"testkey\": \"testvalue\"}, lambda_context)\n    assert result[\"payment_id\"] == 12345\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    print(\"expensive operation\")\n    return {\n        \"payment_id\": 12345,\n        \"message\": \"success\",\n        \"statusCode\": 200,\n    }\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#how-do-i-mock-all-dynamodb-io-operations",
            "title": "How do I mock all DynamoDB I/O operations",
            "text": "<p>The idempotency utility lazily creates the dynamodb Table which it uses to access DynamoDB. This means it is possible to pass a mocked Table resource, or stub various methods.</p> test_with_io_operations.pyapp_test_io_operations.py <pre><code>from dataclasses import dataclass\nfrom unittest.mock import MagicMock\n\nimport app_test_io_operations\nimport pytest\n\n\n@dataclass\nclass LambdaContext:\n    function_name: str = \"test\"\n    memory_limit_in_mb: int = 128\n    invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n    aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n    def get_remaining_time_in_millis(self) -&gt; int:\n        return 5\n\n\n@pytest.fixture\ndef lambda_context() -&gt; LambdaContext:\n    return LambdaContext()\n\n\ndef test_idempotent_lambda(lambda_context):\n    mock_client = MagicMock()\n    app_test_io_operations.persistence_layer.client = mock_client\n    result = app_test_io_operations.handler({\"testkey\": \"testvalue\"}, lambda_context)\n    mock_client.put_item.assert_called()\n    assert result\n</code></pre> <pre><code>from aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n\n\n@idempotent(persistence_store=persistence_layer)\ndef lambda_handler(event: dict, context: LambdaContext):\n    print(\"expensive operation\")\n    return {\n        \"payment_id\": 12345,\n        \"message\": \"success\",\n        \"statusCode\": 200,\n    }\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#testing-with-redis",
            "title": "Testing with Redis",
            "text": "<p>To test locally, you can either utilize fakeredis-py for a simulated Redis environment or refer to the MockRedis class used in our tests to mock Redis operations.</p> test_with_mock_redis.pymock_redis.py <pre><code>from dataclasses import dataclass\n\nimport pytest\nfrom mock_redis import MockRedis\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.idempotency.persistence.redis import (\n    RedisCachePersistenceLayer,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n        aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n        def get_remaining_time_in_millis(self) -&gt; int:\n            return 1000\n\n    return LambdaContext()\n\n\ndef test_idempotent_lambda(lambda_context):\n    # Init the Mock redis client\n    redis_client = MockRedis(decode_responses=True)\n    # Establish persistence layer using the mock redis client\n    persistence_layer = RedisCachePersistenceLayer(client=redis_client)\n\n    # setup idempotent with redis persistence layer\n    @idempotent(persistence_store=persistence_layer)\n    def lambda_handler(event: dict, context: LambdaContext):\n        print(\"expensive operation\")\n        return {\n            \"payment_id\": 12345,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n\n    # Inovke the sim lambda handler\n    result = lambda_handler({\"testkey\": \"testvalue\"}, lambda_context)\n    assert result[\"payment_id\"] == 12345\n</code></pre> <pre><code>import time as t\nfrom typing import Dict\n\n\n# Mock redis class that includes all operations we used in Idempotency\nclass MockRedis:\n    def __init__(self, decode_responses, cache: Dict, **kwargs):\n        self.cache = cache or {}\n        self.expire_dict: Dict = {}\n        self.decode_responses = decode_responses\n        self.acl: Dict = {}\n        self.username = \"\"\n\n    def hset(self, name, mapping):\n        self.expire_dict.pop(name, {})\n        self.cache[name] = mapping\n\n    def from_url(self, url: str):\n        pass\n\n    def expire(self, name, time):\n        self.expire_dict[name] = t.time() + time\n\n    # return {} if no match\n    def hgetall(self, name):\n        if self.expire_dict.get(name, t.time() + 1) &lt; t.time():\n            self.cache.pop(name, {})\n        return self.cache.get(name, {})\n\n    def get_connection_kwargs(self):\n        return {\"decode_responses\": self.decode_responses}\n\n    def auth(self, username, **kwargs):\n        self.username = username\n\n    def delete(self, name):\n        self.cache.pop(name, {})\n</code></pre> <p>If you want to set up a real Redis client for integration testing, you can reference the code provided below.</p> test_with_real_redis.pyMakefile <pre><code>from dataclasses import dataclass\n\nimport pytest\nimport redis\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    idempotent,\n)\nfrom aws_lambda_powertools.utilities.idempotency.persistence.redis import (\n    RedisCachePersistenceLayer,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@pytest.fixture\ndef lambda_context():\n    @dataclass\n    class LambdaContext:\n        function_name: str = \"test\"\n        memory_limit_in_mb: int = 128\n        invoked_function_arn: str = \"arn:aws:lambda:eu-west-1:809313241:function:test\"\n        aws_request_id: str = \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n\n        def get_remaining_time_in_millis(self) -&gt; int:\n            return 1000\n\n    return LambdaContext()\n\n\n@pytest.fixture\ndef persistence_store_standalone_redis():\n    # init a Real Redis client and connect to the Port set in the Makefile\n    redis_client = redis.Redis(\n        host=\"localhost\",\n        port=\"63005\",\n        decode_responses=True,\n    )\n\n    # return a persistence layer with real Redis\n    return RedisCachePersistenceLayer(client=redis_client)\n\n\ndef test_idempotent_lambda(lambda_context, persistence_store_standalone_redis):\n    # Establish persistence layer using the real redis client\n    persistence_layer = persistence_store_standalone_redis\n\n    # setup idempotent with redis persistence layer\n    @idempotent(persistence_store=persistence_layer)\n    def lambda_handler(event: dict, context: LambdaContext):\n        print(\"expensive operation\")\n        return {\n            \"payment_id\": 12345,\n            \"message\": \"success\",\n            \"statusCode\": 200,\n        }\n\n    # Inovke the sim lambda handler\n    result = lambda_handler({\"testkey\": \"testvalue\"}, lambda_context)\n    assert result[\"payment_id\"] == 12345\n</code></pre> <pre><code>test-idempotency-redis: # (1)!\n    docker run --name test-idempotency-redis -d -p 63005:6379 redis\n    pytest test_with_real_redis.py;docker stop test-idempotency-redis;docker rm test-idempotency-redis\n</code></pre> <ol> <li>Use this script to setup a temp Redis docker and auto remove it upon completion</li> </ol>"
        },
        {
            "location": "utilities/idempotency/#extra-resources",
            "title": "Extra resources",
            "text": "<p>If you're interested in a deep dive on how Amazon uses idempotency when building our APIs, check out this article.</p>"
        },
        {
            "location": "utilities/jmespath_functions/",
            "title": "JMESPath Functions",
            "text": "Tip <p>JMESPath is a query language for JSON used by AWS CLI, AWS Python SDK, and Powertools for AWS Lambda (Python).</p> <p>Built-in JMESPath Functions to easily deserialize common encoded JSON payloads in Lambda functions.</p>"
        },
        {
            "location": "utilities/jmespath_functions/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Deserialize JSON from JSON strings, base64, and compressed data</li> <li>Use JMESPath to extract and combine data recursively</li> <li>Provides commonly used JMESPath expression with popular event sources</li> </ul>"
        },
        {
            "location": "utilities/jmespath_functions/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>You might have events that contains encoded JSON payloads as string, base64, or even in compressed format. It is a common use case to decode and extract them partially or fully as part of your Lambda function invocation.</p> <p>Powertools for AWS Lambda (Python) also have utilities like validation, idempotency, or feature flags where you might need to extract a portion of your data before using them.</p> Terminology <p>Envelope is the terminology we use for the JMESPath expression to extract your JSON object from your data input. We might use those two terms interchangeably.</p>"
        },
        {
            "location": "utilities/jmespath_functions/#extracting-data",
            "title": "Extracting data",
            "text": "<p>You can use the <code>query</code> function with any JMESPath expression.</p> Tip <p>Another common use case is to fetch deeply nested data, filter, flatten, and more.</p> query.pyextract_data_from_envelope.json <pre><code>from aws_lambda_powertools.utilities.jmespath_utils import query\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef handler(event: dict, context: LambdaContext) -&gt; dict:\n    payload = query(data=event, envelope=\"powertools_json(body)\")\n    customer_id = payload.get(\"customerId\")  # now deserialized\n\n    # also works for fetching and flattening deeply nested data\n    some_data = query(data=event, envelope=\"deeply_nested[*].some_data[]\")\n\n    return {\"customer_id\": customer_id, \"message\": \"success\", \"context\": some_data, \"statusCode\": 200}\n</code></pre> <pre><code>{\n    \"body\": \"{\\\"customerId\\\":\\\"dd4649e6-2484-4993-acb8-0f9123103394\\\"}\",\n    \"deeply_nested\": [\n        {\n            \"some_data\": [\n                1,\n                2,\n                3\n            ]\n        }\n    ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/jmespath_functions/#built-in-envelopes",
            "title": "Built-in envelopes",
            "text": "<p>We provide built-in envelopes for popular AWS Lambda event sources to easily decode and/or deserialize JSON objects.</p> extract_data_from_builtin_envelope.pyextract_data_from_builtin_envelope.json <pre><code>from __future__ import annotations\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.jmespath_utils import (\n    envelopes,\n    query,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef handler(event: dict, context: LambdaContext) -&gt; dict:\n    records: list = query(data=event, envelope=envelopes.SQS)\n    for record in records:  # records is a list\n        logger.info(record.get(\"customerId\"))  # now deserialized\n\n    return {\"message\": \"success\", \"statusCode\": 200}\n</code></pre> <pre><code>{\n    \"Records\": [\n        {\n            \"messageId\": \"19dd0b57-b21e-4ac1-bd88-01bbb068cb78\",\n            \"receiptHandle\": \"MessageReceiptHandle\",\n            \"body\": \"{\\\"customerId\\\":\\\"dd4649e6-2484-4993-acb8-0f9123103394\\\",\\\"booking\\\":{\\\"id\\\":\\\"5b2c4803-330b-42b7-811a-c68689425de1\\\",\\\"reference\\\":\\\"ySz7oA\\\",\\\"outboundFlightId\\\":\\\"20c0d2f2-56a3-4068-bf20-ff7703db552d\\\"},\\\"payment\\\":{\\\"receipt\\\":\\\"https:\\/\\/pay.stripe.com\\/receipts\\/acct_1Dvn7pF4aIiftV70\\/ch_3JTC14F4aIiftV700iFq2CHB\\/rcpt_K7QsrFln9FgFnzUuBIiNdkkRYGxUL0X\\\",\\\"amount\\\":100}}\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1523232000000\",\n                \"SenderId\": \"123456789012\",\n                \"ApproximateFirstReceiveTimestamp\": \"1523232000001\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"7b270e59b47ff90a553787216d55d91d\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-1:123456789012:MyQueue\",\n            \"awsRegion\": \"us-east-1\"\n        }\n    ]\n}\n</code></pre> <p>These are all built-in envelopes you can use along with their expression as a reference:</p> Envelope JMESPath expression <code>API_GATEWAY_HTTP</code> <code>powertools_json(body)</code> <code>API_GATEWAY_REST</code> <code>powertools_json(body)</code> <code>CLOUDWATCH_EVENTS_SCHEDULED</code> <code>detail</code> <code>CLOUDWATCH_LOGS</code> <code>awslogs.powertools_base64_gzip(data)                                                     | powertools_json(@).logEvents[*]</code> <code>EVENTBRIDGE</code> <code>detail</code> <code>KINESIS_DATA_STREAM</code> <code>Records[*].kinesis.powertools_json(powertools_base64(data))</code> <code>S3_EVENTBRIDGE_SQS</code> <code>Records[*].powertools_json(body).detail</code> <code>S3_KINESIS_FIREHOSE</code> <code>records[*].powertools_json(powertools_base64(data)).Records[0]</code> <code>S3_SNS_KINESIS_FIREHOSE</code> <code>records[*].powertools_json(powertools_base64(data)).powertools_json(Message).Records[0]</code> <code>S3_SNS_SQS</code> <code>Records[*].powertools_json(body).powertools_json(Message).Records[0]</code> <code>S3_SQS</code> <code>Records[*].powertools_json(body).Records[0]</code> <code>SNS</code> <code>Records[0].Sns.Message                                                                   | powertools_json(@)</code> <code>SQS</code> <code>Records[*].powertools_json(body)</code> Using SNS? <p>If you don't require SNS metadata, enable raw message delivery. It will reduce multiple payload layers and size, when using SNS in combination with other services (e.g., SQS, S3, etc).</p>"
        },
        {
            "location": "utilities/jmespath_functions/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/jmespath_functions/#built-in-jmespath-functions",
            "title": "Built-in JMESPath functions",
            "text": "<p>You can use our built-in JMESPath functions within your envelope expression. They handle deserialization for common data formats found in AWS Lambda event sources such as JSON strings, base64, and uncompress gzip data.</p> Info <p>We use these everywhere in Powertools for AWS Lambda (Python) to easily decode and unwrap events from Amazon API Gateway, Amazon Kinesis, AWS CloudWatch Logs, etc.</p>"
        },
        {
            "location": "utilities/jmespath_functions/#powertools_json-function",
            "title": "powertools_json function",
            "text": "<p>Use <code>powertools_json</code> function to decode any JSON string anywhere a JMESPath expression is allowed.</p> <p>Validation scenario</p> <p>This sample will deserialize the JSON string within the <code>data</code> key before validation.</p> powertools_json_jmespath_function.pypowertools_json_jmespath_schema.pypowertools_json_jmespath_payload.json <pre><code>import json\nfrom dataclasses import asdict, dataclass, field, is_dataclass\nfrom uuid import uuid4\n\nimport powertools_json_jmespath_schema as schemas\nfrom jmespath.exceptions import JMESPathTypeError\n\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import SchemaValidationError, validate\n\n\n@dataclass\nclass Order:\n    user_id: int\n    product_id: int\n    quantity: int\n    price: float\n    currency: str\n    order_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass DataclassCustomEncoder(json.JSONEncoder):\n    \"\"\"A custom JSON encoder to serialize dataclass obj\"\"\"\n\n    def default(self, obj):\n        # Only called for values that aren't JSON serializable\n        # where `obj` will be an instance of Order in this example\n        return asdict(obj) if is_dataclass(obj) else super().default(obj)\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    try:\n        # Validate order against our schema\n        validate(event=event, schema=schemas.INPUT, envelope=\"powertools_json(payload)\")\n\n        # Deserialize JSON string order as dict\n        # alternatively, query works here too\n        order_payload: dict = json.loads(event.get(\"payload\"))\n\n        return {\n            \"order\": json.dumps(Order(**order_payload), cls=DataclassCustomEncoder),\n            \"message\": \"order created\",\n            \"success\": True,\n        }\n    except JMESPathTypeError:\n        # The powertools_json() envelope function must match a valid path\n        return return_error_message(\"Invalid request.\")\n    except SchemaValidationError as exception:\n        # SchemaValidationError indicates where a data mismatch is\n        return return_error_message(str(exception))\n    except json.JSONDecodeError:\n        return return_error_message(\"Payload must be valid JSON (base64 encoded).\")\n\n\ndef return_error_message(message: str) -&gt; dict:\n    return {\"order\": None, \"message\": message, \"success\": False}\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema\",\n    \"$id\": \"http://example.com/example.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample order schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n    \"examples\": [{\"user_id\": 123, \"product_id\": 1, \"quantity\": 2, \"price\": 10.40, \"currency\": \"USD\"}],\n    \"required\": [\"user_id\", \"product_id\", \"quantity\", \"price\", \"currency\"],\n    \"properties\": {\n        \"user_id\": {\n            \"$id\": \"#/properties/user_id\",\n            \"type\": \"integer\",\n            \"title\": \"The unique identifier of the user\",\n            \"examples\": [123],\n            \"maxLength\": 10,\n        },\n        \"product_id\": {\n            \"$id\": \"#/properties/product_id\",\n            \"type\": \"integer\",\n            \"title\": \"The unique identifier of the product\",\n            \"examples\": [1],\n            \"maxLength\": 10,\n        },\n        \"quantity\": {\n            \"$id\": \"#/properties/quantity\",\n            \"type\": \"integer\",\n            \"title\": \"The quantity of the product\",\n            \"examples\": [2],\n            \"maxLength\": 10,\n        },\n        \"price\": {\n            \"$id\": \"#/properties/price\",\n            \"type\": \"number\",\n            \"title\": \"The individual price of the product\",\n            \"examples\": [10.40],\n            \"maxLength\": 10,\n        },\n        \"currency\": {\n            \"$id\": \"#/properties/currency\",\n            \"type\": \"string\",\n            \"title\": \"The currency\",\n            \"examples\": [\"The currency of the order\"],\n            \"maxLength\": 100,\n        },\n    },\n}\n</code></pre> <pre><code>{\n    \"payload\":\"{\\\"user_id\\\": 123, \\\"product_id\\\": 1, \\\"quantity\\\": 2, \\\"price\\\": 10.40, \\\"currency\\\": \\\"USD\\\"}\"\n}\n</code></pre> <p>Idempotency scenario</p> <p>This sample will deserialize the JSON string within the <code>body</code> key before Idempotency processes it.</p> powertools_json_idempotency_jmespath.pypowertools_json_idempotency_jmespath.json <pre><code>import json\nfrom uuid import uuid4\n\nimport requests\n\nfrom aws_lambda_powertools.utilities.idempotency import (\n    DynamoDBPersistenceLayer,\n    IdempotencyConfig,\n    idempotent,\n)\n\npersistence_layer = DynamoDBPersistenceLayer(table_name=\"IdempotencyTable\")\n\n# Treat everything under the \"body\" key\n# in the event json object as our payload\nconfig = IdempotencyConfig(event_key_jmespath=\"powertools_json(body)\")\n\n\nclass PaymentError(Exception):\n    ...\n\n\n@idempotent(config=config, persistence_store=persistence_layer)\ndef handler(event, context) -&gt; dict:\n    body = json.loads(event[\"body\"])\n    try:\n        payment: dict = create_subscription_payment(user=body[\"user\"], product_id=body[\"product_id\"])\n        return {\"payment_id\": payment.get(\"id\"), \"message\": \"success\", \"statusCode\": 200}\n    except requests.HTTPError as e:\n        raise PaymentError(\"Unable to create payment subscription\") from e\n\n\ndef create_subscription_payment(user: str, product_id: str) -&gt; dict:\n    payload = {\"user\": user, \"product_id\": product_id}\n    ret: requests.Response = requests.post(url=\"https://httpbin.org/anything\", data=payload)\n    ret.raise_for_status()\n\n    return {\"id\": f\"{uuid4()}\", \"message\": \"paid\"}\n</code></pre> <pre><code>{\n    \"version\":\"2.0\",\n    \"routeKey\":\"ANY /createpayment\",\n    \"rawPath\":\"/createpayment\",\n    \"rawQueryString\":\"\",\n    \"headers\": {\n      \"Header1\": \"value1\",\n      \"Header2\": \"value2\"\n    },\n    \"requestContext\":{\n      \"accountId\":\"123456789012\",\n      \"apiId\":\"api-id\",\n      \"domainName\":\"id.execute-api.us-east-1.amazonaws.com\",\n      \"domainPrefix\":\"id\",\n      \"http\":{\n        \"method\":\"POST\",\n        \"path\":\"/createpayment\",\n        \"protocol\":\"HTTP/1.1\",\n        \"sourceIp\":\"ip\",\n        \"userAgent\":\"agent\"\n      },\n      \"requestId\":\"id\",\n      \"routeKey\":\"ANY /createpayment\",\n      \"stage\":\"$default\",\n      \"time\":\"10/Feb/2021:13:40:43 +0000\",\n      \"timeEpoch\":1612964443723\n    },\n    \"body\":\"{\\\"user\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\",\n    \"isBase64Encoded\":false\n  }\n</code></pre>"
        },
        {
            "location": "utilities/jmespath_functions/#powertools_base64-function",
            "title": "powertools_base64 function",
            "text": "<p>Use <code>powertools_base64</code> function to decode any base64 data.</p> <p>This sample will decode the base64 value within the <code>data</code> key, and deserialize the JSON string before validation.</p> powertools_base64_jmespath_function.pypowertools_base64_jmespath_schema.pypowertools_base64_jmespath_payload.json <pre><code>import base64\nimport binascii\nimport json\nfrom dataclasses import asdict, dataclass, field, is_dataclass\nfrom uuid import uuid4\n\nimport powertools_base64_jmespath_schema as schemas\nfrom jmespath.exceptions import JMESPathTypeError\n\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import SchemaValidationError, validate\n\n\n@dataclass\nclass Order:\n    user_id: int\n    product_id: int\n    quantity: int\n    price: float\n    currency: str\n    order_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass DataclassCustomEncoder(json.JSONEncoder):\n    \"\"\"A custom JSON encoder to serialize dataclass obj\"\"\"\n\n    def default(self, obj):\n        # Only called for values that aren't JSON serializable\n        # where `obj` will be an instance of Todo in this example\n        return asdict(obj) if is_dataclass(obj) else super().default(obj)\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    # Try to validate the schema\n    try:\n        validate(event=event, schema=schemas.INPUT, envelope=\"powertools_json(powertools_base64(payload))\")\n\n        # alternatively, query works here too\n        payload_decoded = base64.b64decode(event[\"payload\"]).decode()\n\n        order_payload: dict = json.loads(payload_decoded)\n\n        return {\n            \"order\": json.dumps(Order(**order_payload), cls=DataclassCustomEncoder),\n            \"message\": \"order created\",\n            \"success\": True,\n        }\n    except JMESPathTypeError:\n        return return_error_message(\n            \"The powertools_json(powertools_base64()) envelope function must match a valid path.\",\n        )\n    except binascii.Error:\n        return return_error_message(\"Payload must be a valid base64 encoded string\")\n    except json.JSONDecodeError:\n        return return_error_message(\"Payload must be valid JSON (base64 encoded).\")\n    except SchemaValidationError as exception:\n        # SchemaValidationError indicates where a data mismatch is\n        return return_error_message(str(exception))\n\n\ndef return_error_message(message: str) -&gt; dict:\n    return {\"order\": None, \"message\": message, \"success\": False}\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema\",\n    \"$id\": \"http://example.com/example.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample order schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n    \"examples\": [{\"user_id\": 123, \"product_id\": 1, \"quantity\": 2, \"price\": 10.40, \"currency\": \"USD\"}],\n    \"required\": [\"user_id\", \"product_id\", \"quantity\", \"price\", \"currency\"],\n    \"properties\": {\n        \"user_id\": {\n            \"$id\": \"#/properties/user_id\",\n            \"type\": \"integer\",\n            \"title\": \"The unique identifier of the user\",\n            \"examples\": [123],\n            \"maxLength\": 10,\n        },\n        \"product_id\": {\n            \"$id\": \"#/properties/product_id\",\n            \"type\": \"integer\",\n            \"title\": \"The unique identifier of the product\",\n            \"examples\": [1],\n            \"maxLength\": 10,\n        },\n        \"quantity\": {\n            \"$id\": \"#/properties/quantity\",\n            \"type\": \"integer\",\n            \"title\": \"The quantity of the product\",\n            \"examples\": [2],\n            \"maxLength\": 10,\n        },\n        \"price\": {\n            \"$id\": \"#/properties/price\",\n            \"type\": \"number\",\n            \"title\": \"The individual price of the product\",\n            \"examples\": [10.40],\n            \"maxLength\": 10,\n        },\n        \"currency\": {\n            \"$id\": \"#/properties/currency\",\n            \"type\": \"string\",\n            \"title\": \"The currency\",\n            \"examples\": [\"The currency of the order\"],\n            \"maxLength\": 100,\n        },\n    },\n}\n</code></pre> <pre><code>{\n    \"payload\":\"eyJ1c2VyX2lkIjogMTIzLCAicHJvZHVjdF9pZCI6IDEsICJxdWFudGl0eSI6IDIsICJwcmljZSI6IDEwLjQwLCAiY3VycmVuY3kiOiAiVVNEIn0=\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/jmespath_functions/#powertools_base64_gzip-function",
            "title": "powertools_base64_gzip function",
            "text": "<p>Use <code>powertools_base64_gzip</code> function to decompress and decode base64 data.</p> <p>This sample will decompress and decode base64 data from Cloudwatch Logs, then use JMESPath pipeline expression to pass the result for decoding its JSON string.</p> powertools_base64_gzip_jmespath_function.pypowertools_base64_gzip_jmespath_schema.pypowertools_base64_gzip_jmespath_payload.json <pre><code>import base64\nimport binascii\nimport gzip\nimport json\n\nimport powertools_base64_gzip_jmespath_schema as schemas\nfrom jmespath.exceptions import JMESPathTypeError\n\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import SchemaValidationError, validate\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    try:\n        validate(event=event, schema=schemas.INPUT, envelope=\"powertools_base64_gzip(payload) | powertools_json(@)\")\n\n        # Alternatively, query works here too\n        encoded_payload = base64.b64decode(event[\"payload\"])\n        uncompressed_payload = gzip.decompress(encoded_payload).decode()\n        log: dict = json.loads(uncompressed_payload)\n\n        return {\n            \"message\": \"Logs processed\",\n            \"log_group\": log.get(\"logGroup\"),\n            \"owner\": log.get(\"owner\"),\n            \"success\": True,\n        }\n\n    except JMESPathTypeError:\n        return return_error_message(\"The powertools_base64_gzip() envelope function must match a valid path.\")\n    except binascii.Error:\n        return return_error_message(\"Payload must be a valid base64 encoded string\")\n    except json.JSONDecodeError:\n        return return_error_message(\"Payload must be valid JSON (base64 encoded).\")\n    except SchemaValidationError as exception:\n        # SchemaValidationError indicates where a data mismatch is\n        return return_error_message(str(exception))\n\n\ndef return_error_message(message: str) -&gt; dict:\n    return {\"message\": message, \"success\": False}\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema\",\n    \"$id\": \"http://example.com/example.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n    \"examples\": [\n        {\n            \"owner\": \"123456789012\",\n            \"logGroup\": \"/aws/lambda/powertools-example\",\n            \"logStream\": \"2022/08/07/[$LATEST]d3a8dcaffc7f4de2b8db132e3e106660\",\n            \"logEvents\": {},\n        },\n    ],\n    \"required\": [\"owner\", \"logGroup\", \"logStream\", \"logEvents\"],\n    \"properties\": {\n        \"owner\": {\n            \"$id\": \"#/properties/owner\",\n            \"type\": \"string\",\n            \"title\": \"The owner\",\n            \"examples\": [\"123456789012\"],\n            \"maxLength\": 12,\n        },\n        \"logGroup\": {\n            \"$id\": \"#/properties/logGroup\",\n            \"type\": \"string\",\n            \"title\": \"The logGroup\",\n            \"examples\": [\"/aws/lambda/powertools-example\"],\n            \"maxLength\": 100,\n        },\n        \"logStream\": {\n            \"$id\": \"#/properties/logStream\",\n            \"type\": \"string\",\n            \"title\": \"The logGroup\",\n            \"examples\": [\"2022/08/07/[$LATEST]d3a8dcaffc7f4de2b8db132e3e106660\"],\n            \"maxLength\": 100,\n        },\n        \"logEvents\": {\n            \"$id\": \"#/properties/logEvents\",\n            \"type\": \"array\",\n            \"title\": \"The logEvents\",\n            \"examples\": [\n                \"{'id': 'eventId1', 'message': {'username': 'lessa', 'message': 'hello world'}, 'timestamp': 1440442987000}\"  # noqa E501\n            ],\n        },\n    },\n}\n</code></pre> <pre><code>{\n    \"payload\": \"H4sIACZAXl8C/52PzUrEMBhFX2UILpX8tPbHXWHqIOiq3Q1F0ubrWEiakqTWofTdTYYB0YWL2d5zvnuTFellBIOedoiyKH5M0iwnlKH7HZL6dDB6ngLDfLFYctUKjie9gHFaS/sAX1xNEq525QxwFXRGGMEkx4Th491rUZdV3YiIZ6Ljfd+lfSyAtZloacQgAkqSJCGhxM6t7cwwuUGPz4N0YKyvO6I9WDeMPMSo8Z4Ca/kJ6vMEYW5f1MX7W1lVxaG8vqX8hNFdjlc0iCBBSF4ERT/3Pl7RbMGMXF2KZMh/C+gDpNS7RRsp0OaRGzx0/t8e0jgmcczyLCWEePhni/23JWalzjdu0a3ZvgEaNLXeugEAAA==\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/jmespath_functions/#bring-your-own-jmespath-function",
            "title": "Bring your own JMESPath function",
            "text": "Warning <p>This should only be used for advanced use cases where you have special formats not covered by the built-in functions.</p> <p>For special binary formats that you want to decode before applying JSON Schema validation, you can bring your own JMESPath function and any additional option via <code>jmespath_options</code> param. To keep Powertools for AWS Lambda (Python) built-in functions, you can subclass from <code>PowertoolsFunctions</code>.</p> <p>Here is an example of how to decompress messages using zlib:</p> powertools_custom_jmespath_function.pypowertools_custom_jmespath_function.json <pre><code>import base64\nimport binascii\nimport zlib\n\nfrom jmespath.exceptions import JMESPathTypeError\nfrom jmespath.functions import signature\n\nfrom aws_lambda_powertools.utilities.jmespath_utils import (\n    PowertoolsFunctions,\n    query,\n)\n\n\nclass CustomFunctions(PowertoolsFunctions):\n    # only decode if value is a string\n    # see supported data types: https://jmespath.org/specification.html#built-in-functions\n    @signature({\"types\": [\"string\"]})\n    def _func_decode_zlib_compression(self, payload: str):\n        decoded: bytes = base64.b64decode(payload)\n        return zlib.decompress(decoded)\n\n\ncustom_jmespath_options = {\"custom_functions\": CustomFunctions()}\n\n\ndef lambda_handler(event, context) -&gt; dict:\n    try:\n        logs = []\n        logs.append(\n            query(\n                data=event,\n                # NOTE: Use the prefix `_func_` before the name of the function\n                envelope=\"Records[*].decode_zlib_compression(log)\",\n                jmespath_options=custom_jmespath_options,\n            ),\n        )\n        return {\"logs\": logs, \"message\": \"Extracted messages\", \"success\": True}\n    except JMESPathTypeError:\n        return return_error_message(\"The envelope function must match a valid path.\")\n    except zlib.error:\n        return return_error_message(\"Log must be a valid zlib compressed message\")\n    except binascii.Error:\n        return return_error_message(\"Log must be a valid base64 encoded string\")\n\n\ndef return_error_message(message: str) -&gt; dict:\n    return {\"logs\": None, \"message\": message, \"success\": False}\n</code></pre> <pre><code>{\n    \"Records\": [\n        {\n            \"application\": \"notification\",\n            \"datetime\": \"2022-01-01T00:00:00.000Z\",\n            \"log\": \"eJxtUNFOwkAQ/JXN+dJq6e22tMD5ZHwQRYSEJpqQhtRy2AvlWq+tEr/eg6DExOzDJjM7M5tZsgCDgGPMKQaKRRAJRFjmRrUphBjRcIQXpy3gkiCvtJZ567jQVkDBwEc7JCK0sk2mSrkGh0IBc2l2qmlUpWEttZJrFz4LS/8YKP12cOjqpjUy23mQl0rqVpw9PWik+ZBGwMoDI9872ViazebJ/expARzGSTLn5BPzfm0sX7RtLTj/+xq3N0V11J+JITELnwHo2VlSzB86zQ+1CFtIiIJGcIWEmP4bDgH2AYH1GLBp9aXKMuORj+C8EF3Do9LdHvbDeBX3Xbip61I+y9eJankUDvwwBmcyTqaPHpRqK+FO5tvKhdvCVDvJCYPjYwiLbJMZdZKwQxZL02+NI3Vs\"\n        }\n    ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/middleware_factory/",
            "title": "Middleware factory",
            "text": "<p>Middleware factory provides a decorator factory to create your own middleware to run logic before, and after each Lambda invocation synchronously.</p>"
        },
        {
            "location": "utilities/middleware_factory/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Run logic before, after, and handle exceptions</li> <li>Built-in tracing opt-in capability</li> </ul>"
        },
        {
            "location": "utilities/middleware_factory/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>You might need a custom middleware to abstract non-functional code. These are often custom authorization or any reusable logic you might need to run before/after a Lambda function invocation.</p>"
        },
        {
            "location": "utilities/middleware_factory/#middleware-with-no-params",
            "title": "Middleware with no params",
            "text": "<p>You can create your own middleware using <code>lambda_handler_decorator</code>. The decorator factory expects 3 arguments in your function signature:</p> <ul> <li>handler - Lambda function handler</li> <li>event - Lambda function invocation event</li> <li>context - Lambda function context object</li> </ul>"
        },
        {
            "location": "utilities/middleware_factory/#middleware-with-before-logic",
            "title": "Middleware with before logic",
            "text": "getting_started_middleware_before_logic_function.pygetting_started_middleware_before_logic_payload.json <pre><code>from dataclasses import dataclass, field\nfrom typing import Callable\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\nfrom aws_lambda_powertools.utilities.jmespath_utils import (\n    envelopes,\n    query,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@dataclass\nclass Payment:\n    user_id: str\n    order_id: str\n    amount: float\n    status_id: str\n    payment_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass PaymentError(Exception): ...\n\n\n@lambda_handler_decorator\ndef middleware_before(\n    handler: Callable[[dict, LambdaContext], dict],\n    event: dict,\n    context: LambdaContext,\n) -&gt; dict:\n    # extract payload from a EventBridge event\n    detail: dict = query(data=event, envelope=envelopes.EVENTBRIDGE)\n\n    # check if status_id exists in payload, otherwise add default state before processing payment\n    if \"status_id\" not in detail:\n        event[\"detail\"][\"status_id\"] = \"pending\"\n\n    return handler(event, context)\n\n\n@middleware_before\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    try:\n        payment_payload: dict = query(data=event, envelope=envelopes.EVENTBRIDGE)\n        return {\n            \"order\": Payment(**payment_payload).__dict__,\n            \"message\": \"payment created\",\n            \"success\": True,\n        }\n    except Exception as e:\n        raise PaymentError(\"Unable to create payment\") from e\n</code></pre> <pre><code>{\n    \"version\": \"0\",\n    \"id\": \"9c95e8e4-96a4-ef3f-b739-b6aa5b193afb\",\n    \"detail-type\": \"PaymentCreated\",\n    \"source\": \"app.payment\",\n    \"account\": \"0123456789012\",\n    \"time\": \"2022-08-08T20:41:53Z\",\n    \"region\": \"eu-east-1\",\n    \"detail\": {\n      \"amount\": \"150.00\",\n      \"order_id\": \"8f1f1710-1b30-48a5-a6bd-153fd23b866b\",\n      \"user_id\": \"f80e3c51-5b8c-49d5-af7d-c7804966235f\"\n    }\n  }\n</code></pre>"
        },
        {
            "location": "utilities/middleware_factory/#middleware-with-after-logic",
            "title": "Middleware with after logic",
            "text": "getting_started_middleware_after_logic_function.pygetting_started_middleware_after_logic_payload.json <pre><code>import time\nfrom typing import Callable\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver()\n\n\n@lambda_handler_decorator\ndef middleware_after(\n    handler: Callable[[dict, LambdaContext], dict],\n    event: dict,\n    context: LambdaContext,\n) -&gt; dict:\n    start_time = time.time()\n    response = handler(event, context)\n    execution_time = time.time() - start_time\n\n    # adding custom headers in response object after lambda executing\n    response[\"headers\"][\"execution_time\"] = execution_time\n    response[\"headers\"][\"aws_request_id\"] = context.aws_request_id\n\n    return response\n\n\n@app.post(\"/todos\")\ndef create_todo() -&gt; dict:\n    todo_data: dict = app.current_event.json_body  # deserialize json str to dict\n    todo: Response = requests.post(\"https://jsonplaceholder.typicode.com/todos\", data=todo_data)\n    todo.raise_for_status()\n\n    return {\"todo\": todo.json()}\n\n\n@middleware_after\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"resource\": \"/todos\",\n    \"path\": \"/todos\",\n    \"httpMethod\": \"POST\",\n    \"body\": \"{\\\"title\\\": \\\"foo\\\", \\\"userId\\\": 1, \\\"completed\\\": false}\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/middleware_factory/#middleware-with-params",
            "title": "Middleware with params",
            "text": "<p>You can also have your own keyword arguments after the mandatory arguments.</p> getting_started_middleware_with_params_function.pygetting_started_middleware_with_params_payload.json <pre><code>import base64\nfrom dataclasses import dataclass, field\nfrom typing import Any, Callable, List\nfrom uuid import uuid4\n\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\nfrom aws_lambda_powertools.utilities.jmespath_utils import (\n    envelopes,\n    query,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\n@dataclass\nclass Booking:\n    days: int\n    date_from: str\n    date_to: str\n    hotel_id: int\n    country: str\n    city: str\n    guest: dict\n    booking_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n\n\nclass BookingError(Exception): ...\n\n\n@lambda_handler_decorator\ndef obfuscate_sensitive_data(\n    handler: Callable[[dict, LambdaContext], dict],\n    event: dict,\n    context: LambdaContext,\n    fields: List,\n) -&gt; dict:\n    # extracting payload from a EventBridge event\n    detail: dict = query(data=event, envelope=envelopes.EVENTBRIDGE)\n    guest_data: Any = detail.get(\"guest\")\n\n    # Obfuscate fields (email, vat, passport) before calling Lambda handler\n    for guest_field in fields:\n        if guest_data.get(guest_field):\n            event[\"detail\"][\"guest\"][guest_field] = obfuscate_data(str(guest_data.get(guest_field)))\n\n    return handler(event, context)\n\n\ndef obfuscate_data(value: str) -&gt; bytes:\n    # base64 is not effective for obfuscation, this is an example\n    return base64.b64encode(value.encode(\"ascii\"))\n\n\n@obfuscate_sensitive_data(fields=[\"email\", \"passport\", \"vat\"])\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    try:\n        booking_payload: dict = query(data=event, envelope=envelopes.EVENTBRIDGE)\n        return {\n            \"book\": Booking(**booking_payload).__dict__,\n            \"message\": \"booking created\",\n            \"success\": True,\n        }\n    except Exception as e:\n        raise BookingError(\"Unable to create booking\") from e\n</code></pre> <pre><code>{\n    \"version\": \"0\",\n    \"id\": \"9c95e8e4-96a4-ef3f-b739-b6aa5b193afb\",\n    \"detail-type\": \"BookingCreated\",\n    \"source\": \"app.booking\",\n    \"account\": \"0123456789012\",\n    \"time\": \"2022-08-08T20:41:53Z\",\n    \"region\": \"eu-east-1\",\n    \"detail\": {\n      \"days\": 5,\n      \"date_from\": \"2020-08-08\",\n      \"date_to\": \"2020-08-13\",\n      \"hotel_id\": \"1\",\n      \"country\": \"Portugal\",\n      \"city\": \"Lisbon\",\n      \"guest\": {\n        \"name\": \"Lambda\",\n        \"email\": \"lambda@powertool.tools\",\n        \"passport\": \"AA123456\",\n        \"vat\": \"123456789\"\n      }\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/middleware_factory/#environment-variables",
            "title": "Environment variables",
            "text": "<p>The following environment variable is available to configure the middleware factory at a global scope:</p> Setting Description Environment variable Default Middleware Trace Creates sub-segment for each custom middleware. <code>POWERTOOLS_TRACE_MIDDLEWARES</code> <code>false</code> <p>You can also use <code>POWERTOOLS_TRACE_MIDDLEWARES</code> on a per-method basis, which will consequently override the environment variable value.</p>"
        },
        {
            "location": "utilities/middleware_factory/#advanced",
            "title": "Advanced",
            "text": "<p>For advanced use cases, you can instantiate Tracer inside your middleware, and add annotations as well as metadata for additional operational insights.</p> advanced_middleware_tracer_function.pyadvanced_middleware_tracer_payload.json <pre><code>import time\nfrom typing import Callable\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools import Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ntracer = Tracer()\napp = APIGatewayRestResolver()\n\n\n@lambda_handler_decorator(trace_execution=True)\ndef middleware_with_advanced_tracing(\n    handler: Callable[[dict, LambdaContext], dict],\n    event: dict,\n    context: LambdaContext,\n) -&gt; dict:\n    tracer.put_metadata(key=\"resource\", value=event.get(\"resource\"))\n\n    start_time = time.time()\n    response = handler(event, context)\n    execution_time = time.time() - start_time\n\n    tracer.put_annotation(key=\"TotalExecutionTime\", value=str(execution_time))\n\n    # adding custom headers in response object after lambda executing\n    response[\"headers\"][\"execution_time\"] = execution_time\n    response[\"headers\"][\"aws_request_id\"] = context.aws_request_id\n\n    return response\n\n\n@app.get(\"/products\")\ndef create_product() -&gt; dict:\n    product: Response = requests.get(\"https://dummyjson.com/products/1\")\n    product.raise_for_status()\n\n    return {\"product\": product.json()}\n\n\n@middleware_with_advanced_tracing\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"resource\": \"/products\",\n    \"path\": \"/products\",\n    \"httpMethod\": \"GET\"\n }\n</code></pre> <p></p>"
        },
        {
            "location": "utilities/middleware_factory/#tracing-middleware-execution",
            "title": "Tracing middleware execution",
            "text": "<p>If you are making use of Tracer, you can trace the execution of your middleware to ease operations.</p> <p>This makes use of an existing Tracer instance that you may have initialized anywhere in your code.</p> Warning <p>You must enable Active Tracing in your Lambda function when using this feature, otherwise Lambda cannot send traces to XRay.</p> getting_started_middleware_tracer_function.pygetting_started_middleware_tracer_payload.json <pre><code>import time\nfrom typing import Callable\n\nimport requests\nfrom requests import Response\n\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\napp = APIGatewayRestResolver()\n\n\n@lambda_handler_decorator(trace_execution=True)\ndef middleware_with_tracing(\n    handler: Callable[[dict, LambdaContext], dict],\n    event: dict,\n    context: LambdaContext,\n) -&gt; dict:\n    start_time = time.time()\n    response = handler(event, context)\n    execution_time = time.time() - start_time\n\n    # adding custom headers in response object after lambda executing\n    response[\"headers\"][\"execution_time\"] = execution_time\n    response[\"headers\"][\"aws_request_id\"] = context.aws_request_id\n\n    return response\n\n\n@app.get(\"/products\")\ndef create_product() -&gt; dict:\n    product: Response = requests.get(\"https://dummyjson.com/products/1\")\n    product.raise_for_status()\n\n    return {\"product\": product.json()}\n\n\n@middleware_with_tracing\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>{\n    \"resource\": \"/products\",\n    \"path\": \"/products\",\n    \"httpMethod\": \"GET\"\n }\n</code></pre> <p>When executed, your middleware name will appear in AWS X-Ray Trace details as <code>## middleware_name</code>, in this example the middleware name is <code>## middleware_with_tracing</code>.</p> <p></p>"
        },
        {
            "location": "utilities/middleware_factory/#combining-powertools-for-aws-lambda-python-utilities",
            "title": "Combining Powertools for AWS Lambda (Python) utilities",
            "text": "<p>You can create your own middleware and combine many features of Powertools for AWS Lambda (Python) such as trace, logs, feature flags, validation, jmespath_functions and others to abstract non-functional code.</p> <p>In the example below, we create a Middleware with the following features:</p> <ul> <li>Logs and traces</li> <li>Validate if the payload contains a specific header</li> <li>Extract specific keys from event</li> <li>Automatically add security headers on every execution</li> <li>Validate if a specific feature flag is enabled</li> <li>Save execution history to a DynamoDB table</li> </ul> combining_powertools_utilities_function.pycombining_powertools_utilities_schema.pycombining_powertools_utilities_event.jsonSAM TEMPLATE <pre><code>import json\nfrom typing import Callable\nfrom urllib.parse import quote\n\nimport boto3\nimport combining_powertools_utilities_schema as schemas\nimport requests\n\nfrom aws_lambda_powertools import Logger, Tracer\nfrom aws_lambda_powertools.event_handler import APIGatewayRestResolver\nfrom aws_lambda_powertools.event_handler.exceptions import InternalServerError\nfrom aws_lambda_powertools.middleware_factory import lambda_handler_decorator\nfrom aws_lambda_powertools.utilities.feature_flags import AppConfigStore, FeatureFlags\nfrom aws_lambda_powertools.utilities.feature_flags.types import JSONType\nfrom aws_lambda_powertools.utilities.jmespath_utils import query\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import SchemaValidationError, validate\n\napp = APIGatewayRestResolver()\ntracer = Tracer()\nlogger = Logger()\n\ntable_historic = boto3.resource(\"dynamodb\").Table(\"HistoricTable\")\n\napp_config = AppConfigStore(environment=\"dev\", application=\"comments\", name=\"features\")\nfeature_flags = FeatureFlags(store=app_config)\n\n\n@lambda_handler_decorator(trace_execution=True)\ndef middleware_custom(\n    handler: Callable[[dict, LambdaContext], dict],\n    event: dict,\n    context: LambdaContext,\n) -&gt; dict:\n    # validating the INPUT with the given schema\n    # X-Customer-Id header must be informed in all requests\n    try:\n        validate(event=event, schema=schemas.INPUT)\n    except SchemaValidationError as e:\n        return {\n            \"statusCode\": 400,\n            \"body\": json.dumps(str(e)),\n        }\n\n    # extracting headers and requestContext from event\n    headers = query(data=event, envelope=\"headers\")\n    request_context = query(data=event, envelope=\"requestContext\")\n\n    logger.debug(f\"X-Customer-Id =&gt; {headers.get('X-Customer-Id')}\")\n    tracer.put_annotation(key=\"CustomerId\", value=headers.get(\"X-Customer-Id\"))\n\n    response = handler(event, context)\n\n    # automatically adding security headers to all responses\n    # see: https://securityheaders.com/\n    logger.info(\"Injecting security headers\")\n    response[\"headers\"][\"Referrer-Policy\"] = \"no-referrer\"\n    response[\"headers\"][\"Strict-Transport-Security\"] = \"max-age=15552000; includeSubDomains; preload\"\n    response[\"headers\"][\"X-DNS-Prefetch-Control\"] = \"off\"\n    response[\"headers\"][\"X-Content-Type-Options\"] = \"nosniff\"\n    response[\"headers\"][\"X-Permitted-Cross-Domain-Policies\"] = \"none\"\n    response[\"headers\"][\"X-Download-Options\"] = \"noopen\"\n\n    logger.info(\"Saving api call in history table\")\n    save_api_execution_history(str(event.get(\"path\")), headers, request_context)\n\n    # return lambda execution\n    return response\n\n\n@tracer.capture_method\ndef save_api_execution_history(path: str, headers: dict, request_context: dict) -&gt; None:\n    try:\n        # using the feature flags utility to check if the new feature \"save api call to history\" is enabled by default\n        # see: https://docs.powertools.aws.dev/lambda/python/latest/utilities/feature_flags/#static-flags\n        save_history: JSONType = feature_flags.evaluate(name=\"save_history\", default=False)\n        if save_history:\n            # saving history in dynamodb table\n            tracer.put_metadata(key=\"execution detail\", value=request_context)\n            table_historic.put_item(\n                Item={\n                    \"customer_id\": headers.get(\"X-Customer-Id\"),\n                    \"request_id\": request_context.get(\"requestId\"),\n                    \"path\": path,\n                    \"request_time\": request_context.get(\"requestTime\"),\n                    \"source_ip\": request_context.get(\"identity\", {}).get(\"sourceIp\"),\n                    \"http_method\": request_context.get(\"httpMethod\"),\n                },\n            )\n\n        return None\n    except Exception:\n        # you can add more logic here to handle exceptions or even save this to a DLQ\n        # but not to make this example too long, we just return None since the Lambda has been successfully executed\n        return None\n\n\n@app.get(\"/comments\")\n@tracer.capture_method\ndef get_comments():\n    try:\n        comments: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/comments\")\n        comments.raise_for_status()\n\n        return {\"comments\": comments.json()[:10]}\n    except Exception as exc:\n        raise InternalServerError(str(exc)) from exc\n\n\n@app.get(\"/comments/&lt;comment_id&gt;\")\n@tracer.capture_method\ndef get_comments_by_id(comment_id: str):\n    try:\n        comment_id = quote(comment_id, safe=\"\")\n        comments: requests.Response = requests.get(f\"https://jsonplaceholder.typicode.com/comments/{comment_id}\")\n        comments.raise_for_status()\n\n        return {\"comments\": comments.json()}\n    except Exception as exc:\n        raise InternalServerError(str(exc)) from exc\n\n\n@middleware_custom\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    return app.resolve(event, context)\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"$id\": \"https://example.com/object1661012141.json\",\n    \"title\": \"Root\",\n    \"type\": \"object\",\n    \"required\": [\"headers\"],\n    \"properties\": {\n        \"headers\": {\n            \"$id\": \"#root/headers\",\n            \"title\": \"Headers\",\n            \"type\": \"object\",\n            \"required\": [\"X-Customer-Id\"],\n            \"properties\": {\n                \"X-Customer-Id\": {\n                    \"$id\": \"#root/headers/X-Customer-Id\",\n                    \"title\": \"X-customer-id\",\n                    \"type\": \"string\",\n                    \"default\": \"\",\n                    \"examples\": [\"1\"],\n                    \"pattern\": \"^.*$\",\n                },\n            },\n        },\n    },\n}\n</code></pre> <pre><code>{\n    \"body\":\"None\",\n    \"headers\":{\n       \"Accept\":\"*/*\",\n       \"Accept-Encoding\":\"gzip, deflate, br\",\n       \"Connection\":\"keep-alive\",\n       \"Host\":\"127.0.0.1:3001\",\n       \"Postman-Token\":\"a9d49365-ebe1-4bb0-8627-d5e37cdce86d\",\n       \"User-Agent\":\"PostmanRuntime/7.29.0\",\n       \"X-Customer-Id\":\"1\",\n       \"X-Forwarded-Port\":\"3001\",\n       \"X-Forwarded-Proto\":\"http\"\n    },\n    \"httpMethod\":\"GET\",\n    \"isBase64Encoded\":false,\n    \"multiValueHeaders\":{\n       \"Accept\":[\n          \"*/*\"\n       ],\n       \"Accept-Encoding\":[\n          \"gzip, deflate, br\"\n       ],\n       \"Connection\":[\n          \"keep-alive\"\n       ],\n       \"Host\":[\n          \"127.0.0.1:3001\"\n       ],\n       \"Postman-Token\":[\n          \"a9d49365-ebe1-4bb0-8627-d5e37cdce86d\"\n       ],\n       \"User-Agent\":[\n          \"PostmanRuntime/7.29.0\"\n       ],\n       \"X-Customer-Id\":[\n          \"1\"\n       ],\n       \"X-Forwarded-Port\":[\n          \"3001\"\n       ],\n       \"X-Forwarded-Proto\":[\n          \"http\"\n       ]\n    },\n    \"multiValueQueryStringParameters\":\"None\",\n    \"path\":\"/comments\",\n    \"pathParameters\":\"None\",\n    \"queryStringParameters\":\"None\",\n    \"requestContext\":{\n       \"accountId\":\"123456789012\",\n       \"apiId\":\"1234567890\",\n       \"domainName\":\"127.0.0.1:3001\",\n       \"extendedRequestId\":\"None\",\n       \"httpMethod\":\"GET\",\n       \"identity\":{\n          \"accountId\":\"None\",\n          \"apiKey\":\"None\",\n          \"caller\":\"None\",\n          \"cognitoAuthenticationProvider\":\"None\",\n          \"cognitoAuthenticationType\":\"None\",\n          \"cognitoIdentityPoolId\":\"None\",\n          \"sourceIp\":\"127.0.0.1\",\n          \"user\":\"None\",\n          \"userAgent\":\"Custom User Agent String\",\n          \"userArn\":\"None\"\n       },\n       \"path\":\"/comments\",\n       \"protocol\":\"HTTP/1.1\",\n       \"requestId\":\"56d1a102-6d9d-4f13-b4f7-26751c10a131\",\n       \"requestTime\":\"20/Aug/2022:18:18:58 +0000\",\n       \"requestTimeEpoch\":1661019538,\n       \"resourceId\":\"123456\",\n       \"resourcePath\":\"/comments\",\n       \"stage\":\"Prod\"\n    },\n    \"resource\":\"/comments\",\n    \"stageVariables\":\"None\",\n    \"version\":\"1.0\"\n }\n</code></pre> <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: Middleware-powertools-utilities example\n\nGlobals:\n  Function:\n    Timeout: 5\n    Runtime: python3.12\n    Tracing: Active\n    Architectures:\n      - x86_64\n    Environment:\n      Variables:\n        POWERTOOLS_LOG_LEVEL: DEBUG\n        POWERTOOLS_LOGGER_SAMPLE_RATE: 0.1\n        POWERTOOLS_LOGGER_LOG_EVENT: true\n        POWERTOOLS_SERVICE_NAME: middleware\n\nResources:\n  MiddlewareFunction:\n    Type: AWS::Serverless::Function # More info about Function Resource: https://github.com/awslabs/serverless-application-model/blob/master/versions/2016-10-31.md#awsserverlessfunction\n    Properties:\n      CodeUri: middleware/\n      Handler: app.lambda_handler\n      Description: Middleware function\n      Policies:\n      - AWSLambdaBasicExecutionRole # Managed Policy\n      - Version: '2012-10-17' # Policy Document\n        Statement:\n          - Effect: Allow\n            Action:\n              - dynamodb:PutItem\n            Resource: !GetAtt HistoryTable.Arn\n          - Effect: Allow\n            Action: # https://docs.aws.amazon.com/appconfig/latest/userguide/getting-started-with-appconfig-permissions.html\n              - ssm:GetDocument\n              - ssm:ListDocuments\n              - appconfig:GetLatestConfiguration\n              - appconfig:StartConfigurationSession\n              - appconfig:ListApplications\n              - appconfig:GetApplication\n              - appconfig:ListEnvironments\n              - appconfig:GetEnvironment\n              - appconfig:ListConfigurationProfiles\n              - appconfig:GetConfigurationProfile\n              - appconfig:ListDeploymentStrategies\n              - appconfig:GetDeploymentStrategy\n              - appconfig:GetConfiguration\n              - appconfig:ListDeployments\n              - appconfig:GetDeployment\n            Resource: \"*\"\n      Events:\n        GetComments:\n          Type: Api\n          Properties:\n            Path: /comments\n            Method: GET\n        GetCommentsById:\n          Type: Api\n          Properties:\n            Path: /comments/{comment_id}\n            Method: GET\n\n  # DynamoDB table to store historical data\n  HistoryTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      TableName: \"HistoryTable\"\n      AttributeDefinitions:\n        - AttributeName: customer_id\n          AttributeType: S\n        - AttributeName: request_id\n          AttributeType: S\n      KeySchema:\n        - AttributeName: customer_id\n          KeyType: HASH\n        - AttributeName: request_id\n          KeyType: \"RANGE\"\n      BillingMode: PAY_PER_REQUEST\n\n  # Feature flags using AppConfig\n  FeatureCommentApp:\n    Type: AWS::AppConfig::Application\n    Properties:\n      Description: \"Comments Application for feature toggles\"\n      Name: comments\n\n  FeatureCommentDevEnv:\n    Type: AWS::AppConfig::Environment\n    Properties:\n      ApplicationId: !Ref FeatureCommentApp\n      Description: \"Development Environment for the App Config Comments\"\n      Name: dev\n\n  FeatureCommentConfigProfile:\n    Type: AWS::AppConfig::ConfigurationProfile\n    Properties:\n      ApplicationId: !Ref FeatureCommentApp\n      Name: features\n      LocationUri: \"hosted\"\n\n  HostedConfigVersion:\n    Type: AWS::AppConfig::HostedConfigurationVersion\n    Properties:\n      ApplicationId: !Ref FeatureCommentApp\n      ConfigurationProfileId: !Ref FeatureCommentConfigProfile\n      Description: 'A sample hosted configuration version'\n      Content: |\n        {\n              \"save_history\": {\n                \"default\": true\n              }\n        }\n      ContentType: 'application/json'\n\n  # this is just an example\n  # change this values according your deployment strategy\n  BasicDeploymentStrategy:\n    Type: AWS::AppConfig::DeploymentStrategy\n    Properties:\n      Name: \"Deployment\"\n      Description: \"Deployment strategy for comments app.\"\n      DeploymentDurationInMinutes: 1\n      FinalBakeTimeInMinutes: 1\n      GrowthFactor: 100\n      GrowthType: LINEAR\n      ReplicateTo: NONE\n\n  ConfigDeployment:\n    Type: AWS::AppConfig::Deployment\n    Properties:\n      ApplicationId: !Ref FeatureCommentApp\n      ConfigurationProfileId: !Ref FeatureCommentConfigProfile\n      ConfigurationVersion: !Ref HostedConfigVersion\n      DeploymentStrategyId: !Ref BasicDeploymentStrategy\n      EnvironmentId: !Ref FeatureCommentDevEnv\n</code></pre>"
        },
        {
            "location": "utilities/middleware_factory/#tips",
            "title": "Tips",
            "text": "<ul> <li>Use <code>trace_execution</code> to quickly understand the performance impact of your middlewares, and reduce or merge tasks when necessary</li> <li>When nesting multiple middlewares, always return the handler with event and context, or response</li> <li>Keep in mind Python decorators execution order. Lambda handler is actually called once (top-down)</li> <li>Async middlewares are not supported</li> </ul>"
        },
        {
            "location": "utilities/parameters/",
            "title": "Parameters",
            "text": "<p>The parameters utility provides high-level functions to retrieve one or multiple parameter values from AWS Systems Manager Parameter Store, AWS Secrets Manager, AWS AppConfig, Amazon DynamoDB, or bring your own.</p>"
        },
        {
            "location": "utilities/parameters/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Retrieve one or multiple parameters from the underlying provider</li> <li>Cache parameter values for a given amount of time (defaults to 5 minutes)</li> <li>Transform parameter values from JSON or base 64 encoded strings</li> <li>Bring Your Own Parameter Store Provider</li> </ul>"
        },
        {
            "location": "utilities/parameters/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>By default, we fetch parameters from System Manager Parameter Store, secrets from Secrets Manager, and application configuration from AppConfig.</p>"
        },
        {
            "location": "utilities/parameters/#iam-permissions",
            "title": "IAM Permissions",
            "text": "<p>This utility requires additional permissions to work as expected.</p> Note <p>Different parameter providers require different permissions.</p> Provider Function/Method IAM Permission SSM <code>get_parameter</code>, <code>SSMProvider.get</code> <code>ssm:GetParameter</code> SSM <code>get_parameters</code>, <code>SSMProvider.get_multiple</code> <code>ssm:GetParametersByPath</code> SSM <code>get_parameters_by_name</code>, <code>SSMProvider.get_parameters_by_name</code> <code>ssm:GetParameter</code> and <code>ssm:GetParameters</code> SSM <code>set_parameter</code>, <code>SSMProvider.set_parameter</code> <code>ssm:PutParameter</code> SSM If using <code>decrypt=True</code> You must add an additional permission <code>kms:Decrypt</code> Secrets <code>get_secret</code>, <code>SecretsProvider.get</code> <code>secretsmanager:GetSecretValue</code> Secrets <code>set_secret</code>, <code>SecretsProvider.set</code> <code>secretsmanager:PutSecretValue</code> and <code>secretsmanager:CreateSecret</code> (if creating secrets) DynamoDB <code>DynamoDBProvider.get</code> <code>dynamodb:GetItem</code> DynamoDB <code>DynamoDBProvider.get_multiple</code> <code>dynamodb:Query</code> AppConfig <code>get_app_config</code>, <code>AppConfigProvider.get_app_config</code> <code>appconfig:GetLatestConfiguration</code> and <code>appconfig:StartConfigurationSession</code>"
        },
        {
            "location": "utilities/parameters/#fetching-parameters",
            "title": "Fetching parameters",
            "text": "<p>You can retrieve a single parameter using the <code>get_parameter</code> high-level function.</p> getting_started_single_ssm_parameter.py <pre><code>import requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    try:\n        # Retrieve a single parameter\n        endpoint_comments = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\")\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <p>For multiple parameters, you can use either:</p> <ul> <li><code>get_parameters</code> to recursively fetch all parameters by path.</li> <li><code>get_parameters_by_name</code> to fetch distinct parameters by their full name. It also accepts custom caching, transform, decrypt per parameter.</li> </ul> getting_started_recursive_ssm_parameter.pygetting_started_parameter_by_name.pyget_parameter_by_name_error_handling.py <p>This is useful when you want to fetch all parameters from a given path, say <code>/dev</code>, e.g., <code>/dev/config</code>, <code>/dev/webhook/config</code></p> <p>To ease readability in deeply nested paths, we strip the path name. For example:</p> <ul> <li><code>/dev/config</code> -&gt; <code>config</code></li> <li><code>/dev/webhook/config</code> -&gt; <code>webhook/config</code></li> </ul> <pre><code>import requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve all parameters within a path e.g., /dev\n        # Say, you had two parameters under `/dev`: /dev/config, /dev/webhook/config\n        all_parameters: dict = parameters.get_parameters(\"/dev\", max_age=20)\n        endpoint_comments = None\n\n        # We strip the path prefix name for readability and memory usage in deeply nested paths\n        # all_parameters would then look like:\n        ## all_parameters[\"config\"] = value # noqa: ERA001\n        ## all_parameters[\"webhook/config\"] = value # noqa: ERA001\n        for parameter, value in all_parameters.items():\n            if parameter == \"endpoint_comments\":\n                endpoint_comments = value\n\n        if endpoint_comments is None:\n            return {\"comments\": None}\n\n        # the value of parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10]}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from __future__ import annotations\n\nfrom typing import Any\n\nfrom aws_lambda_powertools.utilities.parameters.ssm import get_parameters_by_name\n\nparameters = {\n    \"/develop/service/commons/telemetry/config\": {\"max_age\": 300, \"transform\": \"json\"},\n    \"/no_cache_param\": {\"max_age\": 0},\n    # inherit default values\n    \"/develop/service/payment/api/capture/url\": {},\n}\n\n\ndef handler(event, context):\n    # This returns a dict with the parameter name as key\n    response: dict[str, Any] = get_parameters_by_name(parameters=parameters, max_age=60)\n    for parameter, value in response.items():\n        print(f\"{parameter}: {value}\")\n</code></pre> <p>Failing gracefully if one or more parameters cannot be fetched or decrypted.</p> <p>By default, we will raise <code>GetParameterError</code> when any parameter fails to be fetched.</p> <p>You can override it by setting <code>raise_on_error=False</code>. When disabled, we take the following actions:</p> <ul> <li>Add failed parameter name in the <code>_errors</code> key, e.g., <code>{_errors: [\"/param1\", \"/param2\"]}</code></li> <li>Keep only successful parameter names and their values in the response</li> <li>Raise <code>GetParameterError</code> if any of your parameters is named <code>_errors</code></li> </ul> <pre><code>from __future__ import annotations\n\nfrom typing import Any\n\nfrom aws_lambda_powertools.utilities.parameters.ssm import get_parameters_by_name\n\nparameters = {\n    \"/develop/service/commons/telemetry/config\": {\"max_age\": 300, \"transform\": \"json\"},\n    # it would fail by default\n    \"/this/param/does/not/exist\": {},\n}\n\n\ndef handler(event, context):\n    values: dict[str, Any] = get_parameters_by_name(parameters=parameters, raise_on_error=False)\n    errors: list[str] = values.get(\"_errors\", [])\n\n    # Handle gracefully, since '/this/param/does/not/exist' will only be available in `_errors`\n    if errors:\n        ...\n\n    for parameter, value in values.items():\n        print(f\"{parameter}: {value}\")\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#setting-parameters",
            "title": "Setting parameters",
            "text": "<p>You can set a parameter using the <code>set_parameter</code> high-level function. This will create a new parameter if it doesn't exist.</p> getting_started_set_single_ssm_parameter.pygetting_started_set_ssm_parameter_overwrite.py <pre><code>from aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    try:\n        # Set a single parameter, returns the version ID of the parameter\n        parameter_version = parameters.set_parameter(name=\"/mySuper/Parameter\", value=\"PowerToolsIsAwesome\")\n\n        return {\"mySuperParameterVersion\": parameter_version, \"statusCode\": 200}\n    except parameters.exceptions.SetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <p>Sometimes you may be setting a parameter that you will have to update later on. Use the <code>overwrite</code> option to overwrite any existing value. If you do not set this option, the parameter value will not be overwritten and an exception will be raised.</p> <pre><code>from aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    try:\n        # Set a single parameter, but overwrite if it already exists.\n        # Overwrite is False by default, so we explicitly set it to True\n        updating_parameter = parameters.set_parameter(\n            name=\"/mySuper/Parameter\",\n            value=\"PowerToolsIsAwesome\",\n            overwrite=True,\n        )\n\n        return {\"mySuperParameterVersion\": updating_parameter, \"statusCode\": 200}\n    except parameters.exceptions.SetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#fetching-secrets",
            "title": "Fetching secrets",
            "text": "<p>You can fetch secrets stored in Secrets Manager using <code>get_secret</code>.</p> getting_started_secret.py <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in SSM Parameters\n        endpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\")\n        # An API-KEY is a sensitive data and should be stored in SecretsManager\n        api_key: Any = parameters.get_secret(\"/lambda-powertools/api-key\")\n\n        headers: dict = {\"X-API-Key\": api_key}\n\n        comments: requests.Response = requests.get(endpoint_comments, headers=headers)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#setting-secrets",
            "title": "Setting secrets",
            "text": "<p>You can set secrets stored in Secrets Manager using <code>set_secret</code>.</p> Note <p>We strive to minimize API calls by attempting to update existing secrets as our primary approach. If a secret doesn't exist, we proceed to create a new one.</p> getting_started_secret.py <pre><code>from typing import Any\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger(serialize_stacktrace=True)\n\n\ndef access_token(client_id: str, client_secret: str, audience: str) -&gt; str:\n    # example function that returns a JWT Access Token\n    # add your own logic here\n    return f\"{client_id}.{client_secret}.{audience}\"\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        client_id: Any = parameters.get_parameter(\"/aws-powertools/client_id\")\n        client_secret: Any = parameters.get_parameter(\"/aws-powertools/client_secret\")\n        audience: Any = parameters.get_parameter(\"/aws-powertools/audience\")\n\n        jwt_token = access_token(client_id=client_id, client_secret=client_secret, audience=audience)\n\n        # set-secret will create a new secret if it doesn't exist and return the version id\n        update_secret_version_id = parameters.set_secret(name=\"/aws-powertools/jwt_token\", value=jwt_token)\n\n        return {\"access_token\": \"updated\", \"statusCode\": 200, \"update_secret_version_id\": update_secret_version_id}\n    except parameters.exceptions.SetSecretError as error:\n        logger.exception(error)\n        return {\"access_token\": \"updated\", \"statusCode\": 400}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#fetching-app-configurations",
            "title": "Fetching app configurations",
            "text": "<p>You can fetch application configurations in AWS AppConfig using <code>get_app_config</code>.</p> <p>The following will retrieve the latest version and store it in the cache.</p> Warning <p>We make two API calls to fetch each unique configuration name during the first time. This is by design in AppConfig. Please consider adjusting <code>max_age</code> parameter to enhance performance.</p> getting_started_appconfig.py <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\n        endpoint_comments: Any = parameters.get_app_config(name=\"config\", environment=\"dev\", application=\"comments\")\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#environment-variables",
            "title": "Environment variables",
            "text": "<p>The following environment variables are available to configure the parameter utility at a global scope:</p> Setting Description Environment variable Default Max Age Adjusts for how long values are kept in cache (in seconds). <code>POWERTOOLS_PARAMETERS_MAX_AGE</code> <code>300</code> Debug Sample Rate Sets whether to decrypt or not values retrieved from AWS SSM Parameters Store. <code>POWERTOOLS_PARAMETERS_SSM_DECRYPT</code> <code>false</code> <p>You can also use <code>POWERTOOLS_PARAMETERS_MAX_AGE</code> through the <code>max_age</code> parameter and <code>POWERTOOLS_PARAMETERS_SSM_DECRYPT</code> through the <code>decrypt</code> parameter to override the environment variable values.</p>"
        },
        {
            "location": "utilities/parameters/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/parameters/#adjusting-cache-ttl",
            "title": "Adjusting cache TTL",
            "text": "Tip <p><code>max_age</code> parameter is also available in underlying provider functions like <code>get()</code>, <code>get_multiple()</code>, etc.</p> <p>By default, we cache parameters retrieved in-memory for 300 seconds (5 minutes). If you want to change this default value and set the same TTL for all parameters, you can set the <code>POWERTOOLS_PARAMETERS_MAX_AGE</code> environment variable. You can still set <code>max_age</code> for individual parameters.</p> <p>You can adjust how long we should keep values in cache by using the param <code>max_age</code>, when using  <code>get_parameter()</code>, <code>get_parameters()</code> and <code>get_secret()</code> methods across all providers.</p> single_ssm_parameter_with_cache.pyrecursive_ssm_parameter_with_cache.pysecret_with_cache.pyappconfig_with_cache.py <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter with 20s cache\n        endpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\", max_age=20)\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve multiple parameters from a path prefix\n        all_parameters: Any = parameters.get_parameters(\"/lambda-powertools/\", max_age=20)\n        endpoint_comments = \"https://jsonplaceholder.typicode.com/noexists/\"\n\n        for parameter, value in all_parameters.items():\n\n            if parameter == \"endpoint_comments\":\n                endpoint_comments = value\n\n        # the value of parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10]}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in SSM Parameters\n        endpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\")\n        # An API-KEY is a sensitive data and should be stored in SecretsManager\n        api_key: Any = parameters.get_secret(\"/lambda-powertools/api-key\", max_age=20)\n\n        headers: dict = {\"X-API-Key\": api_key}\n\n        comments: requests.Response = requests.get(endpoint_comments, headers=headers)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\n        endpoint_comments: Any = parameters.get_app_config(\n            name=\"config\",\n            environment=\"dev\",\n            application=\"comments\",\n            max_age=20,\n        )\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#always-fetching-the-latest",
            "title": "Always fetching the latest",
            "text": "<p>If you'd like to always ensure you fetch the latest parameter from the store regardless if already available in cache, use <code>force_fetch</code> param.</p> single_ssm_parameter_force_fetch.pyrecursive_ssm_parameter_force_fetch.pysecret_force_fetch.pyappconfig_force_fetch.py <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter with 20s cache\n        endpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\", force_fetch=True)\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve multiple parameters from a path prefix\n        all_parameters: Any = parameters.get_parameters(\"/lambda-powertools/\", force_fetch=True)\n        endpoint_comments = \"https://jsonplaceholder.typicode.com/noexists/\"\n\n        for parameter, value in all_parameters.items():\n\n            if parameter == \"endpoint_comments\":\n                endpoint_comments = value\n\n        # the value of parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10]}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in SSM Parameters\n        endpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\")\n        # An API-KEY is a sensitive data and should be stored in SecretsManager\n        api_key: Any = parameters.get_secret(\"/lambda-powertools/api-key\", force_fetch=True)\n\n        headers: dict = {\"X-API-Key\": api_key}\n\n        comments: requests.Response = requests.get(endpoint_comments, headers=headers)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\n        endpoint_comments: Any = parameters.get_app_config(\n            name=\"config\",\n            environment=\"dev\",\n            application=\"comments\",\n            force_fetch=True,\n        )\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#built-in-provider-class",
            "title": "Built-in provider class",
            "text": "<p>For greater flexibility such as configuring the underlying SDK client used by built-in providers, you can use their respective Provider Classes directly.</p> Tip <p>This is useful when you need to customize parameters for the SDK client, such as region, credentials, retries and others. For more information, read botocore.config and boto3.session.</p>"
        },
        {
            "location": "utilities/parameters/#ssmprovider",
            "title": "SSMProvider",
            "text": "builtin_provider_ssm_single_parameter.pybuiltin_provider_ssm_recursive_parameter.py <pre><code>from typing import Any\n\nimport requests\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# changing region_name, connect_timeout and retrie configurations\n# see: https://botocore.amazonaws.com/v1/documentation/api/latest/reference/config.html\nconfig = Config(region_name=\"sa-east-1\", connect_timeout=1, retries={\"total_max_attempts\": 2, \"max_attempts\": 5})\nssm_provider = parameters.SSMProvider(config=config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\n        endpoint_comments: Any = ssm_provider.get(\"/lambda-powertools/endpoint_comments\")\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport boto3\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n# assuming role from another account to get parameter there\n# see: https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html\nsts_client = boto3.client(\"sts\")\nassumed_role_object = sts_client.assume_role(\n    RoleArn=\"arn:aws:iam::account-of-role-to-assume:role/name-of-role\",\n    RoleSessionName=\"RoleAssume1\",\n)\ncredentials = assumed_role_object[\"Credentials\"]\n\n# using temporary credentials in your SSMProvider provider\n# see: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/core/session.html#module-boto3.session\nboto3_session = boto3.session.Session(\n    region_name=\"us-east-1\",\n    aws_access_key_id=credentials[\"AccessKeyId\"],\n    aws_secret_access_key=credentials[\"SecretAccessKey\"],\n    aws_session_token=credentials[\"SessionToken\"],\n)\nssm_provider = parameters.SSMProvider(boto3_session=boto3_session)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve multiple parameters from a path prefix\n        all_parameters: Any = ssm_provider.get_multiple(\"/lambda-powertools/\")\n        endpoint_comments = \"https://jsonplaceholder.typicode.com/noexists/\"\n\n        for parameter, value in all_parameters.items():\n            if parameter == \"endpoint_comments\":\n                endpoint_comments = value\n\n        # the value of parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10]}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <p>The AWS Systems Manager Parameter Store provider supports two additional arguments for the <code>get()</code> and <code>get_multiple()</code> methods:</p> Parameter Default Description decrypt <code>False</code> Will automatically decrypt the parameter. recursive <code>True</code> For <code>get_multiple()</code> only, will fetch all parameter values recursively based on a path prefix. <p>You can create <code>SecureString</code> parameters, which are parameters that have a plaintext parameter name and an encrypted parameter value. If you don't use the <code>decrypt</code> argument, you will get an encrypted value. Read here about best practices using KMS to secure your parameters.</p> Tip <p>If you want to always decrypt parameters, you can set the <code>POWERTOOLS_PARAMETERS_SSM_DECRYPT=true</code> environment variable. This will override the default value of <code>false</code> but you can still set the <code>decrypt</code> option for individual parameters.</p> builtin_provider_ssm_with_decrypt.pybuiltin_provider_ssm_with_no_recursive.py <pre><code>from typing import Any\nfrom uuid import uuid4\n\nimport boto3\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nec2 = boto3.resource(\"ec2\")\nssm_provider = parameters.SSMProvider()\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve the key pair from secure string parameter\n        ec2_pem: Any = ssm_provider.get(\"/lambda-powertools/ec2_pem\", decrypt=True)\n\n        name_key_pair = f\"kp_{uuid4()}\"\n\n        ec2.import_key_pair(KeyName=name_key_pair, PublicKeyMaterial=ec2_pem)\n\n        ec2.create_instances(\n            ImageId=\"ami-026b57f3c383c2eec\",\n            InstanceType=\"t2.micro\",\n            MinCount=1,\n            MaxCount=1,\n            KeyName=name_key_pair,\n        )\n\n        return {\"message\": \"EC2 created\", \"success\": True}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"message\": f\"Error creating EC2 =&gt; {str(error)}\", \"success\": False}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nssm_provider = parameters.SSMProvider()\n\n\nclass ConfigNotFound(Exception):\n    ...\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve multiple parameters from a path prefix\n        # /config = root\n        # /config/endpoint = url\n        # /config/endpoint/query = querystring\n        all_parameters: Any = ssm_provider.get_multiple(\"/config\", recursive=False)\n        endpoint_comments = \"https://jsonplaceholder.typicode.com/comments/\"\n\n        for parameter, value in all_parameters.items():\n\n            # query parameter is used to query endpoint\n            if \"query\" in parameter:\n                endpoint_comments = f\"{endpoint_comments}{value}\"\n                break\n        else:\n            # scheme config was not found because get_multiple is not recursive\n            raise ConfigNotFound(\"URL query parameter was not found\")\n\n        # the value of parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#secretsprovider",
            "title": "SecretsProvider",
            "text": "builtin_provider_secret.py <pre><code>from typing import Any\n\nimport requests\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nconfig = Config(region_name=\"sa-east-1\", connect_timeout=1, retries={\"total_max_attempts\": 2, \"max_attempts\": 5})\nssm_provider = parameters.SecretsProvider(config=config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in SSM Parameters\n        endpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\")\n        # An API-KEY is a sensitive data and should be stored in SecretsManager\n        api_key: Any = ssm_provider.get(\"/lambda-powertools/api-key\")\n\n        headers: dict = {\"X-API-Key\": api_key}\n\n        comments: requests.Response = requests.get(endpoint_comments, headers=headers)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#dynamodbprovider",
            "title": "DynamoDBProvider",
            "text": "<p>The DynamoDB Provider does not have any high-level functions, as it needs to know the name of the DynamoDB table containing the parameters.</p> <p>DynamoDB table structure for single parameters</p> <p>For single parameters, you must use <code>id</code> as the partition key for that table.</p> Example <p>DynamoDB table with <code>id</code> partition key and <code>value</code> as attribute</p> id value my-parameter my-value <p>With this table, <code>dynamodb_provider.get(\"my-parameter\")</code> will return <code>my-value</code>.</p> builtin_provider_dynamodb_single_parameter.pysam_dynamodb_table_single.yaml <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ndynamodb_provider = parameters.DynamoDBProvider(table_name=\"ParameterTable\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in DynamoDB Table\n        endpoint_comments: Any = dynamodb_provider.get(\"comments_endpoint\")\n\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    # general exception\n    except Exception as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: 'DynamoDB Table example'\nResources:\n  ParameterTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      TableName: ParameterTable\n      AttributeDefinitions:\n        -   AttributeName: id\n            AttributeType: S\n      KeySchema:\n        -   AttributeName: id\n            KeyType: HASH\n      TimeToLiveSpecification:\n        AttributeName: expiration\n        Enabled: true\n      BillingMode: PAY_PER_REQUEST\n</code></pre> <p>You can initialize the DynamoDB provider pointing to DynamoDB Local using <code>endpoint_url</code> parameter:</p> builtin_provider_dynamodb_custom_endpoint.py <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ndynamodb_provider = parameters.DynamoDBProvider(table_name=\"ParameterTable\", endpoint_url=\"http://localhost:8000\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in DynamoDB Table\n        endpoint_comments: Any = dynamodb_provider.get(\"comments_endpoint\")\n\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    # general exception\n    except Exception as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <p>DynamoDB table structure for multiple values parameters</p> <p>You can retrieve multiple parameters sharing the same <code>id</code> by having a sort key named <code>sk</code>.</p> Example <p>DynamoDB table with <code>id</code> primary key, <code>sk</code> as sort key and <code>value</code> as attribute</p> id sk value config endpoint_comments https://jsonplaceholder.typicode.com/comments/ config limit 10 <p>With this table, <code>dynamodb_provider.get_multiple(\"config\")</code> will return a dictionary response in the shape of <code>sk:value</code>.</p> builtin_provider_dynamodb_recursive_parameter.pysam_dynamodb_table_recursive.yaml <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ndynamodb_provider = parameters.DynamoDBProvider(table_name=\"ParameterTable\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Retrieve multiple parameters using HASH KEY\n        all_parameters: Any = dynamodb_provider.get_multiple(\"config\")\n        endpoint_comments = \"https://jsonplaceholder.typicode.com/noexists/\"\n        limit = 2\n\n        for parameter, value in all_parameters.items():\n\n            if parameter == \"endpoint_comments\":\n                endpoint_comments = value\n\n            if parameter == \"limit\":\n                limit = int(value)\n\n        # the value of parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[limit]}\n    # general exception\n    except Exception as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: 'DynamoDB Table example'\nResources:\n  ParameterTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      TableName: ParameterTable\n      AttributeDefinitions:\n        -   AttributeName: id\n            AttributeType: S\n        -   AttributeName: sk\n            AttributeType: S\n      KeySchema:\n        -   AttributeName: id\n            KeyType: HASH\n        -   AttributeName: sk\n            KeyType: RANGE\n      TimeToLiveSpecification:\n        AttributeName: expiration\n        Enabled: true\n      BillingMode: PAY_PER_REQUEST\n</code></pre> <p>Customizing DynamoDBProvider</p> <p>DynamoDB provider can be customized at initialization to match your table structure:</p> Parameter Mandatory Default Description table_name Yes (N/A) Name of the DynamoDB table containing the parameter values. key_attr No <code>id</code> Hash key for the DynamoDB table. sort_attr No <code>sk</code> Range key for the DynamoDB table. You don't need to set this if you don't use the <code>get_multiple()</code> method. value_attr No <code>value</code> Name of the attribute containing the parameter value. builtin_provider_dynamodb_custom_fields.pysam_dynamodb_custom_fields.yaml <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\ndynamodb_provider = parameters.DynamoDBProvider(\n    table_name=\"ParameterTable\",\n    key_attr=\"IdKeyAttr\",\n    sort_attr=\"SkKeyAttr\",\n    value_attr=\"ValueAttr\",\n)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Usually an endpoint is not sensitive data, so we store it in DynamoDB Table\n        endpoint_comments: Any = dynamodb_provider.get(\"comments_endpoint\")\n\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    # general exception\n    except Exception as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: 'DynamoDB Table example'\nResources:\n  ParameterTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      TableName: ParameterTable\n      AttributeDefinitions:\n        -   AttributeName: IdKeyAttr\n            AttributeType: S\n        -   AttributeName: SkKeyAttr\n            AttributeType: S\n      KeySchema:\n        -   AttributeName: IdKeyAttr\n            KeyType: HASH\n        -   AttributeName: SkKeyAttr\n            KeyType: RANGE\n      TimeToLiveSpecification:\n        AttributeName: expiration\n        Enabled: true\n      BillingMode: PAY_PER_REQUEST\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#appconfigprovider",
            "title": "AppConfigProvider",
            "text": "builtin_provider_appconfig.py <pre><code>from typing import Any\n\nimport requests\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nconfig = Config(region_name=\"sa-east-1\")\nappconf_provider = parameters.AppConfigProvider(environment=\"dev\", application=\"comments\", config=config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\n        endpoint_comments: Any = appconf_provider.get(\"config\")\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#create-your-own-provider",
            "title": "Create your own provider",
            "text": "<p>You can create your own custom parameter store provider by inheriting the <code>BaseProvider</code> class, and implementing both <code>_get()</code> and <code>_get_multiple()</code> methods to retrieve a single, or multiple parameters from your custom store.</p> <p>All transformation and caching logic is handled by the <code>get()</code> and <code>get_multiple()</code> methods from the base provider class.</p> <p>Here are two examples of implementing a custom parameter store. One using an external service like Hashicorp Vault, a widely popular key-value and secret storage and the other one using Amazon S3, a popular object storage.</p> working_with_own_provider_vault.pycustom_provider_vault.pyworking_with_own_provider_s3.pycustom_provider_s3.py <pre><code>from typing import Any\n\nimport hvac\nimport requests\nfrom custom_provider_vault import VaultProvider\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n# In production you must use Vault over HTTPS and certificates.\nvault_provider = VaultProvider(vault_url=\"http://192.168.68.105:8200/\", vault_token=\"YOUR_TOKEN\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\n        endpoint_comments: Any = vault_provider.get(\"comments_endpoint\")\n\n        # you can get all parameters using get_multiple and specifying vault mount point\n        # # for testing purposes we will not use it\n        all_parameters: Any = vault_provider.get_multiple(\"/\")\n        logger.info(all_parameters)\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments[\"url\"])\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except hvac.exceptions.InvalidPath as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n    # general exception\n    except Exception as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any, Dict\n\nfrom hvac import Client\n\nfrom aws_lambda_powertools.utilities.parameters import BaseProvider\n\n\nclass VaultProvider(BaseProvider):\n    def __init__(self, vault_url: str, vault_token: str) -&gt; None:\n        super().__init__()\n\n        self.vault_client = Client(url=vault_url, verify=False, timeout=10)\n        self.vault_client.token = vault_token\n\n    def _get(self, name: str, **sdk_options) -&gt; Dict[str, Any]:\n        # for example proposal, the mountpoint is always /secret\n        kv_configuration = self.vault_client.secrets.kv.v2.read_secret(path=name)\n\n        return kv_configuration[\"data\"][\"data\"]\n\n    def _get_multiple(self, path: str, **sdk_options) -&gt; Dict[str, str]:\n        list_secrets = {}\n        all_secrets = self.vault_client.secrets.kv.v2.list_secrets(path=path)\n\n        # for example proposal, the mountpoint is always /secret\n        for secret in all_secrets[\"data\"][\"keys\"]:\n            kv_configuration = self.vault_client.secrets.kv.v2.read_secret(path=secret)\n\n            for key, value in kv_configuration[\"data\"][\"data\"].items():\n                list_secrets[key] = value\n\n        return list_secrets\n</code></pre> <pre><code>from typing import Any\n\nimport requests\nfrom custom_provider_s3 import S3Provider\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\ns3_provider = S3Provider(bucket_name=\"bucket_name\")\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n\n    try:\n        # Retrieve a single parameter using key\n        endpoint_comments: Any = s3_provider.get(\"comments_endpoint\")\n        # you can get all parameters using get_multiple and specifying a bucket prefix\n        # # for testing purposes we will not use it\n        all_parameters: Any = s3_provider.get_multiple(\"/\")\n        logger.info(all_parameters)\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    # general exception\n    except Exception as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>import copy\nfrom typing import Dict\n\nimport boto3\n\nfrom aws_lambda_powertools.utilities.parameters import BaseProvider\n\n\nclass S3Provider(BaseProvider):\n    def __init__(self, bucket_name: str):\n        # Initialize the client to your custom parameter store\n        # E.g.:\n\n        super().__init__()\n\n        self.bucket_name = bucket_name\n        self.client = boto3.client(\"s3\")\n\n    def _get(self, name: str, **sdk_options) -&gt; str:\n        # Retrieve a single value\n        # E.g.:\n\n        sdk_options[\"Bucket\"] = self.bucket_name\n        sdk_options[\"Key\"] = name\n\n        response = self.client.get_object(**sdk_options)\n        return response[\"Body\"].read().decode()\n\n    def _get_multiple(self, path: str, **sdk_options) -&gt; Dict[str, str]:\n        # Retrieve multiple values\n        # E.g.:\n\n        list_sdk_options = copy.deepcopy(sdk_options)\n\n        list_sdk_options[\"Bucket\"] = self.bucket_name\n        list_sdk_options[\"Prefix\"] = path\n\n        list_response = self.client.list_objects_v2(**list_sdk_options)\n\n        parameters = {}\n\n        for obj in list_response.get(\"Contents\", []):\n            get_sdk_options = copy.deepcopy(sdk_options)\n\n            get_sdk_options[\"Bucket\"] = self.bucket_name\n            get_sdk_options[\"Key\"] = obj[\"Key\"]\n\n            get_response = self.client.get_object(**get_sdk_options)\n\n            parameters[obj[\"Key\"]] = get_response[\"Body\"].read().decode()\n\n        return parameters\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#deserializing-values-with-transform-parameter",
            "title": "Deserializing values with transform parameter",
            "text": "<p>For parameters stored in JSON or Base64 format, you can use the <code>transform</code> argument for deserialization.</p> Info <p>The <code>transform</code> argument is available across all providers, including the high level functions.</p> working_with_transform_high_level.pyworking_with_transform_provider.py <pre><code>from typing import Any\n\nimport requests\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    try:\n        # Retrieve a single parameter\n        endpoint_comments: Any = parameters.get_parameter(\"/lambda-powertools/endpoint_comments\", transform=\"json\")\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre> <pre><code>from typing import Any\n\nimport requests\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nconfig = Config(region_name=\"sa-east-1\")\nappconf_provider = parameters.AppConfigProvider(environment=\"dev\", application=\"comments\", config=config)\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        # Retrieve a single parameter\n        endpoint_comments: Any = appconf_provider.get(\"config\", transform=\"json\")\n\n        # the value of this parameter is https://jsonplaceholder.typicode.com/comments/\n        comments: requests.Response = requests.get(endpoint_comments)\n\n        return {\"comments\": comments.json()[:10], \"statusCode\": 200}\n    except parameters.exceptions.GetParameterError as error:\n        return {\"comments\": None, \"message\": str(error), \"statusCode\": 400}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#partial-transform-failures-with-get_multiple",
            "title": "Partial transform failures with <code>get_multiple()</code>",
            "text": "<p>If you use <code>transform</code> with <code>get_multiple()</code>, you can have a single malformed parameter value. To prevent failing the entire request, the method will return a <code>None</code> value for the parameters that failed to transform.</p> <p>You can override this by setting the <code>raise_on_transform_error</code> argument to <code>True</code>. If you do so, a single transform error will raise a <code>TransformParameterError</code> exception.</p> <p>For example, if you have three parameters, /param/a, /param/b and /param/c, but /param/c is malformed:</p> handling_error_transform.py <pre><code>from typing import Any\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nssm_provider = parameters.SSMProvider()\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    # This will display:\n    # /param/a: [some value]\n    # /param/b: [some value]\n    # /param/c: None\n    values: Any = ssm_provider.get_multiple(\"/param\", transform=\"json\")\n    for key, value in values.items():\n        print(f\"{key}: {value}\")\n\n    try:\n        # This will raise a TransformParameterError exception\n        values = ssm_provider.get_multiple(\"/param\", transform=\"json\", raise_on_transform_error=True)\n    except parameters.exceptions.TransformParameterError:\n        ...\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#auto-transform-values-on-suffix",
            "title": "Auto-transform values on suffix",
            "text": "<p>If you use <code>transform</code> with <code>get_multiple()</code>, you might want to retrieve and transform parameters encoded in different formats.</p> <p>You can do this with a single request by using <code>transform=\"auto\"</code>. This will instruct any Parameter to to infer its type based on the suffix and transform it accordingly.</p> Info <p><code>transform=\"auto\"</code> feature is available across all providers, including the high level functions.</p> working_with_auto_transform.py <pre><code>from aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nssm_provider = parameters.SSMProvider()\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    values = ssm_provider.get_multiple(\"/param\", transform=\"auto\")\n\n    return values\n</code></pre> <p>For example, if you have two parameters with the following suffixes <code>.json</code> and <code>.binary</code>:</p> Parameter name Parameter value /param/a.json [some encoded value] /param/a.binary [some encoded value] <p>The return of <code>ssm_provider.get_multiple(\"/param\", transform=\"auto\")</code> call will be a dictionary like:</p> <pre><code>{\n    \"a.json\": [some value],\n    \"b.binary\": [some value]\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#passing-additional-sdk-arguments",
            "title": "Passing additional SDK arguments",
            "text": "<p>You can use arbitrary keyword arguments to pass it directly to the underlying SDK method.</p> working_with_sdk_additional_arguments.py <pre><code>from aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nsecrets_provider = parameters.SecretsProvider()\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    # The 'VersionId' argument will be passed to the underlying get_secret_value() call.\n    value = secrets_provider.get(\"my-secret\", VersionId=\"e62ec170-6b01-48c7-94f3-d7497851a8d2\")\n\n    return value\n</code></pre> <p>Here is the mapping between this utility's functions and methods and the underlying SDK:</p> Provider Function/Method Client name Function name SSM Parameter Store <code>get_parameter</code> <code>ssm</code> get_parameter SSM Parameter Store <code>get_parameters</code> <code>ssm</code> get_parameters_by_path SSM Parameter Store <code>SSMProvider.get</code> <code>ssm</code> get_parameter SSM Parameter Store <code>SSMProvider.get_multiple</code> <code>ssm</code> get_parameters_by_path Secrets Manager <code>get_secret</code> <code>secretsmanager</code> get_secret_value Secrets Manager <code>SecretsProvider.get</code> <code>secretsmanager</code> get_secret_value DynamoDB <code>DynamoDBProvider.get</code> <code>dynamodb</code> (Table resource) DynamoDB <code>DynamoDBProvider.get_multiple</code> <code>dynamodb</code> (Table resource) App Config <code>get_app_config</code> <code>appconfigdata</code> start_configuration_session and get_latest_configuration"
        },
        {
            "location": "utilities/parameters/#bring-your-own-boto-client",
            "title": "Bring your own boto client",
            "text": "<p>You can use <code>boto3_client</code> parameter via any of the available Provider Classes. Some providers expect a low level boto3 client while others expect a high level boto3 client, here is the mapping for each of them:</p> Provider Type Boto client construction SSMProvider low level <code>boto3.client(\"ssm\")</code> SecretsProvider low level <code>boto3.client(\"secrets\")</code> AppConfigProvider low level <code>boto3.client(\"appconfigdata\")</code> DynamoDBProvider high level <code>boto3.resource(\"dynamodb\")</code> <p>Bringing them together in a single code snippet would look like this:</p> custom_boto3_all_providers.py <pre><code>import boto3\nfrom botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\n\nconfig = Config(region_name=\"us-west-1\")\n\n# construct boto clients with any custom configuration\nssm = boto3.client(\"ssm\", config=config)\nsecrets = boto3.client(\"secretsmanager\", config=config)\nappconfig = boto3.client(\"appconfigdata\", config=config)\ndynamodb = boto3.resource(\"dynamodb\", config=config)\n\nssm_provider = parameters.SSMProvider(boto3_client=ssm)\nsecrets_provider = parameters.SecretsProvider(boto3_client=secrets)\nappconf_provider = parameters.AppConfigProvider(boto3_client=appconfig, environment=\"my_env\", application=\"my_app\")\ndynamodb_provider = parameters.DynamoDBProvider(boto3_client=dynamodb, table_name=\"my-table\")\n</code></pre> When is this useful? <p>Injecting a custom boto3 client can make unit/snapshot testing easier, including SDK customizations.</p>"
        },
        {
            "location": "utilities/parameters/#customizing-boto-configuration",
            "title": "Customizing boto configuration",
            "text": "<p>The <code>boto_config</code> , <code>boto3_session</code>, and <code>boto3_client</code>  parameters enable you to pass in a custom botocore config object, boto3 session, or  a boto3 client when constructing any of the built-in provider classes.</p> Tip <p>You can use a custom session for retrieving parameters cross-account/region and for snapshot testing.</p> <p>When using VPC private endpoints, you can pass a custom client altogether. It's also useful for testing when injecting fake instances.</p> custom_boto_session.pycustom_boto_config.pycustom_boto_client.py <pre><code>import boto3\n\nfrom aws_lambda_powertools.utilities import parameters\n\nboto3_session = boto3.session.Session()\nssm_provider = parameters.SSMProvider(boto3_session=boto3_session)\n\n\ndef handler(event, context):\n    # Retrieve a single parameter\n    value = ssm_provider.get(\"/my/parameter\")\n\n    return value\n</code></pre> <pre><code>from botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\n\nboto_config = Config()\nssm_provider = parameters.SSMProvider(boto_config=boto_config)\n\n\ndef handler(event, context):\n    # Retrieve a single parameter\n    value = ssm_provider.get(\"/my/parameter\")\n\n    return value\n</code></pre> <pre><code>import boto3\n\nfrom aws_lambda_powertools.utilities import parameters\n\nboto3_client = boto3.client(\"ssm\")\nssm_provider = parameters.SSMProvider(boto3_client=boto3_client)\n\n\ndef handler(event, context):\n    # Retrieve a single parameter\n    value = ssm_provider.get(\"/my/parameter\")\n\n    return value\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#testing-your-code",
            "title": "Testing your code",
            "text": ""
        },
        {
            "location": "utilities/parameters/#mocking-parameter-values",
            "title": "Mocking parameter values",
            "text": "<p>For unit testing your applications, you can mock the calls to the parameters utility to avoid calling AWS APIs. This can be achieved in a number of ways - in this example, we use the pytest monkeypatch fixture to patch the <code>parameters.get_parameter</code> method:</p> test_single_mock.pysingle_mock.py <pre><code>from src import single_mock\n\n\ndef test_handler(monkeypatch):\n    def mockreturn(name):\n        return \"mock_value\"\n\n    monkeypatch.setattr(single_mock.parameters, \"get_parameter\", mockreturn)\n    return_val = single_mock.handler({}, {})\n    assert return_val.get(\"message\") == \"mock_value\"\n</code></pre> <pre><code>from aws_lambda_powertools.utilities import parameters\n\n\ndef handler(event, context):\n    # Retrieve a single parameter\n    value = parameters.get_parameter(\"my-parameter-name\")\n    return {\"message\": value}\n</code></pre> <p>If we need to use this pattern across multiple tests, we can avoid repetition by refactoring to use our own pytest fixture:</p> test_with_fixture.py <pre><code>import pytest\nfrom src import single_mock\n\n\n@pytest.fixture\ndef mock_parameter_response(monkeypatch):\n    def mockreturn(name):\n        return \"mock_value\"\n\n    monkeypatch.setattr(single_mock.parameters, \"get_parameter\", mockreturn)\n\n\n# Pass our fixture as an argument to all tests where we want to mock the get_parameter response\ndef test_handler(mock_parameter_response):\n    return_val = single_mock.handler({}, {})\n    assert return_val.get(\"message\") == \"mock_value\"\n</code></pre> <p>Alternatively, if we need more fully featured mocking (for example checking the arguments passed to <code>get_parameter</code>), we can use unittest.mock from the python stdlib instead of pytest's <code>monkeypatch</code> fixture. In this example, we use the patch decorator to replace the <code>aws_lambda_powertools.utilities.parameters.get_parameter</code> function with a MagicMock object named <code>get_parameter_mock</code>.</p> test_with_monkeypatch.py <pre><code>from unittest.mock import patch\n\nfrom src import single_mock\n\n\n# Replaces \"aws_lambda_powertools.utilities.parameters.get_parameter\" with a Mock object\n@patch(\"aws_lambda_powertools.utilities.parameters.get_parameter\")\ndef test_handler(get_parameter_mock):\n    get_parameter_mock.return_value = \"mock_value\"\n\n    return_val = single_mock.handler({}, {})\n    get_parameter_mock.assert_called_with(\"my-parameter-name\")\n    assert return_val.get(\"message\") == \"mock_value\"\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#clearing-cache",
            "title": "Clearing cache",
            "text": "<p>Parameters utility caches all parameter values for performance and cost reasons. However, this can have unintended interference in tests using the same parameter name.</p> <p>Within your tests, you can use <code>clear_cache</code> method available in every provider. When using multiple providers or higher level functions like <code>get_parameter</code>, use <code>clear_caches</code> standalone function to clear cache globally.</p> test_clear_cache_method.pytest_clear_cache_global.pyapp.py <pre><code>import pytest\nfrom src import app\n\n\n@pytest.fixture(scope=\"function\", autouse=True)\ndef clear_parameters_cache():\n    yield\n    app.ssm_provider.clear_cache()  # This will clear SSMProvider cache\n\n\n@pytest.fixture\ndef mock_parameter_response(monkeypatch):\n    def mockreturn(name):\n        return \"mock_value\"\n\n    monkeypatch.setattr(app.ssm_provider, \"get\", mockreturn)\n\n\n# Pass our fixture as an argument to all tests where we want to mock the get_parameter response\ndef test_handler(mock_parameter_response):\n    return_val = app.handler({}, {})\n    assert return_val.get(\"message\") == \"mock_value\"\n</code></pre> <pre><code>import pytest\nfrom src import app\n\nfrom aws_lambda_powertools.utilities import parameters\n\n\n@pytest.fixture(scope=\"function\", autouse=True)\ndef clear_parameters_cache():\n    yield\n    parameters.clear_caches()  # This will clear all providers cache\n\n\n@pytest.fixture\ndef mock_parameter_response(monkeypatch):\n    def mockreturn(name):\n        return \"mock_value\"\n\n    monkeypatch.setattr(app.ssm_provider, \"get\", mockreturn)\n\n\n# Pass our fixture as an argument to all tests where we want to mock the get_parameter response\ndef test_handler(mock_parameter_response):\n    return_val = app.handler({}, {})\n    assert return_val.get(\"message\") == \"mock_value\"\n</code></pre> <pre><code>from botocore.config import Config\n\nfrom aws_lambda_powertools.utilities import parameters\n\nssm_provider = parameters.SSMProvider(config=Config(region_name=\"us-west-1\"))\n\n\ndef handler(event, context):\n    value = ssm_provider.get(\"/my/parameter\")\n    return {\"message\": value}\n</code></pre>"
        },
        {
            "location": "utilities/parser/",
            "title": "Parser (Pydantic)",
            "text": "<p>The Parser utility simplifies data parsing and validation using Pydantic. It allows you to define data models in pure Python classes, parse and validate incoming events, and extract only the data you need.</p>"
        },
        {
            "location": "utilities/parser/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Define data models using Python classes</li> <li>Parse and validate Lambda event payloads</li> <li>Built-in support for common AWS event sources</li> <li>Runtime type checking with user-friendly error messages</li> <li>Compatible with Pydantic v2.x</li> </ul>"
        },
        {
            "location": "utilities/parser/#getting-started",
            "title": "Getting started",
            "text": ""
        },
        {
            "location": "utilities/parser/#install",
            "title": "Install",
            "text": "<p>Powertools only supports Pydantic v2, so make sure to install the required dependencies for Pydantic v2 before using the Parser.</p> <pre><code>pip install aws-lambda-powertools[parser]\n</code></pre> <p>This is not necessary if you're installing Powertools for AWS Lambda (Python) via Lambda Layer/SAR</p> <p>You can also add as a dependency in your preferred tool: <code>e.g., requirements.txt, pyproject.toml</code>, etc.</p>"
        },
        {
            "location": "utilities/parser/#data-model-with-parser",
            "title": "Data Model with Parser",
            "text": "<p>You can define models by inheriting from <code>BaseModel</code> or any other supported type through <code>TypeAdapter</code> to parse incoming events. Pydantic then validates the data, ensuring that all fields conform to the specified types and maintaining data integrity.</p> Info <p>The new TypeAdapter feature provide a flexible way to perform validation and serialization based on a Python type. Read more in the Pydantic documentation.</p>"
        },
        {
            "location": "utilities/parser/#event-parser",
            "title": "Event parser",
            "text": "<p>The <code>@event_parser</code> decorator automatically parses the incoming event into the specified Pydantic model <code>MyEvent</code>. If the input doesn't match the model's structure or type requirements, it raises a <code>ValidationError</code> directly from Pydantic.</p> getting_started_with_parser.pySample event <pre><code>from pydantic import BaseModel\n\nfrom aws_lambda_powertools.utilities.parser import event_parser\n\n\nclass MyEvent(BaseModel):\n    id: int\n    name: str\n\n\n@event_parser(model=MyEvent)\ndef lambda_handler(event: MyEvent, context):\n    # if your model is valid, you can return\n    return {\"statusCode\": 200, \"body\": f\"Hello {event.name}, your ID is {event.id}\"}\n</code></pre> <pre><code>{\n    \"id\": \"12345\",\n    \"name\": \"Jane Doe\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/parser/#parse-function",
            "title": "Parse function",
            "text": "<p>You can use the <code>parse()</code> function when you need to have flexibility with different event formats, custom pre-parsing logic, and better exception handling.</p> parser_function.pySample event <pre><code>from pydantic import BaseModel, ValidationError\n\nfrom aws_lambda_powertools.utilities.parser import parse\n\n\n# Define a Pydantic model for the expected structure of the input\nclass MyEvent(BaseModel):\n    id: int\n    name: str\n\n\ndef lambda_handler(event: dict, context):\n    try:\n        # Manually parse the incoming event into MyEvent model\n        parsed_event: MyEvent = parse(model=MyEvent, event=event)\n        return {\"statusCode\": 200, \"body\": f\"Hello {parsed_event.name}, your ID is {parsed_event.id}\"}\n    except ValidationError as e:\n        # Catch validation errors and return a 400 response\n        return {\"statusCode\": 400, \"body\": f\"Validation error: {str(e)}\"}\n</code></pre> <pre><code>{\n    \"id\": \"12345\",\n    \"name\": \"Jane Doe\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/parser/#keys-differences-between-parse-and-event_parser",
            "title": "Keys differences between parse and event_parser",
            "text": "<p>The <code>parse()</code> function offers more flexibility and control:</p> <ul> <li>It allows parsing different parts of an event using multiple models.</li> <li>You can conditionally handle events before parsing them.</li> <li>It's useful for integrating with complex workflows where a decorator might not be sufficient.</li> <li>It provides more control over the validation process and handling exceptions.</li> </ul> <p>The <code>@event_parser</code> decorator is ideal for:</p> <ul> <li>Fail-fast scenarios where you want to immediately stop execution if the event payload is invalid.</li> <li>Simplifying your code by automatically parsing and validating the event at the function entry point.</li> </ul>"
        },
        {
            "location": "utilities/parser/#built-in-models",
            "title": "Built-in models",
            "text": "<p>You can use pre-built models to work events from AWS services, so you don’t need to create them yourself. We’ve already done that for you!</p> sqs_model_event.pySample event <pre><code>from aws_lambda_powertools.utilities.parser import parse\nfrom aws_lambda_powertools.utilities.parser.models import SqsModel\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; list:\n    parsed_event = parse(model=SqsModel, event=event)\n\n    results = []\n    for record in parsed_event.Records:\n        results.append(\n            {\n                \"message_id\": record.messageId,\n                \"body\": record.body,\n            },\n        )\n    return results\n</code></pre> <pre><code>{\n    \"Records\": [\n        {\n            \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n            \"body\": \"Test message hello!\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {\n                \"testAttr\": {\n                    \"stringValue\": \"100\",\n                    \"binaryValue\": \"base64Str\",\n                    \"dataType\": \"Number\"\n                }\n            },\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:my-queue\",\n            \"awsRegion\": \"us-east-2\"\n        }\n    ]\n}\n</code></pre> <p>The example above uses <code>SqsModel</code>. Other built-in models can be found below.</p> Model name Description AlbModel Lambda Event Source payload for Amazon Application Load Balancer APIGatewayProxyEventModel Lambda Event Source payload for Amazon API Gateway ApiGatewayAuthorizerToken Lambda Event Source payload for Amazon API Gateway Lambda Authorizer with Token ApiGatewayAuthorizerRequest Lambda Event Source payload for Amazon API Gateway Lambda Authorizer with Request APIGatewayProxyEventV2Model Lambda Event Source payload for Amazon API Gateway v2 payload ApiGatewayAuthorizerRequestV2 Lambda Event Source payload for Amazon API Gateway v2 Lambda Authorizer APIGatewayWebSocketMessageEventModel Lambda Event Source payload for Amazon API Gateway WebSocket API message body APIGatewayWebSocketConnectEventModel Lambda Event Source payload for Amazon API Gateway WebSocket API $connect message APIGatewayWebSocketDisconnectEventModel Lambda Event Source payload for Amazon API Gateway WebSocket API $disconnect message AppSyncResolverEventModel Lambda Event Source payload for AWS AppSync Resolver BedrockAgentEventModel Lambda Event Source payload for Bedrock Agents CloudFormationCustomResourceCreateModel Lambda Event Source payload for AWS CloudFormation <code>CREATE</code> operation CloudFormationCustomResourceUpdateModel Lambda Event Source payload for AWS CloudFormation <code>UPDATE</code> operation CloudFormationCustomResourceDeleteModel Lambda Event Source payload for AWS CloudFormation <code>DELETE</code> operation CloudwatchLogsModel Lambda Event Source payload for Amazon CloudWatch Logs DynamoDBStreamModel Lambda Event Source payload for Amazon DynamoDB Streams EventBridgeModel Lambda Event Source payload for Amazon EventBridge IoTCoreThingEvent Lambda Event Source payload for IoT Core Thing created, updated, or deleted. IoTCoreThingTypeEvent Lambda Event Source payload for IoT Core Thing Type events. IoTCoreThingTypeAssociationEvent Lambda Event Source payload for IoT Core Thing Type associated or disassociated with a Thing. IoTCoreThingGroupEvent Lambda Event Source payload for IoT Core Thing Group created, updated, or deleted. IoTCoreAddOrRemoveFromThingGroupEvent Lambda Event Source payload for IoT Core Thing added to or removed from a Thing Group. IoTCoreAddOrDeleteFromThingGroupEvent Lambda Event Source payload for IoT Core Thing Group added to or deleted from a Thing Group. KafkaMskEventModel Lambda Event Source payload for AWS MSK payload KafkaSelfManagedEventModel Lambda Event Source payload for self managed Kafka payload KinesisDataStreamModel Lambda Event Source payload for Amazon Kinesis Data Streams KinesisFirehoseModel Lambda Event Source payload for Amazon Kinesis Firehose KinesisFirehoseSqsModel Lambda Event Source payload for SQS messages wrapped in Kinesis Firehose records LambdaFunctionUrlModel Lambda Event Source payload for Lambda Function URL payload S3BatchOperationModel Lambda Event Source payload for Amazon S3 Batch Operation S3EventNotificationEventBridgeModel Lambda Event Source payload for Amazon S3 Event Notification to EventBridge. S3Model Lambda Event Source payload for Amazon S3 S3ObjectLambdaEvent Lambda Event Source payload for Amazon S3 Object Lambda S3SqsEventNotificationModel Lambda Event Source payload for S3 event notifications wrapped in SQS event (S3-&gt;SQS) SesModel Lambda Event Source payload for Amazon Simple Email Service SnsModel Lambda Event Source payload for Amazon Simple Notification Service SqsModel Lambda Event Source payload for Amazon SQS TransferFamilyAuthorizer Lambda Event Source payload for AWS Transfer Family Lambda authorizer VpcLatticeModel Lambda Event Source payload for Amazon VPC Lattice VpcLatticeV2Model Lambda Event Source payload for Amazon VPC Lattice v2 payload"
        },
        {
            "location": "utilities/parser/#extending-built-in-models",
            "title": "Extending built-in models",
            "text": "<p>You can extend them to include your own models, and yet have all other known fields parsed along the way.</p> Tip <p>For Mypy users, we only allow type override for fields where payload is injected e.g. <code>detail</code>, <code>body</code>, etc.</p> <p>Example: custom data model with Amazon EventBridge Use the model to validate and extract relevant information from the incoming event. This can be useful when you need to handle events with a specific structure or when you want to ensure that the event data conforms to certain rules.</p> Custom data modelSample event <pre><code>from pydantic import Field, ValidationError\n\nfrom aws_lambda_powertools.utilities.parser import parse\nfrom aws_lambda_powertools.utilities.parser.models import EventBridgeModel\n\n\n# Define a custom EventBridge model by extending the built-in EventBridgeModel\nclass MyCustomEventBridgeModel(EventBridgeModel):  # type: ignore[override]\n    detail_type: str = Field(alias=\"detail-type\")\n    source: str\n    detail: dict\n\n\ndef lambda_handler(event: dict, context):\n    try:\n        # Manually parse the incoming event into the custom model\n        parsed_event: MyCustomEventBridgeModel = parse(model=MyCustomEventBridgeModel, event=event)\n\n        return {\"statusCode\": 200, \"body\": f\"Event from {parsed_event.source}, type: {parsed_event.detail_type}\"}\n    except ValidationError as e:\n        return {\"statusCode\": 400, \"body\": f\"Validation error: {str(e)}\"}\n</code></pre> <pre><code>{\n    \"version\": \"0\",\n    \"id\": \"abcd-1234-efgh-5678\",\n    \"detail-type\": \"order.created\",\n    \"source\": \"my.order.service\",\n    \"account\": \"123456789012\",\n    \"time\": \"2023-09-10T12:00:00Z\",\n    \"region\": \"us-west-2\",\n    \"resources\": [],\n    \"detail\": {\n        \"orderId\": \"O-12345\",\n        \"amount\": 100.0\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/parser/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/parser/#envelopes",
            "title": "Envelopes",
            "text": "<p>You can use Envelopes to extract specific portions of complex, nested JSON structures. This is useful when your actual payload is wrapped around a known structure, for example Lambda Event Sources like EventBridge.</p> <p>Envelopes can be used via <code>envelope</code> parameter available in both <code>parse</code> function and <code>event_parser</code> decorator.</p> Envelopes using event parser decoratorSample event <pre><code>from pydantic import BaseModel\n\nfrom aws_lambda_powertools.utilities.parser import envelopes, event_parser\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass UserModel(BaseModel):\n    username: str\n    parentid_1: str\n    parentid_2: str\n\n\n@event_parser(model=UserModel, envelope=envelopes.EventBridgeEnvelope)\ndef lambda_handler(event: UserModel, context: LambdaContext):\n    if event.parentid_1 != event.parentid_2:\n        return {\"statusCode\": 400, \"body\": \"Parent ids do not match\"}\n\n    # If parentids match, proceed with user registration\n\n    return {\"statusCode\": 200, \"body\": f\"User {event.username} registered successfully\"}\n</code></pre> <pre><code>{\n    \"version\": \"0\",\n    \"id\": \"6a7e8feb-b491-4cf7-a9f1-bf3703467718\",\n    \"detail-type\": \"CustomerSignedUp\",\n    \"source\": \"CustomerService\",\n    \"account\": \"111122223333\",\n    \"time\": \"2020-10-22T18:43:48Z\",\n    \"region\": \"us-west-1\",\n    \"resources\": [\n        \"some_additional_\"\n    ],\n    \"detail\": {\n        \"username\": \"universe\",\n        \"parentid_1\": \"12345\",\n        \"parentid_2\": \"6789\"\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/parser/#built-in-envelopes",
            "title": "Built-in envelopes",
            "text": "<p>You can use pre-built envelopes provided by the Parser to extract and parse specific parts of complex event structures.</p> Envelope name Behaviour Return DynamoDBStreamEnvelope 1. Parses data using <code>DynamoDBStreamModel</code>. <code>2. Parses records in `NewImage` and `OldImage` keys using your model.</code> 3. Returns a list with a dictionary containing <code>NewImage</code> and <code>OldImage</code> keys <code>List[Dict[str, Optional[Model]]]</code> EventBridgeEnvelope 1. Parses data using <code>EventBridgeModel</code>. <code>2. Parses `detail` key using your model</code> and returns it. <code>Model</code> SqsEnvelope 1. Parses data using <code>SqsModel</code>. <code>2. Parses records in `body` key using your model</code> and return them in a list. <code>List[Model]</code> CloudWatchLogsEnvelope 1. Parses data using <code>CloudwatchLogsModel</code> which will base64 decode and decompress it. <code>2. Parses records in `message` key using your model</code> and return them in a list. <code>List[Model]</code> KinesisDataStreamEnvelope 1. Parses data using <code>KinesisDataStreamModel</code> which will base64 decode it. <code>2. Parses records in in `Records` key using your model</code> and returns them in a list. <code>List[Model]</code> KinesisFirehoseEnvelope 1. Parses data using <code>KinesisFirehoseModel</code> which will base64 decode it. <code>2. Parses records in in` Records` key using your model</code> and returns them in a list. <code>List[Model]</code> SnsEnvelope 1. Parses data using <code>SnsModel</code>. <code>2. Parses records in `body` key using your model</code> and return them in a list. <code>List[Model]</code> SnsSqsEnvelope 1. Parses data using <code>SqsModel</code>. <code>2. Parses SNS records in `body` key using `SnsNotificationModel`.</code> 3. Parses data in <code>Message</code> key using your model and return them in a list. <code>List[Model]</code> ApiGatewayV2Envelope 1. Parses data using <code>APIGatewayProxyEventV2Model</code>. <code>2. Parses `body` key using your model</code> and returns it. <code>Model</code> ApiGatewayEnvelope 1. Parses data using <code>APIGatewayProxyEventModel</code>. <code>2. Parses `body` key using your model</code> and returns it. <code>Model</code> ApiGatewayWebSocketEnvelope 1. Parses data using <code>APIGatewayWebSocketMessageEventModel</code>. <code>2. Parses `body` key using your model</code> and returns it. <code>Model</code> LambdaFunctionUrlEnvelope 1. Parses data using <code>LambdaFunctionUrlModel</code>. <code>2. Parses `body` key using your model</code> and returns it. <code>Model</code> KafkaEnvelope 1. Parses data using <code>KafkaRecordModel</code>. <code>2. Parses `value` key using your model</code> and returns it. <code>Model</code> VpcLatticeEnvelope 1. Parses data using <code>VpcLatticeModel</code>. <code>2. Parses `value` key using your model</code> and returns it. <code>Model</code> BedrockAgentEnvelope 1. Parses data using <code>BedrockAgentEventModel</code>. <code>2. Parses `inputText` key using your model</code> and returns it. <code>Model</code>"
        },
        {
            "location": "utilities/parser/#bringing-your-own-envelope",
            "title": "Bringing your own envelope",
            "text": "<p>You can create your own Envelope model and logic by inheriting from <code>BaseEnvelope</code>, and implementing the <code>parse</code> method.</p> <p>Here's a snippet of how the EventBridge envelope we demonstrated previously is implemented.</p> Bring your own envelope with Event BridgeSample event <pre><code>import json\nfrom typing import Any, Dict, Optional, Type, TypeVar, Union\n\nfrom pydantic import BaseModel\n\nfrom aws_lambda_powertools.utilities.parser import BaseEnvelope, event_parser\nfrom aws_lambda_powertools.utilities.parser.models import EventBridgeModel\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nModel = TypeVar(\"Model\", bound=BaseModel)\n\n\nclass EventBridgeEnvelope(BaseEnvelope):\n    def parse(self, data: Optional[Union[Dict[str, Any], Any]], model: Type[Model]) -&gt; Optional[Model]:\n        if data is None:\n            return None\n\n        parsed_envelope = EventBridgeModel.model_validate(data)\n        return self._parse(data=parsed_envelope.detail, model=model)\n\n\nclass OrderDetail(BaseModel):\n    order_id: str\n    amount: float\n    customer_id: str\n\n\n@event_parser(model=OrderDetail, envelope=EventBridgeEnvelope)\ndef lambda_handler(event: OrderDetail, context: LambdaContext):\n    try:\n        # Process the order\n        print(f\"Processing order {event.order_id} for customer {event.customer_id}\")\n        print(f\"Order amount: ${event.amount:.2f}\")\n\n        # Your business logic here\n        # For example, you might save the order to a database or trigger a payment process\n\n        return {\n            \"statusCode\": 200,\n            \"body\": json.dumps(\n                {\n                    \"message\": f\"Order {event.order_id} processed successfully\",\n                    \"order_id\": event.order_id,\n                    \"amount\": event.amount,\n                    \"customer_id\": event.customer_id,\n                },\n            ),\n        }\n    except Exception as e:\n        print(f\"Error processing order: {str(e)}\")\n        return {\"statusCode\": 500, \"body\": json.dumps({\"error\": \"Internal server error\"})}\n</code></pre> <pre><code>{\n    \"version\": \"0\",\n    \"id\": \"12345678-1234-1234-1234-123456789012\",\n    \"detail-type\": \"Order Placed\",\n    \"source\": \"com.mycompany.orders\",\n    \"account\": \"123456789012\",\n    \"time\": \"2023-05-03T12:00:00Z\",\n    \"region\": \"us-west-2\",\n    \"resources\": [],\n    \"detail\": {\n        \"order_id\": \"ORD-12345\",\n        \"amount\": 99.99,\n        \"customer_id\": \"CUST-6789\"\n    }\n}\n</code></pre> <p>What's going on here, you might ask:</p> <ul> <li>EventBridgeEnvelope: extracts the detail field from EventBridge events.</li> <li>OrderDetail Model: defines and validates the structure of order data.</li> <li>@event_parser: decorator automates parsing and validation of incoming events using the specified model and envelope.</li> </ul>"
        },
        {
            "location": "utilities/parser/#data-model-validation",
            "title": "Data model validation",
            "text": "Warning <p>This is radically different from the Validator utility which validates events against JSON Schema.</p> <p>You can use Pydantic's validator for deep inspection of object values and complex relationships.</p> <p>There are two types of class method decorators you can use:</p> <ul> <li><code>field_validator</code> - Useful to quickly validate an individual field and its value</li> <li><code>model_validator</code> - Useful to validate the entire model's data</li> </ul> <p>Keep the following in mind regardless of which decorator you end up using it:</p> <ul> <li>You must raise either <code>ValueError</code>, <code>TypeError</code>, or <code>AssertionError</code> when value is not compliant</li> <li>You must return the value(s) itself if compliant</li> </ul>"
        },
        {
            "location": "utilities/parser/#field-validator",
            "title": "Field Validator",
            "text": "<p>Quick validation using decorator <code>field_validator</code> to verify whether the field <code>message</code> has the value of <code>hello world</code>.</p> field_validator.py<pre><code>from pydantic import BaseModel, field_validator\n\nfrom aws_lambda_powertools.utilities.parser import parse\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass HelloWorldModel(BaseModel):\n    message: str\n\n    @field_validator(\"message\")\n    def is_hello_world(cls, v):\n        if v != \"hello world\":\n            raise ValueError(\"Message must be hello world!\")\n        return v\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        parsed_event = parse(model=HelloWorldModel, event=event)\n        return {\"statusCode\": 200, \"body\": f\"Received message: {parsed_event.message}\"}\n    except ValueError as e:\n        return {\"statusCode\": 400, \"body\": str(e)}\n</code></pre> <p>If you run using a test event <code>{\"message\": \"hello universe\"}</code> you should expect the following error with the message we provided in our exception:</p> <pre><code>  Message must be hello world! (type=value_error)\n</code></pre>"
        },
        {
            "location": "utilities/parser/#model-validator",
            "title": "Model validator",
            "text": "<p><code>model_validator</code> can help when you have a complex validation mechanism. For example finding whether data has been omitted or comparing field values.</p> <p>If you are still using the deprecated <code>root_validator</code> function, switch to <code>model_validator</code> for the latest Pydantic functionality.</p> model_validator.py<pre><code>from pydantic import BaseModel, model_validator\n\nfrom aws_lambda_powertools.utilities.parser import parse\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\nclass UserModel(BaseModel):\n    username: str\n    parentid_1: str\n    parentid_2: str\n\n    @model_validator(mode=\"after\")  # (1)!\n    def check_parents_match(cls, values):\n        pi1, pi2 = values.get(\"parentid_1\"), values.get(\"parentid_2\")\n        if pi1 is not None and pi2 is not None and pi1 != pi2:\n            raise ValueError(\"Parent ids do not match\")\n        return values\n\n\ndef lambda_handler(event: dict, context: LambdaContext):\n    try:\n        parsed_event = parse(model=UserModel, event=event)\n        return {\n            \"statusCode\": 200,\n            \"body\": f\"Received parent id from: {parsed_event.username}\",\n        }\n    except ValueError as e:\n        return {\n            \"statusCode\": 400,\n            \"body\": str(e),\n        }\n</code></pre> <ol> <li>The keyword argument <code>mode='after'</code> will cause the validator to be called after all field-level validation and parsing has been completed.</li> </ol> Info <p>You can read more about validating list items, reusing validators, validating raw inputs, and a lot more in Pydantic's documentation.</p>"
        },
        {
            "location": "utilities/parser/#string-fields-that-contain-json-data",
            "title": "String fields that contain JSON data",
            "text": "<p>Wrap these fields with Pydantic's Json Type. This approach allows Pydantic to properly parse and validate the JSON content, ensuring type safety and data integrity.</p> Validate string fields containing JSON dataSample event <pre><code>from __future__ import annotations\n\nfrom typing import TYPE_CHECKING, Any\n\nfrom pydantic import BaseModel, Json\n\nfrom aws_lambda_powertools.utilities.parser import BaseEnvelope, event_parser\nfrom aws_lambda_powertools.utilities.parser.functions import (\n    _parse_and_validate_event,\n    _retrieve_or_set_model_from_cache,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nif TYPE_CHECKING:\n    from aws_lambda_powertools.utilities.parser.types import T\n\n\nclass CancelOrder(BaseModel):\n    order_id: int\n    reason: str\n\n\nclass CancelOrderModel(BaseModel):\n    body: Json[CancelOrder]\n\n\nclass CustomEnvelope(BaseEnvelope):\n    def parse(self, data: dict[str, Any] | Any | None, model: type[T]):\n        adapter = _retrieve_or_set_model_from_cache(model=model)\n        return _parse_and_validate_event(data=data, adapter=adapter)\n\n\n@event_parser(model=CancelOrderModel, envelope=CustomEnvelope)\ndef lambda_handler(event: CancelOrderModel, context: LambdaContext):\n    cancel_order: CancelOrder = event.body\n\n    assert cancel_order.order_id is not None\n\n    # Process the cancel order request\n    print(f\"Cancelling order {cancel_order.order_id} for reason: {cancel_order.reason}\")\n\n    return {\n        \"statusCode\": 200,\n        \"body\": f\"Order {cancel_order.order_id} cancelled successfully\",\n    }\n</code></pre> <pre><code>{\n    \"body\": \"{\\\"order_id\\\": 12345, \\\"reason\\\": \\\"Changed my mind\\\"}\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/parser/#serialization",
            "title": "Serialization",
            "text": "<p>Models in Pydantic offer more than direct attribute access. They can be transformed, serialized, and exported in various formats.</p> <p>Pydantic's definition of serialization is broader than usual. It includes converting structured objects to simpler Python types, not just data to strings or bytes. This reflects the close relationship between these processes in Pydantic.</p> <p>Read more at Serialization for Pydantic documentation.</p> serialization_parser.py<pre><code>from pydantic import BaseModel\n\nfrom aws_lambda_powertools.logging import Logger\nfrom aws_lambda_powertools.utilities.parser import parse\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\nclass UserModel(BaseModel):\n    username: str\n    parentid_1: str\n    parentid_2: str\n\n\ndef validate_user(event):\n    try:\n        user = parse(model=UserModel, event=event)\n        return {\"statusCode\": 200, \"body\": user.model_dump_json()}\n    except Exception as e:\n        logger.exception(\"Validation error\")\n        return {\"statusCode\": 400, \"body\": str(e)}\n\n\n@logger.inject_lambda_context\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    logger.info(\"Received event\", extra={\"event\": event})\n\n    result = validate_user(event)\n\n    if result[\"statusCode\"] == 200:\n        user = UserModel.model_validate_json(result[\"body\"])\n        logger.info(\"User validated successfully\", extra={\"username\": user.username})\n\n        # Example of serialization\n        user_dict = user.model_dump()\n        user_json = user.model_dump_json()\n\n        logger.debug(\"User serializations\", extra={\"dict\": user_dict, \"json\": user_json})\n\n    return result\n</code></pre> Info <p>There are number of advanced use cases well documented in Pydantic's doc such as creating immutable models, declaring fields with dynamic values.</p>"
        },
        {
            "location": "utilities/parser/#faq",
            "title": "FAQ",
            "text": "<p>When should I use parser vs data_classes utility?</p> <p>Use data classes utility when you're after autocomplete, self-documented attributes and helpers to extract data from common event sources.</p> <p>Parser is best suited for those looking for a trade-off between defining their models for deep validation, parsing and autocomplete for an additional dependency to be brought in.</p> <p>How do I import X from Pydantic?</p> <p>We recommend importing directly from Pydantic to access all features and stay up-to-date with the latest Pydantic updates. For example:</p> <pre><code>from pydantic import BaseModel, Field, ValidationError\n</code></pre> <p>While we export some common Pydantic classes and utilities through the parser for convenience (e.g., <code>from aws_lambda_powertools.utilities.parser import BaseModel</code>), importing directly from Pydantic ensures you have access to all features and the most recent updates.</p>"
        },
        {
            "location": "utilities/streaming/",
            "title": "Streaming",
            "text": "<p>The streaming utility handles datasets larger than the available memory as streaming data.</p>"
        },
        {
            "location": "utilities/streaming/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Stream Amazon S3 objects with a file-like interface with minimal memory consumption</li> <li>Built-in popular data transformations to decompress and deserialize (gzip, CSV, and ZIP)</li> <li>Build your own data transformation and add it to the pipeline</li> </ul>"
        },
        {
            "location": "utilities/streaming/#background",
            "title": "Background",
            "text": "<p>Within Lambda, processing S3 objects larger than the allocated amount of memory can lead to out of memory or timeout situations. For cost efficiency, your S3 objects may be encoded and compressed in various formats (gzip, CSV, zip files, etc), increasing the  amount of non-business logic and reliability risks.</p> <p>Streaming utility makes this process easier by fetching parts of your data as you consume it, and transparently applying data transformations to the data stream. This allows you to process one, a few, or all rows of your large dataset while consuming a few MBs only.</p>"
        },
        {
            "location": "utilities/streaming/#getting-started",
            "title": "Getting started",
            "text": ""
        },
        {
            "location": "utilities/streaming/#streaming-from-a-s3-object",
            "title": "Streaming from a S3 object",
            "text": "<p>With <code>S3Object</code>, you'll need the bucket, object key, and optionally a version ID to stream its content.</p> <p>We will fetch parts of your data from S3 as you process each line, consuming only the absolute minimal amount of memory.</p> Non-versioned bucketVersioned bucket <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    s3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"])\n    for line in s3:\n        print(line)\n</code></pre> <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    s3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"], version_id=event[\"version_id\"])\n    for line in s3:\n        print(line)\n</code></pre>"
        },
        {
            "location": "utilities/streaming/#data-transformations",
            "title": "Data transformations",
            "text": "<p>Think of data transformations like a data processing pipeline - apply one or more in order.</p> <p>As data is streamed, you can apply transformations to your data like decompressing gzip content and deserializing a CSV into a dictionary.</p> <p>For popular data transformations like CSV or Gzip, you can quickly enable it at the constructor level:</p> Decompressing and deserializing CSV <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    s3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"], is_gzip=True, is_csv=True)\n    for line in s3:\n        print(line)\n</code></pre> <p>Alternatively, you can apply transformations later via the <code>transform</code> method. By default, it will return the transformed stream you can use to read its contents. If you prefer in-place modifications, use <code>in_place=True</code>.</p> When is this useful? <p>In scenarios where you might have a reusable logic to apply common transformations. This might be a function or a class that receives an instance of <code>S3Object</code>.</p> Returning a new objectTransform in-place <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import (\n    CsvTransform,\n    GzipTransform,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    s3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"])\n    data = s3.transform([GzipTransform(), CsvTransform()])\n    for line in data:\n        print(line)  # returns a dict\n</code></pre> <p>Note that when using <code>in_place=True</code>, there is no return (<code>None</code>).</p> <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import (\n    CsvTransform,\n    GzipTransform,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    s3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"])\n    s3.transform([GzipTransform(), CsvTransform()], in_place=True)\n    for line in s3:\n        print(line)  # returns a dict\n</code></pre>"
        },
        {
            "location": "utilities/streaming/#handling-zip-files",
            "title": "Handling ZIP files",
            "text": "<p><code>ZipTransform</code> doesn't support combining other transformations.</p> <p>This is because a Zip file contains multiple files while transformations apply to a single stream.</p> <p>That said, you can still open a specific file as a stream, reading only the necessary bytes to extract it:</p> Reading an individual file in the zip as a stream<pre><code>from aws_lambda_powertools.utilities.streaming import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import ZipTransform\n\ns3object = S3Object(bucket=\"bucket\", key=\"key\")\nzip_reader = s3object.transform(ZipTransform())\nwith zip_reader.open(\"filename.txt\") as f:\n    for line in f:\n        print(line)\n</code></pre>"
        },
        {
            "location": "utilities/streaming/#built-in-data-transformations",
            "title": "Built-in data transformations",
            "text": "<p>We provide popular built-in transformations that you can apply against your streaming data.</p> Name Description Class name Gzip Gunzips the stream of data using the gzip library GzipTransform Zip Exposes the stream as a ZipFile object ZipTransform CSV Parses each CSV line as a CSV object, returning dictionary objects CsvTransform"
        },
        {
            "location": "utilities/streaming/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/streaming/#skipping-or-reading-backwards",
            "title": "Skipping or reading backwards",
            "text": "<p><code>S3Object</code> implements Python I/O interface. This means you can use <code>seek</code> to start reading contents of your file from any particular position, saving you processing time.</p>"
        },
        {
            "location": "utilities/streaming/#reading-backwards",
            "title": "Reading backwards",
            "text": "<p>For example, let's imagine you have a large CSV file, each row has a non-uniform size (bytes), and you want to read and process the last row only.</p> non_uniform_sample.csv<pre><code>id,name,location\n1,Ruben Fonseca, Denmark\n2,Heitor Lessa, Netherlands\n3,Leandro Damascena, Portugal\n</code></pre> <p>You found out the last row has exactly 30 bytes. We can use <code>seek()</code> to skip to the end of the file, read 30 bytes, then transform to CSV.</p> Reading only the last CSV row<pre><code>import io\nfrom typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import CsvTransform\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nLAST_ROW_SIZE = 30\nCSV_HEADERS = [\"id\", \"name\", \"location\"]\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    sample_csv = S3Object(bucket=event[\"bucket\"], key=\"sample.csv\")\n\n    # From the end of the file, jump exactly 30 bytes backwards\n    sample_csv.seek(-LAST_ROW_SIZE, io.SEEK_END)\n\n    # Transform portion of data into CSV with our headers\n    sample_csv.transform(CsvTransform(fieldnames=CSV_HEADERS), in_place=True)\n\n    # We will only read the last portion of the file from S3\n    # as we're only interested in the last 'location' from our dataset\n    for last_row in sample_csv:\n        print(last_row[\"location\"])\n</code></pre>"
        },
        {
            "location": "utilities/streaming/#skipping",
            "title": "Skipping",
            "text": "<p>What if we want to jump the first N rows?</p> <p>You can also solve with <code>seek</code>, but let's take a large uniform CSV file to make this easier to grasp.</p> uniform_sample.csv<pre><code>reading,position,type\n21.3,5,+\n23.4,4,+\n21.3,0,-\n</code></pre> <p>You found out that each row has 8 bytes, the header line has 21 bytes, and every new line has 1 byte. You want to skip the first 100 lines.</p> Skipping the first 100 rows<pre><code>import io\nfrom typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import CsvTransform\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\"\"\"\nAssuming the CSV files contains rows after the header always has 8 bytes + 1 byte newline:\n\nreading,position,type\n21.3,5,+\n23.4,4,+\n21.3,0,-\n...\n\"\"\"\n\nCSV_HEADERS = [\"reading\", \"position\", \"type\"]\nROW_SIZE = 8 + 1  # 1 byte newline\nHEADER_SIZE = 21 + 1  # 1 byte newline\nLINES_TO_JUMP = 100\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    sample_csv = S3Object(bucket=event[\"bucket\"], key=event[\"key\"])\n\n    # Skip the header line\n    sample_csv.seek(HEADER_SIZE, io.SEEK_SET)\n\n    # Jump 100 lines of 9 bytes each (8 bytes of data + 1 byte newline)\n    sample_csv.seek(LINES_TO_JUMP * ROW_SIZE, io.SEEK_CUR)\n\n    sample_csv.transform(CsvTransform(), in_place=True)\n    for row in sample_csv:\n        print(row[\"reading\"])\n</code></pre>"
        },
        {
            "location": "utilities/streaming/#custom-options-for-data-transformations",
            "title": "Custom options for data transformations",
            "text": "<p>We will propagate additional options to the underlying implementation for each transform class.</p> Name Available options GzipTransform GzipFile constructor ZipTransform ZipFile constructor CsvTransform DictReader constructor <p>For instance, take <code>ZipTransform</code>. You can use the <code>compression</code> parameter if you want to unzip an S3 object compressed with <code>LZMA</code>.</p> Unzipping LZMA data <pre><code>import zipfile\nfrom typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import ZipTransform\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    s3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"])\n\n    zf = s3.transform(ZipTransform(compression=zipfile.ZIP_LZMA))\n\n    print(zf.nameslist())\n    zf.extract(zf.namelist()[0], \"/tmp\")\n</code></pre> <p>Or, if you want to load a tab-separated file (TSV), you can use the <code>delimiter</code> parameter in the <code>CsvTransform</code>:</p> Deserializing tab-separated data values <pre><code>from typing import Dict\n\nfrom aws_lambda_powertools.utilities.streaming.s3_object import S3Object\nfrom aws_lambda_powertools.utilities.streaming.transformations import CsvTransform\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef lambda_handler(event: Dict[str, str], context: LambdaContext):\n    s3 = S3Object(bucket=event[\"bucket\"], key=event[\"key\"])\n\n    tsv_stream = s3.transform(CsvTransform(delimiter=\"\\t\"))\n    for obj in tsv_stream:\n        print(obj)\n</code></pre>"
        },
        {
            "location": "utilities/streaming/#building-your-own-data-transformation",
            "title": "Building your own data transformation",
            "text": "<p>You can build your own custom data transformation by extending the <code>BaseTransform</code> class. The <code>transform</code> method receives an <code>IO[bytes]</code> object, and you are responsible for returning an <code>IO[bytes]</code> object.</p> Custom JSON transform <pre><code>import io\nfrom typing import IO, Optional\n\nimport ijson\n\nfrom aws_lambda_powertools.utilities.streaming.transformations import BaseTransform\n\n\n# Using io.RawIOBase gets us default implementations of many of the common IO methods\nclass JsonDeserializer(io.RawIOBase):\n    def __init__(self, input_stream: IO[bytes]):\n        self.input = ijson.items(input_stream, \"\", multiple_values=True)\n\n    def read(self, size: int = -1) -&gt; Optional[bytes]:\n        raise NotImplementedError(f\"{__name__} does not implement read\")\n\n    def readline(self, size: Optional[int] = None) -&gt; bytes:\n        raise NotImplementedError(f\"{__name__} does not implement readline\")\n\n    def read_object(self) -&gt; dict:\n        return self.input.__next__()\n\n    def __next__(self):\n        return self.read_object()\n\n\nclass JsonTransform(BaseTransform):\n    def transform(self, input_stream: IO[bytes]) -&gt; JsonDeserializer:\n        return JsonDeserializer(input_stream=input_stream)\n</code></pre>"
        },
        {
            "location": "utilities/streaming/#testing-your-code",
            "title": "Testing your code",
            "text": ""
        },
        {
            "location": "utilities/streaming/#asserting-data-transformations",
            "title": "Asserting data transformations",
            "text": "<p>Create an input payload using <code>io.BytesIO</code> and assert the response of the transformation:</p> assert_transformation.pyassert_transformation_module.py <pre><code>import io\n\nimport boto3\nfrom assert_transformation_module import UpperTransform\nfrom botocore import stub\n\nfrom aws_lambda_powertools.utilities.streaming import S3Object\nfrom aws_lambda_powertools.utilities.streaming.compat import PowertoolsStreamingBody\n\n\ndef test_upper_transform():\n    # GIVEN\n    data_stream = io.BytesIO(b\"hello world\")\n    # WHEN\n    data_stream = UpperTransform().transform(data_stream)\n    # THEN\n    assert data_stream.read() == b\"HELLO WORLD\"\n\n\ndef test_s3_object_with_upper_transform():\n    # GIVEN\n    payload = b\"hello world\"\n    s3_client = boto3.client(\"s3\")\n    s3_stub = stub.Stubber(s3_client)\n    s3_stub.add_response(\n        \"get_object\",\n        {\"Body\": PowertoolsStreamingBody(raw_stream=io.BytesIO(payload), content_length=len(payload))},\n    )\n    s3_stub.activate()\n\n    # WHEN\n    data_stream = S3Object(bucket=\"bucket\", key=\"key\", boto3_client=s3_client)\n    data_stream.transform(UpperTransform(), in_place=True)\n\n    # THEN\n    assert data_stream.read() == b\"HELLO WORLD\"\n</code></pre> <pre><code>import io\nfrom typing import IO, Optional\n\nfrom aws_lambda_powertools.utilities.streaming.transformations import BaseTransform\n\n\nclass UpperIO(io.RawIOBase):\n    def __init__(self, input_stream: IO[bytes], encoding: str):\n        self.encoding = encoding\n        self.input_stream = io.TextIOWrapper(input_stream, encoding=encoding)\n\n    def read(self, size: int = -1) -&gt; Optional[bytes]:\n        data = self.input_stream.read(size)\n        return data.upper().encode(self.encoding)\n\n\nclass UpperTransform(BaseTransform):\n    def transform(self, input_stream: IO[bytes]) -&gt; UpperIO:\n        return UpperIO(input_stream=input_stream, encoding=\"utf-8\")\n</code></pre>"
        },
        {
            "location": "utilities/streaming/#known-limitations",
            "title": "Known limitations",
            "text": ""
        },
        {
            "location": "utilities/streaming/#aws-x-ray-segment-size-limit",
            "title": "AWS X-Ray segment size limit",
            "text": "<p>We make multiple API calls to S3 as you read chunks from your S3 object. If your function is decorated with Tracer, you can easily hit AWS X-Ray 64K segment size when processing large files.</p> <p>Use tracer decorators in parts where you don't read your <code>S3Object</code> instead.</p>"
        },
        {
            "location": "utilities/typing/",
            "title": "Typing",
            "text": "<p>This typing utility provides static typing classes that can be used to ease the development by providing the IDE type hints.</p>"
        },
        {
            "location": "utilities/typing/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Add static typing classes</li> <li>Ease the development by leveraging your IDE's type hints</li> <li>Avoid common typing mistakes in Python</li> </ul>"
        },
        {
            "location": "utilities/typing/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>We provide static typing for any context methods or properties implemented by Lambda context object.</p>"
        },
        {
            "location": "utilities/typing/#lambdacontext",
            "title": "LambdaContext",
            "text": "<p>The <code>LambdaContext</code> typing is typically used in the handler method for the Lambda function.</p> getting_started_validator_decorator_function.py <pre><code>from aws_lambda_powertools.utilities.typing import LambdaContext\n\n\ndef handler(event: dict, context: LambdaContext) -&gt; dict:\n    # Insert business logic\n    return event\n</code></pre>"
        },
        {
            "location": "utilities/typing/#working-with-context-methods-and-properties",
            "title": "Working with context methods and properties",
            "text": "<p>Using <code>LambdaContext</code> typing makes it possible to access information and hints of all properties and methods implemented by Lambda context object.</p> working_with_context_function.py <pre><code>from time import sleep\n\nimport requests\n\nfrom aws_lambda_powertools import Logger\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\n\nlogger = Logger()\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    limit_execution: int = 1000  # milliseconds\n\n    # scrape website and exit before lambda timeout\n    while context.get_remaining_time_in_millis() &gt; limit_execution:\n        comments: requests.Response = requests.get(\"https://jsonplaceholder.typicode.com/comments\")\n        # add logic here and save the results of the request to an S3 bucket, for example.\n\n        logger.info(\n            {\n                \"operation\": \"scrape_website\",\n                \"request_id\": context.aws_request_id,\n                \"remaining_time\": context.get_remaining_time_in_millis(),\n                \"comments\": comments.json()[:2],\n            },\n        )\n\n        sleep(1)\n\n    return {\"message\": \"Success\"}\n</code></pre> <p> </p>"
        },
        {
            "location": "utilities/validation/",
            "title": "Validation",
            "text": "<p>This utility provides JSON Schema validation for events and responses, including JMESPath support to unwrap events before validation.</p>"
        },
        {
            "location": "utilities/validation/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Validate incoming event and response</li> <li>JMESPath support to unwrap events before validation applies</li> <li>Built-in envelopes to unwrap popular event sources payloads</li> </ul>"
        },
        {
            "location": "utilities/validation/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>You can validate inbound and outbound events using <code>validator</code> decorator.</p> <p>You can also use the standalone <code>validate</code> function, if you want more control over the validation process such as handling a validation error.</p> Tip: Using JSON Schemas for the first time? <p>Check this step-by-step tour in the official JSON Schema website.</p> <p>We support any JSONSchema draft supported by fastjsonschema library.</p> Warning <p>Both <code>validator</code> decorator and <code>validate</code> standalone function expects your JSON Schema to be a dictionary, not a filename.</p>"
        },
        {
            "location": "utilities/validation/#install",
            "title": "Install",
            "text": "<p>This is not necessary if you're installing Powertools for AWS Lambda (Python) via Lambda Layer/SAR</p> <p>Add <code>aws-lambda-powertools[validation]</code> as a dependency in your preferred tool: e.g., requirements.txt, pyproject.toml. This will ensure you have the required dependencies before using Validation.</p>"
        },
        {
            "location": "utilities/validation/#validator-decorator",
            "title": "Validator decorator",
            "text": "<p>Validator decorator is typically used to validate either inbound or functions' response.</p> <p>It will fail fast with <code>SchemaValidationError</code> exception if event or response doesn't conform with given JSON Schema.</p> getting_started_validator_decorator_function.pygetting_started_validator_decorator_schema.pygetting_started_validator_decorator_payload.json <pre><code>from dataclasses import dataclass, field\nfrom uuid import uuid4\n\nimport getting_started_validator_decorator_schema as schemas\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import validator\n\n# we can get list of allowed IPs from AWS Parameter Store using Parameters Utility\n# See: https://docs.powertools.aws.dev/lambda/python/latest/utilities/parameters/\nALLOWED_IPS = parameters.get_parameter(\"/lambda-powertools/allowed_ips\")\n\n\nclass UserPermissionsError(Exception):\n    ...\n\n\n@dataclass\nclass User:\n    ip: str\n    permissions: list\n    user_id: str = field(default_factory=lambda: f\"{uuid4()}\")\n    name: str = \"Project Lambda Powertools\"\n\n\n# using a decorator to validate input and output data\n@validator(inbound_schema=schemas.INPUT, outbound_schema=schemas.OUTPUT)\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    try:\n        user_details: dict = {}\n\n        # get permissions by user_id and project\n        if (\n            event.get(\"user_id\") == \"0d44b083-8206-4a3a-aa95-5d392a99be4a\"\n            and event.get(\"project\") == \"powertools\"\n            and event.get(\"ip\") in ALLOWED_IPS\n        ):\n            user_details = User(ip=event.get(\"ip\"), permissions=[\"read\", \"write\"]).__dict__\n\n        # the body must be an object because must match OUTPUT schema, otherwise it fails\n        return {\"body\": user_details or None, \"statusCode\": 200 if user_details else 204}\n    except Exception as e:\n        raise UserPermissionsError(str(e))\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema\",\n    \"$id\": \"http://example.com/example.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n    \"examples\": [{\"user_id\": \"0d44b083-8206-4a3a-aa95-5d392a99be4a\", \"project\": \"powertools\", \"ip\": \"192.168.0.1\"}],\n    \"required\": [\"user_id\", \"project\", \"ip\"],\n    \"properties\": {\n        \"user_id\": {\n            \"$id\": \"#/properties/user_id\",\n            \"type\": \"string\",\n            \"title\": \"The user_id\",\n            \"examples\": [\"0d44b083-8206-4a3a-aa95-5d392a99be4a\"],\n            \"maxLength\": 50,\n        },\n        \"project\": {\n            \"$id\": \"#/properties/project\",\n            \"type\": \"string\",\n            \"title\": \"The project\",\n            \"examples\": [\"powertools\"],\n            \"maxLength\": 30,\n        },\n        \"ip\": {\n            \"$id\": \"#/properties/ip\",\n            \"type\": \"string\",\n            \"title\": \"The ip\",\n            \"format\": \"ipv4\",\n            \"examples\": [\"192.168.0.1\"],\n            \"maxLength\": 30,\n        },\n    },\n}\n\nOUTPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema\",\n    \"$id\": \"http://example.com/example.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample outgoing schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n    \"examples\": [{\"statusCode\": 200, \"body\": {}}],\n    \"required\": [\"statusCode\", \"body\"],\n    \"properties\": {\n        \"statusCode\": {\n            \"$id\": \"#/properties/statusCode\",\n            \"type\": \"integer\",\n            \"title\": \"The statusCode\",\n            \"examples\": [200],\n            \"maxLength\": 3,\n        },\n        \"body\": {\n            \"$id\": \"#/properties/body\",\n            \"type\": \"object\",\n            \"title\": \"The body\",\n            \"examples\": [\n                '{\"ip\": \"192.168.0.1\", \"permissions\": [\"read\", \"write\"], \"user_id\": \"7576b683-295e-4f69-b558-70e789de1b18\", \"name\": \"Project Lambda Powertools\"}'  # noqa E501\n            ],\n        },\n    },\n}\n</code></pre> <pre><code>{\n    \"user_id\": \"0d44b083-8206-4a3a-aa95-5d392a99be4a\",\n    \"project\": \"powertools\",\n    \"ip\": \"192.168.0.1\"\n}\n</code></pre> Note <p>It's not a requirement to validate both inbound and outbound schemas - You can either use one, or both.</p>"
        },
        {
            "location": "utilities/validation/#validate-function",
            "title": "Validate function",
            "text": "<p>Validate standalone function is typically used within the Lambda handler, or any other methods that perform data validation.</p> Info <p>This function returns the validated event as a JSON object. If the schema specifies <code>default</code> values for omitted fields, those default values will be included in the response.</p> <p>You can also gracefully handle schema validation errors by catching <code>SchemaValidationError</code> exception.</p> getting_started_validator_standalone_function.pygetting_started_validator_standalone_schema.pygetting_started_validator_standalone_payload.json <pre><code>import getting_started_validator_standalone_schema as schemas\n\nfrom aws_lambda_powertools.utilities import parameters\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import SchemaValidationError, validate\n\n# we can get list of allowed IPs from AWS Parameter Store using Parameters Utility\n# See: https://docs.powertools.aws.dev/lambda/python/latest/utilities/parameters/\nALLOWED_IPS = parameters.get_parameter(\"/lambda-powertools/allowed_ips\")\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    try:\n        user_authenticated: str = \"\"\n\n        # using standalone function to validate input data only\n        validate(event=event, schema=schemas.INPUT)\n\n        if (\n            event.get(\"user_id\") == \"0d44b083-8206-4a3a-aa95-5d392a99be4a\"\n            and event.get(\"project\") == \"powertools\"\n            and event.get(\"ip\") in ALLOWED_IPS\n        ):\n            user_authenticated = \"Allowed\"\n\n        # in this example the body can be of any type because we are not validating the OUTPUT\n        return {\"body\": user_authenticated, \"statusCode\": 200 if user_authenticated else 204}\n    except SchemaValidationError as exception:\n        # SchemaValidationError indicates where a data mismatch is\n        return {\"body\": str(exception), \"statusCode\": 400}\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema\",\n    \"$id\": \"http://example.com/example.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n    \"examples\": [{\"user_id\": \"0d44b083-8206-4a3a-aa95-5d392a99be4a\", \"powertools\": \"lessa\", \"ip\": \"192.168.0.1\"}],\n    \"required\": [\"user_id\", \"project\", \"ip\"],\n    \"properties\": {\n        \"user_id\": {\n            \"$id\": \"#/properties/user_id\",\n            \"type\": \"string\",\n            \"title\": \"The user_id\",\n            \"examples\": [\"0d44b083-8206-4a3a-aa95-5d392a99be4a\"],\n            \"maxLength\": 50,\n        },\n        \"project\": {\n            \"$id\": \"#/properties/project\",\n            \"type\": \"string\",\n            \"title\": \"The project\",\n            \"examples\": [\"powertools\"],\n            \"maxLength\": 30,\n        },\n        \"ip\": {\n            \"$id\": \"#/properties/ip\",\n            \"type\": \"string\",\n            \"title\": \"The ip\",\n            \"format\": \"ipv4\",\n            \"examples\": [\"192.168.0.1\"],\n            \"maxLength\": 30,\n        },\n    },\n}\n</code></pre> <pre><code>{\n    \"user_id\": \"0d44b083-8206-4a3a-aa95-5d392a99be4a\",\n    \"project\": \"powertools\",\n    \"ip\": \"192.168.0.1\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/validation/#unwrapping-events-prior-to-validation",
            "title": "Unwrapping events prior to validation",
            "text": "<p>You might want to validate only a portion of your event - This is what the <code>envelope</code> parameter is for.</p> <p>Envelopes are JMESPath expressions to extract a portion of JSON you want before applying JSON Schema validation.</p> <p>Here is a sample custom EventBridge event, where we only validate what's inside the <code>detail</code> key:</p> getting_started_validator_unwrapping_function.pygetting_started_validator_unwrapping_schema.pygetting_started_validator_unwrapping_payload.json <pre><code>import boto3\nimport getting_started_validator_unwrapping_schema as schemas\n\nfrom aws_lambda_powertools.utilities.data_classes.event_bridge_event import (\n    EventBridgeEvent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import validator\n\ns3_client = boto3.resource(\"s3\")\n\n\n# we use the 'envelope' parameter to extract the payload inside the 'detail' key before validating\n@validator(inbound_schema=schemas.INPUT, envelope=\"detail\")\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    my_event = EventBridgeEvent(event)\n    data = my_event.detail.get(\"data\", {})\n    s3_bucket, s3_key = data.get(\"s3_bucket\"), data.get(\"s3_key\")\n\n    try:\n        s3_object = s3_client.Object(bucket_name=s3_bucket, key=s3_key)\n        payload = s3_object.get()[\"Body\"]\n        content = payload.read().decode(\"utf-8\")\n\n        return {\"message\": process_data_object(content), \"success\": True}\n    except s3_client.meta.client.exceptions.NoSuchBucket as exception:\n        return return_error_message(str(exception))\n    except s3_client.meta.client.exceptions.NoSuchKey as exception:\n        return return_error_message(str(exception))\n\n\ndef return_error_message(message: str) -&gt; dict:\n    return {\"message\": message, \"success\": False}\n\n\ndef process_data_object(content: str) -&gt; str:\n    # insert logic here\n    return \"Data OK\"\n</code></pre> <pre><code>INPUT = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"$id\": \"https://example.com/object1660222326.json\",\n    \"type\": \"object\",\n    \"title\": \"Sample schema\",\n    \"description\": \"The root schema comprises the entire JSON document.\",\n    \"examples\": [\n        {\n            \"data\": {\n                \"s3_bucket\": \"aws-lambda-powertools\",\n                \"s3_key\": \"event.txt\",\n                \"file_size\": 200,\n                \"file_type\": \"text/plain\",\n            },\n        },\n    ],\n    \"required\": [\"data\"],\n    \"properties\": {\n        \"data\": {\n            \"$id\": \"#root/data\",\n            \"title\": \"Root\",\n            \"type\": \"object\",\n            \"required\": [\"s3_bucket\", \"s3_key\", \"file_size\", \"file_type\"],\n            \"properties\": {\n                \"s3_bucket\": {\n                    \"$id\": \"#root/data/s3_bucket\",\n                    \"title\": \"The S3 Bucker\",\n                    \"type\": \"string\",\n                    \"default\": \"\",\n                    \"examples\": [\"aws-lambda-powertools\"],\n                    \"pattern\": \"^.*$\",\n                },\n                \"s3_key\": {\n                    \"$id\": \"#root/data/s3_key\",\n                    \"title\": \"The S3 Key\",\n                    \"type\": \"string\",\n                    \"default\": \"\",\n                    \"examples\": [\"folder/event.txt\"],\n                    \"pattern\": \"^.*$\",\n                },\n                \"file_size\": {\n                    \"$id\": \"#root/data/file_size\",\n                    \"title\": \"The file size\",\n                    \"type\": \"integer\",\n                    \"examples\": [200],\n                    \"default\": 0,\n                },\n                \"file_type\": {\n                    \"$id\": \"#root/data/file_type\",\n                    \"title\": \"The file type\",\n                    \"type\": \"string\",\n                    \"default\": \"\",\n                    \"examples\": [\"text/plain\"],\n                    \"pattern\": \"^.*$\",\n                },\n            },\n        },\n    },\n}\n</code></pre> <pre><code>{\n    \"id\": \"cdc73f9d-aea9-11e3-9d5a-835b769c0d9c\",\n    \"detail-type\": \"CustomEvent\",\n    \"source\": \"mycompany.service\",\n    \"account\": \"123456789012\",\n    \"time\": \"1970-01-01T00:00:00Z\",\n    \"region\": \"us-east-1\",\n    \"resources\": [],\n    \"detail\": {\n        \"data\": {\n            \"s3_bucket\": \"aws-lambda-powertools\",\n            \"s3_key\": \"folder/event.txt\",\n            \"file_size\": 200,\n            \"file_type\": \"text/plain\"\n        }\n    }\n}\n</code></pre> <p>This is quite powerful because you can use JMESPath Query language to extract records from arrays, combine pipe and function expressions.</p> <p>When combined, these features allow you to extract what you need before validating the actual payload.</p>"
        },
        {
            "location": "utilities/validation/#built-in-envelopes",
            "title": "Built-in envelopes",
            "text": "<p>We provide built-in envelopes to easily extract the payload from popular event sources.</p> unwrapping_popular_event_source_function.pyunwrapping_popular_event_source_schema.pyunwrapping_popular_event_source_payload.json <pre><code>import boto3\nimport unwrapping_popular_event_source_schema as schemas\nfrom botocore.exceptions import ClientError\n\nfrom aws_lambda_powertools.utilities.data_classes.event_bridge_event import (\n    EventBridgeEvent,\n)\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import envelopes, validator\n\n\n# extracting detail from EventBridge custom event\n# see: https://docs.powertools.aws.dev/lambda/python/latest/utilities/jmespath_functions/#built-in-envelopes\n@validator(inbound_schema=schemas.INPUT, envelope=envelopes.EVENTBRIDGE)\ndef lambda_handler(event: dict, context: LambdaContext) -&gt; dict:\n    my_event = EventBridgeEvent(event)\n    ec2_client = boto3.resource(\"ec2\", region_name=my_event.region)\n\n    try:\n        instance_id = my_event.detail.get(\"instance_id\")\n        instance = ec2_client.Instance(instance_id)\n        instance.stop()\n\n        return {\"message\": f\"Successfully stopped {instance_id}\", \"success\": True}\n    except ClientError as exception:\n        return {\"message\": str(exception), \"success\": False}\n</code></pre> <pre><code>INPUT = {\n    \"definitions\": {},\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"$id\": \"https://example.com/object1660233148.json\",\n    \"title\": \"Root\",\n    \"type\": \"object\",\n    \"required\": [\"instance_id\", \"region\"],\n    \"properties\": {\n        \"instance_id\": {\n            \"$id\": \"#root/instance_id\",\n            \"title\": \"Instance_id\",\n            \"type\": \"string\",\n            \"default\": \"\",\n            \"examples\": [\"i-042dd005362091826\"],\n            \"pattern\": \"^.*$\",\n        },\n        \"region\": {\n            \"$id\": \"#root/region\",\n            \"title\": \"Region\",\n            \"type\": \"string\",\n            \"default\": \"\",\n            \"examples\": [\"us-east-1\"],\n            \"pattern\": \"^.*$\",\n        },\n    },\n}\n</code></pre> <pre><code>{\n    \"id\": \"cdc73f9d-aea9-11e3-9d5a-835b769c0d9c\",\n    \"detail-type\": \"Scheduled Event\",\n    \"source\": \"aws.events\",\n    \"account\": \"123456789012\",\n    \"time\": \"1970-01-01T00:00:00Z\",\n    \"region\": \"us-east-1\",\n    \"resources\": [\n        \"arn:aws:events:us-east-1:123456789012:rule/ExampleRule\"\n    ],\n    \"detail\": {\n        \"instance_id\": \"i-042dd005362091826\",\n        \"region\": \"us-east-2\"\n    }\n}\n</code></pre> <p>Here is a handy table with built-in envelopes along with their JMESPath expressions in case you want to build your own.</p> Envelope JMESPath expression <code>API_GATEWAY_HTTP</code> <code>powertools_json(body)</code> <code>API_GATEWAY_REST</code> <code>powertools_json(body)</code> <code>CLOUDWATCH_EVENTS_SCHEDULED</code> <code>detail</code> <code>CLOUDWATCH_LOGS</code> <code>awslogs.powertools_base64_gzip(data)</code> or <code>powertools_json(@).logEvents[*]</code> <code>EVENTBRIDGE</code> <code>detail</code> <code>KINESIS_DATA_STREAM</code> <code>Records[*].kinesis.powertools_json(powertools_base64(data))</code> <code>SNS</code> <code>Records[0].Sns.Message</code> or <code>powertools_json(@)</code> <code>SQS</code> <code>Records[*].powertools_json(body)</code>"
        },
        {
            "location": "utilities/validation/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/validation/#validating-custom-formats",
            "title": "Validating custom formats",
            "text": "Note <p>JSON Schema DRAFT 7 has many new built-in formats such as date, time, and specifically a regex format which might be a better replacement for a custom format, if you do have control over the schema.</p> <p>JSON Schemas with custom formats like <code>awsaccountid</code> will fail validation. If you have these, you can pass them using <code>formats</code> parameter:</p> custom_json_schema_type_format.json<pre><code>{\n    \"accountid\": {\n        \"format\": \"awsaccountid\",\n        \"type\": \"string\"\n    }\n}\n</code></pre> <p>For each format defined in a dictionary key, you must use a regex, or a function that returns a boolean to instruct the validator on how to proceed when encountering that type.</p> custom_format_function.pycustom_format_schema.pycustom_format_payload.json <pre><code>import json\nimport re\n\nimport boto3\nimport custom_format_schema as schemas\n\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import SchemaValidationError, validate\n\n# awsaccountid must have 12 digits\ncustom_format = {\"awsaccountid\": lambda value: re.match(r\"^(\\d{12})$\", value)}\n\n\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    try:\n        # validate input using custom json format\n        validate(event=event, schema=schemas.INPUT, formats=custom_format)\n\n        client_organization = boto3.client(\"organizations\", region_name=event.get(\"region\"))\n        account_data = client_organization.describe_account(AccountId=event.get(\"accountid\"))\n\n        return {\n            \"account\": json.dumps(account_data.get(\"Account\"), default=str),\n            \"message\": \"Success\",\n            \"statusCode\": 200,\n        }\n    except SchemaValidationError as exception:\n        return return_error_message(str(exception))\n    except Exception as exception:\n        return return_error_message(str(exception))\n\n\ndef return_error_message(message: str) -&gt; dict:\n    return {\"account\": None, \"message\": message, \"statusCode\": 400}\n</code></pre> <pre><code>INPUT = {\n    \"definitions\": {},\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"$id\": \"https://example.com/object1660245931.json\",\n    \"title\": \"Root\",\n    \"type\": \"object\",\n    \"required\": [\"accountid\", \"region\"],\n    \"properties\": {\n        \"accountid\": {\n            \"$id\": \"#root/accountid\",\n            \"title\": \"The accountid\",\n            \"type\": \"string\",\n            \"format\": \"awsaccountid\",\n            \"default\": \"\",\n            \"examples\": [\"123456789012\"],\n        },\n        \"region\": {\n            \"$id\": \"#root/region\",\n            \"title\": \"The region\",\n            \"type\": \"string\",\n            \"default\": \"\",\n            \"examples\": [\"us-east-1\"],\n            \"pattern\": \"^.*$\",\n        },\n    },\n}\n</code></pre> <pre><code>{\n    \"accountid\": \"200984112386\",\n    \"region\": \"us-east-1\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/validation/#built-in-jmespath-functions",
            "title": "Built-in JMESPath functions",
            "text": "<p>You might have events or responses that contain non-encoded JSON, where you need to decode before validating them.</p> <p>You can use our built-in JMESPath functions within your expressions to do exactly that to deserialize JSON Strings, decode base64, and decompress gzip data.</p> Info <p>We use these for built-in envelopes to easily to decode and unwrap events from sources like Kinesis, CloudWatch Logs, etc.</p>"
        },
        {
            "location": "utilities/validation/#validating-with-external-references",
            "title": "Validating with external references",
            "text": "<p>JSON Schema allows schemas to reference other schemas using the <code>$ref</code> keyword with a URI value. By default, <code>fastjsonschema</code> will make a HTTP request to resolve this URI.</p> <p>You can use <code>handlers</code> parameter to have full control over how references schemas are fetched. This is useful when you might want to optimize caching, reducing HTTP calls, or fetching them from non-HTTP endpoints.</p> custom_handlers.pycustom_handlers_parent_schemacustom_handlers_child_schemacustom_handlers_payload.json <pre><code>from custom_handlers_schema import CHILD_SCHEMA, PARENT_SCHEMA\n\nfrom aws_lambda_powertools.utilities.typing import LambdaContext\nfrom aws_lambda_powertools.utilities.validation import validator\n\n\n# Function to return the child schema\ndef get_child_schema(uri: str):\n    return CHILD_SCHEMA\n\n\n@validator(inbound_schema=PARENT_SCHEMA, inbound_handlers={\"https\": get_child_schema})\ndef lambda_handler(event, context: LambdaContext) -&gt; dict:\n    return event\n</code></pre> <pre><code>PARENT_SCHEMA = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"$id\": \"https://example.com/schemas/parent.json\",\n    \"type\": \"object\",\n    \"properties\": {\n        \"ParentSchema\": {\n            \"$ref\": \"https://SCHEMA\",\n        },\n    },\n}\n\nCHILD_SCHEMA = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"$id\": \"https://example.com/schemas/child.json\",\n    \"type\": \"object\",\n    \"properties\": {\n        \"project\": {\n            \"type\": \"string\",\n        },\n    },\n    \"required\": [\"project\"],\n}\n</code></pre> <pre><code>PARENT_SCHEMA = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"$id\": \"https://example.com/schemas/parent.json\",\n    \"type\": \"object\",\n    \"properties\": {\n        \"ParentSchema\": {\n            \"$ref\": \"https://SCHEMA\",\n        },\n    },\n}\n\nCHILD_SCHEMA = {\n    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n    \"$id\": \"https://example.com/schemas/child.json\",\n    \"type\": \"object\",\n    \"properties\": {\n        \"project\": {\n            \"type\": \"string\",\n        },\n    },\n    \"required\": [\"project\"],\n}\n</code></pre> <pre><code>{\n    \"ParentSchema\":\n    {\n        \"project\": \"powertools\"\n    }\n}\n</code></pre>"
        }
    ]
}