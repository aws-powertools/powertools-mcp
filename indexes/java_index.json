{
    "config":
    {
        "lang":
        [
            "en"
        ],
        "separator": "[\\s\\-]+",
        "pipeline":
        [
            "stopWordFilter"
        ]
    },
    "docs":
    [
        {
            "location": "",
            "title": "Homepage",
            "text": "<p>Powertools for AWS Lambda (Java) is a suite of utilities for AWS Lambda Functions that makes tracing with AWS X-Ray, structured logging and creating custom metrics asynchronously easier.</p> Tip <p>Powertools for AWS Lambda  is also available for Python, TypeScript, and .NET</p> Looking for a quick run through of the core utilities? <p>Check out this detailed blog post with a practical example. To dive deeper,  the Powertools for AWS Lambda (Java) workshop is a great next step.</p>"
        },
        {
            "location": "#tenets",
            "title": "Tenets",
            "text": "<p>This project separates core utilities that will be available in other runtimes vs general utilities that might not be available across all runtimes.</p> <ul> <li>AWS Lambda only – We optimise for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported.</li> <li>Eases the adoption of best practices – The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional.</li> <li>Keep it lean – Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time.</li> <li>We strive for backwards compatibility – New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined.</li> <li>We work backwards from the community – We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs)</li> <li>Progressive -  Utilities are designed to be incrementally adoptable for customers at any stage of their Serverless journey. They follow language idioms and their community’s common practices.</li> </ul>"
        },
        {
            "location": "#install",
            "title": "Install",
            "text": "<p>Quick hello world example using SAM CLI</p> <p>You can use SAM to quickly setup a serverless project including Powertools for AWS Lambda (Java).</p> <pre><code>sam init\n\nWhich template source would you like to use?\n    1 - AWS Quick Start Templates\n    2 - Custom Template Location\nChoice: 1\n\nChoose an AWS Quick Start application template\n    1 - Hello World Example\n    2 - Data processing\n    3 - Hello World Example with Powertools for AWS Lambda\n    4 - Multi-step workflow\n    5 - Scheduled task\n    6 - Standalone function\n    7 - Serverless API\n    8 - Infrastructure event management\n    9 - Lambda Response Streaming\n    10 - Serverless Connector Hello World Example\n    11 - Multi-step workflow with Connectors\n    12 - Full Stack\n    13 - Lambda EFS example\n    14 - DynamoDB Example\n    15 - Machine Learning\nTemplate: 3\n\nWhich runtime would you like to use?\n    1 - dotnet6\n    2 - java17\n    3 - java11\n    4 - java8.al2\n    5 - java8\n    6 - nodejs18.x\n    7 - nodejs16.x\n    8 - nodejs14.x\n    9 - python3.9\n    10 - python3.8\n    11 - python3.7\n    12 - python3.10\nRuntime: 2, 3, 4 or 5\n</code></pre> <p>Manual installation Powertools for AWS Lambda (Java) dependencies are available in Maven Central. You can use your favourite dependency management tool to install it</p> <ul> <li>Maven</li> <li>Gradle</li> </ul> <p>Depending on your version of Java (either Java 1.8 or 11+), the configuration slightly changes.</p> Maven Java 11+Maven Java 1.8Gradle Java 11+Gradle Java 1.8 <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-tracing&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-metrics&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;dev.aspectj&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.13.1&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;11&lt;/source&gt; &lt;!-- or higher --&gt;\n                 &lt;target&gt;11&lt;/target&gt; &lt;!-- or higher --&gt;\n                 &lt;complianceLevel&gt;11&lt;/complianceLevel&gt; &lt;!-- or higher --&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-tracing&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-metrics&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-tracing&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-metrics&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.14.0&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;1.8&lt;/source&gt;\n                 &lt;target&gt;1.8&lt;/target&gt;\n                 &lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-tracing&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-metrics&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '8.2.2'\n    }\n\n    // the freefair aspect plugins targets gradle 8.2.1\n    // https://docs.freefair.io/gradle-plugins/8.2.2/reference/\n    wrapper {\n        gradleVersion = \"8.2.1\"\n    }        \n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-logging:1.20.1'\n        aspect 'software.amazon.lambda:powertools-tracing:1.20.1'\n        aspect 'software.amazon.lambda:powertools-metrics:1.20.1'\n    }\n\n    sourceCompatibility = 11\n    targetCompatibility = 11\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '6.6.3'\n    }\n\n    // the freefair aspect plugins targets gradle 7.6.1\n    // https://docs.freefair.io/gradle-plugins/6.6.3/reference/\n    wrapper {\n        gradleVersion = \"7.6.1\"\n    }\n\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-logging:1.20.1'\n        aspect 'software.amazon.lambda:powertools-tracing:1.20.1'\n        aspect 'software.amazon.lambda:powertools-metrics:1.20.1'\n    }\n\n    sourceCompatibility = 1.8\n    targetCompatibility = 1.8\n</code></pre> Why a different configuration? <p>Powertools for AWS Lambda (Java) is using AspectJ internally  to handle annotations. Recently, in order to support Java 17 we had to move to <code>dev.aspectj:aspectj-maven-plugin</code> because <code>org.codehaus.mojo:aspectj-maven-plugin</code> does not support Java 17.  Under the hood, <code>org.codehaus.mojo:aspectj-maven-plugin</code> is based on AspectJ 1.9.7,  while <code>dev.aspectj:aspectj-maven-plugin</code> is based on AspectJ 1.9.8, compiled for Java 11+.</p>"
        },
        {
            "location": "#java-compatibility",
            "title": "Java Compatibility",
            "text": "<p>Powertools for AWS Lambda (Java) supports all Java version from 8 up to 21 as well as the corresponding Lambda runtimes.</p> <p>For the following modules, Powertools for AWS Lambda (Java) leverages the aspectj library to provide annotations: - Logging - Metrics - Tracing - Parameters - Idempotency - Validation - Large messages</p> <p>You may need to add the good version of <code>aspectjrt</code> to your dependencies based on the jdk used for building your function:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.aspectj&lt;/groupId&gt;\n    &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt;\n    &lt;version&gt;1.9.??&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <p>Use the following dependency matrix between this library and the JDK:</p> JDK version aspectj version <code>1.8</code> <code>1.9.7</code> <code>11-17</code> <code>1.9.20.1</code> <code>21</code> <code>1.9.21</code>"
        },
        {
            "location": "#environment-variables",
            "title": "Environment variables",
            "text": "<p>Info</p> <p>Explicit parameters take precedence over environment variables.</p> Environment variable Description Utility POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging All POWERTOOLS_METRICS_NAMESPACE Sets namespace used for metrics Metrics POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling Logging POWERTOOLS_LOG_LEVEL Sets logging level Logging POWERTOOLS_LOGGER_LOG_EVENT Enables/Disables whether to log the incoming event when using the aspect Logging POWERTOOLS_TRACER_CAPTURE_RESPONSE Enables/Disables tracing mode to capture method response Tracing POWERTOOLS_TRACER_CAPTURE_ERROR Enables/Disables tracing mode to capture method error Tracing"
        },
        {
            "location": "FAQs/",
            "title": "FAQs",
            "text": ""
        },
        {
            "location": "FAQs/#how-can-i-use-powertools-for-aws-lambda-java-with-lombok",
            "title": "How can I use Powertools for AWS Lambda (Java) with Lombok?",
            "text": "<p>Powertools uses <code>aspectj-maven-plugin</code> to compile-time weave (CTW) aspects into the project. In case you want to use <code>Lombok</code> or other compile-time preprocessor for your project, it is required to change <code>aspectj-maven-plugin</code> configuration to enable in-place weaving feature. Otherwise, the plugin will ignore changes introduced by <code>Lombok</code> and will use <code>.java</code> files as a source. </p> <p>To enable in-place weaving feature you need to use following <code>aspectj-maven-plugin</code> configuration:</p> <pre><code>&lt;configuration&gt;\n    &lt;forceAjcCompile&gt;true&lt;/forceAjcCompile&gt; \n    &lt;sources/&gt;\n    &lt;weaveDirectories&gt;\n        &lt;weaveDirectory&gt;${project.build.directory}/classes&lt;/weaveDirectory&gt;\n    &lt;/weaveDirectories&gt;\n    ...\n    &lt;aspectLibraries&gt;\n        &lt;aspectLibrary&gt;\n            &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n            &lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n        &lt;/aspectLibrary&gt;\n    &lt;/aspectLibraries&gt;\n&lt;/configuration&gt;\n</code></pre>"
        },
        {
            "location": "FAQs/#how-can-i-use-powertools-for-aws-lambda-java-with-kotlin-projects",
            "title": "How can I use Powertools for AWS Lambda (Java) with Kotlin projects?",
            "text": "<p>Powertools uses <code>aspectj-maven-plugin</code> to compile-time weave (CTW) aspects into the project. When using it with Kotlin projects, it is required to <code>forceAjcCompile</code>.  No explicit configuration should be required for gradle projects. </p> <p>To enable <code>forceAjcCompile</code> you need to use following <code>aspectj-maven-plugin</code> configuration:</p> <pre><code>&lt;configuration&gt;\n    &lt;forceAjcCompile&gt;true&lt;/forceAjcCompile&gt; \n    ...\n    &lt;aspectLibraries&gt;\n        &lt;aspectLibrary&gt;\n            &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n            &lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n        &lt;/aspectLibrary&gt;\n    &lt;/aspectLibraries&gt;\n&lt;/configuration&gt;\n</code></pre>"
        },
        {
            "location": "changelog/",
            "title": "Changelog",
            "text": "<p>All notable changes to this project will be documented in this file.</p> <p>This project follows Keep a Changelog format for changes and adheres to Semantic Versioning.</p>"
        },
        {
            "location": "changelog/#unreleased",
            "title": "[Unreleased]",
            "text": ""
        },
        {
            "location": "changelog/#1201-2025-04-08",
            "title": "[1.20.1] - 2025-04-08",
            "text": "<ul> <li>docs: fix 2 typos (#1739) by @ntestor</li> <li>docs: Correct XML formatting for Maven configuration in Large Messages utility docs (#1796) by @jreijn</li> <li>fix: Load version.properties file as resource stream to fix loading when packaged as jar (#1813) by @phipag</li> </ul>"
        },
        {
            "location": "changelog/#1200-2025-03-25",
            "title": "[1.20.0] - 2025-03-25",
            "text": "<ul> <li>feat(cfn-custom-resource): Add optional 'reason' field for detailed failure reporting (#1758) by @moizsh</li> </ul>"
        },
        {
            "location": "changelog/#1190-2025-03-07",
            "title": "[1.19.0] - 2025-03-07",
            "text": "<ul> <li>chore(deps): Update deps for jackson (#1793) by @sthulb</li> <li>build(deps): bump log4j.version from 2.22.1 to 2.24.3 (#1777) by @dependabot</li> <li>chore(deps): update JSII to 1.108 (#1791) by @sthulb</li> <li>build(deps): bump jinja2 from 3.1.5 to 3.1.6 in /docs (#1789) by @dependabot</li> <li>chore: Update netty version (#1768) by @sthulb</li> <li>chore: Set versions of transitive dependencies (#1767) by @sthulb</li> <li>chore: update Jackson in examples (#1766) by @sthulb</li> <li>build(deps): bump org.apache.maven.plugins:maven-jar-plugin from 3.4.1 to 3.4.2 (#1731) by @dependabot</li> <li>build(deps): bump aws.xray.recorder.version from 2.15.3 to 2.18.1 (#1726) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.26.29 to 2.27.12 (#1724) by @dependabot</li> <li>fix: Allow empty responses as well as null response in AppConfig (#1673) by @chrisclayson</li> <li>build(deps): bump aws.sdk.version from 2.27.2 to 2.27.7 (#1715) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.26.29 to 2.27.2 (#1714) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.25.26 to 2.26.29 (#1713) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.26.25 to 2.26.29 (#1712) by @dependabot</li> <li>chore: deprecate java1.8 al1 (#1706) by @jeromevdl</li> <li>chore: java 1.8 AL1 is deprecated, fix E2E tests (#1692) by @jeromevdl</li> <li>build(deps): bump aws.sdk.version from 2.26.21 to 2.26.25 (#1703) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.26.3 to 2.26.21 (#1697) by @dependabot</li> <li>build(deps): bump jackson.version from 2.17.0 to 2.17.2 (#1696) by @dependabot</li> <li>build(deps): bump org.apache.commons:commons-lang3 from 3.13.0 to 3.14.0 (#1694) by @dependabot</li> <li>build(deps): bump commons-io:commons-io from 2.15.1 to 2.16.1 (#1691) by @dependabot</li> <li>docs: improve tracing doc for sdk instrumentation (#1687) by @jeromevdl</li> <li>docs: fix tracing links for xray (#1686) by @jeromevdl</li> <li>build(deps): bump org.apache.maven.plugins:maven-failsafe-plugin from 3.2.5 to 3.3.0 (#1679) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.25.69 to 2.26.3 (#1658) by @dependabot</li> <li>build(deps): bump com.github.spotbugs:spotbugs-maven-plugin from 4.7.3.6 to 4.8.5.0 (#1657) by @dependabot</li> <li>build(deps): bump org.apache.maven.plugins:maven-checkstyle-plugin from 3.3.0 to 3.4.0 (#1653) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.25.50 to 2.25.69 (#1652) by @dependabot</li> <li>build(deps): bump org.apache.maven.plugins:maven-source-plugin from 3.3.0 to 3.3.1 (#1646) by @dependabot</li> <li>build(deps): bump org.assertj:assertj-core from 3.25.3 to 3.26.0 (#1644) by @dependabot</li> <li>build(deps): bump aws.xray.recorder.version from 2.15.1 to 2.15.3 (#1643) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.25.35 to 2.25.50 (#1642) by @dependabot</li> <li>build(deps): bump com.amazonaws:aws-lambda-java-events from 3.11.2 to 3.11.4 (#1597) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.24.10 to 2.25.6 (#1603) by @dependabot</li> <li>build(deps): bump org.apache.maven.plugins:maven-surefire-plugin from 3.1.2 to 3.2.5 (#1596) by @dependabot</li> <li>build(deps): bump org.codehaus.mojo:exec-maven-plugin from 3.1.0 to 3.2.0 (#1585) by @dependabot</li> <li>build(deps-dev): bump software.amazon.awscdk:aws-cdk-lib from 2.100.0 to 2.130.0 (#1586) by @dependabot</li> <li>build(deps): bump io.burt:jmespath-jackson from 0.5.1 to 0.6.0 (#1587) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.21.0 to 2.24.10 (#1581) by @dependabot</li> <li>build(deps): bump commons-io:commons-io from 2.13.0 to 2.15.1 (#1584) by @dependabot</li> <li>build(deps): bump aws.xray.recorder.version from 2.14.0 to 2.15.1 (#1583) by @dependabot</li> <li>build(deps): bump org.apache.maven.plugins:maven-shade-plugin from 3.5.0 to 3.5.2 (#1582) by @dependabot</li> <li>build(deps-dev): bump org.yaml:snakeyaml from 2.1 to 2.2 (#1400) by @dependabot</li> <li>build(deps): bump log4j.version from 2.20.0 to 2.22.1 (#1547) by @dependabot</li> <li>build(deps): bump org.apache.maven.plugins:maven-artifact-plugin from 3.4.1 to 3.5.0 (#1485) by @dependabot</li> <li>build(deps): bump com.amazonaws:aws-lambda-java-serialization from 1.1.2 to 1.1.5 (#1573) by @dependabot</li> <li>build(deps): bump org.jacoco:jacoco-maven-plugin from 0.8.10 to 0.8.11 (#1509) by @dependabot</li> <li>build(deps): bump aspectj to 1.9.21 for jdk21 (#1536) by @jeromevdl</li> <li>docs: HelloWorldStreamFunction in examples fails with sam (#1532) by @jasoniharris</li> <li>chore: Testing java21 aspectj pre-release (#1519) by @scottgerring</li> <li>fix: LargeMessageIdempotentE2ET Flaky (#1518) by @scottgerring</li> <li>build(deps): bump software.amazon.payloadoffloading:payloadoffloading-common from 2.1.3 to 2.2.0 (#1639) by @dependabot</li> <li>build(deps): bump org.apache.maven.plugins:maven-jar-plugin from 3.3.0 to 3.4.1 (#1638) by @dependabot</li> <li>build(deps): bump jackson.version from 2.15.3 to 2.17.0 (#1637) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.25.31 to 2.25.35 (#1629) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.25.16 to 2.25.31 (#1625) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.21.1 to 2.25.26 (#1622) by @dependabot</li> <li>build(deps): bump org.apache.maven.plugins:maven-failsafe-plugin from 3.1.2 to 3.2.5 (#1619) by @dependabot</li> <li>build(deps): bump com.fasterxml.jackson.datatype:jackson-datatype-joda from 2.15.2 to 2.17.0 (#1616) by @dependabot</li> <li>build(deps): bump aws.sdk.version from 2.25.6 to 2.25.16 (#1613) by @dependabot</li> <li>build(deps): bump org.apache.maven.plugins:maven-gpg-plugin from 3.1.0 to 3.2.1 (#1610) by @dependabot</li> <li>build(deps): bump org.assertj:assertj-core from 3.24.2 to 3.25.3 (#1609) by @dependabot</li> </ul>"
        },
        {
            "location": "changelog/#1180-2023-11-16",
            "title": "[1.18.0] - 2023-11-16",
            "text": ""
        },
        {
            "location": "changelog/#added",
            "title": "Added",
            "text": "<ul> <li>feat: add support for Lambda Advanced Logging Controls (ALC) (#1514) by @jeromevdl</li> <li>feat: Add support for POWERTOOLS_LOGGER_LOG_EVENT (#1510) by @AlexeySoshin</li> </ul>"
        },
        {
            "location": "changelog/#maintenance",
            "title": "Maintenance",
            "text": "<ul> <li>fix: json schema 403 error (#1457) by @jeromevdl</li> <li>fix: array jmespath fail in idempotency module (#1420) by @jeromevdl</li> <li>chore: java21 support in our build (#1488) by @jeromevdl</li> <li>chore: Addition of Warn Message If Invalid Annotation Key While Tracing #1511 (#1512) by @jdoherty</li> <li>fix: null namespace should fallback to default namespace (#1506) by @jeromevdl</li> <li>fix: get trace id from system property when env var is not set (#1503) by @mriccia</li> <li>chore: artifacts size on good branches (#1493) by @jeromevdl</li> <li>fix: enforce jackson databind version (#1472) by @jeromevdl</li> <li>chore: add missing projects and improve workflow (#1487) by @jeromevdl</li> <li>chore: Reporting size of the jars in GitHub comments (#1196) by @jeromevdl</li> <li>Deps: Bump third party dependencies to the latest versions.</li> </ul>"
        },
        {
            "location": "changelog/#documentation",
            "title": "Documentation",
            "text": "<ul> <li>docs(customer-reference): add Vertex Pharmaceuticals as a customer reference (#1486) by @scottgerring</li> <li>docs: Adding Kotlin example. (#1454) by @jasoniharris</li> <li>docs: Terraform example (#1478) by @skal111</li> <li>docs: Add Serveless Framework example (#1363) by @AlexeySoshin</li> <li>docs: Fix link to SQS large message migration guide (#1422) by @scottgerring</li> <li>docs(logging): correct log example keys (#1411) by @walmsles</li> <li>docs: Update gradle configuration readme (#1359) by @scottgerring</li> </ul>"
        },
        {
            "location": "changelog/#1170-2023-08-21",
            "title": "[1.17.0] - 2023-08-21",
            "text": ""
        },
        {
            "location": "changelog/#added_1",
            "title": "Added",
            "text": "<ul> <li>Feat: Add Batch Processor module in (#1317) by @scottgerring </li> <li>Feat: Add SNS+SQS large messages module (#1310) by @jeromevdl</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_1",
            "title": "Maintenance",
            "text": "<ul> <li>fix: use default credentials provider for all provided SDK clients in (#1303) by @roamingthings</li> <li>Chore: Make request for Logger explicitly for current class in (#1307) by @jreijn </li> <li>Chore: checkstyle formater &amp; linter in (#1316) by @jeromevdl</li> <li>Chore: Add powertools specific user-agent-suffix to the AWS SDK v2 clients by @eldimi in (#1306)</li> <li>Chore: Add 'v2' branch to build workflows to prepare for v2 work in (#1341) by @scottgerring </li> <li>Deps: Bump third party dependencies to the latest versions.</li> </ul>"
        },
        {
            "location": "changelog/#documentation_1",
            "title": "Documentation",
            "text": "<ul> <li>Docs: Add maintainers guide in (#1326) by @scottgerring </li> <li>Docs: improve contributing guide in (#1334) by @jeromevdl</li> <li>Docs: Improve example documentation in (#1291) by @scottgerring </li> <li>Docs: Add discord + sec disclosure links to readme in (#1311) by @scottgerring </li> <li>Docs: Add external examples from AWS SAM CLI App Templates in (#1318) by @AlexeySoshin </li> <li>Docs: Add CDK example in (#1321) by @AlexeySoshin</li> </ul>"
        },
        {
            "location": "changelog/#1161-2023-07-19",
            "title": "[1.16.1] - 2023-07-19",
            "text": "<ul> <li>Fix: idempotency timeout bug (#1285) by @scottgerring</li> <li>Fix: ParamManager cannot provide default SSM &amp; Secrets providers (#1282) by @jeromevdl</li> <li>Fix: Handle batch failures in FIFO queues correctly (#1183) by @scottgerring</li> <li>Deps: Bump third party dependencies to the latest versions.</li> </ul>"
        },
        {
            "location": "changelog/#1160-2023-06-29",
            "title": "[1.16.0] - 2023-06-29",
            "text": ""
        },
        {
            "location": "changelog/#added_2",
            "title": "Added",
            "text": "<ul> <li>Feature: Add AppConfig provider to parameters module (#1104) by @scottgerring</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_2",
            "title": "Maintenance",
            "text": "<ul> <li>Fix: missing idempotency key should not persist any data (#1201) by @jeromevdl</li> <li>Fix:Removing env var credentials provider as default. (#1161) by @msailes</li> <li>Chore: Swap implementation of <code>aspectj-maven-plugin</code> to support Java 17 (#1172) by @mriccia</li> <li>Test: end-to-end tests for core modules and idempotency (#970) by @jeromevdl</li> <li>Chore: cleanup spotbugs maven profiles (#1236) by @jeromevdl</li> <li>Chore: removing logback from all components (#1227) by @jeromevdl</li> <li>Chore: Roll SLF4J log4j bindings to v2 (#1190) by @scottgerring</li> <li>Deps: Bump third party dependencies to the latest versions.</li> </ul>"
        },
        {
            "location": "changelog/#1150-2023-03-20",
            "title": "[1.15.0] - 2023-03-20",
            "text": ""
        },
        {
            "location": "changelog/#added_3",
            "title": "Added",
            "text": "<ul> <li>Feature: Add DynamoDB provider to parameters module (#1091) by @scottgerring</li> <li>Feature: Update to powertools-cloudformation to deprecate <code>Response.success()</code> and <code>Response.failed()</code> methods. New helper methods are added to make it easier to follow best practices <code>Response.success(String physicalResourceId)</code> and <code>Response.failed(String physicalResourceId)</code>. For a detailed explanation please read the powertools-cloudformation documentation page. (#1082) by @msailes</li> <li>Update how a Lambda request handler method is identified (#1058) by @humanzz</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_3",
            "title": "Maintenance",
            "text": "<ul> <li>Deps: Bump third party dependencies to the latest versions.</li> <li>Examples: Import examples from aws-samples/aws-lambda-powertools-examples (#1051) by @scottgerring</li> <li>Deprecate withMetricLogger in favor of withMetricsLogger (#1060) by @humanzz</li> <li>Update issue templates (#1062) by @machafer</li> <li>Send code coverage report (jacoco) to codecov (#1094) by @jeromevdl</li> </ul>"
        },
        {
            "location": "changelog/#documentation_2",
            "title": "Documentation",
            "text": "<ul> <li>Improve <code>powertools-cloudformation</code> docs (#1090) by @mriccia</li> <li>Add link to Powertools for AWS Lambda (Java) workshop (#1095) by @scottgerring</li> <li>Fix mdocs and git revision plugin integration (#1066) by @machafer</li> </ul>"
        },
        {
            "location": "changelog/#1140-2023-02-17",
            "title": "[1.14.0] - 2023-02-17",
            "text": ""
        },
        {
            "location": "changelog/#added_4",
            "title": "Added",
            "text": "<ul> <li>Feature: Introduce <code>MetricsUtils.withMetricsLogger()</code> utility method (#1000) by @humanzz</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_4",
            "title": "Maintenance",
            "text": "<ul> <li>Update logic for recording documentation pages views to use correct runtime name (#1047) by @kozub</li> <li>Deps: Bump third party dependencies to the latest versions.</li> </ul>"
        },
        {
            "location": "changelog/#documentation_3",
            "title": "Documentation",
            "text": "<ul> <li>Docs: Update Powertools for AWS Lambda (Java) definition by @heitorlessa</li> <li>Docs: Add information about other supported langauges to README and docs (#1033) by @kozub</li> </ul>"
        },
        {
            "location": "changelog/#1130-2022-12-14",
            "title": "[1.13.0] - 2022-12-14",
            "text": ""
        },
        {
            "location": "changelog/#added_5",
            "title": "Added",
            "text": "<ul> <li>Feature: Idempotency - Handle Lambda timeout scenarios for INPROGRESS records (#933) by @jeromevdl</li> </ul>"
        },
        {
            "location": "changelog/#bug-fixes",
            "title": "Bug Fixes",
            "text": "<ul> <li>Fix: Envelope is not taken into account with built-in types (#960) by @jeromevdl</li> <li>Fix: Code suggestion from CodeGuru (#984) by @kozub</li> <li>Fix: Compilation warning with SqsLargeMessageAspect on gradle (#998) by @jeromevdl</li> <li>Fix: Log message processing exceptions as occur (#1011) by @nem0-97</li> </ul>"
        },
        {
            "location": "changelog/#documentation_4",
            "title": "Documentation",
            "text": "<ul> <li>Docs: Add missing grammar article (#976) by @fsmiamoto</li> </ul>"
        },
        {
            "location": "changelog/#1123-2022-07-12",
            "title": "[1.12.3] - 2022-07-12",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_5",
            "title": "Maintenance",
            "text": "<ul> <li>Fixes to resolve vulnerable transitive dependencies (919)</li> </ul>"
        },
        {
            "location": "changelog/#1122-2022-04-29",
            "title": "[1.12.2] - 2022-04-29",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_1",
            "title": "Bug Fixes",
            "text": "<ul> <li>SQS Large message processing: Classpath conflict on <code>PayloadS3Pointer</code> when consumer application depends on <code>payloadoffloading-common</code>, introduced in v1.8.0. (#851)</li> </ul>"
        },
        {
            "location": "changelog/#1121-2022-04-21",
            "title": "[1.12.1] - 2022-04-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_2",
            "title": "Bug Fixes",
            "text": "<ul> <li>Idempotency: thread-safety issue of MessageDigest (#817) </li> <li>Idempotency: disable dynamodb client creation in persistent store when disabling idempotency (#796)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_6",
            "title": "Maintenance",
            "text": "<ul> <li>deps: Bump third party dependencies to the latest versions.</li> </ul>"
        },
        {
            "location": "changelog/#1120-2022-03-01",
            "title": "[1.12.0] - 2022-03-01",
            "text": ""
        },
        {
            "location": "changelog/#added_6",
            "title": "Added",
            "text": "<ul> <li>Easy Event Deserialization: Extraction and deserialization of the main content of events (body, messages, ...) #757</li> </ul>"
        },
        {
            "location": "changelog/#bug-fixes_3",
            "title": "Bug Fixes",
            "text": "<ul> <li>Different behavior while using SSMProvider with or without trailing slash in parameter names #758</li> </ul>"
        },
        {
            "location": "changelog/#1110-2022-02-16",
            "title": "[1.11.0] - 2022-02-16",
            "text": ""
        },
        {
            "location": "changelog/#added_7",
            "title": "Added",
            "text": "<ul> <li>Powertools for AWS Lambda (Java) Idempotency module: New module to get your Lambda function Idempotent (#717)</li> <li>Powertools for AWS Lambda (Java) Serialization module: New module to handle JSON (de)serialization (Jackson ObjectMapper, JMESPath functions)</li> </ul>"
        },
        {
            "location": "changelog/#1103-2022-02-01",
            "title": "[1.10.3] - 2022-02-01",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_4",
            "title": "Bug Fixes",
            "text": "<ul> <li>SQS Batch processing: Prevent message to be marked as success if failed sending to DLQ for non retryable exceptions. #731</li> </ul>"
        },
        {
            "location": "changelog/#documentation_5",
            "title": "Documentation",
            "text": "<ul> <li>SQS Batch processing: Improve documentation on IAM premissions required by function when using utility with an encrypted SQS queue with customer managed KMS keys.</li> </ul>"
        },
        {
            "location": "changelog/#1102-2022-01-07",
            "title": "[1.10.2] - 2022-01-07",
            "text": "<ul> <li>Tracing: Ability to override object mapper used for serializing method response as trace metadata when enabled. This provides users ability to customize how and what you want to capture as metadata from method response object. #698</li> </ul>"
        },
        {
            "location": "changelog/#1101-2022-01-06",
            "title": "[1.10.1] - 2022-01-06",
            "text": "<ul> <li>Logging: Upgrade Log4j to version 2.17.1 for CVE-2021-44832</li> </ul>"
        },
        {
            "location": "changelog/#1100-2021-12-27",
            "title": "[1.10.0] - 2021-12-27",
            "text": "<ul> <li>Logging: Modern log4j configuration to customise structured logging. Refer docs to start using new config. #670</li> <li>SQS Batch: Support batch size greater than 10. #667</li> </ul>"
        },
        {
            "location": "changelog/#190-2021-12-21",
            "title": "[1.9.0] - 2021-12-21",
            "text": "<ul> <li>Logging: Upgrade Log4j to version 2.17.0 for CVE-2021-45105</li> <li>Tracing: add <code>Service</code> annotation. #654</li> </ul>"
        },
        {
            "location": "changelog/#182-2021-12-15",
            "title": "[1.8.2] - 2021-12-15",
            "text": ""
        },
        {
            "location": "changelog/#security",
            "title": "Security",
            "text": "<ul> <li>Upgrading Log4j to version 2.16.0 for CVE-2021-45046</li> </ul>"
        },
        {
            "location": "changelog/#181-2021-12-10",
            "title": "[1.8.1] - 2021-12-10",
            "text": ""
        },
        {
            "location": "changelog/#security_1",
            "title": "Security",
            "text": "<ul> <li>Upgrading Log4j to version 2.15.0 for CVE-2021-44228</li> </ul>"
        },
        {
            "location": "changelog/#180-2021-11-05",
            "title": "[1.8.0] - 2021-11-05",
            "text": ""
        },
        {
            "location": "changelog/#added_8",
            "title": "Added",
            "text": "<ul> <li>Powertools for AWS Lambda (Java) Cloudformation module (NEW): New module simplifying AWS Lambda-backed custom resources written in Java. #560</li> <li>SQS Large message processing: Ability to override the default <code>S3Client</code> use to fetch payload from S3. #602</li> </ul>"
        },
        {
            "location": "changelog/#regression",
            "title": "Regression",
            "text": "<ul> <li>Logging: <code>@Logging</code> annotation now works with <code>@Tracing</code> annotation on <code>RequestStreamHandler</code> when used in <code>logEvent</code> mode. #567</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_7",
            "title": "Maintenance",
            "text": "<ul> <li>deps: Bump third party dependencies to the latest versions.</li> </ul>"
        },
        {
            "location": "changelog/#173-2021-09-14",
            "title": "[1.7.3] - 2021-09-14",
            "text": "<ul> <li>SQS Batch processing: Ability to move non retryable message to configured dead letter queue(DLQ). #500</li> </ul>"
        },
        {
            "location": "changelog/#172-2021-08-03",
            "title": "[1.7.2] - 2021-08-03",
            "text": "<ul> <li>Powertools for AWS Lambda (Java) All Modules: Upgrade to the latest(1.14.0) aspectj-maven-plugin which also supports Java 9 and newer versions.  Users no longer need to depend on com.nickwongdev as a workaround. #489</li> <li>Logging: Performance optimisation to improve cold start. #484</li> <li>SQS Batch processing/Large message: Module now lazy loads default SQS client. #484</li> </ul>"
        },
        {
            "location": "changelog/#171-2021-07-06",
            "title": "[1.7.1] - 2021-07-06",
            "text": "<ul> <li>Powertools for AWS Lambda (Java) All Modules: Fix static code analysis violations done via spotbugs (#458).</li> </ul>"
        },
        {
            "location": "changelog/#170-2021-07-05",
            "title": "[1.7.0] - 2021-07-05",
            "text": ""
        },
        {
            "location": "changelog/#added_9",
            "title": "Added",
            "text": "<ul> <li>Logging: Support for extracting Correlation id using <code>@Logging</code> annotation via <code>correlationIdPath</code> attribute and <code>setCorrelationId()</code> method in <code>LoggingUtils</code>(#448).</li> <li>Logging: New <code>clearState</code> attribute on <code>@Logging</code> annotation to clear previously added custom keys upon invocation(#453).</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_8",
            "title": "Maintenance",
            "text": "<ul> <li>deps: Bump third party dependencies to the latest versions.</li> </ul>"
        },
        {
            "location": "changelog/#160-2021-06-21",
            "title": "[1.6.0] - 2021-06-21",
            "text": ""
        },
        {
            "location": "changelog/#added_10",
            "title": "Added",
            "text": "<ul> <li>Tracing: Support for Boolean and Number type as value in <code>TracingUtils.putAnnotation()</code>(#423).</li> <li>Logging: API to remove any additional custom key from logger entry using <code>LoggingUtils.removeKeys()</code>(#395).</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_9",
            "title": "Maintenance",
            "text": "<ul> <li>deps: Bump third party dependencies to the latest versions.</li> </ul>"
        },
        {
            "location": "changelog/#150-2021-03-30",
            "title": "[1.5.0] - 2021-03-30",
            "text": "<ul> <li>Metrics: Ability to set multiple dimensions as default dimensions via <code>MetricsUtils.defaultDimensions()</code>.    Introduced in v1.4.0 <code>MetricsUtils.defaultDimensionSet()</code> is deprecated now for better user experience.</li> </ul>"
        },
        {
            "location": "changelog/#140-2021-03-11",
            "title": "[1.4.0] - 2021-03-11",
            "text": "<ul> <li>Metrics: Ability to set default dimension for metrics via <code>MetricsUtils.defaultDimensionSet()</code>.</li> </ul> <p>Note: If your monitoring depends on default dimensions captured before via aws-embedded-metrics-java,    those either need to be updated or has to be explicitly captured via <code>MetricsUtils.defaultDimensionSet()</code>.</p> <ul> <li>Metrics: Remove validation of having minimum one dimension. EMF now support Dimension set being empty as well.</li> </ul>"
        },
        {
            "location": "changelog/#130-2021-03-05",
            "title": "[1.3.0] - 2021-03-05",
            "text": "<ul> <li>Powertools: It now works out of the box with code guru profile handler implementation.</li> <li>Logging: Ability to override object mapper used for logging event. This provides customers ability to customize how and what they want to log from event.</li> <li>Metrics: Module now by default captures AWS Request id as property if used together with Metrics annotation. It will also capture Xray Trace ID as property if tracing is enabled. This ensures good observability and tracing.</li> <li>Metrics:<code>withSingleMetric</code> from `MetricsUtils can now pick the default namespace specified either on Metrics annotation or via POWERTOOLS_METRICS_NAMESPACE env var, without need to specify explicitly for each call.</li> <li>Metrics:<code>Metrics</code> annotation captures metrics even in case of unhandled exception from Lambda function.</li> <li>Docs: Migrated from Gatsby to MKdocs documentation system</li> </ul>"
        },
        {
            "location": "roadmap/",
            "title": "Roadmap",
            "text": ""
        },
        {
            "location": "roadmap/#overview",
            "title": "Overview",
            "text": "<p>Our public roadmap outlines the high level direction we are working towards. We update this document when our priorities change: security and stability are our top priority.</p>"
        },
        {
            "location": "roadmap/#key-areas",
            "title": "Key areas",
            "text": "<p>Security and operational excellence take precedence above all else. This means bug fixing, stability, customer's support, and internal compliance may delay one or more key areas below.</p> <p>We may choose to re-prioritize or defer items based on customer feedback, security, and operational impacts, and business value.</p>"
        },
        {
            "location": "roadmap/#release-security-p0",
            "title": "Release Security (p0)",
            "text": "<p>Our top priority is to establish the processes and infrastructure needed for a fully automated and secure end-to-end release process of new versions to Maven Central.</p> <ul> <li> Implement GitHub workflows and create infrastructure to release to Maven Central</li> <li> Implement end-to-end tests</li> <li> Implement OpenSSF Scorecard</li> </ul>"
        },
        {
            "location": "roadmap/#v2-release-consistency-and-ecosystem-p1",
            "title": "<code>v2</code> Release: Consistency and Ecosystem (p1)",
            "text": "<p>As part of a new major version <code>v2</code> release, we prioritize the Java project's consistency of core utilities (Logging, Metrics, Tracing) with the other runtimes (Python, TypeScript, .NET). Additionally, we will focus on integrating the library with popular technologies and frameworks from the Java and AWS ecosystem. Particularly, we aim at leveraging new techniques to allow customers to reduce Lambda cold-start time. The <code>v2</code> release will also drop support for Java 8 moving to Java 11 as the baseline.</p>"
        },
        {
            "location": "roadmap/#core-utilities",
            "title": "Core Utilities",
            "text": "<ul> <li> Review public interfaces and reduce public API surface area</li> <li> Release Logging <code>v2</code> module</li> <li> Support high resolution metrics</li> </ul>"
        },
        {
            "location": "roadmap/#ecosystem",
            "title": "Ecosystem",
            "text": "<ul> <li> Add GraalVM support</li> <li> Implement priming using CRaC to improve AWS Snapstart support</li> <li> Evaluate integration with popular Java frameworks such as Micronaut, Spring Cloud Function, or Quarkus</li> </ul>"
        },
        {
            "location": "roadmap/#other",
            "title": "Other",
            "text": "<ul> <li> Validation module integration with HTTP requests</li> <li> Support validation module from within the batch module</li> <li> Documentation: Review and improve documentation to be consistent with other runtimes</li> </ul>"
        },
        {
            "location": "roadmap/#feature-parity-p2",
            "title": "Feature Parity (p2)",
            "text": "<p>If priorities <code>p0</code> and <code>p1</code> are addressed, we will also focus on feature parity of non-core utilities. This allows customers to achieve better standardization of their development processes across different Powertools runtimes.</p> <ul> <li> Re-evaluate if there is a need for adding a lightweight customer Powertools event handler</li> <li> Add Feature Flags module</li> <li> Add S3 Streaming module</li> <li> Add support for Data Masking during JSON serialization</li> </ul>"
        },
        {
            "location": "roadmap/#missing-something",
            "title": "Missing something?",
            "text": "<p>You can help us prioritize by upvoting existing feature requests, leaving a comment on what use cases it could unblock for you, and by joining our discussions on Discord.</p> <p></p>"
        },
        {
            "location": "roadmap/#roadmap-status-definition",
            "title": "Roadmap status definition",
            "text": "<p> <pre><code>graph LR\n    Ideas --&gt; Backlog --&gt; Work[\"Working on it\"] --&gt; Merged[\"Coming soon\"] --&gt; Shipped</code></pre> Visual representation </p> <p>Within our public board, you'll see the following values in the <code>Status</code> column:</p> <ul> <li>Ideas. Incoming and existing feature requests that are not being actively considered yet. These will be reviewed   when bandwidth permits.</li> <li>Backlog. Accepted feature requests or enhancements that we want to work on.</li> <li>Working on it. Features or enhancements we're currently either researching or implementing it.</li> <li>Coming soon. Any feature, enhancement, or bug fixes that have been merged and are coming in the next release.</li> <li>Shipped. Features or enhancements that are now available in the most recent release.</li> </ul> <p>Tasks or issues with empty <code>Status</code> will be categorized in upcoming review cycles.</p>"
        },
        {
            "location": "roadmap/#process",
            "title": "Process",
            "text": "<p> <pre><code>graph LR\n    PFR[Feature request] --&gt; Triage{Need RFC?}\n    Triage --&gt; |Complex/major change or new utility?| RFC[Ask or write RFC] --&gt; Approval{Approved?}\n    Triage --&gt; |Minor feature or enhancement?| NoRFC[No RFC required] --&gt; Approval\n    Approval --&gt; |Yes| Backlog\n    Approval --&gt; |No | Reject[\"Inform next steps\"]\n    Backlog --&gt; |Prioritized| Implementation\n    Backlog --&gt; |Defer| WelcomeContributions[\"help-wanted label\"]</code></pre> Visual representation </p> <p>Our end-to-end mechanism follows four major steps:</p> <ul> <li>Feature Request. Ideas start with a feature request to outline their use case at a high level. For complex use cases, maintainers might ask for/write a   RFC.</li> <li>Maintainers review requests based on project tenets, customers reaction (👍),     and use cases.</li> <li>Request-for-comments (RFC). Design proposals use   our RFC template to describe its implementation, challenges, developer experience, dependencies, and alternative solutions.</li> <li>This helps refine the initial idea with community feedback before a decision is made.</li> <li>Decision. After carefully reviewing and discussing them, maintainers make a final decision on whether to start   implementation, defer or reject it, and update everyone with the next steps.</li> <li>Implementation. For approved features, maintainers give priority to the original authors for implementation unless   it is a sensitive task that is best handled by maintainers.</li> </ul> <p>See Maintainers document to understand how we triage issues and pull requests, labels and governance.</p>"
        },
        {
            "location": "roadmap/#disclaimer",
            "title": "Disclaimer",
            "text": "<p>The Powertools for AWS Lambda (Java) team values feedback and guidance from its community of users, although final decisions on inclusion into the project will be made by AWS.</p> <p>We determine the high-level direction for our open roadmap based on customer feedback and popularity (👍🏽 and comments), security and operational impacts, and business value. Where features don’t meet our goals and longer-term strategy, we will communicate that clearly and openly as quickly as possible with an explanation of why the decision was made.</p>"
        },
        {
            "location": "roadmap/#faqs",
            "title": "FAQs",
            "text": "<p>Q: Why did you build this?</p> <p>A: We know that our customers are making decisions and plans based on what we are developing, and we want to provide our customers the insights they need to plan.</p> <p>Q: Why are there no dates on your roadmap?</p> <p>A: Because job zero is security and operational stability, we can't provide specific target dates for features. The roadmap is subject to change at any time, and roadmap issues in this repository do not guarantee a feature will be launched as proposed.</p> <p>Q: How can I provide feedback or ask for more information?</p> <p>A: For existing features, you can directly comment on issues. For anything else, please open an issue.</p>"
        },
        {
            "location": "core/logging/",
            "title": "Logging",
            "text": "<p>Logging provides an opinionated logger with output structured as JSON.</p> <p>Key features</p> <ul> <li>Capture key fields from Lambda context, cold start and structures logging output as JSON</li> <li>Log Lambda event when instructed, disabled by default, can be enabled explicitly via annotation param</li> <li>Append additional keys to structured log at any point in time</li> </ul>"
        },
        {
            "location": "core/logging/#install",
            "title": "Install",
            "text": "<p>Depending on your version of Java (either Java 1.8 or 11+), the configuration slightly changes.</p> Maven Java 11+Maven Java 1.8Gradle Java 11+Gradle Java 1.8 <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;dev.aspectj&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.13.1&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;11&lt;/source&gt; &lt;!-- or higher --&gt;\n                 &lt;target&gt;11&lt;/target&gt; &lt;!-- or higher --&gt;\n                 &lt;complianceLevel&gt;11&lt;/complianceLevel&gt; &lt;!-- or higher --&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.14.0&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;1.8&lt;/source&gt;\n                 &lt;target&gt;1.8&lt;/target&gt;\n                 &lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-logging&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '8.1.0'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-logging:1.20.1'\n    }\n\n    sourceCompatibility = 11\n    targetCompatibility = 11\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '6.6.3'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-logging:1.20.1'\n    }\n\n    sourceCompatibility = 1.8\n    targetCompatibility = 1.8\n</code></pre>"
        },
        {
            "location": "core/logging/#initialization",
            "title": "Initialization",
            "text": "<p>Powertools for AWS Lambda (Java) extends the functionality of Log4J. Below is an example <code>log4j2.xml</code> file, with the <code>JsonTemplateLayout</code> using <code>LambdaJsonLayout.json</code> configured. </p> <p>LambdaJsonLayout is now deprecated</p> <p>Configuring utility using <code>&lt;LambdaJsonLayout/&gt;</code> plugin is deprecated now. While utility still supports the old configuration, we strongly recommend upgrading the  <code>log4j2.xml</code> configuration to <code>JsonTemplateLayout</code> instead. JsonTemplateLayout is recommended way of doing structured logging.</p> <p>Please follow this guide for upgrade steps.</p> log4j2.xml <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration&gt;\n    &lt;Appenders&gt;\n        &lt;Console name=\"JsonAppender\" target=\"SYSTEM_OUT\"&gt;\n            &lt;JsonTemplateLayout eventTemplateUri=\"classpath:LambdaJsonLayout.json\" /&gt;\n        &lt;/Console&gt;\n    &lt;/Appenders&gt;\n    &lt;Loggers&gt;\n        &lt;Logger name=\"JsonLogger\" level=\"INFO\" additivity=\"false\"&gt;\n            &lt;AppenderRef ref=\"JsonAppender\"/&gt;\n        &lt;/Logger&gt;\n        &lt;Root level=\"info\"&gt;\n            &lt;AppenderRef ref=\"JsonAppender\"/&gt;\n        &lt;/Root&gt;\n    &lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre> <p>You can also override log level by setting <code>POWERTOOLS_LOG_LEVEL</code> env var. Here is an example using AWS Serverless Application Model (SAM)</p> template.yaml <pre><code>Resources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n        ...\n        Runtime: java11\n        Environment:\n            Variables:\n                POWERTOOLS_LOG_LEVEL: DEBUG\n                POWERTOOLS_SERVICE_NAME: example\n</code></pre> <p>You can also explicitly set a service name via <code>POWERTOOLS_SERVICE_NAME</code> env var. This sets service key that will be present across all log statements.</p>"
        },
        {
            "location": "core/logging/#standard-structured-keys",
            "title": "Standard structured keys",
            "text": "<p>Your logs will always include the following keys to your structured logging:</p> Key Type Example Description timestamp String \"2020-05-24 18:17:33,774\" Timestamp of actual log statement level String \"INFO\" Logging level coldStart Boolean true ColdStart value. service String \"payment\" Service name defined. \"service_undefined\" will be used if unknown samplingRate int 0.1 Debug logging sampling rate in percentage e.g. 10% in this case message String \"Collecting payment\" Log statement value. Unserializable JSON values will be casted to string functionName String \"example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" functionVersion String \"12\" functionMemorySize String \"128\" functionArn String \"arn:aws:lambda:eu-west-1:012345678910:function:example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" xray_trace_id String \"1-5759e988-bd862e3fe1be46a994272793\" X-Ray Trace ID when Lambda function has enabled Tracing function_request_id String \"899856cb-83d1-40d7-8611-9e78f15f32f4\"\" AWS Request ID from lambda context"
        },
        {
            "location": "core/logging/#capturing-context-lambda-info",
            "title": "Capturing context Lambda info",
            "text": "<p>When debugging in non-production environments, you can instruct Logger to log the incoming event with <code>@Logger(logEvent = true)</code> or via <code>POWERTOOLS_LOGGER_LOG_EVENT=true</code> environment variable.</p> <p>Warning</p> <p>Log event is disabled by default to prevent sensitive info being logged.</p> App.javaAppLogEvent.java <pre><code>import org.apache.logging.log4j.LogManager;\nimport org.apache.logging.log4j.Logger;\nimport software.amazon.lambda.powertools.logging.LoggingUtils;\nimport software.amazon.lambda.powertools.logging.Logging;\n...\n\n/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    Logger log = LogManager.getLogger(App.class);\n\n    @Logging\n    public APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n     ...\n    }\n}\n</code></pre> <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class AppLogEvent implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    Logger log = LogManager.getLogger(AppLogEvent.class);\n\n    @Logging(logEvent = true)\n    public APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n     ...\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#customising-fields-in-logs",
            "title": "Customising fields in logs",
            "text": "<ul> <li>Utility by default emits <code>timestamp</code> field in the logs in format <code>yyyy-MM-dd'T'HH:mm:ss.SSSZz</code> and in system default timezone.  If you need to customize format and timezone, you can do so by configuring <code>log4j2.component.properties</code> and configuring properties as shown in example below:</li> </ul> log4j2.component.properties <pre><code>log4j.layout.jsonTemplate.timestampFormatPattern=yyyy-MM-dd'T'HH:mm:ss.SSSZz\nlog4j.layout.jsonTemplate.timeZone=Europe/Oslo\n</code></pre> <ul> <li> <p>Utility also provides sample template for Elastic Common Schema(ECS) layout. The field emitted in logs will follow specs from ECS together with field captured by utility as mentioned above.</p> <p>Use <code>LambdaEcsLayout.json</code> as <code>eventTemplateUri</code> when configuring <code>JsonTemplateLayout</code>.</p> </li> </ul> log4j2.xml <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration&gt;\n    &lt;Appenders&gt;\n        &lt;Console name=\"JsonAppender\" target=\"SYSTEM_OUT\"&gt;\n            &lt;JsonTemplateLayout eventTemplateUri=\"classpath:LambdaEcsLayout.json\" /&gt;\n        &lt;/Console&gt;\n    &lt;/Appenders&gt;\n    &lt;Loggers&gt;\n        &lt;Logger name=\"JsonLogger\" level=\"INFO\" additivity=\"false\"&gt;\n            &lt;AppenderRef ref=\"JsonAppender\"/&gt;\n        &lt;/Logger&gt;\n        &lt;Root level=\"info\"&gt;\n            &lt;AppenderRef ref=\"JsonAppender\"/&gt;\n        &lt;/Root&gt;\n    &lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre>"
        },
        {
            "location": "core/logging/#setting-a-correlation-id",
            "title": "Setting a Correlation ID",
            "text": "<p>You can set a Correlation ID using <code>correlationIdPath</code> attribute by passing a JSON Pointer expression.</p> App.javaExample EventExample CloudWatch Logs excerpt <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    Logger log = LogManager.getLogger(App.class);\n\n    @Logging(correlationIdPath = \"/headers/my_request_id_header\")\n    public APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n        ...\n        log.info(\"Collecting payment\")\n        ...\n    }\n}\n</code></pre> <pre><code>{\n  \"headers\": {\n    \"my_request_id_header\": \"correlation_id_value\"\n  }\n}\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n    \"service\": \"payment\",\n    \"coldStart\": true,\n    \"functionName\": \"test\",\n    \"functionMemorySize\": 128,\n    \"functionArn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n    \"correlation_id\": \"correlation_id_value\"\n}\n</code></pre> <p>We provide built-in JSON Pointer expression  for known event sources, where either a request ID or X-Ray Trace ID are present.</p> App.javaExample EventExample CloudWatch Logs excerpt <pre><code>import software.amazon.lambda.powertools.logging.CorrelationIdPathConstants;\n\n/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    Logger log = LogManager.getLogger(App.class);\n\n    @Logging(correlationIdPath = CorrelationIdPathConstants.API_GATEWAY_REST)\n    public APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n        ...\n        log.info(\"Collecting payment\")\n        ...\n    }\n}\n</code></pre> <pre><code>{\n  \"requestContext\": {\n    \"requestId\": \"correlation_id_value\"\n  }\n}\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n    \"service\": \"payment\",\n    \"coldStart\": true,\n    \"functionName\": \"test\",\n    \"functionMemorySize\": 128,\n    \"functionArn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n    \"correlation_id\": \"correlation_id_value\"\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#appending-additional-keys",
            "title": "Appending additional keys",
            "text": "<p>Custom keys are persisted across warm invocations</p> <pre><code>Always set additional keys as part of your handler to ensure they have the latest value, or explicitly clear them with [`clearState=true`](#clearing-all-state).\n</code></pre> <p>You can append your own keys to your existing logs via <code>appendKey</code>.</p> App.java <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    Logger log = LogManager.getLogger(App.class);\n\n    @Logging(logEvent = true)\n    public APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n        ...\n        LoggingUtils.appendKey(\"test\", \"willBeLogged\");\n        ...\n\n        ...\n         Map&lt;String, String&gt; customKeys = new HashMap&lt;&gt;();\n         customKeys.put(\"test\", \"value\");\n         customKeys.put(\"test1\", \"value1\");\n\n         LoggingUtils.appendKeys(customKeys);\n        ...\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#removing-additional-keys",
            "title": "Removing additional keys",
            "text": "<p>You can remove any additional key from entry using <code>LoggingUtils.removeKeys()</code>.</p> App.java <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    Logger log = LogManager.getLogger(App.class);\n\n    @Logging(logEvent = true)\n    public APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n        ...\n        LoggingUtils.appendKey(\"test\", \"willBeLogged\");\n        ...\n        Map&lt;String, String&gt; customKeys = new HashMap&lt;&gt;();\n        customKeys.put(\"test1\", \"value\");\n        customKeys.put(\"test2\", \"value1\");\n\n        LoggingUtils.appendKeys(customKeys);\n        ...\n        LoggingUtils.removeKey(\"test\");\n        LoggingUtils.removeKeys(\"test1\", \"test2\");\n        ...\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#clearing-all-state",
            "title": "Clearing all state",
            "text": "<p>Logger is commonly initialized in the global scope. Due to Lambda Execution Context reuse,  this means that custom keys can be persisted across invocations. If you want all custom keys to be deleted, you can use  <code>clearState=true</code> attribute on <code>@Logging</code> annotation.</p> App.java#1 Request#2 Request <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    Logger log = LogManager.getLogger(App.class);\n\n    @Logging(clearState = true)\n    public APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n        ...\n        if(input.getHeaders().get(\"someSpecialHeader\")) {\n            LoggingUtils.appendKey(\"specialKey\", \"value\");\n        }\n\n        log.info(\"Collecting payment\");\n        ...\n    }\n}\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n    \"service\": \"payment\",\n    \"coldStart\": true,\n    \"functionName\": \"test\",\n    \"functionMemorySize\": 128,\n    \"functionArn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n    \"specialKey\": \"value\"\n}\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-05-03 11:47:12,494+0200\",\n    \"service\": \"payment\",\n    \"coldStart\": true,\n    \"functionName\": \"test\",\n    \"functionMemorySize\": 128,\n    \"functionArn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#override-default-object-mapper",
            "title": "Override default object mapper",
            "text": "<p>You can optionally choose to override default object mapper which is used to serialize lambda function events. You might want to supply custom object mapper in order to control how serialisation is done, for example, when you want to log only specific fields from received event due to security.</p> App.java <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    Logger log = LogManager.getLogger(App.class);\n\n    static {\n        ObjectMapper objectMapper = new ObjectMapper();\n        LoggingUtils.defaultObjectMapper(objectMapper);\n    }\n\n    @Logging(logEvent = true)\n    public APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n        ...\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#sampling-debug-logs",
            "title": "Sampling debug logs",
            "text": "<p>You can dynamically set a percentage of your logs to DEBUG level via env var <code>POWERTOOLS_LOGGER_SAMPLE_RATE</code> or via <code>samplingRate</code> attribute on annotation. </p> <p>Info</p> <p>Configuration on environment variable is given precedence over sampling rate configuration on annotation, provided it's in valid value range.</p> Sampling via annotation attributeSampling via environment variable <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    Logger log = LogManager.getLogger(App.class);\n\n    @Logging(samplingRate = 0.5)\n    public APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n     ...\n    }\n}\n</code></pre> <pre><code>Resources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n        ...\n        Runtime: java11\n        Environment:\n            Variables:\n                POWERTOOLS_LOGGER_SAMPLE_RATE: 0.5\n</code></pre>"
        },
        {
            "location": "core/logging/#aws-lambda-advanced-logging-controls-alc",
            "title": "AWS Lambda Advanced Logging Controls (ALC)",
            "text": "<p>When is it useful?</p> <p>When you want to set a logging policy to drop informational or verbose logs for one or all AWS Lambda functions, regardless of runtime and logger used.</p> <p>With AWS Lambda Advanced Logging Controls (ALC), you can enforce a minimum log level that Lambda will accept from your application code.</p> <p>When enabled, you should keep <code>Logger</code> and ALC log level in sync to avoid data loss.</p> <p>Here's a sequence diagram to demonstrate how ALC will drop both <code>INFO</code> and <code>DEBUG</code> logs emitted from <code>Logger</code>, when ALC log level is stricter than <code>Logger</code>.</p> <pre><code>sequenceDiagram\n    participant Lambda service\n    participant Lambda function\n    participant Application Logger\n\n    Note over Lambda service: AWS_LAMBDA_LOG_LEVEL=\"WARN\"\n    Note over Application Logger: POWERTOOLS_LOG_LEVEL=\"DEBUG\"\n\n    Lambda service-&gt;&gt;Lambda function: Invoke (event)\n    Lambda function-&gt;&gt;Lambda function: Calls handler\n    Lambda function-&gt;&gt;Application Logger: logger.error(\"Something happened\")\n    Lambda function--&gt;&gt;Application Logger: logger.debug(\"Something happened\")\n    Lambda function--&gt;&gt;Application Logger: logger.info(\"Something happened\")\n    Lambda service--xLambda service: DROP INFO and DEBUG logs\n    Lambda service-&gt;&gt;CloudWatch Logs: Ingest error logs</code></pre>"
        },
        {
            "location": "core/logging/#priority-of-log-level-settings-in-powertools-for-aws-lambda",
            "title": "Priority of log level settings in Powertools for AWS Lambda",
            "text": "<p>We prioritise log level settings in this order:</p> <ol> <li><code>AWS_LAMBDA_LOG_LEVEL</code> environment variable</li> <li><code>POWERTOOLS_LOG_LEVEL</code> environment variable</li> </ol> <p>If you set <code>Logger</code> level lower than ALC, we will emit a warning informing you that your messages will be discarded by Lambda.</p> <p>NOTE</p> <p>With ALC enabled, we are unable to increase the minimum log level below the <code>AWS_LAMBDA_LOG_LEVEL</code> environment variable value, see AWS Lambda service documentation for more details.</p>"
        },
        {
            "location": "core/logging/#timestamp-format",
            "title": "Timestamp format",
            "text": "<p>When the Advanced Logging Controls feature is enabled, Powertools for AWS Lambda must comply with the timestamp format required by AWS Lambda, which is RFC3339.  In this case the format will be <code>yyyy-MM-dd'T'HH:mm:ss.SSS'Z'</code>.</p>"
        },
        {
            "location": "core/logging/#upgrade-to-jsontemplatelayout-from-deprecated-lambdajsonlayout-configuration-in-log4j2xml",
            "title": "Upgrade to JsonTemplateLayout from deprecated LambdaJsonLayout configuration in log4j2.xml",
            "text": "<p>Prior to version 1.10.0, only supported way of configuring <code>log4j2.xml</code> was via  <code>&lt;LambdaJsonLayout/&gt;</code>. This plugin is  deprecated now and will be removed in future version. Switching to <code>JsonTemplateLayout</code> is straight forward. </p> <p>Below examples shows deprecated and new configuration of <code>log4j2.xml</code>.</p> Deprecated configuration of log4j2.xmlNew configuration of log4j2.xml <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration&gt;\n    &lt;Appenders&gt;\n        &lt;Console name=\"JsonAppender\" target=\"SYSTEM_OUT\"&gt;\n            &lt;LambdaJsonLayout compact=\"true\" eventEol=\"true\"/&gt;\n        &lt;/Console&gt;\n    &lt;/Appenders&gt;\n    &lt;Loggers&gt;\n        &lt;Logger name=\"JsonLogger\" level=\"INFO\" additivity=\"false\"&gt;\n            &lt;AppenderRef ref=\"JsonAppender\"/&gt;\n        &lt;/Logger&gt;\n        &lt;Root level=\"info\"&gt;\n            &lt;AppenderRef ref=\"JsonAppender\"/&gt;\n        &lt;/Root&gt;\n    &lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre> <pre><code>&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;\n&lt;Configuration&gt;\n    &lt;Appenders&gt;\n        &lt;Console name=\"JsonAppender\" target=\"SYSTEM_OUT\"&gt;\n            &lt;JsonTemplateLayout eventTemplateUri=\"classpath:LambdaJsonLayout.json\" /&gt;\n        &lt;/Console&gt;\n    &lt;/Appenders&gt;\n    &lt;Loggers&gt;\n        &lt;Logger name=\"JsonLogger\" level=\"INFO\" additivity=\"false\"&gt;\n            &lt;AppenderRef ref=\"JsonAppender\"/&gt;\n        &lt;/Logger&gt;\n        &lt;Root level=\"info\"&gt;\n            &lt;AppenderRef ref=\"JsonAppender\"/&gt;\n        &lt;/Root&gt;\n    &lt;/Loggers&gt;\n&lt;/Configuration&gt;\n</code></pre>"
        },
        {
            "location": "core/metrics/",
            "title": "Metrics",
            "text": "<p>Metrics creates custom metrics asynchronously by logging metrics to standard output following Amazon CloudWatch Embedded Metric Format (EMF).</p> <p>These metrics can be visualized through Amazon CloudWatch Console.</p> <p>Key features</p> <ul> <li>Aggregate up to 100 metrics using a single CloudWatch EMF object (large JSON blob).</li> <li>Validate against common metric definitions mistakes (metric unit, values, max dimensions, max metrics, etc).</li> <li>Metrics are created asynchronously by the CloudWatch service, no custom stacks needed.</li> <li>Context manager to create a one off metric with a different dimension.</li> </ul>"
        },
        {
            "location": "core/metrics/#terminologies",
            "title": "Terminologies",
            "text": "<p>If you're new to Amazon CloudWatch, there are two terminologies you must be aware of before using this utility:</p> <ul> <li>Namespace. It's the highest level container that will group multiple metrics from multiple services for a given application, for example <code>ServerlessEcommerce</code>.</li> <li>Dimensions. Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example <code>ColdStart</code> metric by Payment <code>service</code>.</li> </ul> Metric terminology, visually explained"
        },
        {
            "location": "core/metrics/#install",
            "title": "Install",
            "text": "<p>Depending on your version of Java (either Java 1.8 or 11+), the configuration slightly changes.</p> Maven Java 11+Maven Java 1.8Gradle Java 11+Gradle Java 1.8 <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-metrics&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;dev.aspectj&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.13.1&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;11&lt;/source&gt; &lt;!-- or higher --&gt;\n                 &lt;target&gt;11&lt;/target&gt; &lt;!-- or higher --&gt;\n                 &lt;complianceLevel&gt;11&lt;/complianceLevel&gt; &lt;!-- or higher --&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-metrics&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-metrics&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.14.0&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;1.8&lt;/source&gt;\n                 &lt;target&gt;1.8&lt;/target&gt;\n                 &lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-metrics&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '8.1.0'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-metrics:1.20.1'\n    }\n\n    sourceCompatibility = 11\n    targetCompatibility = 11\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '6.6.3'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-metrics:1.20.1'\n    }\n\n    sourceCompatibility = 1.8\n    targetCompatibility = 1.8\n</code></pre>"
        },
        {
            "location": "core/metrics/#getting-started",
            "title": "Getting started",
            "text": "<p>Metric has two global settings that will be used across all metrics emitted:</p> Setting Description Environment variable Constructor parameter Metric namespace Logical container where all metrics will be placed e.g. <code>ServerlessAirline</code> <code>POWERTOOLS_METRICS_NAMESPACE</code> <code>namespace</code> Service Optionally, sets service metric dimension across all metrics e.g. <code>payment</code> <code>POWERTOOLS_SERVICE_NAME</code> <code>service</code> <p>Use your application or main service as the metric namespace to easily group all metrics</p> template.yamlMetricsEnabledHandler.java <pre><code>Resources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n        ...\n        Runtime: java11\n        Environment:\n            Variables:\n                POWERTOOLS_SERVICE_NAME: payment\n                POWERTOOLS_METRICS_NAMESPACE: ServerlessAirline\n</code></pre> <pre><code>import software.amazon.lambda.powertools.metrics.Metrics;\n\npublic class MetricsEnabledHandler implements RequestHandler&lt;Object, Object&gt; {\n\n    MetricsLogger metricsLogger = MetricsUtils.metricsLogger();\n\n    @Override\n    @Metrics(namespace = \"ExampleApplication\", service = \"booking\")\n    public Object handleRequest(Object input, Context context) {\n        ...\n    }\n}\n</code></pre> <p>You can initialize Metrics anywhere in your code as many times as you need - It'll keep track of your aggregate metrics in memory.</p>"
        },
        {
            "location": "core/metrics/#creating-metrics",
            "title": "Creating metrics",
            "text": "<p>You can create metrics using <code>putMetric</code>, and manually create dimensions for all your aggregate metrics using <code>putDimensions</code>.</p> MetricsEnabledHandler.java <pre><code>import software.amazon.lambda.powertools.metrics.Metrics;\nimport software.amazon.cloudwatchlogs.emf.logger.MetricsLogger;\n\npublic class MetricsEnabledHandler implements RequestHandler&lt;Object, Object&gt; {\n\n    MetricsLogger metricsLogger = MetricsUtils.metricsLogger();\n\n    @Override\n    @Metrics(namespace = \"ExampleApplication\", service = \"booking\")\n    public Object handleRequest(Object input, Context context) {\n        metricsLogger.putDimensions(DimensionSet.of(\"environment\", \"prod\"));\n        metricsLogger.putMetric(\"SuccessfulBooking\", 1, Unit.COUNT);\n        ...\n    }\n}\n</code></pre> <p>The <code>Unit</code> enum facilitate finding a supported metric unit by CloudWatch.</p> <p>Metrics overflow</p> <p>CloudWatch EMF supports a max of 100 metrics. Metrics utility will flush all metrics when adding the 100th metric while subsequent metrics will be aggregated into a new EMF object, for your convenience.</p>"
        },
        {
            "location": "core/metrics/#flushing-metrics",
            "title": "Flushing metrics",
            "text": "<p>The <code>@Metrics</code> annotation validates, serializes, and flushes all your metrics. During metrics validation,  if no metrics are provided no exception will be raised. If metrics are provided, and any of the following criteria are  not met, <code>ValidationException</code> exception will be raised.</p> <p>Metric validation</p> <ul> <li>Maximum of 9 dimensions</li> </ul> <p>If you want to ensure that at least one metric is emitted, you can pass <code>raiseOnEmptyMetrics = true</code> to the @Metrics annotation:</p> MetricsRaiseOnEmpty.java <pre><code>import software.amazon.lambda.powertools.metrics.Metrics;\n\npublic class MetricsRaiseOnEmpty implements RequestHandler&lt;Object, Object&gt; {\n\n    @Override\n    @Metrics(raiseOnEmptyMetrics = true)\n    public Object handleRequest(Object input, Context context) {\n    ...\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#capturing-cold-start-metric",
            "title": "Capturing cold start metric",
            "text": "<p>You can capture cold start metrics automatically with <code>@Metrics</code> via the <code>captureColdStart</code> variable.</p> MetricsColdStart.java <pre><code>import software.amazon.lambda.powertools.metrics.Metrics;\n\npublic class MetricsColdStart implements RequestHandler&lt;Object, Object&gt; {\n\n    @Override\n    @Metrics(captureColdStart = true)\n    public Object handleRequest(Object input, Context context) {\n    ...\n    }\n}\n</code></pre> <p>If it's a cold start invocation, this feature will:</p> <ul> <li>Create a separate EMF blob solely containing a metric named <code>ColdStart</code></li> <li>Add <code>FunctionName</code> and <code>Service</code> dimensions</li> </ul> <p>This has the advantage of keeping cold start metric separate from your application metrics.</p>"
        },
        {
            "location": "core/metrics/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/metrics/#adding-metadata",
            "title": "Adding metadata",
            "text": "<p>You can use <code>putMetadata</code> for advanced use cases, where you want to metadata as part of the serialized metrics object.</p> <p>Info</p> <p>This will not be available during metrics visualization, use <code>dimensions</code> for this purpose.</p> App.java <pre><code>import software.amazon.lambda.powertools.metrics.Metrics;\nimport software.amazon.cloudwatchlogs.emf.logger.MetricsLogger;\n\npublic class App implements RequestHandler&lt;Object, Object&gt; {\n\n    @Override\n    @Metrics(namespace = \"ServerlessAirline\", service = \"payment\")\n    public Object handleRequest(Object input, Context context) {\n        metricsLogger().putMetric(\"CustomMetric1\", 1, Unit.COUNT);\n        metricsLogger().putMetadata(\"booking_id\", \"1234567890\");\n        ...\n    }\n}\n</code></pre> <p>This will be available in CloudWatch Logs to ease operations on high cardinal data.</p>"
        },
        {
            "location": "core/metrics/#overriding-default-dimension-set",
            "title": "Overriding default dimension set",
            "text": "<p>By default, all metrics emitted via module captures <code>Service</code> as one of the default dimension. This is either specified via <code>POWERTOOLS_SERVICE_NAME</code> environment variable or via <code>service</code> attribute on <code>Metrics</code> annotation. If you wish to override the default  Dimension, it can be done via <code>MetricsUtils.defaultDimensions()</code>.</p> App.java <pre><code>import software.amazon.lambda.powertools.metrics.Metrics;\nimport static software.amazon.lambda.powertools.metrics.MetricsUtils;\n\npublic class App implements RequestHandler&lt;Object, Object&gt; {\n\n    MetricsLogger metricsLogger = MetricsUtils.metricsLogger();\n\n    static {\n        MetricsUtils.defaultDimensions(DimensionSet.of(\"CustomDimension\", \"booking\"));\n    }\n\n    @Override\n    @Metrics(namespace = \"ExampleApplication\", service = \"booking\")\n    public Object handleRequest(Object input, Context context) {\n        ...\n        MetricsUtils.withSingleMetric(\"Metric2\", 1, Unit.COUNT, log -&gt; {});\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#creating-a-metric-with-a-different-dimension",
            "title": "Creating a metric with a different dimension",
            "text": "<p>CloudWatch EMF uses the same dimensions across all your metrics. Use <code>withSingleMetric</code> if you have a metric that should have different dimensions.</p> <p>Info</p> <p>Generally, this would be an edge case since you pay for unique metric. Keep the following formula in mind: unique metric = (metric_name + dimension_name + dimension_value)</p> App.java <pre><code>import static software.amazon.lambda.powertools.metrics.MetricsUtils.withSingleMetric;\n\npublic class App implements RequestHandler&lt;Object, Object&gt; {\n\n    @Override\n    public Object handleRequest(Object input, Context context) {\n         withSingleMetric(\"CustomMetrics2\", 1, Unit.COUNT, \"Another\", (metric) -&gt; {\n            metric.setDimensions(DimensionSet.of(\"AnotherService\", \"CustomService\"));\n        });\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#creating-metrics-with-different-configurations",
            "title": "Creating metrics with different configurations",
            "text": "<p>Use <code>withMetricsLogger</code> if you have one or more metrics that should have different configurations e.g. dimensions or namespace.</p> App.java <pre><code>import static software.amazon.lambda.powertools.metrics.MetricsUtils.withMetricsLogger;\n\npublic class App implements RequestHandler&lt;Object, Object&gt; {\n\n    @Override\n    public Object handleRequest(Object input, Context context) {\n         withMetricsLogger(logger -&gt; {\n            // override default dimensions\n            logger.setDimensions(DimensionSet.of(\"AnotherService\", \"CustomService\"));\n            // add metrics\n            logger.putMetric(\"CustomMetrics1\", 1, Unit.COUNT);\n            logger.putMetric(\"CustomMetrics2\", 5, Unit.COUNT);\n        });\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/tracing/",
            "title": "Tracing",
            "text": "<p>Powertools tracing is an opinionated thin wrapper for AWS X-Ray Java SDK a provides functionality to reduce the overhead of performing common tracing tasks.</p> <p></p> <p>Key Features</p> <ul> <li>Capture cold start as annotation, and responses as well as full exceptions as metadata</li> <li>Helper methods to improve the developer experience of creating new X-Ray subsegments.</li> <li>Better developer experience when developing with multiple threads.</li> <li>Auto patch supported modules by AWS X-Ray</li> </ul>"
        },
        {
            "location": "core/tracing/#install",
            "title": "Install",
            "text": "<p>Depending on your version of Java (either Java 1.8 or 11+), the configuration slightly changes.</p> Maven Java 11+Maven Java 1.8Gradle Java 11+Gradle Java 1.8 <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-tracing&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;dev.aspectj&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.13.1&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;11&lt;/source&gt; &lt;!-- or higher --&gt;\n                 &lt;target&gt;11&lt;/target&gt; &lt;!-- or higher --&gt;\n                 &lt;complianceLevel&gt;11&lt;/complianceLevel&gt; &lt;!-- or higher --&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-tracing&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-tracing&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.14.0&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;1.8&lt;/source&gt;\n                 &lt;target&gt;1.8&lt;/target&gt;\n                 &lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-tracing&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '8.1.0'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-tracing:1.20.1'\n    }\n\n    sourceCompatibility = 11\n    targetCompatibility = 11\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '6.6.3'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-tracing:1.20.1'\n    }\n\n    sourceCompatibility = 1.8\n    targetCompatibility = 1.8\n</code></pre>"
        },
        {
            "location": "core/tracing/#initialization",
            "title": "Initialization",
            "text": "<p>Before your use this utility, your AWS Lambda function must have permissions to send traces to AWS X-Ray.</p> <p>Example using AWS Serverless Application Model (SAM)</p> template.yaml <pre><code>Resources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n        ...\n        Runtime: java11\n\n        Tracing: Active\n        Environment:\n            Variables:\n                POWERTOOLS_SERVICE_NAME: example\n</code></pre> <p>The Powertools for AWS Lambda (Java) service name is used as the X-Ray namespace. This can be set using the environment variable <code>POWERTOOLS_SERVICE_NAME</code></p>"
        },
        {
            "location": "core/tracing/#lambda-handler",
            "title": "Lambda handler",
            "text": "<p>To enable Powertools for AWS Lambda (Java) tracing to your function add the <code>@Tracing</code> annotation to your <code>handleRequest</code> method or on any method will capture the method as a separate subsegment automatically. You can optionally choose to customize  segment name that appears in traces.</p> Tracing annotationCustom Segment names <pre><code>public class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    @Tracing\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n        businessLogic1();\n\n        businessLogic2();\n    }\n\n    @Tracing\n    public void businessLogic1(){\n\n    }\n\n    @Tracing\n    public void businessLogic2(){\n\n    }\n}\n</code></pre> <pre><code>public class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    @Tracing(segmentName=\"yourCustomName\")\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n    ...\n    }\n</code></pre> <p>When using this <code>@Tracing</code> annotation, Utility performs these additional tasks to ease operations:</p> <ul> <li>Creates a <code>ColdStart</code> annotation to easily filter traces that have had an initialization overhead.</li> <li>Creates a <code>Service</code> annotation if service parameter or <code>POWERTOOLS_SERVICE_NAME</code> is set.</li> <li>Captures any response, or full exceptions generated by the handler, and include as tracing metadata.</li> </ul> <p>By default, this annotation will automatically record method responses and exceptions. You can change the default behavior by setting the environment variables <code>POWERTOOLS_TRACER_CAPTURE_RESPONSE</code> and <code>POWERTOOLS_TRACER_CAPTURE_ERROR</code> as needed. Optionally, you can override behavior by different supported <code>captureMode</code> to record response, exception or both.</p> <p>Returning sensitive information from your Lambda handler or functions, where <code>Tracing</code> is used?</p> <p>You can disable annotation from capturing their responses and exception as tracing metadata with <code>captureMode=DISABLED</code> or globally by setting environment variables <code>POWERTOOLS_TRACER_CAPTURE_RESPONSE</code> and <code>POWERTOOLS_TRACER_CAPTURE_ERROR</code> to <code>false</code></p> Disable on annotationDisable Globally <pre><code>public class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    @Tracing(captureMode=CaptureMode.DISABLED)\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n    ...\n    }\n</code></pre> <pre><code>Resources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n        ...\n        Runtime: java11\n\n        Tracing: Active\n        Environment:\n            Variables:\n                POWERTOOLS_TRACER_CAPTURE_RESPONSE: false\n                POWERTOOLS_TRACER_CAPTURE_ERROR: false\n</code></pre>"
        },
        {
            "location": "core/tracing/#annotations-metadata",
            "title": "Annotations &amp; Metadata",
            "text": "<p>Annotations are key-values associated with traces and indexed by AWS X-Ray. You can use them to filter traces and to create Trace Groups to slice and dice your transactions.</p> <p>Metadata are key-values also associated with traces but not indexed by AWS X-Ray. You can use them to add additional  context for an operation using any native object.</p> AnnotationsMetadata <p>You can add annotations using <code>putAnnotation()</code> method from TracingUtils <pre><code>import software.amazon.lambda.powertools.tracing.Tracing;\nimport software.amazon.lambda.powertools.tracing.TracingUtils;\n\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    @Tracing\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n        TracingUtils.putAnnotation(\"annotation\", \"value\");\n    }\n}\n</code></pre></p> <p>You can add metadata using <code>putMetadata()</code> method from TracingUtils <pre><code>import software.amazon.lambda.powertools.tracing.Tracing;\nimport software.amazon.lambda.powertools.tracing.TracingUtils;\n\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    @Tracing\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n        TracingUtils.putMetadata(\"content\", \"value\");\n    }\n}\n</code></pre></p>"
        },
        {
            "location": "core/tracing/#override-default-object-mapper",
            "title": "Override default object mapper",
            "text": "<p>You can optionally choose to override default object mapper which is used to serialize method response and exceptions when enabled. You might want to supply custom object mapper in order to control how serialisation is done, for example, when you want to log only specific fields from received event due to security.</p> App.java <pre><code>import software.amazon.lambda.powertools.tracing.Tracing;\nimport software.amazon.lambda.powertools.tracing.TracingUtils;\nimport static software.amazon.lambda.powertools.tracing.CaptureMode.RESPONSE;\n\n/**\n * Handler for requests to Lambda function.\n */\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; { \n    static {\n        ObjectMapper objectMapper = new ObjectMapper();\n        SimpleModule simpleModule = new SimpleModule();\n        objectMapper.registerModule(simpleModule);\n\n        TracingUtils.defaultObjectMapper(objectMapper);\n    }\n\n    @Tracing(captureMode = RESPONSE)\n    public APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) {\n        ...\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/tracing/#utilities",
            "title": "Utilities",
            "text": "<p>Tracing modules comes with certain utility method when you don't want to use annotation for capturing a code block under a subsegment, or you are doing multithreaded programming. Refer examples below.</p> Functional ApiMulti Threaded Programming <pre><code>import software.amazon.lambda.powertools.tracing.Tracing;\nimport software.amazon.lambda.powertools.tracing.TracingUtils;\n\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n         TracingUtils.withSubsegment(\"loggingResponse\", subsegment -&gt; {\n            // Some business logic\n         });\n\n         TracingUtils.withSubsegment(\"localNamespace\", \"loggingResponse\", subsegment -&gt; {\n            // Some business logic\n         });\n    }\n}\n</code></pre> <pre><code>import static software.amazon.lambda.powertools.tracing.TracingUtils.withEntitySubsegment;\n\npublic class App implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n        // Extract existing trace data\n        Entity traceEntity = AWSXRay.getTraceEntity();\n\n        Thread anotherThread = new Thread(() -&gt; withEntitySubsegment(\"inlineLog\", traceEntity, subsegment -&gt; {\n            // Business logic in separate thread\n        }));\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/tracing/#instrumenting-sdk-clients-and-http-calls",
            "title": "Instrumenting SDK clients and HTTP calls",
            "text": "<p>Powertools for Lambda (Java) cannot intercept SDK clients instantiation to add X-Ray instrumentation. You should make sure to instrument the SDK clients explicitly. Refer details on how to instrument SDK client with Xray  and outgoing http calls. For example:</p> LambdaHandler.java <pre><code>import com.amazonaws.xray.AWSXRay;\nimport com.amazonaws.xray.handlers.TracingHandler;\n\npublic class LambdaHandler {\n    private AmazonDynamoDB client = AmazonDynamoDBClientBuilder.standard()\n        .withRegion(Regions.fromName(System.getenv(\"AWS_REGION\")))\n        .withRequestHandlers(new TracingHandler(AWSXRay.getGlobalRecorder()))\n        .build();\n    // ...\n}\n</code></pre>"
        },
        {
            "location": "core/tracing/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>When using <code>@Tracing</code> annotation, your Junit test cases needs to be configured to create parent Segment required by AWS X-Ray SDK for Java.</p> <p>Below are two ways in which you can configure your tests.</p>"
        },
        {
            "location": "core/tracing/#configure-environment-variable-on-project-level-recommended",
            "title": "Configure environment variable on project level (Recommended)",
            "text": "<p>You can choose to configure environment variable on project level for your test cases run. This is recommended approach as it will avoid the need of configuring each test case specifically.</p> <p>Below are examples configuring your maven/gradle projects. You can choose to configure it differently as well as long as you are making sure that environment variable <code>LAMBDA_TASK_ROOT</code> is set. This variable is  used internally via AWS X-Ray SDK to configure itself properly for lambda runtime.</p> Maven (pom.xml)Gradle (build.gradle)  <pre><code>&lt;build&gt;\n    ...\n  &lt;plugins&gt;\n    &lt;!--  Configures environment variable to avoid initialization of AWS X-Ray segments for each tests--&gt;\n      &lt;plugin&gt;\n          &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n          &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n          &lt;configuration&gt;\n              &lt;environmentVariables&gt;\n                  &lt;LAMBDA_TASK_ROOT&gt;handler&lt;/LAMBDA_TASK_ROOT&gt;\n              &lt;/environmentVariables&gt;\n          &lt;/configuration&gt;\n      &lt;/plugin&gt;\n  &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>// Configures environment variable to avoid initialization of AWS X-Ray segments for each tests\ntest {\n    environment \"LAMBDA_TASK_ROOT\", \"handler\"\n}\n</code></pre>"
        },
        {
            "location": "core/tracing/#configure-test-cases-not-recommended",
            "title": "Configure test cases (Not Recommended)",
            "text": "<p>You can choose to configure each of your test case instead as well if you choose not to configure environment variable on project level.  Below is an example configuration needed for each test case.</p> AppTest.java <pre><code>import com.amazonaws.xray.AWSXRay;\nimport org.junit.After;\nimport org.junit.Before;\nimport org.junit.Test;\n\npublic class AppTest {\n\n    @Before\n    public void setup() {\n        if(null == System.getenv(\"LAMBDA_TASK_ROOT\")) {\n            AWSXRay.beginSegment(\"test\");\n        }\n    }\n\n    @After\n    public void tearDown() {\n        // Needed when using sam build --use-container\n        if (AWSXRay.getCurrentSubsegmentOptional().isPresent()) {\n            AWSXRay.endSubsegment();\n        }\n\n        if(null == System.getenv(\"LAMBDA_TASK_ROOT\")) {\n          AWSXRay.endSegment();\n        }\n    }\n\n    @Test\n    public void successfulResponse() {\n        // test logic\n    }\n</code></pre>"
        },
        {
            "location": "processes/maintainers/",
            "title": "Maintainers playbook",
            "text": ""
        },
        {
            "location": "processes/maintainers/#overview",
            "title": "Overview",
            "text": "<p>Please treat this content as a living document.</p> <p>This is document explains who the maintainers are, their responsibilities, and how they should be doing it. If you're interested in contributing,  see CONTRIBUTING.</p>"
        },
        {
            "location": "processes/maintainers/#current-maintainers",
            "title": "Current Maintainers",
            "text": "Maintainer GitHub ID Affiliation Jerome Van Der Linden jeromevdl Amazon Michele Ricciardi mriccia Amazon Scott Gerring scottgerring Amazon"
        },
        {
            "location": "processes/maintainers/#emeritus",
            "title": "Emeritus",
            "text": "<p>Previous active maintainers who contributed to this project.</p> Maintainer GitHub ID Affiliation Mark Sailes msailes Amazon Pankaj Agrawal pankajagrawal16 Former Amazon Steve Houel stevehouel Amazon"
        },
        {
            "location": "processes/maintainers/#labels",
            "title": "Labels",
            "text": "<p>These are the most common labels used by maintainers to triage issues, pull requests (PR), and for project management:</p> Label Usage Notes triage New issues that require maintainers review Issue template bug Unexpected, reproducible and unintended software behavior PR/Release automation; Doc snippets are excluded; documentation Documentation improvements PR/Release automation; Doc additions, fixes, etc.; duplicate Dupe of another issue enhancement New or enhancements to existing features Issue template RFC Technical design documents related to a feature request Issue template help wanted Tasks you want help from anyone to move forward Bandwidth, complex topics, etc. feature-parity Adding features present in other Powertools for Lambda libraries good first issue Somewhere for new contributors to start governance Issues related to project governance - contributor guides, automation, etc. question Issues that are raised to ask questions maven Related to the build system need-more-information Missing information before making any calls status/staged-next-release Changes are merged and will be available once the next release is made. status/staged-next-major-release Contains breaking changes - merged changes will be available once the next major release is made. blocked Issues or PRs that are blocked for varying reasons Timeline is uncertain priority:1 Critical - needs urgent attention priority:2 High - core feature, or affects 60%+ of users priority:3 Neutral - not a core feature, or affects &lt; 40% of users priority:4 Low - nice to have priority:5 Low - idea for later invalid This doesn't seem right size/XS PRs between 0-9 LOC PR automation size/S PRs between 10-29 LOC PR automation size/M PRs between 30-99 LOC PR automation size/L PRs between 100-499 LOC PR automation size/XL PRs between 500-999 LOC, often PRs that grown with feedback PR automation size/XXL PRs with 1K+ LOC, largely documentation related PR automation dependencies Changes that touch dependencies, e.g. Dependabot, etc. PR/ automation maintenance Address outstanding tech debt"
        },
        {
            "location": "processes/maintainers/#maintainer-responsibilities",
            "title": "Maintainer Responsibilities",
            "text": "<p>Maintainers are active and visible members of the community, and have  maintain-level permissions on a repository.  Use those privileges to serve the community and evolve code as follows.</p> <p>Be aware of recurring ambiguous situations and document them to help your fellow maintainers.</p>"
        },
        {
            "location": "processes/maintainers/#uphold-code-of-conduct",
            "title": "Uphold Code of Conduct",
            "text": "<p>Model the behavior set forward by the Code of Conduct and raise any violations to other maintainers and admins. There could be unusual circumstances where inappropriate  behavior does not immediately fall within the Code of Conduct.</p> <p>These might be nuanced and should be handled with extra care - when in doubt, do not engage and reach out to other maintainers  and admins.</p>"
        },
        {
            "location": "processes/maintainers/#prioritize-security",
            "title": "Prioritize Security",
            "text": "<p>Security is your number one priority. Maintainer's Github keys must be password protected securely and any reported  security vulnerabilities are addressed before features or bugs.</p> <p>Note that this repository is monitored and supported 24/7 by Amazon Security, see Security disclosures for details.</p>"
        },
        {
            "location": "processes/maintainers/#review-pull-requests",
            "title": "Review Pull Requests",
            "text": "<p>Review pull requests regularly, comment, suggest, reject, merge and close. Accept only high quality pull-requests.  Provide code reviews and guidance on incoming pull requests.</p> <p>PRs are labeled based on file changes and semantic title. Pay attention to whether labels reflect the current state of the PR and correct accordingly.</p> <p>Use and enforce semantic versioning pull request titles, as these will be used for CHANGELOG and Release notes - make sure they communicate their  intent at the human level.</p> <p>For issues linked to a PR, make sure <code>status/staged-next-release</code> label is applied to them when merging. Upon release, these issues will be notified which release version contains their change.</p> <p>See Common scenarios section for additional guidance.</p>"
        },
        {
            "location": "processes/maintainers/#triage-new-issues",
            "title": "Triage New Issues",
            "text": "<p>Manage labels, review issues regularly, and create new labels as needed by the project. Remove <code>triage</code>  label when you're able to confirm the validity of a request, a bug can be reproduced, etc.  Give priority to the original author for implementation, unless it is a sensitive task that is best handled by maintainers.</p> <p>Make sure issues are assigned to our board of activities.</p> <p>Use our labels to signal good first issues to new community members, and to set expectation that this might  need additional feedback from the author, other customers, experienced community members and/or maintainers.</p> <p>Be aware of casual contributors and recurring contributors.  Provide the experience and attention you wish you had if you were starting in open source.</p> <p>See Common scenarios section for additional guidance.</p>"
        },
        {
            "location": "processes/maintainers/#triage-bug-reports",
            "title": "Triage Bug Reports",
            "text": "<p>Be familiar with our definition of bug. If it's not a bug, you can close it or adjust its title and  labels - always communicate the reason accordingly.</p> <p>For bugs caused by upstream dependencies, replace <code>bug</code> with <code>bug-upstream</code> label. Ask the author whether they'd like to raise the issue upstream or if they prefer us to do so.</p> <p>Assess the impact and make the call on whether we need an emergency release. Contact other maintainers when in doubt.</p> <p>See Common scenarios section for additional guidance.</p>"
        },
        {
            "location": "processes/maintainers/#triage-rfcs",
            "title": "Triage RFCs",
            "text": "<p>RFC is a collaborative process to help us get to the most optimal solution given the context. Their purpose is to ensure everyone understands what this context is, their trade-offs, and alternative solutions that were part of the research  before implementation begins.</p> <p>Make sure you ask these questions in mind when reviewing:</p> <ul> <li>Does it use our RFC template?</li> <li>Does it match our Tenets?</li> <li>Does the proposal address the use case? If so, is the recommended usage explicit?</li> <li>Does it focus on the mechanics to solve the use case over fine-grained implementation details?</li> <li>Can anyone familiar with the code base implement it?</li> <li>If approved, are they interested in contributing? Do they need any guidance?</li> <li>Does this significantly increase the overall project maintenance? Do we have the skills to maintain it?</li> <li>If we can't take this use case, are there alternative projects we could recommend? Or does it call for a new project altogether?</li> </ul> <p>When necessary, be upfront that the time to review, approve, and implement a RFC can vary -  see Contribution is stuck. Some RFCs may be further updated after implementation, as certain areas become clearer.</p> <p>Some examples using our initial and new RFC templates: #92, #94, #95, #991, #1226</p>"
        },
        {
            "location": "processes/maintainers/#releasing-a-new-version",
            "title": "Releasing a new version",
            "text": "<p>The release process is currently a long, multi-step process. The team is in the process of automating at it.</p> <p>Firstly, make sure the commit history in the <code>main</code> branch (1) it's up to date, (2) commit messages are semantic,  and (3) commit messages have their respective area, for example <code>feat: &lt;change&gt;</code>, <code>chore: ...</code>).</p> <p>Looks good, what's next?</p> <p>Kickoff the <code>Prepare for maven central release</code> workflow with the intended rekease version. Once this has completed, it will draft a Pull Request named something like <code>chore: Prep release 1.19.0</code>. the PR will (1) roll all of the POM versions forward to the new release version and (2) release notes. </p> <p>Once this is done, check out the branch and clean up the release notes. These will be used both in the CHANGELOG.md file file and the published github release information, and you can use the existing release notes to see how changes are summarized.</p> <p>Next, commit and push, wait for the build to complete, and merge to main. Once main has built successfully (i.e. build, tests and end-to-end tests should pass), create a  tagged release from the Github UI, using the same release notes.</p> <p>Next, run the <code>Publish package to the Maven Central Repository</code> action to release the library.</p> <p>Finally, by hand, create a PR rolling all of the POMs onto the next snapshot version (e.g. <code>1.20.0-SNAPSHOT</code>). </p>"
        },
        {
            "location": "processes/maintainers/#add-continuous-integration-checks",
            "title": "Add Continuous Integration Checks",
            "text": "<p>Add integration checks that validate pull requests and pushes to ease the burden on Pull Request reviewers.  Continuously revisit areas of improvement to reduce operational burden in all parties involved.</p>"
        },
        {
            "location": "processes/maintainers/#negative-impact-on-the-project",
            "title": "Negative Impact on the Project",
            "text": "<p>Actions that negatively impact the project will be handled by the admins, in coordination with other maintainers,  in balance with the urgency of the issue. Examples would be Code of Conduct violations, deliberate harmful or malicious actions, spam, monopolization, and security risks.</p>"
        },
        {
            "location": "processes/maintainers/#common-scenarios",
            "title": "Common scenarios",
            "text": "<p>These are recurring ambiguous situations that new and existing maintainers may encounter. They serve as guidance.  It is up to each maintainer to follow, adjust, or handle in a different manner as long as  our conduct is consistent</p>"
        },
        {
            "location": "processes/maintainers/#contribution-is-stuck",
            "title": "Contribution is stuck",
            "text": "<p>A contribution can get stuck often due to lack of bandwidth and language barrier. For bandwidth issues,  check whether the author needs help. Make sure you get their permission before pushing code into their existing PR - do not create a new PR unless strictly necessary.</p> <p>For language barrier and others, offer a 1:1 chat to get them unblocked. Often times, English might not be their  primary language, and writing in public might put them off, or come across not the way they intended to be.</p> <p>In other cases, you may have constrained capacity. Use <code>help wanted</code> label when you want to signal other maintainers  and external contributors that you could use a hand to move it forward.</p>"
        },
        {
            "location": "processes/maintainers/#insufficient-feedback-or-information",
            "title": "Insufficient feedback or information",
            "text": "<p>When in doubt, use the <code>need-more-information</code> label to signal more context and feedback are necessary before proceeding. </p>"
        },
        {
            "location": "processes/maintainers/#crediting-contributions",
            "title": "Crediting contributions",
            "text": "<p>We credit all contributions as part of each release note as an automated process. If you find  contributors are missing from the release note you're producing, please add them manually.</p>"
        },
        {
            "location": "processes/maintainers/#is-that-a-bug",
            "title": "Is that a bug?",
            "text": "<p>A bug produces incorrect or unexpected results at runtime that differ from its intended behavior.  Bugs must be reproducible. They directly affect customers experience at runtime despite following its recommended usage.</p> <p>Documentation snippets, use of internal components, or unadvertised functionalities are not considered bugs.</p>"
        },
        {
            "location": "processes/maintainers/#mentoring-contributions",
            "title": "Mentoring contributions",
            "text": "<p>Always favor mentoring issue authors to contribute, unless they're not interested or the implementation is sensitive (e.g., complexity, time to release, etc.).</p> <p>Make use of <code>help wanted</code> and <code>good first issue</code> to signal additional contributions the community can help.</p>"
        },
        {
            "location": "processes/maintainers/#long-running-issues-or-prs",
            "title": "Long running issues or PRs",
            "text": "<p>Try offering a 1:1 call in the attempt to get to a mutual understanding and clarify areas that maintainers could help.</p> <p>In the rare cases where both parties don't have the bandwidth or expertise to continue, it's best to use the <code>revisit-in-3-months</code> label. By then, see if it's possible to break the PR or issue in smaller chunks, and eventually close if there is no progress.</p>"
        },
        {
            "location": "utilities/batch/",
            "title": "Batch Processing",
            "text": "<p>The batch processing utility provides a way to handle partial failures when processing batches of messages from SQS queues, SQS FIFO queues, Kinesis Streams, or DynamoDB Streams.</p> <pre><code>stateDiagram-v2\n    direction LR\n    BatchSource: Amazon SQS &lt;br/&gt;&lt;br/&gt; Amazon Kinesis Data Streams &lt;br/&gt;&lt;br/&gt; Amazon DynamoDB Streams &lt;br/&gt;&lt;br/&gt;\n    LambdaInit: Lambda invocation\n    BatchProcessor: Batch Processor\n    RecordHandler: Record Handler function\n    YourLogic: Your logic to process each batch item\n    LambdaResponse: Lambda response\n    BatchSource --&gt; LambdaInit\n    LambdaInit --&gt; BatchProcessor\n    BatchProcessor --&gt; RecordHandler\n    state BatchProcessor {\n        [*] --&gt; RecordHandler: Your function\n        RecordHandler --&gt; YourLogic\n    }\n    RecordHandler --&gt; BatchProcessor: Collect results\n    BatchProcessor --&gt; LambdaResponse: Report items that failed processing</code></pre> <p>Key Features</p> <ul> <li>Reports batch item failures to reduce number of retries for a record upon errors</li> <li>Simple interface to process each batch record</li> <li>Integrates with Java Events library and the deserialization module </li> <li>Build your own batch processor by extending primitives</li> </ul> <p>Background</p> <p>When using SQS, Kinesis Data Streams, or DynamoDB Streams as a Lambda event source, your Lambda functions are  triggered with a batch of messages. If your function fails to process any message from the batch, the entire batch returns to your queue or stream. This same batch is then retried until either condition happens first: a) your Lambda function returns a successful response,  b) record reaches maximum retry attempts, or  c) records expire.</p> <pre><code>journey\n  section Conditions\n    Successful response: 5: Success\n    Maximum retries: 3: Failure\n    Records expired: 1: Failure</code></pre> <p>This behavior changes when you enable Report Batch Item Failures feature in your Lambda function event source configuration:</p> <ul> <li>SQS queues. Only messages reported as failure will return to the queue for a retry, while successful ones will be deleted.</li> <li>Kinesis data streams and DynamoDB streams. Single reported failure will use its sequence number as the stream checkpoint.  Multiple reported failures will use the lowest sequence number as checkpoint.</li> </ul> <p>With this utility, batch records are processed individually – only messages that failed to be processed  return to the queue or stream for a further retry. You simply build a <code>BatchProcessor</code> in your handler, and return its response from the handler's <code>processMessage</code> implementation. Exceptions are handled  internally and an appropriate partial response for the message source is returned to Lambda for you.</p> <p>Warning</p> <p>While this utility lowers the chance of processing messages more than once, it is still not guaranteed.  We recommend implementing processing logic in an idempotent manner wherever possible, for instance, by taking advantage of the idempotency module. More details on how Lambda works with SQS can be found in the AWS documentation</p>"
        },
        {
            "location": "utilities/batch/#install",
            "title": "Install",
            "text": "<p>We simply add <code>powertools-batch</code> to our build dependencies. Note - if you are using other Powertools modules that require code-weaving, such as <code>powertools-core</code>, you will need to configure that also.</p> MavenGradle <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-batch&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n</code></pre> <pre><code>    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        implementation 'software.amazon.lambda:powertools-batch:1.20.1'\n    }\n</code></pre>"
        },
        {
            "location": "utilities/batch/#getting-started",
            "title": "Getting Started",
            "text": "<p>For this feature to work, you need to (1) configure your Lambda function event source to use <code>ReportBatchItemFailures</code>, and (2) return a specific response to report which records failed to be processed. </p> <p>You can use your preferred deployment framework to set the correct configuration while this utility, while the <code>powertools-batch</code> module handles generating the response, which simply needs to be returned as the result of your Lambda handler.</p> <p>A complete Serverless Application Model example can be found here covering all of the batch sources.</p> <p>For more information on configuring <code>ReportBatchItemFailures</code>,  see the details for SQS,  Kinesis,and DynamoDB Streams. </p> <p>You do not need any additional IAM permissions to use this utility, except for what each event source requires.</p>"
        },
        {
            "location": "utilities/batch/#processing-messages-from-sqs",
            "title": "Processing messages from SQS",
            "text": "SQSBatchHandlerSQS ProductSQS Example Event <pre><code>import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.SQSBatchResponse;\nimport com.amazonaws.services.lambda.runtime.events.SQSEvent;\nimport software.amazon.lambda.powertools.batch.BatchMessageHandlerBuilder;\nimport software.amazon.lambda.powertools.batch.handler.BatchMessageHandler;\n\npublic class SqsBatchHandler implements RequestHandler&lt;SQSEvent, SQSBatchResponse&gt; {\n\n    private final BatchMessageHandler&lt;SQSEvent, SQSBatchResponse&gt; handler;\n\n    public SqsBatchHandler() {\n        handler = new BatchMessageHandlerBuilder()\n                .withSqsBatchHandler()\n                .buildWithMessageHandler(this::processMessage, Product.class);\n    }\n\n    @Override\n    public SQSBatchResponse handleRequest(SQSEvent sqsEvent, Context context) {\n        return handler.processBatch(sqsEvent, context);\n    }\n\n\n    private void processMessage(Product p, Context c) {\n        // Process the product\n    }\n\n}\n</code></pre> <pre><code>public class Product {\n    private long id;\n\n    private String name;\n\n    private double price;\n\n    public Product() {\n    }\n\n    public Product(long id, String name, double price) {\n        this.id = id;\n        this.name = name;\n        this.price = price;\n    }\n\n    public long getId() {\n        return id;\n    }\n\n    public void setId(long id) {\n        this.id = id;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public double getPrice() {\n        return price;\n    }\n\n    public void setPrice(double price) {\n        this.price = price;\n    }\n}\n</code></pre> <pre><code>    {\n        \"Records\": [\n        {\n            \"messageId\": \"d9144555-9a4f-4ec3-99a0-34ce359b4b54\",\n            \"receiptHandle\": \"13e7f7851d2eaa5c01f208ebadbf1e72==\",\n            \"body\": \"{\\n  \\\"id\\\": 1234,\\n  \\\"name\\\": \\\"product\\\",\\n  \\\"price\\\": 42\\n}\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1601975706495\",\n                \"SenderId\": \"AROAIFU437PVZ5L2J53F5\",\n                \"ApproximateFirstReceiveTimestamp\": \"1601975706499\"\n            },\n            \"messageAttributes\": {\n            },\n            \"md5OfBody\": \"13e7f7851d2eaa5c01f208ebadbf1e72\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:eu-central-1:123456789012:TestLambda\",\n            \"awsRegion\": \"eu-central-1\"\n        },\n        {\n            \"messageId\": \"e9144555-9a4f-4ec3-99a0-34ce359b4b54\",\n            \"receiptHandle\": \"13e7f7851d2eaa5c01f208ebadbf1e72==\",\n            \"body\": \"{\\n  \\\"id\\\": 12345,\\n  \\\"name\\\": \\\"product5\\\",\\n  \\\"price\\\": 45\\n}\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1601975706495\",\n                \"SenderId\": \"AROAIFU437PVZ5L2J53F5\",\n                \"ApproximateFirstReceiveTimestamp\": \"1601975706499\"\n            },\n            \"messageAttributes\": {\n            },\n            \"md5OfBody\": \"13e7f7851d2eaa5c01f208ebadbf1e72\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:eu-central-1:123456789012:TestLambda\",\n            \"awsRegion\": \"eu-central-1\"\n        }]\n    }\n</code></pre>"
        },
        {
            "location": "utilities/batch/#processing-messages-from-kinesis-streams",
            "title": "Processing messages from Kinesis Streams",
            "text": "KinesisBatchHandlerKinesis ProductKinesis Example Event <pre><code>import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.KinesisEvent;\nimport com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;\nimport software.amazon.lambda.powertools.batch.BatchMessageHandlerBuilder;\nimport software.amazon.lambda.powertools.batch.handler.BatchMessageHandler;\n\npublic class KinesisBatchHandler implements RequestHandler&lt;KinesisEvent, StreamsEventResponse&gt; {\n\n    private final BatchMessageHandler&lt;KinesisEvent, StreamsEventResponse&gt; handler;\n\n    public KinesisBatchHandler() {\n        handler = new BatchMessageHandlerBuilder()\n                .withKinesisBatchHandler()\n                .buildWithMessageHandler(this::processMessage, Product.class);\n    }\n\n    @Override\n    public StreamsEventResponse handleRequest(KinesisEvent kinesisEvent, Context context) {\n        return handler.processBatch(kinesisEvent, context);\n    }\n\n    private void processMessage(Product p, Context c) {\n        // process the product\n    }\n\n}\n</code></pre> <pre><code>public class Product {\n    private long id;\n\n    private String name;\n\n    private double price;\n\n    public Product() {\n    }\n\n    public Product(long id, String name, double price) {\n        this.id = id;\n        this.name = name;\n        this.price = price;\n    }\n\n    public long getId() {\n        return id;\n    }\n\n    public void setId(long id) {\n        this.id = id;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public double getPrice() {\n        return price;\n    }\n\n    public void setPrice(double price) {\n        this.price = price;\n    }\n}\n</code></pre> <pre><code>    {\n      \"Records\": [\n        {\n          \"kinesis\": {\n            \"partitionKey\": \"partitionKey-03\",\n            \"kinesisSchemaVersion\": \"1.0\",\n            \"data\": \"eyJpZCI6MTIzNCwgIm5hbWUiOiJwcm9kdWN0IiwgInByaWNlIjo0Mn0=\",\n            \"sequenceNumber\": \"49545115243490985018280067714973144582180062593244200961\",\n            \"approximateArrivalTimestamp\": 1428537600,\n            \"encryptionType\": \"NONE\"\n          },\n          \"eventSource\": \"aws:kinesis\",\n          \"eventID\": \"shardId-000000000000:49545115243490985018280067714973144582180062593244200961\",\n          \"invokeIdentityArn\": \"arn:aws:iam::EXAMPLE\",\n          \"eventVersion\": \"1.0\",\n          \"eventName\": \"aws:kinesis:record\",\n          \"eventSourceARN\": \"arn:aws:kinesis:EXAMPLE\",\n          \"awsRegion\": \"eu-central-1\"\n        },\n        {\n          \"kinesis\": {\n            \"partitionKey\": \"partitionKey-03\",\n            \"kinesisSchemaVersion\": \"1.0\",\n            \"data\": \"eyJpZCI6MTIzNDUsICJuYW1lIjoicHJvZHVjdDUiLCAicHJpY2UiOjQ1fQ==\",\n            \"sequenceNumber\": \"49545115243490985018280067714973144582180062593244200962\",\n            \"approximateArrivalTimestamp\": 1428537600,\n            \"encryptionType\": \"NONE\"\n          },\n          \"eventSource\": \"aws:kinesis\",\n          \"eventID\": \"shardId-000000000000:49545115243490985018280067714973144582180062593244200961\",\n          \"invokeIdentityArn\": \"arn:aws:iam::EXAMPLE\",\n          \"eventVersion\": \"1.0\",\n          \"eventName\": \"aws:kinesis:record\",\n          \"eventSourceARN\": \"arn:aws:kinesis:EXAMPLE\",\n          \"awsRegion\": \"eu-central-1\"\n        }\n      ]\n    }\n</code></pre>"
        },
        {
            "location": "utilities/batch/#processing-messages-from-dynamodb-streams",
            "title": "Processing messages from DynamoDB Streams",
            "text": "DynamoDBStreamBatchHandlerDynamoDB Example Event <pre><code>import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.RequestHandler;\nimport com.amazonaws.services.lambda.runtime.events.DynamodbEvent;\nimport com.amazonaws.services.lambda.runtime.events.StreamsEventResponse;\nimport software.amazon.lambda.powertools.batch.BatchMessageHandlerBuilder;\nimport software.amazon.lambda.powertools.batch.handler.BatchMessageHandler;\n\npublic class DynamoDBStreamBatchHandler implements RequestHandler&lt;DynamodbEvent, StreamsEventResponse&gt; {\n\n    private final BatchMessageHandler&lt;DynamodbEvent, StreamsEventResponse&gt; handler;\n\n    public DynamoDBStreamBatchHandler() {\n        handler = new BatchMessageHandlerBuilder()\n                .withDynamoDbBatchHandler()\n                .buildWithRawMessageHandler(this::processMessage);\n    }\n\n    @Override\n    public StreamsEventResponse handleRequest(DynamodbEvent ddbEvent, Context context) {\n        return handler.processBatch(ddbEvent, context);\n    }\n\n    private void processMessage(DynamodbEvent.DynamodbStreamRecord dynamodbStreamRecord, Context context) {\n        // Process the change record\n    }\n}\n</code></pre> <pre><code>    {\n      \"Records\": [\n        {\n          \"eventID\": \"c4ca4238a0b923820dcc509a6f75849b\",\n          \"eventName\": \"INSERT\",\n          \"eventVersion\": \"1.1\",\n          \"eventSource\": \"aws:dynamodb\",\n          \"awsRegion\": \"eu-central-1\",\n          \"dynamodb\": {\n            \"Keys\": {\n              \"Id\": {\n                \"N\": \"101\"\n              }\n            },\n            \"NewImage\": {\n              \"Message\": {\n                \"S\": \"New item!\"\n              },\n              \"Id\": {\n                \"N\": \"101\"\n              }\n            },\n            \"ApproximateCreationDateTime\": 1428537600,\n            \"SequenceNumber\": \"4421584500000000017450439091\",\n            \"SizeBytes\": 26,\n            \"StreamViewType\": \"NEW_AND_OLD_IMAGES\"\n          },\n          \"eventSourceARN\": \"arn:aws:dynamodb:eu-central-1:123456789012:table/ExampleTableWithStream/stream/2015-06-27T00:48:05.899\",\n          \"userIdentity\": {\n            \"principalId\": \"dynamodb.amazonaws.com\",\n            \"type\": \"Service\"\n          }\n        },\n        {\n          \"eventID\": \"c81e728d9d4c2f636f067f89cc14862c\",\n          \"eventName\": \"MODIFY\",\n          \"eventVersion\": \"1.1\",\n          \"eventSource\": \"aws:dynamodb\",\n          \"awsRegion\": \"eu-central-1\",\n          \"dynamodb\": {\n            \"Keys\": {\n              \"Id\": {\n                \"N\": \"101\"\n              }\n            },\n            \"NewImage\": {\n              \"Message\": {\n                \"S\": \"This item has changed\"\n              },\n              \"Id\": {\n                \"N\": \"101\"\n              }\n            },\n            \"OldImage\": {\n              \"Message\": {\n                \"S\": \"New item!\"\n              },\n              \"Id\": {\n                \"N\": \"101\"\n              }\n            },\n            \"ApproximateCreationDateTime\": 1428537600,\n            \"SequenceNumber\": \"4421584500000000017450439092\",\n            \"SizeBytes\": 59,\n            \"StreamViewType\": \"NEW_AND_OLD_IMAGES\"\n          },\n          \"eventSourceARN\": \"arn:aws:dynamodb:eu-central-1:123456789012:table/ExampleTableWithStream/stream/2015-06-27T00:48:05.899\"\n        }\n      ]\n    }\n</code></pre>"
        },
        {
            "location": "utilities/batch/#handling-messages",
            "title": "Handling Messages",
            "text": ""
        },
        {
            "location": "utilities/batch/#raw-message-and-deserialized-message-handlers",
            "title": "Raw message and deserialized message handlers",
            "text": "<p>You must provide either a raw message handler, or a deserialized message handler. The raw message handler receives the envelope record type relevant for the particular event source - for instance, the SQS event source provides SQSMessage instances. The deserialized message handler extracts the body from this envelope, and deserializes it to a user-defined type. Note that deserialized message handlers are not relevant for the DynamoDB provider, as the format of the inner  message is fixed by DynamoDB.</p> <p>In general, the deserialized message handler should be used unless you need access to information on the envelope.</p> Raw Message HandlerDeserialized Message Handler <pre><code>public void setup() {\n    BatchMessageHandler&lt;SQSEvent, SQSBatchResponse&gt; handler = new BatchMessageHandlerBuilder()\n            .withSqsBatchHandler()\n            .buildWithRawMessageHandler(this::processRawMessage);\n}\n\nprivate void processRawMessage(SQSEvent.SQSMessage sqsMessage) {\n    // Do something with the raw message\n}\n</code></pre> <pre><code>public void setup() {\n    BatchMessageHandler&lt;SQSEvent, SQSBatchResponse&gt; handler = new BatchMessageHandlerBuilder()\n            .withSqsBatchHandler()\n            .buildWitMessageHandler(this::processRawMessage, Product.class);\n}\n\nprivate void processMessage(Product product) {\n    // Do something with the deserialized message\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch/#success-and-failure-handlers",
            "title": "Success and failure handlers",
            "text": "<p>You can register a success or failure handler which will be invoked as each message is processed by the batch module. This may be useful for reporting - for instance, writing metrics or logging failures. </p> <p>These handlers are optional. Batch failures are handled by the module regardless of whether or not you  provide a custom failure handler. </p> <p>Handlers can be provided when building the batch processor and are available for all event sources. For instance for DynamoDB:</p> <pre><code>BatchMessageHandler&lt;DynamodbEvent, StreamsEventResponse&gt; handler = new BatchMessageHandlerBuilder()\n            .withDynamoDbBatchHandler()\n            .withSuccessHandler((m) -&gt; {\n                // Success handler receives the raw message\n                LOGGER.info(\"Message with sequenceNumber {} was successfully processed\",\n                    m.getDynamodb().getSequenceNumber());\n            })\n            .withFailureHandler((m, e) -&gt; {\n                // Failure handler receives the raw message and the exception thrown.\n                LOGGER.info(\"Message with sequenceNumber {} failed to be processed: {}\"\n                , e.getDynamodb().getSequenceNumber(), e);\n            })\n            .buildWithMessageHander(this::processMessage);\n</code></pre> <p>Info</p> <p>If the success handler throws an exception, the item it is processing will be marked as failed by the batch processor. If the failure handler throws, the batch processing will continue; the item it is processing has already been marked as failed.</p>"
        },
        {
            "location": "utilities/batch/#lambda-context",
            "title": "Lambda Context",
            "text": "<p>Both raw and deserialized message handlers can choose to take the Lambda context as an argument if they need it, or not:</p> <pre><code>    public class ClassWithHandlers {\n\n        private void processMessage(Product product) {\n            // Do something with the raw message\n        }\n\n        private void processMessageWithContext(Product product, Context context) {\n            // Do something with the raw message and the lambda Context\n        }\n    }\n</code></pre>"
        },
        {
            "location": "utilities/custom_resources/",
            "title": "Custom Resources",
            "text": "<p>CloudFormation Custom resources provide a way for AWS Lambda functions to execute provisioning logic whenever CloudFormation stacks are created, updated, or deleted. </p> <p>Powertools-cloudformation makes it easy to write Lambda functions in Java that are used as CloudFormation custom resources.   The utility reads incoming CloudFormation events, calls your custom code depending on the operation (CREATE, UPDATE or DELETE) and sends responses back to CloudFormation. By using this library you do not need to write code to integrate with CloudFormation, and you only focus on writing the custom provisioning logic inside the Lambda function.</p>"
        },
        {
            "location": "utilities/custom_resources/#install",
            "title": "Install",
            "text": "<p>To install this utility, add the following dependency to your project.</p> MavenGradle <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n    &lt;artifactId&gt;powertools-cloudformation&lt;/artifactId&gt;\n    &lt;version&gt;1.20.1&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> <pre><code> dependencies {\n    ...\n    implementation 'software.amazon.lambda:powertools-cloudformation:1.20.1'\n}\n</code></pre>"
        },
        {
            "location": "utilities/custom_resources/#usage",
            "title": "Usage",
            "text": "<p>To utilise the feature, extend the <code>AbstractCustomResourceHandler</code> class in your Lambda handler class. Next, implement and override the following 3 methods: <code>create</code>, <code>update</code> and <code>delete</code>. The <code>AbstractCustomResourceHandler</code> invokes the right method according to the CloudFormation custom resource request event it receives. Inside the methods, implement your custom provisioning logic, and return a <code>Response</code>. The <code>AbstractCustomResourceHandler</code> takes your <code>Response</code>, builds a custom resource responses and sends it to CloudFormation automatically.  </p> <p>Custom resources notify cloudformation either of <code>SUCCESS</code> or <code>FAILED</code> status. You have 2 utility methods to represent these responses: <code>Response.success(physicalResourceId)</code> and <code>Response.failed(physicalResourceId)</code>. The <code>physicalResourceId</code> is an identifier that is used during the lifecycle operations of the Custom Resource. You should generate a <code>physicalResourceId</code> during the <code>CREATE</code> operation, CloudFormation stores the <code>physicalResourceId</code> and includes it in <code>UPDATE</code> and <code>DELETE</code> events.</p> <p>Here an example of how to implement a Custom Resource using the powertools-cloudformation library:</p> <pre><code>import com.amazonaws.services.lambda.runtime.Context;\nimport com.amazonaws.services.lambda.runtime.events.CloudFormationCustomResourceEvent;\nimport software.amazon.lambda.powertools.cloudformation.AbstractCustomResourceHandler;\nimport software.amazon.lambda.powertools.cloudformation.Response;\n\npublic class MyCustomResourceHandler extends AbstractCustomResourceHandler {\n\n    @Override\n    protected Response create(CloudFormationCustomResourceEvent createEvent, Context context) {\n        String physicalResourceId = \"sample-resource-id-\" + UUID.randomUUID(); //Create a unique ID for your resource\n        ProvisioningResult provisioningResult = doProvisioning(physicalResourceId);\n        if(provisioningResult.isSuccessful()){ //check if the provisioning was successful\n            return Response.success(physicalResourceId);\n        }else{\n            return Response.failed(physicalResourceId);\n        }\n    }\n\n    @Override\n    protected Response update(CloudFormationCustomResourceEvent updateEvent, Context context) {\n        String physicalResourceId = updateEvent.getPhysicalResourceId(); //Get the PhysicalResourceId from CloudFormation\n        UpdateResult updateResult = doUpdates(physicalResourceId);\n        if(updateResult.isSuccessful()){ //check if the update operations were successful\n            return Response.success(physicalResourceId);\n        }else{\n            return Response.failed(physicalResourceId);\n        }\n    }\n\n    @Override\n    protected Response delete(CloudFormationCustomResourceEvent deleteEvent, Context context) {\n        String physicalResourceId = deleteEvent.getPhysicalResourceId(); //Get the PhysicalResourceId from CloudFormation\n        DeleteResult deleteResult = doDeletes(physicalResourceId);\n        if(deleteResult.isSuccessful()){ //check if the delete operations were successful\n            return Response.success(physicalResourceId);\n        }else{\n            return Response.failed(physicalResourceId);\n        }\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/custom_resources/#missing-response-and-exception-handling",
            "title": "Missing <code>Response</code> and exception handling",
            "text": "<p>If a <code>Response</code> is not returned by your code, <code>AbstractCustomResourceHandler</code> defaults the response to <code>SUCCESS</code>. If your code raises an exception (which is not handled), the <code>AbstractCustomResourceHandler</code> defaults the response to <code>FAILED</code>.</p> <p>In both of the scenarios, powertools-java will return the <code>physicalResourceId</code> to CloudFormation based on the following logic: - For CREATE operations, the <code>LogStreamName</code> from the Lambda context is used.  - For UPDATE and DELETE operations, the <code>physicalResourceId</code> provided in the <code>CloudFormationCustomResourceEvent</code> is used. </p>"
        },
        {
            "location": "utilities/custom_resources/#why-do-you-need-a-physicalresourceid",
            "title": "Why do you need a physicalResourceId?",
            "text": "<p>It is recommended that you always explicitly provide a <code>physicalResourceId</code> in your response rather than letting Powertools for AWS Lambda (Java) generate if for you because <code>physicalResourceId</code> has a crucial role in the lifecycle of a CloudFormation custom resource. If the <code>physicalResourceId</code> changes between calls from Cloudformation, for instance in response to an <code>Update</code> event, Cloudformation treats the resource update as a replacement.</p>"
        },
        {
            "location": "utilities/custom_resources/#customising-a-response",
            "title": "Customising a response",
            "text": "<p>As well as the <code>Response.success(physicalResourceId)</code> and <code>Response.failed(physicalResourceId)</code>, you can customise the <code>Response</code> by using the <code>Response.builder()</code>. You customise the responses when you need additional attributes to be shared with other parts of the CloudFormation stack.</p> <p>In the example below, the Lambda function creates a Chime AppInstance and maps the returned ARN to a \"ChimeAppInstanceArn\" attribute.</p> <pre><code>public class ChimeAppInstanceHandler extends AbstractCustomResourceHandler {\n    @Override\n    protected Response create(CloudFormationCustomResourceEvent createEvent, Context context) {\n        String physicalResourceId = \"my-app-name-\" + UUID.randomUUID(); //Create a unique ID \n        CreateAppInstanceRequest chimeRequest = CreateAppInstanceRequest.builder()\n                .name(physicalResourceId)\n                .build();\n        CreateAppInstanceResponse chimeResponse = ChimeClient.builder()\n                .region(\"us-east-1\")\n                .createAppInstance(chimeRequest);\n\n        Map&lt;String, String&gt; chimeAtts = Map.of(\"ChimeAppInstanceArn\", chimeResponse.appInstanceArn());\n        return Response.builder()\n                .value(chimeAtts)\n                .status(Response.Status.SUCCESS)\n                .physicalResourceId(physicalResourceId)\n                .build();\n    }\n}\n</code></pre> <p>For the example above the following response payload will be sent.</p> <pre><code>{\n  \"Status\": \"SUCCESS\",\n  \"PhysicalResourceId\": \"2021/10/01/e3a37e552eff4718a5675c1e31f0649e\",\n  \"StackId\": \"arn:aws:cloudformation:us-east-1:123456789000:stack/Custom-stack/59e4d2d0-2fe2-10ec-b00e-124d7c1c5f15\",\n  \"RequestId\": \"7cae0346-0359-4dff-b80a-a82f247467b6\",\n  \"LogicalResourceId:\": \"ChimeTriggerResource\",\n  \"PhysicalResourceId:\": \"my-app-name-db4a47b9-0cac-45ba-8cc4-a480490c5779\",\n  \"NoEcho\": false,\n  \"Data\": {\n    \"ChimeAppInstanceArn\": \"arn:aws:chime:us-east-1:123456789000:app-instance/150972c2-5490-49a9-8ba7-e7da4257c16a\"\n  }\n}\n</code></pre> <p>Once the custom resource receives this response, its \"ChimeAppInstanceArn\" attribute is set and the Fn::GetAtt function may be used to retrieve the attribute value and make it available to other resources in the stack.</p>"
        },
        {
            "location": "utilities/custom_resources/#sensitive-response-data",
            "title": "Sensitive Response Data",
            "text": "<p>If any attributes are sensitive, enable the \"noEcho\" flag to mask the output of the custom resource when it's retrieved with the Fn::GetAtt function.</p> <pre><code>public class SensitiveDataHandler extends AbstractResourceHandler {\n    @Override\n    protected Response create(CloudFormationCustomResourceEvent createEvent, Context context) {\n        String physicalResourceId = \"my-sensitive-resource-\" + UUID.randomUUID(); //Create a unique ID \n        return Response.builder()\n                .status(Response.Status.SUCCESS)\n                .physicalResourceId(physicalResourceId)\n                .value(Map.of(\"SomeSecret\", sensitiveValue))\n                .noEcho(true)\n                .build();\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/custom_resources/#customizing-serialization",
            "title": "Customizing Serialization",
            "text": "<p>Although using a <code>Map</code> as the Response's value is the most straightforward way to provide attribute name/value pairs, any arbitrary <code>java.lang.Object</code> may be used. By default, these objects are serialized with an internal Jackson <code>ObjectMapper</code>. If the object requires special serialization logic, a custom <code>ObjectMapper</code> can be specified.</p> <pre><code>public class CustomSerializationHandler extends AbstractResourceHandler {\n    /**\n     * Type representing the custom response Data. \n     */\n    static class Policy {\n        public ZonedDateTime getExpires() {\n            return ZonedDateTime.now().plusDays(10);\n        }\n    }\n\n    /**\n     * Mapper for serializing Policy instances.\n     */\n    private final ObjectMapper policyMapper = new ObjectMapper()\n            .registerModule(new JavaTimeModule())\n            .disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);\n\n    @Override\n    protected Response create(CloudFormationCustomResourceEvent createEvent, Context context) {\n        String physicalResourceId = \"my-policy-name-\" + UUID.randomUUID(); //Create a unique ID \n        Policy policy = new Policy();\n        return Response.builder()\n                .status(Response.Status.SUCCESS)\n                .physicalResourceId(physicalResourceId)\n                .value(policy)\n                .objectMapper(policyMapper) // customize serialization\n                .build();\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/custom_resources/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/custom_resources/#understanding-the-cloudformation-custom-resource-lifecycle",
            "title": "Understanding the CloudFormation custom resource lifecycle",
            "text": "<p>While the library provides an easy-to-use interface, we recommend that you understand the lifecycle of CloudFormation custom resources before using them in production.</p>"
        },
        {
            "location": "utilities/custom_resources/#creating-a-custom-resource",
            "title": "Creating a custom resource",
            "text": "<p>When CloudFormation issues a CREATE on a custom resource, there are 2 possible states: <code>CREATE_COMPLETE</code> and <code>CREATE_FAILED</code> <pre><code>stateDiagram\n    direction LR\n    createState: Create custom resource\n    [*] --&gt; createState\n    createState --&gt; CREATE_COMPLETE \n    createState --&gt; CREATE_FAILED</code></pre></p> <p>If the resource is created successfully, the <code>physicalResourceId</code> is stored by CloudFormation for future operations. If the resource failed to create, CloudFormation triggers a rollback operation by default (rollback can be disabled, see stack failure options)</p>"
        },
        {
            "location": "utilities/custom_resources/#updating-a-custom-resource",
            "title": "Updating a custom resource",
            "text": "<p>CloudFormation issues an UPDATE operation on a custom resource only when one or more custom resource properties change. During the update, the custom resource may update successfully, or may fail the update. <pre><code>stateDiagram\n    direction LR\n    updateState: Update custom resource\n    [*] --&gt; updateState\n    updateState --&gt; UPDATE_COMPLETE \n    updateState --&gt; UPDATE_FAILED</code></pre></p> <p>In both of these scenarios, the custom resource can return the same <code>physicalResourceId</code> it received in the CloudFormation event, or a different <code>physicalResourceId</code>. Semantically an <code>UPDATE_COMPLETE</code> that returns the same <code>physicalResourceId</code> it received indicates that the existing resource was updated successfully. Instead, an <code>UPDATE_COMPLETE</code> with a different <code>physicalResourceId</code> means that a new physical resource was created successfully.  <pre><code>flowchart BT\n    id1(Logical resource)\n    id2(Previous physical Resource)\n    id3(New physical Resource)\n    id2 --&gt; id1 \n    id3 --&gt; id1 </code></pre> Therefore, after the custom resource update completed or failed, there may be other cleanup operations by Cloudformation during the rollback, as described in the diagram below: <pre><code>stateDiagram\n    state if_state &lt;&lt;choice&gt;&gt;\n    updateState: Update custom resource\n    deletePrev: DELETE resource with previous physicalResourceId\n    updatePrev: Rollback - UPDATE resource with previous properties\n    noOp: No further operations\n    [*] --&gt; updateState\n    updateState --&gt; UPDATE_COMPLETE\n    UPDATE_COMPLETE --&gt; if_state\n    if_state --&gt; noOp : Same physicalResourceId\n    if_state --&gt; deletePrev : Different physicalResourceId\n    updateState --&gt; UPDATE_FAILED\n    UPDATE_FAILED --&gt; updatePrev</code></pre></p>"
        },
        {
            "location": "utilities/custom_resources/#deleting-a-custom-resource",
            "title": "Deleting a custom resource",
            "text": "<p>CloudFormation issues a DELETE on a custom resource when: - the CloudFormation stack is being deleted - a new <code>physicalResourceId</code> was received during an update, and CloudFormation proceeds to rollback(DELETE) the custom resource with the previous <code>physicalResourceId</code>.</p> <pre><code>stateDiagram\n    direction LR\n    deleteState: Delete custom resource\n    [*] --&gt; deleteState\n    deleteState --&gt; DELETE_COMPLETE \n    deleteState --&gt; DELETE_FAILED</code></pre>"
        },
        {
            "location": "utilities/idempotency/",
            "title": "Idempotency",
            "text": "<p>The idempotency utility provides a simple solution to convert your Lambda functions into idempotent operations which are safe to retry.</p>"
        },
        {
            "location": "utilities/idempotency/#terminology",
            "title": "Terminology",
            "text": "<p>The property of idempotency means that an operation does not cause additional side effects if it is called more than once with the same input parameters.</p> <p>Idempotent operations will return the same result when they are called multiple times with the same parameters. This makes idempotent operations safe to retry. Read more about idempotency.</p> <p>Idempotency key is a hash representation of either the entire event or a specific configured subset of the event, and invocation results are JSON serialized and stored in your persistence storage layer.</p>"
        },
        {
            "location": "utilities/idempotency/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Prevent Lambda handler function from executing more than once on the same event payload during a time window</li> <li>Ensure Lambda handler returns the same result when called with the same payload</li> <li>Select a subset of the event as the idempotency key using JMESPath expressions</li> <li>Set a time window in which records with the same payload should be considered duplicates</li> </ul>"
        },
        {
            "location": "utilities/idempotency/#getting-started",
            "title": "Getting started",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#installation",
            "title": "Installation",
            "text": "<p>Depending on your version of Java (either Java 1.8 or 11+), the configuration slightly changes.</p> Maven Java 11+Maven Java 1.8Gradle Java 11+Gradle Java 1.8 <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-idempotency&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;dev.aspectj&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.13.1&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;11&lt;/source&gt; &lt;!-- or higher --&gt;\n                 &lt;target&gt;11&lt;/target&gt; &lt;!-- or higher --&gt;\n                 &lt;complianceLevel&gt;11&lt;/complianceLevel&gt; &lt;!-- or higher --&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-idempotency&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-idempotency&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.14.0&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;1.8&lt;/source&gt;\n                 &lt;target&gt;1.8&lt;/target&gt;\n                 &lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-idempotency&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '8.1.0'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-idempotency:1.20.1'\n    }\n\n    sourceCompatibility = 11 // or higher\n    targetCompatibility = 11 // or higher\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '6.6.3'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-idempotency:1.20.1'\n    }\n\n    sourceCompatibility = 1.8\n    targetCompatibility = 1.8\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#required-resources",
            "title": "Required resources",
            "text": "<p>Before getting started, you need to create a persistent storage layer where the idempotency utility can store its state - your Lambda functions will need read and write access to it.</p> <p>As of now, Amazon DynamoDB is the only supported persistent storage layer, so you'll need to create a table first.</p> <p>Default table configuration</p> <p>If you're not changing the default configuration for the DynamoDB persistence layer, this is the expected default configuration:</p> Configuration Value Notes Partition key <code>id</code> TTL attribute name <code>expiration</code> This can only be configured after your table is created if you're using AWS Console <p>Tip: You can share a single state table for all functions</p> <p>You can reuse the same DynamoDB table to store idempotency state. We add your function name in addition to the idempotency key as a hash key.</p> AWS Serverless Application Model (SAM) example<pre><code>Resources:\n  IdempotencyTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      AttributeDefinitions:\n        - AttributeName: id\n          AttributeType: S\n      KeySchema:\n        - AttributeName: id\n          KeyType: HASH\n      TimeToLiveSpecification:\n        AttributeName: expiration\n        Enabled: true\n      BillingMode: PAY_PER_REQUEST\n\n  IdempotencyFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: Function\n      Handler: helloworld.App::handleRequest\n      Policies:\n        - DynamoDBCrudPolicy:\n            TableName: !Ref IdempotencyTable\n      Environment:\n        Variables:\n          IDEMPOTENCY_TABLE: !Ref IdempotencyTable\n</code></pre> <p>Warning: Large responses with DynamoDB persistence layer</p> <p>When using this utility with DynamoDB, your function's responses must be smaller than 400KB. Larger items cannot be written to DynamoDB and will cause exceptions.</p> <p>Info: DynamoDB</p> <p>Each function invocation will generally make 2 requests to DynamoDB. If the result returned by your Lambda is less than 1kb, you can expect 2 WCUs per invocation. For retried invocations, you will see 1WCU and 1RCU. Review the DynamoDB pricing documentation to estimate the cost.</p>"
        },
        {
            "location": "utilities/idempotency/#idempotent-annotation",
            "title": "Idempotent annotation",
            "text": "<p>You can quickly start by initializing the <code>DynamoDBPersistenceStore</code> and using it with the <code>@Idempotent</code> annotation on your Lambda handler.</p> <p>Important</p> <p>Initialization and configuration of the <code>DynamoDBPersistenceStore</code> must be performed outside the handler, preferably in the constructor.</p> App.javaExample event <pre><code>public class App implements RequestHandler&lt;Subscription, SubscriptionResult&gt; {\n\n  public App() {\n    // we need to initialize idempotency store before the handleRequest method is called\n    Idempotency.config().withPersistenceStore(\n      DynamoDBPersistenceStore.builder()\n        .withTableName(System.getenv(\"TABLE_NAME\"))\n        .build()\n      ).configure();\n  }\n\n  @Idempotent\n  public SubscriptionResult handleRequest(final Subscription event, final Context context) {\n    SubscriptionPayment payment = createSubscriptionPayment(\n      event.getUsername(),\n      event.getProductId()\n    );\n\n    return new SubscriptionResult(payment.getId(), \"success\", 200);\n  }\n}\n</code></pre> <pre><code>{\n  \"username\": \"xyz\",\n  \"product_id\": \"123456789\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#idempotent-annotation-on-another-method",
            "title": "Idempotent annotation on another method",
            "text": "<p>You can use the <code>@Idempotent</code> annotation for any synchronous Java function, not only the <code>handleRequest</code> one.</p> <p>When using <code>@Idempotent</code> annotation on another method, you must tell which parameter in the method signature has the data we should use:</p> <ul> <li>If the method only has one parameter, it will be used by default. </li> <li>If there are 2 or more parameters, you must set the <code>@IdempotencyKey</code> on the parameter to use.</li> </ul> <p>The parameter must be serializable in JSON. We use Jackson internally to (de)serialize objects</p> AppSqsEvent.javaBatch event <p>This example also demonstrates how you can integrate with Batch utility, so you can process each record in an idempotent manner.</p> <pre><code>public class AppSqsEvent implements RequestHandler&lt;SQSEvent, String&gt; {\n\n  public AppSqsEvent() {\n    Idempotency.config()\n      .withPersistenceStore(\n          DynamoDBPersistenceStore.builder()\n            .withTableName(System.getenv(\"TABLE_NAME\"))\n            .build()\n      ).withConfig(\n           IdempotencyConfig.builder()\n             .withEventKeyJMESPath(\"messageId\") // see Choosing a payload subset section\n             .build()\n      ).configure();\n    }\n\n  @Override\n  @SqsBatch(SampleMessageHandler.class)\n  public String handleRequest(SQSEvent input, Context context) {\n    dummy(\"hello\", \"world\");\n    return \"{\\\"statusCode\\\": 200}\";\n  }\n\n  @Idempotent\n  private String dummy(String argOne, @IdempotencyKey String argTwo) {\n    return \"something\";\n  }\n\n  public static class SampleMessageHandler implements SqsMessageHandler&lt;Object&gt; {\n    @Override\n    @Idempotent\n    // no need to use @IdempotencyKey as there is only one parameter\n    public String process(SQSMessage message) {\n      String returnVal = doSomething(message.getBody());\n      return returnVal;\n    }\n  }\n}\n</code></pre> <pre><code>{\n    \"Records\": [\n        {\n            \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n            \"body\": \"Test message.\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {\n                \"testAttr\": {\n                \"stringValue\": \"100\",\n                \"binaryValue\": \"base64Str\",\n                \"dataType\": \"Number\"\n                }\n            },\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:my-queue\",\n            \"awsRegion\": \"us-east-2\"\n        }\n    ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#choosing-a-payload-subset-for-idempotency",
            "title": "Choosing a payload subset for idempotency",
            "text": "<p>Tip: Dealing with always changing payloads</p> <p>When dealing with an elaborate payload (API Gateway request for example), where parts of the payload always change, you should configure the <code>EventKeyJMESPath</code>.</p> <p>Use <code>IdempotencyConfig</code> to instruct the Idempotent annotation to only use a portion of your payload to verify whether a request is idempotent, and therefore it should not be retried.</p> <p>Payment scenario</p> <p>In this example, we have a Lambda handler that creates a payment for a user subscribing to a product. We want to ensure that we don't accidentally charge our customer by subscribing them more than once.</p> <p>Imagine the function executes successfully, but the client never receives the response due to a connection issue. It is safe to retry in this instance, as the idempotent decorator will return a previously saved response.</p> <p>Warning: Idempotency for JSON payloads</p> <p>The payload extracted by the <code>EventKeyJMESPath</code> is treated as a string by default, so will be sensitive to differences in whitespace even when the JSON payload itself is identical.</p> <p>To alter this behaviour, you can use the JMESPath built-in function <code>powertools_json()</code> to treat the payload as a JSON object rather than a string.</p> PaymentFunction.javaExample event <pre><code>public class PaymentFunction implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n  public PaymentFunction() {\n    Idempotency.config()\n    .withConfig(\n        IdempotencyConfig.builder()\n          .withEventKeyJMESPath(\"powertools_json(body)\")\n          .build())\n    .withPersistenceStore(\n        DynamoDBPersistenceStore.builder()\n          .withTableName(System.getenv(\"TABLE_NAME\"))\n          .build())\n    .configure();\n}\n\n@Idempotent\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent event, final Context context) {\n  APIGatewayProxyResponseEvent response = new APIGatewayProxyResponseEvent();\n\n  try {\n    Subscription subscription = JsonConfig.get().getObjectMapper().readValue(event.getBody(), Subscription.class);\n\n    SubscriptionPayment payment = createSubscriptionPayment(\n         subscription.getUsername(),\n         subscription.getProductId()\n    );\n\n    return response\n             .withStatusCode(200)\n             .withBody(String.format(\"{\\\"paymentId\\\":\\\"%s\\\"}\", payment.getId()));\n\n  } catch (JsonProcessingException e) {\n    return response.withStatusCode(500);\n  }\n}\n</code></pre> <pre><code>{\n  \"version\":\"2.0\",\n  \"body\":\"{\\\"username\\\":\\\"xyz\\\",\\\"productId\\\":\\\"123456789\\\"}\",\n  \"routeKey\":\"ANY /createpayment\",\n  \"rawPath\":\"/createpayment\",\n  \"rawQueryString\":\"\",\n  \"headers\": {\n    \"Header1\": \"value1\",\n    \"Header2\": \"value2\"\n  },\n  \"requestContext\":{\n    \"accountId\":\"123456789012\",\n    \"apiId\":\"api-id\",\n    \"domainName\":\"id.execute-api.us-east-1.amazonaws.com\",\n    \"domainPrefix\":\"id\",\n    \"http\":{\n      \"method\":\"POST\",\n      \"path\":\"/createpayment\",\n      \"protocol\":\"HTTP/1.1\",\n      \"sourceIp\":\"ip\",\n      \"userAgent\":\"agent\"\n    },\n    \"requestId\":\"id\",\n    \"routeKey\":\"ANY /createpayment\",\n    \"stage\":\"$default\",\n    \"time\":\"10/Feb/2021:13:40:43 +0000\",\n    \"timeEpoch\":1612964443723\n  },\n  \"isBase64Encoded\":false\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#idempotency-request-flow",
            "title": "Idempotency request flow",
            "text": "<p>This sequence diagram shows an example flow of what happens in the payment scenario:</p> <p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set (id=event.search(payload))\n        activate Persistence Layer\n        Note right of Persistence Layer: Locked to prevent concurrent&lt;br/&gt;invocations with &lt;br/&gt; the same payload.\n        Lambda--&gt;&gt;Lambda: Call handler (event)\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record with result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set (id=event.search(payload))\n        Persistence Layer--&gt;&gt;Lambda: Already exists in persistence layer. Return result\n        Lambda--&gt;&gt;Client: Response sent to client\n    end</code></pre> Idempotent sequence </p> <p>The client was successful in receiving the result after the retry. Since the Lambda handler was only executed once, our customer hasn't been charged twice.</p> <p>Note</p> <p>Bear in mind that the entire Lambda handler is treated as a single idempotent operation. If your Lambda handler can cause multiple side effects, consider splitting it into separate functions.</p>"
        },
        {
            "location": "utilities/idempotency/#lambda-timeouts",
            "title": "Lambda timeouts",
            "text": "<p>This is automatically done when you annotate your Lambda handler with @Idempotent annotation.</p> <p>To prevent against extended failed retries when a Lambda function times out, Powertools for AWS Lambda (Java) calculates and includes the remaining invocation available time as part of the idempotency record.</p> <p>Example</p> <p>If a second invocation happens after this timestamp, and the record is marked as <code>INPROGRESS</code>, we will execute the invocation again as if it was in the <code>EXPIRED</code> state. This means that if an invocation expired during execution, it will be quickly executed again on the next retry.</p> <p>Important</p> <p>If you are using the @Idempotent annotation on another method to guard isolated parts of your code, you must use <code>registerLambdaContext</code> method available in the <code>Idempotency</code> object to benefit from this protection.</p> <p>Here is an example on how you register the Lambda context in your handler:</p> Registering the Lambda context<pre><code>public class PaymentHandler implements RequestHandler&lt;SQSEvent, List&lt;String&gt;&gt; {\n\n    public PaymentHandler() {\n        Idempotency.config()\n                .withPersistenceStore(\n                        DynamoDBPersistenceStore.builder()\n                                .withTableName(System.getenv(\"IDEMPOTENCY_TABLE\"))\n                                .build())\n                .configure();\n    }\n\n    @Override\n    public List&lt;String&gt; handleRequest(SQSEvent sqsEvent, Context context) {\n        Idempotency.registerLambdaContext(context);\n        return sqsEvent.getRecords().stream().map(record -&gt; process(record.getMessageId(), record.getBody())).collect(Collectors.toList());\n    }\n\n    @Idempotent\n    private String process(String messageId, @IdempotencyKey String messageBody) {\n        logger.info(\"Processing messageId: {}\", messageId);\n        PaymentRequest request = extractDataFrom(messageBody).as(PaymentRequest.class);\n        return paymentService.process(request);\n    }\n\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#lambda-timeout-sequence-diagram",
            "title": "Lambda timeout sequence diagram",
            "text": "<p>This sequence diagram shows an example flow of what happens if a Lambda function times out:</p> <p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set (id=event.search(payload))\n        activate Persistence Layer\n        Note right of Persistence Layer: Locked to prevent concurrent&lt;br/&gt;invocations with &lt;br/&gt; the same payload.\n        Note over Lambda: Time out\n        Lambda--xLambda: Call handler (event)\n        Lambda--&gt;&gt;Client: Return error response\n        deactivate Persistence Layer\n    else concurrent request before timeout\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set (id=event.search(payload))\n        Persistence Layer--&gt;&gt;Lambda: Request already INPROGRESS\n        Lambda--xClient: Return IdempotencyAlreadyInProgressError\n    else retry after Lambda timeout\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set (id=event.search(payload))\n        activate Persistence Layer\n        Note right of Persistence Layer: Locked to prevent concurrent&lt;br/&gt;invocations with &lt;br/&gt; the same payload.\n        Lambda--&gt;&gt;Lambda: Call handler (event)\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record with result\n        Lambda--&gt;&gt;Client: Response sent to client\n    end</code></pre> Idempotent sequence for Lambda timeouts </p>"
        },
        {
            "location": "utilities/idempotency/#handling-exceptions",
            "title": "Handling exceptions",
            "text": "<p>If you are using the <code>@Idempotent</code> annotation on your Lambda handler or any other method, any unhandled exceptions that are thrown during the code execution will cause the record in the persistence layer to be deleted. This means that new invocations will execute your code again despite having the same payload. If you don't want the record to be deleted, you need to catch exceptions within the idempotent function and return a successful response.</p> <p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;Persistence Layer: Get or set (id=event.search(payload))\n    activate Persistence Layer\n    Note right of Persistence Layer: Locked during this time. Prevents multiple&lt;br/&gt;Lambda invocations with the same&lt;br/&gt;payload running concurrently.\n    Lambda--xLambda: Call handler (event).&lt;br/&gt;Raises exception\n    Lambda-&gt;&gt;Persistence Layer: Delete record (id=event.search(payload))\n    deactivate Persistence Layer\n    Lambda--&gt;&gt;Client: Return error response</code></pre> Idempotent sequence exception </p> <p>If an Exception is raised outside the scope of a decorated method and after your method has been called, the persistent record will not be affected. In this case, idempotency will be maintained for your decorated function. Example:</p> Exception not affecting idempotency record sample<pre><code>  public SubscriptionResult handleRequest(final Subscription event, final Context context) {\n    // If an exception is thrown here, no idempotent record will ever get created as the\n    // idempotent function does not get called \n    doSomeStuff();\n\n    result = idempotentMethod(event);\n\n    // This exception will not cause the idempotent record to be deleted, since it\n    // happens after the decorated function has been successfully called    \n    throw new Exception();\n  }\n\n  @Idempotent\n  private String idempotentMethod(final Subscription subscription) {\n    // perform some operation with no exception thrown\n  }\n</code></pre> <p>Warning</p> <p>We will throw an <code>IdempotencyPersistenceLayerException</code> if any of the calls to the persistence layer fail unexpectedly.</p> <p>As this happens outside the scope of your decorated function, you are not able to catch it.</p>"
        },
        {
            "location": "utilities/idempotency/#persistence-stores",
            "title": "Persistence stores",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#dynamodbpersistencestore",
            "title": "DynamoDBPersistenceStore",
            "text": "<p>This persistence store is built-in, and you can either use an existing DynamoDB table or create a new one dedicated for idempotency state (recommended).</p> <p>Use the builder to customize the table structure: Customizing DynamoDBPersistenceStore to suit your table structure<pre><code>DynamoDBPersistenceStore.builder()\n                        .withTableName(System.getenv(\"TABLE_NAME\"))\n                        .withKeyAttr(\"idempotency_key\")\n                        .withExpiryAttr(\"expires_at\")\n                        .withStatusAttr(\"current_status\")\n                        .withDataAttr(\"result_data\")\n                        .withValidationAttr(\"validation_key\")\n                        .build()\n</code></pre></p> <p>When using DynamoDB as a persistence layer, you can alter the attribute names by passing these parameters when initializing the persistence layer:</p> Parameter Required Default Description TableName Y Table name to store state KeyAttr <code>id</code> Partition key of the table. Hashed representation of the payload (unless SortKeyAttr is specified) ExpiryAttr <code>expiration</code> Unix timestamp of when record expires StatusAttr <code>status</code> Stores status of the Lambda execution during and after invocation DataAttr <code>data</code> Stores results of successfully idempotent methods ValidationAttr <code>validation</code> Hashed representation of the parts of the event used for validation SortKeyAttr Sort key of the table (if table is configured with a sort key). StaticPkValue <code>idempotency#{LAMBDA_FUNCTION_NAME}</code> Static value to use as the partition key. Only used when SortKeyAttr is set."
        },
        {
            "location": "utilities/idempotency/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#customizing-the-default-behavior",
            "title": "Customizing the default behavior",
            "text": "<p>Idempotency behavior can be further configured with <code>IdempotencyConfig</code> using a builder:</p> Customizing IdempotencyConfig<pre><code>IdempotencyConfig.builder()\n                .withEventKeyJMESPath(\"id\")\n                .withPayloadValidationJMESPath(\"paymentId\")\n                .withThrowOnNoIdempotencyKey(true)\n                .withExpiration(Duration.of(5, ChronoUnit.MINUTES))\n                .withUseLocalCache(true)\n                .withLocalCacheMaxItems(432)\n                .withHashFunction(\"SHA-256\")\n                .build()\n</code></pre> <p>These are the available options for further configuration:</p> Parameter Default Description EventKeyJMESPath <code>\"\"</code> JMESPath expression to extract the idempotency key from the event record. See available built-in functions PayloadValidationJMESPath <code>\"\"</code> JMESPath expression to validate whether certain parameters have changed in the event ThrowOnNoIdempotencyKey <code>False</code> Throw exception if no idempotency key was found in the request ExpirationInSeconds 3600 The number of seconds to wait before a record is expired UseLocalCache <code>false</code> Whether to locally cache idempotency results (LRU cache) LocalCacheMaxItems 256 Max number of items to store in local cache HashFunction <code>MD5</code> Algorithm to use for calculating hashes, as supported by <code>java.security.MessageDigest</code> (eg. SHA-1, SHA-256, ...) <p>These features are detailed below.</p>"
        },
        {
            "location": "utilities/idempotency/#handling-concurrent-executions-with-the-same-payload",
            "title": "Handling concurrent executions with the same payload",
            "text": "<p>This utility will throw an <code>IdempotencyAlreadyInProgressException</code> if we receive multiple invocations with the same payload while the first invocation hasn't completed yet.</p> <p>Info</p> <p>If you receive <code>IdempotencyAlreadyInProgressException</code>, you can safely retry the operation.</p> <p>This is a locking mechanism for correctness. Since we don't know the result from the first invocation yet, we can't safely allow another concurrent execution.</p>"
        },
        {
            "location": "utilities/idempotency/#using-in-memory-cache",
            "title": "Using in-memory cache",
            "text": "<p>By default, in-memory local caching is disabled, to avoid using memory in an unpredictable way. </p> <p>Warning</p> <p>Be sure to configure the Lambda memory according to the number of records and the potential size of each record.</p> <p>You can enable it as seen before with: Enable local cache<pre><code>    IdempotencyConfig.builder()\n        .withUseLocalCache(true)\n        .build()\n</code></pre> When enabled, we cache a maximum of 256 records in each Lambda execution environment - You can change it with the <code>LocalCacheMaxItems</code> parameter.</p> <p>Note: This in-memory cache is local to each Lambda execution environment</p> <p>This means it will be effective in cases where your function's concurrency is low in comparison to the number of \"retry\" invocations with the same payload, because cache might be empty.</p>"
        },
        {
            "location": "utilities/idempotency/#expiring-idempotency-records",
            "title": "Expiring idempotency records",
            "text": "<p>Note</p> <p>By default, we expire idempotency records after an hour (3600 seconds).</p> <p>In most cases, it is not desirable to store the idempotency records forever. Rather, you want to guarantee that the same payload won't be executed within a period of time.</p> <p>You can change this window with the <code>ExpirationInSeconds</code> parameter: Customizing expiration time<pre><code>IdempotencyConfig.builder()\n    .withExpiration(Duration.of(5, ChronoUnit.MINUTES))\n    .build()\n</code></pre></p> <p>Records older than 5 minutes will be marked as expired, and the Lambda handler will be executed normally even if it is invoked with a matching payload.</p> <p>Note: DynamoDB time-to-live field</p> <p>This utility uses <code>expiration</code> as the TTL field in DynamoDB, as demonstrated in the SAM example earlier.</p>"
        },
        {
            "location": "utilities/idempotency/#payload-validation",
            "title": "Payload validation",
            "text": "<p>Question: What if your function is invoked with the same payload except some outer parameters have changed?</p> <p>Example: A payment transaction for a given productID was requested twice for the same customer, however the amount to be paid has changed in the second transaction.</p> <p>By default, we will return the same result as it returned before, however in this instance it may be misleading; we provide a fail fast payload validation to address this edge case.</p> <p>With <code>PayloadValidationJMESPath</code>, you can provide an additional JMESPath expression to specify which part of the event body should be validated against previous idempotent invocations</p> App.javaExample Event 1Example Event 2 <pre><code>public App() {\n  Idempotency.config()\n    .withPersistenceStore(DynamoDBPersistenceStore.builder()\n        .withTableName(System.getenv(\"TABLE_NAME\"))\n        .build())\n    .withConfig(IdempotencyConfig.builder()\n        .withEventKeyJMESPath(\"[userDetail, productId]\")\n        .withPayloadValidationJMESPath(\"amount\")\n        .build())\n    .configure();\n}\n\n@Idempotent\npublic SubscriptionResult handleRequest(final Subscription input, final Context context) {\n    // Creating a subscription payment is a side\n    // effect of calling this function!\n    SubscriptionPayment payment = createSubscriptionPayment(\n      input.getUserDetail().getUsername(),\n      input.getProductId(),\n      input.getAmount()\n    )\n    // ...\n    return new SubscriptionResult(\n        \"success\", 200,\n        payment.getId(),\n        payment.getAmount()\n    );\n}\n</code></pre> <pre><code>{\n    \"userDetail\": {\n        \"username\": \"User1\",\n        \"user_email\": \"user@example.com\"\n    },\n    \"productId\": 1500,\n    \"charge_type\": \"subscription\",\n    \"amount\": 500\n}\n</code></pre> <pre><code>{\n    \"userDetail\": {\n        \"username\": \"User1\",\n        \"user_email\": \"user@example.com\"\n    },\n    \"productId\": 1500,\n    \"charge_type\": \"subscription\",\n    \"amount\": 1\n}\n</code></pre> <p>In this example, the <code>userDetail</code> and <code>productId</code> keys are used as the payload to generate the idempotency key, as per <code>EventKeyJMESPath</code> parameter.</p> <p>Note</p> <p>If we try to send the same request but with a different amount, we will raise <code>IdempotencyValidationException</code>.</p> <p>Without payload validation, we would have returned the same result as we did for the initial request. Since we're also returning an amount in the response, this could be quite confusing for the client.</p> <p>By using <code>withPayloadValidationJMESPath(\"amount\")</code>, we prevent this potentially confusing behavior and instead throw an Exception.</p>"
        },
        {
            "location": "utilities/idempotency/#making-idempotency-key-required",
            "title": "Making idempotency key required",
            "text": "<p>If you want to enforce that an idempotency key is required, you can set <code>ThrowOnNoIdempotencyKey</code> to <code>true</code>.</p> <p>This means that we will throw <code>IdempotencyKeyException</code> if the evaluation of <code>EventKeyJMESPath</code> is <code>null</code>.</p> <p>When set to <code>false</code> (the default), if the idempotency key is null, then the data is not persisted in the store.</p> App.javaSuccess EventFailure Event <pre><code>public App() {\n  Idempotency.config()\n    .withPersistenceStore(DynamoDBPersistenceStore.builder()\n        .withTableName(System.getenv(\"TABLE_NAME\"))\n        .build())\n    .withConfig(IdempotencyConfig.builder()\n        // Requires \"user\".\"uid\" and \"orderId\" to be present\n        .withEventKeyJMESPath(\"[user.uid, orderId]\")\n        .withThrowOnNoIdempotencyKey(true)\n        .build())\n    .configure();\n}\n\n@Idempotent\npublic OrderResult handleRequest(final Order input, final Context context) {\n  // ...\n}\n</code></pre> <pre><code>{\n    \"user\": {\n        \"uid\": \"BB0D045C-8878-40C8-889E-38B3CB0A61B1\",\n        \"name\": \"Foo\"\n    },\n    \"orderId\": 10000\n}\n</code></pre> <p>Notice that <code>orderId</code> is now accidentally within <code>user</code> key</p> <pre><code>{\n    \"user\": {\n        \"uid\": \"DE0D000E-1234-10D1-991E-EAC1DD1D52C8\",\n        \"name\": \"Joe Bloggs\",\n        \"orderId\": 10000\n    },\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#customizing-dynamodb-configuration",
            "title": "Customizing DynamoDB configuration",
            "text": "<p>When creating the <code>DynamoDBPersistenceStore</code>, you can set a custom <code>DynamoDbClient</code> if you need to customize the configuration:</p> Custom DynamoDbClient with X-Ray interceptor <pre><code>public App() {\n    DynamoDbClient customClient = DynamoDbClient.builder()\n        .region(Region.US_WEST_2)\n        .overrideConfiguration(ClientOverrideConfiguration.builder()\n            .addExecutionInterceptor(new TracingInterceptor())\n            .build()\n        )\n        .build();\n\n    Idempotency.config().withPersistenceStore(\n      DynamoDBPersistenceStore.builder()\n            .withTableName(System.getenv(\"TABLE_NAME\"))\n            .withDynamoDbClient(customClient)\n            .build()\n  ).configure();\n}\n</code></pre> <p>Default configuration is the following:</p> <pre><code>DynamoDbClient.builder()\n    .credentialsProvider(EnvironmentVariableCredentialsProvider.create())\n    .httpClient(UrlConnectionHttpClient.builder().build())\n    .region(Region.of(System.getenv(AWS_REGION_ENV)))\n    .build();\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#using-a-dynamodb-table-with-a-composite-primary-key",
            "title": "Using a DynamoDB table with a composite primary key",
            "text": "<p>When using a composite primary key table (hash+range key), use <code>SortKeyAttr</code> parameter when initializing your persistence store.</p> <p>With this setting, we will save the idempotency key in the sort key instead of the primary key. By default, the primary key will now be set to <code>idempotency#{LAMBDA_FUNCTION_NAME}</code>.</p> <p>You can optionally set a static value for the partition key using the <code>StaticPkValue</code> parameter.</p> Reusing a DynamoDB table that uses a composite primary key<pre><code>Idempotency.config().withPersistenceStore(\n     DynamoDBPersistenceStore.builder()\n       .withTableName(System.getenv(\"TABLE_NAME\"))\n       .withSortKeyAttr(\"sort_key\")\n       .build())\n   .configure();\n</code></pre> <p>Data would then be stored in DynamoDB like this:</p> id sort_key expiration status data idempotency#MyLambdaFunction 1e956ef7da78d0cb890be999aecc0c9e 1636549553 COMPLETED {\"id\": 12391, \"message\": \"success\"} idempotency#MyLambdaFunction 2b2cdb5f86361e97b4383087c1ffdf27 1636549571 COMPLETED {\"id\": 527212, \"message\": \"success\"} idempotency#MyLambdaFunction f091d2527ad1c78f05d54cc3f363be80 1636549585 IN_PROGRESS"
        },
        {
            "location": "utilities/idempotency/#bring-your-own-persistent-store",
            "title": "Bring your own persistent store",
            "text": "<p>This utility provides an abstract base class, so that you can implement your choice of persistent storage layer.</p> <p>You can extend the <code>BasePersistenceStore</code> class and implement the abstract methods <code>getRecord</code>, <code>putRecord</code>, <code>updateRecord</code> and <code>deleteRecord</code>. You can have a look at <code>DynamoDBPersistenceStore</code> as an implementation reference.</p> <p>Danger</p> <p>Pay attention to the documentation for each method - you may need to perform additional checks inside these methods to ensure the idempotency guarantees remain intact.</p> <p>For example, the <code>putRecord</code> method needs to throw an exception if a non-expired record already exists in the data store with a matching key.</p>"
        },
        {
            "location": "utilities/idempotency/#compatibility-with-other-utilities",
            "title": "Compatibility with other utilities",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#validation-utility",
            "title": "Validation utility",
            "text": "<p>The idempotency utility can be used with the <code>@Validation</code> annotation from the validation module. Ensure that idempotency is the innermost annotation.</p> Using Idempotency with JSONSchema Validation utility<pre><code>@Validation(inboundSchema = \"classpath:/schema_in.json\")\n@Idempotent\npublic APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n  // ...\n}\n</code></pre> <p>Tip: JMESPath Powertools for AWS Lambda (Java) functions are also available</p> <p>Built-in functions like <code>powertools_json</code>, <code>powertools_base64</code>, <code>powertools_base64_gzip</code> are also available to use in this utility. See JMESPath Powertools for AWS Lambda (Java) functions</p>"
        },
        {
            "location": "utilities/idempotency/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>The idempotency utility provides several routes to test your code.</p>"
        },
        {
            "location": "utilities/idempotency/#disabling-the-idempotency-utility",
            "title": "Disabling the idempotency utility",
            "text": "<p>When testing your code, you may wish to disable the idempotency logic altogether and focus on testing your business logic. To do this, you can set the environment variable <code>POWERTOOLS_IDEMPOTENCY_DISABLED</code> to true.  If you prefer setting this for specific tests, and are using JUnit 5, you can use junit-pioneer library:</p> MyFunctionTest.java <pre><code>@Test\n@SetEnvironmentVariable(key = Constants.IDEMPOTENCY_DISABLED_ENV, value = \"true\")\npublic void testIdempotencyDisabled_shouldJustRunTheFunction() {\n    MyFunction func = new MyFunction();\n    func.handleRequest(someInput, mockedContext);\n}\n</code></pre> <p>You can also disable the idempotency for all tests using <code>maven-surefire-plugin</code> and adding the environment variable:</p> pom.xml <pre><code>&lt;plugin&gt;\n    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n    &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n    &lt;configuration&gt;\n        &lt;environmentVariables&gt;\n            &lt;POWERTOOLS_IDEMPOTENCY_DISABLED&gt;true&lt;/POWERTOOLS_IDEMPOTENCY_DISABLED&gt;\n        &lt;/environmentVariables&gt;\n    &lt;/configuration&gt;\n&lt;/plugin&gt;\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#testing-with-dynamodb-local",
            "title": "Testing with DynamoDB Local",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#unit-tests",
            "title": "Unit tests",
            "text": "<p>To unit test your function with DynamoDB Local, you can refer to this guide to setup with Maven.</p> pom.xmlAppTest.javaApp.java <pre><code>&lt;dependencies&gt;\n    &lt;!-- maven dependency for DynamoDB local --&gt;\n    &lt;dependency&gt;\n       &lt;groupId&gt;com.amazonaws&lt;/groupId&gt;\n       &lt;artifactId&gt;DynamoDBLocal&lt;/artifactId&gt;\n       &lt;version&gt;[1.12,2.0)&lt;/version&gt;\n        &lt;scope&gt;test&lt;/scope&gt;\n    &lt;/dependency&gt;\n    &lt;!-- Needed when building locally on M1 Mac --&gt;\n    &lt;dependency&gt;\n        &lt;groupId&gt;io.github.ganadist.sqlite4java&lt;/groupId&gt;\n        &lt;artifactId&gt;libsqlite4java-osx-aarch64&lt;/artifactId&gt;\n        &lt;version&gt;1.0.392&lt;/version&gt;\n        &lt;scope&gt;test&lt;/scope&gt;\n        &lt;type&gt;dylib&lt;/type&gt;\n    &lt;/dependency&gt;\n&lt;/dependencies&gt;\n&lt;repositories&gt;\n    &lt;!-- custom repository to get the dependency --&gt;\n    &lt;!-- see https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/DynamoDBLocal.DownloadingAndRunning.html#apache-maven --&gt;\n    &lt;repository&gt;\n       &lt;id&gt;dynamodb-local-oregon&lt;/id&gt;\n       &lt;name&gt;DynamoDB Local Release Repository&lt;/name&gt;\n       &lt;url&gt;https://s3-us-west-2.amazonaws.com/dynamodb-local/release&lt;/url&gt;\n    &lt;/repository&gt;\n&lt;/repositories&gt;\n&lt;plugins&gt;\n    &lt;plugin&gt;\n        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n        &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt;\n        &lt;version&gt;3.0.0-M5&lt;/version&gt;\n        &lt;configuration&gt;\n            &lt;!-- need sqlite native libs --&gt;\n            &lt;systemPropertyVariables&gt;\n                &lt;sqlite4java.library.path&gt;${project.build.directory}/native-libs&lt;/sqlite4java.library.path&gt;\n            &lt;/systemPropertyVariables&gt;\n            &lt;!-- environment variables for the tests --&gt;\n            &lt;environmentVariables&gt;\n                &lt;IDEMPOTENCY_TABLE_NAME&gt;idempotency&lt;/IDEMPOTENCY_TABLE_NAME&gt;\n                &lt;AWS_REGION&gt;eu-central-1&lt;/AWS_REGION&gt;\n            &lt;/environmentVariables&gt;\n        &lt;/configuration&gt;\n    &lt;/plugin&gt;\n    &lt;plugin&gt;\n        &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;\n        &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;\n        &lt;executions&gt;\n            &lt;execution&gt;\n                &lt;id&gt;copy&lt;/id&gt;\n                &lt;phase&gt;test-compile&lt;/phase&gt;\n                &lt;goals&gt;\n                    &lt;goal&gt;copy-dependencies&lt;/goal&gt;\n                &lt;/goals&gt;\n                &lt;configuration&gt;\n                    &lt;includeScope&gt;test&lt;/includeScope&gt;\n                    &lt;includeTypes&gt;so,dll,dylib&lt;/includeTypes&gt;\n                    &lt;outputDirectory&gt;${project.build.directory}/native-libs&lt;/outputDirectory&gt;\n                &lt;/configuration&gt;\n            &lt;/execution&gt;\n        &lt;/executions&gt;\n    &lt;/plugin&gt;\n&lt;/plugins&gt;\n</code></pre> <pre><code>public class AppTest {\n    @Mock\n    private Context context;\n    private App app;\n    private static DynamoDbClient client;\n\n    @BeforeAll\n    public static void setupDynamoLocal() {\n        int port = getFreePort();\n\n        // Initialize DynamoDBLocal\n        try {\n            DynamoDBProxyServer dynamoProxy = ServerRunner.createServerFromCommandLineArgs(new String[]{\n                    \"-inMemory\",\n                    \"-port\",\n                    Integer.toString(port)\n            });\n            dynamoProxy.start();\n        } catch (Exception e) {\n            throw new RuntimeException();\n        }\n\n        // Initialize DynamoDBClient\n        client = DynamoDbClient.builder()\n                .httpClient(UrlConnectionHttpClient.builder().build())\n                .region(Region.EU_WEST_1)\n                .endpointOverride(URI.create(\"http://localhost:\" + port))\n                .credentialsProvider(StaticCredentialsProvider.create(\n                        AwsBasicCredentials.create(\"FAKE\", \"FAKE\")))\n                .build();\n\n        // create the table (use same table name as in pom.xml)\n        client.createTable(CreateTableRequest.builder()\n                .tableName(\"idempotency\")\n                .keySchema(KeySchemaElement.builder().keyType(KeyType.HASH).attributeName(\"id\").build())\n                .attributeDefinitions(\n                        AttributeDefinition.builder().attributeName(\"id\").attributeType(ScalarAttributeType.S).build()\n                )\n                .billingMode(BillingMode.PAY_PER_REQUEST)\n                .build());\n    }\n\n    private static int getFreePort() {\n        try {\n            ServerSocket socket = new ServerSocket(0);\n            int port = socket.getLocalPort();\n            socket.close();\n            return port;\n        } catch (IOException ioe) {\n            throw new RuntimeException(ioe);\n        }\n    }\n\n    @BeforeEach\n    void setUp() {\n        MockitoAnnotations.openMocks(this);\n        app = new App(client);\n    }\n\n    @Test\n    public void testApp() {\n        app.handleRequest(..., context);\n        // ... assert\n    }\n}\n</code></pre> <pre><code>public class App implements RequestHandler&lt;Subscription, SubscriptionResult&gt; {\n\npublic App(DynamoDbClient ddbClient) {\n    Idempotency.config().withPersistenceStore(\n            DynamoDBPersistenceStore.builder()\n                    .withTableName(System.getenv(\"IDEMPOTENCY_TABLE_NAME\"))\n                    .withDynamoDbClient(ddbClient)\n                    .build()\n    ).configure();\n}\n\npublic App() {\n    this(null);\n}\n\n@Idempotent\npublic SubscriptionResult handleRequest(final Subscription event, final Context context) {\n    // ...\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#sam-local",
            "title": "SAM Local",
            "text": "App.javashellenv.json <pre><code>public class App implements RequestHandler&lt;Subscription, SubscriptionResult&gt; {\n\n  public App() {\n    DynamoDbClientBuilder ddbBuilder = DynamoDbClient.builder()\n       .credentialsProvider(EnvironmentVariableCredentialsProvider.create())\n       .httpClient(UrlConnectionHttpClient.builder().build());\n\n    if (System.getenv(\"AWS_SAM_LOCAL\") != null) {\n      ddbBuilder.endpointOverride(URI.create(\"http://dynamo:8000\"));\n    } else {\n      ddbBuilder.region(Region.of(System.getenv(\"AWS_REGION\")));\n    }\n\n    Idempotency.config().withPersistenceStore(\n       DynamoDBPersistenceStore.builder()\n          .withTableName(System.getenv(\"IDEMPOTENCY_TABLE_NAME\"))\n          .withDynamoDbClient(ddbBuilder.build())\n          .build()\n    ).configure();\n  }\n\n  @Idempotent\n  public SubscriptionResult handleRequest(final Subscription event, final Context context) {\n    // ...\n  }\n}\n</code></pre> <pre><code># use or create a docker network \ndocker network inspect sam-local || docker network create sam-local\n\n# start dynamodb-local with docker\ndocker run -d --rm -p 8000:8000 \\\n    --network sam-local \\\n    --name dynamo \\\n    amazon/dynamodb-local\n\n# create the idempotency table\naws dynamodb create-table \n    --table-name idempotency \\\n    --attribute-definitions AttributeName=id,AttributeType=S \\\n    --key-schema AttributeName=id,KeyType=HASH \\\n    --billing-mode PAY_PER_REQUEST \\\n    --endpoint-url http://localhost:8000\n\n# invoke the function locally\nsam local invoke IdempotentFunction \\\n    --event event.json \\\n    --env-vars env.json \\\n    --docker-network sam-local\n</code></pre> <pre><code>{\n    \"IdempotentFunction\": {\n        \"IDEMPOTENCY_TABLE_NAME\": \"idempotency\"\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#extra-resources",
            "title": "Extra resources",
            "text": "<p>If you're interested in a deep dive on how Amazon uses idempotency when building our APIs, check out this article.</p>"
        },
        {
            "location": "utilities/large_messages/",
            "title": "Large Messages",
            "text": "<p>The large message utility handles SQS and SNS messages which have had their payloads offloaded to S3 if they are larger than the maximum allowed size (256 KB).</p> <p>Notice</p> <p>The large message utility (available in the <code>powertools-sqs</code> module for versions v1.16.1 and earlier) is now deprecated and replaced by the <code>powertools-large-messages</code> described in this page. You can still get the documentation here and the migration guide here.</p>"
        },
        {
            "location": "utilities/large_messages/#features",
            "title": "Features",
            "text": "<ul> <li>Automatically retrieve the content of S3 objects when SQS or SNS messages have been offloaded to S3.</li> <li>Automatically delete the S3 Objects after processing succeeds.</li> <li>Compatible with the batch module (with SQS).</li> </ul>"
        },
        {
            "location": "utilities/large_messages/#background",
            "title": "Background",
            "text": "<pre><code>stateDiagram-v2\n    direction LR\n    Function : Lambda Function\n\n    state Application {\n        direction TB\n        sendMsg: sendMessage(QueueUrl, MessageBody)\n        extendLib: extended-client-lib\n        [*] --&gt; sendMsg\n        sendMsg --&gt; extendLib\n        state extendLib {\n            state if_big &lt;&lt;choice&gt;&gt;\n            bigMsg: MessageBody &gt; 256KB ?\n            putObject: putObject(S3Bucket, S3Key, Body)\n            updateMsg: Update MessageBody&lt;br&gt;with a pointer to S3&lt;br&gt;and add a message attribute\n            bigMsg --&gt; if_big\n            if_big --&gt; [*]: size(body) &lt;= 256kb\n            if_big --&gt; putObject: size(body) &gt; 256kb\n            putObject --&gt; updateMsg\n            updateMsg --&gt; [*]\n        }\n    }\n\n    state Function {\n        direction TB\n        iterateMsgs: Iterate over messages\n        ptLargeMsg: powertools-large-messages\n        [*] --&gt; Handler\n        Handler --&gt; iterateMsgs\n        iterateMsgs --&gt; ptLargeMsg\n        state ptLargeMsg {\n            state if_pointer &lt;&lt;choice&gt;&gt;\n            pointer: Message attribute &lt;br&gt;for large message ?\n            normalMsg: Small message,&lt;br&gt;body left unchanged\n            getObject: getObject(S3Pointer)\n            deleteObject: deleteObject(S3Pointer)\n            updateBody: Update message body&lt;br&gt;with content from S3 object&lt;br&gt;and remove message attribute\n            updateMD5: Update MD5 of the body&lt;br&gt;and attributes (SQS only)\n            yourcode: &lt;b&gt;YOUR CODE HERE!&lt;/b&gt;\n            pointer --&gt; if_pointer\n            if_pointer --&gt; normalMsg : False\n            normalMsg --&gt; [*]\n            if_pointer --&gt; getObject : True\n            getObject --&gt; updateBody\n            updateBody --&gt; updateMD5\n            updateMD5 --&gt; yourcode\n            yourcode --&gt; deleteObject\n            deleteObject --&gt; [*]\n        }\n    }\n\n    [*] --&gt; Application\n    Application --&gt; Function : Lambda Invocation\n    Function --&gt; [*]\n</code></pre> <p>SQS and SNS message payload is limited to 256KB. If you wish to send messages with a larger payload, you can leverage the amazon-sqs-java-extended-client-lib or amazon-sns-java-extended-client-lib which offload the message to Amazon S3. See documentation (SQS / SNS)</p> <p>When offloaded to S3, the message contains a specific message attribute and the payload only contains a pointer to the S3 object (bucket and object key).</p> <p>This utility automatically retrieves messages which have been offloaded to S3 using the extended client libraries. Once a message's payload has been processed successfully, the utility deletes the payload from S3.</p> <p>This utility is compatible with versions 1.1.0+ of amazon-sqs-java-extended-client-lib and 1.0.0+ of amazon-sns-java-extended-client-lib.</p>"
        },
        {
            "location": "utilities/large_messages/#install",
            "title": "Install",
            "text": "<p>Depending on your version of Java (either Java 1.8 or 11+), the configuration slightly changes.</p> Maven Java 11+ <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-large-messages&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n            &lt;groupId&gt;dev.aspectj&lt;/groupId&gt;\n            &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n            &lt;version&gt;1.13.1&lt;/version&gt;\n            &lt;configuration&gt;\n                &lt;source&gt;11&lt;/source&gt; &lt;!-- or higher --&gt;\n                &lt;target&gt;11&lt;/target&gt; &lt;!-- or higher --&gt;\n                &lt;complianceLevel&gt;11&lt;/complianceLevel&gt; &lt;!-- or higher --&gt;\n                &lt;aspectLibraries&gt;\n                    &lt;aspectLibrary&gt;\n                        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                        &lt;artifactId&gt;powertools-large-messages&lt;/artifactId&gt;\n                    &lt;/aspectLibrary&gt;\n                &lt;/aspectLibraries&gt;\n            &lt;/configuration&gt;\n            &lt;executions&gt;\n                &lt;execution&gt;\n                    &lt;goals&gt;\n                        &lt;goal&gt;compile&lt;/goal&gt;\n                    &lt;/goals&gt;\n                &lt;/execution&gt;\n            &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> Maven Java 1.8Gradle Java 11+Gradle Java 1.8 <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-large-messages&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.14.0&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;1.8&lt;/source&gt;\n                 &lt;target&gt;1.8&lt;/target&gt;\n                 &lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-large-messages&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '8.1.0'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-large-messages:1.20.1'\n    }\n\n    sourceCompatibility = 11 // or higher\n    targetCompatibility = 11 // or higher\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '6.6.3'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-large-messages:1.20.1'\n    }\n\n    sourceCompatibility = 1.8\n    targetCompatibility = 1.8\n</code></pre>"
        },
        {
            "location": "utilities/large_messages/#permissions",
            "title": "Permissions",
            "text": "<p>As the utility interacts with Amazon S3, the lambda function must have the following permissions on the S3 bucket used for the large messages offloading:</p> <ul> <li><code>s3:GetObject</code></li> <li><code>s3:DeleteObject</code></li> </ul>"
        },
        {
            "location": "utilities/large_messages/#annotation",
            "title": "Annotation",
            "text": "<p>The annotation <code>@LargeMessage</code> can be used on any method where the first parameter is one of:</p> <ul> <li><code>SQSEvent.SQSMessage</code></li> <li><code>SNSEvent.SNSRecord</code></li> </ul> SQS ExampleSNS Example <pre><code>import software.amazon.lambda.powertools.largemessages.LargeMessage;\n\npublic class SqsMessageHandler implements RequestHandler&lt;SQSEvent, SQSBatchResponse&gt; {\n\n    @Override\n    public SQSBatchResponse handleRequest(SQSEvent event, Context context) {\n        for (SQSMessage message: event.getRecords()) {\n            processRawMessage(message, context);\n        }\n        return SQSBatchResponse.builder().build();\n    }\n\n    @LargeMessage\n    private void processRawMessage(SQSEvent.SQSMessage sqsMessage, Context context) {\n        // sqsMessage.getBody() will contain the content of the S3 object\n    }\n}\n</code></pre> <pre><code>import software.amazon.lambda.powertools.largemessages.LargeMessage;\n\npublic class SnsRecordHandler implements RequestHandler&lt;SNSEvent, String&gt; {\n\n    @Override\n    public String handleRequest(SNSEvent event, Context context) {\n        processSNSRecord(event.records.get(0)); // there are always only one message \n        return \"Hello World\";\n    }\n\n    @LargeMessage\n    private void processSNSRecord(SNSEvent.SNSRecord snsRecord) {\n        // snsRecord.getSNS().getMessage() will contain the content of the S3 object\n    }\n}\n</code></pre> <p>When the Lambda function is invoked with a SQS or SNS event, the utility first checks if the content was offloaded to S3. In the case of a large message, there is a message attribute specifying the size of the offloaded message and the message contains a pointer to the S3 object.</p> <p>If this is the case, the utility will retrieve the object from S3 using the <code>getObject(bucket, key)</code> API, and place the content of the object in the message payload. You can then directly use the content of the message. If there was an error during the S3 download, the function will fail with a <code>LargeMessageProcessingException</code>.</p> <p>After your code is invoked and returns without error, the object is deleted from S3 using the <code>deleteObject(bucket, key)</code> API. You can disable the deletion of S3 objects with the following configuration:</p> Don't delete S3 Objects <pre><code>@LargeMessage(deleteS3Object = false)\nprivate void processRawMessage(SQSEvent.SQSMessage sqsMessage) {\n    // do something with the message\n}\n</code></pre> <p>Use together with batch module</p> <p>This utility works perfectly together with the batch module (<code>powertools-batch</code>), especially for SQS:</p> Combining batch and large message modules<pre><code>public class SqsBatchHandler implements RequestHandler&lt;SQSEvent, SQSBatchResponse&gt; {\n    private final BatchMessageHandler&lt;SQSEvent, SQSBatchResponse&gt; handler;\n\n    public SqsBatchHandler() {\n        handler = new BatchMessageHandlerBuilder()\n                .withSqsBatchHandler()\n                .buildWithRawMessageHandler(this::processMessage);\n    }\n\n    @Override\n    public SQSBatchResponse handleRequest(SQSEvent sqsEvent, Context context) {\n        return handler.processBatch(sqsEvent, context);\n    }\n\n    @LargeMessage\n    private void processMessage(SQSEvent.SQSMessage sqsMessage) {\n        // do something with the message\n    }\n}\n</code></pre> <p>Use together with idempotency module</p> <p>This utility also works together with the idempotency module (<code>powertools-idempotency</code>).  You can add both the <code>@LargeMessage</code> and <code>@Idempotent</code> annotations, in any order, to the same method.  The <code>@Idempotent</code> takes precedence over the <code>@LargeMessage</code> annotation. It means Idempotency module will use the initial raw message (containing the S3 pointer) and not the large message.</p> Combining idempotency and large message modules<pre><code>public class SqsBatchHandler implements RequestHandler&lt;SQSEvent, SQSBatchResponse&gt; {\n\n    public SqsBatchHandler() {\n        Idempotency.config().withConfig(\n                    IdempotencyConfig.builder()\n                            .withEventKeyJMESPath(\"body\") // get the body of the message for the idempotency key\n                            .build())\n            .withPersistenceStore(\n                    DynamoDBPersistenceStore.builder()\n                            .withTableName(System.getenv(\"IDEMPOTENCY_TABLE\"))\n                            .build()\n            ).configure();\n    }\n\n    @Override\n    public SQSBatchResponse handleRequest(SQSEvent sqsEvent, Context context) {\n        for (SQSMessage message: event.getRecords()) {\n            processRawMessage(message, context);\n        }\n        return SQSBatchResponse.builder().build();\n    }\n\n    @Idempotent\n    @LargeMessage\n    private String processRawMessage(@IdempotencyKey SQSEvent.SQSMessage sqsMessage, Context context) {\n        // do something with the message\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/large_messages/#customizing-s3-client-configuration",
            "title": "Customizing S3 client configuration",
            "text": "<p>To interact with S3, the utility creates a default S3 Client :</p> Default S3 Client <pre><code>S3Client client = S3Client.builder()\n                    .httpClient(UrlConnectionHttpClient.builder().build())\n                    .region(Region.of(System.getenv(AWS_REGION_ENV)))\n                    .build();\n</code></pre> <p>If you need to customize this <code>S3Client</code>, you can leverage the <code>LargeMessageConfig</code> singleton:</p> Custom S3 Client <pre><code>import software.amazon.lambda.powertools.largemessages.LargeMessage;\n\npublic class SnsRecordHandler implements RequestHandler&lt;SNSEvent, String&gt; {\n\n    public SnsRecordHandler() {\n        LargeMessageConfig.init().withS3Client(/* put your custom S3Client here */);\n    }\n\n    @Override\n    public String handleRequest(SNSEvent event, Context context) {\n        processSNSRecord(event.records.get(0)); \n        return \"Hello World\";\n    }\n\n    @LargeMessage\n    private void processSNSRecord(SNSEvent.SNSRecord snsRecord) {\n        // snsRecord.getSNS().getMessage() will contain the content of the S3 object\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/large_messages/#migration-from-the-sqs-large-message-utility",
            "title": "Migration from the SQS Large Message utility",
            "text": "<ul> <li>Replace the dependency in maven / gradle: <code>powertools-sqs</code> ==&gt; <code>powertools-large-messages</code></li> <li>Replace the annotation: <code>@SqsLargeMessage</code> ==&gt; <code>@LargeMessage</code> (the new module handles both SQS and SNS)</li> <li>Move the annotation away from the Lambda <code>handleRequest</code> method and put it on a method with <code>SQSEvent.SQSMessage</code>   or <code>SNSEvent.SNSRecord</code> as first parameter.</li> <li>The annotation now handles a single message, contrary to the previous version that was handling the complete batch.   It gives more control, especially when dealing with partial failures with SQS (see the batch module).</li> <li>The new module only provides an annotation, an equivalent to the <code>SqsUtils</code> class is not available anymore in this new version.</li> </ul> <p>Finally, if you are still using the <code>powertools-sqs</code> library for batch processing, consider moving to <code>powertools-batch</code> at the same time to remove the dependency on this library completely; it has been deprecated and will be removed in v2.</p>"
        },
        {
            "location": "utilities/parameters/",
            "title": "Parameters",
            "text": "<p>The parameters utility provides a way to retrieve parameter values from AWS Systems Manager Parameter Store,  AWS Secrets Manager, or Amazon DynamoDB.  It also provides a base class to create your parameter provider implementation.</p> <p>Key features</p> <ul> <li>Retrieve one or multiple parameters from the underlying provider</li> <li>Cache parameter values for a given amount of time (defaults to 5 seconds)</li> <li>Transform parameter values from JSON or base 64 encoded strings</li> </ul>"
        },
        {
            "location": "utilities/parameters/#install",
            "title": "Install",
            "text": "<p>Depending on your version of Java (either Java 1.8 or 11+), the configuration slightly changes.</p> Maven Java 11+Maven Java 1.8Gradle Java 11+Gradle Java 1.8 <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-parameters&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;dev.aspectj&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.13.1&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;11&lt;/source&gt; &lt;!-- or higher --&gt;\n                 &lt;target&gt;11&lt;/target&gt; &lt;!-- or higher --&gt;\n                 &lt;complianceLevel&gt;11&lt;/complianceLevel&gt; &lt;!-- or higher --&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-parameters&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-parameters&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.14.0&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;1.8&lt;/source&gt;\n                 &lt;target&gt;1.8&lt;/target&gt;\n                 &lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-parameters&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '8.1.0'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-parameters:1.20.1'\n    }\n\n    sourceCompatibility = 11 // or higher\n    targetCompatibility = 11 // or higher\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '6.6.3'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-parameters:1.20.1'\n    }\n\n    sourceCompatibility = 1.8\n    targetCompatibility = 1.8\n</code></pre> <p>IAM Permissions</p> <p>This utility requires additional permissions to work as expected. See the table below:</p> Provider Function/Method IAM Permission SSM Parameter Store <code>SSMProvider.get(String)</code> <code>SSMProvider.get(String, Class)</code> <code>ssm:GetParameter</code> SSM Parameter Store <code>SSMProvider.getMultiple(String)</code> <code>ssm:GetParametersByPath</code> Secrets Manager <code>SecretsProvider.get(String)</code> <code>SecretsProvider.get(String, Class)</code> <code>secretsmanager:GetSecretValue</code> DynamoDB <code>DynamoDBProvider.get(String)</code> <code>DynamoDBProvider.getMultiple(string)</code> <code>dynamodb:GetItem</code> <code>dynamoDB:Query</code>"
        },
        {
            "location": "utilities/parameters/#ssm-parameter-store",
            "title": "SSM Parameter Store",
            "text": "<p>You can retrieve a single parameter using SSMProvider.get() and pass the key of the parameter. For multiple parameters, you can use SSMProvider.getMultiple() and pass the path to retrieve them all.</p> <p>Alternatively, you can retrieve an instance of a provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials.</p> SSMProviderSSMProvider with a custom client <pre><code>import software.amazon.lambda.powertools.parameters.SSMProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSSM implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n    // Get an instance of the SSM Provider\n    SSMProvider ssmProvider = ParamManager.getSsmProvider();\n\n    // Retrieve a single parameter\n    String value = ssmProvider.get(\"/my/parameter\");\n\n    // Retrieve multiple parameters from a path prefix\n    // This returns a Map with the parameter name as key\n    Map&lt;String, String&gt; values = ssmProvider.getMultiple(\"/my/path/prefix\");\n\n}\n</code></pre> <pre><code>import software.amazon.lambda.powertools.parameters.SSMProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSSM implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n    SsmClient client = SsmClient.builder().region(Region.EU_CENTRAL_1).build();\n    // Get an instance of the SSM Provider\n    SSMProvider ssmProvider = ParamManager.getSsmProvider(client);\n\n    // Retrieve a single parameter\n    String value = ssmProvider.get(\"/my/parameter\");\n\n    // Retrieve multiple parameters from a path prefix\n    // This returns a Map with the parameter name as key\n    Map&lt;String, String&gt; values = ssmProvider.getMultiple(\"/my/path/prefix\");\n\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#additional-arguments",
            "title": "Additional arguments",
            "text": "<p>The AWS Systems Manager Parameter Store provider supports two additional arguments for the <code>get()</code> and <code>getMultiple()</code> methods:</p> Option Default Description withDecryption() <code>False</code> Will automatically decrypt the parameter. recursive() <code>False</code> For <code>getMultiple()</code> only, will fetch all parameter values recursively based on a path prefix. <p>Example:</p> AppWithSSM.java <pre><code>import software.amazon.lambda.powertools.parameters.SSMProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSSM implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n    // Get an instance of the SSM Provider\n    SSMProvider ssmProvider = ParamManager.getSsmProvider();\n\n    // Retrieve a single parameter and decrypt it\n    String value = ssmProvider.withDecryption().get(\"/my/parameter\");\n\n    // Retrieve multiple parameters recursively from a path prefix\n    Map&lt;String, String&gt; values = ssmProvider.recursive().getMultiple(\"/my/path/prefix\");\n\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#secrets-manager",
            "title": "Secrets Manager",
            "text": "<p>For secrets stored in Secrets Manager, use <code>getSecretsProvider</code>.</p> <p>Alternatively, you can retrieve an instance of a provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials.</p> SecretsProviderSecretsProvider with a custom client <pre><code>import software.amazon.lambda.powertools.parameters.SecretsProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSecrets implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n    // Get an instance of the Secrets Provider\n    SecretsProvider secretsProvider = ParamManager.getSecretsProvider();\n\n    // Retrieve a single secret\n    String value = secretsProvider.get(\"/my/secret\");\n\n}\n</code></pre> <pre><code>import software.amazon.lambda.powertools.parameters.SecretsProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSecrets implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n    SecretsManagerClient client = SecretsManagerClient.builder().region(Region.EU_CENTRAL_1).build();\n    // Get an instance of the Secrets Provider\n    SecretsProvider secretsProvider = ParamManager.getSecretsProvider(client);\n\n    // Retrieve a single secret\n    String value = secretsProvider.get(\"/my/secret\");\n\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#dynamodb",
            "title": "DynamoDB",
            "text": "<p>To get secrets stored in DynamoDB, use <code>getDynamoDbProvider</code>, providing the name of the table that contains the secrets. As with the other providers, an overloaded methods allows you to retrieve  a <code>DynamoDbProvider</code> providing a client if you need to configure it yourself. </p> DynamoDbProviderDynamoDbProvider with a custom client <pre><code>import software.amazon.lambda.powertools.parameters.DynamoDbProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithDynamoDbParameters implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n    // Get an instance of the DynamoDbProvider\n    DynamoDbProvider ddbProvider = ParamManager.getDynamoDbProvider(\"my-parameters-table\");\n\n    // Retrieve a single parameter\n    String value = ddbProvider.get(\"my-key\"); \n} \n</code></pre> <pre><code>import software.amazon.lambda.powertools.parameters.DynamoDbProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\nimport software.amazon.awssdk.services.dynamodb.DynamoDbClient;\nimport software.amazon.awssdk.http.urlconnection.UrlConnectionHttpClient;\nimport software.amazon.awssdk.regions.Region;\n\npublic class AppWithDynamoDbParameters implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n    // Get a DynamoDB Client with an explicit region\n    DynamoDbClient ddbClient = DynamoDbClient.builder()\n            .httpClientBuilder(UrlConnectionHttpClient.builder())\n            .region(Region.EU_CENTRAL_2)\n            .build();\n\n    // Get an instance of the DynamoDbProvider\n    DynamoDbProvider provider = ParamManager.getDynamoDbProvider(ddbClient, \"test-table\");\n\n    // Retrieve a single parameter\n    String value = ddbProvider.get(\"my-key\"); \n} \n</code></pre>"
        },
        {
            "location": "utilities/parameters/#appconfig",
            "title": "AppConfig",
            "text": "<p>To get parameters stored in AppConfig, use <code>getAppConfigProvider</code>, providing the application and environment name to retrieve configuration from. As with the other providers, an overloaded method allows you to retrieve an <code>AppConfigProvider</code> providing a client if you need to configure it yourself.</p> AppConfigProviderAppConfigProvider with a custom client <pre><code>import software.amazon.lambda.powertools.parameters.AppConfigProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWitAppConfigParameters implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n    // Get an instance of the AppConfigProvider\n    AppConfigProvider appConfigProvider = ParamManager.getAppConfigProvider(\"my-environment\", \"my-app\");\n\n    // Retrieve a single parameter\n    String value = appConfigProvider.get(\"my-key\"); \n} \n</code></pre> <pre><code>import software.amazon.lambda.powertools.parameters.AppConfigProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\nimport software.amazon.awssdk.services.appconfigdata.AppConfigDataClient;\nimport software.amazon.awssdk.http.urlconnection.UrlConnectionHttpClient;\nimport software.amazon.awssdk.regions.Region;\n\npublic class AppWithDynamoDbParameters implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n    // Get an AppConfig Client with an explicit region\n    AppConfigDataClient appConfigDataClient = AppConfigDataClient.builder()\n            .httpClientBuilder(UrlConnectionHttpClient.builder())\n            .region(Region.EU_CENTRAL_2)\n            .build();\n\n    // Get an instance of the DynamoDbProvider\n    AppConfigProvider appConfigProvider = ParamManager.getAppConfigProvider(appConfigDataClient, \"my-environment\", \"my-app\");\n\n    // Retrieve a single parameter\n    String value = appConfigProvider.get(\"my-key\"); \n} \n</code></pre>"
        },
        {
            "location": "utilities/parameters/#advanced-configuration",
            "title": "Advanced configuration",
            "text": ""
        },
        {
            "location": "utilities/parameters/#caching",
            "title": "Caching",
            "text": "<p>By default, all parameters and their corresponding values are cached for 5 seconds.</p> <p>You can customize this default value using <code>defaultMaxAge</code>. You can also customize this value for each parameter using  <code>withMaxAge</code>.</p> Provider with default Max ageProvider with age for each param <pre><code>import software.amazon.lambda.powertools.parameters.SecretsProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSecrets implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n    // Get an instance of the Secrets Provider\n    SecretsProvider secretsProvider = ParamManager.getSecretsProvider()\n                                                  .defaultMaxAge(10, ChronoUnit.SECONDS);\n\n    String value = secretsProvider.get(\"/my/secret\");\n\n}\n</code></pre> <pre><code>import software.amazon.lambda.powertools.parameters.SecretsProvider;\nimport software.amazon.lambda.powertools.parameters.ParamManager;\n\npublic class AppWithSecrets implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n    SecretsManagerClient client = SecretsManagerClient.builder().region(Region.EU_CENTRAL_1).build();\n\n    SecretsProvider secretsProvider = ParamManager.getSecretsProvider(client);\n\n    String value = secretsProvider.withMaxAge(10, ChronoUnit.SECONDS).get(\"/my/secret\");\n\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#transform-values",
            "title": "Transform values",
            "text": "<p>Parameter values can be transformed using <code>withTransformation(transformerClass)</code>. Base64 and JSON transformations are provided. For more complex transformation, you need to specify how to deserialize-</p> <p><code>SSMProvider.getMultiple()</code> does not support transformation and will return simple Strings.</p> Base64 TransformationComplex Transformation <pre><code>   String value = provider\n                    .withTransformation(Transformer.base64)\n                    .get(\"/my/parameter/b64\");\n</code></pre> <pre><code>   MyObj object = provider\n                    .withTransformation(Transformer.json)\n                    .get(\"/my/parameter/json\", MyObj.class);\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#write-your-own-transformer",
            "title": "Write your own Transformer",
            "text": "<p>You can write your own transformer, by implementing the <code>Transformer</code> interface and the <code>applyTransformation()</code> method. For example, if you wish to deserialize XML into an object.</p> XmlTransformer.javaUsing XmlTransformer <pre><code>public class XmlTransformer&lt;T&gt; implements Transformer&lt;T&gt; {\n\n    private final XmlMapper mapper = new XmlMapper();\n\n    @Override\n    public T applyTransformation(String value, Class&lt;T&gt; targetClass) throws TransformationException {\n        try {\n            return mapper.readValue(value, targetClass);\n        } catch (IOException e) {\n            throw new TransformationException(e);\n        }\n    }\n}\n</code></pre> <pre><code>    MyObj object = provider\n                        .withTransformation(XmlTransformer.class)\n                        .get(\"/my/parameter/xml\", MyObj.class);\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#fluent-api",
            "title": "Fluent API",
            "text": "<p>To simplify the use of the library, you can chain all method calls before a get.</p> Fluent API call <pre><code>    ssmProvider\n      .defaultMaxAge(10, SECONDS)     // will set 10 seconds as the default cache TTL\n      .withMaxAge(1, MINUTES)         // will set the cache TTL for this value at 1 minute\n      .withTransformation(json)       // json is a static import from Transformer.json\n      .withDecryption()               // enable decryption of the parameter value\n      .get(\"/my/param\", MyObj.class); // finally get the value\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#create-your-own-provider",
            "title": "Create your own provider",
            "text": "<p>You can create your own custom parameter store provider by inheriting the <code>BaseProvider</code> class and implementing the <code>String getValue(String key)</code> method to retrieve data from your underlying store. All transformation and caching logic is handled by the get() methods in the base class.</p> Example implementation using S3 as a custom parameterUsing custom parameter store <pre><code>public class S3Provider extends BaseProvider {\n\n    private final S3Client client;\n    private String bucket;\n\n    S3Provider(CacheManager cacheManager) {\n        this(cacheManager, S3Client.create());\n    }\n\n    S3Provider(CacheManager cacheManager, S3Client client) {\n        super(cacheManager);\n        this.client = client;\n    }\n\n    public S3Provider withBucket(String bucket) {\n        this.bucket = bucket;\n        return this;\n    }\n\n    @Override\n    protected String getValue(String key) {\n        if (bucket == null) {\n            throw new IllegalStateException(\"A bucket must be specified, using withBucket() method\");\n        }\n\n        GetObjectRequest request = GetObjectRequest.builder().bucket(bucket).key(key).build();\n        ResponseBytes&lt;GetObjectResponse&gt; response = client.getObject(request, ResponseTransformer.toBytes());\n        return response.asUtf8String();\n    }\n\n    @Override\n    protected Map&lt;String, String&gt; getMultipleValues(String path) {\n        if (bucket == null) {\n            throw new IllegalStateException(\"A bucket must be specified, using withBucket() method\");\n        }\n\n        ListObjectsV2Request listRequest = ListObjectsV2Request.builder().bucket(bucket).prefix(path).build();\n        List&lt;S3Object&gt; s3Objects = client.listObjectsV2(listRequest).contents();\n\n        Map&lt;String, String&gt; result = new HashMap&lt;&gt;();\n        s3Objects.forEach(s3Object -&gt; {\n            result.put(s3Object.key(), getValue(s3Object.key()));\n        });\n\n        return result;\n    }\n\n    @Override\n    protected void resetToDefaults() {\n        super.resetToDefaults();\n        bucket = null;\n    }\n\n}\n</code></pre> <pre><code>    S3Provider provider = new S3Provider(ParamManager.getCacheManager());\n\n    provider.setTransformationManager(ParamManager.getTransformationManager());\n\n    String value = provider.withBucket(\"myBucket\").get(\"myKey\");\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#annotation",
            "title": "Annotation",
            "text": "<p>You can make use of the annotation <code>@Param</code> to inject a parameter value in a variable.</p> <p>By default, it will use <code>SSMProvider</code> to retrieve the value from AWS System Manager Parameter Store. You could specify a different provider as long as it extends <code>BaseProvider</code> and/or a <code>Transformer</code>.</p> Param AnnotationCustom Provider Usage <pre><code>public class AppWithAnnotation implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    @Param(key = \"/my/parameter/json\")\n    ObjectToDeserialize value;\n\n}\n</code></pre> <pre><code>public class AppWithAnnotation implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    @Param(key = \"/my/parameter/json\" provider = SecretsProvider.class, transformer = JsonTransformer.class)\n    ObjectToDeserialize value;\n\n}\n</code></pre> <p>In this case <code>SecretsProvider</code> will be used to retrieve a raw value that is then transformed into the target Object by using <code>JsonTransformer</code>. To show the convenience of the annotation compare the following two code snippets.</p>"
        },
        {
            "location": "utilities/parameters/#install_1",
            "title": "Install",
            "text": "<p>If you want to use the <code>@Param</code> annotation in your project add configuration to compile-time weave (CTW) the powertools-parameters aspects into your project.</p> MavenGradle <pre><code>&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;dev.aspectj&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.13.1&lt;/version&gt;\n             &lt;configuration&gt;\n                 ...\n                 &lt;aspectLibraries&gt;\n                     ...\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-parameters&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>plugins{\n    id 'java'\n    id 'io.freefair.aspectj.post-compile-weaving' version '6.3.0'\n}\n\nrepositories {\n    mavenCentral()\n}\n\ndependencies {\n    ...\n    aspect 'software.amazon.lambda:powertools-parameters:1.20.1'\n    implementation 'org.aspectj:aspectjrt:1.9.19'\n}\n</code></pre>"
        },
        {
            "location": "utilities/serialization/",
            "title": "Serialization Utilities",
            "text": "<p>This module contains a set of utilities you may use in your Lambda functions, to manipulate JSON.</p>"
        },
        {
            "location": "utilities/serialization/#easy-deserialization",
            "title": "Easy deserialization",
            "text": ""
        },
        {
            "location": "utilities/serialization/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Easily deserialize the main content of an event (for example, the body of an API Gateway event)</li> <li>15+ built-in events (see the list below)</li> </ul>"
        },
        {
            "location": "utilities/serialization/#getting-started",
            "title": "Getting started",
            "text": "MavenGradle <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-serialization&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n</code></pre> <pre><code>implementation 'software.amazon.lambda:powertools-serialization:1.20.1'\n</code></pre>"
        },
        {
            "location": "utilities/serialization/#eventdeserializer",
            "title": "EventDeserializer",
            "text": "<p>The <code>EventDeserializer</code> can be used to extract the main part of an event (body, message, records) and deserialize it from JSON to your desired type.</p> <p>It can handle single elements like the body of an API Gateway event:</p> APIGWHandler.javaProduct.javaevent <pre><code>import static software.amazon.lambda.powertools.utilities.EventDeserializer.extractDataFrom;\n\npublic class APIGWHandler implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    public APIGatewayProxyResponseEvent handleRequest(\n            final APIGatewayProxyRequestEvent event, \n            final Context context) {\n\n        Product product = extractDataFrom(event).as(Product.class);\n\n    }\n</code></pre> <pre><code>public class Product {\n    private long id;\n    private String name;\n    private double price;\n\n    public Product() {\n    }\n\n    public Product(long id, String name, double price) {\n        this.id = id;\n        this.name = name;\n        this.price = price;\n    }\n\n    public long getId() {\n        return id;\n    }\n\n    public void setId(long id) {\n        this.id = id;\n    }\n\n    public String getName() {\n        return name;\n    }\n\n    public void setName(String name) {\n        this.name = name;\n    }\n\n    public double getPrice() {\n        return price;\n    }\n\n    public void setPrice(double price) {\n        this.price = price;\n    }\n}\n</code></pre> <pre><code>{\n    \"body\": \"{\\\"id\\\":1234, \\\"name\\\":\\\"product\\\", \\\"price\\\":42}\",\n    \"resource\": \"/{proxy+}\",\n    \"path\": \"/path/to/resource\",\n    \"httpMethod\": \"POST\",\n    \"isBase64Encoded\": false,\n    \"queryStringParameters\": {\n        \"foo\": \"bar\"\n    },\n    \"pathParameters\": {\n        \"proxy\": \"/path/to/resource\"\n    },\n    \"stageVariables\": {\n        \"baz\": \"qux\"\n    },\n    \"headers\": {\n        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n        \"Accept-Encoding\": \"gzip, deflate, sdch\",\n        \"Accept-Language\": \"en-US,en;q=0.8\",\n        \"Cache-Control\": \"max-age=0\",\n        \"Host\": \"1234567890.execute-api.us-east-1.amazonaws.com\",\n        \"Upgrade-Insecure-Requests\": \"1\",\n        \"User-Agent\": \"Custom User Agent String\",\n        \"Via\": \"1.1 08f323deadbeefa7af34d5feb414ce27.cloudfront.net (CloudFront)\",\n        \"X-Amz-Cf-Id\": \"cDehVQoZnx43VYQb9j2-nvCh-9z396Uhbp027Y2JvkCPNLmGJHqlaA==\",\n        \"X-Forwarded-For\": \"127.0.0.1, 127.0.0.2\",\n        \"X-Forwarded-Port\": \"443\",\n        \"X-Forwarded-Proto\": \"https\"\n    },\n    \"requestContext\": {\n        \"accountId\": \"123456789012\",\n        \"resourceId\": \"123456\",\n        \"stage\": \"prod\",\n        \"requestId\": \"c6af9ac6-7b61-11e6-9a41-93e8deadbeef\",\n        \"requestTime\": \"09/Apr/2015:12:34:56 +0000\",\n        \"requestTimeEpoch\": 1428582896000,\n        \"identity\": {\n        \"cognitoIdentityPoolId\": null,\n        \"accountId\": null,\n        \"cognitoIdentityId\": null,\n        \"caller\": null,\n        \"accessKey\": null,\n        \"sourceIp\": \"127.0.0.1\",\n        \"cognitoAuthenticationType\": null,\n        \"cognitoAuthenticationProvider\": null,\n        \"userArn\": null,\n        \"userAgent\": \"Custom User Agent String\",\n        \"user\": null\n    },\n    \"path\": \"/prod/path/to/resource\",\n    \"resourcePath\": \"/{proxy+}\",\n    \"httpMethod\": \"POST\",\n    \"apiId\": \"1234567890\",\n    \"protocol\": \"HTTP/1.1\"\n    }\n}\n</code></pre> <p>It can also handle a collection of elements like the records of an SQS event:</p> SQSHandler.javaevent <pre><code>import static software.amazon.lambda.powertools.utilities.EventDeserializer.extractDataFrom;\n\npublic class SQSHandler implements RequestHandler&lt;SQSEvent, String&gt; {\n\n    public String handleRequest(\n            final SQSEvent event, \n            final Context context) {\n\n        List&lt;Product&gt; products = extractDataFrom(event).asListOf(Product.class);\n\n    }\n</code></pre> <pre><code>{\n    \"Records\": [\n      {\n        \"messageId\": \"d9144555-9a4f-4ec3-99a0-34ce359b4b54\",\n        \"receiptHandle\": \"13e7f7851d2eaa5c01f208ebadbf1e72==\",\n        \"body\": \"{  \\\"id\\\": 1234,  \\\"name\\\": \\\"product\\\",  \\\"price\\\": 42}\",\n        \"attributes\": {\n            \"ApproximateReceiveCount\": \"1\",\n            \"SentTimestamp\": \"1601975706495\",\n            \"SenderId\": \"AROAIFU437PVZ5L2J53F5\",\n            \"ApproximateFirstReceiveTimestamp\": \"1601975706499\"\n        },\n        \"messageAttributes\": {\n        },\n        \"md5OfBody\": \"13e7f7851d2eaa5c01f208ebadbf1e72\",\n        \"eventSource\": \"aws:sqs\",\n        \"eventSourceARN\": \"arn:aws:sqs:eu-central-1:123456789012:TestLambda\",\n        \"awsRegion\": \"eu-central-1\"\n      },\n      {\n        \"messageId\": \"d9144555-9a4f-4ec3-99a0-34ce359b4b54\",\n        \"receiptHandle\": \"13e7f7851d2eaa5c01f208ebadbf1e72==\",\n        \"body\": \"{  \\\"id\\\": 12345,  \\\"name\\\": \\\"product5\\\",  \\\"price\\\": 45}\",\n        \"attributes\": {\n          \"ApproximateReceiveCount\": \"1\",\n          \"SentTimestamp\": \"1601975706495\",\n          \"SenderId\": \"AROAIFU437PVZ5L2J53F5\",\n          \"ApproximateFirstReceiveTimestamp\": \"1601975706499\"\n        },\n        \"messageAttributes\": {\n\n        },\n        \"md5OfBody\": \"13e7f7851d2eaa5c01f208ebadbf1e72\",\n        \"eventSource\": \"aws:sqs\",\n        \"eventSourceARN\": \"arn:aws:sqs:eu-central-1:123456789012:TestLambda\",\n        \"awsRegion\": \"eu-central-1\"\n      }\n    ]\n}\n</code></pre> <p>Tip</p> <p>In the background, <code>EventDeserializer</code> is using Jackson. The <code>ObjectMapper</code> is configured in <code>JsonConfig</code>. You can customize the configuration of the mapper if needed: <code>JsonConfig.get().getObjectMapper()</code>. Using this feature, you don't need to add Jackson to your project and create another instance of <code>ObjectMapper</code>.</p>"
        },
        {
            "location": "utilities/serialization/#built-in-events",
            "title": "Built-in events",
            "text": "Event Type Path to the content List <code>APIGatewayProxyRequestEvent</code> <code>body</code> <code>APIGatewayV2HTTPEvent</code> <code>body</code> <code>SNSEvent</code> <code>Records[0].Sns.Message</code> <code>SQSEvent</code> <code>Records[*].body</code> x <code>ScheduledEvent</code> <code>detail</code> <code>ApplicationLoadBalancerRequestEvent</code> <code>body</code> <code>CloudWatchLogsEvent</code> <code>powertools_base64_gzip(data)</code> <code>CloudFormationCustomResourceEvent</code> <code>resourceProperties</code> <code>KinesisEvent</code> <code>Records[*].kinesis.powertools_base64(data)</code> x <code>KinesisFirehoseEvent</code> <code>Records[*].powertools_base64(data)</code> x <code>KafkaEvent</code> <code>records[*].values[*].powertools_base64(value)</code> x <code>ActiveMQEvent</code> <code>messages[*].powertools_base64(data)</code> x <code>RabbitMQEvent</code> <code>rmqMessagesByQueue[*].values[*].powertools_base64(data)</code> x <code>KinesisAnalyticsFirehoseInputPreprocessingEvent</code> <code>Records[*].kinesis.powertools_base64(data)</code> x <code>KinesisAnalyticsStreamsInputPreprocessingEvent</code> <code>Records[*].kinesis.powertools_base64(data)</code> x"
        },
        {
            "location": "utilities/serialization/#jmespath-functions",
            "title": "JMESPath functions",
            "text": "<p>Tip</p> <p>JMESPath is a query language for JSON used by AWS CLI and Powertools for AWS Lambda (Java) to get a specific part of a json.</p>"
        },
        {
            "location": "utilities/serialization/#key-features_1",
            "title": "Key features",
            "text": "<ul> <li>Deserialize JSON from JSON strings, base64, and compressed data</li> <li>Use JMESPath to extract and combine data recursively</li> </ul>"
        },
        {
            "location": "utilities/serialization/#getting-started_1",
            "title": "Getting started",
            "text": "<p>You might have events that contain encoded JSON payloads as string, base64, or even in compressed format. It is a common use case to decode and extract them partially or fully as part of your Lambda function invocation.</p> <p>You will generally use this in combination with other Powertools for AWS Lambda (Java) modules (validation and idempotency) where you might need to extract a portion of your data before using them.</p>"
        },
        {
            "location": "utilities/serialization/#built-in-functions",
            "title": "Built-in functions",
            "text": "<p>Powertools for AWS Lambda (Java) provides the following JMESPath Functions to easily deserialize common encoded JSON payloads in Lambda functions:</p>"
        },
        {
            "location": "utilities/serialization/#powertools_json-function",
            "title": "powertools_json function",
            "text": "<p>Use <code>powertools_json</code> function to decode any JSON string anywhere a JMESPath expression is allowed.</p> <p>Below example use this function to load the content from the body of an API Gateway request event as a JSON object and retrieve the id field in it:</p> MyHandler.javaevent <pre><code>public class MyHandler implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n  public MyHandler() {\n    Idempotency.config()\n    .withConfig(\n        IdempotencyConfig.builder()\n          .withEventKeyJMESPath(\"powertools_json(body).id\")\n          .build())\n    .withPersistenceStore(\n        DynamoDBPersistenceStore.builder()\n          .withTableName(System.getenv(\"TABLE_NAME\"))\n          .build())\n    .configure();\n}\n\n@Idempotent\npublic APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent event, final Context context) {\n}\n</code></pre> <pre><code>{\n  \"body\": \"{\\\"message\\\": \\\"Lambda rocks\\\", \\\"id\\\": 43876123454654}\",\n  \"resource\": \"/{proxy+}\",\n  \"path\": \"/path/to/resource\",\n  \"httpMethod\": \"POST\",\n  \"queryStringParameters\": {\n    \"foo\": \"bar\"\n  },\n  \"headers\": {\n    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n    \"Accept-Encoding\": \"gzip, deflate, sdch\",\n    \"Accept-Language\": \"en-US,en;q=0.8\",\n    \"Cache-Control\": \"max-age=0\",\n  },\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"resourceId\": \"123456\",\n    \"stage\": \"prod\",\n    \"requestId\": \"c6af9ac6-7b61-11e6-9a41-93e8deadbeef\",\n    \"requestTime\": \"09/Apr/2015:12:34:56 +0000\",\n    \"requestTimeEpoch\": 1428582896000,\n    \"identity\": {\n      \"cognitoIdentityPoolId\": null,\n      \"accountId\": null,\n      \"cognitoIdentityId\": null,\n      \"caller\": null,\n      \"accessKey\": null,\n      \"sourceIp\": \"127.0.0.1\",\n      \"cognitoAuthenticationType\": null,\n      \"cognitoAuthenticationProvider\": null,\n      \"userArn\": null,\n      \"userAgent\": \"Custom User Agent String\",\n      \"user\": null\n    },\n    \"path\": \"/prod/path/to/resource\",\n    \"resourcePath\": \"/{proxy+}\",\n    \"httpMethod\": \"POST\",\n    \"apiId\": \"1234567890\",\n    \"protocol\": \"HTTP/1.1\"\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/serialization/#powertools_base64-function",
            "title": "powertools_base64 function",
            "text": "<p>Use <code>powertools_base64</code> function to decode any base64 data.</p> <p>Below sample will decode the base64 value within the <code>data</code> key, and decode the JSON string into a valid JSON before we can validate it.</p> MyEventHandler.javaschema.json <pre><code>import software.amazon.lambda.powertools.validation.ValidationUtils;\n\npublic class MyEventHandler implements RequestHandler&lt;MyEvent, String&gt; {\n\n    @Override\n    public String handleRequest(MyEvent myEvent, Context context) {\n        validate(myEvent, \"classpath:/schema.json\", \"powertools_base64(data)\");\n        return \"OK\";\n   }\n}\n</code></pre> <pre><code>{\n\"data\" : \"ewogICJpZCI6IDQzMjQyLAogICJuYW1lIjogIkZvb0JhciBYWSIsCiAgInByaWNlIjogMjU4Cn0=\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/serialization/#powertools_base64_gzip-function",
            "title": "powertools_base64_gzip function",
            "text": "<p>Use <code>powertools_base64_gzip</code> function to decompress and decode base64 data.</p> <p>Below sample will decompress and decode base64 data.</p> MyEventHandler.javaschema.json <pre><code>import software.amazon.lambda.powertools.validation.ValidationUtils;\n\npublic class MyEventHandler implements RequestHandler&lt;MyEvent, String&gt; {\n\n    @Override\n    public String handleRequest(MyEvent myEvent, Context context) {\n        validate(myEvent, \"classpath:/schema.json\", \"powertools_base64_gzip(data)\");\n        return \"OK\";\n   }\n}\n</code></pre> <pre><code>{\n   \"data\" : \"H4sIAAAAAAAA/6vmUlBQykxRslIwMTYyMdIBcfMSc1OBAkpu+flOiUUKEZFKYOGCosxkkLiRqQVXLQDnWo6bOAAAAA==\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/serialization/#bring-your-own-jmespath-function",
            "title": "Bring your own JMESPath function",
            "text": "<p>Warning</p> <p>This should only be used for advanced use cases where you have special formats not covered by the built-in functions. Please open an issue in Github if you need us to add some common functions.</p> <p>Your function must extend <code>io.burt.jmespath.function.BaseFunction</code>, take a String as parameter and return a String. You can read the doc for more information.</p> <p>Below is an example that takes some xml and transform it into json. Once your function is created, you need to add it to powertools.You can then use it to do your validation or in idempotency module.</p> XMLFunction.javaHandler with validation APIHandler with validation annotation <pre><code>public class XMLFunction extends BaseFunction {\n    public Base64Function() {\n        super(\"powertools_xml\", ArgumentConstraints.typeOf(JmesPathType.STRING));\n    }\n\n    @Override\n    protected &lt;T&gt; T callFunction(Adapter&lt;T&gt; runtime, List&lt;FunctionArgument&lt;T&gt;&gt; arguments) {\n        T value = arguments.get(0).value();\n        String xmlString = runtime.toString(value);\n\n        String jsonString =  // ... transform xmlString to json\n\n        return runtime.createString(jsonString);\n    }\n}\n</code></pre> <pre><code>...\nimport software.amazon.lambda.powertools.validation.ValidationConfig;\nimport software.amazon.lambda.powertools.validation.ValidationUtils.validate;\n\nstatic {\n    JsonConfig.get().addFunction(new XMLFunction());\n}\n\npublic class MyXMLEventHandler implements RequestHandler&lt;MyEventWithXML, String&gt; {\n\n    @Override\n    public String handleRequest(MyEventWithXML myEvent, Context context) {\n        validate(myEvent, \"classpath:/schema.json\", \"powertools_xml(path.to.xml_data)\");\n        return \"OK\";\n   }\n}\n</code></pre> <pre><code>...\nimport software.amazon.lambda.powertools.validation.ValidationConfig;\nimport software.amazon.lambda.powertools.validation.Validation;\n\nstatic {\n    JsonConfig.get().addFunction(new XMLFunction());\n}\n\npublic class MyXMLEventHandler implements RequestHandler&lt;MyEventWithXML, String&gt; {\n\n    @Override\n    @Validation(inboundSchema=\"classpath:/schema.json\", envelope=\"powertools_xml(path.to.xml_data)\")\n    public String handleRequest(MyEventWithXML myEvent, Context context) {\n        return \"OK\";\n   }\n}\n</code></pre>"
        },
        {
            "location": "utilities/sqs_batch/",
            "title": "SQS Batch Processing (Deprecated)",
            "text": "<p>Warning</p> <p>The SQS batch module is now deprecated and will be removed in v2 of the library. Use the batch module,  and check out migrating to the batch library for migration instructions.  </p> <p>The SQS batch processing utility provides a way to handle partial failures when processing batches of messages from SQS. The utility handles batch processing for both  standard and  FIFO SQS queues. </p> <p>Key Features</p> <ul> <li>Prevent successfully processed messages from being returned to SQS</li> <li>A simple interface for individually processing messages from a batch</li> </ul> <p>Background</p> <p>When using SQS as a Lambda event source mapping, Lambda functions can be triggered with a batch of messages from SQS.  If your function fails to process any message from the batch, the entire batch returns to your SQS queue, and your  Lambda function will be triggered with the same batch again. With this utility, messages within a batch will be handled individually - only messages that were not successfully processed are returned to the queue.</p> <p>Warning</p> <p>While this utility lowers the chance of processing messages more than once, it is not guaranteed. We recommend implementing processing logic in an idempotent manner wherever possible. More details on how Lambda works with SQS can be found in the AWS documentation</p>"
        },
        {
            "location": "utilities/sqs_batch/#install",
            "title": "Install",
            "text": "<p>Depending on your version of Java (either Java 1.8 or 11+), the configuration slightly changes.</p> Maven Java 11+Maven Java 1.8Gradle Java 11+Gradle Java 1.8 <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-sqs&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;dev.aspectj&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.13.1&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;11&lt;/source&gt; &lt;!-- or higher --&gt;\n                 &lt;target&gt;11&lt;/target&gt; &lt;!-- or higher --&gt;\n                 &lt;complianceLevel&gt;11&lt;/complianceLevel&gt; &lt;!-- or higher --&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-sqs&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-sqs&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.14.0&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;1.8&lt;/source&gt;\n                 &lt;target&gt;1.8&lt;/target&gt;\n                 &lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-sqs&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '8.1.0'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-sqs:1.20.1'\n    }\n\n    sourceCompatibility = 11 // or higher\n    targetCompatibility = 11 // or higher\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '6.6.3'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-sqs:1.20.1'\n    }\n\n    sourceCompatibility = 1.8\n    targetCompatibility = 1.8\n</code></pre>"
        },
        {
            "location": "utilities/sqs_batch/#iam-permissions",
            "title": "IAM Permissions",
            "text": "<p>This utility requires additional permissions to work as expected. Lambda functions using this utility require the <code>sqs:DeleteMessageBatch</code> permission.</p> <p>If you are also using nonRetryableExceptions attribute, utility will need additional permission of <code>sqs:GetQueueAttributes</code> on source SQS.  It also needs <code>sqs:SendMessage</code> and <code>sqs:SendMessageBatch</code> on configured dead letter queue.  </p> <p>If source or dead letter queue is configured to use encryption at rest using AWS Key Management Service (KMS), function will need additional permissions of  <code>kms:GenerateDataKey</code> and <code>kms:Decrypt</code> on the KMS key being used for encryption. Refer docs for more details.</p> <p>Refer example project for policy details example.</p>"
        },
        {
            "location": "utilities/sqs_batch/#processing-messages-from-sqs",
            "title": "Processing messages from SQS",
            "text": "<p>You can use either SqsBatch annotation, or SqsUtils Utility API as a fluent API.</p> <p>Both have nearly the same behaviour when it comes to processing messages from the batch:</p> <ul> <li>Entire batch has been successfully processed, where your Lambda handler returned successfully, we will let SQS delete the batch to optimize your cost</li> <li>Entire Batch has been partially processed successfully, where exceptions were raised within your <code>SqsMessageHandler</code> interface implementation, we will:<ul> <li>1) Delete successfully processed messages from the queue by directly calling <code>sqs:DeleteMessageBatch</code></li> <li>2) If a message with a message group ID fails,           the processing of the batch will be stopped and the remainder of the messages will be returned to SQS.           This behaviour is required to handle SQS FIFO queues.   </li> <li>3) if non retryable exceptions occur, messages resulting in configured exceptions during processing will be immediately moved to the dead letter queue associated to the source SQS queue or deleted from the source SQS queue if <code>deleteNonRetryableMessageFromQueue</code> is set to <code>true</code>.</li> <li>4) Raise <code>SQSBatchProcessingException</code> to ensure failed messages return to your SQS queue</li> </ul> </li> </ul> <p>The only difference is that SqsUtils Utility API will give you access to return from the processed messages if you need. Exception <code>SQSBatchProcessingException</code> thrown from the utility will have access to both successful and failed messaged along with failure exceptions.</p>"
        },
        {
            "location": "utilities/sqs_batch/#functional-interface-sqsmessagehandler",
            "title": "Functional Interface SqsMessageHandler",
            "text": "<p>Both annotation and SqsUtils Utility API requires an implementation of functional interface <code>SqsMessageHandler</code>.</p> <p>This implementation is responsible for processing each individual message from the batch, and to raise an exception if unable to process any of the messages sent.</p> <p>Any non-exception/successful return from your record handler function will instruct utility to queue up each individual message for deletion.</p>"
        },
        {
            "location": "utilities/sqs_batch/#sqsbatch-annotation",
            "title": "SqsBatch annotation",
            "text": "<p>When using this annotation, you need provide a class implementation of <code>SqsMessageHandler</code> that will process individual messages from the batch - It should raise an exception if it is unable to process the record.</p> <p>All records in the batch will be passed to this handler for processing, even if exceptions are thrown - Here's the behaviour after completing the batch:</p> <ul> <li>Any successfully processed messages, we will delete them from the queue via <code>sqs:DeleteMessageBatch</code>.</li> <li>if, nonRetryableExceptions attribute is used, messages resulting in configured exceptions during processing will be immediately moved to the dead letter queue associated to the source SQS queue or deleted from the source SQS queue if <code>deleteNonRetryableMessageFromQueue</code> is set to <code>true</code>.</li> <li>Any unprocessed messages detected, we will raise <code>SQSBatchProcessingException</code> to ensure failed messages return to your SQS queue.</li> </ul> <p>Warning</p> <p>You will not have access to the processed messages within the Lambda Handler - all processing logic will and should be performed by the implemented <code>SqsMessageHandler#process()</code> function.</p> AppSqsEvent.javaAppSqsEventWithNonRetryableExceptions.java <pre><code>import software.amazon.lambda.powertools.sqs.SqsBatch;\nimport software.amazon.lambda.powertools.sqs.SqsMessageHandler;\nimport software.amazon.lambda.powertools.sqs.SqsUtils;\n\npublic class AppSqsEvent implements RequestHandler&lt;SQSEvent, String&gt; {\n    @Override\n    @SqsBatch(SampleMessageHandler.class)\n    public String handleRequest(SQSEvent input, Context context) {\n        return \"{\\\"statusCode\\\": 200}\";\n    }\n\n    public class SampleMessageHandler implements SqsMessageHandler&lt;Object&gt; {\n\n        @Override\n        public String process(SQSMessage message) {\n            // This will be called for each individual message from a batch\n            // It should raise an exception if the message was not processed successfully\n            String returnVal = doSomething(message.getBody());\n            return returnVal;\n        }\n    }\n}\n</code></pre> <pre><code>import software.amazon.lambda.powertools.sqs.SqsBatch;\nimport software.amazon.lambda.powertools.sqs.SqsMessageHandler;\nimport software.amazon.lambda.powertools.sqs.SqsUtils;\n\npublic class AppSqsEvent implements RequestHandler&lt;SQSEvent, String&gt; {\n    @Override\n    @SqsBatch(value = SampleMessageHandler.class, nonRetryableExceptions = {IllegalArgumentException.class})\n    public String handleRequest(SQSEvent input, Context context) {\n        return \"{\\\"statusCode\\\": 200}\";\n    }\n\n    public class SampleMessageHandler implements SqsMessageHandler&lt;Object&gt; {\n\n        @Override\n        public String process(SQSMessage message) {\n            // This will be called for each individual message from a batch\n            // It should raise an exception if the message was not processed successfully\n            String returnVal = doSomething(message.getBody());\n\n            if(/**Business validation failure**/) {\n                throw new IllegalArgumentException(\"Failed business validation. No point of retrying. Move me to DLQ.\" + message.getMessageId());\n            }\n\n            return returnVal;\n        }\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/sqs_batch/#sqsutils-utility-api",
            "title": "SqsUtils Utility API",
            "text": "<p>If you require access to the result of processed messages, you can use this utility. The result from calling <code>SqsUtils#batchProcessor()</code> on the context manager will be a list of all the return values  from your <code>SqsMessageHandler#process()</code> function.</p> <p>You can also use the utility in functional way by providing inline implementation of functional interface <code>SqsMessageHandler#process()</code></p> Utility APIFunction implementation <pre><code>public class AppSqsEvent implements RequestHandler&lt;SQSEvent, List&lt;String&gt;&gt; {\n    @Override\n    public List&lt;String&gt; handleRequest(SQSEvent input, Context context) {\n        List&lt;String&gt; returnValues = SqsUtils.batchProcessor(input, SampleMessageHandler.class);\n\n        return returnValues;\n    }\n\n    public class SampleMessageHandler implements SqsMessageHandler&lt;String&gt; {\n\n        @Override\n        public String process(SQSMessage message) {\n            // This will be called for each individual message from a batch\n            // It should raise an exception if the message was not processed successfully\n            String returnVal = doSomething(message.getBody());\n            return returnVal;\n        }\n    }\n}\n</code></pre> <pre><code>public class AppSqsEvent implements RequestHandler&lt;SQSEvent, List&lt;String&gt;&gt; {\n\n    @Override\n    public List&lt;String&gt; handleRequest(SQSEvent input, Context context) {\n        List&lt;String&gt; returnValues = SqsUtils.batchProcessor(input, (message) -&gt; {\n            // This will be called for each individual message from a batch\n            // It should raise an exception if the message was not processed successfully\n            String returnVal = doSomething(message.getBody());\n            return returnVal;\n        });\n\n        return returnValues;\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/sqs_batch/#passing-custom-sqsclient",
            "title": "Passing custom SqsClient",
            "text": "<p>If you need to pass custom SqsClient such as region to the SDK, you can pass your own <code>SqsClient</code> to be used by utility either for SqsBatch annotation, or SqsUtils Utility API.</p> App.java <pre><code>public class AppSqsEvent implements RequestHandler&lt;SQSEvent, List&lt;String&gt;&gt; {\n    static {\n        SqsUtils.overrideSqsClient(SqsClient.builder()\n                .build());\n    }\n\n    @Override\n    public List&lt;String&gt; handleRequest(SQSEvent input, Context context) {\n        List&lt;String&gt; returnValues = SqsUtils.batchProcessor(input, SampleMessageHandler.class);\n\n        return returnValues;\n    }\n\n    public class SampleMessageHandler implements SqsMessageHandler&lt;String&gt; {\n\n        @Override\n        public String process(SQSMessage message) {\n            // This will be called for each individual message from a batch\n            // It should raise an exception if the message was not processed successfully\n            String returnVal = doSomething(message.getBody());\n            return returnVal;\n        }\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/sqs_batch/#suppressing-exceptions",
            "title": "Suppressing exceptions",
            "text": "<p>If you want to disable the default behavior where <code>SQSBatchProcessingException</code> is raised if there are any exception, you can pass the <code>suppressException</code> boolean argument.</p> Within SqsBatch annotationWithin SqsUtils Utility API <pre><code>    @Override\n    @SqsBatch(value = SampleMessageHandler.class, suppressException = true)\n    public String handleRequest(SQSEvent input, Context context) {\n        return \"{\\\"statusCode\\\": 200}\";\n    }\n</code></pre> <pre><code>    @Override\n    public List&lt;String&gt; handleRequest(SQSEvent input, Context context) {\n        List&lt;String&gt; returnValues = SqsUtils.batchProcessor(input, true, SampleMessageHandler.class);\n\n        return returnValues;\n    }\n</code></pre>"
        },
        {
            "location": "utilities/sqs_batch/#move-non-retryable-messages-to-a-dead-letter-queue",
            "title": "Move non retryable messages to a dead letter queue",
            "text": "<p>If you want certain exceptions to be treated as permanent failures during batch processing, i.e. exceptions where the result of retrying will always be a failure and want these can be immediately moved to the dead letter queue associated to the source SQS queue, you can use <code>SqsBatch#nonRetryableExceptions()</code>  to configure such exceptions. </p> <p>If you want such messages to be deleted instead, set <code>SqsBatch#deleteNonRetryableMessageFromQueue()</code> to <code>true</code>. By default, its value is <code>false</code>.</p> <p>Same capability is also provided by SqsUtils Utility API.</p> <p>Info</p> <p>Make sure the lambda function has required permissions needed by utility. Refer this section.</p> SqsBatch annotationSqsBatch API <pre><code>import software.amazon.lambda.powertools.sqs.SqsBatch;\nimport software.amazon.lambda.powertools.sqs.SqsMessageHandler;\nimport software.amazon.lambda.powertools.sqs.SqsUtils;\n\npublic class AppSqsEvent implements RequestHandler&lt;SQSEvent, String&gt; {\n    @Override\n    @SqsBatch(value = SampleMessageHandler.class, nonRetryableExceptions = {IllegalArgumentException.class})\n    public String handleRequest(SQSEvent input, Context context) {\n        return \"{\\\"statusCode\\\": 200}\";\n    }\n\n    public class SampleMessageHandler implements SqsMessageHandler&lt;Object&gt; {\n\n        @Override\n        public String process(SQSMessage message) {\n            // This will be called for each individual message from a batch\n            // It should raise an exception if the message was not processed successfully\n            String returnVal = doSomething(message.getBody());\n\n            if(/**Business validation failure**/) {\n                throw new IllegalArgumentException(\"Failed business validation. No point of retrying. Move me to DLQ.\" + message.getMessageId());\n            }\n\n            return returnVal;\n        }\n    }\n}\n</code></pre> <pre><code>import software.amazon.lambda.powertools.sqs.SqsBatch;\nimport software.amazon.lambda.powertools.sqs.SqsMessageHandler;\nimport software.amazon.lambda.powertools.sqs.SqsUtils;\n\npublic class AppSqsEvent implements RequestHandler&lt;SQSEvent, String&gt; {\n    @Override\n    public String handleRequest(SQSEvent input, Context context) {\n\n        SqsUtils.batchProcessor(input, BatchProcessor.class, IllegalArgumentException.class);\n\n        return \"{\\\"statusCode\\\": 200}\";\n    }\n\n    public class SampleMessageHandler implements SqsMessageHandler&lt;Object&gt; {\n\n        @Override\n        public String process(SQSMessage message) {\n            // This will be called for each individual message from a batch\n            // It should raise an exception if the message was not processed successfully\n            String returnVal = doSomething(message.getBody());\n\n            if(/**Business validation failure**/) {\n                throw new IllegalArgumentException(\"Failed business validation. No point of retrying. Move me to DLQ.\" + message.getMessageId());\n            }\n\n            return returnVal;\n        }\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/sqs_batch/#migrating-to-the-batch-library",
            "title": "Migrating to the Batch Library",
            "text": "<p>The  batch processing library provides a way to process messages and gracefully handle partial failures for SQS, Kinesis Streams, and DynamoDB Streams batch sources. In comparison the legacy SQS Batch library, it relies on Lambda partial batch responses, which allows the library to provide a simpler, reliable interface for processing batches.</p> <p>In order to get started, check out the processing messages from SQS documentation.  In most cases, you will simply be able to retain your existing batch message handler function, and wrap it with the new  batch processing interface. Unlike this module, As the batch processor uses partial batch responses to communicate to Lambda which messages have been processed and must be removed from the queue, the return of the handler's process function must be returned to Lambda. </p> <p>The new library also no longer requires the <code>SQS:DeleteMessage</code> action on the Lambda function's role policy, as Lambda itself now manages removal of messages from the queue. </p> <p>Info</p> <p>Some tuneables from this library are no longer provided.</p> <ul> <li>Non-retryable Exceptions - there is no mechanism to indicate in a partial batch response that a particular message     should not be retried and instead moved to DLQ - a message either succeeds, or fails and is retried. A message     will be moved to the DLQ once the normal retry process has expired.</li> <li>Suppress Exception - The new batch processor does not throw an exception on failure of a handler. Instead,     its result must be returned by your code from your message handler to Lambda, so that Lambda can manage     the completed messages and retry behaviour.</li> </ul>"
        },
        {
            "location": "utilities/sqs_large_message_handling/",
            "title": "SQS Large Message Handling (Deprecated)",
            "text": "<p>Warning</p> <p>This module is now deprecated and will be removed in version 2. See Large Message Handling and  the migration guide for the new module (<code>powertools-large-messages</code>) documentation</p> <p>The large message handling utility handles SQS messages which have had their payloads offloaded to S3 due to them being larger than the SQS maximum.</p> <p>The utility automatically retrieves messages which have been offloaded to S3 using the amazon-sqs-java-extended-client-lib client library. Once the message payloads have been processed successful the utility can delete the message payloads from S3.</p> <p>This utility is compatible with versions 1.1.0+ of amazon-sqs-java-extended-client-lib.</p> Maven <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.amazonaws&lt;/groupId&gt;\n    &lt;artifactId&gt;amazon-sqs-java-extended-client-lib&lt;/artifactId&gt;\n    &lt;version&gt;1.1.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> Gradle <pre><code> dependencies {\n    implementation 'com.amazonaws:amazon-sqs-java-extended-client-lib:1.1.0'\n}\n</code></pre>"
        },
        {
            "location": "utilities/sqs_large_message_handling/#install",
            "title": "Install",
            "text": "<p>Depending on your version of Java (either Java 1.8 or 11+), the configuration slightly changes.</p> Maven Java 11+ <pre><code>&lt;dependencies&gt;\n...\n&lt;dependency&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-sqs&lt;/artifactId&gt;\n&lt;version&gt;1.20.1&lt;/version&gt;\n&lt;/dependency&gt;\n...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n&lt;plugins&gt;\n...\n&lt;plugin&gt;\n&lt;groupId&gt;dev.aspectj&lt;/groupId&gt;\n&lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n&lt;version&gt;1.13.1&lt;/version&gt;\n&lt;configuration&gt;\n&lt;source&gt;11&lt;/source&gt; &lt;!-- or higher --&gt;\n&lt;target&gt;11&lt;/target&gt; &lt;!-- or higher --&gt;\n&lt;complianceLevel&gt;11&lt;/complianceLevel&gt; &lt;!-- or higher --&gt;\n&lt;aspectLibraries&gt;\n&lt;aspectLibrary&gt;\n&lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n&lt;artifactId&gt;powertools-sqs&lt;/artifactId&gt;\n&lt;/aspectLibrary&gt;\n&lt;/aspectLibraries&gt;\n&lt;/configuration&gt;\n&lt;executions&gt;\n&lt;execution&gt;\n&lt;goals&gt;\n&lt;goal&gt;compile&lt;/goal&gt;\n&lt;/goals&gt;\n&lt;/execution&gt;\n&lt;/executions&gt;\n&lt;/plugin&gt;\n...\n&lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> Maven Java 1.8Gradle Java 11+Gradle Java 1.8 <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-sqs&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.14.0&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;1.8&lt;/source&gt;\n                 &lt;target&gt;1.8&lt;/target&gt;\n                 &lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-sqs&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '8.1.0'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-sqs:1.20.1'\n    }\n\n    sourceCompatibility = 11 // or higher\n    targetCompatibility = 11 // or higher\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '6.6.3'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-sqs:1.20.1'\n    }\n\n    sourceCompatibility = 1.8\n    targetCompatibility = 1.8\n</code></pre>"
        },
        {
            "location": "utilities/sqs_large_message_handling/#lambda-handler",
            "title": "Lambda handler",
            "text": "<p>The annotation <code>@SqsLargeMessage</code> should be used with the handleRequest method of a class which implements <code>com.amazonaws.services.lambda.runtime.RequestHandler</code> with <code>com.amazonaws.services.lambda.runtime.events.SQSEvent</code> as the first parameter.</p> SqsMessageHandler.java <pre><code>import software.amazon.lambda.powertools.sqs.SqsLargeMessage;\n\npublic class SqsMessageHandler implements RequestHandler&lt;SQSEvent, String&gt; {\n\n    @Override\n    @SqsLargeMessage\n    public String handleRequest(SQSEvent sqsEvent, Context context) {\n    // process messages\n\n    return \"ok\";\n    }\n}\n</code></pre> <p><code>@SqsLargeMessage</code> creates a default S3 Client <code>AmazonS3 amazonS3 = AmazonS3ClientBuilder.defaultClient()</code>.</p> <p>Tip</p> <p>When the Lambda function is invoked with an event from SQS, each received record in the SQSEvent is checked to see to validate if it is offloaded to S3. If it does then <code>getObject(bucket, key)</code> will be called, and the payload retrieved. If there is an error during this process then the function will fail with a <code>FailedProcessingLargePayloadException</code> exception.</p> <pre><code>If the request handler method returns without error then each payload will be\ndeleted from S3 using `deleteObject(bucket, key)`\n</code></pre> <p>To disable deletion of payloads setting the following annotation parameter:</p> Disable payload deletion <pre><code>import software.amazon.lambda.powertools.sqs.SqsLargeMessage;\n\n@SqsLargeMessage(deletePayloads=false)\npublic class SqsMessageHandler implements RequestHandler&lt;SQSEvent, String&gt; {\n\n}\n</code></pre>"
        },
        {
            "location": "utilities/sqs_large_message_handling/#utility",
            "title": "Utility",
            "text": "<p>If you want to avoid using annotation and have control over error that can happen during payload enrichment use <code>SqsUtils.enrichedMessageFromS3()</code>. It provides you access with a list of <code>SQSMessage</code> object enriched from S3 payload.</p> <p>Original <code>SQSEvent</code> object is never mutated. You can also control if the S3 payload should be deleted after successful processing.</p> Functional API without annotation <pre><code>import software.amazon.lambda.powertools.sqs.SqsLargeMessage;\nimport software.amazon.lambda.powertools.sqs.SqsUtils;\n\npublic class SqsMessageHandler implements RequestHandler&lt;SQSEvent, String&gt; {\n\n    @Override\n    public String handleRequest(SQSEvent sqsEvent, Context context) {\n\n         Map&lt;String, String&gt; sqsMessage = SqsUtils.enrichedMessageFromS3(sqsEvent, sqsMessages -&gt; {\n            // Some business logic\n            Map&lt;String, String&gt; someBusinessLogic = new HashMap&lt;&gt;();\n            someBusinessLogic.put(\"Message\", sqsMessages.get(0).getBody());\n            return someBusinessLogic;\n        });\n\n         // Do not delete payload after processing.\n         Map&lt;String, String&gt; sqsMessage = SqsUtils.enrichedMessageFromS3(sqsEvent, false, sqsMessages -&gt; {\n            // Some business logic\n            Map&lt;String, String&gt; someBusinessLogic = new HashMap&lt;&gt;();\n            someBusinessLogic.put(\"Message\", sqsMessages.get(0).getBody());\n            return someBusinessLogic;\n        });\n\n         // Better control over exception during enrichment\n         try {\n               // Do not delete payload after processing.\n            SqsUtils.enrichedMessageFromS3(sqsEvent, false, sqsMessages -&gt; {\n                // Some business logic\n            });\n         } catch (FailedProcessingLargePayloadException e) {\n             // handle any exception.\n         }\n\n        return \"ok\";\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/sqs_large_message_handling/#overriding-the-default-s3client",
            "title": "Overriding the default S3Client",
            "text": "<p>If you require customisations to the default S3Client, you can create your own <code>S3Client</code> and pass it to be used by utility either for SqsLargeMessage annotation, or SqsUtils Utility API.</p> App.java <pre><code>import software.amazon.lambda.powertools.sqs.SqsLargeMessage;\n\nstatic {\n    SqsUtils.overrideS3Client(S3Client.builder()\n            .build());\n}\n\npublic class SqsMessageHandler implements RequestHandler&lt;SQSEvent, String&gt; {\n\n    @Override\n    @SqsLargeMessage\n    public String handleRequest(SQSEvent sqsEvent, Context context) {\n    // process messages\n\n    return \"ok\";\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/validation/",
            "title": "Validation",
            "text": "<p>This utility provides JSON Schema validation for payloads held within events and response used in AWS Lambda.</p> <p>Key features</p> <ul> <li>Validate incoming events and responses</li> <li>Built-in validation for most common events (API Gateway, SNS, SQS, ...)</li> <li>JMESPath support validate only a sub part of the event</li> </ul>"
        },
        {
            "location": "utilities/validation/#install",
            "title": "Install",
            "text": "<p>Depending on your version of Java (either Java 1.8 or 11+), the configuration slightly changes.</p> Maven Java 11+Maven Java 1.8Gradle Java 11+Gradle Java 1.8 <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-validation&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;dev.aspectj&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.13.1&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;11&lt;/source&gt; &lt;!-- or higher --&gt;\n                 &lt;target&gt;11&lt;/target&gt; &lt;!-- or higher --&gt;\n                 &lt;complianceLevel&gt;11&lt;/complianceLevel&gt; &lt;!-- or higher --&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-validation&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>&lt;dependencies&gt;\n    ...\n    &lt;dependency&gt;\n        &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n        &lt;artifactId&gt;powertools-validation&lt;/artifactId&gt;\n        &lt;version&gt;1.20.1&lt;/version&gt;\n    &lt;/dependency&gt;\n    ...\n&lt;/dependencies&gt;\n...\n&lt;!-- configure the aspectj-maven-plugin to compile-time weave (CTW) the aws-lambda-powertools-java aspects into your project --&gt;\n&lt;build&gt;\n    &lt;plugins&gt;\n        ...\n        &lt;plugin&gt;\n             &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;\n             &lt;artifactId&gt;aspectj-maven-plugin&lt;/artifactId&gt;\n             &lt;version&gt;1.14.0&lt;/version&gt;\n             &lt;configuration&gt;\n                 &lt;source&gt;1.8&lt;/source&gt;\n                 &lt;target&gt;1.8&lt;/target&gt;\n                 &lt;complianceLevel&gt;1.8&lt;/complianceLevel&gt;\n                 &lt;aspectLibraries&gt;\n                     &lt;aspectLibrary&gt;\n                         &lt;groupId&gt;software.amazon.lambda&lt;/groupId&gt;\n                         &lt;artifactId&gt;powertools-validation&lt;/artifactId&gt;\n                     &lt;/aspectLibrary&gt;\n                 &lt;/aspectLibraries&gt;\n             &lt;/configuration&gt;\n             &lt;executions&gt;\n                 &lt;execution&gt;\n                     &lt;goals&gt;\n                         &lt;goal&gt;compile&lt;/goal&gt;\n                     &lt;/goals&gt;\n                 &lt;/execution&gt;\n             &lt;/executions&gt;\n        &lt;/plugin&gt;\n        ...\n    &lt;/plugins&gt;\n&lt;/build&gt;\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '8.1.0'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-validation:1.20.1'\n    }\n\n    sourceCompatibility = 11 // or higher\n    targetCompatibility = 11 // or higher\n</code></pre> <pre><code>    plugins {\n        id 'java'\n        id 'io.freefair.aspectj.post-compile-weaving' version '6.6.3'\n    }\n\n    repositories {\n        mavenCentral()\n    }\n\n    dependencies {\n        aspect 'software.amazon.lambda:powertools-validation:1.20.1'\n    }\n\n    sourceCompatibility = 1.8\n    targetCompatibility = 1.8\n</code></pre>"
        },
        {
            "location": "utilities/validation/#validating-events",
            "title": "Validating events",
            "text": "<p>You can validate inbound and outbound events using <code>@Validation</code> annotation.</p> <p>You can also use the <code>Validator#validate()</code> methods, if you want more control over the validation process such as handling a validation error.</p> <p>We support JSON schema version 4, 6, 7 and 201909 (from jmespath-jackson library).</p>"
        },
        {
            "location": "utilities/validation/#validation-annotation",
            "title": "Validation annotation",
            "text": "<p><code>@Validation</code> annotation is used to validate either inbound events or functions' response.</p> <p>It will fail fast with <code>ValidationException</code> if an event or response doesn't conform with given JSON Schema.</p> <p>While it is easier to specify a json schema file in the classpath (using the notation <code>\"classpath:/path/to/schema.json\"</code>), you can also provide a JSON String containing the schema.</p> MyFunctionHandler.java <pre><code>import software.amazon.lambda.powertools.validation.Validation;\n\npublic class MyFunctionHandler implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    @Override\n    @Validation(inboundSchema = \"classpath:/schema_in.json\", outboundSchema = \"classpath:/schema_out.json\")\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n        // ...\n        return something;\n    }\n}\n</code></pre> <p>NOTE: It's not a requirement to validate both inbound and outbound schemas - You can either use one, or both.</p>"
        },
        {
            "location": "utilities/validation/#validate-function",
            "title": "Validate function",
            "text": "<p>Validate standalone function is used within the Lambda handler, or any other methods that perform data validation.</p> <p>You can also gracefully handle schema validation errors by catching <code>ValidationException</code>.</p> MyFunctionHandler.java <pre><code>import static software.amazon.lambda.powertools.validation.ValidationUtils.*;\n\npublic class MyFunctionHandler implements RequestHandler&lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent&gt; {\n\n    @Override\n    public APIGatewayProxyResponseEvent handleRequest(APIGatewayProxyRequestEvent input, Context context) {\n        try {\n            validate(input, \"classpath:/schema.json\");\n        } catch (ValidationException ex) {\n            // do something before throwing it\n            throw ex;\n        }\n\n        // ...\n        return something;\n    }\n}\n</code></pre> <p>NOTE: Schemas are stored in memory for reuse, to avoid loading them from file each time.</p>"
        },
        {
            "location": "utilities/validation/#built-in-events-and-responses",
            "title": "Built-in events and responses",
            "text": "<p>For the following events and responses, the Validator will automatically perform validation on the content.</p> <p>** Events **</p> Type of event Class Path to content API Gateway REST APIGatewayProxyRequestEvent <code>body</code> API Gateway HTTP APIGatewayV2HTTPEvent <code>body</code> Application Load Balancer ApplicationLoadBalancerRequestEvent <code>body</code> Cloudformation Custom Resource CloudFormationCustomResourceEvent <code>resourceProperties</code> CloudWatch Logs CloudWatchLogsEvent <code>awslogs.powertools_base64_gzip(data)</code> EventBridge / Cloudwatch ScheduledEvent <code>detail</code> Kafka KafkaEvent <code>records[*][*].value</code> Kinesis KinesisEvent <code>Records[*].kinesis.powertools_base64(data)</code> Kinesis Firehose KinesisFirehoseEvent <code>Records[*].powertools_base64(data)</code> Kinesis Analytics from Firehose KinesisAnalyticsFirehoseInputPreprocessingEvent <code>Records[*].powertools_base64(data)</code> Kinesis Analytics from Streams KinesisAnalyticsStreamsInputPreprocessingEvent <code>Records[*].powertools_base64(data)</code> SNS SNSEvent <code>Records[*].Sns.Message</code> SQS SQSEvent <code>Records[*].body</code> <p>** Responses **</p> Type of response Class Path to content (envelope) API Gateway REST APIGatewayProxyResponseEvent} <code>body</code> API Gateway HTTP APIGatewayV2HTTPResponse} <code>body</code> API Gateway WebSocket APIGatewayV2WebSocketResponse} <code>body</code> Load Balancer ApplicationLoadBalancerResponseEvent} <code>body</code> Kinesis Analytics KinesisAnalyticsInputPreprocessingResponse} `Records[*].powertools_base64(data)``"
        },
        {
            "location": "utilities/validation/#custom-events-and-responses",
            "title": "Custom events and responses",
            "text": "<p>You can also validate any Event or Response type, once you have the appropriate schema.</p> <p>Sometimes, you might want to validate only a portion of it - This is where the envelope parameter is for.</p> <p>Envelopes are JMESPath expressions to extract a portion of JSON you want before applying JSON Schema validation.</p> MyCustomEventHandler.javamy_custom_event_schema.json <pre><code>import software.amazon.lambda.powertools.validation.Validation;\n\npublic class MyCustomEventHandler implements RequestHandler&lt;MyCustomEvent, String&gt; {\n\n    @Override\n    @Validation(inboundSchema = \"classpath:/my_custom_event_schema.json\",\n                envelope = \"basket.products[*]\")\n    public String handleRequest(MyCustomEvent input, Context context) {\n        return \"OK\";\n    }\n}\n</code></pre> <pre><code>{\n  \"basket\": {\n    \"products\" : [\n      {\n        \"id\": 43242,\n        \"name\": \"FooBar XY\",\n        \"price\": 258\n      },\n      {\n        \"id\": 765,\n        \"name\": \"BarBaz AB\",\n        \"price\": 43.99\n      }\n    ]\n  }\n}\n</code></pre> <p>This is quite powerful because you can use JMESPath Query language to extract records from arrays, slice and dice, to pipe expressions and function expressions, where you'd extract what you need before validating the actual payload.</p>"
        },
        {
            "location": "utilities/validation/#change-the-schema-version",
            "title": "Change the schema version",
            "text": "<p>By default, powertools-validation is configured with V7. You can use the <code>ValidationConfig</code> to change that behaviour.</p> Handler with custom schema version <pre><code>...\nimport software.amazon.lambda.powertools.validation.ValidationConfig;\nimport software.amazon.lambda.powertools.validation.Validation;\n\nstatic {\n    ValidationConfig.get().setSchemaVersion(SpecVersion.VersionFlag.V4);\n}\n\npublic class MyXMLEventHandler implements RequestHandler&lt;MyEventWithXML, String&gt; {\n\n    @Override\n    @Validation(inboundSchema=\"classpath:/schema.json\", envelope=\"powertools_xml(path.to.xml_data)\")\n    public String handleRequest(MyEventWithXML myEvent, Context context) {\n        return \"OK\";\n   }\n}\n</code></pre>"
        },
        {
            "location": "utilities/validation/#advanced-objectmapper-settings",
            "title": "Advanced ObjectMapper settings",
            "text": "<p>If you need to configure the Jackson ObjectMapper, you can use the <code>ValidationConfig</code>:</p> Handler with custom ObjectMapper <pre><code>...\nimport software.amazon.lambda.powertools.validation.ValidationConfig;\nimport software.amazon.lambda.powertools.validation.Validation;\n\nstatic {\n    ObjectMapper objectMapper= ValidationConfig.get().getObjectMapper();\n    // update (de)serializationConfig or other properties\n}\n\npublic class MyXMLEventHandler implements RequestHandler&lt;MyEventWithXML, String&gt; {\n\n    @Override\n    @Validation(inboundSchema=\"classpath:/schema.json\", envelope=\"powertools_xml(path.to.xml_data)\")\n    public String handleRequest(MyEventWithXML myEvent, Context context) {\n        return \"OK\";\n   }\n}\n</code></pre>"
        }
    ]
}