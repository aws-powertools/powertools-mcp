{
    "config":
    {
        "lang":
        [
            "en"
        ],
        "separator": "[\\s\\-]+",
        "pipeline":
        [
            "stopWordFilter"
        ]
    },
    "docs":
    [
        {
            "location": "",
            "title": "Powertools for AWS Lambda (.NET)",
            "text": ""
        },
        {
            "location": "#powertools-for-aws-lambda-net",
            "title": "Powertools for AWS Lambda (.NET)",
            "text": "<p>Powertools for AWS Lambda (.NET) (which from here will be referred as Powertools) is a suite of utilities for AWS Lambda functions to ease adopting best practices such as tracing, structured logging, custom metrics, and more.</p> <p>Info</p> <p>Supports .NET 6 and .NET 8 runtimes</p> Tip <p>Powertools is also available for Python, Java, and TypeScript.</p> Support this project by becoming a reference customer or sharing your work  <p>You can choose to support us in three ways:</p> <p>1) Become a reference customers. This gives us permission to list your company in our documentation.</p> <p>2) Share your work. Blog posts, video, sample projects you used Powertools!</p>"
        },
        {
            "location": "#features",
            "title": "Features",
            "text": "<p>Core utilities such as Tracing, Logging, and Metrics will be available across all Powertools for AWS Lambda languages. Additional utilities are subjective to each language ecosystem and customer demand.</p> Utility Description Tracing Decorators and utilities to trace Lambda function handlers, and both synchronous and asynchronous functions Logger Structured logging made easier, and decorator to enrich structured logging with key Lambda context details Metrics Custom AWS metrics created asynchronously via CloudWatch Embedded Metric Format (EMF) Parameters provides high-level functionality to retrieve one or multiple parameter values from AWS Systems Manager Parameter Store, AWS Secrets Manager, or Amazon DynamoDB. We also provide extensibility to bring your own providers. Idempotency The idempotency utility provides a simple solution to convert your Lambda functions into idempotent operations which are safe to retry. Batch Processing The batch processing utility handles partial failures when processing batches from Amazon SQS, Amazon Kinesis Data Streams, and Amazon DynamoDB Streams."
        },
        {
            "location": "#install",
            "title": "Install",
            "text": "<p>Powertools for AWS Lambda (.NET) is available as NuGet packages. You can install the packages from NuGet gallery or from Visual Studio editor. Search <code>AWS.Lambda.Powertools*</code> to see various utilities available.</p> <ul> <li> <p>AWS.Lambda.Powertools.Tracing:</p> <p><code>dotnet add package AWS.Lambda.Powertools.Tracing</code></p> </li> <li> <p>AWS.Lambda.Powertools.Logging:</p> <p><code>dotnet add package AWS.Lambda.Powertools.Logging</code></p> </li> <li> <p>AWS.Lambda.Powertools.Metrics:</p> <p><code>dotnet add package AWS.Lambda.Powertools.Metrics</code></p> </li> <li> <p>AWS.Lambda.Powertools.Parameters:</p> <p><code>dotnet add package AWS.Lambda.Powertools.Parameters</code></p> </li> <li> <p>AWS.Lambda.Powertools.Idempotency:</p> <p><code>dotnet add package AWS.Lambda.Powertools.Idempotency</code></p> </li> <li> <p>AWS.Lambda.Powertools.BatchProcessing:</p> <p><code>dotnet add package AWS.Lambda.Powertools.BatchProcessing</code></p> </li> </ul>"
        },
        {
            "location": "#using-sam-cli-template",
            "title": "Using SAM CLI template",
            "text": "<p>We have provided you with a custom template for the Serverless Application Model (AWS SAM) command-line interface (CLI). This generates a starter project that allows you to interactively choose the Powertools for AWS Lambda (.NET) features that enables you to include in your project.</p> <p>To use the SAM CLI, you need the following tools.</p> <ul> <li>SAM CLI - Install the SAM CLI</li> <li>.NET 6.0 (LTS)  - Install .NET 6.0</li> <li>Docker - Install Docker community edition</li> </ul> <p>Once you have SAM CLI installed, follow the these steps to initialize a .NET 6 project using Powertools for AWS (.NET)</p> <ol> <li>Run the following command in your command line     <pre><code>sam init -r dotnet6\n</code></pre></li> <li> <p>Select option 1 as your template source</p> <p><pre><code>Which template source would you like to use?\n    1 - AWS Quick Start Templates\n    2 - Custom Template Location\n</code></pre> 3. Select the <code>Hello World Example with Powertools for AWS Lambda</code> template</p> <pre><code>Choose an AWS Quick Start application template\n    1 - Hello World Example\n    2 - Data processing\n    3 - Hello World Example with Powertools for AWS Lambda\n    4 - Multi-step workflow\n    5 - Scheduled task\n    6 - Standalone function\n    7 - Serverless API\nTemplate: 3\n</code></pre> </li> <li> <p>Follow the rest of the prompts and give your project a name</p> </li> </ol> <p>Viola! You now have a SAM application pre-configured with Powertools!</p>"
        },
        {
            "location": "#examples",
            "title": "Examples",
            "text": "<p>We have provided a few examples that should you how to use the each of the core Powertools for AWS Lambda (.NET) features.</p> <ul> <li>Tracing</li> <li>Logging</li> <li>Metrics</li> <li>Serverless API</li> <li>Parameters</li> <li>Idempotency</li> <li>Batch Processing</li> </ul>"
        },
        {
            "location": "#connect",
            "title": "Connect",
            "text": "<ul> <li>Powertools for AWS Lambda (.NET) on Discord: <code>#dotnet</code> - Invite link</li> <li>Email: aws-powertools-maintainers@amazon.com</li> </ul>"
        },
        {
            "location": "#support-powertools-for-aws-lambda-net",
            "title": "Support Powertools for AWS Lambda (.NET)",
            "text": "<p>There are many ways you can help us gain future investments to improve everyone's experience:</p> <ul> <li> <p> Become a public reference</p> <p>Add your company name and logo on our landing page.</p> <p> GitHub Issue template</p> </li> <li> <p> Share your work</p> <p>Blog posts, video, and sample projects about Powertools for AWS Lambda.</p> <p> GitHub Issue template</p> </li> <li> <p> Join the community</p> <p>Connect, ask questions, and share what features you use.</p> <p> Discord invite</p> </li> </ul>"
        },
        {
            "location": "#becoming-a-reference-customer",
            "title": "Becoming a reference customer",
            "text": "<p>Knowing which companies are using this library is important to help prioritize the project internally. The following companies, among others, use Powertools:</p> <p>Caylent</p> <p>Pushpay</p>"
        },
        {
            "location": "#tenets",
            "title": "Tenets",
            "text": "<p>These are our core principles to guide our decision making.</p> <ul> <li>AWS Lambda only. We optimize for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported.</li> <li>Eases the adoption of best practices. The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional.</li> <li>Keep it lean. Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time.</li> <li>We strive for backwards compatibility. New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined.</li> <li>We work backwards from the community. We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs)</li> <li>Idiomatic. Utilities follow programming language idioms and language-specific best practices.</li> </ul>"
        },
        {
            "location": "changelog/",
            "title": "Changelog",
            "text": ""
        },
        {
            "location": "changelog/#changelog",
            "title": "Changelog",
            "text": "<p>All notable changes to this project will be documented in this file. See Conventional Commits for commit guidelines.</p> <p></p>"
        },
        {
            "location": "changelog/#140-2025-04-08",
            "title": "1.40 - 2025-04-08",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes",
            "title": "Bug Fixes",
            "text": "<ul> <li>build: update ProjectReference condition to always include AWS.Lambda.Powertools.Common project</li> <li>tests: update AWS_EXECUTION_ENV version in assertions to 1.0.0</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring",
            "title": "Code Refactoring",
            "text": "<ul> <li>enhance log buffer management to discard oversized entries and improve entry tracking</li> <li>update logger factory and builder to support log output configuration</li> <li>update parameter names and improve documentation in logging configuration classes</li> <li>improve logging buffer management and configuration handling</li> <li>replace SystemWrapper with ConsoleWrapper in tests and update logging methods. revert systemwrapper, revert lambda.core to 2.5.0</li> <li>replace SystemWrapper with ConsoleWrapper in tests and update logging methods. revert systemwrapper, revert lambda.core to 2.5.0</li> <li>enhance logger configuration and output handling. Fix tests</li> <li>update log buffering options and improve serializer handling</li> <li>clean up whitespace and improve logger configuration handling</li> <li>change Logger class to static and enhance logging capabilities</li> <li>logging: enhance IsEnabled method for improved log level handling</li> </ul>"
        },
        {
            "location": "changelog/#features",
            "title": "Features",
            "text": "<ul> <li>console: enhance ConsoleWrapper for test mode and output management</li> <li>lifecycle: add LambdaLifecycleTracker to manage cold start state and initialization type</li> <li>logger: enhance random number generation and improve regex match timeout</li> <li>logging: introduce custom logger output and enhance configuration options</li> <li>logging: add GetLogOutput method and CompositeJsonTypeInfoResolver for enhanced logging capabilities</li> <li>workflows: update .NET version setup to support multiple versions and improve package handling</li> <li>workflows: add examples tests and publish packages workflow; remove redundant test step</li> </ul>"
        },
        {
            "location": "changelog/#maintenance",
            "title": "Maintenance",
            "text": "<ul> <li>update Microsoft.Extensions.DependencyInjection to version 8.0.1</li> <li>deps: bump actions/setup-node from 4.2.0 to 4.3.0</li> <li>deps: bump actions/setup-dotnet from 4.3.0 to 4.3.1</li> <li>deps: update AWS Lambda Powertools packages to latest versions</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #844 from hjgraca/fix/revert-common-setup</li> <li>Merge pull request #843 from hjgraca/fix/batch-example-nuget-update</li> <li>Merge pull request #842 from hjgraca/fix/update-example-nuget</li> <li>Merge pull request #841 from hjgraca/fix/execution-env-ignore-version</li> <li>Merge pull request #840 from hjgraca/fix/execution-env-version</li> <li>Merge pull request #832 from hjgraca/feature/logger-ilogger-instance</li> <li>Merge pull request #821 from aws-powertools/dependabot/github_actions/actions/setup-node-4.3.0</li> <li>Merge pull request #820 from aws-powertools/dependabot/github_actions/actions/setup-dotnet-4.3.1</li> <li>Merge pull request #835 from hjgraca/fix/override-lambda-console</li> <li>Merge pull request #834 from hjgraca/feature/coldstart-provisioned-concurrency</li> <li>Merge pull request #814 from hjgraca/chore/update-examples-130</li> <li>Merge pull request #813 from hjgraca/chore/update-examples-130</li> </ul>"
        },
        {
            "location": "changelog/#130-2025-03-07",
            "title": "1.30 - 2025-03-07",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_1",
            "title": "Bug Fixes",
            "text": "<ul> <li>build: simplify dependency installation step in CI configuration</li> <li>build: pass target framework properties during restore, build, and test steps</li> <li>build: update test commands and project configurations for .NET frameworks</li> <li>build: add SkipInvalidProjects property to build properties for .NET frameworks</li> <li>build: add /tl option to dotnet build command in build.yml</li> <li>build: update .NET setup step to use matrix variable for versioning</li> <li>ci: Permissions (#782)</li> <li>ci: Permissions and depdendencies</li> <li>ci: add write for issues</li> <li>ci: Add permissions to read issues and pull requests</li> <li>ci: label PRs</li> <li>ci: Workflow permissions (#774)</li> <li>ci: Indentation issue</li> <li>metrics: add null checks and unit tests for MetricsAspect and MetricsAttribute</li> <li>metrics: rename variable for default dimensions in cold start handling</li> <li>metrics: ensure thread safety by locking metrics during cold start flag reset</li> <li>tests: correct command in e2e-tests.yml and remove unnecessary assertions in FunctionTests.cs</li> <li>tests: conditionally include project reference for net8.0 framework</li> </ul>"
        },
        {
            "location": "changelog/#code-refactoring_1",
            "title": "Code Refactoring",
            "text": "<ul> <li>metrics: simplify MetricsTests by removing unused variables and improving syntax</li> <li>metrics: standardize parameter names for clarity in metric methods</li> <li>metrics: standardize parameter names for metric methods to improve clarity</li> </ul>"
        },
        {
            "location": "changelog/#documentation",
            "title": "Documentation",
            "text": "<ul> <li>metrics: document breaking changes in metrics output format and default dimensions</li> </ul>"
        },
        {
            "location": "changelog/#features_1",
            "title": "Features",
            "text": "<ul> <li>build: increase verbosity for test and example runs in CI pipeline</li> <li>build: enhance CI configuration with multi-framework support for .NET 6.0 and 8.0</li> <li>ci: Permissions updates</li> <li>metrics: enhance cold start handling with default dimensions and add corresponding tests</li> <li>metrics: enhance WithFunctionName method to handle null or empty values and add corresponding unit tests</li> <li>metrics: update metrics to version 2.0.0, enhance cold start tracking, and improve documentation</li> <li>metrics: update default dimensions handling and increase maximum dimensions limit</li> <li>metrics: add Metrics.AspNetCore version to version.json</li> <li>metrics: add ColdStartTracker for tracking cold starts in ASP.NET Core applications</li> <li>metrics: enhance default dimensions handling and refactor metrics initialization. Adding default dimensions to cold start metrics</li> <li>metrics: implement IConsoleWrapper for abstracting console operations and enhance cold start metric capturing</li> <li>metrics: add unit tests for Metrics constructor and validation methods</li> <li>metrics: always set namespace and service, update tests for service handling</li> <li>metrics: add HandlerEmpty method and test for empty metrics exception handling</li> <li>metrics: add HandlerRaiseOnEmptyMetrics method and corresponding test for empty metrics exception</li> <li>metrics: enhance documentation for Cold Start Function Name dimension and update test classes</li> <li>metrics: add support for disabling metrics via environment variable</li> <li>metrics: add function name support for metrics dimensions</li> <li>metrics: add support for default dimensions in metrics handling</li> <li>metrics: introduce MetricsOptions for configurable metrics setup and refactor initialization logic</li> <li>metrics: add ASP.NET Core metrics package with cold start tracking and middleware support for aspnetcore. Docs</li> <li>metrics: enhance MetricsBuilder with detailed configuration options and improve documentation</li> <li>metrics: add MetricsBuilder for fluent configuration of metrics options and enhance default dimensions handling</li> <li>metrics: update TargetFramework to net8.0 and adjust MaxDimensions limit</li> <li>tests: add unit tests for ConsoleWrapper and Metrics middleware extensions</li> <li>version: update Metrics version to 2.0.0 in version.json</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_1",
            "title": "Maintenance",
            "text": "<ul> <li>Add openssf scorecard badge to readme (#790)</li> <li>deps: bump jinja2 from 3.1.5 to 3.1.6</li> <li>deps: bump jinja2 from 3.1.5 to 3.1.6 in /docs</li> <li>deps: bump squidfunk/mkdocs-material in /docs</li> <li>deps: bump codecov/codecov-action from 5.3.1 to 5.4.0</li> <li>deps: bump github/codeql-action from 3.28.9 to 3.28.10</li> <li>deps: bump ossf/scorecard-action from 2.4.0 to 2.4.1</li> <li>deps: bump actions/upload-artifact from 4.6.0 to 4.6.1</li> <li>deps: bump squidfunk/mkdocs-material in /docs</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions</li> <li>deps: bump squidfunk/mkdocs-material in /docs</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_1",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #811 from aws-powertools/chore/update-version</li> <li>Merge pull request #810 from aws-powertools/fix-release-drafter</li> <li>Merge pull request #807 from hjgraca/fix/metrics-namespace-service-not-present</li> <li>Merge pull request #805 from aws-powertools/dependabot/pip/jinja2-3.1.6</li> <li>Merge pull request #804 from aws-powertools/dependabot/pip/docs/jinja2-3.1.6</li> <li>Merge pull request #802 from hjgraca/fix/metrics-e2e-tests</li> <li>Merge pull request #801 from aws-powertools/dependabot/docker/docs/squidfunk/mkdocs-material-047452c6641137c9caa3647d050ddb7fa67b59ed48cc67ec3a4995f3d360ab32</li> <li>Merge pull request #800 from hjgraca/fix/low-hanging-fruit-metrics-v2</li> <li>Merge pull request #799 from aws-powertools/maintenance/workflow-branch-develop</li> <li>Merge pull request #797 from aws-powertools/fix-version-comma</li> <li>Merge pull request #793 from aws-powertools/dependabot/github_actions/codecov/codecov-action-5.4.0</li> <li>Merge pull request #791 from gregsinclair42/CheckForValidLambdaContext</li> <li>Merge pull request #786 from hjgraca/feature/metrics-disabled</li> <li>Merge pull request #785 from hjgraca/feature/metrics-function-name</li> <li>Merge pull request #780 from hjgraca/feature/metrics-single-default-dimensions</li> <li>Merge pull request #775 from hjgraca/feature/metrics-aspnetcore</li> <li>Merge pull request #771 from hjgraca/feature/metrics-default-dimensions-coldstart</li> <li>Merge pull request #789 from aws-powertools/permissions</li> <li>Merge pull request #788 from aws-powertools/pr_merge</li> <li>Merge pull request #787 from aws-powertools/indentation</li> <li>Merge pull request #767 from aws-powertools/maintenance/sitemap</li> <li>Merge pull request #778 from aws-powertools/dependabot/github_actions/github/codeql-action-3.28.10</li> <li>Merge pull request #777 from aws-powertools/dependabot/github_actions/ossf/scorecard-action-2.4.1</li> <li>Merge pull request #776 from aws-powertools/dependabot/github_actions/actions/upload-artifact-4.6.1</li> <li>Merge pull request #770 from aws-powertools/dependabot/docker/docs/squidfunk/mkdocs-material-26153027ff0b192d3dbea828f2fe2dd1bf6ff753c58dd542b3ddfe866b08bf60</li> <li>Merge pull request #666 from hjgraca/fix(metrics)-dimessions-with-missing-array</li> <li>Merge pull request #768 from aws-powertools/dependabot/github_actions/zgosalvez/github-actions-ensure-sha-pinned-actions-3.0.22</li> <li>Merge pull request #764 from aws-powertools/dependabot/docker/docs/squidfunk/mkdocs-material-f5bcec4e71c138bcb89c0dccb633c830f54a0218e1aefedaade952b61b908d00</li> </ul>"
        },
        {
            "location": "changelog/#120-2025-02-11",
            "title": "1.20 - 2025-02-11",
            "text": ""
        },
        {
            "location": "changelog/#features_2",
            "title": "Features",
            "text": "<ul> <li>idempotency: add support for custom key prefixes in IdempotencyHandler and related tests</li> <li>tests: add unit tests for IdempotencySerializer and update JSON options handling</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_2",
            "title": "Maintenance",
            "text": "<ul> <li>add openssf scorecard workflow</li> <li>deps: bump squidfunk/mkdocs-material in /docs</li> <li>deps: bump squidfunk/mkdocs-material in /docs</li> <li>deps: bump actions/upload-artifact from 4.5.0 to 4.6.0</li> <li>deps: bump github/codeql-action from 3.28.8 to 3.28.9</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions</li> <li>deps: bump aws-actions/configure-aws-credentials</li> <li>deps: bump squidfunk/mkdocs-material in /docs</li> <li>deps: bump github/codeql-action from 3.27.9 to 3.28.9</li> <li>deps: bump github/codeql-action from 3.28.6 to 3.28.8</li> <li>deps: bump actions/setup-dotnet from 4.2.0 to 4.3.0</li> <li>deps: bump github/codeql-action from 3.28.5 to 3.28.6</li> <li>deps: bump actions/setup-python from 5.3.0 to 5.4.0</li> <li>deps: bump aws-actions/configure-aws-credentials</li> <li>deps: bump pygments from 2.13.0 to 2.15.0</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_2",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #755 from aws-powertools/dependabot/github_actions/aws-actions/configure-aws-credentials-4.1.0</li> <li>Merge pull request #754 from aws-powertools/dependabot/github_actions/actions/upload-artifact-4.6.0</li> <li>Merge pull request #753 from aws-powertools/dependabot/github_actions/github/codeql-action-3.28.9</li> <li>Merge pull request #757 from hjgraca/docs/roadmap-2025-update</li> <li>Merge pull request #758 from aws-powertools/docs/idempotency-prefix</li> <li>Merge pull request #743 from aws-powertools/release(1.20)-update-versions</li> <li>Merge pull request #355 from aws-powertools/dependabot/pip/pygments-2.15.0</li> <li>Merge pull request #751 from aws-powertools/dependabot/github_actions/github/codeql-action-3.28.9</li> <li>Merge pull request #750 from aws-powertools/dependabot/github_actions/zgosalvez/github-actions-ensure-sha-pinned-actions-3.0.21</li> <li>Merge pull request #748 from aws-powertools/dependabot/docker/docs/squidfunk/mkdocs-material-c62453b1ba229982c6325a71165c1a3007c11bd3dd470e7a1446c5783bd145b4</li> <li>Merge pull request #745 from hjgraca/feature/idempotency-key-prefix</li> <li>Merge pull request #747 from aws-powertools/mkdocs/privacy-plugin</li> <li>Merge pull request #653 from hjgraca/aot(idempotency|jmespath)-aot-support</li> <li>Merge pull request #744 from aws-powertools/dependabot/docker/docs/squidfunk/mkdocs-material-7e841df1cfb6c8c4ff0968f2cfe55127fb1a2f5614e1c9bc23cbc11fe4c96644</li> <li>Merge pull request #738 from hjgraca/feat(e2e)-idempotency-e2e-tests</li> <li>Merge pull request #741 from hjgraca/fix(tracing)-invalid-sement-name</li> <li>Merge pull request #739 from aws-powertools/dependabot/docker/docs/squidfunk/mkdocs-material-471695f3e611d9858788ac04e4daa9af961ccab73f1c0f545e90f8cc5d4268b8</li> <li>Merge pull request #736 from aws-powertools/dependabot/github_actions/actions/setup-dotnet-4.3.0</li> <li>Merge pull request #737 from aws-powertools/dependabot/github_actions/github/codeql-action-3.28.8</li> <li>Merge pull request #734 from aws-powertools/fix-apidocs-build</li> <li>Merge pull request #727 from aws-powertools/dependabot/github_actions/github/codeql-action-3.28.6</li> <li>Merge pull request #725 from aws-powertools/dependabot/github_actions/aws-actions/configure-aws-credentials-4.0.3</li> <li>Merge pull request #726 from aws-powertools/dependabot/github_actions/actions/setup-python-5.4.0</li> <li>Merge pull request #731 from aws-powertools/patch-do-not-pack-tests</li> </ul>"
        },
        {
            "location": "changelog/#119-2025-01-28",
            "title": "1.19 - 2025-01-28",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_3",
            "title": "Maintenance",
            "text": "<ul> <li>deps: bump codecov/codecov-action from 5.3.0 to 5.3.1</li> <li>deps: bump github/codeql-action from 3.28.4 to 3.28.5</li> <li>deps: bump actions/upload-artifact from 4.5.0 to 4.6.0</li> <li>deps: bump actions/checkout from 4.1.7 to 4.2.2</li> <li>deps: bump zgosalvez/github-actions-ensure-sha-pinned-actions</li> <li>deps: bump release-drafter/release-drafter from 5.21.1 to 6.1.0</li> <li>deps: bump codecov/codecov-action from 4.5.0 to 5.3.0</li> <li>deps: bump actions/github-script from 6 to 7</li> <li>deps: bump github/codeql-action from 2.1.18 to 3.28.4</li> <li>deps: bump actions/upload-artifact from 3 to 4</li> <li>deps: bump aws-actions/configure-aws-credentials</li> <li>deps: bump actions/setup-dotnet from 3.0.3 to 4.2.0</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_3",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #728 from aws-powertools/hjgraca-docs-service</li> <li>Merge pull request #724 from aws-powertools/release(1.19)-update-versions</li> <li>Merge pull request #704 from hjgraca/fix(logging)-service-name-override</li> <li>Merge pull request #722 from aws-powertools/dependabot/github_actions/codecov/codecov-action-5.3.1</li> <li>Merge pull request #721 from aws-powertools/dependabot/github_actions/github/codeql-action-3.28.5</li> <li>Merge pull request #714 from aws-powertools/dependabot/github_actions/codecov/codecov-action-5.3.0</li> <li>Merge pull request #715 from aws-powertools/dependabot/github_actions/release-drafter/release-drafter-6.1.0</li> <li>Merge pull request #716 from aws-powertools/dependabot/github_actions/zgosalvez/github-actions-ensure-sha-pinned-actions-3.0.20</li> <li>Merge pull request #717 from aws-powertools/dependabot/github_actions/actions/checkout-4.2.2</li> <li>Merge pull request #720 from aws-powertools/chore/e2e-libraries-path</li> <li>Merge pull request #718 from aws-powertools/dependabot/github_actions/actions/upload-artifact-4.6.0</li> <li>Merge pull request #713 from aws-powertools/chore(e2e)-concurrency</li> <li>Merge pull request #707 from aws-powertools/dependabot/github_actions/actions/setup-dotnet-4.2.0</li> <li>Merge pull request #708 from aws-powertools/dependabot/github_actions/aws-actions/configure-aws-credentials-4.0.2</li> <li>Merge pull request #711 from aws-powertools/dependabot/github_actions/actions/github-script-7</li> <li>Merge pull request #710 from aws-powertools/dependabot/github_actions/github/codeql-action-3.28.4</li> <li>Merge pull request #709 from aws-powertools/dependabot/github_actions/actions/upload-artifact-4</li> <li>Merge pull request #706 from aws-powertools/ci/dependabot</li> <li>Merge pull request #700 from hjgraca/hjgraca-e2e-aot</li> <li>Merge pull request #679 from hjgraca/dep(examples)-update-examples-dep</li> <li>Merge pull request #682 from aws-powertools/dependabot/pip/jinja2-3.1.5</li> <li>Merge pull request #699 from hjgraca/aot-e2e-tests</li> <li>Merge pull request #698 from ankitdhaka07/issue-697</li> </ul>"
        },
        {
            "location": "changelog/#118-2025-01-14",
            "title": "1.18 - 2025-01-14",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_4",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #695 from aws-powertools/update-versio-release118</li> <li>Merge pull request #692 from hjgraca/feature/e2etests</li> <li>Merge pull request #691 from aws-powertools/hjgraca-patch-e2e-6</li> <li>Merge pull request #690 from aws-powertools/hjgraca-patch-e2e-5</li> <li>Merge pull request #689 from aws-powertools/hjgraca-patch-e2e-4</li> <li>Merge pull request #688 from aws-powertools/hjgraca-patch-e2e-3</li> <li>Merge pull request #687 from aws-powertools/hjgraca-patch-e2e-2</li> <li>Merge pull request #686 from aws-powertools/hjgraca-patch-e2e</li> <li>Merge pull request #685 from hjgraca/feat-e2e</li> <li>Merge pull request #684 from hjgraca/feature/e2etests</li> <li>Merge pull request #681 from hjgraca/feat(logging)-inner-exception</li> </ul>"
        },
        {
            "location": "changelog/#117-2024-11-12",
            "title": "1.17 - 2024-11-12",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_5",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #675 from hjgraca/fix(tracing)-aot-void-task-and-serialization</li> </ul>"
        },
        {
            "location": "changelog/#116-2024-10-22",
            "title": "1.16 - 2024-10-22",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_6",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #672 from aws-powertools/hjgraca-logging-release115</li> <li>Merge pull request #670 from hjgraca/fix(logging)-enum-serialization</li> <li>Merge pull request #664 from hjgraca/fix(metrics)-multiple-dimension-array</li> </ul>"
        },
        {
            "location": "changelog/#115-2024-10-05",
            "title": "1.15 - 2024-10-05",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_7",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #660 from hjgraca/fix(tracing)-revert-imethodaspecthander-removal</li> <li>Merge pull request #657 from hjgraca/fix(logging)-typeinforesolver-non-aot</li> <li>Merge pull request #646 from lachriz-aws/feature/throw-on-full-batch-failure-option</li> <li>Merge pull request #652 from hjgraca/chore(dependencies)-update-logging-examples</li> </ul>"
        },
        {
            "location": "changelog/#114-2024-09-24",
            "title": "1.14 - 2024-09-24",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_8",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #649 from hjgraca/(docs)-update-logging-aot</li> <li>Merge pull request #628 from hjgraca/aot(logging)-support-logging</li> <li>Merge pull request #645 from aws-powertools/chore(examples)Update-examples-release-1.13</li> <li>Merge pull request #643 from hjgraca/fix(dependencies)-Fix-Common-dependency</li> <li>Merge pull request #641 from hjgraca/fix(references)-build-targets-common</li> </ul>"
        },
        {
            "location": "changelog/#113-2024-08-29",
            "title": "1.13 - 2024-08-29",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_4",
            "title": "Maintenance",
            "text": "<ul> <li>docs: load self hosted mermaid.js</li> <li>docs: load self hosted mermaid.js</li> <li>docs: Caylent customer reference</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_9",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #639 from aws-powertools/fix(docs)-missing-closing-tag</li> <li>Merge pull request #638 from aws-powertools/release(1.13)-update-versions</li> <li>Merge pull request #622 from aws-powertools/fix-typo-tracing-docs</li> <li>Merge pull request #632 from hjgraca/fix(tracing)-batch-handler-result-null-reference</li> <li>Merge pull request #633 from hjgraca/publicref/pushpay</li> <li>Merge pull request #627 from hjgraca/fix-idempotency-jmespath-dependency</li> <li>Merge pull request #625 from hjgraca/docs(public_reference)-add-Caylent-as-a-public-reference</li> <li>Merge pull request #623 from hjgraca/chore-update-tracing-examples-150</li> </ul>"
        },
        {
            "location": "changelog/#112-2024-07-24",
            "title": "1.12 - 2024-07-24",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_5",
            "title": "Maintenance",
            "text": "<ul> <li>deps-dev: bump zipp from 3.11.0 to 3.19.1</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_10",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #607 from hjgraca/aot-tracing-support</li> <li>Merge pull request #610 from aws-powertools/dependabot/pip/zipp-3.19.1</li> <li>Merge pull request #617 from hjgraca/example-update-release-1.11.1</li> </ul>"
        },
        {
            "location": "changelog/#1111-2024-07-12",
            "title": "1.11.1 - 2024-07-12",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_11",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #613 from hjgraca/fix-metrics-resolution-context</li> </ul>"
        },
        {
            "location": "changelog/#111-2024-07-09",
            "title": "1.11 - 2024-07-09",
            "text": ""
        },
        {
            "location": "changelog/#1102-2024-07-09",
            "title": "1.10.2 - 2024-07-09",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_6",
            "title": "Maintenance",
            "text": "<ul> <li>deps: bump jinja2 from 3.1.3 to 3.1.4</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_12",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #579 from aws-powertools/dependabot/pip/jinja2-3.1.4</li> <li>Merge pull request #602 from hjgraca/aot-metrics-support</li> <li>Merge pull request #605 from aws-powertools/hjgraca-codecov</li> <li>Merge pull request #600 from aws-powertools/hjgraca-examples-1.10.1</li> </ul>"
        },
        {
            "location": "changelog/#1101-2024-05-22",
            "title": "1.10.1 - 2024-05-22",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_13",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #596 from aws-powertools/hjgraca-update-version-1.10.1</li> <li>Merge pull request #594 from hjgraca/metrics-thread-safety-bug</li> <li>Merge pull request #589 from aws-powertools/hjgraca-idempotency-examples</li> <li>Merge pull request #590 from hjgraca/fix-jmespath-dep</li> </ul>"
        },
        {
            "location": "changelog/#1100-2024-05-09",
            "title": "1.10.0 - 2024-05-09",
            "text": ""
        },
        {
            "location": "changelog/#192-2024-05-09",
            "title": "1.9.2 - 2024-05-09",
            "text": ""
        },
        {
            "location": "changelog/#documentation_1",
            "title": "Documentation",
            "text": "<ul> <li>add link to Powertools for AWS Lambda workshop</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_14",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #586 from aws-powertools/hjgraca-version-release-1-10</li> <li>Merge pull request #578 from hjgraca/feature/jmespath-powertools</li> <li>Merge pull request #584 from aws-powertools/hjgraca-build-pipeline</li> <li>Merge pull request #581 from dreamorosi/docs/link_workshop</li> </ul>"
        },
        {
            "location": "changelog/#191-2024-03-21",
            "title": "1.9.1 - 2024-03-21",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_15",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #575 from aws-powertools/release-191</li> <li>Merge pull request #572 from hjgraca/fix-tracing-duplicate-generic-method-decorator</li> <li>Merge pull request #569 from aws-powertools/hjgraca-update-docs-dotnet8</li> </ul>"
        },
        {
            "location": "changelog/#190-2024-03-11",
            "title": "1.9.0 - 2024-03-11",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_16",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #565 from aws-powertools/update-nuget-examples</li> <li>Merge pull request #564 from amirkaws/update-nuget-versions-for-examples</li> <li>Merge pull request #563 from amirkaws/release-version-1.9.0</li> <li>Merge pull request #561 from amirkaws/update-nuget-versions</li> <li>Merge pull request #555 from aws-powertools/hjgraca-update-examples-185</li> <li>Merge pull request #559 from amirkaws/add-configuration-parameter-provider</li> </ul>"
        },
        {
            "location": "changelog/#185-2024-02-16",
            "title": "1.8.5 - 2024-02-16",
            "text": ""
        },
        {
            "location": "changelog/#documentation_2",
            "title": "Documentation",
            "text": "<ul> <li>updated we made this section with video series from Rahul and workshops</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_7",
            "title": "Maintenance",
            "text": "<ul> <li>deps: bump jinja2 from 3.1.2 to 3.1.3</li> <li>deps: bump gitpython from 3.1.37 to 3.1.41</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_17",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #552 from aws-powertools/hjgraca-update-version-185</li> <li>Merge pull request #538 from hjgraca/hendle-exception-logger</li> <li>Merge pull request #547 from aws-powertools/hjgraca-batch-docs</li> <li>Merge pull request #548 from H1Gdev/doc</li> <li>Merge pull request #542 from hjgraca/dotnet8-support</li> <li>Merge pull request #539 from aws-powertools/dependabot/pip/gitpython-3.1.41</li> <li>Merge pull request #540 from aws-powertools/dependabot/pip/jinja2-3.1.3</li> <li>Merge pull request #544 from aws-powertools/hjgraca-docs-auto-disable-tracing</li> <li>Merge pull request #536 from sliedig/develop</li> </ul>"
        },
        {
            "location": "changelog/#184-2023-12-12",
            "title": "1.8.4 - 2023-12-12",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_18",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #532 from aws-powertools/hjgraca-update-batch-ga</li> <li>Merge pull request #528 from aws-powertools/idempotency-183-examples</li> </ul>"
        },
        {
            "location": "changelog/#183-2023-11-21",
            "title": "1.8.3 - 2023-11-21",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_19",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #525 from aws-powertools/idempotency-ga</li> <li>Merge pull request #523 from hjgraca/update-examples-182</li> <li>Merge pull request #513 from hjgraca/idempotency-method-e2e-test</li> <li>Merge pull request #521 from hjgraca/182-fix-examples-logging-batch</li> </ul>"
        },
        {
            "location": "changelog/#182-2023-11-16",
            "title": "1.8.2 - 2023-11-16",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_20",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #518 from aws-powertools/hjgraca-version-1.8.2</li> <li>Merge pull request #516 from hjgraca/lambda-log-level</li> <li>Merge pull request #510 from aws-powertools/hjgraca-examples-1.8.1</li> </ul>"
        },
        {
            "location": "changelog/#181-2023-10-30",
            "title": "1.8.1 - 2023-10-30",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_8",
            "title": "Maintenance",
            "text": "<ul> <li>deps: bump gitpython from 3.1.35 to 3.1.37</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_21",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #507 from aws-powertools/hjgraca-release-1.8.1</li> <li>Merge pull request #505 from hjgraca/fix-exception-addmetadata</li> <li>Merge pull request #499 from hjgraca/metrics-decorator-exception</li> <li>Merge pull request #503 from hjgraca/dateonly-converter</li> <li>Merge pull request #502 from aws-powertools/dependabot/pip/gitpython-3.1.37</li> <li>Merge pull request #495 from hjgraca/update-projects-readme</li> <li>Merge pull request #493 from hjgraca/release1.8.0-example-updates</li> <li>Merge pull request #492 from aws-powertools/update-changelog-6248167844</li> </ul>"
        },
        {
            "location": "changelog/#180-2023-09-20",
            "title": "1.8.0 - 2023-09-20",
            "text": ""
        },
        {
            "location": "changelog/#documentation_3",
            "title": "Documentation",
            "text": "<ul> <li>add kinesis and dynamodb</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_22",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #489 from amirkaws/release-version-1.8.0</li> <li>Merge pull request #337 from lachriz-aws/feature/batch-processing</li> </ul>"
        },
        {
            "location": "changelog/#171-2023-09-19",
            "title": "1.7.1 - 2023-09-19",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_23",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #486 from amirkaws/update-examples-nuget-versions</li> <li>Merge pull request #484 from aws-powertools/hjgraca-release-1.7.1</li> <li>Merge pull request #482 from aws-powertools/hjgraca-release-1.7.1</li> <li>Merge pull request #480 from hjgraca/bug-revert-aspectinjector</li> <li>Merge pull request #479 from aws-powertools/hjgraca-update-examples-1.7.0</li> <li>Merge pull request #477 from aws-powertools/hjgraca-delete-dependabot</li> </ul>"
        },
        {
            "location": "changelog/#170-2023-09-14",
            "title": "1.7.0 - 2023-09-14",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_9",
            "title": "Maintenance",
            "text": "<ul> <li>deps: bump gitpython from 3.1.30 to 3.1.35</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_24",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #475 from aws-powertools/hjgraca-disable-dependabot</li> <li>Merge pull request #464 from aws-powertools/hjgraca-release-1.7.0</li> <li>Merge pull request #451 from aws-powertools/dependabot/pip/gitpython-3.1.35</li> <li>Merge pull request #340 from hjgraca/fix-common-dependency</li> <li>Merge pull request #437 from aws-powertools/update-changelog-6143683791</li> <li>Merge pull request #435 from amirkaws/release-version-1.6.0-update-examples</li> </ul>"
        },
        {
            "location": "changelog/#160-2023-09-07",
            "title": "1.6.0 - 2023-09-07",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_25",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #433 from amirkaws/release-version-1.6.0-in-preview-fix</li> <li>Merge pull request #432 from amirkaws/release-version-1.6.0-document-fix</li> <li>Merge pull request #430 from amirkaws/release-version-1.6.0</li> <li>Merge pull request #428 from amirkaws/automatic-xray-register</li> <li>Merge pull request #400 from aws-powertools/hjgraca-fix-idempotency-docs</li> <li>Merge pull request #391 from aws-powertools/hjgraca-patch-dependabot</li> </ul>"
        },
        {
            "location": "changelog/#150-2023-08-29",
            "title": "1.5.0 - 2023-08-29",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_26",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #397 from aws-powertools/hjgraca-version-1.5.0</li> <li>Merge pull request #363 from hjgraca/idempotency-inprogressexpiration</li> </ul>"
        },
        {
            "location": "changelog/#142-2023-08-22",
            "title": "1.4.2 - 2023-08-22",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_10",
            "title": "Maintenance",
            "text": "<ul> <li>deps: bump AWSSDK.SecretsManager in /libraries</li> <li>deps: bump xunit from 2.4.1 to 2.4.2 in /libraries</li> <li>deps: bump Moq from 4.18.1 to 4.18.4 in /libraries</li> <li>deps: bump AWSSDK.DynamoDBv2 in /libraries</li> <li>deps: bump Testcontainers from 3.2.0 to 3.3.0 in /libraries</li> <li>deps: bump AWSXRayRecorder.Core in /libraries</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_27",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #388 from amirkaws/update-samples-nuget-versions</li> <li>Merge pull request #383 from aws-powertools/hjgraca-patch-version-1.4.2</li> <li>Merge pull request #381 from aws-powertools/hjgraca-patch-dependabot</li> <li>Merge pull request #375 from amirkaws/custom-log-formatter</li> <li>Merge pull request #357 from hjgraca/fix-capture-stacktrace</li> <li>Merge pull request #343 from aws-powertools/update-changelog-5462167625</li> <li>Merge pull request #370 from amirkaws/replace-moq-with-nsubstitute</li> <li>Merge pull request #359 from aws-powertools/dependabot/nuget/libraries/develop/AWSSDK.SecretsManager-3.7.200.3</li> <li>Merge pull request #342 from hjgraca/idempotency-simpler-example</li> <li>Merge pull request #347 from hjgraca/docs-clarify-xray-over-adot</li> <li>Merge pull request #338 from aws-powertools/hjgraca-patch-boring-cyborg</li> <li>Merge pull request #349 from hossambarakat/feature/idempotent-function</li> <li>Merge pull request #328 from aws-powertools/dependabot/nuget/libraries/develop/xunit-2.4.2</li> <li>Merge pull request #327 from aws-powertools/dependabot/nuget/libraries/develop/AWSSDK.DynamoDBv2-3.7.104.1</li> <li>Merge pull request #325 from aws-powertools/dependabot/nuget/libraries/develop/AWSXRayRecorder.Core-2.14.0</li> <li>Merge pull request #326 from aws-powertools/dependabot/nuget/libraries/develop/Testcontainers-3.3.0</li> <li>Merge pull request #329 from aws-powertools/dependabot/nuget/libraries/develop/Moq-4.18.4</li> </ul>"
        },
        {
            "location": "changelog/#141-2023-06-29",
            "title": "1.4.1 - 2023-06-29",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_11",
            "title": "Maintenance",
            "text": "<ul> <li>remove GH pages</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_28",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #318 from aws-powertools/hjgraca-dependabot-location</li> <li>Merge pull request #324 from amirkaws/release-version-1.4.1</li> <li>Merge pull request #320 from aws-powertools/hjgraca-idempotency-example-fix</li> <li>Merge pull request #319 from aws-powertools/hjgraca-idempotency-example-DynamoDBv2-version</li> <li>Merge pull request #312 from hjgraca/metrics-prevent-exceed-100-datapoint</li> <li>Merge pull request #317 from aws-powertools/hjgraca-add-dependabot</li> <li>Merge pull request #300 from hossambarakat/feature/idempotency-example</li> <li>Merge pull request #298 from amirkaws/parameters-example</li> <li>Merge pull request #315 from aws-powertools/url-updates</li> <li>Merge pull request #314 from aws-powertools/readme-updates</li> <li>Merge pull request #313 from hjgraca/metrics-addmetric-raceconditiom</li> <li>Merge pull request #287 from swimming-potato/develop</li> <li>Merge pull request #303 from aws-powertools/remove-gh-pages</li> <li>Merge pull request #308 from aws-powertools/update-changelog-5332675096</li> </ul>"
        },
        {
            "location": "changelog/#140-2023-06-21",
            "title": "1.4.0 - 2023-06-21",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_2",
            "title": "Bug Fixes",
            "text": "<ul> <li>update team name</li> <li>update references</li> <li>updated codeowners</li> <li>reapplying some lins that got screwed up in the merge</li> </ul>"
        },
        {
            "location": "changelog/#documentation_4",
            "title": "Documentation",
            "text": "<ul> <li>adding permission</li> </ul>"
        },
        {
            "location": "changelog/#features_3",
            "title": "Features",
            "text": "<ul> <li>docs: Start S3 Docs</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_12",
            "title": "Maintenance",
            "text": "<ul> <li>updated code owners</li> <li>Change repo URL to the new location</li> <li>rename project to Powertools for AWS Lambda (.NET)</li> <li>ci: updated links to new repo</li> <li>ci: removed unnecessary areas</li> <li>docs: fix we made this link</li> <li>docs: update docs homepage with additional features, fixed dot cli commands, new SAM cli instructions</li> <li>docs: updated readme with idempotency package and examples for parameters and idempotency</li> <li>docs: move idempotency</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_29",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #305 from aws-powertools/version-bump-1.4</li> <li>Merge pull request #301 from sliedig/sliedig-docs</li> <li>Merge pull request #302 from aws-powertools/rename-part2</li> <li>Merge pull request #291 from aws-powertools/doc-updates-roadmap</li> <li>Merge pull request #285 from aws-powertools/url-rename</li> <li>Merge pull request #293 from glynn1211/develop</li> <li>Merge pull request #163 from hossambarakat/feature/idempotency</li> <li>Merge pull request #282 from awslabs/rename</li> <li>Merge pull request #277 from awslabs/update-changelog-4981653012</li> <li>Merge pull request #274 from awslabs/dependabot/pip/pymdown-extensions-10.0</li> <li>Merge pull request #276 from awslabs/pymdown-extension-fix</li> <li>Merge pull request #278 from awslabs/s3-docs</li> <li>Merge pull request #273 from leandrodamascena/parameters/docs</li> <li>Merge pull request #271 from amirkaws/amirkaws-fix-parameters-nuget-icon</li> </ul>"
        },
        {
            "location": "changelog/#130-2023-05-12",
            "title": "1.3.0 - 2023-05-12",
            "text": ""
        },
        {
            "location": "changelog/#documentation_5",
            "title": "Documentation",
            "text": "<ul> <li>fixed formatting and updated content</li> </ul>"
        },
        {
            "location": "changelog/#features_4",
            "title": "Features",
            "text": "<ul> <li>add package readme</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_13",
            "title": "Maintenance",
            "text": "<ul> <li>ci: skip analytics on forks</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_30",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #268 from amirkaws/amirkaws-release-version-1.3.0</li> <li>Merge pull request #167 from amirkaws/amirkaws-feature-parameters</li> <li>Merge pull request #1 from sliedig/amirkaws-feature-parameters</li> <li>Merge pull request #264 from awslabs/chore(ci)-skip-analytics-on-forks</li> <li>Merge pull request #262 from awslabs/chorebump-version-1.2.0-release</li> </ul>"
        },
        {
            "location": "changelog/#120-2023-05-05",
            "title": "1.2.0 - 2023-05-05",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_31",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #258 from amirkaws/amirkaws-release-version-1.2.0</li> <li>Merge pull request #226 from hjgraca/feat_support_high_resolution_metrics</li> </ul>"
        },
        {
            "location": "changelog/#110-2023-05-05",
            "title": "1.1.0 - 2023-05-05",
            "text": ""
        },
        {
            "location": "changelog/#maintenance_14",
            "title": "Maintenance",
            "text": "<ul> <li>add Lambda Powertools for Python in issue templates</li> <li>add workflow to dispatch analytics fetching</li> <li>ci: add workflow to dispatch analytics fetching</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_32",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #255 from awslabs/fix-remove-real-env-tests</li> <li>Merge pull request #253 from amirkaws/amirkaws-release-v1.1.0</li> <li>Merge pull request #246 from hjgraca/feat_set-execution-context</li> <li>Merge pull request #251 from leandrodamascena/issues-templates/python</li> <li>Merge pull request #241 from awslabs/update-changelog-4691350388</li> <li>Merge pull request #237 from hjgraca/changelog-update-pipeline</li> <li>Merge pull request #235 from amirkaws/amirkaws-update-examples-nuget-references-release-v1.0.1</li> </ul>"
        },
        {
            "location": "changelog/#v101-2023-04-06",
            "title": "v1.0.1 - 2023-04-06",
            "text": ""
        },
        {
            "location": "changelog/#pull-requests_33",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #232 from amirkaws/amirkaws-release-v1.0.1</li> <li>Merge pull request #227 from hjgraca/chore_fix_changelog_build</li> <li>Merge pull request #225 from srcsakthivel/develop</li> <li>Merge pull request #223 from hjgraca/fix_tracing_on_exception_thrown</li> <li>Merge pull request #218 from amirkaws/amirkaws-update-examples-nuget-references-release</li> </ul>"
        },
        {
            "location": "changelog/#v100-2023-02-24",
            "title": "v1.0.0 - 2023-02-24",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_3",
            "title": "Bug Fixes",
            "text": "<ul> <li>removing manual trigger on docs wf</li> </ul>"
        },
        {
            "location": "changelog/#documentation_6",
            "title": "Documentation",
            "text": "<ul> <li>home: update powertools definition</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_15",
            "title": "Maintenance",
            "text": "<ul> <li>ci: api docs build update (#188)</li> <li>ci: changing trigger to run manually</li> <li>ci: updated api docs implementation</li> <li>ci: updated bug report template</li> <li>deps: updates sample deps</li> <li>docs: incorrect crefs</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_34",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #215 from amirkaws/amirkaws-release-v1.0.0</li> <li>Merge pull request #208 from amirkaws/amirkaws-cold-start-capture-warning-bug-fix</li> <li>Merge pull request #210 from awslabs/powertools-definition-update</li> <li>Merge pull request #209 from amirkaws/amirkaws-metrics-timestamp-fix</li> <li>Merge pull request #199 from awslabs/sliedig-ci-reviewers</li> <li>Merge pull request #193 from hjgraca/maintenance-new-issue-template</li> <li>Merge pull request #202 from hjgraca/fix-test-json-escaping</li> <li>Merge pull request #195 from hjgraca/update-dotnet-sdk-6.0.405</li> <li>Merge pull request #194 from hjgraca/patch-1</li> <li>Merge pull request #192 from hjgraca/fix-incorrect-crefs</li> <li>Merge pull request #189 from sliedig/develop</li> <li>Merge pull request #185 from amirkaws/amirkaws-update-examples-nuget-references</li> <li>Merge pull request #183 from awslabs/develop</li> <li>Merge pull request #150 from awslabs/develop</li> <li>Merge pull request #140 from awslabs/develop</li> </ul>"
        },
        {
            "location": "changelog/#v002-preview-2023-01-18",
            "title": "v0.0.2-preview - 2023-01-18",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_4",
            "title": "Bug Fixes",
            "text": "<ul> <li>removed duplicate template issue</li> <li>updated logger casing env vars in samples</li> </ul>"
        },
        {
            "location": "changelog/#documentation_7",
            "title": "Documentation",
            "text": "<ul> <li>typo in metrics README</li> </ul>"
        },
        {
            "location": "changelog/#features_5",
            "title": "Features",
            "text": "<ul> <li>ci: codeql static code analysis (#148)</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_16",
            "title": "Maintenance",
            "text": "<ul> <li>updated setup-dotnet@v1 to @v3</li> <li>updated packages (#172)</li> <li>ci: bumped version</li> <li>ci: minor updates, licensing</li> <li>deps: bump gitpython from 3.1.29 to 3.1.30</li> <li>docs: updated documentation (#175)</li> <li>docs: add discord invitation link</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_35",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #182 from sliedig/develop</li> <li>Merge pull request #181 from awslabs/dependabot/pip/gitpython-3.1.30</li> <li>Merge pull request #179 from sliedig/sliedig-ci</li> <li>Merge pull request #174 from sliedig/sliedig-ci</li> <li>Merge pull request #173 from sliedig/sliedig-samples</li> <li>Merge pull request #157 from kenfdev/fix-readme-title-typo</li> <li>Merge pull request #170 from nCubed/develop</li> <li>Merge pull request #152 from amirkaws/amirkaws-custom-exception-json-converter</li> <li>Merge pull request #155 from sthuber90/add-discord-link-154</li> <li>Merge pull request #147 from amirkaws/amirkaws-fix-doc-links</li> </ul>"
        },
        {
            "location": "changelog/#v001-preview1-2022-08-01",
            "title": "v0.0.1-preview.1 - 2022-08-01",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_5",
            "title": "Bug Fixes",
            "text": "<ul> <li>force directy rename</li> <li>making test function compile.</li> <li>updating issue templates with correct extention</li> <li>updated auto assign</li> <li>skip duplicate nuget packages publish</li> <li>added missing runtimes</li> <li>updated Logging template description</li> <li>updated documentation and doc generation (#96)</li> <li>removed optional doc file paths</li> <li>explicitly adding doc files for build configurations</li> <li>resolving dependecy alert CVE-2020-8116</li> <li>added missing codecov packages for test projects</li> <li>fixed build</li> <li>forcing rename</li> <li>fixed powertolls spelling in docs</li> <li>replaced PackageIconUrl which is being depreciated with PackageIcon</li> <li>added missing include to pack README files</li> <li>fixing node vulnerabilites for docs</li> <li>resolving merge conflict</li> <li>update packages to resolve vulnerabilities. Switched to yarn package manager</li> <li>intermin fix to resolve vulnerability issues.</li> <li>proj references</li> <li>fixed spelling in libraries folder name</li> <li>ci: lockdown gh-pages workflow to sha</li> </ul>"
        },
        {
            "location": "changelog/#documentation_8",
            "title": "Documentation",
            "text": "<ul> <li>fixed nav for roadmap</li> <li>updated link to feature request; added roadmap</li> <li>library readme updates and minor updates  (#117)</li> <li>spell check with US-English dictionary (#115)</li> <li>docs review (#112)</li> <li>Reviewing documentation (#68)</li> <li>adding auto-generated API Reference to docs (#87)</li> <li>alternative brew installation (#86)</li> <li>homebrew installation (#85)</li> <li>merging api generation tasks (#84)</li> <li>fixing docfx path (#83)</li> <li>fix docfx path (#82)</li> <li>fix api docs generator installation (#81)</li> <li>update github actions to publish api docs (#80)</li> <li>API docs generation (#79)</li> </ul>"
        },
        {
            "location": "changelog/#features_6",
            "title": "Features",
            "text": "<ul> <li>added security.md</li> <li>updated record_pr action</li> <li>PR Labeler GitHub actions (#119)</li> <li>Logger output case attributes docs and unit testing (#100)</li> <li>add extra fields to the logger methods (#98)</li> <li>updated examples to include managed runtime configuration as well as docker. Made updates to Tracing implementation</li> <li>added Tracing example</li> <li>added init Metrics sample</li> <li>added Logging example</li> <li>added serialisation options to force dictionary keys to camel case</li> <li>added build tools to generate nuget packages</li> <li>updated project packaging properties</li> <li>added package README files for core utilities</li> <li>update make and doc dep to build docs</li> <li>added docs template</li> </ul>"
        },
        {
            "location": "changelog/#maintenance_17",
            "title": "Maintenance",
            "text": "<ul> <li>set global .net version</li> <li>temporarily removing docs while content is being developed</li> <li>added example project</li> <li>refctored PowerTools to Powertools</li> <li>added github files and templates</li> <li>initial folder structure</li> <li>interim resolution of docs package vulnerabilities</li> <li>migrated AWS.Lambda.PowerTools to AWS.Lambda.PowerTools.Common namespace. fix: resolved incorrect namespace for Tracing fix: resolved dependencies in example project</li> <li>refactored to new namespace</li> <li>updated readme</li> <li>updated github templates</li> <li>added customer 404 page</li> <li>removing unecessary buildtools</li> <li>update pr template</li> <li>updating type documentation and file headers (#56)</li> <li>moved solution file into libraries. Need a separate solution for examples</li> <li>added docs</li> <li>added gitignore and updated licence</li> <li>updating doc build workflow</li> <li>updated issue templates</li> <li>updated Label PR based on title action</li> <li>deleted unnecessay publishing action</li> <li>updated stale action</li> <li>removed unnecessary pr labeling</li> <li>updated PR labeling path</li> <li>updated list of assignees</li> <li>updated docker builds to use Amazon.Lambda.Tools (#118)</li> <li>bumped .net version in global to 6.0.301 (#120)</li> <li>bumped .net version in global to 6.0.301</li> <li>adding missed copyright info</li> <li>added copyright to examples</li> <li>removed SimpleLambda from examples</li> <li>cleaned up logging and metrics functions</li> <li>ci: add on_merge_pr workflow to notify releases</li> <li>ci: lockdown untrusted workflows to sha</li> <li>ci: add missing scripts</li> <li>ci: updated bug report template (#144)</li> <li>ci: add workflow to detect missing related issue</li> <li>ci: enable concurrency group for docs workflow</li> <li>ci: upudated wording in PR template checklist</li> <li>ci: added codeowners</li> <li>ci: added Maintainers doc</li> <li>ci: updated PR workflows and scripts</li> <li>ci: upgrade setup-python to v4</li> <li>ci: upgrade checkout action to v3</li> <li>ci: use untrusted workflows with sha</li> <li>ci: add reusable export pr workflow dependency</li> <li>deps: bump hosted-git-info from 2.8.8 to 2.8.9 in /docs</li> <li>deps: bump object-path from 0.11.4 to 0.11.5 in /docs</li> <li>deps: bump ssri from 6.0.1 to 6.0.2 in /docs</li> <li>deps: bump elliptic from 6.5.3 to 6.5.4 in /docs</li> <li>deps: bump socket.io from 2.3.0 to 2.4.1 in /docs</li> <li>deps: bump ini from 1.3.5 to 1.3.8 in /docs</li> <li>deps: bump ua-parser-js from 0.7.23 to 0.7.28 in /docs</li> <li>deps: bump underscore from 1.12.0 to 1.13.1 in /docs</li> <li>deps: bump url-parse from 1.4.7 to 1.5.1 in /docs</li> <li>deps: bump prismjs from 1.20.0 to 1.21.0 in /docs</li> <li>deps: updates sample deps (#142)</li> <li>deps: bump mkdocs from 1.2.2 to 1.2.3 (#29)</li> <li>governance: render debug logs with csharp syntax</li> <li>governance: typo in pending release label name</li> </ul>"
        },
        {
            "location": "changelog/#pull-requests_36",
            "title": "Pull Requests",
            "text": "<ul> <li>Merge pull request #139 from awslabs/amirkaws-resolve-conflicts-2</li> <li>Merge pull request #135 from awslabs/amirkaws-update-versions</li> <li>Merge pull request #134 from heitorlessa/chore/lockdown-gh-pages-workflow</li> <li>Merge pull request #132 from heitorlessa/chore/github-concurrency-docs</li> <li>Merge pull request #130 from heitorlessa/chore/enforce-github-actions-sha</li> <li>Merge pull request #128 from sliedig/sliedig-ci</li> <li>Merge pull request #127 from sliedig/sliedig-ci</li> <li>Merge pull request #126 from sliedig/develop</li> <li>Merge pull request #123 from sliedig/develop</li> <li>Merge pull request #1 from sliedig/sliedig/develop</li> <li>Merge pull request #121 from awslabs/amirkaws-update-versions</li> <li>Merge pull request #116 from awslabs/amirkaws/add-di-support-for-logging</li> <li>Merge pull request #113 from awslabs/amirkaws/update-doc-1</li> <li>Merge pull request #111 from awslabs/amirkaws/add-env-vars-docs</li> <li>Merge pull request #102 from sliedig/sliedig/examples</li> <li>Merge pull request #103 from awslabs/amirkaws/fix-example-issues</li> <li>Merge pull request #97 from sliedig/sliedig/examples</li> <li>Merge pull request #95 from awslabs/pr/91</li> <li>Merge pull request #90 from sliedig/develop</li> <li>Merge pull request #89 from awslabs/api-docs-template</li> <li>Merge pull request #74 from awslabs/amirkaws/disable-tracing-outside-lambda-env</li> <li>Merge pull request #66 from sliedig/develop</li> <li>Merge pull request #59 from sliedig/develop</li> <li>Merge pull request #58 from sliedig/sliedig/nuget</li> <li>Merge pull request #32 from awslabs/amirkaws/metrics-1</li> <li>Merge pull request #31 from t1agob/develop</li> <li>Merge pull request #2 from awslabs/develop</li> <li>Merge pull request #25 from t1agob/develop</li> <li>Merge pull request #1 from t1agob/sourcegenerators</li> <li>Merge pull request #24 from sliedig/develop</li> <li>Merge pull request #23 from sliedig/develop</li> <li>Merge pull request #22 from sliedig/develop</li> <li>Merge pull request #21 from t1agob/develop</li> <li>Merge pull request #19 from awslabs/dependabot/npm_and_yarn/docs/url-parse-1.5.1</li> <li>Merge pull request #18 from awslabs/dependabot/npm_and_yarn/docs/hosted-git-info-2.8.9</li> <li>Merge pull request #17 from awslabs/dependabot/npm_and_yarn/docs/ua-parser-js-0.7.28</li> <li>Merge pull request #16 from awslabs/dependabot/npm_and_yarn/docs/underscore-1.13.1</li> <li>Merge pull request #15 from awslabs/dependabot/npm_and_yarn/docs/ssri-6.0.2</li> <li>Merge pull request #14 from awslabs/dependabot/npm_and_yarn/docs/elliptic-6.5.4</li> <li>Merge pull request #13 from sliedig/develop</li> <li>Merge pull request #12 from sliedig/develop</li> <li>Merge pull request #11 from awslabs/dependabot/npm_and_yarn/docs/socket.io-2.4.1</li> <li>Merge pull request #10 from awslabs/dependabot/npm_and_yarn/docs/ini-1.3.8</li> <li>Merge pull request #9 from awslabs/dependabot/npm_and_yarn/docs/object-path-0.11.5</li> <li>Merge pull request #7 from t1agob/develop</li> <li>Merge pull request #8 from sliedig/develop</li> <li>Merge pull request #5 from sliedig/develop</li> <li>Merge pull request #4 from sliedig/develop</li> <li>Merge pull request #3 from sliedig/develop</li> <li>Merge pull request #2 from awslabs/dependabot/npm_and_yarn/docs/prismjs-1.21.0</li> <li>Merge pull request #1 from sliedig/develop</li> </ul>"
        },
        {
            "location": "references/",
            "title": "Powertools for AWS Lambda (.NET) references",
            "text": ""
        },
        {
            "location": "references/#environment-variables",
            "title": "Environment variables",
            "text": "<p>Info</p> <p>Explicit parameters take precedence over environment variables.</p> Environment variable Description Utility Default POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging All <code>\"service_undefined\"</code> POWERTOOLS_LOG_LEVEL Sets logging level Logging <code>Information</code> POWERTOOLS_LOGGER_CASE Override the default casing for log keys Logging <code>SnakeCase</code> POWERTOOLS_LOGGER_LOG_EVENT Logs incoming event Logging <code>false</code> POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling Logging <code>0</code> POWERTOOLS_METRICS_NAMESPACE Sets namespace used for metrics Metrics <code>None</code> POWERTOOLS_TRACE_DISABLED Disables tracing Tracing <code>false</code> POWERTOOLS_TRACER_CAPTURE_RESPONSE Captures Lambda or method return as metadata. Tracing <code>true</code> POWERTOOLS_TRACER_CAPTURE_ERROR Captures Lambda or method exception as metadata. Tracing <code>true</code>"
        },
        {
            "location": "references/#sam-template-snippets",
            "title": "SAM template snippets",
            "text": ""
        },
        {
            "location": "references/#logging",
            "title": "Logging",
            "text": "<pre><code># Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: MIT-0\nAWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: &gt;\n  Example project for Powertools for AWS Lambda (.NET) Logging utility\n\n# More info about Globals: https://github.com/awslabs/serverless-application-model/blob/master/docs/globals.rst\nGlobals:\n  Function:\n    Timeout: 10\n    Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: powertools-dotnet-logging-sample\n        POWERTOOLS_LOG_LEVEL: Debug\n        POWERTOOLS_LOGGER_LOG_EVENT: true\n        POWERTOOLS_LOGGER_CASE: PascalCase # Allowed values are: CamelCase, PascalCase and SnakeCase\n        POWERTOOLS_LOGGER_SAMPLE_RATE: 0\n</code></pre>"
        },
        {
            "location": "references/#metrics",
            "title": "Metrics",
            "text": "<pre><code># Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: MIT-0\nAWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: &gt;\n  Example project for Powertools for AWS Lambda (.NET) Metrics utility\n\n# More info about Globals: https://github.com/awslabs/serverless-application-model/blob/master/docs/globals.rst\nGlobals:\n  Function:\n    Timeout: 10\n    Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: powertools-dotnet-metrics-sample # This can also be set using the Metrics decorator on your handler [Metrics(Namespace = \"aws-lambda-powertools\"]\n        POWERTOOLS_METRICS_NAMESPACE: AWSLambdaPowertools # This can also be set using the Metrics decorator on your handler [Metrics(Namespace = \"aws-lambda-powertools\"]\n</code></pre>"
        },
        {
            "location": "references/#tracing",
            "title": "Tracing",
            "text": "<pre><code># Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: MIT-0\nAWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: &gt;\n  Example project for Powertools for AWS Lambda (.NET) tracing utility\n\n# More info about Globals: https://github.com/awslabs/serverless-application-model/blob/master/docs/globals.rst\nGlobals:\n  Function:\n    Timeout: 10\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: powertools-dotnet-tracing-sample\n        POWERTOOLS_TRACE_DISABLED: true\n        POWERTOOLS_TRACER_CAPTURE_RESPONSE: true\n        POWERTOOLS_TRACER_CAPTURE_ERROR: true     # To disable tracing (CaptureMode = TracingCaptureMode.Disabled)\n</code></pre>"
        },
        {
            "location": "roadmap/",
            "title": "Roadmap",
            "text": ""
        },
        {
            "location": "roadmap/#overview",
            "title": "Overview",
            "text": "<p>Our public roadmap outlines the high level direction we are working towards. We update this document when our priorities change: security and stability are our top priority.</p> <p>For most up-to-date information, see our board of activities.</p>"
        },
        {
            "location": "roadmap/#key-areas",
            "title": "Key areas",
            "text": "<p>Security and operational excellence take precedence above all else. This means bug fixing, stability, customer's support, and internal compliance may delay one or more key areas below.</p> <p>Missing something or want us to prioritize an existing area?</p> <p>You can help us prioritize by upvoting existing feature requests, leaving a comment on what use cases it could unblock for you, and by joining our discussions on Discord.</p> <p></p>"
        },
        {
            "location": "roadmap/#core-utilities-p0",
            "title": "Core Utilities (P0)",
            "text": ""
        },
        {
            "location": "roadmap/#logging-v2",
            "title": "Logging V2",
            "text": "<p>Modernizing our logging capabilities to align with .NET practices and improve developer experience.</p> <ul> <li> Logger buffer implementation</li> <li> New .NET-friendly API design (Serilog-like patterns)</li> <li> Filtering and JMESPath expression support</li> <li> Documentation for SDK context.Logger vs Powertools Logger differences</li> </ul>"
        },
        {
            "location": "roadmap/#metrics-v2",
            "title": "Metrics V2",
            "text": "<p>Updating metrics implementation to support latest EMF specifications and improve performance.</p> <ul> <li> Update to latest EMF specifications</li> <li> Breaking changes implementation for multiple dimensions</li> <li> Add support for default dimensions on ColdStart metric</li> <li> API updates - missing functionality that is present in Python implementation (ie: flush_metrics)</li> </ul>"
        },
        {
            "location": "roadmap/#security-and-production-readiness-p1",
            "title": "Security and Production Readiness (P1)",
            "text": "<p>Ensuring enterprise-grade security and compatibility with latest .NET developments.</p> <ul> <li> .NET 10 support from day one</li> <li> Deprecation path for .NET 6</li> <li> Scorecard implementation</li> <li> Security compliance checks on our pipeline</li> <li> All utilities with end-to-end tests in our pipeline</li> </ul>"
        },
        {
            "location": "roadmap/#feature-parity-and-aspnet-support-p2",
            "title": "Feature Parity and ASP.NET Support (P2)",
            "text": ""
        },
        {
            "location": "roadmap/#feature-parity",
            "title": "Feature Parity",
            "text": "<p>Implementing key features to achieve parity with other Powertools implementations.</p> <ul> <li> Data masking</li> <li> Feature Flags</li> <li> S3 Streaming support</li> </ul>"
        },
        {
            "location": "roadmap/#aspnet-support",
            "title": "ASP.NET Support",
            "text": "<p>Adding first-class support for ASP.NET Core in Lambda with performance considerations.</p> <ul> <li> AspNetCoreServer.Hosting - Tracking issue</li> <li> Minimal APIs support</li> <li> ASP.NET Core integration</li> <li> Documentation for cold start impacts</li> <li> Clear guidance on Middleware vs. Decorators usage</li> </ul>"
        },
        {
            "location": "roadmap/#improve-operational-excellence",
            "title": "Improve operational excellence",
            "text": "<p>We continue to work on increasing operational excellence to remove as much undifferentiated heavylifting for maintainers, so that we can focus on delivering features that help you.</p> <p>This means improving our automation workflows, and project management, and test coverage.</p>"
        },
        {
            "location": "roadmap/#roadmap-status-definition",
            "title": "Roadmap status definition",
            "text": "<p> <pre><code>graph LR\n    Ideas --&gt; Backlog --&gt; Work[\"Working on it\"] --&gt; Merged[\"Coming soon\"] --&gt; Shipped</code></pre> Visual representation </p> <p>Within our public board, you'll see the following values in the <code>Status</code> column:</p> <ul> <li>Ideas. Incoming and existing feature requests that are not being actively considered yet. These will be reviewed when bandwidth permits and based on demand.</li> <li>Backlog. Accepted feature requests or enhancements that we want to work on.</li> <li>Working on it. Features or enhancements we're currently either researching or implementing it.</li> <li>Coming soon. Any feature, enhancement, or bug fixes that have been merged and are coming in the next release.</li> <li>Shipped. Features or enhancements that are now available in the most recent release.</li> <li>On hold. Features or items that are currently blocked until further notice.</li> <li>Pending review. Features which implementation is mostly completed, but need review and some additional iterations.</li> </ul> <p>Tasks or issues with empty <code>Status</code> will be categorized in upcoming review cycles.</p>"
        },
        {
            "location": "roadmap/#process",
            "title": "Process",
            "text": "<p> <pre><code>graph LR\n    PFR[Feature request] --&gt; Triage{Need RFC?}\n    Triage --&gt; |Complex/major change or new utility?| RFC[Ask or write RFC] --&gt; Approval{Approved?}\n    Triage --&gt; |Minor feature or enhancement?| NoRFC[No RFC required] --&gt; Approval\n    Approval --&gt; |Yes| Backlog\n    Approval --&gt; |No | Reject[\"Inform next steps\"]\n    Backlog --&gt; |Prioritized| Implementation\n    Backlog --&gt; |Defer| WelcomeContributions[\"help-wanted label\"]</code></pre> Visual representation </p> <p>Our end-to-end mechanism follows four major steps:</p> <ul> <li>Feature Request. Ideas start with a feature request to outline their use case at a high level. For complex use cases, maintainers might ask for/write a RFC.</li> <li>Maintainers review requests based on project tenets, customers reaction (), and use cases.</li> <li>Request-for-comments (RFC). Design proposals use our RFC issue template to describe its implementation, challenges, developer experience, dependencies, and alternative solutions.</li> <li>This helps refine the initial idea with community feedback before a decision is made.</li> <li>Decision. After carefully reviewing and discussing them, maintainers make a final decision on whether to start implementation, defer or reject it, and update everyone with the next steps.</li> <li>Implementation. For approved features, maintainers give priority to the original authors for implementation unless it is a sensitive task that is best handled by maintainers.</li> </ul> See Maintainers document to understand how we triage issues and pull requests, labels and governance."
        },
        {
            "location": "roadmap/#disclaimer",
            "title": "Disclaimer",
            "text": "<p>The Powertools for AWS Lambda team values feedback and guidance from its community of users, although final decisions on inclusion into the project will be made by AWS.</p> <p>We determine the high-level direction for our open roadmap based on customer feedback and popularity ( and comments), security and operational impacts, and business value. Where features dont meet our goals and longer-term strategy, we will communicate that clearly and openly as quickly as possible with an explanation of why the decision was made.</p>"
        },
        {
            "location": "roadmap/#faqs",
            "title": "FAQs",
            "text": "<p>Q: Why did you build this?</p> <p>A: We know that our customers are making decisions and plans based on what we are developing, and we want to provide our customers the insights they need to plan.</p> <p>Q: Why are there no dates on your roadmap?</p> <p>A: Because job zero is security and operational stability, we can't provide specific target dates for features. The roadmap is subject to change at any time, and roadmap issues in this repository do not guarantee a feature will be launched as proposed.</p> <p>Q: How can I provide feedback or ask for more information?</p> <p>A: For existing features, you can directly comment on issues. For anything else, please open an issue.</p>"
        },
        {
            "location": "tenets/",
            "title": "Powertools for AWS Lambda (.NET)",
            "text": "<p>Core utilities such as Tracing, Logging, Metrics, and Event Handler will be available across all Powertools for AWS Lambda runtimes. Additional utilities are subjective to each language ecosystem and customer demand.</p> <ul> <li>AWS Lambda only. We optimize for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported.</li> <li>Eases the adoption of best practices. The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional.</li> <li>Keep it lean. Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time.</li> <li>We strive for backwards compatibility. New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined.</li> <li>We work backwards from the community. We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs)</li> <li>Idiomatic. Utilities follow programming language idioms and language-specific best practices.</li> </ul>"
        },
        {
            "location": "we_made_this/",
            "title": "We Made This (Community)",
            "text": "<p>This space is dedicated to highlight our awesome community content featuring Powertools for AWS Lambda (.NET) !</p> <p>Get your content featured here!</p>"
        },
        {
            "location": "we_made_this/#connect",
            "title": "Connect",
            "text": "<p>Join us on Discord to connect with the Powertools for AWS Lambda community . Ask questions, learn from each other, contribute, hang out with key contributors, and more!</p> <p></p>"
        },
        {
            "location": "we_made_this/#videos",
            "title": "Videos",
            "text": "<p>Check out the great series of videos from Rahul Nath on Powertools for AWS Lambda (.NET). Rahul is a programmer, blogger, Microsoft MVP, AWS Community Builder and YouTuber! He loves teaching and try to explain 'Why we do, What we do' by going a level deeper in the things I teach. His YouTube channel has a lot of AWS content that you can what on his AWS .NET series.</p> <ul> <li> <p> Logging</p> <p></p> <p>The Powertools for AWS Lambda (.NET) Logging utility provides a Lambda-optimized logger to output JSON logs. In this video, let's learn how to get started with the Powertools for Lambda Logging utility when building Lambda Functions in .NET. </p> <p> Watch now</p> </li> <li> <p> Tracing</p> <p></p> <p>The Powertools for AWS Lambda (.NET) Tracing library is an opinionated wrapper for AWS X-Ray aimed to reduce the overhead of performing common tracing tasks. In this video lets explore how you can start using the Lambda Annotations library when building AWS Lambda Functions in .NET.</p> <p> Watch now</p> </li> <li> <p> Metrics</p> <p></p> <p>The Powertools for AWS Lambda (.NET) Metrics library makes publishing custom metrics from your AWS Lambda Function easy. In this video, let's learn how to easily integrate with Amazon CloudWatch Metrics and start publishing custom metrics from your .NET AWS Lambda Function.</p> <p> Watch now</p> </li> <li> <p> Parameters</p> <p></p> <p>The Powertools for AWS Lambda (.NET) Parameters library makes it easy to work with these different services and retrieve parameter values. In this video, lets learn how to get started using the Lambda Powertools Parameters NuGet package and how to use it when building Lambda Functions.</p> <p> Watch now</p> </li> <li> <p> Idempotency</p> <p></p> <p>The Powertools for AWS Lambda (.NET) Idempotency utility makes it easy to convert your Lambda functions into idempotent operations that are safe to retry. In this video, let's learn how to get started using the Powertools Idempotency package, some key features, and how it easily fits into your existing Lambda Functions.</p> <p> Watch now</p> </li> <li> <p> Batch Processing</p> <p></p> <p>The Powertools for AWS Lambda (.NET) Batch processing utility makes it easy to process a batch of messages from Amazon SQS, Amazon Kinesis Data Streams, and Amazon DynamoDB Streams. In this video, lets learn how to use the Lambda Powertools Batch processing utility to process messages in batches from Amazon SQS.</p> <p> Watch now</p> </li> </ul>"
        },
        {
            "location": "we_made_this/#workshops",
            "title": "Workshops",
            "text": ""
        },
        {
            "location": "we_made_this/#accelerate-your-serverless-journey-with-powertools-for-aws-lambda",
            "title": "Accelerate your serverless journey with Powertools for AWS Lambda",
            "text": "<p>Are you hoping to speed up your serverless applications with best practices and faster development? Powertools for AWS Lambda can help you reduce boilerplate code and increase developer velocity. In this workshop, learn how you can implement structured logging and tracing, operational and business metrics, and idempotency practices for a media processing application. Choose between Python, JavaScript/TypeScript, Java, or .NET when building your program.</p> <p> Explore workshop</p>"
        },
        {
            "location": "we_made_this/#aws-serverless-developer-experience-workshop-a-day-in-a-life-of-a-developer",
            "title": "AWS Serverless Developer Experience Workshop: A day in a life of a developer",
            "text": "<p>This advanced workshop teaches building serverless solutions with AWS SAM and AWS SAM CLI. Learn about event-driven architectures, messaging patterns, orchestration, observability, and Powertools for AWS Lambda, in four different runtimes. Explore open-source tools and simplified CI/CD deployments with SAM Pipelines.</p> <p> Explore workshop</p>"
        },
        {
            "location": "core/logging-v2/",
            "title": "Logging V2",
            "text": "<p>The logging utility provides a Lambda optimized logger with output structured as JSON.</p>"
        },
        {
            "location": "core/logging-v2/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Capture key fields from Lambda context, cold start and structures logging output as JSON</li> <li>Log Lambda event when instructed (disabled by default)</li> <li>Log sampling enables DEBUG log level for a percentage of requests (disabled by default)</li> <li>Append additional keys to structured log at any point in time</li> <li>Ahead-of-Time compilation to native code   support AOT</li> <li>Custom log formatter to override default log structure</li> <li>Support   for AWS Lambda Advanced Logging Controls (ALC)</li> <li>Support for Microsoft.Extensions.Logging   and ILogger   interface</li> <li>Support   for ILoggerFactory   interface</li> <li>Support for message templates <code>{}</code> and <code>{@}</code> for structured logging</li> </ul>"
        },
        {
            "location": "core/logging-v2/#installation",
            "title": "Installation",
            "text": "<p>Powertools for AWS Lambda (.NET) are available as NuGet packages. You can install the packages from NuGet Gallery or from Visual Studio editor by searching <code>AWS.Lambda.Powertools*</code> to see various utilities available.</p> <ul> <li>AWS.Lambda.Powertools.Logging:</li> </ul> <p><code>dotnet add package AWS.Lambda.Powertools.Logging</code></p>"
        },
        {
            "location": "core/logging-v2/#getting-started",
            "title": "Getting started",
            "text": "<p>Info</p> <p>AOT Support If loooking for AOT specific configurations navigate to the AOT section </p> <p>Logging requires two settings:</p> Setting Description Environment variable Attribute parameter Service Sets Service key that will be present across all log statements <code>POWERTOOLS_SERVICE_NAME</code> <code>Service</code> Logging level Sets how verbose Logger should be (Information, by default) <code>POWERTOOLS_LOG_LEVEL</code> <code>LogLevel</code>"
        },
        {
            "location": "core/logging-v2/#full-list-of-environment-variables",
            "title": "Full list of environment variables",
            "text": "Environment variable Description Default POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging <code>\"service_undefined\"</code> POWERTOOLS_LOG_LEVEL Sets logging level <code>Information</code> POWERTOOLS_LOGGER_CASE Override the default casing for log keys <code>SnakeCase</code> POWERTOOLS_LOGGER_LOG_EVENT Logs incoming event <code>false</code> POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling <code>0</code>"
        },
        {
            "location": "core/logging-v2/#setting-up-the-logger",
            "title": "Setting up the logger",
            "text": "<p>You can set up the logger in different ways. The most common way is to use the <code>Logging</code> attribute on your Lambda. You can also use the <code>ILogger</code> interface to log messages. This interface is part of the Microsoft.Extensions.Logging.</p> Using decoratorLogger FactoryWith Builder <pre><code>    /**\n     * Handler for requests to Lambda function.\n     */\n    public class Function\n    {\n        [Logging(Service = \"payment\", LogLevel = LogLevel.Debug)]\n        public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n            (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n        {\n            Logger.LogInformation(\"Collecting payment\");\n            ...\n        }\n    }\n</code></pre> <pre><code>    /**\n     * Handler for requests to Lambda function.\n     */\n    public class Function\n    {\n        private readonly ILogger _logger;\n\n        public Function(ILoggerFactory loggerFactory)\n        {\n            _logger = loggerFactory.Create(builder =&gt;\n            {\n                builder.AddPowertoolsLogger(config =&gt;\n                {\n                    config.Service = \"TestService\";\n                    config.LoggerOutputCase = LoggerOutputCase.PascalCase;\n                });\n            }).CreatePowertoolsLogger();\n        }\n\n        public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n            (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n        {\n            _logger.LogInformation(\"Collecting payment\");\n            ...\n        }\n    }\n</code></pre> <pre><code>    /**\n     * Handler for requests to Lambda function.\n     */\n    public class Function\n    {\n        private readonly ILogger _logger;\n\n        public Function(ILogger logger)\n        {\n            _logger = logger ?? new PowertoolsLoggerBuilder()\n                .WithService(\"TestService\")\n                .WithOutputCase(LoggerOutputCase.PascalCase)\n                .Build();\n        }\n\n        public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n            (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n        {\n            _logger.LogInformation(\"Collecting payment\");\n            ...\n        }\n    }\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#customizing-the-logger",
            "title": "Customizing the logger",
            "text": "<p>You can customize the logger by setting the following properties in the <code>Logger.Configure</code> method:</p> Property Description <code>Service</code> The name of the service. This is used to identify the service in the logs. <code>MinimumLogLevel</code> The minimum log level to log. This is used to filter out logs below the specified level. <code>LogFormatter</code> The log formatter to use. This is used to customize the structure of the log entries. <code>JsonOptions</code> The JSON options to use. This is used to customize the serialization of logs. <code>LogBuffering</code> The log buffering options. This is used to configure log buffering. <code>TimestampFormat</code> The format of the timestamp. This is used to customize the format of the timestamp in the logs. <code>SamplingRate</code> Sets a percentage (0.0 to 1.0) of logs that will be dynamically elevated to DEBUG level <code>LoggerOutputCase</code> The output casing of the logger. This is used to customize the casing of the log entries. <code>LogOutput</code> Specifies the console output wrapper used for writing logs. This property allows redirecting log output for testing or specialized handling scenarios."
        },
        {
            "location": "core/logging-v2/#configuration",
            "title": "Configuration",
            "text": "<p>You can configure Powertools Logger using the static <code>Logger</code> class. This class is a singleton and is created when the Lambda function is initialized. You can configure the logger using the <code>Logger.Configure</code> method.</p> Configure static Logger <pre><code>    public class Function\n    {\n        public Function()\n        {\n            Logger.Configure(options =&gt;\n            {\n                options.MinimumLogLevel = LogLevel.Information;\n                options.LoggerOutputCase = LoggerOutputCase.CamelCase;\n            });\n        }\n\n        public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n            (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n        {\n            Logger.LogInformation(\"Collecting payment\");\n            ...\n        }\n    }\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#ilogger",
            "title": "ILogger",
            "text": "<p>You can also use the <code>ILogger</code> interface to log messages. This interface is part of the Microsoft.Extensions.Logging. With this approach you get more flexibility and testability using dependency injection (DI).</p> Configure with LoggerFactory or Builder <pre><code>    public class Function\n    {\n        public Function(ILogger logger)\n        {\n            _logger = logger ?? LoggerFactory.Create(builder =&gt;\n            {\n                builder.AddPowertoolsLogger(config =&gt;\n                {\n                    config.Service = \"TestService\";\n                    config.LoggerOutputCase = LoggerOutputCase.PascalCase;\n                });\n            }).CreatePowertoolsLogger();\n        }\n\n        public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n            (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n        {\n            Logger.LogInformation(\"Collecting payment\");\n            ...\n        }\n    }\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#standard-structured-keys",
            "title": "Standard structured keys",
            "text": "<p>Your logs will always include the following keys to your structured logging:</p> Key Type Example Description Level string \"Information\" Logging level Message string \"Collecting payment\" Log statement value. Unserializable JSON values will be cast to string Timestamp string \"2020-05-24 18:17:33,774\" Timestamp of actual log statement Service string \"payment\" Service name defined. \"service_undefined\" will be used if unknown ColdStart bool true ColdStart value. FunctionName string \"example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" FunctionMemorySize string \"128\" FunctionArn string \"arn:aws:lambda:eu-west-1:012345678910:function:example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" FunctionRequestId string \"899856cb-83d1-40d7-8611-9e78f15f32f4\" AWS Request ID from lambda context FunctionVersion string \"12\" XRayTraceId string \"1-5759e988-bd862e3fe1be46a994272793\" X-Ray Trace ID when Lambda function has enabled Tracing Name string \"Powertools for AWS Lambda (.NET) Logger\" Logger name SamplingRate int 0.1 Debug logging sampling rate in percentage e.g. 10% in this case Customer Keys"
        },
        {
            "location": "core/logging-v2/#message-templates",
            "title": "Message templates",
            "text": "<p>You can use message templates to extract properties from your objects and log them as structured data.</p> <p>Info</p> <p>Override the <code>ToString()</code> method of your object to return a meaningful string representation of the object.</p> <p>This is especially important when using <code>{}</code> to log the object as a string.</p> <pre><code>    public class User\n    {\n        public string FirstName { get; set; }\n        public string LastName { get; set; }\n        public int Age { get; set; }\n\n        public override string ToString()\n        {\n            return $\"{LastName}, {FirstName} ({Age})\";\n        }\n    }\n</code></pre> <p>If you want to log the object as a JSON object, use <code>{@}</code>. This will serialize the object and log it as a JSON object.</p> Message template {@}{@} Output <pre><code>    public class Function\n    {\n        [Logging(Service = \"user-service\", LogLevel = LogLevel.Information)]\n        public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n            (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n        {\n            var user = new User\n            {\n                FirstName = \"John\",\n                LastName = \"Doe\",\n                Age = 42\n            };\n\n            logger.LogInformation(\"User object: {@user}\", user);\n            ...\n        }\n    }\n</code></pre> <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"User object: Doe, John (42)\",\n    \"timestamp\": \"2025-04-07 09:06:30.708\",\n    \"service\": \"user-service\",\n    \"coldStart\": true,\n    \"name\": \"AWS.Lambda.Powertools.Logging.Logger\",\n    \"user\": {\n        \"firstName\": \"John\",\n        \"lastName\": \"Doe\",\n        \"age\": 42\n    },\n    ...\n}\n</code></pre> <p>If you want to log the object as a string, use <code>{}</code>. This will call the <code>ToString()</code> method of the object and log it as a string.</p> Message template {} ToStringOutput {} ToString <pre><code>    public class Function\n    {\n        [Logging(Service = \"user\", LogLevel = LogLevel.Information)]\n        public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n            (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n        {\n            var user = new User\n            {\n                FirstName = \"John\",\n                LastName = \"Doe\",\n                Age = 42\n            };\n\n            logger.LogInformation(\"User data: {user}\", user);\n\n            // Also works with numbers, dates, etc.\n\n            logger.LogInformation(\"Price: {price:0.00}\", 123.4567); // will respect decimal places\n            logger.LogInformation(\"Percentage: {percent:0.0%}\", 0.1234);\n            ...\n        }\n    }\n</code></pre> <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"User data: Doe, John (42)\",\n    \"timestamp\": \"2025-04-07 09:06:30.689\",\n    \"service\": \"user-servoice\",\n    \"coldStart\": true,\n    \"name\": \"AWS.Lambda.Powertools.Logging.Logger\",\n    \"user\": \"Doe, John (42)\"\n}\n{\n    \"level\": \"Information\",\n    \"message\": \"Price: 123.46\",\n    \"timestamp\": \"2025-04-07 09:23:01.235\",\n    \"service\": \"user-servoice\",\n    \"cold_start\": true,\n    \"name\": \"AWS.Lambda.Powertools.Logging.Logger\",\n    \"price\": 123.46\n}\n{\n    \"level\": \"Information\",\n    \"message\": \"Percentage: 12.3%\",\n    \"timestamp\": \"2025-04-07 09:23:01.260\",\n    \"service\": \"user-servoice\",\n    \"cold_start\": true,\n    \"name\": \"AWS.Lambda.Powertools.Logging.Logger\",\n    \"percent\": \"12.3%\"\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#logging-incoming-event",
            "title": "Logging incoming event",
            "text": "<p>When debugging in non-production environments, you can instruct Logger to log the incoming event with <code>LogEvent</code> parameter or via <code>POWERTOOLS_LOGGER_LOG_EVENT</code> environment variable.</p> <p>Warning</p> <p>Log event is disabled by default to prevent sensitive info being logged.</p> Function.cs <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(LogEvent = true)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#setting-a-correlation-id",
            "title": "Setting a Correlation ID",
            "text": "<p>You can set a Correlation ID using <code>CorrelationIdPath</code> parameter by passing a JSON Pointer expression.</p> <p>Attention</p> <p>The JSON Pointer expression is <code>case sensitive</code>. In the bellow example <code>/headers/my_request_id_header</code> would work but <code>/Headers/my_request_id_header</code> would not find the element.</p> Function.csExample EventExample CloudWatch Logs excerpt <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(CorrelationIdPath = \"/headers/my_request_id_header\")]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre> <pre><code>{\n    \"headers\": {\n        \"my_request_id_header\": \"correlation_id_value\"\n    }\n}\n</code></pre> <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"service\": \"lambda-example\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n    \"function_version\": \"$LATEST\",\n    \"xray_trace_id\": \"1-61b7add4-66532bb81441e1b060389429\",\n    \"name\": \"AWS.Lambda.Powertools.Logging.Logger\",\n    \"sampling_rate\": 0.7,\n    \"correlation_id\": \"correlation_id_value\",\n}\n</code></pre> <p>We provide built-in JSON Pointer expression {target=\"_blank\"} for known event sources, where either a request ID or X-Ray Trace ID are present.</p> Function.csExample EventExample CloudWatch Logs excerpt <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(CorrelationIdPath = CorrelationIdPaths.ApiGatewayRest)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre> <pre><code>{\n    \"RequestContext\": {\n        \"RequestId\": \"correlation_id_value\"\n    }\n}\n</code></pre> <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"service\": \"lambda-example\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n    \"function_version\": \"$LATEST\",\n    \"xray_trace_id\": \"1-61b7add4-66532bb81441e1b060389429\",\n    \"name\": \"AWS.Lambda.Powertools.Logging.Logger\",\n    \"sampling_rate\": 0.7,\n    \"correlation_id\": \"correlation_id_value\",\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#appending-additional-keys",
            "title": "Appending additional keys",
            "text": "<p>Custom keys are persisted across warm invocations</p> <p>Always set additional keys as part of your handler to ensure they have the latest value, or explicitly clear them with  <code>ClearState=true</code>.</p> <p>You can append your own keys to your existing logs via <code>AppendKey</code>. Typically this value would be passed into the function via the event. Appended keys are added to all subsequent log entries in the current execution from the point the logger method is called. To ensure the key is added to all log entries, call this method as early as possible in the Lambda handler.</p> Function.csExample CloudWatch Logs excerpt <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(LogEvent = true)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigwProxyEvent,\n        ILambdaContext context)\n    {\n        var requestContextRequestId = apigwProxyEvent.RequestContext.RequestId;\n\n    var lookupInfo = new Dictionary&lt;string, object&gt;()\n    {\n        {\"LookupInfo\", new Dictionary&lt;string, object&gt;{{ \"LookupId\", requestContextRequestId }}}\n    };  \n\n    // Appended keys are added to all subsequent log entries in the current execution.\n    // Call this method as early as possible in the Lambda handler.\n    // Typically this is value would be passed into the function via the event.\n    // Set the ClearState = true to force the removal of keys across invocations,\n    Logger.AppendKeys(lookupInfo);\n\n    Logger.LogInformation(\"Getting ip address from external service\");\n\n}\n</code></pre> <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"Getting ip address from external service\"\n    \"timestamp\": \"2022-03-14T07:25:20.9418065Z\",\n    \"service\": \"powertools-dotnet-logging-sample\",\n    \"cold_start\": false,\n    \"function_name\": \"PowertoolsLoggingSample-HelloWorldFunction-hm1r10VT3lCy\",\n    \"function_memory_size\": 256,\n    \"function_arn\": \"arn:aws:lambda:function:PowertoolsLoggingSample-HelloWorldFunction-hm1r10VT3lCy\",\n    \"function_request_id\": \"96570b2c-f00e-471c-94ad-b25e95ba7347\",\n    \"function_version\": \"$LATEST\",\n    \"xray_trace_id\": \"1-622eede0-647960c56a91f3b071a9fff1\",\n    \"name\": \"AWS.Lambda.Powertools.Logging.Logger\",\n    \"lookup_info\": {\n        \"lookup_id\": \"4c50eace-8b1e-43d3-92ba-0efacf5d1625\"\n    },\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#removing-additional-keys",
            "title": "Removing additional keys",
            "text": "<p>You can remove any additional key from entry using <code>Logger.RemoveKeys()</code>.</p> Function.cs <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(LogEvent = true)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n        Logger.AppendKey(\"test\", \"willBeLogged\");\n        ...\n        var customKeys = new Dictionary&lt;string, string&gt;\n        {\n            {\"test1\", \"value1\"}, \n            {\"test2\", \"value2\"}\n        };\n\n        Logger.AppendKeys(customKeys);\n        ...\n        Logger.RemoveKeys(\"test\");\n        Logger.RemoveKeys(\"test1\", \"test2\");\n        ...\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#extra-keys",
            "title": "Extra Keys",
            "text": "<p>Extra keys allow you to append additional keys to a log entry. Unlike <code>AppendKey</code>, extra keys will only apply to the current log entry.</p> <p>Extra keys argument is available for all log levels' methods, as implemented in the standard logging library - e.g. Logger.Information, Logger.Warning.</p> <p>It accepts any dictionary, and all keyword arguments will be added as part of the root structure of the logs for that log statement.</p> <p>Info</p> <p>Any keyword argument added using extra keys will not be persisted for subsequent messages.</p> Function.cs <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(LogEvent = true)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigwProxyEvent,\n        ILambdaContext context)\n    {\n        var requestContextRequestId = apigwProxyEvent.RequestContext.RequestId;\n\n        var lookupId = new Dictionary&lt;string, object&gt;()\n        {\n            { \"LookupId\", requestContextRequestId }\n        };\n\n        // Appended keys are added to all subsequent log entries in the current execution.\n        // Call this method as early as possible in the Lambda handler.\n        // Typically this is value would be passed into the function via the event.\n        // Set the ClearState = true to force the removal of keys across invocations,\n        Logger.AppendKeys(lookupId);\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#clearing-all-state",
            "title": "Clearing all state",
            "text": "<p>Logger is commonly initialized in the global scope. Due to Lambda Execution Context reuse, this means that custom keys can be persisted across invocations. If you want all custom keys to be deleted, you can use <code>ClearState=true</code> attribute on <code>[Logging]</code> attribute.</p> Function.cs#1 Request#2 Request <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(ClearState = true)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n        if (apigProxyEvent.Headers.ContainsKey(\"SomeSpecialHeader\"))\n        {\n            Logger.AppendKey(\"SpecialKey\", \"value\");\n        }\n\n        Logger.LogInformation(\"Collecting payment\");\n        ...\n    }\n}\n</code></pre> <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"service\": \"payment\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n    \"special_key\": \"value\"\n}\n</code></pre> <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"service\": \"payment\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#sampling-debug-logs",
            "title": "Sampling debug logs",
            "text": "<p>You can dynamically set a percentage of your logs to DEBUG level via env var <code>POWERTOOLS_LOGGER_SAMPLE_RATE</code> or via <code>SamplingRate</code> parameter on attribute.</p> <p>Info</p> <p>Configuration on environment variable is given precedence over sampling rate configuration on attribute, provided it's in valid value range.</p> Sampling via attribute parameterSampling via environment variable <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(SamplingRate = 0.5)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre> <pre><code>Resources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n        ...\n        Environment:\n            Variables:\n                POWERTOOLS_LOGGER_SAMPLE_RATE: 0.5\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#configure-log-output-casing",
            "title": "Configure Log Output Casing",
            "text": "<p>By definition Powertools for AWS Lambda (.NET) outputs logging keys using snake case (e.g. \"function_memory_size\": 128). This allows developers using different Powertools for AWS Lambda (.NET) runtimes, to search logs across services written in languages such as Python or TypeScript.</p> <p>If you want to override the default behavior you can either set the desired casing through attributes, as described in the example below, or by setting the <code>POWERTOOLS_LOGGER_CASE</code> environment variable on your AWS Lambda function. Allowed values are: <code>CamelCase</code>, <code>PascalCase</code> and <code>SnakeCase</code>.</p> Output casing via attribute parameter <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(LoggerOutputCase = LoggerOutputCase.CamelCase)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre> <p>Below are some output examples for different casing.</p> Camel CasePascal CaseSnake Case <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"service\": \"payment\",\n    \"coldStart\": true,\n    \"functionName\": \"test\",\n    \"functionMemorySize\": 128,\n    \"functionArn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"functionRequestId\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre> <pre><code>{\n    \"Level\": \"Information\",\n    \"Message\": \"Collecting payment\",\n    \"Timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"Service\": \"payment\",\n    \"ColdStart\": true,\n    \"FunctionName\": \"test\",\n    \"FunctionMemorySize\": 128,\n    \"FunctionArn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"FunctionRequestId\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre> <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"service\": \"payment\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/logging-v2/#log-levels",
            "title": "Log Levels",
            "text": "<p>The default log level is <code>Information</code> and can be set using the <code>MinimumLogLevel</code> property option or by using the <code>POWERTOOLS_LOG_LEVEL</code> environment variable.</p> <p>We support the following log levels:</p> Level Numeric value Lambda Level <code>Trace</code> 0 <code>trace</code> <code>Debug</code> 1 <code>debug</code> <code>Information</code> 2 <code>info</code> <code>Warning</code> 3 <code>warn</code> <code>Error</code> 4 <code>error</code> <code>Critical</code> 5 <code>fatal</code> <code>None</code> 6"
        },
        {
            "location": "core/logging-v2/#using-aws-lambda-advanced-logging-controls-alc",
            "title": "Using AWS Lambda Advanced Logging Controls (ALC)",
            "text": "<p>When is it useful?</p> <p>When you want to set a logging policy to drop informational or verbose logs for one or all AWS Lambda functions, regardless of runtime and logger used.</p> <p>With AWS Lambda Advanced Logging Controls (ALC) {target=\"_blank\"}, you can enforce a minimum log level that Lambda will accept from your application code.</p> <p>When enabled, you should keep <code>Logger</code> and ALC log level in sync to avoid data loss.</p> <p>When using AWS Lambda Advanced Logging Controls (ALC)</p> <ul> <li>When Powertools Logger output is set to <code>PascalCase</code> <code>Level</code>  property name will be replaced by <code>LogLevel</code> as   a property name.</li> <li>ALC takes precedence over <code>POWERTOOLS_LOG_LEVEL</code> and when setting it in code using <code>[Logging(LogLevel = )]</code></li> </ul> <p>Here's a sequence diagram to demonstrate how ALC will drop both <code>Information</code> and <code>Debug</code> logs emitted from <code>Logger</code>, when ALC log level is stricter than <code>Logger</code>.</p> <pre><code>sequenceDiagram\n    title Lambda ALC allows WARN logs only\n    participant Lambda service\n    participant Lambda function\n    participant Application Logger\n\n    Note over Lambda service: AWS_LAMBDA_LOG_LEVEL=\"WARN\"\n    Note over Application Logger: POWERTOOLS_LOG_LEVEL=\"DEBUG\"\n    Lambda service-&gt;&gt;Lambda function: Invoke (event)\n    Lambda function-&gt;&gt;Lambda function: Calls handler\n    Lambda function-&gt;&gt;Application Logger: Logger.Warning(\"Something happened\")\n    Lambda function--&gt;&gt;Application Logger: Logger.Debug(\"Something happened\")\n    Lambda function--&gt;&gt;Application Logger: Logger.Information(\"Something happened\")\n\n    Lambda service-&gt;&gt;Lambda service: DROP INFO and DEBUG logs\n\n    Lambda service-&gt;&gt;CloudWatch Logs: Ingest error logs</code></pre> <p>Priority of log level settings in Powertools for AWS Lambda</p> <p>We prioritise log level settings in this order:</p> <ol> <li>AWS_LAMBDA_LOG_LEVEL environment variable</li> <li>Setting the log level in code using <code>[Logging(LogLevel = )]</code></li> <li>POWERTOOLS_LOG_LEVEL environment variable</li> </ol> <p>If you set <code>Logger</code> level lower than ALC, we will emit a warning informing you that your messages will be discarded by Lambda.</p> <p>NOTE With ALC enabled, we are unable to increase the minimum log level below the <code>AWS_LAMBDA_LOG_LEVEL</code> environment variable value, see AWS Lambda service documentation {target=\"_blank\"} for more details.</p>"
        },
        {
            "location": "core/logging-v2/#using-jsonserializeroptions",
            "title": "Using JsonSerializerOptions",
            "text": "<p>Powertools supports customizing the serialization and deserialization of Lambda JSON events and your own types using <code>JsonSerializerOptions</code>. You can do this by creating a custom <code>JsonSerializerOptions</code> and passing it to the <code>JsonOptions</code> of the Powertools Logger.</p> <p>Supports <code>TypeInfoResolver</code> and <code>DictionaryKeyPolicy</code> options. These two options are the most common ones used to customize the serialization of Powertools Logger.</p> <ul> <li><code>TypeInfoResolver</code>: This option allows you to specify a custom <code>JsonSerializerContext</code> that contains the types you   want to serialize and deserialize. This is especially useful when using AOT compilation, as it allows you to specify   the types that should be included in the generated assembly.</li> <li><code>DictionaryKeyPolicy</code>: This option allows you to specify a custom naming policy for the properties in the JSON output.   This is useful when you want to change the casing of the property names or use a different naming convention.</li> </ul> <p>Info</p> <p>If you want to preserve the original casing of the property names (keys), you can set the <code>DictionaryKeyPolicy</code> to <code>null</code>.</p> <pre><code>builder.Logging.AddPowertoolsLogger(options =&gt; \n{\n    options.JsonOptions = new JsonSerializerOptions\n    {\n        DictionaryKeyPolicy = JsonNamingPolicy.CamelCase, // Override output casing\n        TypeInfoResolver = MyCustomJsonSerializerContext.Default // Your custom JsonSerializerContext\n    };\n});\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#custom-log-formatter-bring-your-own-formatter",
            "title": "Custom Log formatter (Bring Your Own Formatter)",
            "text": "<p>You can customize the structure (keys and values) of your log entries by implementing a custom log formatter and override default log formatter using <code>LogFormatter</code> property in the <code>configure</code> options. </p> <p>You can implement a custom log formatter by inheriting the <code>ILogFormatter</code> class and implementing the <code>object FormatLogEntry(LogEntry logEntry)</code> method.</p> Function.csCustomLogFormatter.csExample CloudWatch Logs excerpt <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    /// &lt;summary&gt;\n    /// Function constructor\n    /// &lt;/summary&gt;\n    public Function()\n    {\n        Logger.Configure(options =&gt;\n        {\n            options.LogFormatter = new CustomLogFormatter();\n        });\n    }\n\n    [Logging(CorrelationIdPath = \"/headers/my_request_id_header\", SamplingRate = 0.7)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre> <pre><code>public class CustomLogFormatter : ILogFormatter\n{\n    public object FormatLogEntry(LogEntry logEntry)\n    {\n        return new\n        {\n            Message = logEntry.Message,\n            Service = logEntry.Service,\n            CorrelationIds = new \n            {\n                AwsRequestId = logEntry.LambdaContext?.AwsRequestId,\n                XRayTraceId = logEntry.XRayTraceId,\n                CorrelationId = logEntry.CorrelationId\n            },\n            LambdaFunction = new\n            {\n                Name = logEntry.LambdaContext?.FunctionName,\n                Arn = logEntry.LambdaContext?.InvokedFunctionArn,\n                MemoryLimitInMB = logEntry.LambdaContext?.MemoryLimitInMB,\n                Version = logEntry.LambdaContext?.FunctionVersion,\n                ColdStart = logEntry.ColdStart,\n            },\n            Level = logEntry.Level.ToString(),\n            Timestamp = logEntry.Timestamp.ToString(\"o\"),\n            Logger = new\n            {\n                Name = logEntry.Name,\n                SampleRate = logEntry.SamplingRate\n            },\n        };\n    }\n}\n</code></pre> <pre><code>{\n    \"Message\": \"Test Message\",\n    \"Service\": \"lambda-example\",\n    \"CorrelationIds\": {\n        \"AwsRequestId\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n        \"XRayTraceId\": \"1-61b7add4-66532bb81441e1b060389429\",\n        \"CorrelationId\": \"correlation_id_value\"\n    },\n    \"LambdaFunction\": {\n        \"Name\": \"test\",\n        \"Arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n        \"MemorySize\": 128,\n        \"Version\": \"$LATEST\",\n        \"ColdStart\": true\n    },\n    \"Level\": \"Information\",\n    \"Timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"Logger\": {\n        \"Name\": \"AWS.Lambda.Powertools.Logging.Logger\",\n        \"SampleRate\": 0.7\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#buffering-logs",
            "title": "Buffering logs",
            "text": "<p>Log buffering enables you to buffer logs for a specific request or invocation. Enable log buffering by passing <code>LogBufferingOptions</code> when configuring a Logger instance. You can buffer logs at the <code>Warning</code>, <code>Information</code>, <code>Debug</code> or <code>Trace</code> level, and flush them automatically on error or manually as needed.</p> <p>This is useful when you want to reduce the number of log messages emitted while still having detailed logs when needed, such as when troubleshooting issues.</p> LogBufferingOptions <pre><code>public class Function \n{\n    public Function()\n    {\n      Logger.Configure(logger =&gt;\n      {\n          logger.Service = \"MyServiceName\";\n          logger.LogBuffering = new LogBufferingOptions\n          {\n              BufferAtLogLevel = LogLevel.Debug,\n              MaxBytes = 20480, // Default is 20KB (20480 bytes) \n              FlushOnErrorLog = true // default true\n          };\n      });\n\n      Logger.LogDebug('This is a debug message'); // This is NOT buffered\n    }\n\n    [Logging]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        Logger.LogDebug('This is a debug message'); // This is buffered\n        Logger.LogInformation('This is an info message');\n\n        // your business logic here\n\n        Logger.LogError('This is an error message'); // This also flushes the buffer\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#configuring-the-buffer",
            "title": "Configuring the buffer",
            "text": "<p>When configuring the buffer, you can set the following options to fine-tune how logs are captured, stored, and emitted. You can configure the following options in the <code>logBufferOptions</code> constructor parameter:</p> Parameter Description Configuration Default <code>MaxBytes</code> Maximum size of the log buffer in bytes <code>number</code> <code>20480</code> <code>BufferAtLogLevel</code> Minimum log level to buffer <code>Trace</code>, <code>Debug</code>, <code>Information</code>, <code>Warning</code> <code>Debug</code> <code>FlushOnErrorLog</code> Automatically flush buffer when logging an error <code>True</code>, <code>False</code> <code>True</code> BufferAtLogLevelFlushOnErrorLog <pre><code>public class Function \n{\n    public Function()\n    {\n      Logger.Configure(logger =&gt;\n      {\n          logger.Service = \"MyServiceName\";\n          logger.LogBuffering = new LogBufferingOptions\n          {\n              BufferAtLogLevel = LogLevel.Warning\n          };\n      });\n    }\n\n    [Logging]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n      // All logs below are buffered\n      Logger.LogDebug('This is a debug message');\n      Logger.LogInformation('This is an info message');\n      Logger.LogWarning('This is a warn message');\n\n      Logger.ClearBuffer(); // This will clear the buffer without emitting the logs\n    }\n}\n</code></pre> <ol> <li>Setting <code>BufferAtLogLevel: 'Warning'</code> configures log buffering for <code>Warning</code> and all lower severity levels like <code>Information</code>, <code>Debug</code>, and <code>Trace</code>.</li> <li>Calling <code>Logger.ClearBuffer()</code> will clear the buffer without emitting the logs.</li> </ol> <pre><code>public class Function \n{\n    public Function()\n    {\n      Logger.Configure(logger =&gt;\n      {\n          logger.Service = \"MyServiceName\";\n          logger.LogBuffering = new LogBufferingOptions\n          {\n              FlushOnErrorLog = false\n          };\n      });\n    }\n\n    [Logging]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n      Logger.LogDebug('This is a debug message'); // this is buffered\n\n      try\n      {\n          throw new Exception();\n      }\n      catch (Exception e)\n      {\n          Logger.LogError(e.Message); // this does NOT flush the buffer\n      }\n\n      Logger.LogDebug(\"Debug!!\"); // this is buffered\n\n      try\n      {\n          throw new Exception();\n      }\n      catch (Exception e)\n      {\n          Logger.LogError(e.Message); // this does NOT flush the buffer\n          Logger.FlushBuffer(); // Manually flush\n      }\n    }\n}\n</code></pre> <ol> <li>Disabling <code>FlushOnErrorLog</code> will not flush the buffer when logging an error. This is useful when you want to control when the buffer is flushed by calling the <code>Logger.FlushBuffer()</code> method.</li> </ol>"
        },
        {
            "location": "core/logging-v2/#flushing-on-errors",
            "title": "Flushing on errors",
            "text": "<p>When using the <code>Logger</code> decorator, you can configure the logger to automatically flush the buffer when an error occurs. This is done by setting the <code>FlushBufferOnUncaughtError</code> option to <code>true</code> in the decorator.</p> FlushBufferOnUncaughtError <pre><code>public class Function \n{\n    public Function()\n    {\n      Logger.Configure(logger =&gt;\n      {\n          logger.Service = \"MyServiceName\";\n          logger.LogBuffering = new LogBufferingOptions\n          {\n              BufferAtLogLevel = LogLevel.Debug\n          };\n      });\n    }\n\n    [Logging(FlushBufferOnUncaughtError = true)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n      Logger.LogDebug('This is a debug message');\n\n      throw new Exception(); // This causes the buffer to be flushed\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#buffering-workflows",
            "title": "Buffering workflows",
            "text": ""
        },
        {
            "location": "core/logging-v2/#manual-flush",
            "title": "Manual flush",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Logger\n    participant CloudWatch\n    Client-&gt;&gt;Lambda: Invoke Lambda\n    Lambda-&gt;&gt;Logger: Initialize with DEBUG level buffering\n    Logger--&gt;&gt;Lambda: Logger buffer ready\n    Lambda-&gt;&gt;Logger: Logger.LogDebug(\"First debug log\")\n    Logger--&gt;&gt;Logger: Buffer first debug log\n    Lambda-&gt;&gt;Logger: Logger.LogInformation(\"Info log\")\n    Logger-&gt;&gt;CloudWatch: Directly log info message\n    Lambda-&gt;&gt;Logger: Logger.LogDebug(\"Second debug log\")\n    Logger--&gt;&gt;Logger: Buffer second debug log\n    Lambda-&gt;&gt;Logger: Logger.FlushBuffer()\n    Logger-&gt;&gt;CloudWatch: Emit buffered logs to stdout\n    Lambda-&gt;&gt;Client: Return execution result</code></pre> Flushing buffer manually </p>"
        },
        {
            "location": "core/logging-v2/#flushing-when-logging-an-error",
            "title": "Flushing when logging an error",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Logger\n    participant CloudWatch\n    Client-&gt;&gt;Lambda: Invoke Lambda\n    Lambda-&gt;&gt;Logger: Initialize with DEBUG level buffering\n    Logger--&gt;&gt;Lambda: Logger buffer ready\n    Lambda-&gt;&gt;Logger: Logger.LogDebug(\"First log\")\n    Logger--&gt;&gt;Logger: Buffer first debug log\n    Lambda-&gt;&gt;Logger: Logger.LogDebug(\"Second log\")\n    Logger--&gt;&gt;Logger: Buffer second debug log\n    Lambda-&gt;&gt;Logger: Logger.LogDebug(\"Third log\")\n    Logger--&gt;&gt;Logger: Buffer third debug log\n    Lambda-&gt;&gt;Lambda: Exception occurs\n    Lambda-&gt;&gt;Logger: Logger.LogError(\"Error details\")\n    Logger-&gt;&gt;CloudWatch: Emit buffered debug logs\n    Logger-&gt;&gt;CloudWatch: Emit error log\n    Lambda-&gt;&gt;Client: Raise exception</code></pre> Flushing buffer when an error happens </p>"
        },
        {
            "location": "core/logging-v2/#flushing-on-error",
            "title": "Flushing on error",
            "text": "<p>This works only when using the <code>Logger</code> decorator. You can configure the logger to automatically flush the buffer when an error occurs by setting the <code>FlushBufferOnUncaughtError</code> option to <code>true</code> in the decorator.</p> <p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Logger\n    participant CloudWatch\n    Client-&gt;&gt;Lambda: Invoke Lambda\n    Lambda-&gt;&gt;Logger: Using decorator\n    Logger--&gt;&gt;Lambda: Logger context injected\n    Lambda-&gt;&gt;Logger: Logger.LogDebug(\"First log\")\n    Logger--&gt;&gt;Logger: Buffer first debug log\n    Lambda-&gt;&gt;Logger: Logger.LogDebug(\"Second log\")\n    Logger--&gt;&gt;Logger: Buffer second debug log\n    Lambda-&gt;&gt;Lambda: Uncaught Exception\n    Lambda-&gt;&gt;CloudWatch: Automatically emit buffered debug logs\n    Lambda-&gt;&gt;Client: Raise uncaught exception</code></pre> Flushing buffer when an uncaught exception happens </p>"
        },
        {
            "location": "core/logging-v2/#buffering-faqs",
            "title": "Buffering FAQs",
            "text": "<ol> <li> <p>Does the buffer persist across Lambda invocations?    No, each Lambda invocation has its own buffer. The buffer is initialized when the Lambda function is invoked and is cleared after the function execution completes or when flushed manually.</p> </li> <li> <p>Are my logs buffered during cold starts?    No, we never buffer logs during cold starts. This is because we want to ensure that logs emitted during this phase are always available for debugging and monitoring purposes. The buffer is only used during the execution of the Lambda function.</p> </li> <li> <p>How can I prevent log buffering from consuming excessive memory?    You can limit the size of the buffer by setting the <code>MaxBytes</code> option in the <code>LogBufferingOptions</code> constructor parameter. This will ensure that the buffer does not grow indefinitely and consume excessive memory.</p> </li> <li> <p>What happens if the log buffer reaches its maximum size?    Older logs are removed from the buffer to make room for new logs. This means that if the buffer is full, you may lose some logs if they are not flushed before the buffer reaches its maximum size. When this happens, we emit a warning when flushing the buffer to indicate that some logs have been dropped.</p> </li> <li> <p>How is the log size of a log line calculated?    The log size is calculated based on the size of the serialized log line in bytes. This includes the size of the log message, the size of any additional keys, and the size of the timestamp.</p> </li> <li> <p>What timestamp is used when I flush the logs?    The timestamp preserves the original time when the log record was created. If you create a log record at 11:00:10 and flush it at 11:00:25, the log line will retain its original timestamp of 11:00:10.</p> </li> <li> <p>What happens if I try to add a log line that is bigger than max buffer size?    The log will be emitted directly to standard output and not buffered. When this happens, we emit a warning to indicate that the log line was too big to be buffered.</p> </li> <li> <p>What happens if Lambda times out without flushing the buffer?    Logs that are still in the buffer will be lost. If you are using the log buffer to log asynchronously, you should ensure that the buffer is flushed before the Lambda function times out. You can do this by calling the <code>Logger.FlushBuffer()</code> method at the end of your Lambda function.</p> </li> </ol>"
        },
        {
            "location": "core/logging-v2/#timestamp-formatting",
            "title": "Timestamp formatting",
            "text": "<p>You can customize the timestamp format by setting the <code>TimestampFormat</code> property in the <code>Logger.Configure</code> method. The default format is <code>o</code>, which is the ISO 8601 format. You can use any valid DateTime format string to customize the timestamp format. For example, to use the <code>yyyy-MM-dd HH:mm:ss</code> format, you can do the following:</p> <p><pre><code>Logger.Configure(logger =&gt;\n{\n    logger.TimestampFormat = \"yyyy-MM-dd HH:mm:ss\";\n});\n</code></pre> This will output the timestamp in the following format:</p> <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"Test Message\",\n    \"timestamp\": \"2021-12-13 20:32:22\",\n    \"service\": \"lambda-example\",\n    ...\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#aot-support",
            "title": "AOT Support",
            "text": "<p>Info</p> <p>If you want to use the <code>LogEvent</code>, <code>Custom Log Formatter</code> features, or serialize your own types when Logging events, you need to either pass <code>JsonSerializerContext</code> or make changes in your Lambda <code>Main</code> method.</p> <p>Info</p> <p>Starting from version 1.6.0, it is required to update the Amazon.Lambda.Serialization.SystemTextJson NuGet package to version 2.4.3 in your csproj.</p>"
        },
        {
            "location": "core/logging-v2/#using-jsonserializeroptions_1",
            "title": "Using JsonSerializerOptions",
            "text": "<p>To be able to serializer your own types, you need to pass your <code>JsonSerializerContext</code> to the <code>TypeInfoResolver</code> of the <code>Logger.Configure</code> method.</p> <pre><code>Logger.Configure(logger =&gt; \n{\n    logger.JsonOptions = new JsonSerializerOptions\n    {\n        TypeInfoResolver = YourJsonSerializerContext.Default\n    };\n});\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#using-powertoolssourcegeneratorserializer",
            "title": "Using PowertoolsSourceGeneratorSerializer",
            "text": "<p>Replace <code>SourceGeneratorLambdaJsonSerializer</code> with <code>PowertoolsSourceGeneratorSerializer</code>.</p> <p>This change enables Powertools to construct an instance of <code>JsonSerializerOptions</code> used to customize the serialization and deserialization of Lambda JSON events and your own types.</p> BeforeAfter <pre><code> Func&lt;APIGatewayHttpApiV2ProxyRequest, ILambdaContext, Task&lt;APIGatewayHttpApiV2ProxyResponse&gt;&gt; handler = FunctionHandler;\n await LambdaBootstrapBuilder.Create(handler, new SourceGeneratorLambdaJsonSerializer&lt;MyCustomJsonSerializerContext&gt;())\n     .Build()\n     .RunAsync();\n</code></pre> <pre><code>Func&lt;APIGatewayHttpApiV2ProxyRequest, ILambdaContext, Task&lt;APIGatewayHttpApiV2ProxyResponse&gt;&gt; handler = FunctionHandler;\nawait LambdaBootstrapBuilder.Create(handler, new PowertoolsSourceGeneratorSerializer&lt;MyCustomJsonSerializerContext&gt;())\n    .Build()\n    .RunAsync();\n</code></pre> <p>For example when you have your own Demo type</p> <pre><code>public class Demo\n{\n    public string Name { get; set; }\n    public Headers Headers { get; set; }\n}\n</code></pre> <p>To be able to serialize it in AOT you have to have your own <code>JsonSerializerContext</code></p> <pre><code>[JsonSerializable(typeof(APIGatewayHttpApiV2ProxyRequest))]\n[JsonSerializable(typeof(APIGatewayHttpApiV2ProxyResponse))]\n[JsonSerializable(typeof(Demo))]\npublic partial class MyCustomJsonSerializerContext : JsonSerializerContext\n{\n}\n</code></pre> <p>When you update your code to use <code>PowertoolsSourceGeneratorSerializer&lt;MyCustomJsonSerializerContext&gt;</code>, we combine your <code>JsonSerializerContext</code> with Powertools' <code>JsonSerializerContext</code>. This allows Powertools to serialize your types and Lambda events.</p>"
        },
        {
            "location": "core/logging-v2/#custom-log-formatter",
            "title": "Custom Log Formatter",
            "text": "<p>To use a custom log formatter with AOT, pass an instance of <code>ILogFormatter</code> to <code>PowertoolsSourceGeneratorSerializer</code> instead of using the static <code>Logger.UseFormatter</code> in the Function constructor as you do in non-AOT Lambdas.</p> Function Main methodCustomLogFormatter.cs <pre><code>Func&lt;APIGatewayHttpApiV2ProxyRequest, ILambdaContext, Task&lt;APIGatewayHttpApiV2ProxyResponse&gt;&gt; handler = FunctionHandler;\nawait LambdaBootstrapBuilder.Create(handler, \n    new PowertoolsSourceGeneratorSerializer&lt;LambdaFunctionJsonSerializerContext&gt;\n    ( \n        new CustomLogFormatter()\n    )\n)\n.Build()\n.RunAsync();\n</code></pre> <pre><code>public class CustomLogFormatter : ILogFormatter\n{\n    public object FormatLogEntry(LogEntry logEntry)\n    {\n        return new\n        {\n            Message = logEntry.Message,\n            Service = logEntry.Service,\n            CorrelationIds = new\n            {\n                AwsRequestId = logEntry.LambdaContext?.AwsRequestId,\n                XRayTraceId = logEntry.XRayTraceId,\n                CorrelationId = logEntry.CorrelationId\n            },\n            LambdaFunction = new\n            {\n                Name = logEntry.LambdaContext?.FunctionName,\n                Arn = logEntry.LambdaContext?.InvokedFunctionArn,\n                MemoryLimitInMB = logEntry.LambdaContext?.MemoryLimitInMB,\n                Version = logEntry.LambdaContext?.FunctionVersion,\n                ColdStart = logEntry.ColdStart,\n            },\n            Level = logEntry.Level.ToString(),\n            Timestamp = logEntry.Timestamp.ToString(\"o\"),\n            Logger = new\n            {\n            Name = logEntry.Name,\n            SampleRate = logEntry.SamplingRate\n            },\n        };\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#anonymous-types",
            "title": "Anonymous types",
            "text": "<p>Note</p> <p>While we support anonymous type serialization by converting to a <code>Dictionary&lt;string, object&gt;</code>, this is not a best practice and is not recommended when using native AOT. </p> <p>We recommend using concrete classes and adding them to your <code>JsonSerializerContext</code>.</p>"
        },
        {
            "location": "core/logging-v2/#testing",
            "title": "Testing",
            "text": "<p>You can change where the <code>Logger</code> will output its logs by setting the <code>LogOutput</code> property. We also provide a helper class for tests <code>TestLoggerOutput</code> or you can provider your own implementation of <code>IConsoleWrapper</code>.</p> <pre><code>// Using TestLoggerOutput\noptions.LogOutput = new TestLoggerOutput();\n// Custom console output for testing\noptions.LogOutput = new TestConsoleWrapper();\n\n// Example implementation for testing:\npublic class TestConsoleWrapper : IConsoleWrapper\n{\n    public List&lt;string&gt; CapturedOutput { get; } = new();\n\n    public void WriteLine(string message)\n    {\n        CapturedOutput.Add(message);\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging-v2/#ilogger_1",
            "title": "ILogger",
            "text": "<p>If you are using ILogger interface you can inject the logger in a dedicated constructor for your Lambda function and thus you can mock your ILogger instance.</p> <pre><code>public class Function\n{\n    private readonly ILogger _logger;\n\n    public Function()\n    {\n        _logger = oggerFactory.Create(builder =&gt;\n        {\n            builder.AddPowertoolsLogger(config =&gt;\n            {\n                config.Service = \"TestService\";\n                config.LoggerOutputCase = LoggerOutputCase.PascalCase;\n            });\n        }).CreatePowertoolsLogger();\n    }\n\n    // constructor used for tests - pass the mock ILogger\n    public Function(ILogger logger)\n    {\n        _logger = logger ?? loggerFactory.Create(builder =&gt;\n        {\n            builder.AddPowertoolsLogger(config =&gt;\n            {\n                config.Service = \"TestService\";\n                config.LoggerOutputCase = LoggerOutputCase.PascalCase;\n            });\n        }).CreatePowertoolsLogger();\n    }\n\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        _logger.LogInformation(\"Collecting payment\");\n        ...\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging/",
            "title": "Logging",
            "text": "<p>The logging utility provides a Lambda optimized logger with output structured as JSON.</p>"
        },
        {
            "location": "core/logging/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Capture key fields from Lambda context, cold start and structures logging output as JSON</li> <li>Log Lambda event when instructed (disabled by default)</li> <li>Log sampling enables DEBUG log level for a percentage of requests (disabled by default)</li> <li>Append additional keys to structured log at any point in time</li> <li>Ahead-of-Time compilation to native code support AOT from version 1.6.0</li> </ul>"
        },
        {
            "location": "core/logging/#installation",
            "title": "Installation",
            "text": "<p>Powertools for AWS Lambda (.NET) are available as NuGet packages. You can install the packages from NuGet Gallery or from Visual Studio editor by searching <code>AWS.Lambda.Powertools*</code> to see various utilities available.</p> <ul> <li> <p>AWS.Lambda.Powertools.Logging:</p> <p><code>dotnet add package AWS.Lambda.Powertools.Logging --version 1.6.5</code></p> </li> </ul>"
        },
        {
            "location": "core/logging/#getting-started",
            "title": "Getting started",
            "text": "<p>Info</p> <p>AOT Support If loooking for AOT specific configurations navigate to the AOT section </p> <p>Logging requires two settings:</p> Setting Description Environment variable Attribute parameter Service Sets Service key that will be present across all log statements <code>POWERTOOLS_SERVICE_NAME</code> <code>Service</code> Logging level Sets how verbose Logger should be (Information, by default) <code>POWERTOOLS_LOG_LEVEL</code> <code>LogLevel</code>"
        },
        {
            "location": "core/logging/#service-property-priority-resolution",
            "title": "Service Property Priority Resolution",
            "text": "<p>The root level Service property now correctly follows this priority order:</p> <ol> <li>LoggingAttribute.Service (property value set in the decorator)</li> <li>POWERTOOLS_SERVICE_NAME (environment variable)</li> </ol>"
        },
        {
            "location": "core/logging/#example-using-aws-serverless-application-model-aws-sam",
            "title": "Example using AWS Serverless Application Model (AWS SAM)",
            "text": "<p>You can override log level by setting <code>POWERTOOLS_LOG_LEVEL</code> environment variable in the AWS SAM template.</p> <p>You can also explicitly set a service name via <code>POWERTOOLS_SERVICE_NAME</code> environment variable. This sets Service key that will be present across all log statements.</p> <p>Here is an example using the AWS SAM Globals section.</p> template.yaml <pre><code># Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: MIT-0\nAWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: &gt;\nExample project for Powertools for AWS Lambda (.NET) Logging utility\n\nGlobals:\n    Function:\n        Timeout: 10\n        Environment:\n        Variables:\n            POWERTOOLS_SERVICE_NAME: powertools-dotnet-logging-sample\n            POWERTOOLS_LOG_LEVEL: Debug\n            POWERTOOLS_LOGGER_LOG_EVENT: true\n            POWERTOOLS_LOGGER_CASE: PascalCase # Allowed values are: CamelCase, PascalCase and SnakeCase\n            POWERTOOLS_LOGGER_SAMPLE_RATE: 0\n</code></pre>"
        },
        {
            "location": "core/logging/#full-list-of-environment-variables",
            "title": "Full list of environment variables",
            "text": "Environment variable Description Default POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging <code>\"service_undefined\"</code> POWERTOOLS_LOG_LEVEL Sets logging level <code>Information</code> POWERTOOLS_LOGGER_CASE Override the default casing for log keys <code>SnakeCase</code> POWERTOOLS_LOGGER_LOG_EVENT Logs incoming event <code>false</code> POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling <code>0</code>"
        },
        {
            "location": "core/logging/#using-aws-lambda-advanced-logging-controls-alc",
            "title": "Using AWS Lambda Advanced Logging Controls (ALC)",
            "text": "<p>When is it useful?</p> <p>When you want to set a logging policy to drop informational or verbose logs for one or all AWS Lambda functions, regardless of runtime and logger used.</p> <p>With AWS Lambda Advanced Logging Controls (ALC), you can enforce a minimum log level that Lambda will accept from your application code.</p> <p>When enabled, you should keep <code>Logger</code> and ALC log level in sync to avoid data loss.</p> <p>When using AWS Lambda Advanced Logging Controls (ALC)</p> <ul> <li>When Powertools Logger output is set to <code>PascalCase</code> <code>Level</code>  property name will be replaced by <code>LogLevel</code> as a property name.</li> <li>ALC takes precedence over <code>POWERTOOLS_LOG_LEVEL</code> and when setting it in code using <code>[Logging(LogLevel = )]</code></li> </ul> <p>Here's a sequence diagram to demonstrate how ALC will drop both <code>Information</code> and <code>Debug</code> logs emitted from <code>Logger</code>, when ALC log level is stricter than <code>Logger</code>.</p> <pre><code>sequenceDiagram\n    title Lambda ALC allows WARN logs only\n    participant Lambda service\n    participant Lambda function\n    participant Application Logger\n\n    Note over Lambda service: AWS_LAMBDA_LOG_LEVEL=\"WARN\"\n    Note over Application Logger: POWERTOOLS_LOG_LEVEL=\"DEBUG\"\n    Lambda service-&gt;&gt;Lambda function: Invoke (event)\n    Lambda function-&gt;&gt;Lambda function: Calls handler\n    Lambda function-&gt;&gt;Application Logger: Logger.Warning(\"Something happened\")\n    Lambda function--&gt;&gt;Application Logger: Logger.Debug(\"Something happened\")\n    Lambda function--&gt;&gt;Application Logger: Logger.Information(\"Something happened\")\n\n    Lambda service-&gt;&gt;Lambda service: DROP INFO and DEBUG logs\n\n    Lambda service-&gt;&gt;CloudWatch Logs: Ingest error logs</code></pre> <p>Priority of log level settings in Powertools for AWS Lambda</p> <p>We prioritise log level settings in this order:</p> <ol> <li>AWS_LAMBDA_LOG_LEVEL environment variable</li> <li>Setting the log level in code using <code>[Logging(LogLevel = )]</code></li> <li>POWERTOOLS_LOG_LEVEL environment variable</li> </ol> <p>If you set <code>Logger</code> level lower than ALC, we will emit a warning informing you that your messages will be discarded by Lambda.</p> <p>NOTE With ALC enabled, we are unable to increase the minimum log level below the <code>AWS_LAMBDA_LOG_LEVEL</code> environment variable value, see AWS Lambda service documentation for more details.</p>"
        },
        {
            "location": "core/logging/#standard-structured-keys",
            "title": "Standard structured keys",
            "text": "<p>Your logs will always include the following keys to your structured logging:</p> Key Type Example Description Timestamp string \"2020-05-24 18:17:33,774\" Timestamp of actual log statement Level string \"Information\" Logging level Name string \"Powertools for AWS Lambda (.NET) Logger\" Logger name ColdStart bool true ColdStart value. Service string \"payment\" Service name defined. \"service_undefined\" will be used if unknown SamplingRate int 0.1 Debug logging sampling rate in percentage e.g. 10% in this case Message string \"Collecting payment\" Log statement value. Unserializable JSON values will be cast to string FunctionName string \"example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" FunctionVersion string \"12\" FunctionMemorySize string \"128\" FunctionArn string \"arn:aws:lambda:eu-west-1:012345678910:function:example-powertools-HelloWorldFunction-1P1Z6B39FLU73\" XRayTraceId string \"1-5759e988-bd862e3fe1be46a994272793\" X-Ray Trace ID when Lambda function has enabled Tracing FunctionRequestId string \"899856cb-83d1-40d7-8611-9e78f15f32f4\" AWS Request ID from lambda context"
        },
        {
            "location": "core/logging/#logging-incoming-event",
            "title": "Logging incoming event",
            "text": "<p>When debugging in non-production environments, you can instruct Logger to log the incoming event with <code>LogEvent</code> parameter or via <code>POWERTOOLS_LOGGER_LOG_EVENT</code> environment variable.</p> <p>Warning</p> <p>Log event is disabled by default to prevent sensitive info being logged.</p> Function.cs <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(LogEvent = true)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#setting-a-correlation-id",
            "title": "Setting a Correlation ID",
            "text": "<p>You can set a Correlation ID using <code>CorrelationIdPath</code> parameter by passing a JSON Pointer expression.</p> <p>Attention</p> <p>The JSON Pointer expression is <code>case sensitive</code>. In the bellow example <code>/headers/my_request_id_header</code> would work but <code>/Headers/my_request_id_header</code> would not find the element.</p> Function.csExample EventExample CloudWatch Logs excerpt <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(CorrelationIdPath = \"/headers/my_request_id_header\")]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre> <pre><code>{\n    \"headers\": {\n        \"my_request_id_header\": \"correlation_id_value\"\n    }\n}\n</code></pre> <pre><code>{\n    \"cold_start\": true,\n    \"xray_trace_id\": \"1-61b7add4-66532bb81441e1b060389429\",\n    \"function_name\": \"test\",\n    \"function_version\": \"$LATEST\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n    \"timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"level\": \"Information\",\n    \"service\": \"lambda-example\",\n    \"name\": \"AWS.Lambda.Powertools.Logging.Logger\",\n    \"message\": \"Collecting payment\",\n    \"sampling_rate\": 0.7,\n    \"correlation_id\": \"correlation_id_value\",\n}\n</code></pre> <p>We provide built-in JSON Pointer expression for known event sources, where either a request ID or X-Ray Trace ID are present.</p> Function.csExample EventExample CloudWatch Logs excerpt <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(CorrelationIdPath = CorrelationIdPaths.ApiGatewayRest)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre> <pre><code>{\n    \"RequestContext\": {\n        \"RequestId\": \"correlation_id_value\"\n    }\n}\n</code></pre> <pre><code>{\n    \"cold_start\": true,\n    \"xray_trace_id\": \"1-61b7add4-66532bb81441e1b060389429\",\n    \"function_name\": \"test\",\n    \"function_version\": \"$LATEST\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n    \"timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"level\": \"Information\",\n    \"service\": \"lambda-example\",\n    \"name\": \"AWS.Lambda.Powertools.Logging.Logger\",\n    \"message\": \"Collecting payment\",\n    \"sampling_rate\": 0.7,\n    \"correlation_id\": \"correlation_id_value\",\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#appending-additional-keys",
            "title": "Appending additional keys",
            "text": "<p>Custom keys are persisted across warm invocations</p> <pre><code>Always set additional keys as part of your handler to ensure they have the latest value, or explicitly clear them with [`ClearState=true`](#clearing-all-state).\n</code></pre> <p>You can append your own keys to your existing logs via <code>AppendKey</code>. Typically this value would be passed into the function via the event. Appended keys are added to all subsequent log entries in the current execution from the point the logger method is called. To ensure the key is added to all log entries, call this method as early as possible in the Lambda handler.</p> Function.csExample CloudWatch Logs excerpt <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(LogEvent = true)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigwProxyEvent,\n        ILambdaContext context)\n    {\n        var requestContextRequestId = apigwProxyEvent.RequestContext.RequestId;\n\n    var lookupInfo = new Dictionary&lt;string, object&gt;()\n    {\n        {\"LookupInfo\", new Dictionary&lt;string, object&gt;{{ \"LookupId\", requestContextRequestId }}}\n    };  \n\n    // Appended keys are added to all subsequent log entries in the current execution.\n    // Call this method as early as possible in the Lambda handler.\n    // Typically this is value would be passed into the function via the event.\n    // Set the ClearState = true to force the removal of keys across invocations,\n    Logger.AppendKeys(lookupInfo);\n\n    Logger.LogInformation(\"Getting ip address from external service\");\n\n}\n</code></pre> <pre><code>{\n    \"cold_start\": false,\n    \"xray_trace_id\": \"1-622eede0-647960c56a91f3b071a9fff1\",\n    \"lookup_info\": {\n        \"lookup_id\": \"4c50eace-8b1e-43d3-92ba-0efacf5d1625\"\n    },\n    \"function_name\": \"PowertoolsLoggingSample-HelloWorldFunction-hm1r10VT3lCy\",\n    \"function_version\": \"$LATEST\",\n    \"function_memory_size\": 256,\n    \"function_arn\": \"arn:aws:lambda:ap-southeast-2:538510314095:function:PowertoolsLoggingSample-HelloWorldFunction-hm1r10VT3lCy\",\n    \"function_request_id\": \"96570b2c-f00e-471c-94ad-b25e95ba7347\",\n    \"timestamp\": \"2022-03-14T07:25:20.9418065Z\",\n    \"level\": \"Information\",\n    \"service\": \"powertools-dotnet-logging-sample\",\n    \"name\": \"AWS.Lambda.Powertools.Logging.Logger\",\n    \"message\": \"Getting ip address from external service\"\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#removing-additional-keys",
            "title": "Removing additional keys",
            "text": "<p>You can remove any additional key from entry using <code>Logger.RemoveKeys()</code>.</p> Function.cs <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(LogEvent = true)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n        Logger.AppendKey(\"test\", \"willBeLogged\");\n        ...\n        var customKeys = new Dictionary&lt;string, string&gt;\n        {\n            {\"test1\", \"value1\"}, \n            {\"test2\", \"value2\"}\n        };\n\n        Logger.AppendKeys(customKeys);\n        ...\n        Logger.RemoveKeys(\"test\");\n        Logger.RemoveKeys(\"test1\", \"test2\");\n        ...\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#extra-keys",
            "title": "Extra Keys",
            "text": "<p>Extra keys allow you to append additional keys to a log entry. Unlike <code>AppendKey</code>, extra keys will only apply to the current log entry.</p> <p>Extra keys argument is available for all log levels' methods, as implemented in the standard logging library - e.g. Logger.Information, Logger.Warning.</p> <p>It accepts any dictionary, and all keyword arguments will be added as part of the root structure of the logs for that log statement.</p> <p>Info</p> <pre><code>Any keyword argument added using extra keys will not be persisted for subsequent messages.\n</code></pre> Function.cs <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(LogEvent = true)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigwProxyEvent,\n        ILambdaContext context)\n    {\n        var requestContextRequestId = apigwProxyEvent.RequestContext.RequestId;\n\n        var lookupId = new Dictionary&lt;string, object&gt;()\n        {\n            { \"LookupId\", requestContextRequestId }\n        };\n\n        // Appended keys are added to all subsequent log entries in the current execution.\n        // Call this method as early as possible in the Lambda handler.\n        // Typically this is value would be passed into the function via the event.\n        // Set the ClearState = true to force the removal of keys across invocations,\n        Logger.AppendKeys(lookupId);\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#clearing-all-state",
            "title": "Clearing all state",
            "text": "<p>Logger is commonly initialized in the global scope. Due to Lambda Execution Context reuse, this means that custom keys can be persisted across invocations. If you want all custom keys to be deleted, you can use <code>ClearState=true</code> attribute on <code>[Logging]</code> attribute.</p> Function.cs#1 Request#2 Request <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(ClearState = true)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n        if (apigProxyEvent.Headers.ContainsKey(\"SomeSpecialHeader\"))\n        {\n            Logger.AppendKey(\"SpecialKey\", \"value\");\n        }\n\n        Logger.LogInformation(\"Collecting payment\");\n        ...\n    }\n}\n</code></pre> <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"service\": \"payment\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n    \"special_key\": \"value\"\n}\n</code></pre> <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"service\": \"payment\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#sampling-debug-logs",
            "title": "Sampling debug logs",
            "text": "<p>You can dynamically set a percentage of your logs to DEBUG level via env var <code>POWERTOOLS_LOGGER_SAMPLE_RATE</code> or via <code>SamplingRate</code> parameter on attribute.</p> <p>Info</p> <p>Configuration on environment variable is given precedence over sampling rate configuration on attribute, provided it's in valid value range.</p> Sampling via attribute parameterSampling via environment variable <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(SamplingRate = 0.5)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre> <pre><code>Resources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n        ...\n        Environment:\n            Variables:\n                POWERTOOLS_LOGGER_SAMPLE_RATE: 0.5\n</code></pre>"
        },
        {
            "location": "core/logging/#configure-log-output-casing",
            "title": "Configure Log Output Casing",
            "text": "<p>By definition Powertools for AWS Lambda (.NET) outputs logging keys using snake case (e.g. \"function_memory_size\": 128). This allows developers using different Powertools for AWS Lambda (.NET) runtimes, to search logs across services written in languages such as Python or TypeScript.</p> <p>If you want to override the default behavior you can either set the desired casing through attributes, as described in the example below, or by setting the <code>POWERTOOLS_LOGGER_CASE</code> environment variable on your AWS Lambda function. Allowed values are: <code>CamelCase</code>, <code>PascalCase</code> and <code>SnakeCase</code>.</p> Output casing via attribute parameter <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    [Logging(LoggerOutputCase = LoggerOutputCase.CamelCase)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre> <p>Below are some output examples for different casing.</p> Camel CasePascal CaseSnake Case <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"service\": \"payment\",\n    \"coldStart\": true,\n    \"functionName\": \"test\",\n    \"functionMemorySize\": 128,\n    \"functionArn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"functionRequestId\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre> <pre><code>{\n    \"Level\": \"Information\",\n    \"Message\": \"Collecting payment\",\n    \"Timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"Service\": \"payment\",\n    \"ColdStart\": true,\n    \"FunctionName\": \"test\",\n    \"FunctionMemorySize\": 128,\n    \"FunctionArn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"FunctionRequestId\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre> <pre><code>{\n    \"level\": \"Information\",\n    \"message\": \"Collecting payment\",\n    \"timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"service\": \"payment\",\n    \"cold_start\": true,\n    \"function_name\": \"test\",\n    \"function_memory_size\": 128,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n    \"function_request_id\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\"\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#custom-log-formatter-bring-your-own-formatter",
            "title": "Custom Log formatter (Bring Your Own Formatter)",
            "text": "<p>You can customize the structure (keys and values) of your log entries by implementing a custom log formatter and override default log formatter using <code>Logger.UseFormatter</code> method. You can implement a custom log formatter by inheriting the <code>ILogFormatter</code> class and implementing the <code>object FormatLogEntry(LogEntry logEntry)</code> method.</p> Function.csCustomLogFormatter.csExample CloudWatch Logs excerpt <pre><code>/**\n * Handler for requests to Lambda function.\n */\npublic class Function\n{\n    /// &lt;summary&gt;\n    /// Function constructor\n    /// &lt;/summary&gt;\n    public Function()\n    {\n        Logger.UseFormatter(new CustomLogFormatter());\n    }\n\n    [Logging(CorrelationIdPath = \"/headers/my_request_id_header\", SamplingRate = 0.7)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre> <pre><code>public class CustomLogFormatter : ILogFormatter\n{\n    public object FormatLogEntry(LogEntry logEntry)\n    {\n        return new\n        {\n            Message = logEntry.Message,\n            Service = logEntry.Service,\n            CorrelationIds = new \n            {\n                AwsRequestId = logEntry.LambdaContext?.AwsRequestId,\n                XRayTraceId = logEntry.XRayTraceId,\n                CorrelationId = logEntry.CorrelationId\n            },\n            LambdaFunction = new\n            {\n                Name = logEntry.LambdaContext?.FunctionName,\n                Arn = logEntry.LambdaContext?.InvokedFunctionArn,\n                MemoryLimitInMB = logEntry.LambdaContext?.MemoryLimitInMB,\n                Version = logEntry.LambdaContext?.FunctionVersion,\n                ColdStart = logEntry.ColdStart,\n            },\n            Level = logEntry.Level.ToString(),\n            Timestamp = logEntry.Timestamp.ToString(\"o\"),\n            Logger = new\n            {\n                Name = logEntry.Name,\n                SampleRate = logEntry.SamplingRate\n            },\n        };\n    }\n}\n</code></pre> <pre><code>{\n    \"Message\": \"Test Message\",\n    \"Service\": \"lambda-example\",\n    \"CorrelationIds\": {\n        \"AwsRequestId\": \"52fdfc07-2182-154f-163f-5f0f9a621d72\",\n        \"XRayTraceId\": \"1-61b7add4-66532bb81441e1b060389429\",\n        \"CorrelationId\": \"correlation_id_value\"\n    },\n    \"LambdaFunction\": {\n        \"Name\": \"test\",\n        \"Arn\": \"arn:aws:lambda:eu-west-1:12345678910:function:test\",\n        \"MemorySize\": 128,\n        \"Version\": \"$LATEST\",\n        \"ColdStart\": true\n    },\n    \"Level\": \"Information\",\n    \"Timestamp\": \"2021-12-13T20:32:22.5774262Z\",\n    \"Logger\": {\n        \"Name\": \"AWS.Lambda.Powertools.Logging.Logger\",\n        \"SampleRate\": 0.7\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#aot-support",
            "title": "AOT Support",
            "text": "<p>Info</p> <p>If you want to use the <code>LogEvent</code>, <code>Custom Log Formatter</code> features, or serialize your own types when Logging events, you need to make changes in your Lambda <code>Main</code> method.</p> <p>Info</p> <p>Starting from version 1.6.0, it is required to update the Amazon.Lambda.Serialization.SystemTextJson NuGet package to version 2.4.3 in your csproj.</p>"
        },
        {
            "location": "core/logging/#configure",
            "title": "Configure",
            "text": "<p>Replace <code>SourceGeneratorLambdaJsonSerializer</code> with <code>PowertoolsSourceGeneratorSerializer</code>.</p> <p>This change enables Powertools to construct an instance of <code>JsonSerializerOptions</code> used to customize the serialization and deserialization of Lambda JSON events and your own types.</p> BeforeAfter <pre><code> Func&lt;APIGatewayHttpApiV2ProxyRequest, ILambdaContext, Task&lt;APIGatewayHttpApiV2ProxyResponse&gt;&gt; handler = FunctionHandler;\n await LambdaBootstrapBuilder.Create(handler, new SourceGeneratorLambdaJsonSerializer&lt;MyCustomJsonSerializerContext&gt;())\n     .Build()\n     .RunAsync();\n</code></pre> <pre><code>Func&lt;APIGatewayHttpApiV2ProxyRequest, ILambdaContext, Task&lt;APIGatewayHttpApiV2ProxyResponse&gt;&gt; handler = FunctionHandler;\nawait LambdaBootstrapBuilder.Create(handler, new PowertoolsSourceGeneratorSerializer&lt;MyCustomJsonSerializerContext&gt;())\n    .Build()\n    .RunAsync();\n</code></pre> <p>For example when you have your own Demo type </p> <pre><code>public class Demo\n{\n    public string Name { get; set; }\n    public Headers Headers { get; set; }\n}\n</code></pre> <p>To be able to serialize it in AOT you have to have your own <code>JsonSerializerContext</code></p> <pre><code>[JsonSerializable(typeof(APIGatewayHttpApiV2ProxyRequest))]\n[JsonSerializable(typeof(APIGatewayHttpApiV2ProxyResponse))]\n[JsonSerializable(typeof(Demo))]\npublic partial class MyCustomJsonSerializerContext : JsonSerializerContext\n{\n}\n</code></pre> <p>When you update your code to use <code>PowertoolsSourceGeneratorSerializer&lt;MyCustomJsonSerializerContext&gt;</code>, we combine your <code>JsonSerializerContext</code> with Powertools' <code>JsonSerializerContext</code>. This allows Powertools to serialize your types and Lambda events.</p>"
        },
        {
            "location": "core/logging/#custom-log-formatter",
            "title": "Custom Log Formatter",
            "text": "<p>To use a custom log formatter with AOT, pass an instance of <code>ILogFormatter</code> to <code>PowertoolsSourceGeneratorSerializer</code> instead of using the static <code>Logger.UseFormatter</code> in the Function constructor as you do in non-AOT Lambdas.</p> Function Main methodCustomLogFormatter.cs <pre><code>Func&lt;APIGatewayHttpApiV2ProxyRequest, ILambdaContext, Task&lt;APIGatewayHttpApiV2ProxyResponse&gt;&gt; handler = FunctionHandler;\nawait LambdaBootstrapBuilder.Create(handler, \n    new PowertoolsSourceGeneratorSerializer&lt;LambdaFunctionJsonSerializerContext&gt;\n    ( \n        new CustomLogFormatter()\n    )\n)\n.Build()\n.RunAsync();\n</code></pre> <pre><code>public class CustomLogFormatter : ILogFormatter\n{\n    public object FormatLogEntry(LogEntry logEntry)\n    {\n        return new\n        {\n            Message = logEntry.Message,\n            Service = logEntry.Service,\n            CorrelationIds = new\n            {\n                AwsRequestId = logEntry.LambdaContext?.AwsRequestId,\n                XRayTraceId = logEntry.XRayTraceId,\n                CorrelationId = logEntry.CorrelationId\n            },\n            LambdaFunction = new\n            {\n                Name = logEntry.LambdaContext?.FunctionName,\n                Arn = logEntry.LambdaContext?.InvokedFunctionArn,\n                MemoryLimitInMB = logEntry.LambdaContext?.MemoryLimitInMB,\n                Version = logEntry.LambdaContext?.FunctionVersion,\n                ColdStart = logEntry.ColdStart,\n            },\n            Level = logEntry.Level.ToString(),\n            Timestamp = logEntry.Timestamp.ToString(\"o\"),\n            Logger = new\n            {\n            Name = logEntry.Name,\n            SampleRate = logEntry.SamplingRate\n            },\n        };\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/logging/#anonymous-types",
            "title": "Anonymous types",
            "text": "<p>Note</p> <p>While we support anonymous type serialization by converting to a <code>Dictionary&lt;string, object&gt;</code>, this is not a best practice and is not recommended when using native AOT. </p> <p>We recommend using concrete classes and adding them to your <code>JsonSerializerContext</code>.</p>"
        },
        {
            "location": "core/metrics-v2/",
            "title": "Metrics V2",
            "text": "<p>Metrics creates custom metrics asynchronously by logging metrics to standard output following Amazon CloudWatch Embedded Metric Format (EMF).</p> <p>These metrics can be visualized through Amazon CloudWatch Console.</p>"
        },
        {
            "location": "core/metrics-v2/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Aggregate up to 100 metrics using a single CloudWatch EMF object (large JSON blob)</li> <li>Validating your metrics against common metric definitions mistakes (for example, metric unit, values, max dimensions, max metrics)</li> <li>Metrics are created asynchronously by the CloudWatch service. You do not need any custom stacks, and there is no impact to Lambda function latency</li> <li>Context manager to create a one off metric with a different dimension</li> <li>Ahead-of-Time compilation to native code support AOT from version 1.7.0</li> <li>Support for AspNetCore middleware and filters to capture metrics for HTTP requests</li> </ul>"
        },
        {
            "location": "core/metrics-v2/#breaking-changes-from-v1",
            "title": "Breaking changes from V1",
            "text": "<ul> <li><code>Dimensions</code> outputs as an array of arrays instead of an array of objects. Example: <code>Dimensions: [[\"service\", \"Environment\"]]</code> instead of <code>Dimensions: [\"service\", \"Environment\"]</code></li> <li><code>FunctionName</code> is not added as default dimension and only to cold start metric.</li> <li><code>Default Dimensions</code> can now be included in Cold Start metrics, this is a potential breaking change if you were relying on the absence of default dimensions in Cold Start metrics when searching.</li> </ul> Metrics showcase - Metrics Explorer"
        },
        {
            "location": "core/metrics-v2/#installation",
            "title": "Installation",
            "text": "<p>Powertools for AWS Lambda (.NET) are available as NuGet packages. You can install the packages from NuGet Gallery or from Visual Studio editor by searching <code>AWS.Lambda.Powertools*</code> to see various utilities available.</p> <ul> <li> <p>AWS.Lambda.Powertools.Metrics:</p> <p><code>dotnet add package AWS.Lambda.Powertools.Metrics</code></p> </li> </ul>"
        },
        {
            "location": "core/metrics-v2/#terminologies",
            "title": "Terminologies",
            "text": "<p>If you're new to Amazon CloudWatch, there are two terminologies you must be aware of before using this utility:</p> <ul> <li>Namespace. It's the highest level container that will group multiple metrics from multiple services for a given application, for example <code>ServerlessEcommerce</code>.</li> <li>Dimensions. Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example <code>ColdStart</code> metric by Payment <code>service</code>.</li> <li>Metric. It's the name of the metric, for example: SuccessfulBooking or UpdatedBooking.</li> <li>Unit. It's a value representing the unit of measure for the corresponding metric, for example: Count or Seconds.</li> <li>Resolution. It's a value representing the storage resolution for the corresponding metric. Metrics can be either Standard or High resolution. Read more here.</li> </ul> <p>Visit the AWS documentation for a complete explanation for Amazon CloudWatch concepts.</p> Metric terminology, visually explained"
        },
        {
            "location": "core/metrics-v2/#getting-started",
            "title": "Getting started",
            "text": "<p><code>Metrics</code> is implemented as a Singleton to keep track of your aggregate metrics in memory and make them accessible anywhere in your code. To guarantee that metrics are flushed properly the <code>MetricsAttribute</code> must be added on the lambda handler.</p> <p>Metrics has three global settings that will be used across all metrics emitted. Use your application or main service as the metric namespace to easily group all metrics:</p> Setting Description Environment variable Decorator parameter Metric namespace Logical container where all metrics will be placed e.g. <code>MyCompanyEcommerce</code> <code>POWERTOOLS_METRICS_NAMESPACE</code> <code>Namespace</code> Service Optionally, sets Service metric dimension across all metrics e.g. <code>payment</code> <code>POWERTOOLS_SERVICE_NAME</code> <code>Service</code> Disable Powertools Metrics Optionally, disables all Powertools metrics <code>POWERTOOLS_METRICS_DISABLED</code> N/A Info <p><code>POWERTOOLS_METRICS_DISABLED</code> will not disable default metrics created by AWS services.</p> <p>Autocomplete Metric Units</p> <p>All parameters in <code>Metrics Attribute</code> are optional. Following rules apply:</p> <ul> <li>Namespace: <code>Empty</code> string by default. You can either specify it in code or environment variable. If not present before flushing metrics, a <code>SchemaValidationException</code> will be thrown.</li> <li>Service: <code>service_undefined</code> by default. You can either specify it in code or environment variable.</li> <li>CaptureColdStart: <code>false</code> by default. </li> <li>RaiseOnEmptyMetrics: <code>false</code> by default.</li> </ul>"
        },
        {
            "location": "core/metrics-v2/#metrics-object",
            "title": "Metrics object",
            "text": ""
        },
        {
            "location": "core/metrics-v2/#attribute",
            "title": "Attribute",
            "text": "<p>The <code>MetricsAttribute</code> is a class-level attribute that can be used to set the namespace and service for all metrics emitted by the lambda handler.</p> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\n[Metrics(Namespace = \"ExampleApplication\", Service = \"Booking\")]\npublic async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n{\n    ...\n}\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#methods",
            "title": "Methods",
            "text": "<p>The <code>Metrics</code> class provides methods to add metrics, dimensions, and metadata to the metrics object.</p> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n{\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    Metrics.AddDimension(\"Environment\", \"Prod\");\n    Metrics.AddMetadata(\"BookingId\", \"683EEB2D-B2F3-4075-96EE-788E6E2EED45\");\n    ...\n}\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#initialization",
            "title": "Initialization",
            "text": "<p>The <code>Metrics</code> object is initialized as a Singleton and can be accessed anywhere in your code.</p> <p>But can also be initialize with <code>Configure</code> or <code>Builder</code> patterns in your Lambda constructor, this the best option for testing.</p> <p>Configure:</p> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic Function()\n{\n    Metrics.Configure(options =&gt;\n    {\n        options.Namespace = \"dotnet-powertools-test\";\n        options.Service = \"testService\";\n        options.CaptureColdStart = true;\n        options.DefaultDimensions = new Dictionary&lt;string, string&gt;\n        {\n            { \"Environment\", \"Prod\" },\n            { \"Another\", \"One\" }\n        };\n    });\n}\n\n[Metrics]\npublic async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n{\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    ...\n}\n</code></pre> <p>Builder:</p> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\nprivate readonly IMetrics _metrics;\n\npublic Function()\n{\n    _metrics = new MetricsBuilder()\n        .WithCaptureColdStart(true)\n        .WithService(\"testService\")\n        .WithNamespace(\"dotnet-powertools-test\")\n        .WithDefaultDimensions(new Dictionary&lt;string, string&gt;\n        {\n            { \"Environment\", \"Prod1\" },\n            { \"Another\", \"One\" }\n        }).Build();\n}\n\n[Metrics]\npublic async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n{\n    _metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    ...\n}\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#creating-metrics",
            "title": "Creating metrics",
            "text": "<p>You can create metrics using <code>AddMetric</code>, and you can create dimensions for all your aggregate metrics using <code>AddDimension</code> method.</p> MetricsMetrics with custom dimensions <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = \"ExampleApplication\", Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n  }\n}\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = \"ExampleApplication\", Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddDimension(\"Environment\",\"Prod\");\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n  }\n}\n</code></pre> <p>Autocomplete Metric Units</p> <p><code>MetricUnit</code> enum facilitates finding a supported metric unit by CloudWatch.</p> <p>Metrics overflow</p> <p>CloudWatch EMF supports a max of 100 metrics per batch. Metrics utility will flush all metrics when adding the 100th metric. Subsequent metrics, e.g. 101th, will be aggregated into a new EMF object, for your convenience.</p> <p>Metric value must be a positive number</p> <p>Metric values must be a positive number otherwise an <code>ArgumentException</code> will be thrown.</p> <p>Do not create metrics or dimensions outside the handler</p> <p>Metrics or dimensions added in the global scope will only be added during cold start. Disregard if that's the intended behavior.</p>"
        },
        {
            "location": "core/metrics-v2/#adding-high-resolution-metrics",
            "title": "Adding high-resolution metrics",
            "text": "<p>You can create high-resolution metrics passing <code>MetricResolution</code> as parameter to <code>AddMetric</code>.</p> <p>When is it useful?</p> <p>High-resolution metrics are data with a granularity of one second and are very useful in several situations such as telemetry, time series, real-time incident management, and others.</p> Metrics with high resolution <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = \"ExampleApplication\", Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    // Publish a metric with standard resolution i.e. StorageResolution = 60\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count, MetricResolution.Standard);\n\n    // Publish a metric with high resolution i.e. StorageResolution = 1\n    Metrics.AddMetric(\"FailedBooking\", 1, MetricUnit.Count, MetricResolution.High);\n\n    // The last parameter (storage resolution) is optional\n    Metrics.AddMetric(\"SuccessfulUpgrade\", 1, MetricUnit.Count);\n  }\n}\n</code></pre> <p>Autocomplete Metric Resolutions</p> <p>Use the <code>MetricResolution</code> enum to easily find a supported metric resolution by CloudWatch.</p>"
        },
        {
            "location": "core/metrics-v2/#adding-default-dimensions",
            "title": "Adding default dimensions",
            "text": "<p>You can use <code>SetDefaultDimensions</code> method to persist dimensions across Lambda invocations.</p> SetDefaultDimensions method <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n  private Dictionary&lt;string, string&gt; _defaultDimensions = new Dictionary&lt;string, string&gt;{\n        {\"Environment\", \"Prod\"},\n        {\"Another\", \"One\"}\n    }; \n\n  [Metrics(Namespace = \"ExampleApplication\", Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.SetDefaultDimensions(_defaultDimensions);\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n  }\n}\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#adding-default-dimensions-with-cold-start-metric",
            "title": "Adding default dimensions with cold start metric",
            "text": "<p>You can use the Builder or Configure patterns in your Lambda class constructor to set default dimensions.</p> Builder patternConfigure pattern <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n  private readonly IMetrics _metrics;\n\n  public Function()\n  {\n    _metrics = new MetricsBuilder()\n        .WithCaptureColdStart(true)\n        .WithService(\"testService\")\n        .WithNamespace(\"dotnet-powertools-test\")\n        .WithDefaultDimensions(new Dictionary&lt;string, string&gt;\n        {\n            { \"Environment\", \"Prod1\" },\n            { \"Another\", \"One\" }\n        }).Build();\n  }\n\n  [Metrics]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    _metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    ...\n}\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  public Function()\n  {\n    Metrics.Configure(options =&gt;\n    {\n        options.Namespace = \"dotnet-powertools-test\";\n        options.Service = \"testService\";\n        options.CaptureColdStart = true;\n        options.DefaultDimensions = new Dictionary&lt;string, string&gt;\n        {\n            { \"Environment\", \"Prod\" },\n            { \"Another\", \"One\" }\n        };\n    });\n  }\n\n  [Metrics]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    ...\n}\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#adding-dimensions",
            "title": "Adding dimensions",
            "text": "<p>You can add dimensions to your metrics using <code>AddDimension</code> method.</p> Function.csExample CloudWatch Logs excerpt <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = \"ExampleApplication\", Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddDimension(\"Environment\",\"Prod\");\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n  }\n}\n</code></pre> <pre><code>{\n    \"SuccessfulBooking\": 1.0,\n    \"_aws\": {\n        \"Timestamp\": 1592234975665,\n        \"CloudWatchMetrics\": [\n            {\n        \"Namespace\": \"ExampleApplication\",\n        \"Dimensions\": [\n            [\n                \"service\",\n                \"Environment\"\n            ]\n        ],\n        \"Metrics\": [\n            {\n                \"Name\": \"SuccessfulBooking\",\n                \"Unit\": \"Count\"\n            }\n            ]\n        }\n    ]\n},\n\"service\": \"ExampleService\",\n\"Environment\": \"Prod\"\n}\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#flushing-metrics",
            "title": "Flushing metrics",
            "text": "<p>With <code>MetricsAttribute</code> all your metrics are validated, serialized and flushed to standard output when lambda handler completes execution or when you had the 100th metric to memory.</p> <p>You can also flush metrics manually by calling <code>Flush</code> method.</p> <p>During metrics validation, if no metrics are provided then a warning will be logged, but no exception will be raised.</p> Function.csExample CloudWatch Logs excerpt <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = \"ExampleApplication\", Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    Metrics.Flush();\n  }\n}\n</code></pre> <pre><code>{\n\"BookingConfirmation\": 1.0,\n\"_aws\": {\n    \"Timestamp\": 1592234975665,\n    \"CloudWatchMetrics\": [\n        {\n    \"Namespace\": \"ExampleApplication\",\n    \"Dimensions\": [\n        [\n        \"service\"\n        ]\n    ],\n    \"Metrics\": [\n        {\n        \"Name\": \"BookingConfirmation\",\n        \"Unit\": \"Count\"\n        }\n    ]\n        }\n    ]\n    },\n\"service\": \"ExampleService\"\n}\n</code></pre> <p>Metric validation</p> <p>If metrics are provided, and any of the following criteria are not met, <code>SchemaValidationException</code> will be raised:</p> <ul> <li>Maximum of 30 dimensions</li> <li>Namespace is set</li> <li>Metric units must be supported by CloudWatch</li> </ul> <p>We do not emit 0 as a value for ColdStart metric for cost reasons. Let us know if you'd prefer a flag to override it</p>"
        },
        {
            "location": "core/metrics-v2/#raising-schemavalidationexception-on-empty-metrics",
            "title": "Raising SchemaValidationException on empty metrics",
            "text": "<p>If you want to ensure that at least one metric is emitted, you can pass <code>RaiseOnEmptyMetrics</code> to the Metrics attribute:</p> Function.cs <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(RaiseOnEmptyMetrics = true)]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    ...\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#capturing-cold-start-metric",
            "title": "Capturing cold start metric",
            "text": "<p>You can optionally capture cold start metrics by setting <code>CaptureColdStart</code> parameter to <code>true</code>.</p> Function.csBuilder patternConfigure pattern <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(CaptureColdStart = true)]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    ...\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n  private readonly IMetrics _metrics;\n\n  public Function()\n  {\n    _metrics = new MetricsBuilder()\n        .WithCaptureColdStart(true)\n        .WithService(\"testService\")\n        .WithNamespace(\"dotnet-powertools-test\")\n  }\n\n  [Metrics]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    _metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    ...\n}\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  public Function()\n  {\n    Metrics.Configure(options =&gt;\n    {\n        options.Namespace = \"dotnet-powertools-test\";\n        options.Service = \"testService\";\n        options.CaptureColdStart = true;\n    });\n  }\n\n  [Metrics]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    ...\n}\n</code></pre> <p>If it's a cold start invocation, this feature will:</p> <ul> <li>Create a separate EMF blob solely containing a metric named <code>ColdStart</code></li> <li>Add <code>FunctionName</code> and <code>Service</code> dimensions</li> </ul> <p>This has the advantage of keeping cold start metric separate from your application metrics, where you might have unrelated dimensions.</p>"
        },
        {
            "location": "core/metrics-v2/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/metrics-v2/#adding-metadata",
            "title": "Adding metadata",
            "text": "<p>You can add high-cardinality data as part of your Metrics log with <code>AddMetadata</code> method. This is useful when you want to search highly contextual information along with your metrics in your logs.</p> <p>Info</p> <p>This will not be available during metrics visualization - Use dimensions for this purpose</p> <p>Info</p> <p>Adding metadata with a key that is the same as an existing metric will be ignored</p> Function.csExample CloudWatch Logs excerpt <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = ExampleApplication, Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    Metrics.AddMetadata(\"BookingId\", \"683EEB2D-B2F3-4075-96EE-788E6E2EED45\");\n    ...\n</code></pre> <pre><code>{\n  \"SuccessfulBooking\": 1.0,\n  \"_aws\": {\n  \"Timestamp\": 1592234975665,\n  \"CloudWatchMetrics\": [\n    {\n  \"Namespace\": \"ExampleApplication\",\n  \"Dimensions\": [\n    [\n    \"service\"\n    ]\n  ],\n  \"Metrics\": [\n    {\n    \"Name\": \"SuccessfulBooking\",\n    \"Unit\": \"Count\"\n    }\n  ]\n    }\n  ]\n  },\n  \"Service\": \"Booking\",\n  \"BookingId\": \"683EEB2D-B2F3-4075-96EE-788E6E2EED45\"\n}\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#single-metric-with-a-different-dimension",
            "title": "Single metric with a different dimension",
            "text": "<p>CloudWatch EMF uses the same dimensions across all your metrics. Use <code>PushSingleMetric</code> if you have a metric that should have different dimensions.</p> <p>Info</p> <p>Generally, this would be an edge case since you pay for unique metric. Keep the following formula in mind:</p> <p>unique metric = (metric_name + dimension_name + dimension_value)</p> Function.cs <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = ExampleApplication, Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.PushSingleMetric(\n                name: \"ColdStart\",\n                value: 1,\n                unit: MetricUnit.Count,\n                nameSpace: \"ExampleApplication\",\n                service: \"Booking\");\n    ...\n</code></pre> <p>By default it will skip all previously defined dimensions including default dimensions. Use <code>dimensions</code> argument if you want to reuse default dimensions or specify custom dimensions from a dictionary.</p> <ul> <li><code>Metrics.DefaultDimensions</code>: Reuse default dimensions when using static Metrics</li> <li><code>Options.DefaultDimensions</code>: Reuse default dimensions when using Builder or Configure patterns</li> </ul> New Default Dimensions.csDefault Dimensions static.csDefault Dimensions Options / Builder patterns <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = ExampleApplication, Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.PushSingleMetric(\n                name: \"ColdStart\",\n                value: 1,\n                unit: MetricUnit.Count,\n                nameSpace: \"ExampleApplication\",\n                service: \"Booking\",\n                dimensions: new Dictionary&lt;string, string&gt;\n                {\n                    {\"FunctionContext\", \"$LATEST\"}\n                });\n    ...\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = ExampleApplication, Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n     Metrics.SetDefaultDimensions(new Dictionary&lt;string, string&gt; \n    {\n        { \"Default\", \"SingleMetric\" }\n    });\n    Metrics.PushSingleMetric(\"SingleMetric\", 1, MetricUnit.Count, dimensions: Metrics.DefaultDimensions );\n    ...\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic MetricsnBuilderHandler(IMetrics metrics = null)\n{\n    _metrics = metrics ?? new MetricsBuilder()\n        .WithCaptureColdStart(true)\n        .WithService(\"testService\")\n        .WithNamespace(\"dotnet-powertools-test\")\n        .WithDefaultDimensions(new Dictionary&lt;string, string&gt;\n        {\n            { \"Environment\", \"Prod1\" },\n            { \"Another\", \"One\" }\n        }).Build();\n}\n\npublic void HandlerSingleMetricDimensions()\n{\n    _metrics.PushSingleMetric(\"SuccessfulBooking\", 1, MetricUnit.Count, dimensions: _metrics.Options.DefaultDimensions);\n}\n    ...\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#cold-start-function-name-dimension",
            "title": "Cold start Function Name dimension",
            "text": "<p>In cases where you want to customize the <code>FunctionName</code> dimension in Cold Start metrics.</p> <p>This is useful where you want to maintain the same name in case of auto generated handler names (cdk, top-level statement functions, etc.)</p> <p>Example:</p> In decoratorConfigure / Builder patterns <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(FunctionName = \"MyFunctionName\", Namespace = \"ExampleApplication\", Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    ...\n  }\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  public Function()\n  {\n    Metrics.Configure(options =&gt;\n    {\n        options.Namespace = \"dotnet-powertools-test\";\n        options.Service = \"testService\";\n        options.CaptureColdStart = true;\n        options.FunctionName = \"MyFunctionName\";\n    });\n  }\n\n  [Metrics]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    ...\n  }\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#aspnetcore",
            "title": "AspNetCore",
            "text": ""
        },
        {
            "location": "core/metrics-v2/#installation_1",
            "title": "Installation",
            "text": "<p>To use the Metrics middleware in an ASP.NET Core application, you need to install the <code>AWS.Lambda.Powertools.Metrics.AspNetCore</code> NuGet package.</p> <pre><code>dotnet add package AWS.Lambda.Powertools.Metrics.AspNetCore\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#usemetrics-middleware",
            "title": "UseMetrics() Middleware",
            "text": "<p>The <code>UseMetrics</code> middleware is an extension method for the <code>IApplicationBuilder</code> interface.</p> <p>It adds a metrics middleware to the specified application builder, which captures cold start metrics (if enabled) and flushes metrics on function exit.</p>"
        },
        {
            "location": "core/metrics-v2/#example",
            "title": "Example",
            "text": "<pre><code>using AWS.Lambda.Powertools.Metrics.AspNetCore.Http;\n\nvar builder = WebApplication.CreateBuilder(args);\n\n// Configure metrics\nbuilder.Services.AddSingleton&lt;IMetrics&gt;(_ =&gt; new MetricsBuilder()\n    .WithNamespace(\"MyApi\") // Namespace for the metrics\n    .WithService(\"WeatherService\") // Service name for the metrics\n    .WithCaptureColdStart(true) // Capture cold start metrics\n    .WithDefaultDimensions(new Dictionary&lt;string, string&gt; // Default dimensions for the metrics\n    {\n        {\"Environment\", \"Prod\"},\n        {\"Another\", \"One\"}\n    })\n    .Build()); // Build the metrics\n\nbuilder.Services.AddAWSLambdaHosting(LambdaEventSource.RestApi);\n\nvar app = builder.Build();\n\napp.UseMetrics(); // Add the metrics middleware\n\napp.MapGet(\"/powertools\", (IMetrics metrics) =&gt; \n    {\n        // add custom metrics\n        metrics.AddMetric(\"MyCustomMetric\", 1, MetricUnit.Count);\n        // flush metrics - this is required to ensure metrics are sent to CloudWatch\n        metrics.Flush();\n    });\n\napp.Run();\n</code></pre> <p>Here is the highlighted <code>UseMetrics</code> method:</p> <pre><code>/// &lt;summary&gt;\n/// Adds a metrics middleware to the specified application builder.\n/// This will capture cold start (if CaptureColdStart is enabled) metrics and flush metrics on function exit.\n/// &lt;/summary&gt;\n/// &lt;param name=\"app\"&gt;The application builder to add the metrics middleware to.&lt;/param&gt;\n/// &lt;returns&gt;The application builder with the metrics middleware added.&lt;/returns&gt;\npublic static IApplicationBuilder UseMetrics(this IApplicationBuilder app)\n{\n    app.UseMiddleware&lt;MetricsMiddleware&gt;();\n    return app;\n}\n</code></pre> <p>Explanation:</p> <ul> <li>The method is defined as an extension method for the <code>IApplicationBuilder</code> interface.</li> <li>It adds a <code>MetricsMiddleware</code> to the application builder using the <code>UseMiddleware</code> method.</li> <li>The <code>MetricsMiddleware</code> captures and records metrics for HTTP requests, including cold start metrics if the <code>CaptureColdStart</code> option is enabled.</li> </ul>"
        },
        {
            "location": "core/metrics-v2/#withmetrics-filter",
            "title": "WithMetrics() filter",
            "text": "<p>The <code>WithMetrics</code> method is an extension method for the <code>RouteHandlerBuilder</code> class.</p> <p>It adds a metrics filter to the specified route handler builder, which captures cold start metrics (if enabled) and flushes metrics on function exit.</p>"
        },
        {
            "location": "core/metrics-v2/#example_1",
            "title": "Example",
            "text": "<pre><code>using AWS.Lambda.Powertools.Metrics;\nusing AWS.Lambda.Powertools.Metrics.AspNetCore.Http;\n\nvar builder = WebApplication.CreateBuilder(args);\n\n// Configure metrics\nbuilder.Services.AddSingleton&lt;IMetrics&gt;(_ =&gt; new MetricsBuilder()\n    .WithNamespace(\"MyApi\") // Namespace for the metrics\n    .WithService(\"WeatherService\") // Service name for the metrics\n    .WithCaptureColdStart(true) // Capture cold start metrics\n    .WithDefaultDimensions(new Dictionary&lt;string, string&gt; // Default dimensions for the metrics\n    {\n        {\"Environment\", \"Prod\"},\n        {\"Another\", \"One\"}\n    })\n    .Build()); // Build the metrics\n\n// Add AWS Lambda support. When the application is run in Lambda, Kestrel is swapped out as the web server with Amazon.Lambda.AspNetCoreServer. This\n// package will act as the web server translating requests and responses between the Lambda event source and ASP.NET Core.\nbuilder.Services.AddAWSLambdaHosting(LambdaEventSource.RestApi);\n\nvar app = builder.Build();\n\napp.MapGet(\"/powertools\", (IMetrics metrics) =&gt; \n    {\n        // add custom metrics\n        metrics.AddMetric(\"MyCustomMetric\", 1, MetricUnit.Count);\n        // flush metrics - this is required to ensure metrics are sent to CloudWatch\n        metrics.Flush();\n    })\n    .WithMetrics();\n\napp.Run();\n</code></pre> <p>Here is the highlighted <code>WithMetrics</code> method:</p> <pre><code>/// &lt;summary&gt;\n/// Adds a metrics filter to the specified route handler builder.\n/// This will capture cold start (if CaptureColdStart is enabled) metrics and flush metrics on function exit.\n/// &lt;/summary&gt;\n/// &lt;param name=\"builder\"&gt;The route handler builder to add the metrics filter to.&lt;/param&gt;\n/// &lt;returns&gt;The route handler builder with the metrics filter added.&lt;/returns&gt;\npublic static RouteHandlerBuilder WithMetrics(this RouteHandlerBuilder builder)\n{\n    builder.AddEndpointFilter&lt;MetricsFilter&gt;();\n    return builder;\n}\n</code></pre> <p>Explanation:</p> <ul> <li>The method is defined as an extension method for the <code>RouteHandlerBuilder</code> class.</li> <li>It adds a <code>MetricsFilter</code> to the route handler builder using the <code>AddEndpointFilter</code> method.</li> <li>The <code>MetricsFilter</code> captures and records metrics for HTTP endpoints, including cold start metrics if the <code>CaptureColdStart</code> option is enabled.</li> <li>The method returns the modified <code>RouteHandlerBuilder</code> instance with the metrics filter added.</li> </ul>"
        },
        {
            "location": "core/metrics-v2/#testing-your-code",
            "title": "Testing your code",
            "text": ""
        },
        {
            "location": "core/metrics-v2/#unit-testing",
            "title": "Unit testing",
            "text": "<p>To test your code that uses the Metrics utility, you can use the <code>TestLambdaContext</code> class from the <code>Amazon.Lambda.TestUtilities</code> package.</p> <p>You can also use the <code>IMetrics</code> interface to mock the Metrics utility in your tests.</p> <p>Here is an example of how you can test a Lambda function that uses the Metrics utility:</p>"
        },
        {
            "location": "core/metrics-v2/#lambda-function",
            "title": "Lambda Function",
            "text": "<pre><code>using System.Collections.Generic;\nusing Amazon.Lambda.Core;\n\npublic class MetricsnBuilderHandler\n{\n    private readonly IMetrics _metrics;\n\n    // Allow injection of IMetrics for testing\n    public MetricsnBuilderHandler(IMetrics metrics = null)\n    {\n        _metrics = metrics ?? new MetricsBuilder()\n            .WithCaptureColdStart(true)\n            .WithService(\"testService\")\n            .WithNamespace(\"dotnet-powertools-test\")\n            .WithDefaultDimensions(new Dictionary&lt;string, string&gt;\n            {\n                { \"Environment\", \"Prod1\" },\n                { \"Another\", \"One\" }\n            }).Build();\n    }\n\n    [Metrics]\n    public void Handler(ILambdaContext context)\n    {\n        _metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#unit-tests",
            "title": "Unit Tests",
            "text": "<pre><code>[Fact]\n    public void Handler_With_Builder_Should_Configure_In_Constructor()\n    {\n        // Arrange\n        var handler = new MetricsnBuilderHandler();\n\n        // Act\n        handler.Handler(new TestLambdaContext\n        {\n            FunctionName = \"My_Function_Name\"\n        });\n\n        // Get the output and parse it\n        var metricsOutput = _consoleOut.ToString();\n\n        // Assert cold start\n        Assert.Contains(\n            \"\\\"CloudWatchMetrics\\\":[{\\\"Namespace\\\":\\\"dotnet-powertools-test\\\",\\\"Metrics\\\":[{\\\"Name\\\":\\\"ColdStart\\\",\\\"Unit\\\":\\\"Count\\\"}],\\\"Dimensions\\\":[[\\\"Service\\\",\\\"Environment\\\",\\\"Another\\\",\\\"FunctionName\\\"]]}]},\\\"Service\\\":\\\"testService\\\",\\\"Environment\\\":\\\"Prod1\\\",\\\"Another\\\":\\\"One\\\",\\\"FunctionName\\\":\\\"My_Function_Name\\\",\\\"ColdStart\\\":1}\",\n            metricsOutput);\n        // Assert successful Memory metrics\n        Assert.Contains(\n            \"\\\"CloudWatchMetrics\\\":[{\\\"Namespace\\\":\\\"dotnet-powertools-test\\\",\\\"Metrics\\\":[{\\\"Name\\\":\\\"SuccessfulBooking\\\",\\\"Unit\\\":\\\"Count\\\"}],\\\"Dimensions\\\":[[\\\"Service\\\",\\\"Environment\\\",\\\"Another\\\",\\\"FunctionName\\\"]]}]},\\\"Service\\\":\\\"testService\\\",\\\"Environment\\\":\\\"Prod1\\\",\\\"Another\\\":\\\"One\\\",\\\"FunctionName\\\":\\\"My_Function_Name\\\",\\\"SuccessfulBooking\\\":1}\",\n            metricsOutput);\n    }\n\n    [Fact]\n    public void Handler_With_Builder_Should_Configure_In_Constructor_Mock()\n    {\n        var metricsMock = Substitute.For&lt;IMetrics&gt;();\n\n        metricsMock.Options.Returns(new MetricsOptions\n        {\n            CaptureColdStart = true,\n            Namespace = \"dotnet-powertools-test\",\n            Service = \"testService\",\n            DefaultDimensions = new Dictionary&lt;string, string&gt;\n            {\n                { \"Environment\", \"Prod\" },\n                { \"Another\", \"One\" }\n            }\n        });\n\n        Metrics.UseMetricsForTests(metricsMock);\n\n        var sut = new MetricsnBuilderHandler(metricsMock);\n\n        // Act\n        sut.Handler(new TestLambdaContext\n        {\n            FunctionName = \"My_Function_Name\"\n        });\n\n        metricsMock.Received(1).PushSingleMetric(\"ColdStart\", 1, MetricUnit.Count, \"dotnet-powertools-test\",\n            service: \"testService\", Arg.Any&lt;Dictionary&lt;string, string&gt;&gt;());\n        metricsMock.Received(1).AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    }\n</code></pre>"
        },
        {
            "location": "core/metrics-v2/#environment-variables",
            "title": "Environment variables",
            "text": "Tip <p>Ignore this section, if:</p> <ul> <li>You are explicitly setting namespace/default dimension via <code>namespace</code> and <code>service</code> parameters</li> <li>You're not instantiating <code>Metrics</code> in the global namespace</li> </ul> <p>For example, <code>Metrics(namespace=\"ExampleApplication\", service=\"booking\")</code></p> <p>Make sure to set <code>POWERTOOLS_METRICS_NAMESPACE</code> and <code>POWERTOOLS_SERVICE_NAME</code> before running your tests to prevent failing on <code>SchemaValidation</code> exception. You can set it before you run tests by adding the environment variable.</p> Injecting Metric Namespace before running tests<pre><code>Environment.SetEnvironmentVariable(\"POWERTOOLS_METRICS_NAMESPACE\",\"AWSLambdaPowertools\");\n</code></pre>"
        },
        {
            "location": "core/metrics/",
            "title": "Metrics",
            "text": "<p>Metrics creates custom metrics asynchronously by logging metrics to standard output following Amazon CloudWatch Embedded Metric Format (EMF).</p> <p>These metrics can be visualized through Amazon CloudWatch Console.</p>"
        },
        {
            "location": "core/metrics/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Aggregate up to 100 metrics using a single CloudWatch EMF object (large JSON blob)</li> <li>Validating your metrics against common metric definitions mistakes (for example, metric unit, values, max dimensions, max metrics)</li> <li>Metrics are created asynchronously by the CloudWatch service. You do not need any custom stacks, and there is no impact to Lambda function latency</li> <li>Context manager to create a one off metric with a different dimension</li> <li>Ahead-of-Time compilation to native code support AOT from version 1.7.0</li> </ul> Metrics showcase - Metrics Explorer"
        },
        {
            "location": "core/metrics/#installation",
            "title": "Installation",
            "text": "<p>Powertools for AWS Lambda (.NET) are available as NuGet packages. You can install the packages from NuGet Gallery or from Visual Studio editor by searching <code>AWS.Lambda.Powertools*</code> to see various utilities available.</p> <ul> <li> <p>AWS.Lambda.Powertools.Metrics:</p> <p><code>dotnet add package AWS.Lambda.Powertools.Metrics -v 1.7.1</code></p> </li> </ul>"
        },
        {
            "location": "core/metrics/#terminologies",
            "title": "Terminologies",
            "text": "<p>If you're new to Amazon CloudWatch, there are two terminologies you must be aware of before using this utility:</p> <ul> <li>Namespace. It's the highest level container that will group multiple metrics from multiple services for a given application, for example <code>ServerlessEcommerce</code>.</li> <li>Dimensions. Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example <code>ColdStart</code> metric by Payment <code>service</code>.</li> <li>Metric. It's the name of the metric, for example: SuccessfulBooking or UpdatedBooking.</li> <li>Unit. It's a value representing the unit of measure for the corresponding metric, for example: Count or Seconds.</li> <li>Resolution. It's a value representing the storage resolution for the corresponding metric. Metrics can be either Standard or High resolution. Read more here.</li> </ul> <p>Visit the AWS documentation for a complete explanation for Amazon CloudWatch concepts.</p> Metric terminology, visually explained"
        },
        {
            "location": "core/metrics/#getting-started",
            "title": "Getting started",
            "text": "<p><code>Metrics</code> is implemented as a Singleton to keep track of your aggregate metrics in memory and make them accessible anywhere in your code. To guarantee that metrics are flushed properly the <code>MetricsAttribute</code> must be added on the lambda handler.</p> <p>Metrics has two global settings that will be used across all metrics emitted. Use your application or main service as the metric namespace to easily group all metrics:</p> Setting Description Environment variable Constructor parameter Service Optionally, sets service metric dimension across all metrics e.g. <code>payment</code> <code>POWERTOOLS_SERVICE_NAME</code> <code>Service</code> Metric namespace Logical container where all metrics will be placed e.g. <code>MyCompanyEcommerce</code> <code>POWERTOOLS_METRICS_NAMESPACE</code> <code>Namespace</code> <p>Autocomplete Metric Units</p> <p>All parameters in <code>Metrics Attribute</code> are optional. Following rules apply:</p> <ul> <li>Namespace: <code>Empty</code> string by default. You can either specify it in code or environment variable. If not present before flushing metrics, a <code>SchemaValidationException</code> will be thrown.</li> <li>Service: <code>service_undefined</code> by default. You can either specify it in code or environment variable.</li> <li>CaptureColdStart: <code>false</code> by default. </li> <li>RaiseOnEmptyMetrics: <code>false</code> by default.</li> </ul>"
        },
        {
            "location": "core/metrics/#example-using-aws-serverless-application-model-aws-sam",
            "title": "Example using AWS Serverless Application Model (AWS SAM)",
            "text": "template.ymlFunction.cs <pre><code>Resources:\nHelloWorldFunction:\n    Type: AWS::Serverless::Function \n    Properties:\n    ...\n    Environment: \n    Variables:\n        POWERTOOLS_SERVICE_NAME: ShoppingCartService\n        POWERTOOLS_METRICS_NAMESPACE: MyCompanyEcommerce\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n  [Metrics(Namespace = \"MyCompanyEcommerce\", Service = \"ShoppingCartService\", CaptureColdStart = true, RaiseOnEmptyMetrics = true)]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    ...\n  }\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#full-list-of-environment-variables",
            "title": "Full list of environment variables",
            "text": "Environment variable Description Default POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging <code>\"service_undefined\"</code> POWERTOOLS_METRICS_NAMESPACE Sets namespace used for metrics <code>None</code>"
        },
        {
            "location": "core/metrics/#creating-metrics",
            "title": "Creating metrics",
            "text": "<p>You can create metrics using <code>AddMetric</code>, and you can create dimensions for all your aggregate metrics using <code>AddDimension</code> method.</p> MetricsMetrics with custom dimensions <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = \"ExampleApplication\", Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n  }\n}\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = \"ExampleApplication\", Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddDimension(\"Environment\",\"Prod\");\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n  }\n}\n</code></pre> <p>Autocomplete Metric Units</p> <p><code>MetricUnit</code> enum facilitates finding a supported metric unit by CloudWatch.</p> <p>Metrics overflow</p> <p>CloudWatch EMF supports a max of 100 metrics per batch. Metrics utility will flush all metrics when adding the 100th metric. Subsequent metrics, e.g. 101th, will be aggregated into a new EMF object, for your convenience.</p> <p>Metric value must be a positive number</p> <p>Metric values must be a positive number otherwise an <code>ArgumentException</code> will be thrown.</p> <p>Do not create metrics or dimensions outside the handler</p> <p>Metrics or dimensions added in the global scope will only be added during cold start. Disregard if that's the intended behavior.</p>"
        },
        {
            "location": "core/metrics/#adding-high-resolution-metrics",
            "title": "Adding high-resolution metrics",
            "text": "<p>You can create high-resolution metrics passing <code>MetricResolution</code> as parameter to <code>AddMetric</code>.</p> <p>When is it useful?</p> <p>High-resolution metrics are data with a granularity of one second and are very useful in several situations such as telemetry, time series, real-time incident management, and others.</p> Metrics with high resolution <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = \"ExampleApplication\", Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    // Publish a metric with standard resolution i.e. StorageResolution = 60\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count, MetricResolution.Standard);\n\n    // Publish a metric with high resolution i.e. StorageResolution = 1\n    Metrics.AddMetric(\"FailedBooking\", 1, MetricUnit.Count, MetricResolution.High);\n\n    // The last parameter (storage resolution) is optional\n    Metrics.AddMetric(\"SuccessfulUpgrade\", 1, MetricUnit.Count);\n  }\n}\n</code></pre> <p>Autocomplete Metric Resolutions</p> <p>Use the <code>MetricResolution</code> enum to easily find a supported metric resolution by CloudWatch.</p>"
        },
        {
            "location": "core/metrics/#adding-default-dimensions",
            "title": "Adding default dimensions",
            "text": "<p>You can use <code>SetDefaultDimensions</code> method to persist dimensions across Lambda invocations.</p> SetDefaultDimensions method <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n  private Dictionary&lt;string, string&gt; _defaultDimensions = new Dictionary&lt;string, string&gt;{\n        {\"Environment\", \"Prod\"},\n        {\"Another\", \"One\"}\n    }; \n\n  [Metrics(Namespace = \"ExampleApplication\", Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.SetDefaultDimensions(_defaultDimensions);\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n  }\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#flushing-metrics",
            "title": "Flushing metrics",
            "text": "<p>With <code>MetricsAttribute</code> all your metrics are validated, serialized and flushed to standard output when lambda handler completes execution or when you had the 100th metric to memory.</p> <p>During metrics validation, if no metrics are provided then a warning will be logged, but no exception will be raised.</p> Function.csExample CloudWatch Logs excerpt <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = \"ExampleApplication\", Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n  }\n}\n</code></pre> <pre><code>{\n\"BookingConfirmation\": 1.0,\n\"_aws\": {\n    \"Timestamp\": 1592234975665,\n    \"CloudWatchMetrics\": [\n        {\n    \"Namespace\": \"ExampleApplication\",\n    \"Dimensions\": [\n        [\n        \"service\"\n        ]\n    ],\n    \"Metrics\": [\n        {\n        \"Name\": \"BookingConfirmation\",\n        \"Unit\": \"Count\"\n        }\n    ]\n        }\n    ]\n    },\n\"service\": \"ExampleService\"\n}\n</code></pre> <p>Metric validation</p> <p>If metrics are provided, and any of the following criteria are not met, <code>SchemaValidationException</code> will be raised:</p> <ul> <li>Maximum of 9 dimensions</li> <li>Namespace is set</li> <li>Metric units must be supported by CloudWatch</li> </ul> <p>We do not emit 0 as a value for ColdStart metric for cost reasons. Let us know if you'd prefer a flag to override it</p>"
        },
        {
            "location": "core/metrics/#raising-schemavalidationexception-on-empty-metrics",
            "title": "Raising SchemaValidationException on empty metrics",
            "text": "<p>If you want to ensure that at least one metric is emitted, you can pass <code>RaiseOnEmptyMetrics</code> to the Metrics attribute:</p> Function.cs <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(RaiseOnEmptyMetrics = true)]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    ...\n</code></pre>"
        },
        {
            "location": "core/metrics/#capturing-cold-start-metric",
            "title": "Capturing cold start metric",
            "text": "<p>You can optionally capture cold start metrics by setting <code>CaptureColdStart</code> parameter to <code>true</code>.</p> Function.cs <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(CaptureColdStart = true)]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    ...\n</code></pre> <p>If it's a cold start invocation, this feature will:</p> <ul> <li>Create a separate EMF blob solely containing a metric named <code>ColdStart</code></li> <li>Add <code>function_name</code> and <code>service</code> dimensions</li> </ul> <p>This has the advantage of keeping cold start metric separate from your application metrics, where you might have unrelated dimensions.</p>"
        },
        {
            "location": "core/metrics/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/metrics/#adding-metadata",
            "title": "Adding metadata",
            "text": "<p>You can add high-cardinality data as part of your Metrics log with <code>AddMetadata</code> method. This is useful when you want to search highly contextual information along with your metrics in your logs.</p> <p>Info</p> <p>This will not be available during metrics visualization - Use dimensions for this purpose</p> <p>Info</p> <p>Adding metadata with a key that is the same as an existing metric will be ignored</p> Function.csExample CloudWatch Logs excerpt <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = ExampleApplication, Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.AddMetric(\"SuccessfulBooking\", 1, MetricUnit.Count);\n    Metrics.AddMetadata(\"BookingId\", \"683EEB2D-B2F3-4075-96EE-788E6E2EED45\");\n    ...\n</code></pre> <pre><code>{\n  \"SuccessfulBooking\": 1.0,\n  \"_aws\": {\n  \"Timestamp\": 1592234975665,\n  \"CloudWatchMetrics\": [\n    {\n  \"Namespace\": \"ExampleApplication\",\n  \"Dimensions\": [\n    [\n    \"service\"\n    ]\n  ],\n  \"Metrics\": [\n    {\n    \"Name\": \"SuccessfulBooking\",\n    \"Unit\": \"Count\"\n    }\n  ]\n    }\n  ]\n  },\n  \"Service\": \"Booking\",\n  \"BookingId\": \"683EEB2D-B2F3-4075-96EE-788E6E2EED45\"\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#single-metric-with-a-different-dimension",
            "title": "Single metric with a different dimension",
            "text": "<p>CloudWatch EMF uses the same dimensions across all your metrics. Use <code>PushSingleMetric</code> if you have a metric that should have different dimensions.</p> <p>Info</p> <p>Generally, this would be an edge case since you pay for unique metric. Keep the following formula in mind:</p> <p>unique metric = (metric_name + dimension_name + dimension_value)</p> Function.cs <pre><code>using AWS.Lambda.Powertools.Metrics;\n\npublic class Function {\n\n  [Metrics(Namespace = ExampleApplication, Service = \"Booking\")]\n  public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler(APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n  {\n    Metrics.PushSingleMetric(\n                metricName: \"ColdStart\",\n                value: 1,\n                unit: MetricUnit.Count,\n                nameSpace: \"ExampleApplication\",\n                service: \"Booking\",\n                defaultDimensions: new Dictionary&lt;string, string&gt;\n                {\n                    {\"FunctionContext\", \"$LATEST\"}\n                });\n    ...\n</code></pre>"
        },
        {
            "location": "core/metrics/#testing-your-code",
            "title": "Testing your code",
            "text": ""
        },
        {
            "location": "core/metrics/#environment-variables",
            "title": "Environment variables",
            "text": "Tip <p>Ignore this section, if:</p> <ul> <li>You are explicitly setting namespace/default dimension via <code>namespace</code> and <code>service</code> parameters</li> <li>You're not instantiating <code>Metrics</code> in the global namespace</li> </ul> <p>For example, <code>Metrics(namespace=\"ExampleApplication\", service=\"booking\")</code></p> <p>Make sure to set <code>POWERTOOLS_METRICS_NAMESPACE</code> and <code>POWERTOOLS_SERVICE_NAME</code> before running your tests to prevent failing on <code>SchemaValidation</code> exception. You can set it before you run tests by adding the environment variable.</p> Injecting Metric Namespace before running tests<pre><code>Environment.SetEnvironmentVariable(\"POWERTOOLS_METRICS_NAMESPACE\",\"AWSLambdaPowertools\");\n</code></pre>"
        },
        {
            "location": "core/tracing/",
            "title": "Tracing",
            "text": "<p>Powertools for AWS Lambda (.NET) tracing is an opinionated thin wrapper for AWS X-Ray .NET SDK a provides functionality to reduce the overhead of performing common tracing tasks.</p> <p></p>"
        },
        {
            "location": "core/tracing/#key-features",
            "title": "Key Features",
            "text": "<ul> <li>Helper methods to improve the developer experience for creating custom AWS X-Ray subsegments.</li> <li>Capture cold start as annotation.</li> <li>Capture function responses and full exceptions as metadata.</li> <li>Better experience when developing with multiple threads.</li> <li>Auto-patch supported modules by AWS X-Ray</li> <li>Auto-disable when not running in AWS Lambda environment</li> <li>Ahead-of-Time compilation to native code support AOT from version 1.5.0</li> </ul>"
        },
        {
            "location": "core/tracing/#installation",
            "title": "Installation",
            "text": "<p>Powertools for AWS Lambda (.NET) are available as NuGet packages. You can install the packages from NuGet Gallery or from Visual Studio editor by searching <code>AWS.Lambda.Powertools*</code> to see various utilities available.</p> <ul> <li> <p>AWS.Lambda.Powertools.Tracing:</p> <p><code>dotnet nuget add AWS.Lambda.Powertools.Tracing</code></p> </li> </ul>"
        },
        {
            "location": "core/tracing/#getting-started",
            "title": "Getting Started",
            "text": "<p>Tracer relies on AWS X-Ray SDK over OpenTelememetry Distro (ADOT) for optimal cold start (lower latency).</p> <p>Before you use this utility, your AWS Lambda function must have permissions to send traces to AWS X-Ray.</p> <p>To enable active tracing on an AWS Serverless Application Model (AWS SAM) AWS::Serverless::Function resource, use the <code>Tracing</code> property. You can use the Globals section of the AWS SAM template to set this for all  </p>"
        },
        {
            "location": "core/tracing/#using-aws-serverless-application-model-aws-sam",
            "title": "Using AWS Serverless Application Model (AWS SAM)",
            "text": "template.yaml <pre><code>Resources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n        ...\n        Runtime: dotnet6.0\n\n        Tracing: Active\n        Environment:\n            Variables:\n                POWERTOOLS_SERVICE_NAME: example\n</code></pre> <p>The Powertools for AWS Lambda (.NET) service name is used as the X-Ray namespace. This can be set using the environment variable <code>POWERTOOLS_SERVICE_NAME</code></p>"
        },
        {
            "location": "core/tracing/#full-list-of-environment-variables",
            "title": "Full list of environment variables",
            "text": "Environment variable Description Default POWERTOOLS_SERVICE_NAME Sets service name used for tracing namespace, metrics dimension and structured logging <code>\"service_undefined\"</code> POWERTOOLS_TRACE_DISABLED Disables tracing <code>false</code> POWERTOOLS_TRACER_CAPTURE_RESPONSE Captures Lambda or method return as metadata. <code>true</code> POWERTOOLS_TRACER_CAPTURE_ERROR Captures Lambda or method exception as metadata. <code>true</code>"
        },
        {
            "location": "core/tracing/#lambda-handler",
            "title": "Lambda handler",
            "text": "<p>To enable Powertools for AWS Lambda (.NET) tracing to your function add the <code>[Tracing]</code> attribute to your <code>FunctionHandler</code> method or on any method will capture the method as a separate subsegment automatically. You can optionally choose to customize segment name that appears in traces.</p> Tracing attributeCustom Segment names <pre><code>public class Function\n{\n    [Tracing]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        await BusinessLogic1()\n            .ConfigureAwait(false);\n\n        await BusinessLogic2()\n            .ConfigureAwait(false);\n    }\n\n    [Tracing]\n    private async Task BusinessLogic1()\n    {\n\n    }\n\n    [Tracing]\n    private async Task BusinessLogic2()\n    {\n\n    }\n}\n</code></pre> <pre><code>public class Function\n{\n    [Tracing(SegmentName = \"YourCustomName\")]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre> <p>By default, this attribute will automatically record method responses and exceptions. You can change the default behavior by setting the environment variables <code>POWERTOOLS_TRACER_CAPTURE_RESPONSE</code> and <code>POWERTOOLS_TRACER_CAPTURE_ERROR</code> as needed. Optionally, you can override behavior by different supported <code>CaptureMode</code> to record response, exception or both.</p> <p>Returning sensitive information from your Lambda handler or functions, where <code>Tracing</code> is used?</p> <p>You can disable attribute from capturing their responses and exception as tracing metadata with <code>captureMode=DISABLED</code> or globally by setting environment variables <code>POWERTOOLS_TRACER_CAPTURE_RESPONSE</code> and <code>POWERTOOLS_TRACER_CAPTURE_ERROR</code> to <code>false</code></p> Disable on attributeDisable Globally <pre><code>public class Function\n{\n    [Tracing(CaptureMode = TracingCaptureMode.Disabled)]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        ...\n    }\n}\n</code></pre> <pre><code>Resources:\n    HelloWorldFunction:\n        Type: AWS::Serverless::Function\n        Properties:\n        ...\n        Runtime: dotnetcore3.1\n\n        Tracing: Active\n        Environment:\n            Variables:\n                POWERTOOLS_TRACER_CAPTURE_RESPONSE: false\n                POWERTOOLS_TRACER_CAPTURE_ERROR: false\n</code></pre>"
        },
        {
            "location": "core/tracing/#annotations-metadata",
            "title": "Annotations &amp; Metadata",
            "text": "<p>Annotations are key-values associated with traces and indexed by AWS X-Ray. You can use them to filter traces and to create Trace Groups to slice and dice your transactions.</p> <p>Metadata are key-values also associated with traces but not indexed by AWS X-Ray. You can use them to add additional context for an operation using any native object.</p> AnnotationsMetadata <p>You can add annotations using <code>AddAnnotation()</code> method from Tracing <pre><code>using AWS.Lambda.Powertools.Tracing;\n\npublic class Function\n{\n    [Tracing]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        Tracing.AddAnnotation(\"annotation\", \"value\");\n    }\n}\n</code></pre></p> <p>You can add metadata using <code>AddMetadata()</code> method from Tracing <pre><code>using AWS.Lambda.Powertools.Tracing;\n\npublic class Function\n{\n    [Tracing]\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        Tracing.AddMetadata(\"content\", \"value\");\n    }\n}\n</code></pre></p>"
        },
        {
            "location": "core/tracing/#utilities",
            "title": "Utilities",
            "text": "<p>Tracing modules comes with certain utility method when you don't want to use attribute for capturing a code block under a subsegment, or you are doing multithreaded programming. Refer examples below.</p> Functional ApiMulti Threaded Programming <pre><code>using AWS.Lambda.Powertools.Tracing;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        Tracing.WithSubsegment(\"loggingResponse\", (subsegment) =&gt; {\n            // Some business logic\n        });\n\n        Tracing.WithSubsegment(\"localNamespace\", \"loggingResponse\", (subsegment) =&gt; {\n            // Some business logic\n        });\n    }\n}\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Tracing;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Extract existing trace data\n        var entity = Tracing.GetEntity();\n\n        var task = Task.Run(() =&gt;\n        {\n            Tracing.WithSubsegment(\"InlineLog\", entity, (subsegment) =&gt;\n            {\n                // Business logic in separate task\n            });\n        });\n    }\n}\n</code></pre>"
        },
        {
            "location": "core/tracing/#instrumenting-sdk-clients",
            "title": "Instrumenting SDK clients",
            "text": "<p>You should make sure to instrument the SDK clients explicitly based on the function dependency. You can instrument all of your AWS SDK for .NET clients by calling RegisterForAllServices before you create them.</p> Function.cs <pre><code>using Amazon.DynamoDBv2;\nusing Amazon.DynamoDBv2.Model;\nusing AWS.Lambda.Powertools.Tracing;\n\npublic class Function\n{\n    private static IAmazonDynamoDB _dynamoDb;\n\n    /// &lt;summary&gt;\n    /// Function constructor\n    /// &lt;/summary&gt;\n    public Function()\n    {\n        Tracing.RegisterForAllServices();\n\n        _dynamoDb = new AmazonDynamoDBClient();\n    }\n}\n</code></pre> <p>To instrument clients for some services and not others, call Register instead of RegisterForAllServices. Replace the highlighted text with the name of the service's client interface.</p> <pre><code>Tracing.Register&lt;IAmazonDynamoDB&gt;()\n</code></pre> <p>This functionality is a thin wrapper for AWS X-Ray .NET SDK. Refer details on how to instrument SDK client with Xray</p>"
        },
        {
            "location": "core/tracing/#instrumenting-outgoing-http-calls",
            "title": "Instrumenting outgoing HTTP calls",
            "text": "Function.cs <pre><code>using Amazon.XRay.Recorder.Handlers.System.Net;\n\npublic class Function\n{\n    public Function()\n    {\n        var httpClient = new HttpClient(new HttpClientXRayTracingHandler(new HttpClientHandler()));\n        var myIp = await httpClient.GetStringAsync(\"https://checkip.amazonaws.com/\");\n    }\n}\n</code></pre> <p>More information about instrumenting outgoing http calls.</p>"
        },
        {
            "location": "core/tracing/#aot-support",
            "title": "AOT Support",
            "text": "<p>Native AOT trims your application code as part of the compilation to ensure that the binary is as small as possible. .NET 8 for Lambda provides improved trimming support compared to previous versions of .NET.</p>"
        },
        {
            "location": "core/tracing/#withtracing",
            "title": "WithTracing()",
            "text": "<p>To use Tracing utility with AOT support you first need to add <code>WithTracing()</code> to the source generator you are using either the default <code>SourceGeneratorLambdaJsonSerializer</code> or the Powertools Logging utility source generator <code>PowertoolsSourceGeneratorSerializer</code>.</p> <p>Examples:</p> Without Powertools LoggingWith Powertools Logging <pre><code>using AWS.Lambda.Powertools.Tracing;\nusing AWS.Lambda.Powertools.Tracing.Serializers;\n\nprivate static async Task Main()\n{\n    Func&lt;string, ILambdaContext, string&gt; handler = FunctionHandler;\n    await LambdaBootstrapBuilder.Create(handler, new SourceGeneratorLambdaJsonSerializer&lt;LambdaFunctionJsonSerializerContext&gt;()\n    .WithTracing())\n        .Build()\n        .RunAsync();\n}\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Logging;\nusing AWS.Lambda.Powertools.Logging.Serializers;\nusing AWS.Lambda.Powertools.Tracing;\nusing AWS.Lambda.Powertools.Tracing.Serializers;\n\nprivate static async Task Main()\n{\n    Func&lt;string, ILambdaContext, string&gt; handler = FunctionHandler;\n    await LambdaBootstrapBuilder.Create(handler, \n        new PowertoolsSourceGeneratorSerializer&lt;LambdaFunctionJsonSerializerContext&gt;()\n        .WithTracing())\n            .Build()\n            .RunAsync();\n}\n</code></pre>"
        },
        {
            "location": "core/tracing/#publishing",
            "title": "Publishing",
            "text": "<p>Publishing</p> <p>Make sure you are publishing your code with <code>--self-contained true</code> and that you have <code>&lt;TrimMode&gt;partial&lt;/TrimMode&gt;</code> in your <code>.csproj</code> file </p>"
        },
        {
            "location": "core/tracing/#trimming",
            "title": "Trimming",
            "text": "<p>Trim warnings</p> <pre><code>&lt;ItemGroup&gt;\n    &lt;TrimmerRootAssembly Include=\"AWSSDK.Core\" /&gt;\n    &lt;TrimmerRootAssembly Include=\"AWSXRayRecorder.Core\" /&gt;\n    &lt;TrimmerRootAssembly Include=\"AWSXRayRecorder.Handlers.AwsSdk\" /&gt;\n    &lt;TrimmerRootAssembly Include=\"Amazon.Lambda.APIGatewayEvents\" /&gt;\n    &lt;TrimmerRootAssembly Include=\"bootstrap\" /&gt;\n    &lt;TrimmerRootAssembly Include=\"Shared\" /&gt;\n&lt;/ItemGroup&gt;\n</code></pre> <p>Note that when you receive a trim warning, adding the class that generates the warning to TrimmerRootAssembly might not resolve the issue. A trim warning indicates that the class is trying to access some other class that can't be determined until runtime. To avoid runtime errors, add this second class to TrimmerRootAssembly. </p> <p>To learn more about managing trim warnings, see Introduction to trim warnings in the Microsoft .NET documentation.</p>"
        },
        {
            "location": "core/tracing/#not-supported",
            "title": "Not supported",
            "text": "<p>Not supported</p> <p>Currently instrumenting SDK clients with <code>Tracing.RegisterForAllServices()</code> is not supported on AOT mode.</p>"
        },
        {
            "location": "utilities/batch-processing/",
            "title": "Batch Processing",
            "text": "<p>The batch processing utility handles partial failures when processing batches from Amazon SQS, Amazon Kinesis Data Streams, and Amazon DynamoDB Streams.</p> <pre><code>stateDiagram-v2\n    direction LR\n    BatchSource: Amazon SQS &lt;br/&gt;&lt;br/&gt; Amazon Kinesis Data Streams &lt;br/&gt;&lt;br/&gt; Amazon DynamoDB Streams &lt;br/&gt;&lt;br/&gt;\n    LambdaInit: Lambda invocation\n    BatchProcessor: Batch Processor\n    RecordHandler: Record Handler function\n    YourLogic: Your logic to process each batch item\n    LambdaResponse: Lambda response\n\n    BatchSource --&gt; LambdaInit\n\n    LambdaInit --&gt; BatchProcessor\n    BatchProcessor --&gt; RecordHandler\n\n    state BatchProcessor {\n        [*] --&gt; RecordHandler: Your function\n        RecordHandler --&gt; YourLogic\n    }\n\n    RecordHandler --&gt; BatchProcessor: Collect results\n    BatchProcessor --&gt; LambdaResponse: Report items that failed processing</code></pre>"
        },
        {
            "location": "utilities/batch-processing/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Reports batch item failures to reduce number of retries for a record upon errors</li> <li>Simple interface to process each batch record</li> <li>Bring your own batch processor</li> <li>Parallel processing</li> </ul>"
        },
        {
            "location": "utilities/batch-processing/#background",
            "title": "Background",
            "text": "<p>When using SQS, Kinesis Data Streams, or DynamoDB Streams as a Lambda event source, your Lambda functions are triggered with a batch of messages.</p> <p>If your function fails to process any message from the batch, the entire batch returns to your queue or stream. This same batch is then retried until either condition happens first: a) your Lambda function returns a successful response, b) record reaches maximum retry attempts, or c) when records expire.</p> <pre><code>journey\n  section Conditions\n    Successful response: 5: Success\n    Maximum retries: 3: Failure\n    Records expired: 1: Failure</code></pre> <p>This behavior changes when you enable Report Batch Item Failures feature in your Lambda function event source configuration:</p> <ul> <li>SQS queues. Only messages reported as failure will return to the queue for a retry, while successful ones will be deleted.</li> <li>Kinesis data streams and DynamoDB streams. Single reported failure will use its sequence number as the stream checkpoint. Multiple  reported failures will use the lowest sequence number as checkpoint.</li> </ul> Warning: This utility lowers the chance of processing records more than once; it does not guarantee it <p>We recommend implementing processing logic in an idempotent manner wherever possible.</p> <p>You can find more details on how Lambda works with either SQS, Kinesis, or DynamoDB in the AWS Documentation.</p>"
        },
        {
            "location": "utilities/batch-processing/#installation",
            "title": "Installation",
            "text": "<p>You should install with NuGet:</p> <pre><code>Install-Package AWS.Lambda.Powertools.BatchProcessing\n</code></pre> <p>Or via the .NET Core command line interface:</p> <pre><code>dotnet add package AWS.Lambda.Powertools.BatchProcessing\n</code></pre>"
        },
        {
            "location": "utilities/batch-processing/#getting-started",
            "title": "Getting started",
            "text": "<p>For this feature to work, you need to (1) configure your Lambda function event source to use <code>ReportBatchItemFailures</code>, and (2) return a specific response to report which records failed to be processed.</p> <p>You use your preferred deployment framework to set the correct configuration while this utility handles the correct response to be returned.</p> <p>Batch processing can be configured with the settings bellow:</p> Setting Description Environment variable Default Error Handling Policy The error handling policy to apply during batch processing. <code>POWERTOOLS_BATCH_ERROR_HANDLING_POLICY</code> <code>DeriveFromEvent</code> Parallel Enabled Controls if parallel processing of batch items is enabled. <code>POWERTOOLS_BATCH_PARALLEL_ENABLED</code> <code>false</code> Max Degree of Parallelism The maximum degree of parallelism to apply if parallel processing is enabled. <code>POWERTOOLS_BATCH_MAX_DEGREE_OF_PARALLELISM</code> <code>1</code> Throw on Full Batch Failure Controls if a <code>BatchProcessingException</code> is thrown on full batch failure. <code>POWERTOOLS_BATCH_THROW_ON_FULL_BATCH_FAILURE</code> <code>true</code>"
        },
        {
            "location": "utilities/batch-processing/#required-resources",
            "title": "Required resources",
            "text": "<p>The remaining sections of the documentation will rely on these samples. For completeness, this demonstrates IAM permissions and Dead Letter Queue where batch records will be sent after 2 retries were attempted.</p> <p>You do not need any additional IAM permissions to use this utility, except for what each event source requires.</p> SQSKinesis Data StreamsDynamoDB Streams template.yaml<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Example project demoing SQS Queue processing using the Batch Processing Utility in Powertools for AWS Lambda (.NET)\n\nGlobals:\n  Function:\n    Timeout: 20\n    Runtime: dotnet8\n    MemorySize: 1024\n    Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: powertools-dotnet-sample-batch-sqs\n        POWERTOOLS_LOG_LEVEL: Debug\n        POWERTOOLS_LOGGER_CASE: PascalCase\n        POWERTOOLS_BATCH_ERROR_HANDLING_POLICY: DeriveFromEvent\n        POWERTOOLS_BATCH_MAX_DEGREE_OF_PARALLELISM: 1\n        POWERTOOLS_BATCH_PARALLEL_ENABLED : false\n        POWERTOOLS_BATCH_THROW_ON_FULL_BATCH_FAILURE: true\n\nResources:\n\n  # --------------\n  # KMS key for encrypted messages / records\n  CustomerKey:\n    Type: AWS::KMS::Key\n    Properties:\n      Description: KMS key for encrypted queues\n      Enabled: true\n      KeyPolicy:\n        Version: \"2012-10-17\"\n        Statement:\n          - Sid: Enable IAM User Permissions\n            Effect: Allow\n            Principal:\n              AWS: !Sub \"arn:aws:iam::${AWS::AccountId}:root\"\n            Action: \"kms:*\"\n            Resource: \"*\"\n          - Sid: Allow AWS Lambda to use the key\n            Effect: Allow\n            Principal:\n              Service: lambda.amazonaws.com\n            Action:\n              - kms:Decrypt\n              - kms:GenerateDataKey\n            Resource: \"*\"\n\n  CustomerKeyAlias:\n    Type: AWS::KMS::Alias\n    Properties:\n      AliasName: !Sub alias/${AWS::StackName}-kms-key\n      TargetKeyId: !Ref CustomerKey\n\n  # --------------\n  # Batch Processing for SQS Queue\n  SqsDeadLetterQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      KmsMasterKeyId: !Ref CustomerKey\n\n  SqsQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      RedrivePolicy:\n        deadLetterTargetArn: !GetAtt SqsDeadLetterQueue.Arn\n        maxReceiveCount: 2\n      KmsMasterKeyId: !Ref CustomerKey\n\n  SqsBatchProcessorFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: ./src/HelloWorld/\n      Handler: HelloWorld::HelloWorld.Function::SqsHandlerUsingAttribute\n      Policies:\n        - Statement:\n            - Sid: DlqPermissions\n              Effect: Allow\n              Action:\n                - sqs:SendMessage\n                - sqs:SendMessageBatch\n              Resource: !GetAtt SqsDeadLetterQueue.Arn\n            - Sid: KmsKeyPermissions\n              Effect: Allow\n              Action:\n                - kms:Decrypt\n                - kms:GenerateDataKey\n              Resource: !GetAtt CustomerKey.Arn\n      Events:\n        SqsBatch:\n          Type: SQS\n          Properties:\n            BatchSize: 5\n            Enabled: true\n            FunctionResponseTypes:\n              - ReportBatchItemFailures\n            Queue: !GetAtt SqsQueue.Arn\n\n  SqsBatchProcessorFunctionLogGroup:\n    Type: AWS::Logs::LogGroup\n    Properties:\n      LogGroupName: !Sub \"/aws/lambda/${SqsBatchProcessorFunction}\"\n      RetentionInDays: 7\n\nOutputs:\n  SqsQueueUrl:\n    Description: \"SQS Queue URL\"\n    Value: !Ref SqsQueue\n</code></pre> template.yaml<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Example project demoing Kinesis Data Streams processing using the Batch Processing Utility in Powertools for AWS Lambda (.NET)\n\nGlobals:\n  Function:\n    Timeout: 20\n    Runtime: dotnet8\n    MemorySize: 1024\n    Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: powertools-dotnet-sample-batch-kinesis\n        POWERTOOLS_LOG_LEVEL: Debug\n        POWERTOOLS_LOGGER_CASE: PascalCase\n        POWERTOOLS_BATCH_ERROR_HANDLING_POLICY: DeriveFromEvent\n        POWERTOOLS_BATCH_MAX_DEGREE_OF_PARALLELISM: 1\n        POWERTOOLS_BATCH_PARALLEL_ENABLED : false\n        POWERTOOLS_BATCH_THROW_ON_FULL_BATCH_FAILURE: true\n\nResources:\n\n  # --------------\n  # KMS key for encrypted messages / records\n  CustomerKey:\n    Type: AWS::KMS::Key\n    Properties:\n      Description: KMS key for encrypted queues\n      Enabled: true\n      KeyPolicy:\n        Version: \"2012-10-17\"\n        Statement:\n          - Sid: Enable IAM User Permissions\n            Effect: Allow\n            Principal:\n              AWS: !Sub \"arn:aws:iam::${AWS::AccountId}:root\"\n            Action: \"kms:*\"\n            Resource: \"*\"\n          - Sid: Allow AWS Lambda to use the key\n            Effect: Allow\n            Principal:\n              Service: lambda.amazonaws.com\n            Action:\n              - kms:Decrypt\n              - kms:GenerateDataKey\n            Resource: \"*\"\n\n  CustomerKeyAlias:\n    Type: AWS::KMS::Alias\n    Properties:\n      AliasName: !Sub alias/${AWS::StackName}-kms-key\n      TargetKeyId: !Ref CustomerKey\n\n  # --------------\n  # Batch Processing for Kinesis Data Stream\n  KinesisStreamDeadLetterQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      KmsMasterKeyId: !Ref CustomerKey\n\n  KinesisStream:\n    Type: AWS::Kinesis::Stream\n    Properties:\n      ShardCount: 1\n      StreamEncryption:\n        EncryptionType: KMS\n        KeyId: !Ref CustomerKey\n\n  KinesisStreamConsumer:\n    Type: AWS::Kinesis::StreamConsumer\n    Properties:\n      ConsumerName: powertools-dotnet-sample-batch-kds-consumer\n      StreamARN: !GetAtt KinesisStream.Arn\n\n  KinesisBatchProcessorFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Policies:\n        - Statement:\n            - Sid: KinesisStreamConsumerPermissions\n              Effect: Allow\n              Action:\n                - kinesis:DescribeStreamConsumer\n              Resource:\n                - !GetAtt KinesisStreamConsumer.ConsumerARN\n            - Sid: DlqPermissions\n              Effect: Allow\n              Action:\n                - sqs:SendMessage\n                - sqs:SendMessageBatch\n              Resource: !GetAtt KinesisStreamDeadLetterQueue.Arn\n            - Sid: KmsKeyPermissions\n              Effect: Allow\n              Action:\n                - kms:Decrypt\n                - kms:GenerateDataKey\n              Resource: !GetAtt CustomerKey.Arn\n      CodeUri: ./src/HelloWorld/\n      Handler: HelloWorld::HelloWorld.Function::KinesisEventHandlerUsingAttribute\n      Events:\n        Kinesis:\n          Type: Kinesis\n          Properties:\n            BatchSize: 5\n            BisectBatchOnFunctionError: true\n            DestinationConfig:\n              OnFailure:\n                Destination: !GetAtt KinesisStreamDeadLetterQueue.Arn\n            Enabled: true\n            FunctionResponseTypes:\n              - ReportBatchItemFailures\n            MaximumRetryAttempts: 2\n            ParallelizationFactor: 1\n            StartingPosition: LATEST\n            Stream: !GetAtt KinesisStreamConsumer.ConsumerARN\n\n  KinesisBatchProcessorFunctionLogGroup:\n    Type: AWS::Logs::LogGroup\n    Properties:\n      LogGroupName: !Sub \"/aws/lambda/${KinesisBatchProcessorFunction}\"\n      RetentionInDays: 7\n\nOutputs:\n  KinesisStreamArn:\n    Description: \"Kinesis Stream ARN\"\n    Value: !GetAtt KinesisStream.Arn\n</code></pre> template.yaml<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"\nTransform: AWS::Serverless-2016-10-31\nDescription: Example project demoing DynamoDB Streams processing using the Batch Processing Utility in Powertools for AWS Lambda (.NET)\n\nGlobals:\n  Function:\n    Timeout: 20\n    Runtime: dotnet8\n    MemorySize: 1024\n    Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: powertools-dotnet-sample-batch-ddb\n        POWERTOOLS_LOG_LEVEL: Debug\n        POWERTOOLS_LOGGER_CASE: PascalCase\n        POWERTOOLS_BATCH_ERROR_HANDLING_POLICY: DeriveFromEvent\n        POWERTOOLS_BATCH_MAX_DEGREE_OF_PARALLELISM: 1\n        POWERTOOLS_BATCH_PARALLEL_ENABLED : false\n        POWERTOOLS_BATCH_THROW_ON_FULL_BATCH_FAILURE: true\n\nResources:\n\n  # --------------\n  # KMS key for encrypted messages / records\n  CustomerKey:\n    Type: AWS::KMS::Key\n    Properties:\n      Description: KMS key for encrypted queues\n      Enabled: true\n      KeyPolicy:\n        Version: \"2012-10-17\"\n        Statement:\n          - Sid: Enable IAM User Permissions\n            Effect: Allow\n            Principal:\n              AWS: !Sub \"arn:aws:iam::${AWS::AccountId}:root\"\n            Action: \"kms:*\"\n            Resource: \"*\"\n          - Sid: Allow AWS Lambda to use the key\n            Effect: Allow\n            Principal:\n              Service: lambda.amazonaws.com\n            Action:\n              - kms:Decrypt\n              - kms:GenerateDataKey\n            Resource: \"*\"\n\n  CustomerKeyAlias:\n    Type: AWS::KMS::Alias\n    Properties:\n      AliasName: !Sub alias/${AWS::StackName}-kms-key\n      TargetKeyId: !Ref CustomerKey\n\n  # --------------\n  # Batch Processing for DynamoDb (DDB) Stream\n  DdbStreamDeadLetterQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      KmsMasterKeyId: !Ref CustomerKey\n\n  DdbTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      BillingMode: PAY_PER_REQUEST\n      AttributeDefinitions:\n        - AttributeName: id\n          AttributeType: S\n      KeySchema:\n        - AttributeName: id\n          KeyType: HASH\n      StreamSpecification:\n        StreamViewType: NEW_AND_OLD_IMAGES\n\n  DdbStreamBatchProcessorFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      CodeUri: ./src/HelloWorld/\n      Handler: HelloWorld::HelloWorld.Function::DynamoDbStreamHandlerUsingAttribute\n      Policies:\n        - AWSLambdaDynamoDBExecutionRole\n        - Statement:\n            - Sid: DlqPermissions\n              Effect: Allow\n              Action:\n                - sqs:SendMessage\n                - sqs:SendMessageBatch\n              Resource: !GetAtt DdbStreamDeadLetterQueue.Arn\n            - Sid: KmsKeyPermissions\n              Effect: Allow\n              Action:\n                - kms:GenerateDataKey\n              Resource: !GetAtt CustomerKey.Arn\n      Events:\n        Stream:\n          Type: DynamoDB\n          Properties:\n            BatchSize: 5\n            BisectBatchOnFunctionError: true\n            DestinationConfig:\n              OnFailure:\n                Destination: !GetAtt DdbStreamDeadLetterQueue.Arn\n            Enabled: true\n            FunctionResponseTypes:\n              - ReportBatchItemFailures\n            MaximumRetryAttempts: 2\n            ParallelizationFactor: 1\n            StartingPosition: LATEST\n            Stream: !GetAtt DdbTable.StreamArn\n\n  DdbStreamBatchProcessorFunctionLogGroup:\n    Type: AWS::Logs::LogGroup\n    Properties:\n      LogGroupName: !Sub \"/aws/lambda/${DdbStreamBatchProcessorFunction}\"\n      RetentionInDays: 7\n\nOutputs:\n  DdbTableName:\n    Description: \"DynamoDB Table Name\"\n    Value: !Ref DdbTable\n</code></pre>"
        },
        {
            "location": "utilities/batch-processing/#processing-messages-from-sqs",
            "title": "Processing messages from SQS",
            "text": ""
        },
        {
            "location": "utilities/batch-processing/#using-handler-decorator",
            "title": "Using Handler decorator",
            "text": "<p>Processing batches from SQS using Lambda handler decorator works in three stages:</p> <ol> <li>Decorate your handler with <code>BatchProcessor</code> attribute</li> <li>Create a class that implements <code>ISqsRecordHandler</code> interface and the HandleAsync method. </li> <li>Pass the type of that class to  <code>RecordHandler</code> property of the <code>BatchProcessor</code> attribute</li> <li>Return <code>BatchItemFailuresResponse</code> from Lambda handler using <code>SqsBatchProcessor.Result.BatchItemFailuresResponse</code></li> </ol> Function.csSample eventSample response <pre><code>public class CustomSqsRecordHandler : ISqsRecordHandler // (1)!\n{\n    public async Task&lt;RecordHandlerResult&gt; HandleAsync(SQSEvent.SQSMessage record, CancellationToken cancellationToken)\n    {\n         /*\n         * Your business logic.\n         * If an exception is thrown, the item will be marked as a partial batch item failure.\n         */\n\n         var product = JsonSerializer.Deserialize&lt;Product&gt;(record.Body);\n\n         if (product.Id == 4) // (2)!\n         {\n             throw new ArgumentException(\"Error on id 4\");\n         }\n\n         return await Task.FromResult(RecordHandlerResult.None); // (3)!\n     }\n}\n\n\n[BatchProcessor(RecordHandler = typeof(CustomSqsRecordHandler))]\npublic BatchItemFailuresResponse HandlerUsingAttribute(SQSEvent _)\n{\n    return SqsBatchProcessor.Result.BatchItemFailuresResponse; // (4)!\n}\n</code></pre> <ol> <li>Step 1. Creates a class that implements ISqsRecordHandler interface and the HandleAsync method.</li> <li>Step 2. You can have custom logic inside the record handler and throw exceptions that will cause this message to fail</li> <li>Step 3. RecordHandlerResult can return empty (None) or some data.</li> <li>Step 4. Lambda function returns the Partial batch response</li> </ol> <pre><code>{\n    \"Records\": [\n        {\n            \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n            \"body\": \"{\\\"Id\\\":1,\\\"Name\\\":\\\"product-4\\\",\\\"Price\\\":14}\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n            \"awsRegion\": \"us-east-1\"\n        },\n        {\n            \"messageId\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n            \"body\": \"fail\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n            \"awsRegion\": \"us-east-1\"\n        },\n        {\n            \"messageId\": \"213f4fd3-84a4-4667-a1b9-c277964197d9\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n            \"body\": \"{\\\"Id\\\":4,\\\"Name\\\":\\\"product-4\\\",\\\"Price\\\":14}\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n            \"awsRegion\": \"us-east-1\"\n        },\n    ]\n}\n</code></pre> <p>The second record failed to be processed, therefore the processor added its message ID in the response.</p> <pre><code>{\n    \"batchItemFailures\": [\n        {\n            \"itemIdentifier\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\"\n        },\n        {\n            \"itemIdentifier\": \"213f4fd3-84a4-4667-a1b9-c277964197d9\"\n        }\n    ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch-processing/#fifo-queues",
            "title": "FIFO queues",
            "text": "<p>When using SQS FIFO queues, we will stop processing messages after the first failure, and return all failed and unprocessed messages in <code>batchItemFailures</code>. This helps preserve the ordering of messages in your queue. Powertools automatically detects a FIFO queue.</p>"
        },
        {
            "location": "utilities/batch-processing/#processing-messages-from-kinesis",
            "title": "Processing messages from Kinesis",
            "text": "<p>Processing batches from Kinesis using Lambda handler decorator works in three stages:</p> <ol> <li>Decorate your handler with <code>BatchProcessor</code> attribute</li> <li>Create a class that implements <code>IKinesisEventRecordHandler</code> interface and the HandleAsync method.</li> <li>Pass the type of that class to  <code>RecordHandler</code> property of the <code>BatchProcessor</code> attribute</li> <li>Return <code>BatchItemFailuresResponse</code> from Lambda handler using <code>KinesisEventBatchProcessor.Result.BatchItemFailuresResponse</code></li> </ol> Function.csSample eventSample response <pre><code>internal class CustomKinesisEventRecordHandler : IKinesisEventRecordHandler // (1)!\n{\n    public async Task&lt;RecordHandlerResult&gt; HandleAsync(KinesisEvent.KinesisEventRecord record, CancellationToken cancellationToken)\n    {\n        var product = JsonSerializer.Deserialize&lt;Product&gt;(record.Kinesis.Data);\n\n        if (product.Id == 4) // (2)!\n        {\n            throw new ArgumentException(\"Error on id 4\");\n        }\n\n        return await Task.FromResult(RecordHandlerResult.None); // (3)!\n    }\n}\n\n\n[BatchProcessor(RecordHandler = typeof(CustomKinesisEventRecordHandler))]\npublic BatchItemFailuresResponse HandlerUsingAttribute(KinesisEvent _)\n{\n    return KinesisEventBatchProcessor.Result.BatchItemFailuresResponse; // (4)!\n}\n</code></pre> <ol> <li>Step 1. Creates a class that implements the IKinesisEventRecordHandler interface and the HandleAsync method.</li> <li>Step 2. You can have custom logic inside the record handler and throw exceptions that will cause this message to fail</li> <li>Step 3. RecordHandlerResult can return empty (None) or some data.</li> <li>Step 4. Lambda function returns the Partial batch response</li> </ol> <pre><code>{\n    \"Records\": [\n        {\n            \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n            \"body\": \"{\\\"Id\\\":1,\\\"Name\\\":\\\"product-4\\\",\\\"Price\\\":14}\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n            \"awsRegion\": \"us-east-1\"\n        },\n        {\n            \"messageId\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n            \"body\": \"fail\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n            \"awsRegion\": \"us-east-1\"\n        },\n        {\n            \"messageId\": \"213f4fd3-84a4-4667-a1b9-c277964197d9\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n            \"body\": \"{\\\"Id\\\":4,\\\"Name\\\":\\\"product-4\\\",\\\"Price\\\":14}\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n            \"awsRegion\": \"us-east-1\"\n        },\n    ]\n}\n</code></pre> <p>The second record failed to be processed, therefore the processor added its message ID in the response.</p> <pre><code>{\n    \"batchItemFailures\": [\n        {\n            \"itemIdentifier\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\"\n        },\n        {\n            \"itemIdentifier\": \"213f4fd3-84a4-4667-a1b9-c277964197d9\"\n        }\n    ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch-processing/#processing-messages-from-dynamodb",
            "title": "Processing messages from DynamoDB",
            "text": "<p>Processing batches from DynamoDB Streams using Lambda handler decorator works in three stages:</p> <ol> <li>Decorate your handler with <code>BatchProcessor</code> attribute</li> <li>Create a class that implements <code>IDynamoDbStreamRecordHandler</code> and the HandleAsync method.</li> <li>Pass the type of that class to  <code>RecordHandler</code> property of the <code>BatchProcessor</code> attribute</li> <li>Return <code>BatchItemFailuresResponse</code> from Lambda handler using <code>DynamoDbStreamBatchProcessor.Result.BatchItemFailuresResponse</code></li> </ol> Function.csSample eventSample response <pre><code>internal class CustomDynamoDbStreamRecordHandler : IDynamoDbStreamRecordHandler // (1)!\n{\n    public async Task&lt;RecordHandlerResult&gt; HandleAsync(DynamoDBEvent.DynamodbStreamRecord record, CancellationToken cancellationToken)\n    {\n        var product = JsonSerializer.Deserialize&lt;Product&gt;(record.Dynamodb.NewImage[\"Product\"].S);\n\n        if (product.Id == 4) // (2)!\n        {\n            throw new ArgumentException(\"Error on id 4\");\n        }\n\n        return await Task.FromResult(RecordHandlerResult.None); // (3)!\n    }\n}\n\n\n[BatchProcessor(RecordHandler = typeof(CustomDynamoDbStreamRecordHandler))]\npublic BatchItemFailuresResponse HandlerUsingAttribute(DynamoDBEvent _)\n{\n    return DynamoDbStreamBatchProcessor.Result.BatchItemFailuresResponse; // (4)!\n}\n</code></pre> <ol> <li>Step 1. Creates a class that implements the IDynamoDbStreamRecordHandler and the HandleAsync method.</li> <li>Step 2. You can have custom logic inside the record handler and throw exceptions that will cause this message to fail</li> <li>Step 3. RecordHandlerResult can return empty (None) or some data.</li> <li>Step 4. Lambda function returns the Partial batch response</li> </ol> <pre><code>{\n    \"Records\": [\n        {\n            \"eventID\": \"1\",\n            \"eventVersion\": \"1.0\",\n            \"dynamodb\": {\n                \"Keys\": {\n                    \"Id\": {\n                        \"N\": \"101\"\n                }\n            },\n            \"NewImage\": {\n                \"Product\": {\n                    \"S\": \"{\\\"Id\\\":1,\\\"Name\\\":\\\"product-name\\\",\\\"Price\\\":14}\"\n                }\n            },\n            \"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n            \"SequenceNumber\": \"3275880929\",\n            \"SizeBytes\": 26\n            },\n            \"awsRegion\": \"us-west-2\",\n            \"eventName\": \"INSERT\",\n            \"eventSourceARN\": \"eventsource_arn\",\n            \"eventSource\": \"aws:dynamodb\"\n        },\n        {\n            \"eventID\": \"1\",\n            \"eventVersion\": \"1.0\",\n            \"dynamodb\": {\n                \"Keys\": {\n                    \"Id\": {\n                        \"N\": \"101\"\n                }\n            },\n            \"NewImage\": {\n                \"Product\": {\n                    \"S\": \"fail\"\n                }\n            },\n            \"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n            \"SequenceNumber\": \"8640712661\",\n            \"SizeBytes\": 26\n            },\n            \"awsRegion\": \"us-west-2\",\n            \"eventName\": \"INSERT\",\n            \"eventSourceARN\": \"eventsource_arn\",\n            \"eventSource\": \"aws:dynamodb\"\n        }\n    ]\n}\n</code></pre> <p>The second record failed to be processed, therefore the processor added its message ID in the response.</p> <pre><code>{\n    \"batchItemFailures\": [\n        {\n            \"itemIdentifier\": \"8640712661\"\n        }\n    ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch-processing/#error-handling",
            "title": "Error handling",
            "text": "<p>By default, we catch any exception raised by your custom record handler HandleAsync method (ISqsRecordHandler, IKinesisEventRecordHandler, IDynamoDbStreamRecordHandler).  This allows us to (1) continue processing the batch, (2) collect each batch item that failed processing, and (3) return the appropriate response correctly without failing your Lambda function execution.</p> Function.csSample eventSample response <pre><code>public class CustomSqsRecordHandler : ISqsRecordHandler // (1)!\n{\n    public async Task&lt;RecordHandlerResult&gt; HandleAsync(SQSEvent.SQSMessage record, CancellationToken cancellationToken)\n    {\n         /*\n         * Your business logic.\n         * If an exception is thrown, the item will be marked as a partial batch item failure.\n         */\n\n         var product = JsonSerializer.Deserialize&lt;Product&gt;(record.Body);\n\n         if (product.Id == 4) // (2)!\n         {\n             throw new ArgumentException(\"Error on id 4\");\n         }\n\n         return await Task.FromResult(RecordHandlerResult.None); // (3)!\n     }\n}\n</code></pre> <pre><code>{\n    \"Records\": [\n        {\n            \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n            \"body\": \"{\\\"Id\\\":1,\\\"Name\\\":\\\"product-4\\\",\\\"Price\\\":14}\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n            \"awsRegion\": \"us-east-1\"\n        },\n        {\n            \"messageId\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n            \"body\": \"fail\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n            \"awsRegion\": \"us-east-1\"\n        },\n        {\n            \"messageId\": \"213f4fd3-84a4-4667-a1b9-c277964197d9\",\n            \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n            \"body\": \"{\\\"Id\\\":4,\\\"Name\\\":\\\"product-4\\\",\\\"Price\\\":14}\",\n            \"attributes\": {\n                \"ApproximateReceiveCount\": \"1\",\n                \"SentTimestamp\": \"1545082649183\",\n                \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n                \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n            },\n            \"messageAttributes\": {},\n            \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n            \"eventSource\": \"aws:sqs\",\n            \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n            \"awsRegion\": \"us-east-1\"\n        },\n    ]\n}\n</code></pre> <p>The second record failed to be processed, therefore the processor added its message ID in the response.</p> <pre><code>{\n    \"batchItemFailures\": [\n        {\n            \"itemIdentifier\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\"\n        },\n        {\n            \"itemIdentifier\": \"213f4fd3-84a4-4667-a1b9-c277964197d9\"\n        }\n    ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch-processing/#error-handling-policy",
            "title": "Error Handling Policy",
            "text": "<p>You can specify the error handling policy applied during batch processing.</p> <p><code>ErrorHandlingPolicy</code> is used to control the error handling policy of the batch item processing. With a value of <code>DeriveFromEvent</code> (default), the specific BatchProcessor, determines the policy based on the incoming event.</p> <p>For example, the <code>SqsBatchProcessor</code> looks at the EventSourceArn to determine if the ErrorHandlingPolicy should be <code>StopOnFirstBatchItemFailure</code> (for FIFO queues) or <code>ContinueOnBatchItemFailure</code> (for standard queues). For <code>StopOnFirstBatchItemFailure</code> the batch processor stops processing and marks any remaining records as batch item failures. For <code>ContinueOnBatchItemFailure</code> the batch processor continues processing batch items regardless of item failures.</p> Policy Description DeriveFromEvent Auto-derive the policy based on the event. ContinueOnBatchItemFailure Continue processing regardless of whether other batch items fails during processing. StopOnFirstBatchItemFailure Stop processing other batch items after the first batch item has failed processing. This is useful to preserve ordered processing of events. <p>Note</p> <p>When using StopOnFirstBatchItemFailure and parallel processing is enabled, all batch items already scheduled to be processed, will be allowed to complete before the batch processing stops. </p> <p>Therefore, if order is important, it is recommended to use sequential (non-parallel) processing together with this value.\"</p> <p>To change the default error handling policy, you can set the <code>POWERTOOLS_BATCH_ERROR_HANDLING_POLICY</code> Environment Variable.</p> <p>Another approach is to decorate the handler and use one of the policies in the <code>ErrorHandlingPolicy</code> Enum property of the <code>BatchProcessor</code> attribute</p> Function.cs <pre><code>[BatchProcessor(RecordHandler = typeof(CustomDynamoDbStreamRecordHandler), \n    ErrorHandlingPolicy = BatchProcessorErrorHandlingPolicy.StopOnFirstBatchItemFailure)]\npublic BatchItemFailuresResponse HandlerUsingAttribute(DynamoDBEvent _)\n{\n    return DynamoDbStreamBatchProcessor.Result.BatchItemFailuresResponse;\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch-processing/#partial-failure-mechanics",
            "title": "Partial failure mechanics",
            "text": "<p>All records in the batch will be passed to this handler for processing, even if exceptions are thrown - Here's the behaviour after completing the batch:</p> <ul> <li>All records successfully processed. We will return an empty list of item failures <code>{'batchItemFailures': []}</code>.</li> <li>Partial success with some exceptions. We will return a list of all item IDs/sequence numbers that failed processing.</li> <li>All records failed to be processed. By defaullt, we will throw a <code>BatchProcessingException</code> with a list of all exceptions raised during processing to reflect the failure in your operational metrics. However, in some scenarios, this might not be desired. See Working with full batch failures for more information.</li> </ul> <p>The following sequence diagrams explain how each Batch processor behaves under different scenarios.</p>"
        },
        {
            "location": "utilities/batch-processing/#sqs-standard",
            "title": "SQS Standard",
            "text": "<p>Read more about Batch Failure Reporting feature in AWS Lambda.</p> <p>Sequence diagram to explain how <code>BatchProcessor</code> works with SQS Standard queues.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant SQS queue\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;SQS queue: Poll\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    Lambda function-&gt;&gt;Lambda service: Report some failed messages\n    activate SQS queue\n    Lambda service-&gt;&gt;SQS queue: Delete successful messages\n    SQS queue--&gt;&gt;SQS queue: Failed messages return\n    Note over SQS queue,Lambda service: Process repeat\n    deactivate SQS queue</code></pre> SQS mechanism with Batch Item Failures </p>"
        },
        {
            "location": "utilities/batch-processing/#sqs-fifo",
            "title": "SQS FIFO",
            "text": "<p>Read more about Batch Failure Reporting feature in AWS Lambda.</p> <p>Sequence diagram to explain how <code>SqsFifoPartialProcessor</code> works with SQS FIFO queues.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant SQS queue\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;SQS queue: Poll\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    activate Lambda function\n    Lambda function--&gt;Lambda function: Process 2 out of 10 batch items\n    Lambda function--xLambda function: Fail on 3rd batch item\n    Lambda function-&gt;&gt;Lambda service: Report 3rd batch item and unprocessed messages as failure\n    deactivate Lambda function\n    activate SQS queue\n    Lambda service-&gt;&gt;SQS queue: Delete successful messages (1-2)\n    SQS queue--&gt;&gt;SQS queue: Failed messages return (3-10)\n    deactivate SQS queue</code></pre> SQS FIFO mechanism with Batch Item Failures </p>"
        },
        {
            "location": "utilities/batch-processing/#kinesis-and-dynamodb-streams",
            "title": "Kinesis and DynamoDB Streams",
            "text": "<p>Read more about Batch Failure Reporting feature.</p> <p>Sequence diagram to explain how <code>BatchProcessor</code> works with both Kinesis Data Streams and DynamoDB Streams.</p> <p>For brevity, we will use <code>Streams</code> to refer to either services. For theory on stream checkpoints, see this blog post</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Streams\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;Streams: Poll latest records\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    activate Lambda function\n    Lambda function--&gt;Lambda function: Process 2 out of 10 batch items\n    Lambda function--xLambda function: Fail on 3rd batch item\n    Lambda function--&gt;Lambda function: Continue processing batch items (4-10)\n    Lambda function-&gt;&gt;Lambda service: Report batch item as failure (3)\n    deactivate Lambda function\n    activate Streams\n    Lambda service-&gt;&gt;Streams: Checkpoints to sequence number from 3rd batch item\n    Lambda service-&gt;&gt;Streams: Poll records starting from updated checkpoint\n    deactivate Streams</code></pre> Kinesis and DynamoDB streams mechanism with single batch item failure </p> <p>The behavior changes slightly when there are multiple item failures. Stream checkpoint is updated to the lowest sequence number reported.</p> <p>Note that the batch item sequence number could be different from batch item number in the illustration.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Streams\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;Streams: Poll latest records\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    activate Lambda function\n    Lambda function--&gt;Lambda function: Process 2 out of 10 batch items\n    Lambda function--xLambda function: Fail on 3-5 batch items\n    Lambda function--&gt;Lambda function: Continue processing batch items (6-10)\n    Lambda function-&gt;&gt;Lambda service: Report batch items as failure (3-5)\n    deactivate Lambda function\n    activate Streams\n    Lambda service-&gt;&gt;Streams: Checkpoints to lowest sequence number\n    Lambda service-&gt;&gt;Streams: Poll records starting from updated checkpoint\n    deactivate Streams</code></pre> Kinesis and DynamoDB streams mechanism with multiple batch item failures </p>"
        },
        {
            "location": "utilities/batch-processing/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/batch-processing/#using-utility-outside-handler-and-ioc",
            "title": "Using utility outside handler and IoC",
            "text": "<p>You can use Batch processing without using the decorator.</p> <p>Calling the <code>ProcessAsync</code> method on the Instance of the static BatchProcessor (<code>SqsBatchProcessor</code>, <code>DynamoDbStreamBatchProcessor</code>, <code>KinesisEventBatchProcessor</code>)</p> Function.cs <pre><code>public async Task&lt;BatchItemFailuresResponse&gt; HandlerUsingUtility(DynamoDBEvent dynamoDbEvent)\n{\n    var result = await DynamoDbStreamBatchProcessor.Instance.ProcessAsync(dynamoDbEvent, RecordHandler&lt;DynamoDBEvent.DynamodbStreamRecord&gt;.From(record =&gt;\n    {\n        var product = JsonSerializer.Deserialize&lt;JsonElement&gt;(record.Dynamodb.NewImage[\"Product\"].S);\n\n        if (product.GetProperty(\"Id\").GetInt16() == 4)\n        {\n            throw new ArgumentException(\"Error on 4\");\n        }\n    }));\n    return result.BatchItemFailuresResponse;\n}\n</code></pre> <p>To make the handler testable you can use Dependency Injection to resolve the BatchProcessor (<code>SqsBatchProcessor</code>, <code>DynamoDbStreamBatchProcessor</code>, <code>KinesisEventBatchProcessor</code>) instance and then call the <code>ProcessAsync</code> method.</p> GetRequiredService inside the methodInjecting method parametersExample implementation of IServiceProvider <pre><code>public async Task&lt;BatchItemFailuresResponse&gt; HandlerUsingUtilityFromIoc(DynamoDBEvent dynamoDbEvent)\n{\n    var batchProcessor = Services.Provider.GetRequiredService&lt;IDynamoDbStreamBatchProcessor&gt;();\n    var recordHandler = Services.Provider.GetRequiredService&lt;IDynamoDbStreamRecordHandler&gt;();\n    var result = await batchProcessor.ProcessAsync(dynamoDbEvent, recordHandler);\n    return result.BatchItemFailuresResponse;\n}\n</code></pre> <pre><code>public async Task&lt;BatchItemFailuresResponse&gt; HandlerUsingUtilityFromIoc(DynamoDBEvent dynamoDbEvent, \n    IDynamoDbStreamBatchProcessor batchProcessor, IDynamoDbStreamRecordHandler recordHandler)\n{\n    var result = await batchProcessor.ProcessAsync(dynamoDbEvent, recordHandler);\n    return result.BatchItemFailuresResponse;\n}\n</code></pre> <pre><code>internal class Services\n{\n    private static readonly Lazy&lt;IServiceProvider&gt; LazyInstance = new(Build);\n\n    private static ServiceCollection _services;\n    public static IServiceProvider Provider =&gt; LazyInstance.Value;\n\n    public static IServiceProvider Init()\n    {\n        return LazyInstance.Value;\n    }\n\n    private static IServiceProvider Build()\n    {\n        _services = new ServiceCollection();\n        _services.AddScoped&lt;IDynamoDbStreamBatchProcessor, CustomDynamoDbStreamBatchProcessor&gt;();\n        _services.AddScoped&lt;IDynamoDbStreamRecordHandler, CustomDynamoDbStreamRecordHandler&gt;();\n        return _services.BuildServiceProvider();\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch-processing/#processing-messages-in-parallel",
            "title": "Processing messages in parallel",
            "text": "<p>You can set the <code>POWERTOOLS_BATCH_PARALLEL_ENABLED</code> Environment Variable to <code>true</code> or set the property <code>BatchParallelProcessingEnabled</code> on the Lambda decorator to process messages concurrently.</p> <p>You can also set <code>POWERTOOLS_BATCH_MAX_DEGREE_OF_PARALLELISM</code> Environment Variable to the number of parallelism you which.</p> <p>Note</p> <p>MaxDegreeOfParallelism is used to control the parallelism of the batch item processing. </p> <p>With a value of 1, the processing is done sequentially (default). Sequential processing is recommended when preserving order is important - i.e. with SQS FIFIO queues. </p> <p>With a value &gt; 1, the processing is done in parallel. Doing parallel processing can enable processing to complete faster, i.e., when processing does downstream service calls. </p> <p>With a value of -1, the parallelism is automatically configured to be the vCPU count of the Lambda function. Internally, the Batch Processing Utility utilizes Parallel.ForEachAsync Method and the ParallelOptions.MaxDegreeOfParallelism Property to enable this functionality.</p> When is this useful? <p>Your use case might be able to process multiple records at the same time without conflicting with one another.</p> <p>For example, imagine you need to process multiple loyalty points and incrementally save in a database. While you await the database to confirm your records are saved, you could start processing another request concurrently.</p> <p>The reason this is not the default behaviour is that not all use cases can handle concurrency safely (e.g., loyalty points must be updated in order).</p> Function.cs <pre><code>[BatchProcessor(RecordHandler = typeof(CustomDynamoDbStreamRecordHandler), BatchParallelProcessingEnabled = true )]\npublic BatchItemFailuresResponse HandlerUsingAttribute(DynamoDBEvent _)\n{\n    return DynamoDbStreamBatchProcessor.Result.BatchItemFailuresResponse;\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch-processing/#working-with-full-batch-failures",
            "title": "Working with full batch failures",
            "text": "<p>By default, the <code>BatchProcessor</code> will throw a <code>BatchProcessingException</code> if all records in the batch fail to process. We do this to reflect the failure in your operational metrics.</p> <p>When working with functions that handle batches with a small number of records, or when you use errors as a flow control mechanism, this behavior might not be desirable as your function might generate an unnaturally high number of errors. When this happens, the Lambda service will scale down the concurrency of your function, potentially impacting performance.</p> <p>For these scenarios, you can set <code>POWERTOOLS_BATCH_THROW_ON_FULL_BATCH_FAILURE = false</code>, or the equivalent on either the <code>BatchProcessor</code> decorator or on the <code>ProcessingOptions</code> object. See examples below.</p> Setting ThrowOnFullBatchFailure on DecoratorSetting ThrowOnFullBatchFailure outside Decorator <pre><code>[BatchProcessor(\n    RecordHandler = typeof(CustomSqsRecordHandler),\n    ThrowOnFullBatchFailure = false)]\npublic BatchItemFailuresResponse HandlerUsingAttribute(SQSEvent _)\n{\n    return SqsBatchProcessor.Result.BatchItemFailuresResponse;\n}\n</code></pre> <pre><code>public async Task&lt;BatchItemFailuresResponse&gt; HandlerUsingUtility(SQSEvent sqsEvent)\n{\n    var result = await SqsBatchProcessor.Instance.ProcessAsync(sqsEvent, RecordHandler&lt;SQSEvent.SQSMessage&gt;.From(x =&gt;\n    {\n        // Inline handling of SQS message...\n    }), new ProcessingOptions\n    {\n        ThrowOnFullBatchFailure = false\n    });\n    return result.BatchItemFailuresResponse;\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch-processing/#extending-batchprocessor",
            "title": "Extending BatchProcessor",
            "text": "<p>You might want to bring custom logic to the existing <code>BatchProcessor</code> to slightly override how we handle successes and failures.</p> <p>For these scenarios, you can create a class that inherits from <code>BatchProcessor</code> (<code>SqsBatchProcessor</code>, <code>DynamoDbStreamBatchProcessor</code>, <code>KinesisEventBatchProcessor</code>) and quickly override <code>ProcessAsync</code> and <code>HandleRecordFailureAsync</code> methods:</p> <ul> <li><code>ProcessAsync()</code>  Keeps track of successful batch records</li> <li><code>HandleRecordFailureAsync()</code>  Keeps track of failed batch records</li> </ul> Example <p>Let's suppose you'd like to add a metric named <code>BatchRecordFailures</code> for each batch record that failed processing. And also override the default error handling policy to stop on first item failure.</p> Function.cs <pre><code>public class CustomDynamoDbStreamBatchProcessor : DynamoDbStreamBatchProcessor\n{\n    public override async Task&lt;ProcessingResult&lt;DynamoDBEvent.DynamodbStreamRecord&gt;&gt; ProcessAsync(DynamoDBEvent @event,\n    IRecordHandler&lt;DynamoDBEvent.DynamodbStreamRecord&gt; recordHandler, ProcessingOptions processingOptions)\n    {\n        ProcessingResult = new ProcessingResult&lt;DynamoDBEvent.DynamodbStreamRecord&gt;();\n\n        // Prepare batch records (order is preserved)\n        var batchRecords = GetRecordsFromEvent(@event).Select(x =&gt; new KeyValuePair&lt;string, DynamoDBEvent.DynamodbStreamRecord&gt;(GetRecordId(x), x))\n            .ToArray();\n\n        // We assume all records fail by default to avoid loss of data\n        var failureBatchRecords = batchRecords.Select(x =&gt; new KeyValuePair&lt;string, RecordFailure&lt;DynamoDBEvent.DynamodbStreamRecord&gt;&gt;(x.Key,\n            new RecordFailure&lt;DynamoDBEvent.DynamodbStreamRecord&gt;\n            {\n                Exception = new UnprocessedRecordException($\"Record: '{x.Key}' has not been processed.\"),\n                Record = x.Value\n            }));\n\n        // Override to fail on first failure\n        var errorHandlingPolicy = BatchProcessorErrorHandlingPolicy.StopOnFirstBatchItemFailure;\n\n        var successRecords = new Dictionary&lt;string, RecordSuccess&lt;DynamoDBEvent.DynamodbStreamRecord&gt;&gt;();\n        var failureRecords = new Dictionary&lt;string, RecordFailure&lt;DynamoDBEvent.DynamodbStreamRecord&gt;&gt;(failureBatchRecords);\n\n        try\n        {\n            foreach (var pair in batchRecords)\n            {\n                var (recordId, record) = pair;\n\n                try\n                {\n                    var result = await HandleRecordAsync(record, recordHandler, CancellationToken.None);\n                    failureRecords.Remove(recordId, out _);\n                    successRecords.TryAdd(recordId, new RecordSuccess&lt;DynamoDBEvent.DynamodbStreamRecord&gt;\n                    {\n                        Record = record,\n                        RecordId = recordId,\n                        HandlerResult = result\n                    });\n                }\n                catch (Exception ex)\n                {\n                    // Capture exception\n                    failureRecords[recordId] = new RecordFailure&lt;DynamoDBEvent.DynamodbStreamRecord&gt;\n                    {\n                        Exception = new RecordProcessingException(\n                            $\"Failed processing record: '{recordId}'. See inner exception for details.\", ex),\n                        Record = record,\n                        RecordId = recordId\n                    };\n\n                    Metrics.AddMetric(\"BatchRecordFailures\", 1, MetricUnit.Count);\n\n                    try\n                    {\n                        // Invoke hook\n                        await HandleRecordFailureAsync(record, ex);\n                    }\n                    catch\n                    {\n                        // NOOP\n                    }\n\n                    // Check if we should stop record processing on first error\n                    // ReSharper disable once ConditionIsAlwaysTrueOrFalse\n                    if (errorHandlingPolicy == BatchProcessorErrorHandlingPolicy.StopOnFirstBatchItemFailure)\n                    {\n                        // This causes the loop's (inner) cancellation token to be cancelled for all operations already scheduled internally\n                        throw new CircuitBreakerException(\n                            \"Error handling policy is configured to stop processing on first batch item failure. See inner exception for details.\",\n                            ex);\n                    }\n                }\n            }\n        }\n        catch (Exception ex) when (ex is CircuitBreakerException or OperationCanceledException)\n        {\n            // NOOP\n        }\n\n        ProcessingResult.BatchRecords.AddRange(batchRecords.Select(x =&gt; x.Value));\n        ProcessingResult.BatchItemFailuresResponse.BatchItemFailures.AddRange(failureRecords.Select(x =&gt;\n            new BatchItemFailuresResponse.BatchItemFailure\n            {\n                ItemIdentifier = x.Key\n            }));\n        ProcessingResult.FailureRecords.AddRange(failureRecords.Values);\n\n        ProcessingResult.SuccessRecords.AddRange(successRecords.Values);\n\n        return ProcessingResult;\n    }\n\n    // ReSharper disable once RedundantOverriddenMember\n    protected override async Task HandleRecordFailureAsync(DynamoDBEvent.DynamodbStreamRecord record, Exception exception)\n    {\n        await base.HandleRecordFailureAsync(record, exception);\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch-processing/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>As there is no external calls, you can unit test your code with <code>BatchProcessor</code> quite easily.</p> Test.csFunction.csCustomSqsRecordHandler.csSQS Event.cs <pre><code>[Fact]\npublic Task Sqs_Handler_Using_Attribute()\n{\n    var request = new SQSEvent\n    {\n        Records = TestHelper.SqsMessages\n    };\n\n    var function = new HandlerFunction();\n\n    var response = function.HandlerUsingAttribute(request);\n\n    Assert.Equal(2, response.BatchItemFailures.Count);\n    Assert.Equal(\"2\", response.BatchItemFailures[0].ItemIdentifier);\n    Assert.Equal(\"4\", response.BatchItemFailures[1].ItemIdentifier);\n\n    return Task.CompletedTask;\n}\n</code></pre> <pre><code>[BatchProcessor(RecordHandler = typeof(CustomSqsRecordHandler))]\npublic BatchItemFailuresResponse HandlerUsingAttribute(SQSEvent _)\n{\n    return SqsBatchProcessor.Result.BatchItemFailuresResponse;\n}\n</code></pre> <pre><code>public class CustomSqsRecordHandler : ISqsRecordHandler\n{\n    public async Task&lt;RecordHandlerResult&gt; HandleAsync(SQSEvent.SQSMessage record, CancellationToken cancellationToken)\n    {\n        var product = JsonSerializer.Deserialize&lt;JsonElement&gt;(record.Body);\n\n        if (product.GetProperty(\"Id\").GetInt16() == 4)\n        {\n            throw new ArgumentException(\"Error on 4\");\n        }\n\n        return await Task.FromResult(RecordHandlerResult.None);\n    }\n}\n</code></pre> <pre><code>internal static List&lt;SQSEvent.SQSMessage&gt; SqsMessages =&gt; new()\n{\n    new SQSEvent.SQSMessage\n    {\n        MessageId = \"1\",\n        Body = \"{\\\"Id\\\":1,\\\"Name\\\":\\\"product-4\\\",\\\"Price\\\":14}\",\n        EventSourceArn = \"arn:aws:sqs:us-east-2:123456789012:my-queue\"\n    },\n    new SQSEvent.SQSMessage\n    {\n        MessageId = \"2\",\n        Body = \"fail\",\n        EventSourceArn = \"arn:aws:sqs:us-east-2:123456789012:my-queue\"\n    },\n    new SQSEvent.SQSMessage\n    {\n        MessageId = \"3\",\n        Body = \"{\\\"Id\\\":3,\\\"Name\\\":\\\"product-4\\\",\\\"Price\\\":14}\",\n        EventSourceArn = \"arn:aws:sqs:us-east-2:123456789012:my-queue\"\n    },\n    new SQSEvent.SQSMessage\n    {\n        MessageId = \"4\",\n        Body = \"{\\\"Id\\\":4,\\\"Name\\\":\\\"product-4\\\",\\\"Price\\\":14}\",\n        EventSourceArn = \"arn:aws:sqs:us-east-2:123456789012:my-queue\"\n    },\n    new SQSEvent.SQSMessage\n    {\n        MessageId = \"5\",\n        Body = \"{\\\"Id\\\":5,\\\"Name\\\":\\\"product-4\\\",\\\"Price\\\":14}\",\n        EventSourceArn = \"arn:aws:sqs:us-east-2:123456789012:my-queue\"\n    },\n};\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/",
            "title": "Idempotency",
            "text": "<p>The idempotency utility provides a simple solution to convert your Lambda functions into idempotent operations which are safe to retry.</p>"
        },
        {
            "location": "utilities/idempotency/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Prevent Lambda handler function from executing more than once on the same event payload during a time window</li> <li>Ensure Lambda handler returns the same result when called with the same payload</li> <li>Select a subset of the event as the idempotency key using JMESPath expressions</li> <li>Set a time window in which records with the same payload should be considered duplicates</li> <li>Expires in-progress executions if the Lambda function times out halfway through</li> <li>Ahead-of-Time compilation to native code support AOT from version 1.3.0</li> </ul>"
        },
        {
            "location": "utilities/idempotency/#terminology",
            "title": "Terminology",
            "text": "<p>The property of idempotency means that an operation does not cause additional side effects if it is called more than once with the same input parameters.</p> <p>Idempotent operations will return the same result when they are called multiple times with the same parameters. This makes idempotent operations safe to retry. Read more about idempotency.</p> <p>Idempotency key is a hash representation of either the entire event or a specific configured subset of the event, and invocation results are JSON serialized and stored in your persistence storage layer.</p> <p>Idempotency record is the data representation of an idempotent request saved in your preferred  storage layer. We use it to coordinate whether a request is idempotent, whether it's still valid or expired based on timestamps, etc.</p> <pre><code>classDiagram\n    direction LR\n    class DataRecord {\n        string IdempotencyKey\n        DataRecordStatus Status\n        long ExpiryTimestamp\n        long InProgressExpiryTimestamp\n        string ResponseData\n        string PayloadHash\n    }\n    class Status {\n        &lt;&lt;Enum&gt;&gt;\n        INPROGRESS\n        COMPLETED\n        EXPIRED\n    }\n    DataRecord -- Status</code></pre> Idempotency record representation"
        },
        {
            "location": "utilities/idempotency/#getting-started",
            "title": "Getting started",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#installation",
            "title": "Installation",
            "text": "<p>You should install with NuGet:</p> <pre><code>Install-Package AWS.Lambda.Powertools.Idempotency\n</code></pre> <p>Or via the .NET Core command line interface:</p> <pre><code>dotnet add package AWS.Lambda.Powertools.Idempotency\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#iam-permissions",
            "title": "IAM Permissions",
            "text": "<p>Your Lambda function IAM Role must have <code>dynamodb:GetItem</code>, <code>dynamodb:PutItem</code>, <code>dynamodb:UpdateItem</code> and <code>dynamodb:DeleteItem</code> IAM permissions before using this feature.</p> Note <p>If you're using our example AWS Serverless Application Model (SAM), AWS Cloud Development Kit (CDK), or Terraform it already adds the required permissions.</p>"
        },
        {
            "location": "utilities/idempotency/#required-resources",
            "title": "Required resources",
            "text": "<p>Before getting started, you need to create a persistent storage layer where the idempotency utility can store its state - your Lambda functions will need read and write access to it.</p> <p>As of now, Amazon DynamoDB is the only supported persistent storage layer, so you'll need to create a table first.</p> <p>Default table configuration</p> <p>If you're not changing the default configuration for the DynamoDB persistence layer, this is the expected default configuration:</p> Configuration Value Notes Partition key <code>id</code> TTL attribute name <code>expiration</code> This can only be configured after your table is created if you're using AWS Console <p>Tip: You can share a single state table for all functions</p> <p>You can reuse the same DynamoDB table to store idempotency state. We add your function name in addition to the idempotency key as a hash key.</p> template.yml AWS Serverless Application Model (SAM) example<pre><code>Resources:\nIdempotencyTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n    AttributeDefinitions:\n        - AttributeName: id\n        AttributeType: S\n    KeySchema:\n        - AttributeName: id\n        KeyType: HASH\n    TimeToLiveSpecification:\n        AttributeName: expiration\n        Enabled: true\n    BillingMode: PAY_PER_REQUEST\n\nIdempotencyFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n    CodeUri: Function\n    Handler: HelloWorld::HelloWorld.Function::FunctionHandler\n    Policies:\n        - DynamoDBCrudPolicy:\n            TableName: !Ref IdempotencyTable\n    Environment:\n        Variables:\n        IDEMPOTENCY_TABLE: !Ref IdempotencyTable\n</code></pre> <p>Warning: Large responses with DynamoDB persistence layer</p> <p>When using this utility with DynamoDB, your function's responses must be smaller than 400KB. Larger items cannot be written to DynamoDB and will cause exceptions.</p> <p>Info: DynamoDB</p> <p>Each function invocation will generally make 2 requests to DynamoDB. If the result returned by your Lambda is less than 1kb, you can expect 2 WCUs per invocation. For retried invocations, you will see 1WCU and 1RCU. Review the DynamoDB pricing documentation to estimate the cost.</p>"
        },
        {
            "location": "utilities/idempotency/#idempotent-attribute",
            "title": "Idempotent attribute",
            "text": "<p>You can quickly start by configuring <code>Idempotency</code> and using it with the <code>Idempotent</code> attribute on your Lambda function.</p> <p>Important</p> <p>Initialization and configuration of the <code>Idempotency</code> must be performed outside the handler, preferably in the constructor.</p> <pre><code>public class Function\n{\n    public Function()\n    {\n        Idempotency.Configure(builder =&gt; builder.UseDynamoDb(\"idempotency_table\"));\n    }\n\n    [Idempotent]\n    public Task&lt;string&gt; FunctionHandler(string input, ILambdaContext context)\n    {\n        return Task.FromResult(input.ToUpper());\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#idempotent-attribute-on-another-method",
            "title": "Idempotent attribute on another method",
            "text": "<p>You can use the <code>Idempotent</code> attribute for any .NET function, not only the Lambda handlers.</p> <p>When using <code>Idempotent</code> attribute on another method, you must tell which parameter in the method signature has the data we should use:</p> <ul> <li>If the method only has one parameter, it will be used by default. </li> <li>If there are 2 or more parameters, you must set the <code>IdempotencyKey</code> attribute on the parameter to use.</li> </ul> <p>The parameter must be serializable in JSON. We use <code>System.Text.Json</code> internally to (de)serialize objects</p> <pre><code>public class Function\n{\n    public Function()\n    {\n        Idempotency.Configure(builder =&gt; builder.UseDynamoDb(\"idempotency_table\"));\n    }\n\n    public Task&lt;string&gt; FunctionHandler(string input, ILambdaContext context)\n    {\n        MyInternalMethod(\"hello\", \"world\")\n        return Task.FromResult(input.ToUpper());\n    }\n\n    [Idempotent]\n    private string MyInternalMethod(string argOne, [IdempotencyKey] string argTwo) {\n        return \"something\";\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#choosing-a-payload-subset-for-idempotency",
            "title": "Choosing a payload subset for idempotency",
            "text": "<p>Tip: Dealing with always changing payloads</p> <p>When dealing with an elaborate payload (API Gateway request for example), where parts of the payload always change, you should configure the <code>EventKeyJmesPath</code>.</p> <p>Use <code>IdempotencyConfig</code> to instruct the Idempotent annotation to only use a portion of your payload to verify whether a request is idempotent, and therefore it should not be retried.</p> <p>Payment scenario</p> <p>In this example, we have a Lambda handler that creates a payment for a user subscribing to a product. We want to ensure that we don't accidentally charge our customer by subscribing them more than once.</p> <p>Imagine the function executes successfully, but the client never receives the response due to a connection issue. It is safe to retry in this instance, as the idempotent decorator will return a previously saved response.</p> <p>What we want here is to instruct Idempotency to use <code>user_id</code> and <code>product_id</code> fields from our incoming payload as our idempotency key. If we were to treat the entire request as our idempotency key, a simple HTTP header change would cause our customer to be charged twice.</p> Deserializing JSON strings in payloads for increased accuracy. <p>The payload extracted by the <code>EventKeyJmesPath</code> is treated as a string by default, so will be sensitive to differences in whitespace even when the JSON payload itself is identical.</p> <p>To alter this behaviour, you can use the JMESPath built-in function <code>powertools_json()</code> to treat the payload as a JSON object rather than a string.</p> Payment functionSample event <pre><code>Idempotency.Configure(builder =&gt;\n        builder\n            .WithOptions(optionsBuilder =&gt;\n                optionsBuilder.WithEventKeyJmesPath(\"powertools_json(Body).[\\\"user_id\\\", \\\"product_id\\\"]\"))\n            .UseDynamoDb(\"idempotency_table\"));\n</code></pre> <pre><code>{\n\"version\": \"2.0\",\n\"routeKey\": \"ANY /createpayment\",\n\"rawPath\": \"/createpayment\",\n\"rawQueryString\": \"\",\n\"headers\": {\n\"Header1\": \"value1\",\n\"Header2\": \"value2\"\n},\n\"requestContext\": {\n\"accountId\": \"123456789012\",\n\"apiId\": \"api-id\",\n\"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n\"domainPrefix\": \"id\",\n\"http\": {\n\"method\": \"POST\",\n\"path\": \"/createpayment\",\n\"protocol\": \"HTTP/1.1\",\n\"sourceIp\": \"ip\",\n\"userAgent\": \"agent\"\n},\n\"requestId\": \"id\",\n\"routeKey\": \"ANY /createpayment\",\n\"stage\": \"$default\",\n\"time\": \"10/Feb/2021:13:40:43 +0000\",\n\"timeEpoch\": 1612964443723\n},\n\"body\": \"{\\\"user_id\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\",\n\"isBase64Encoded\": false\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#custom-key-prefix",
            "title": "Custom key prefix",
            "text": "<p>By default, the idempotency key is prefixed with <code>[ClassName].[DecoratedMethodName]#[PayloadHash]</code>.</p> <p>You can customize this prefix by setting the <code>KeyPrefix</code> property in the Idempotency decorator:</p> <pre><code>public class Function\n{\n    public Function()\n    {\n        var tableName = Environment.GetEnvironmentVariable(\"IDEMPOTENCY_TABLE_NAME\");\n        Idempotency.Configure(builder =&gt; builder.UseDynamoDb(tableName));\n    }\n\n    [Idempotent(KeyPrefix = \"MyCustomKeyPrefix\")]\n    public APIGatewayProxyResponse FunctionHandler(APIGatewayProxyRequest apigwProxyEvent, ILambdaContext context)\n    {\n        return TestHelper.TestMethod(apigwProxyEvent);\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#lambda-timeouts",
            "title": "Lambda timeouts",
            "text": "Note <p>This is automatically done when you decorate your Lambda handler with Idempotent attribute.</p> <p>To prevent against extended failed retries when a Lambda function times out, Powertools for AWS Lambda (.NET) calculates and includes the remaining invocation available time as part of the idempotency record.</p> Example <p>If a second invocation happens after this timestamp, and the record is marked as <code>INPROGRESS</code>, we will execute the invocation again as if it was in the <code>EXPIRED</code> state (e.g, <code>Expired</code> field elapsed).</p> <p>This means that if an invocation expired during execution, it will be quickly executed again on the next retry.</p> Important <p>If you are only using the Idempotent attribute to guard isolated parts of your code, you must use <code>RegisterLambdaContext</code> available in the <code>Idempotency</code> static class to benefit from this protection.</p> <p>Here is an example on how you register the Lambda context in your handler:</p> Registering the Lambda context Registering the Lambda context<pre><code>public class Function\n{\n    public Function()\n    {\n        Idempotency.Configure(builder =&gt; builder.UseDynamoDb(\"idempotency_table\"));\n    }\n\n    public Task&lt;string&gt; FunctionHandler(string input, ILambdaContext context)\n    {\n        Idempotency.RegisterLambdaContext(context);\n        MyInternalMethod(\"hello\", \"world\")\n        return Task.FromResult(input.ToUpper());\n    }\n\n    [Idempotent]\n    private string MyInternalMethod(string argOne, [IdempotencyKey] string argTwo) {\n        return \"something\";\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#handling-exceptions",
            "title": "Handling exceptions",
            "text": "<p>If you are using the <code>Idempotent</code> attribute on your Lambda handler or any other method, any unhandled exceptions that are thrown during the code execution will cause the record in the persistence layer to be deleted. This means that new invocations will execute your code again despite having the same payload. If you don't want the record to be deleted, you need to catch exceptions within the idempotent function and return a successful response.</p> <p>Warning</p> <p>We will throw an <code>IdempotencyPersistenceLayerException</code> if any of the calls to the persistence layer fail unexpectedly.</p> <p>As this happens outside the scope of your decorated function, you are not able to catch it.</p> <p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;Persistence Layer: Get or set (id=event.search(payload))\n    activate Persistence Layer\n    Note right of Persistence Layer: Locked during this time. Prevents multiple&lt;br/&gt;Lambda invocations with the same&lt;br/&gt;payload running concurrently.\n    Lambda--xLambda: Call handler (event).&lt;br/&gt;Raises exception\n    Lambda-&gt;&gt;Persistence Layer: Delete record (id=event.search(payload))\n    deactivate Persistence Layer\n    Lambda--&gt;&gt;Client: Return error response</code></pre> Idempotent sequence exception </p> <p>If you are using <code>Idempotent</code> attribute on another method, any unhandled exceptions that are raised inside the decorated function will cause the record in the persistence layer to be deleted, and allow the function to be executed again if retried.</p> <p>If an Exception is raised outside the scope of the decorated method and after your method has been called, the persistent record will not be affected. In this case, idempotency will be maintained for your decorated function. Example:</p> Handling exceptions Exception not affecting idempotency record sample<pre><code>public class Function\n{\n    public Function()\n    {\n        Idempotency.Configure(builder =&gt; builder.UseDynamoDb(\"idempotency_table\"));\n    }\n\n    public Task&lt;string&gt; FunctionHandler(string input, ILambdaContext context)\n    {\n        Idempotency.RegisterLambdaContext(context);\n        // If an exception is thrown here, no idempotent record will ever get created as the\n        // idempotent method does not get called\n\n        MyInternalMethod(\"hello\", \"world\")\n\n        // This exception will not cause the idempotent record to be deleted, since it\n        // happens after the decorated method has been successfully called    \n        throw new Exception();\n    }\n\n    [Idempotent]\n    private string MyInternalMethod(string argOne, [IdempotencyKey] string argTwo) {\n        return \"something\";\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#idempotency-request-flow",
            "title": "Idempotency request flow",
            "text": "<p>The following sequence diagrams explain how the Idempotency feature behaves under different scenarios.</p>"
        },
        {
            "location": "utilities/idempotency/#successful-request",
            "title": "Successful request",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Persistence Layer--&gt;&gt;Lambda: Already exists in persistence layer.\n        deactivate Persistence Layer\n        Note over Lambda,Persistence Layer: Record status is COMPLETE and not expired\n        Lambda--&gt;&gt;Client: Same response sent to client\n    end</code></pre> Idempotent successful request </p>"
        },
        {
            "location": "utilities/idempotency/#successful-request-with-cache-enabled",
            "title": "Successful request with cache enabled",
            "text": "<p>In-memory cache is disabled by default.</p> <p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n      Client-&gt;&gt;Lambda: Invoke (event)\n      Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n      activate Persistence Layer\n      Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n      Lambda--&gt;&gt;Lambda: Call your function\n      Lambda-&gt;&gt;Persistence Layer: Update record with result\n      deactivate Persistence Layer\n      Persistence Layer--&gt;&gt;Persistence Layer: Update record\n      Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n      Lambda--&gt;&gt;Lambda: Save record and result in memory\n      Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n      Client-&gt;&gt;Lambda: Invoke (event)\n      Lambda--&gt;&gt;Lambda: Get idempotency_key=hash(payload)\n      Note over Lambda,Persistence Layer: Record status is COMPLETE and not expired\n      Lambda--&gt;&gt;Client: Same response sent to client\n    end</code></pre> Idempotent successful request cached </p>"
        },
        {
            "location": "utilities/idempotency/#expired-idempotency-records",
            "title": "Expired idempotency records",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Persistence Layer--&gt;&gt;Lambda: Already exists in persistence layer.\n        deactivate Persistence Layer\n        Note over Lambda,Persistence Layer: Record status is COMPLETE but expired hours ago\n        loop Repeat initial request process\n            Note over Lambda,Persistence Layer: 1. Set record to INPROGRESS, &lt;br&gt; 2. Call your function, &lt;br&gt; 3. Set record to COMPLETE\n        end\n        Lambda--&gt;&gt;Client: Same response sent to client\n    end</code></pre> Previous Idempotent request expired </p>"
        },
        {
            "location": "utilities/idempotency/#concurrent-identical-in-flight-requests",
            "title": "Concurrent identical in-flight requests",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n    activate Persistence Layer\n    Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n      par Second request\n          Client-&gt;&gt;Lambda: Invoke (event)\n          Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n          Lambda--xLambda: IdempotencyAlreadyInProgressError\n          Lambda-&gt;&gt;Client: Error sent to client if unhandled\n      end\n    Lambda--&gt;&gt;Lambda: Call your function\n    Lambda-&gt;&gt;Persistence Layer: Update record with result\n    deactivate Persistence Layer\n    Persistence Layer--&gt;&gt;Persistence Layer: Update record\n    Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n    Lambda--&gt;&gt;Client: Response sent to client</code></pre> Concurrent identical in-flight requests </p>"
        },
        {
            "location": "utilities/idempotency/#lambda-request-timeout",
            "title": "Lambda request timeout",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Note right of Lambda: Time out\n        Lambda--xLambda: Time out error\n        Lambda--&gt;&gt;Client: Return error response\n        deactivate Persistence Layer\n    else retry after Lambda timeout elapses\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Reset in_progress_expiry attribute\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Lambda--&gt;&gt;Client: Response sent to client\n    end</code></pre> Idempotent request during and after Lambda timeouts </p>"
        },
        {
            "location": "utilities/idempotency/#optional-idempotency-key",
            "title": "Optional idempotency key",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt request with idempotency key\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else request(s) without idempotency key\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Note over Lambda: Idempotency key is missing\n        Note over Persistence Layer: Skips any operation to fetch, update, and delete\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda--&gt;&gt;Client: Response sent to client\n    end</code></pre> Optional idempotency key </p>"
        },
        {
            "location": "utilities/idempotency/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#persistence-stores",
            "title": "Persistence stores",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#dynamodbpersistencestore",
            "title": "DynamoDBPersistenceStore",
            "text": "<p>This persistence store is built-in, and you can either use an existing DynamoDB table or create a new one dedicated for idempotency state (recommended).</p> <p>Use the builder to customize the table structure: Customizing DynamoDBPersistenceStore to suit your table structure<pre><code>new DynamoDBPersistenceStoreBuilder()\n    .WithTableName(\"TABLE_NAME\")\n    .WithKeyAttr(\"idempotency_key\")\n    .WithExpiryAttr(\"expires_at\")\n    .WithStatusAttr(\"current_status\")\n    .WithDataAttr(\"result_data\")\n    .WithValidationAttr(\"validation_key\")\n    .WithInProgressExpiryAttr(\"in_progress_expires_at\")\n    .Build()\n</code></pre></p> <p>When using DynamoDB as a persistence layer, you can alter the attribute names by passing these parameters when initializing the persistence layer:</p> Parameter Required Default Description TableName Y Table name to store state KeyAttr <code>id</code> Partition key of the table. Hashed representation of the payload (unless SortKeyAttr is specified) ExpiryAttr <code>expiration</code> Unix timestamp of when record expires InProgressExpiryAttr <code>in_progress_expiration</code> Unix timestamp of when record expires while in progress (in case of the invocation times out) StatusAttr <code>status</code> Stores status of the Lambda execution during and after invocation DataAttr <code>data</code> Stores results of successfully idempotent methods ValidationAttr <code>validation</code> Hashed representation of the parts of the event used for validation SortKeyAttr Sort key of the table (if table is configured with a sort key). StaticPkValue <code>idempotency#{LAMBDA_FUNCTION_NAME}</code> Static value to use as the partition key. Only used when SortKeyAttr is set."
        },
        {
            "location": "utilities/idempotency/#customizing-the-default-behavior",
            "title": "Customizing the default behavior",
            "text": "<p>Idempotency behavior can be further configured with <code>IdempotencyOptions</code> using a builder:</p> <pre><code>new IdempotencyOptionsBuilder()\n    .WithEventKeyJmesPath(\"id\")\n    .WithPayloadValidationJmesPath(\"paymentId\")\n    .WithThrowOnNoIdempotencyKey(true)\n    .WithExpiration(TimeSpan.FromMinutes(1))\n    .WithUseLocalCache(true)\n    .WithHashFunction(\"MD5\")\n    .Build();\n</code></pre> <p>These are the available options for further configuration:</p> Parameter Default Description EventKeyJMESPath <code>\"\"</code> JMESPath expression to extract the idempotency key from the event record. PayloadValidationJMESPath <code>\"\"</code> JMESPath expression to validate whether certain parameters have changed in the event ThrowOnNoIdempotencyKey <code>False</code> Throw exception if no idempotency key was found in the request ExpirationInSeconds 3600 The number of seconds to wait before a record is expired UseLocalCache <code>false</code> Whether to locally cache idempotency results (LRU cache) HashFunction <code>MD5</code> Algorithm to use for calculating hashes, as supported by <code>System.Security.Cryptography.HashAlgorithm</code> (eg. SHA1, SHA-256, ...) <p>These features are detailed below.</p>"
        },
        {
            "location": "utilities/idempotency/#handling-concurrent-executions-with-the-same-payload",
            "title": "Handling concurrent executions with the same payload",
            "text": "<p>This utility will throw an <code>IdempotencyAlreadyInProgressException</code> if we receive multiple invocations with the same payload while the first invocation hasn't completed yet.</p> <p>Info</p> <p>If you receive <code>IdempotencyAlreadyInProgressException</code>, you can safely retry the operation.</p> <p>This is a locking mechanism for correctness. Since we don't know the result from the first invocation yet, we can't safely allow another concurrent execution.</p>"
        },
        {
            "location": "utilities/idempotency/#using-in-memory-cache",
            "title": "Using in-memory cache",
            "text": "<p>By default, in-memory local caching is disabled, to avoid using memory in an unpredictable way. </p> <p>Warning</p> <p>Be sure to configure the Lambda memory according to the number of records and the potential size of each record.</p> <p>You can enable it as seen before with: Enable local cache<pre><code>    new IdempotencyOptionsBuilder()\n        .WithUseLocalCache(true)\n        .Build()\n</code></pre> When enabled, we cache a maximum of 255 records in each Lambda execution environment</p> <p>Note: This in-memory cache is local to each Lambda execution environment</p> <p>This means it will be effective in cases where your function's concurrency is low in comparison to the number of \"retry\" invocations with the same payload, because cache might be empty.</p>"
        },
        {
            "location": "utilities/idempotency/#expiring-idempotency-records",
            "title": "Expiring idempotency records",
            "text": "<p>Note</p> <p>By default, we expire idempotency records after an hour (3600 seconds).</p> <p>In most cases, it is not desirable to store the idempotency records forever. Rather, you want to guarantee that the same payload won't be executed within a period of time.</p> <p>You can change this window with the <code>ExpirationInSeconds</code> parameter: Customizing expiration time<pre><code>new IdempotencyOptionsBuilder()\n    .WithExpiration(TimeSpan.FromMinutes(5))\n    .Build()\n</code></pre></p> <p>Records older than 5 minutes will be marked as expired, and the Lambda handler will be executed normally even if it is invoked with a matching payload.</p> <p>Note: DynamoDB time-to-live field</p> <p>This utility uses <code>expiration</code> as the TTL field in DynamoDB, as demonstrated in the SAM example earlier.</p>"
        },
        {
            "location": "utilities/idempotency/#payload-validation",
            "title": "Payload validation",
            "text": "<p>Question: What if your function is invoked with the same payload except some outer parameters have changed?</p> <p>Example: A payment transaction for a given productID was requested twice for the same customer, however the amount to be paid has changed in the second transaction.</p> <p>By default, we will return the same result as it returned before, however in this instance it may be misleading; we provide a fail fast payload validation to address this edge case.</p> <p>With <code>PayloadValidationJMESPath</code>, you can provide an additional JMESPath expression to specify which part of the event body should be validated against previous idempotent invocations</p> Function.csExample Event 1Example Event 2 <pre><code>Idempotency.Configure(builder =&gt;\n        builder\n            .WithOptions(optionsBuilder =&gt;\n                optionsBuilder\n                    .WithEventKeyJmesPath(\"[userDetail, productId]\")\n                    .WithPayloadValidationJmesPath(\"amount\"))\n            .UseDynamoDb(\"TABLE_NAME\"));\n</code></pre> <pre><code>{\n    \"userDetail\": {\n        \"username\": \"User1\",\n        \"user_email\": \"user@example.com\"\n    },\n    \"productId\": 1500,\n    \"charge_type\": \"subscription\",\n    \"amount\": 500\n}\n</code></pre> <pre><code>{\n    \"userDetail\": {\n        \"username\": \"User1\",\n        \"user_email\": \"user@example.com\"\n    },\n    \"productId\": 1500,\n    \"charge_type\": \"subscription\",\n    \"amount\": 1\n}\n</code></pre> <p>In this example, the <code>userDetail</code> and <code>productId</code> keys are used as the payload to generate the idempotency key, as per <code>EventKeyJMESPath</code> parameter.</p> <p>Note</p> <p>If we try to send the same request but with a different amount, we will raise <code>IdempotencyValidationException</code>.</p> <p>Without payload validation, we would have returned the same result as we did for the initial request. Since we're also returning an amount in the response, this could be quite confusing for the client.</p> <p>By using <code>withPayloadValidationJMESPath(\"amount\")</code>, we prevent this potentially confusing behavior and instead throw an Exception.</p>"
        },
        {
            "location": "utilities/idempotency/#making-idempotency-key-required",
            "title": "Making idempotency key required",
            "text": "<p>If you want to enforce that an idempotency key is required, you can set <code>ThrowOnNoIdempotencyKey</code> to <code>True</code>.</p> <p>This means that we will throw <code>IdempotencyKeyException</code> if the evaluation of <code>EventKeyJMESPath</code> is <code>null</code>.</p> Function.csSuccess EventFailure Event <pre><code>public App() \n{\n  Idempotency.Configure(builder =&gt;\n        builder\n            .WithOptions(optionsBuilder =&gt;\n                optionsBuilder\n                    // Requires \"user\".\"uid\" and \"orderId\" to be present\n                    .WithEventKeyJmesPath(\"[user.uid, orderId]\")\n                    .WithThrowOnNoIdempotencyKey(true))\n            .UseDynamoDb(\"TABLE_NAME\"));\n}\n\n[Idempotent]\npublic Task&lt;OrderResult&gt; FunctionHandler(Order input, ILambdaContext context)\n{\n  // ...\n}\n</code></pre> <pre><code>{\n    \"user\": {\n        \"uid\": \"BB0D045C-8878-40C8-889E-38B3CB0A61B1\",\n        \"name\": \"Foo\"\n    },\n    \"orderId\": 10000\n}\n</code></pre> <p>Notice that <code>orderId</code> is now accidentally within <code>user</code> key</p> <pre><code>{\n    \"user\": {\n        \"uid\": \"DE0D000E-1234-10D1-991E-EAC1DD1D52C8\",\n        \"name\": \"Joe Bloggs\",\n        \"orderId\": 10000\n    },\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#customizing-dynamodb-configuration",
            "title": "Customizing DynamoDB configuration",
            "text": "<p>When creating the <code>DynamoDBPersistenceStore</code>, you can set a custom <code>AmazonDynamoDBClient</code> if you need to customize the configuration:</p> Custom AmazonDynamoDBClient <pre><code>public Function()\n{\n    AmazonDynamoDBClient customClient = new AmazonDynamoDBClient(RegionEndpoint.APSouth1);\n\n    Idempotency.Configure(builder =&gt; \n        builder.UseDynamoDb(storeBuilder =&gt; \n            storeBuilder.\n                WithTableName(\"TABLE_NAME\")\n                .WithDynamoDBClient(customClient)\n        ));\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#using-a-dynamodb-table-with-a-composite-primary-key",
            "title": "Using a DynamoDB table with a composite primary key",
            "text": "<p>When using a composite primary key table (hash+range key), use <code>SortKeyAttr</code> parameter when initializing your persistence store.</p> <p>With this setting, we will save the idempotency key in the sort key instead of the primary key. By default, the primary key will now be set to <code>idempotency#{LAMBDA_FUNCTION_NAME}</code>.</p> <p>You can optionally set a static value for the partition key using the <code>StaticPkValue</code> parameter.</p> Reusing a DynamoDB table that uses a composite primary key <pre><code>Idempotency.Configure(builder =&gt; \n    builder.UseDynamoDb(storeBuilder =&gt; \n        storeBuilder.\n            WithTableName(\"TABLE_NAME\")\n            .WithSortKeyAttr(\"sort_key\")\n    ));\n</code></pre> <p>Data would then be stored in DynamoDB like this:</p> id sort_key expiration status data idempotency#MyLambdaFunction 1e956ef7da78d0cb890be999aecc0c9e 1636549553 COMPLETED {\"id\": 12391, \"message\": \"success\"} idempotency#MyLambdaFunction 2b2cdb5f86361e97b4383087c1ffdf27 1636549571 COMPLETED {\"id\": 527212, \"message\": \"success\"} idempotency#MyLambdaFunction f091d2527ad1c78f05d54cc3f363be80 1636549585 IN_PROGRESS"
        },
        {
            "location": "utilities/idempotency/#aot-support",
            "title": "AOT Support",
            "text": "<p>Native AOT trims your application code as part of the compilation to ensure that the binary is as small as possible. .NET 8 for Lambda provides improved trimming support compared to previous versions of .NET.</p>"
        },
        {
            "location": "utilities/idempotency/#withjsonserializationcontext",
            "title": "WithJsonSerializationContext()",
            "text": "<p>To use Idempotency utility with AOT support you first need to add <code>WithJsonSerializationContext()</code> to your <code>Idempotency</code> configuration.</p> <p>This ensures that when serializing your payload, the utility uses the correct serialization context.</p> <p>In the example below, we use the default <code>LambdaFunctionJsonSerializerContext</code>:</p> <pre><code>Idempotency.Configure(builder =&gt;\nbuilder.WithJsonSerializationContext(LambdaFunctionJsonSerializerContext.Default)));\n</code></pre> <p>Full example:</p> <pre><code>public static class Function\n{\n    private static async Task Main()\n    {\n        var tableName = Environment.GetEnvironmentVariable(\"IDEMPOTENCY_TABLE_NAME\");\n        Idempotency.Configure(builder =&gt;\n            builder\n                .WithJsonSerializationContext(LambdaFunctionJsonSerializerContext.Default)\n                .WithOptions(optionsBuilder =&gt; optionsBuilder\n                    .WithExpiration(TimeSpan.FromHours(1)))\n                .UseDynamoDb(storeBuilder =&gt; storeBuilder\n                    .WithTableName(tableName)\n                ));\n\n        Func&lt;APIGatewayProxyRequest, ILambdaContext, APIGatewayProxyResponse&gt; handler = FunctionHandler;\n        await LambdaBootstrapBuilder.Create(handler,\n                new SourceGeneratorLambdaJsonSerializer&lt;LambdaFunctionJsonSerializerContext&gt;())\n            .Build()\n            .RunAsync();\n    }\n\n    [Idempotent]\n    public static APIGatewayProxyResponse FunctionHandler(APIGatewayProxyRequest apigwProxyEvent,\n        ILambdaContext context)\n    {\n        return new APIGatewayProxyResponse\n            {\n                Body = JsonSerializer.Serialize(response, typeof(Response), LambdaFunctionJsonSerializerContext.Default),\n                StatusCode = 200,\n                Headers = new Dictionary&lt;string, string&gt; { { \"Content-Type\", \"application/json\" } }\n            };\n    }\n}\n\n[JsonSerializable(typeof(APIGatewayProxyRequest))]\n[JsonSerializable(typeof(APIGatewayProxyResponse))]\n[JsonSerializable(typeof(Response))]\npublic partial class LambdaFunctionJsonSerializerContext : JsonSerializerContext\n{\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>The idempotency utility provides several routes to test your code.</p> <p>You can check our Integration tests which use TestContainers with a local DynamoDB instance to test the idempotency utility. Or our end-to-end tests which use the AWS SDK to interact with a real DynamoDB table.</p>"
        },
        {
            "location": "utilities/idempotency/#disabling-the-idempotency-utility",
            "title": "Disabling the idempotency utility",
            "text": "<p>When testing your code, you may wish to disable the idempotency logic altogether and focus on testing your business logic. To do this, you can set the environment variable <code>POWERTOOLS_IDEMPOTENCY_DISABLED</code> to true. </p>"
        },
        {
            "location": "utilities/idempotency/#extra-resources",
            "title": "Extra resources",
            "text": "<p>If you're interested in a deep dive on how Amazon uses idempotency when building our APIs, check out this article.</p>"
        },
        {
            "location": "utilities/jmespath-functions/",
            "title": "JMESPath Functions",
            "text": "Tip <p>JMESPath is a query language for JSON used by AWS CLI, AWS Python SDK, and Powertools for AWS Lambda.</p> <p>Built-in JMESPath functions to easily deserialize common encoded JSON payloads in Lambda functions.</p>"
        },
        {
            "location": "utilities/jmespath-functions/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Deserialize JSON from JSON strings, base64, and compressed data</li> <li>Use JMESPath to extract and combine data recursively</li> <li>Provides commonly used JMESPath expression with popular event sources</li> </ul>"
        },
        {
            "location": "utilities/jmespath-functions/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p> <p>You might have events that contains encoded JSON payloads as string, base64, or even in compressed format. It is a common use case to decode and extract them partially or fully as part of your Lambda function invocation.</p> Terminology <p>Envelope is the terminology we use for the JMESPath expression to extract your JSON object from your data input. We might use those two terms interchangeably.</p>"
        },
        {
            "location": "utilities/jmespath-functions/#extracting-data",
            "title": "Extracting data",
            "text": "<p>You can use the <code>JsonTransformer.Transform</code> function with any JMESPath expression.</p> Tip <p>Another common use case is to fetch deeply nested data, filter, flatten, and more.</p> TransformPayload <pre><code>var transformer = JsonTransformer.Parse(\"powertools_json(body).customerId\");\nusing var result = transformer.Transform(doc.RootElement);\n\nLogger.LogInformation(result.RootElement.GetRawText()); // \"dd4649e6-2484-4993-acb8-0f9123103394\"\n</code></pre> <pre><code> {\n     \"body\": \"{\\\"customerId\\\":\\\"dd4649e6-2484-4993-acb8-0f9123103394\\\"}\",\n     \"deeply_nested\": [\n         {\n             \"some_data\": [\n                 1,\n                 2,\n                 3\n             ]\n         }\n     ]\n }\n</code></pre>"
        },
        {
            "location": "utilities/jmespath-functions/#built-in-envelopes",
            "title": "Built-in envelopes",
            "text": "<p>We provide built-in envelopes for popular AWS Lambda event sources to easily decode and/or deserialize JSON objects.</p> Envelop JMESPath expression API_GATEWAY_HTTP powertools_json(body) API_GATEWAY_REST powertools_json(body) CLOUDWATCH_LOGS awslogs.powertools_base64_gzip(data) | powertools_json(@).logEvents[*] KINESIS_DATA_STREAM Records[*].kinesis.powertools_json(powertools_base64(data)) SNS Records[*].Sns.Message | powertools_json(@) SQS Records[*].powertools_json(body) Using SNS? <p>If you don't require SNS metadata, enable raw message delivery. It will reduce multiple payload layers and size, when using SNS in combination with other services (e.g., SQS, S3, etc).</p>"
        },
        {
            "location": "utilities/jmespath-functions/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/jmespath-functions/#built-in-jmespath-functions",
            "title": "Built-in JMESPath functions",
            "text": "<p>You can use our built-in JMESPath functions within your envelope expression. They handle deserialization for common data formats found in AWS Lambda event sources such as JSON strings, base64, and uncompress gzip data.</p>"
        },
        {
            "location": "utilities/jmespath-functions/#powertools_json-function",
            "title": "powertools_json function",
            "text": "<p>Use <code>powertools_json</code> function to decode any JSON string anywhere a JMESPath expression is allowed.</p> <p>Idempotency scenario</p> <p>This sample will deserialize the JSON string within the <code>body</code> key before Idempotency processes it.</p> Idempotency utility: WithEventKeyJmesPathPayload <pre><code>Idempotency.Configure(builder =&gt;\n        builder\n            .WithOptions(optionsBuilder =&gt;\n                optionsBuilder.WithEventKeyJmesPath(\"powertools_json(Body).[\\\"user_id\\\", \\\"product_id\\\"]\"))\n            .UseDynamoDb(\"idempotency_table\"));\n</code></pre> <pre><code>{\n  \"version\": \"2.0\",\n  \"routeKey\": \"ANY /createpayment\",\n  \"rawPath\": \"/createpayment\",\n  \"rawQueryString\": \"\",\n  \"headers\": {\n    \"Header1\": \"value1\",\n    \"Header2\": \"value2\"\n  },\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"apiId\": \"api-id\",\n    \"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n    \"domainPrefix\": \"id\",\n    \"http\": {\n      \"method\": \"POST\",\n      \"path\": \"/createpayment\",\n      \"protocol\": \"HTTP/1.1\",\n      \"sourceIp\": \"ip\",\n      \"userAgent\": \"agent\"\n    },\n    \"requestId\": \"id\",\n    \"routeKey\": \"ANY /createpayment\",\n    \"stage\": \"$default\",\n    \"time\": \"10/Feb/2021:13:40:43 +0000\",\n    \"timeEpoch\": 1612964443723\n  },\n  \"body\": \"{\\\"user_id\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\",\n  \"isBase64Encoded\": false\n}\n</code></pre>"
        },
        {
            "location": "utilities/jmespath-functions/#powertools_base64-function",
            "title": "powertools_base64 function",
            "text": "<p>Use <code>powertools_base64</code> function to decode any base64 data.</p> <p>This sample will decode the base64 value within the <code>data</code> key, and deserialize the JSON string before validation.</p> FunctionPayload <pre><code>var transformer = JsonTransformer.Parse(\"powertools_base64(body).customerId\");\nusing var result = transformer.Transform(doc.RootElement);\n\nLogger.LogInformation(result.RootElement.GetRawText()); // \"dd4649e6-2484-4993-acb8-0f9123103394\"\n</code></pre> <pre><code> {\n  \"body\": \"eyJjdXN0b21lcklkIjoiZGQ0NjQ5ZTYtMjQ4NC00OTkzLWFjYjgtMGY5MTIzMTAzMzk0In0=\",\n  \"deeply_nested\": [\n    {\n      \"some_data\": [\n        1,\n        2,\n        3\n      ]\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/jmespath-functions/#powertools_base64_gzip-function",
            "title": "powertools_base64_gzip function",
            "text": "<p>Use <code>powertools_base64_gzip</code> function to decompress and decode base64 data.</p> <p>This sample will decompress and decode base64 data from Cloudwatch Logs, then use JMESPath pipeline expression to pass the result for decoding its JSON string.</p> FunctionPayload <pre><code>var transformer = JsonTransformer.Parse(\"powertools_base64_gzip(body).customerId\");\nusing var result = transformer.Transform(doc.RootElement);\n\nLogger.LogInformation(result.RootElement.GetRawText()); // \"dd4649e6-2484-4993-acb8-0f9123103394\"\n</code></pre> <pre><code>{\n  \"body\": \"H4sIAAAAAAAAA6tWSi4tLsnPTS3yTFGyUkpJMTEzsUw10zUysTDRNbG0NNZNTE6y0DVIszQ0MjY0MDa2NFGqBQCMzDWgNQAAAA==\",\n  \"deeply_nested\": [\n    {\n      \"some_data\": [\n        1,\n        2,\n        3\n      ]\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/",
            "title": "Parameters",
            "text": "<p>The Parameters utility provides high-level functionality to retrieve one or multiple parameter values from AWS Systems Manager Parameter Store, AWS Secrets Manager, Amazon DynamoDB, or AWS AppConfig. We also provide extensibility to bring your own providers.</p>"
        },
        {
            "location": "utilities/parameters/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Retrieve one or multiple parameters from the underlying provider</li> <li>Cache parameter values for a given amount of time (defaults to 5 seconds)</li> <li>Transform parameter values from JSON or base 64 encoded strings</li> <li>Bring your own parameter store provider</li> </ul>"
        },
        {
            "location": "utilities/parameters/#installation",
            "title": "Installation",
            "text": "<p>Powertools for AWS Lambda (.NET) are available as NuGet packages. You can install the packages from NuGet Gallery or from Visual Studio editor by searching <code>AWS.Lambda.Powertools*</code> to see various utilities available.</p> <ul> <li> <p>AWS.Lambda.Powertools.Parameters:</p> <p><code>dotnet nuget add AWS.Lambda.Powertools.Parameters</code></p> </li> </ul> <p>IAM Permissions</p> <p>This utility requires additional permissions to work as expected. See the table below:</p> Provider Function/Method IAM Permission SSM Parameter Store <code>SsmProvider.Get(string)</code> <code>SsmProvider.Get&lt;T&gt;(string)</code> <code>ssm:GetParameter</code> SSM Parameter Store <code>SsmProvider.GetMultiple(string)</code> <code>SsmProvider.GetMultiple&lt;T&gt;(string)</code> <code>ssm:GetParametersByPath</code> SSM Parameter Store If using <code>WithDecryption()</code> option You must add an additional permission <code>kms:Decrypt</code> Secrets Manager <code>SecretsProvider.Get(string)</code> <code>SecretsProvider.Get&lt;T&gt;(string)</code> <code>secretsmanager:GetSecretValue</code> DynamoDB <code>DynamoDBProvider.Get(string)</code> <code>DynamoDBProvider.Get&lt;T&gt;(string)</code> <code>dynamodb:GetItem</code> DynamoDB <code>DynamoDBProvider.GetMultiple(string)</code> <code>DynamoDBProvider.GetMultiple&lt;T&gt;(string)</code> <code>dynamodb:Query</code> App Config <code>AppConfigProvider.Get()</code> <code>appconfig:StartConfigurationSession</code> <code>appconfig:GetLatestConfiguration</code>"
        },
        {
            "location": "utilities/parameters/#ssm-parameter-store",
            "title": "SSM Parameter Store",
            "text": "<p>You can retrieve a single parameter using <code>SsmProvider.Get()</code> and pass the key of the parameter. For multiple parameters, you can use <code>SsmProvider.GetMultiple()</code> and pass the path to retrieve them all.</p> <p>Alternatively, you can retrieve the instance of provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials.</p> SsmProviderSsmProvider with an explicit regionSsmProvider with a custom client <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SimpleSystemsManagement;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get SSM Provider instance\n        ISsmProvider ssmProvider = ParametersManager.SsmProvider;\n\n        // Retrieve a single parameter\n        string? value = await ssmProvider\n            .GetAsync(\"/my/parameter\")\n            .ConfigureAwait(false);\n\n        // Retrieve multiple parameters from a path prefix\n        // This returns a Dictionary with the parameter name as key\n        IDictionary&lt;string, string?&gt; values = await ssmProvider\n            .GetMultipleAsync(\"/my/path/prefix\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SimpleSystemsManagement;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get SSM Provider instance\n        ISsmProvider ssmProvider = ParametersManager.SsmProvider\n            .ConfigureClient(RegionEndpoint.EUCentral1);\n\n        // Retrieve a single parameter\n        string? value = await ssmProvider\n            .GetAsync(\"/my/parameter\")\n            .ConfigureAwait(false);\n\n        // Retrieve multiple parameters from a path prefix\n        // This returns a Dictionary with the parameter name as key\n        IDictionary&lt;string, string?&gt; values = await ssmProvider\n            .GetMultipleAsync(\"/my/path/prefix\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre> <pre><code>using Amazon.SimpleSystemsManagement;\nusing AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SimpleSystemsManagement;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Create a new instance of client\n        IAmazonSimpleSystemsManagement client = new AmazonSimpleSystemsManagementClient();\n\n        // Get SSM Provider instance\n        ISsmProvider ssmProvider = ParametersManager.SsmProvider\n            .UseClient(client);\n\n        // Retrieve a single parameter\n        string? value = await ssmProvider\n            .GetAsync(\"/my/parameter\")\n            .ConfigureAwait(false);\n\n        // Retrieve multiple parameters from a path prefix\n        // This returns a Dictionary with the parameter name as key\n        IDictionary&lt;string, string?&gt; values = await ssmProvider\n            .GetMultipleAsync(\"/my/path/prefix\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#additional-arguments",
            "title": "Additional arguments",
            "text": "<p>The AWS Systems Manager Parameter Store provider supports two additional arguments for the <code>Get()</code> and <code>GetMultiple()</code> methods:</p> Option Default Description WithDecryption() <code>False</code> Will automatically decrypt the parameter. Recursive() <code>False</code> For <code>GetMultiple()</code> only, will fetch all parameter values recursively based on a path prefix. <p>You can create <code>SecureString</code> parameters, which are parameters that have a plaintext parameter name and an encrypted parameter value. If you don't use the <code>WithDecryption()</code> option, you will get an encrypted value. Read here about best practices using KMS to secure your parameters.</p> <p>Example:</p> Function.cs <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SimpleSystemsManagement;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get SSM Provider instance\n        ISsmProvider ssmProvider = ParametersManager.SsmProvider;\n\n        // Retrieve a single parameter\n        string? value = await ssmProvider\n            .WithDecryption()\n            .GetAsync(\"/my/parameter\")\n            .ConfigureAwait(false);\n\n        // Retrieve multiple parameters from a path prefix\n        // This returns a Dictionary with the parameter name as key\n        IDictionary&lt;string, string?&gt; values = await ssmProvider\n            .Recursive()\n            .GetMultipleAsync(\"/my/path/prefix\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#secrets-manager",
            "title": "Secrets Manager",
            "text": "<p>For secrets stored in Secrets Manager, use <code>SecretsProvider</code>.</p> <p>Alternatively, you can retrieve the instance of provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials.</p> SecretsProviderSecretsProvider with an explicit regionSecretsProvider with a custom client <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SecretsManager;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get Secrets Provider instance\n        ISecretsProvider secretsProvider = ParametersManager.SecretsProvider;\n\n        // Retrieve a single secret\n        string? value = await secretsProvider\n            .GetAsync(\"/my/secret\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SecretsManager;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get Secrets Provider instance\n        ISecretsProvider secretsProvider = ParametersManager.SecretsProvider\n            .ConfigureClient(RegionEndpoint.EUCentral1);\n\n        // Retrieve a single secret\n        string? value = await secretsProvider\n            .GetAsync(\"/my/secret\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre> <pre><code>using Amazon.SecretsManager;\nusing AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SecretsManager;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n         // Create a new instance of client\n        IAmazonSecretsManager client = new AmazonSecretsManagerClient(); \n\n        // Get Secrets Provider instance\n        ISecretsProvider secretsProvider = ParametersManager.SecretsProvider\n            .UseClient(client);\n\n        // Retrieve a single secret\n        string? value = await secretsProvider\n            .GetAsync(\"/my/secret\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#dynamodb-provider",
            "title": "DynamoDB Provider",
            "text": "<p>For parameters stored in a DynamoDB table, use <code>DynamoDBProvider</code>.</p> <p>DynamoDB table structure for single parameters</p> <p>For single parameters, you must use <code>id</code> as the partition key for that table.</p> Example <p>DynamoDB table with <code>id</code> partition key and <code>value</code> as attribute</p> id value my-parameter my-value <p>With this table, <code>DynamoDBProvider.Get(\"my-param\")</code> will return <code>my-value</code>.</p> DynamoDBProvider <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.DynamoDB;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get DynamoDB Provider instance\n        IDynamoDBProvider dynamoDbProvider = ParametersManager.DynamoDBProvider\n            .UseTable(\"my-table\");\n\n        // Retrieve a single parameter\n        string? value = await dynamoDbProvider\n            .GetAsync(\"my-param\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre> <p>DynamoDB table structure for multiple values parameters</p> <p>You can retrieve multiple parameters sharing the same <code>id</code> by having a sort key named <code>sk</code>.</p> Example <p>DynamoDB table with <code>id</code> primary key, <code>sk</code> as sort key<code>and</code>value` as attribute</p> id sk value my-hash-key param-a my-value-a my-hash-key param-b my-value-b my-hash-key param-c my-value-c <p>With this table, <code>DynamoDBProvider.GetMultiple(\"my-hash-key\")</code> will return a dictionary response in the shape of <code>sk:value</code>.</p> DynamoDBProviderparameters dictionary response <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.DynamoDB;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get DynamoDB Provider instance\n        IDynamoDBProvider dynamoDbProvider = ParametersManager.DynamoDBProvider\n            .UseTable(\"my-table\");\n\n        // Retrieve a single parameter\n        IDictionary&lt;string, string?&gt; value = await dynamoDbProvider\n            .GetMultipleAsync(\"my-hash-key\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre> <pre><code>{\n    \"param-a\": \"my-value-a\",\n    \"param-b\": \"my-value-b\",\n    \"param-c\": \"my-value-c\"\n}\n</code></pre> <p>Customizing DynamoDBProvider</p> <p>DynamoDB provider can be customized at initialization to match your table structure:</p> Parameter Mandatory Default Description table_name Yes (N/A) Name of the DynamoDB table containing the parameter values. key_attr No <code>id</code> Hash key for the DynamoDB table. sort_attr No <code>sk</code> Range key for the DynamoDB table. You don't need to set this if you don't use the <code>GetMultiple()</code> method. value_attr No <code>value</code> Name of the attribute containing the parameter value. DynamoDBProvider <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.DynamoDB;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get DynamoDB Provider instance\n        IDynamoDBProvider dynamoDbProvider = ParametersManager.DynamoDBProvider\n            .UseTable\n            (\n                tableName: \"TableName\",    // DynamoDB table name, Required.\n                primaryKeyAttribute: \"id\", // Partition Key attribute name, optional, default is 'id'\n                sortKeyAttribute: \"sk\",    // Sort Key attribute name, optional, default is 'sk'\n                valueAttribute: \"value\"    // Value attribute name, optional, default is 'value'\n            );\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#app-configurations",
            "title": "App Configurations",
            "text": "<p>For application configurations in AWS AppConfig, use <code>AppConfigProvider</code>.</p> <p>Alternatively, you can retrieve the instance of provider and configure its underlying SDK client, in order to get data from other regions or use specific credentials.</p> AppConfigProviderAppConfigProvider with an explicit region <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.AppConfig;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get AppConfig Provider instance\n        IAppConfigProvider appConfigProvider = ParametersManager.AppConfigProvider\n            .DefaultApplication(\"MyApplicationId\")\n            .DefaultEnvironment(\"MyEnvironmentId\")\n            .DefaultConfigProfile(\"MyConfigProfileId\");\n\n        // Retrieve a single configuration, latest version\n        IDictionary&lt;string, string?&gt; value = await appConfigProvider\n            .GetAsync()\n            .ConfigureAwait(false);\n    }\n}\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.AppConfig;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get AppConfig Provider instance\n        IAppConfigProvider appConfigProvider = ParametersManager.AppConfigProvider\n            .ConfigureClient(RegionEndpoint.EUCentral1)\n            .DefaultApplication(\"MyApplicationId\")\n            .DefaultEnvironment(\"MyEnvironmentId\")\n            .DefaultConfigProfile(\"MyConfigProfileId\");\n\n        // Retrieve a single configuration, latest version\n        IDictionary&lt;string, string?&gt; value = await appConfigProvider\n            .GetAsync()\n            .ConfigureAwait(false);\n    }\n}\n</code></pre> <p>Using AWS AppConfig Feature Flags</p> <p>Feature flagging is a powerful tool that allows safely pushing out new features in a measured and usually gradual way. AppConfig provider offers helper methods to make it easier to work with feature flags.</p> AppConfigProvider <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.AppConfig;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get AppConfig Provider instance\n        IAppConfigProvider appConfigProvider = ParametersManager.AppConfigProvider\n            .DefaultApplication(\"MyApplicationId\")\n            .DefaultEnvironment(\"MyEnvironmentId\")\n            .DefaultConfigProfile(\"MyConfigProfileId\");\n\n        // Check if feature flag is enabled\n        var isFeatureFlagEnabled = await appConfigProvider\n            .IsFeatureFlagEnabledAsync(\"MyFeatureFlag\")\n            .ConfigureAwait(false);\n\n        if (isFeatureFlagEnabled)\n        {\n            // Retrieve an attribute value of the feature flag\n            var strAttValue = await appConfigProvider\n                .GetFeatureFlagAttributeValueAsync&lt;string&gt;(\"MyFeatureFlag\", \"StringAttribute\")\n                .ConfigureAwait(false);\n\n            // Retrieve another attribute value of the feature flag\n            var numberAttValue = await appConfigProvider\n                .GetFeatureFlagAttributeValueAsync&lt;int&gt;(\"MyFeatureFlag\", \"NumberAttribute\")\n                .ConfigureAwait(false);\n        }\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#advanced-configuration",
            "title": "Advanced configuration",
            "text": ""
        },
        {
            "location": "utilities/parameters/#caching",
            "title": "Caching",
            "text": "<p>By default, all parameters and their corresponding values are cached for 5 seconds.</p> <p>You can customize this default value using <code>DefaultMaxAge</code>. You can also customize this value for each parameter using  <code>WithMaxAge</code>.</p> <p>If you'd like to always ensure you fetch the latest parameter from the store regardless if already available in cache, use <code>ForceFetch</code>.</p> Provider with default Max ageProvider with age for each parameterForce to fetch the latest parameter <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SimpleSystemsManagement;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get SSM Provider instance\n        ISsmProvider ssmProvider = ParametersManager.SsmProvider\n            .DefaultMaxAge(TimeSpan.FromSeconds(10));\n\n        // Retrieve a single parameter\n        string? value = await ssmProvider\n            .GetAsync(\"/my/parameter\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SimpleSystemsManagement;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get SSM Provider instance\n        ISsmProvider ssmProvider = ParametersManager.SsmProvider;\n\n        // Retrieve a single parameter\n        string? value = await ssmProvider\n            .WithMaxAge(TimeSpan.FromSeconds(10))\n            .GetAsync(\"/my/parameter\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SimpleSystemsManagement;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get SSM Provider instance\n        ISsmProvider ssmProvider = ParametersManager.SsmProvider;\n\n        // Retrieve a single parameter\n        string? value = await ssmProvider\n            .ForceFetch()\n            .GetAsync(\"/my/parameter\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#transform-values",
            "title": "Transform values",
            "text": "<p>Parameter values can be transformed using <code>WithTransformation()</code>. Base64 and JSON transformations are provided. For more complex transformation, you need to specify how to deserialize by writing your own transfomer.</p> JSON TransformationBase64 Transformation <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SimpleSystemsManagement;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get SSM Provider instance\n        ISsmProvider ssmProvider = ParametersManager.SsmProvider;\n\n        // Retrieve a single parameter\n        var value = await ssmProvider\n            .WithTransformation(Transformation.Json)\n            .GetAsync&lt;MyObj&gt;(\"/my/parameter/json\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre> <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SimpleSystemsManagement;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get SSM Provider instance\n        ISsmProvider ssmProvider = ParametersManager.SsmProvider;\n\n        // Retrieve a single parameter\n        var value = await ssmProvider\n            .WithTransformation(Transformation.Base64)\n            .GetAsync(\"/my/parameter/b64\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#partial-transform-failures-with-getmultiple",
            "title": "Partial transform failures with <code>GetMultiple()</code>",
            "text": "<p>If you use <code>Transformation</code> with <code>GetMultiple()</code>, you can have a single malformed parameter value. To prevent failing the entire request, the method will return a <code>Null</code> value for the parameters that failed to transform.</p> <p>You can override this by using <code>RaiseTransformationError()</code>. If you do so, a single transform error will raise a <code>TransformationException</code> exception.</p> Function.cs <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SimpleSystemsManagement;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get SSM Provider instance\n        ISsmProvider ssmProvider = ParametersManager.SsmProvider\n            .RaiseTransformationError();\n\n        // Retrieve a single parameter\n        var value = await ssmProvider\n            .WithTransformation(Transformation.Json)\n            .GetAsync&lt;MyObj&gt;(\"/my/parameter/json\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#auto-transform-values-on-suffix",
            "title": "Auto-transform values on suffix",
            "text": "<p>If you use <code>Transformation</code> with <code>GetMultiple()</code>, you might want to retrieve and transform parameters encoded in different formats.</p> <p>You can do this with a single request by using <code>Transformation.Auto</code>. This will instruct any Parameter to to infer its type based on the suffix and transform it accordingly.</p> Function.cs <pre><code>using AWS.Lambda.Powertools.Parameters;\nusing AWS.Lambda.Powertools.Parameters.SimpleSystemsManagement;\n\npublic class Function\n{\n    public async Task&lt;APIGatewayProxyResponse&gt; FunctionHandler\n        (APIGatewayProxyRequest apigProxyEvent, ILambdaContext context)\n    {\n        // Get SSM Provider instance\n        ISsmProvider ssmProvider = ParametersManager.SsmProvider;\n\n        // Retrieve multiple parameters from a path prefix\n        // This returns a Dictionary with the parameter name as key\n        IDictionary&lt;string, object?&gt; values = await ssmProvider\n            .WithTransformation(Transformation.Auto)\n            .GetMultipleAsync(\"/param\")\n            .ConfigureAwait(false);\n    }\n}\n</code></pre> <p>For example, if you have two parameters with the following suffixes <code>.json</code> and <code>.binary</code>:</p> Parameter name Parameter value /param/a.json [some encoded value] /param/a.binary [some encoded value] <p>The return of <code>GetMultiple()</code> with <code>Transformation.Auto</code> will be a dictionary like:</p> <pre><code>{\n    \"a.json\": [some value],\n    \"b.binary\": [some value]\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#write-your-own-transformer",
            "title": "Write your own Transformer",
            "text": "<p>You can write your own transformer, by implementing the <code>ITransformer</code> interface and the <code>Transform&lt;T&gt;(string)</code> method. For example, if you wish to deserialize XML into an object.</p> XmlTransformer.csUsing XmlTransformerAdding XmlTransformer as transformer <pre><code>public class XmlTransformer : ITransformer\n{\n    public T? Transform&lt;T&gt;(string value)\n    {\n        if (string.IsNullOrEmpty(value))\n            return default;\n\n        var serializer = new XmlSerializer(typeof(T));\n        using var reader = new StringReader(value);\n        return (T?)serializer.Deserialize(reader);\n    }\n}\n</code></pre> <pre><code>    var value = await ssmProvider\n        .WithTransformation(new XmlTransformer())\n        .GetAsync&lt;MyObj&gt;(\"/my/parameter/xml\")\n        .ConfigureAwait(false);\n</code></pre> <pre><code>    // Get SSM Provider instance\n    ISsmProvider ssmProvider = ParametersManager.SsmProvider\n        .AddTransformer(\"XML\", new XmlTransformer());\n\n    // Retrieve a single parameter\n    var value = await ssmProvider\n        .WithTransformation(\"XML\")\n        .GetAsync&lt;MyObj&gt;(\"/my/parameter/xml\")\n        .ConfigureAwait(false);\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#fluent-api",
            "title": "Fluent API",
            "text": "<p>To simplify the use of the library, you can chain all method calls before a get.</p> Fluent API call <pre><code>    ssmProvider\n      .DefaultMaxAge(TimeSpan.FromSeconds(10))  // will set 10 seconds as the default cache TTL\n      .WithMaxAge(TimeSpan.FromMinutes(1))      // will set the cache TTL for this value at 1 minute\n      .WithTransformation(Transformation.Json)  // Will use JSON transfomer to deserializes JSON to an object\n      .WithDecryption()                         // enable decryption of the parameter value\n      .Get&lt;MyObj&gt;(\"/my/param\");                 // finally get the value\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#create-your-own-provider",
            "title": "Create your own provider",
            "text": "<p>You can create your own custom parameter provider by inheriting the <code>BaseProvider</code> class and implementing the <code>String getValue(String key)</code> method to retrieve data from your underlying store. All transformation and caching logic is handled by the get() methods in the base class.</p> Example implementation using S3 as a custom parameterUsing custom parameter store <pre><code>public class S3Provider : ParameterProvider\n{\n\n    private string _bucket;\n    private readonly IAmazonS3 _client;\n\n    public S3Provider()\n    {\n        _client = new AmazonS3Client();\n    }\n\n    public S3Provider(IAmazonS3 client)\n    {\n        _client = client;\n    }\n\n    public S3Provider WithBucket(string bucket)\n    {\n        _bucket = bucket;\n        return this;\n    }\n\n    protected override async Task&lt;string?&gt; GetAsync(string key, ParameterProviderConfiguration? config)\n    {\n        if (string.IsNullOrEmpty(key))\n            throw new ArgumentNullException(nameof(key));\n\n        if (string.IsNullOrEmpty(_bucket))\n            throw new ArgumentException(\"A bucket must be specified, using withBucket() method\");\n\n        var request = new GetObjectRequest\n        {\n            Key = key,\n            BucketName = _bucket\n        };\n\n        using var response = await _client.GetObjectAsync(request);\n        await using var responseStream = response.ResponseStream;\n        using var reader = new StreamReader(responseStream);\n        return await reader.ReadToEndAsync();\n    }\n\n     protected override async Task&lt;IDictionary&lt;string, string?&gt;&gt; GetMultipleAsync(string path, ParameterProviderConfiguration? config)\n    {\n        if (string.IsNullOrEmpty(path))\n            throw new ArgumentNullException(nameof(path));\n\n        if (string.IsNullOrEmpty(_bucket))\n            throw new ArgumentException(\"A bucket must be specified, using withBucket() method\");\n\n        var request = new ListObjectsV2Request\n        {\n            Prefix = path,\n            BucketName = _bucket\n        };\n        var response = await _client.ListObjectsV2Async(request);\n\n        var result = new Dictionary&lt;string, string?&gt;();\n        foreach (var s3Object in response.S3Objects)\n        {\n            var value = await GetAsync(s3Object.Key);\n            result.Add(s3Object.Key, value);\n        }\n\n        return result;\n    }\n}\n</code></pre> <pre><code>    var provider = new S3Provider();\n\n    var value = await provider\n        .WithBucket(\"myBucket\")\n        .GetAsync(\"myKey\")\n        .ConfigureAwait(false);\n</code></pre>"
        }
    ]
}