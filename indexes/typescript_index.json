{
    "config":
    {
        "lang":
        [
            "en"
        ],
        "separator": "[\\s\\-]+",
        "pipeline":
        [
            "stopWordFilter"
        ]
    },
    "docs":
    [
        {
            "location": "",
            "title": "Homepage",
            "text": "<p>Powertools for AWS Lambda (TypeScript) is a developer toolkit to implement Serverless best practices and increase developer velocity.</p> <p>You can use Powertools for AWS Lambda in both TypeScript and JavaScript code bases.</p> <ul> <li> <p> Features</p> <p>Adopt one, a few, or all industry practices. Progressively.</p> <p> All features</p> </li> <li> <p> Support this project</p> <p>Become a public reference customer, share your work, contribute, use Lambda Layers, etc.</p> <p> Support</p> </li> <li> <p> Available languages</p> <p>Powertools for AWS Lambda is also available in other languages</p> <p> Python, Java, and .NET</p> </li> </ul>"
        },
        {
            "location": "#install",
            "title": "Install",
            "text": "<p>You can use Powertools for AWS Lambda (TypeScript) by installing it with your favorite dependency management, or via Lambda Layers:</p> npmjs.comLambda LayerLayer in GovCloud <p>All features are available as individual packages, so you can install only the ones you need, for example:</p> <ul> <li>Logger: <code>npm i @aws-lambda-powertools/logger</code></li> <li>Metrics: <code>npm i @aws-lambda-powertools/metrics</code></li> <li>Tracer: <code>npm i @aws-lambda-powertools/tracer</code></li> </ul> <p>You can add our layer both in the AWS Lambda Console (under <code>Layers</code>), or via your favorite infrastructure as code framework with the ARN value.</p> <p>For the latter, make sure to replace <code>{region}</code> with your AWS region, e.g., <code>eu-west-1</code>.</p> <p>arn:aws:lambda:{region}:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24</p> Code snippets for popular infrastructure as code frameworks CDKSAMServerless frameworkTerraformPulumiAmplify <pre><code>import { Stack } from 'aws-cdk-lib';\nimport { Construct } from 'constructs';\nimport { LayerVersion, Function, Runtime, Code } from 'aws-cdk-lib/aws-lambda';\nimport { NodejsFunction } from 'aws-cdk-lib/aws-lambda-nodejs';\n\nexport class SampleFunctionWithLayer extends Construct {\n  constructor(scope: Construct, id: string) {\n    super(scope, id);\n\n    // Create a Layer with Powertools for AWS Lambda (TypeScript)\n    const powertoolsLayer = LayerVersion.fromLayerVersionArn(\n      this,\n      'PowertoolsLayer',\n      `arn:aws:lambda:${Stack.of(this).region}:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24`\n    );\n\n    new Function(this, 'Function', {\n      runtime: Runtime.NODEJS_22_X,\n      // Add the Layer to a Lambda function\n      layers: [powertoolsLayer],\n      code: Code.fromInline(`...`),\n      handler: 'index.handler',\n    });\n  }\n}\n</code></pre> <p>If you use <code>esbuild</code> to bundle your code, make sure to exclude <code>@aws-lambda-powertools/*</code> and <code>@aws-sdk/*</code> from being bundled since the packages are already present the layer:</p> <pre><code>new NodejsFunction(this, 'Function', {\n  ...\n  bundling: {\n    externalModules: [\n      '@aws-lambda-powertools/*',\n      '@aws-sdk/*',\n    ],\n  }\n});\n</code></pre> <p>Check the documentation for more details.</p> <pre><code>MyLambdaFunction:\n  Type: AWS::Serverless::Function\n    Properties:\n      Layers:\n        - !Sub arn:aws:lambda:${AWS::Region}:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24\n</code></pre> <p>You can also use AWS SSM Parameter Store to dynamically add Powertools for AWS Lambda. The <code>{version}</code> placeholder is the semantic version number (e,g. 2.1.0) for a release or <code>_latest_</code>.</p> <pre><code>MyLambdaFunction:\n  Type: AWS::Serverless::Function\n    Properties:\n      Layers:\n        - {{resolve:ssm:/aws/service/powertools/typescript/generic/all/{version}}}\n</code></pre> <p>If you use <code>esbuild</code> to bundle your code, make sure to exclude <code>@aws-lambda-powertools/*</code> and <code>@aws-sdk/*</code> from being bundled since the packages are already present the layer:</p> <pre><code>MyLambdaFunction:\n  Type: AWS::Serverless::Function\n  Properties:\n    ...\n    Metadata: \n      # Manage esbuild properties\n      BuildMethod: esbuild\n      BuildProperties:\n      Minify: true\n      External:\n        - '@aws-lambda-powertools/*'\n        - '@aws-sdk/*'\n</code></pre> <p>Check the documentation for more details.</p> <pre><code>functions:\n  hello:\n    handler: lambda_function.lambda_handler\n    layers:\n      - arn:aws:lambda:${aws:region}:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24\n</code></pre> <p>If you use <code>esbuild</code> to bundle your code, make sure to exclude <code>@aws-lambda-powertools/*</code> and <code>@aws-sdk/*</code> from being bundled since the packages are already present the layer:</p> <pre><code>custom:\n  esbuild:\n    external:\n      - '@aws-lambda-powertools/*'\n      - '@aws-sdk/*'\n</code></pre> <p>Check the documentation for more details.</p> <pre><code>terraform {\n  required_version = \"~&gt; 1.0.5\"\n  required_providers {\n    aws = \"~&gt; 3.50.0\"\n  }\n}\n\nprovider \"aws\" {\n  region  = \"{aws::region}\"\n}\n\nresource \"aws_lambda_function\" \"test_lambda\" {\n  filename      = \"lambda_function_payload.zip\"\n  function_name = \"lambda_function_name\"\n  role          = ...\n  handler       = \"index.handler\"\n  runtime       = \"nodejs22.x\"\n  layers        = [\"arn:aws:lambda:{aws::region}:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24\"]\n  source_code_hash = filebase64sha256(\"lambda_function_payload.zip\")\n}\n</code></pre> <p>You can use data sources to resolve the SSM Parameter Store in your code, allowing you to pin to <code>_latest_</code> or a specific Powertools for AWS Lambda version.</p> <pre><code>  data \"aws_ssm_parameter\" \"powertools_version\" {\n    # Replace {version} with your chosen Powertools for AWS Lambda version or latest\n    name = \"/aws/service/powertools/python/generic/all/{version}\"\n  }\n\n  resource \"aws_lambda_function\" \"test_lambda\" {\n    ...\n\n    runtime = \"nodejs22.x\"\n\n    layers = [data.aws_ssm_parameter.powertools_version.value]\n  }\n</code></pre> <pre><code>import * as pulumi from '@pulumi/pulumi';\nimport * as aws from '@pulumi/aws';\n\nconst role = new aws.iam.Role('role', {\n    assumeRolePolicy: aws.iam.assumeRolePolicyForPrincipal(aws.iam.Principals.LambdaPrincipal),\n    managedPolicyArns: [aws.iam.ManagedPolicies.AWSLambdaBasicExecutionRole]\n});\n\nconst lambdaFunction = new aws.lambda.Function('function', {\n    layers: [\n        pulumi.interpolate`arn:aws:lambda:${aws.getRegionOutput().name}:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24`\n    ],\n    code: new pulumi.asset.FileArchive('lambda_function_payload.zip'),\n    tracingConfig: {\n        mode: 'Active'\n    },\n    runtime: aws.lambda.Runtime.NodeJS22dX,\n    handler: 'index.handler',\n    role: role.arn,\n    architectures: ['x86_64']\n});\n</code></pre> <p>Remember to replace the region with your AWS region, e.g., <code>eu-west-1</code>. Amplify Gen 2 currently does not support obtaining the region dynamically.</p> <pre><code>import { defineFunction } from \"@aws-amplify/backend\";\n\nexport const myFunction = defineFunction({\n  name: \"my-function\",\n  layers: {\n    \"@aws-lambda-powertools/*\":\n      \"arn:aws:lambda:${AWS::Region}:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24\",\n  },\n});\n</code></pre> <p>We also provide layers in two GovCloud regions:</p> <ul> <li>arn:aws-us-gov:lambda:us-gov-east-1:165087284144:layer:AWSLambdaPowertoolsTypeScriptV2:24</li> <li>arn:aws-us-gov:lambda:us-gov-west-1:165093116878:layer:AWSLambdaPowertoolsTypeScriptV2:24</li> </ul>"
        },
        {
            "location": "#extra-dependencies",
            "title": "Extra dependencies",
            "text": "<p>Some features use additional dependencies like the AWS SDK for JavaScript v3, which might you need to install separately if you are using any of the features below:</p> Feature Install Default dependency Tracer <code>npm i @aws-lambda-powertools/tracer</code> <code>aws-xray-sdk-core</code> Idempotency <code>npm i @aws-lambda-powertools/idempotency @aws-sdk/client-dynamodb @aws-sdk/lib-dynamodb</code> Parameters (SSM) <code>npm i @aws-lambda-powertools/parameters @aws-sdk/client-ssm</code> Parameters (Secrets Manager) <code>npm i @aws-lambda-powertools/parameters @aws-sdk/client-secrets-manager</code> Parameters (AppConfig) <code>npm i @aws-lambda-powertools/parameters @aws-sdk/client-appconfigdata</code> Parser <code>npm i @aws-lambda-powertools/parser zod@~3</code>"
        },
        {
            "location": "#lambda-layer",
            "title": "Lambda Layer",
            "text": "<p>Lambda Layer is a <code>.zip</code> file archive that can contain additional code, pre-packaged dependencies, data, or configuration files. We compile and optimize all dependencies to achieve an optimal build.</p> <p>You can use the Lambda Layer both with CommonJS and ESM (ECMAScript modules) for Node.js 18.x and newer runtimes.</p> Click to expand and copy any regional Lambda Layer ARN Region Layer ARN <code>us-east-1</code> arn:aws:lambda:us-east-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>us-east-2</code> arn:aws:lambda:us-east-2:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>us-west-1</code> arn:aws:lambda:us-west-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>us-west-2</code> arn:aws:lambda:us-west-2:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ap-south-1</code> arn:aws:lambda:ap-south-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ap-south-2</code> arn:aws:lambda:ap-south-2:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ap-east-1</code> arn:aws:lambda:ap-east-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ap-northeast-1</code> arn:aws:lambda:ap-northeast-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ap-northeast-2</code> arn:aws:lambda:ap-northeast-2:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ap-northeast-3</code> arn:aws:lambda:ap-northeast-3:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ap-southeast-1</code> arn:aws:lambda:ap-southeast-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ap-southeast-2</code> arn:aws:lambda:ap-southeast-2:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ap-southeast-3</code> arn:aws:lambda:ap-southeast-3:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ap-southeast-4</code> arn:aws:lambda:ap-southeast-4:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ap-southeast-5</code> arn:aws:lambda:ap-southeast-5:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ap-southeast-7</code> arn:aws:lambda:ap-southeast-7:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>eu-central-1</code> arn:aws:lambda:eu-central-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>eu-central-2</code> arn:aws:lambda:eu-central-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>eu-west-1</code> arn:aws:lambda:eu-west-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>eu-west-2</code> arn:aws:lambda:eu-west-2:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>eu-west-3</code> arn:aws:lambda:eu-west-3:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>eu-north-1</code> arn:aws:lambda:eu-north-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>eu-south-1</code> arn:aws:lambda:eu-south-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>eu-south-2</code> arn:aws:lambda:eu-south-2:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ca-central-1</code> arn:aws:lambda:ca-central-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>ca-west-1</code> arn:aws:lambda:ca-west-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>sa-east-1</code> arn:aws:lambda:sa-east-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>af-south-1</code> arn:aws:lambda:af-south-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>me-south-1</code> arn:aws:lambda:me-south-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>me-central-1</code> arn:aws:lambda:me-central-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>il-central-1</code> arn:aws:lambda:il-central-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <code>mx-central-1</code> arn:aws:lambda:mx-central-1:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 <p>Want to inspect the contents of the Layer?</p> <p>The pre-signed URL to download this Lambda Layer will be within <code>Location</code> key in the CLI output. The CLI output will also contain the Powertools for AWS Lambda version it contains.</p> <p>Change <code>{aws::region}</code> to your AWS region, e.g. <code>eu-west-1</code>, and run the following command:</p> AWS CLI command to download Lambda Layer content<pre><code>aws lambda get-layer-version-by-arn --arn arn:aws:lambda:{aws::region}:094274105915:layer:AWSLambdaPowertoolsTypeScriptV2:24 --region {aws::region}\n</code></pre>"
        },
        {
            "location": "#instrumentation",
            "title": "Instrumentation",
            "text": "<p>Many of the utilities provided by Powertools for AWS Lambda (TypeScript) can be used with different programming paradigms:</p> <ul> <li>Middy middleware. It is the best choice if your existing code base relies on the Middy.js middleware engine. Powertools for AWS Lambda (TypeScript) offers compatible Middy middleware to make this integration seamless.</li> <li>Method decorator. Use TypeScript method decorators if you prefer writing your business logic using TypeScript Classes. If you aren’t using Classes, this requires the most significant refactoring.</li> <li>Manually. It provides the most granular control. It’s the most verbose approach, with the added benefit of no additional dependency and no refactoring to TypeScript Classes.</li> </ul> <p>The examples in this documentation will feature all the approaches described above wherever applicable.</p>"
        },
        {
            "location": "#examples",
            "title": "Examples",
            "text": "<p>You can find examples of how to use Powertools for AWS Lambda (TypeScript) in the examples directory. The application is a simple REST API that can be deployed via either AWS CDK or AWS SAM.</p> <p>If instead you want to see Powertools for AWS Lambda (TypeScript) in slightly different use cases, check the Serverless TypeScript Demo or the AWS Lambda performance tuning repository. Both demos use Powertools for AWS Lambda (TypeScript) as well as demonstrating other common techniques for Lambda functions written in TypeScript.</p>"
        },
        {
            "location": "#features",
            "title": "Features",
            "text": "<p>Core utilities such as Tracing, Logging, and Metrics will be available across all Powertools for AWS Lambda languages. Additional utilities are subjective to each language ecosystem and customer demand.</p> Utility Description Tracer Decorators and utilities to trace Lambda function handlers, and both synchronous and asynchronous functions Logger Structured logging made easier, and a middleware to enrich structured logging with key Lambda context details Metrics Custom Metrics created asynchronously via CloudWatch Embedded Metric Format (EMF) Parameters High-level functions to retrieve one or more parameters from AWS SSM Parameter Store, AWS Secrets Manager, AWS AppConfig, and Amazon DynamoDB Idempotency Class method decorator, Middy middleware, and function wrapper to make your Lambda functions idempotent and prevent duplicate execution based on payload content. Batch Processing Utility to handle partial failures when processing batches from Amazon SQS, Amazon Kinesis Data Streams, and Amazon DynamoDB Streams. Parser Utility to parse and validate AWS Lambda event payloads using Zod, a TypeScript-first schema declaration and validation library."
        },
        {
            "location": "#environment-variables",
            "title": "Environment variables",
            "text": "Info <p>Explicit parameters take precedence over environment variables</p> Environment variable Description Utility Default POWERTOOLS_SERVICE_NAME Set service name used for tracing namespace, metrics dimension and structured logging All <code>service_undefined</code> POWERTOOLS_METRICS_NAMESPACE Set namespace used for metrics Metrics <code>default_namespace</code> POWERTOOLS_METRICS_FUNCTION_NAME Function name used as dimension for the <code>ColdStart</code> metric Metrics See docs POWERTOOLS_METRICS_ENABLED Explicitly disables emitting metrics to stdout Metrics <code>true</code> POWERTOOLS_TRACE_ENABLED Explicitly disables tracing Tracer <code>true</code> POWERTOOLS_TRACER_CAPTURE_RESPONSE Capture Lambda or method return as metadata. Tracer <code>true</code> POWERTOOLS_TRACER_CAPTURE_ERROR Capture Lambda or method exception as metadata. Tracer <code>true</code> POWERTOOLS_TRACER_CAPTURE_HTTPS_REQUESTS Capture HTTP(s) requests as segments. Tracer <code>true</code> POWERTOOLS_LOGGER_LOG_EVENT Log incoming event Logger <code>false</code> POWERTOOLS_LOGGER_SAMPLE_RATE Debug log sampling Logger <code>0</code> POWERTOOLS_DEV Pretty-print logs, disable metrics flushing, and disable traces - use for dev only See section below <code>false</code> POWERTOOLS_LOG_LEVEL Sets how verbose Logger should be, from the most verbose to the least verbose (no logs) Logger <code>INFO</code> POWERTOOLS_PARAMETERS_MAX_AGE Adjust how long values are kept in cache (in seconds) Parameters <code>5</code> POWERTOOLS_PARAMETERS_SSM_DECRYPT Set whether to decrypt or not values retrieved from AWS Systems Manager Parameters Store Parameters <code>false</code> POWERTOOLS_IDEMPOTENCY_DISABLED Disable the Idempotency logic without changing your code, useful for testing Idempotency <code>false</code> <p>Each Utility page provides information on example values and allowed values.</p>"
        },
        {
            "location": "#optimizing-for-non-production-environments",
            "title": "Optimizing for non-production environments",
            "text": "<p>Whether you're prototyping locally or against a non-production environment, you can use <code>POWERTOOLS_DEV</code> to increase verbosity across multiple utilities.</p> <p>When <code>POWERTOOLS_DEV</code> is set to a truthy value (<code>1</code>, <code>true</code>), it'll have the following effects:</p> Utility Effect Logger Increase JSON indentation to 4 and uses global <code>console</code> to emit logs to ease testing and local debugging when running functions locally. However, Amazon CloudWatch Logs view will degrade as each new line is treated as a new message Tracer Disables tracing operations in non-Lambda environments. This already happens automatically in the Tracer utility Metrics Disables emitting metrics to stdout. Can be overridden by setting <code>POWERTOOLS_METRICS_ENABLED</code> to <code>true</code>"
        },
        {
            "location": "#support-powertools-for-aws-lambda-typescript",
            "title": "Support Powertools for AWS Lambda (TypeScript)",
            "text": "<p>There are many ways you can help us gain future investments to improve everyone's experience:</p> <ul> <li> <p> Become a public reference</p> <p>Add your company name and logo on our landing page, documentation, and README files.</p> <p> GitHub Issue template</p> </li> <li> <p> Share your work</p> <p>Blog posts, video, and sample projects about Powertools for AWS Lambda.</p> <p> GitHub Issue template</p> </li> <li> <p> Join the community</p> <p>Connect, ask questions, and share what features you use.</p> <p> Discord invite</p> </li> </ul>"
        },
        {
            "location": "#becoming-a-reference-customer",
            "title": "Becoming a reference customer",
            "text": "<p>Knowing which companies are using this library is important to help prioritize the project internally. The following companies, among others, use Powertools:</p> <p>Alma Media</p> <p>AppYourself</p> <p>Bailey Nelson</p> <p>Banxware</p> <p>Caylent</p> <p>Certible</p> <p>Elva</p> <p>Flyweight</p> <p>globaldatanet</p> <p>Guild</p> <p>Hashnode</p> <p>LocalStack</p> <p>Perfect Post</p> <p>Sennder</p> <p>tecRacer GmbH &amp; Co. KG</p> <p>Trek10</p> <p>WeSchool</p>"
        },
        {
            "location": "#using-lambda-layers",
            "title": "Using Lambda Layers",
            "text": "<p>Layers help us understand who uses Powertools for AWS Lambda (TypeScript) in a non-intrusive way.</p> <p>When using Layers, you can add Powertools for AWS Lambda (TypeScript) as a dev dependency to not impact the development process. For Layers, we pre-package all dependencies, compile and optimize for storage.</p>"
        },
        {
            "location": "#tenets",
            "title": "Tenets",
            "text": "<p>These are our core principles to guide our decision making.</p> <ul> <li>AWS Lambda only. We optimise for AWS Lambda function environments and supported runtimes only. Utilities might work with web frameworks and non-Lambda environments, though they are not officially supported.</li> <li>Eases the adoption of best practices. The main priority of the utilities is to facilitate best practices adoption, as defined in the AWS Well-Architected Serverless Lens; all other functionality is optional.</li> <li>Keep it lean. Additional dependencies are carefully considered for security and ease of maintenance, and prevent negatively impacting startup time.</li> <li>We strive for backwards compatibility. New features and changes should keep backwards compatibility. If a breaking change cannot be avoided, the deprecation and migration process should be clearly defined.</li> <li>We work backwards from the community. We aim to strike a balance of what would work best for 80% of customers. Emerging practices are considered and discussed via Requests for Comment (RFCs)</li> <li>Progressive. Utilities are designed to be incrementally adoptable for customers at any stage of their Serverless journey. They follow language idioms and their community’s common practices.</li> </ul>"
        },
        {
            "location": "changelog/",
            "title": "Change Log",
            "text": "<p>All notable changes to this project will be documented in this file. See Conventional Commits for commit guidelines.</p>"
        },
        {
            "location": "changelog/#2180-2025-04-07",
            "title": "2.18.0 (2025-04-07)",
            "text": ""
        },
        {
            "location": "changelog/#features",
            "title": "Features",
            "text": "<ul> <li>parser: add Cognito pre-signup trigger schema (#3729) (4116f65)</li> <li>parser: add schema support for API Gateway WebSocket events (#3807) (663d328)</li> </ul>"
        },
        {
            "location": "changelog/#2170-2025-03-25",
            "title": "2.17.0 (2025-03-25)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: Remove --compatible-architectures from workflow (#3752) (dafa496)</li> <li>idempotency: include sk in error msgs when using composite key (#3709) (661f5ff)</li> <li>logger: correctly refresh sample rate (#3722) (2692ca4)</li> <li>parser: ddb base schema + other exports (#3741) (51a3410)</li> </ul>"
        },
        {
            "location": "changelog/#features_1",
            "title": "Features",
            "text": "<ul> <li>commons: make utilities aware of provisioned concurrency (#3724) (c28e45e)</li> <li>logger: set correlation ID in logs (#3726) (aa74fc8)</li> <li>metrics: allow setting functionName via constructor parameter and environment variable (#3696) (3176fa0)</li> </ul>"
        },
        {
            "location": "changelog/#2160-2025-03-07",
            "title": "2.16.0 (2025-03-07)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_1",
            "title": "Bug Fixes",
            "text": "<ul> <li>batch: clear message group references after request (#3674) (270115e)</li> <li>ci: Update layer balance scripts (#3660) (aa14637)</li> <li>parser: envelope sub-path exports regression (#3667) (beac102)</li> <li>parser: update S3 Event Schema (#3671) (c14c7b3)</li> </ul>"
        },
        {
            "location": "changelog/#features_2",
            "title": "Features",
            "text": "<ul> <li>logger: Enable log buffering feature (#3641) (8203016)</li> <li>logger: flush buffer on uncaught error decorator (#3676) (28db2e3)</li> <li>logger: Flush buffer on uncaught error in Middy middleware (#3690) (23eebe4)</li> <li>logger: refresh sample rate calculation before each invocation (#3672) (8c8d6b2)</li> <li>validation: add @validator decorator for JSON Schema validation (#3679) (ae6b7cf)</li> <li>validation: Add Middy.js middleware for JSON Schema validation (#3694) (443202b)</li> <li>validation: implement validate function (#3662) (f55127b)</li> </ul>"
        },
        {
            "location": "changelog/#2150-2025-02-25",
            "title": "2.15.0 (2025-02-25)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_2",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: Add permissions to jobs (#3586) (90c93ea)</li> <li>ci: fix path for latest SSM param (#3585) (e34952d)</li> <li>logger: handle illegal <code>null</code>/<code>undefined</code> as extra args (#3614) (6f99073)</li> </ul>"
        },
        {
            "location": "changelog/#features_3",
            "title": "Features",
            "text": "<ul> <li>idempotency: add support for custom key prefix (#3532) (7be7a83)</li> <li>logger: add circular buffer (#3593) (618cdee)</li> <li>logger: Add log buffer and flush method (#3617) (6968ca8)</li> <li>logger: Emit a warning on buffer flush (#3639) (f471552)</li> <li>logger: refresh sample rate calculation per invocation (#3644) (1d66a2a)</li> <li>parser: provide sub-path exports (#3598) (09f0aaa)</li> </ul>"
        },
        {
            "location": "changelog/#2140-2025-02-10",
            "title": "2.14.0 (2025-02-10)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_3",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: prevent overwriting standard keys (#3553) (f0bdf3c)</li> <li>parser: parse sqs record body field as JSON and S3Schema in S3SqsEventNoificationRecordSchema (#3529) (bcd4b9f)</li> </ul>"
        },
        {
            "location": "changelog/#features_4",
            "title": "Features",
            "text": "<ul> <li>ci: Add advanced automation (#3438) (4e9ff07)</li> <li>parser: add TransferFamilySchema for AWS Transfer Family events (#3575) (2c27c5e)</li> <li>parser: simplify <code>ParseResult</code> and <code>parse</code> inference (#3568) (95762ad)</li> </ul>"
        },
        {
            "location": "changelog/#2131-2025-01-28",
            "title": "2.13.1 (2025-01-28)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_4",
            "title": "Bug Fixes",
            "text": "<ul> <li>parser: allow Kinesis envelopes to handle non-JSON strings (#3531) (d18e03d)</li> <li>parser: allow SQS envelopes to handle non-JSON strings (#3513) (89f0006)</li> <li>parser: allow VPC envelopes to handle non-JSON strings (#3534) (603988d)</li> <li>parser: API Gateway Envelopes handle non-JSON (#3511) (a4846af)</li> <li>parser: CloudWatch Log Envelope handles non-JSON (#3505) (781a14e)</li> <li>parser: DynamoDBStream schema &amp; envelope (#3482) (7f7f8ce)</li> <li>parser: EventBridge envelope uses correct path (#3504) (7cce60b)</li> <li>parser: Firehose SQS should fail for invalid SQS message (#3526) (4721dda)</li> <li>parser: Kafka Envelope + tests (#3489) (bd6b24a)</li> <li>parser: LambdaFunctionUrl envelope assumes JSON string in body (#3514) (09aa287)</li> <li>parser: make identitySource nulablel in APIGatewayRequestAuthorizerEventV2Schema (#3485) (8692de6)</li> <li>parser: min array length on Records (#3521) (89a6281)</li> <li>parser: set min length of 1 to s3 event lists (#3524) (937be64)</li> <li>parser: SNS Envelope handles non-JSON (#3506) (4d7f05f)</li> </ul>"
        },
        {
            "location": "changelog/#2130-2025-01-14",
            "title": "2.13.0 (2025-01-14)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_5",
            "title": "Bug Fixes",
            "text": "<ul> <li>tracer: forward <code>X-Amzn-Trace-Id</code> header when instrumenting fetch (#3470) (4eb3e2d)</li> </ul>"
        },
        {
            "location": "changelog/#features_5",
            "title": "Features",
            "text": "<ul> <li>parser: <code>DynamoDBMarshalled</code> helper to parse DynamoDB data structure (#3442) (e154e58)</li> </ul>"
        },
        {
            "location": "changelog/#2120-2024-12-17",
            "title": "2.12.0 (2024-12-17)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_6",
            "title": "Bug Fixes",
            "text": "<ul> <li>parser: make SNS subject field nullish (#3415) (0da9cea)</li> </ul>"
        },
        {
            "location": "changelog/#features_6",
            "title": "Features",
            "text": "<ul> <li>logger: change selected method visibility to protected (#3377) (93a19a5)</li> <li>metrics: disable metrics with <code>POWERTOOLS_METRICS_DISABLED</code> (#3351) (7e8578e)</li> <li>metrics: warn when overwriting dimension (#3352) (12f3e44)</li> <li>parser: Add appsync resolver event Zod schemas (#3301) (318f34b)</li> <li>parser: add schema for DynamoDB - Kinesis Stream event (#3328) (a8dfa74)</li> </ul>"
        },
        {
            "location": "changelog/#2110-2024-11-20",
            "title": "2.11.0 (2024-11-20)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_7",
            "title": "Bug Fixes",
            "text": "<ul> <li>metrics: skip empty string dimension values (#3319) (924d49d)</li> <li>parser: add aws region to kinesis event (#3260) (246f132)</li> <li>parser: event type literal for selfManagedKafka (#3325) (5350afe)</li> <li>parser: fix cause errors nested structure (#3250) (1ff97cb)</li> </ul>"
        },
        {
            "location": "changelog/#features_7",
            "title": "Features",
            "text": "<ul> <li>batch: Async Processing of Records for for SQS Fifo (#3160) (e73b575)</li> <li>metrics: ability to set custom timestamp with <code>setTimestamp</code> for metrics (#3310) (0fb94c3)</li> <li>metrics: add ability to pass custom logger (#3057) (a531b90)</li> </ul>"
        },
        {
            "location": "changelog/#2100-2024-10-22",
            "title": "2.10.0 (2024-10-22)",
            "text": ""
        },
        {
            "location": "changelog/#features_8",
            "title": "Features",
            "text": "<ul> <li>logger: include enumerable properties in formatted errors (#3195) (4b80d9f)</li> </ul>"
        },
        {
            "location": "changelog/#290-2024-10-07",
            "title": "2.9.0 (2024-10-07)",
            "text": ""
        },
        {
            "location": "changelog/#features_9",
            "title": "Features",
            "text": "<ul> <li>batch: sequential async processing of records for <code>BatchProcessor</code> (#3109) (e31279a)</li> <li>idempotency: ability to specify JMESPath custom functions (#3150) (869b6fc)</li> <li>idempotency: manipulate idempotent response via response hook (#3071) (f7c1769)</li> </ul>"
        },
        {
            "location": "changelog/#280-2024-09-16",
            "title": "2.8.0 (2024-09-16)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_8",
            "title": "Bug Fixes",
            "text": "<ul> <li>idempotency: include cause in idempotency persistence layer error (#2916) (47f0161)</li> <li>tracer: include request pathname in trace data (#2955) (6864e53)</li> </ul>"
        },
        {
            "location": "changelog/#features_10",
            "title": "Features",
            "text": "<ul> <li>logger: introduce log key reordering functionality (#2736) (9677258)</li> <li>logger: introduce loglevel trace #1589 (#2902) (650252c)</li> <li>parameters: adds setParameter function to store SSM parameters (#3020) (8fd5479)</li> </ul>"
        },
        {
            "location": "changelog/#270-2024-08-08",
            "title": "2.7.0 (2024-08-08)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_9",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: invalid time zone environment variables leads to error (#2865) (d55465f)</li> </ul>"
        },
        {
            "location": "changelog/#features_11",
            "title": "Features",
            "text": "<ul> <li>metrics: add unit None for CloudWatch EMF Metrics (#2904) (fa27cba)</li> <li>parser: add helper function to handle JSON stringified fields (#2901) (806b884)</li> </ul>"
        },
        {
            "location": "changelog/#260-2024-07-25",
            "title": "2.6.0 (2024-07-25)",
            "text": ""
        },
        {
            "location": "changelog/#features_12",
            "title": "Features",
            "text": "<ul> <li>logger: introduce loglevel constant (#2787) (e75f593)</li> <li>parser: allow parser set event type of handler with middy (#2786) (9973f09)</li> </ul>"
        },
        {
            "location": "changelog/#250-2024-07-15",
            "title": "2.5.0 (2024-07-15)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_10",
            "title": "Bug Fixes",
            "text": "<ul> <li>parser: include error cause in ParseError (#2774) (34d0b55)</li> </ul>"
        },
        {
            "location": "changelog/#features_13",
            "title": "Features",
            "text": "<ul> <li>logger: custom function for unserializable values (JSON replacer)  (#2739) (fbc8688)</li> </ul>"
        },
        {
            "location": "changelog/#240-2024-07-10",
            "title": "2.4.0 (2024-07-10)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_11",
            "title": "Bug Fixes",
            "text": "<ul> <li>idempotency: check error identity via names (#2747) (55c3878)</li> </ul>"
        },
        {
            "location": "changelog/#features_14",
            "title": "Features",
            "text": "<ul> <li>batch: add option to not throw <code>FullBatchFailureError</code> when the entire batch fails (#2711) (74198ef)</li> <li>internal: support Middy.js 5.x (#2748) (1d7ad61)</li> <li>layers: deploy Lambda layers in <code>ap-south-2</code> and <code>me-central-1</code> (#2675) (208c57a)</li> <li>logger: time zone aware timestamp in Logger (#2710) (9fe4c75)</li> <li>maintenance: drop support for Node.js 16.x (#2717) (e4eee73)</li> </ul>"
        },
        {
            "location": "changelog/#230-2024-06-27",
            "title": "2.3.0 (2024-06-27)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_12",
            "title": "Bug Fixes",
            "text": "<ul> <li>idempotency: preserve scope of decorated class (#2693) (22ec1f0)</li> <li>logger: reset log level after sampling refresh (#2673) (618faec)</li> </ul>"
        },
        {
            "location": "changelog/#features_15",
            "title": "Features",
            "text": "<ul> <li>logger: add <code>clearState()</code> method (#2408) (f55e2d0)</li> <li>parser: enhance API Gateway schemas (#2665) (b3bc1f0)</li> </ul>"
        },
        {
            "location": "changelog/#220-2024-06-13",
            "title": "2.2.0 (2024-06-13)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_13",
            "title": "Bug Fixes",
            "text": "<ul> <li>idempotency: deep sort payload during hashing (#2570) (6765f35)</li> <li>parser: handle API Gateway Test UI sourceIp (#2531) (cd6c512)</li> </ul>"
        },
        {
            "location": "changelog/#features_16",
            "title": "Features",
            "text": "<ul> <li>batch: add option to continue processing other group IDs on failure in <code>SqsFifoPartialProcessor</code> (#2590) (a615c24)</li> </ul>"
        },
        {
            "location": "changelog/#211-2024-05-14",
            "title": "2.1.1 (2024-05-14)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_14",
            "title": "Bug Fixes",
            "text": "<ul> <li>parser: lambda function url cognitoIdentity and principalOrgId nullable (#2430) (3c3e393)</li> <li>parser: set APIGatewayProxyEventSchema body and query string keys to be nullable (#2465) (7ce5b3c)</li> <li>parser: set etag optional for delete object notifications (#2429) (100e223)</li> </ul>"
        },
        {
            "location": "changelog/#210-2024-04-17",
            "title": "2.1.0 (2024-04-17)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_15",
            "title": "Bug Fixes",
            "text": "<ul> <li>jmespath: refactor custom function introspection to work with minification (#2384) (21ecc4f)</li> </ul>"
        },
        {
            "location": "changelog/#features_17",
            "title": "Features",
            "text": "<ul> <li>idempotency: add custom JMESPath functions (#2364) (9721e7c)</li> </ul>"
        },
        {
            "location": "changelog/#204-2024-04-10",
            "title": "2.0.4 (2024-04-10)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_16",
            "title": "Bug Fixes",
            "text": "<p>idempotency: return correct value from in-memory cache (#2309) (5b4c103) logger: buffer logs emitted during init (#2269) (1439867)</p>"
        },
        {
            "location": "changelog/#features_18",
            "title": "Features",
            "text": "<p>tracer: support tracing <code>fetch</code> requests (#1619) (607548b) jmespath public release of JMESPAth utility (#1645) (233ff9b)</p>"
        },
        {
            "location": "changelog/#minor-changes",
            "title": "Minor Changes",
            "text": "<p>logger: use template literal instead of <code>node:util</code> format (#2283) (961ace1)</p>"
        },
        {
            "location": "changelog/#203-2024-03-15",
            "title": "2.0.3 (2024-03-15)",
            "text": "<p>feat(logger): improve regex in stack trace parsing (#2121) (ebe5eef) fix(idempotency): transform private class fields (#2230) (aa6e6e0) improv(commons):: expand type utils functions (#2191) (9208393) feat(commons): add fromBase64 helper function (#2188) (133159b) fix(layers):: add createRequire banner in esm build (#2231) (730bcc9)</p>"
        },
        {
            "location": "changelog/#202-2024-03-05",
            "title": "2.0.2 (2024-03-05)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_17",
            "title": "Bug Fixes",
            "text": "<ul> <li>tracer: modify aws-xray-sdk-core import for js (#2164) (29630b5)</li> </ul>"
        },
        {
            "location": "changelog/#201-2024-03-04",
            "title": "2.0.1 (2024-03-04)",
            "text": "<p>Note: Version bump only for package aws-lambda-powertools-typescript</p>"
        },
        {
            "location": "changelog/#200-2024-03-04",
            "title": "2.0.0 (2024-03-04)",
            "text": "<p>Note: Version bump only for package aws-lambda-powertools-typescript</p>"
        },
        {
            "location": "changelog/#1181-2024-02-20",
            "title": "1.18.1 (2024-02-20)",
            "text": "<p>Note: Version bump only for package aws-lambda-powertools-typescript</p>"
        },
        {
            "location": "changelog/#1180-2024-01-26",
            "title": "1.18.0 (2024-01-26)",
            "text": ""
        },
        {
            "location": "changelog/#features_19",
            "title": "Features",
            "text": "<p>layers: add <code>ca-west-1</code> region (#1836) (55ff4df)</p>"
        },
        {
            "location": "changelog/#1170-2023-11-24",
            "title": "1.17.0 (2023-11-24)",
            "text": "<p>maintenance: drop support for Node.js 14 (#1664) (e2a0923)</p>"
        },
        {
            "location": "changelog/#1160-2023-11-16",
            "title": "1.16.0 (2023-11-16)",
            "text": ""
        },
        {
            "location": "changelog/#features_20",
            "title": "Features",
            "text": "<ul> <li>logger: add support for <code>AWS_LAMBDA_LOG_LEVEL</code> and <code>POWERTOOLS_LOG_LEVEL</code> (#1795) (e69abfb)</li> </ul>"
        },
        {
            "location": "changelog/#1150-2023-11-14",
            "title": "1.15.0 (2023-11-14)",
            "text": ""
        },
        {
            "location": "changelog/#features_21",
            "title": "Features",
            "text": "<ul> <li>maintenance: add support for nodejs20.x runtime (#1790) (6b9b1bc)</li> <li>metrics: log directly to stdout (#1786) (75dc5b1)</li> </ul>"
        },
        {
            "location": "changelog/#1142-2023-11-03",
            "title": "1.14.2 (2023-11-03)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_18",
            "title": "Bug Fixes",
            "text": "<ul> <li>metrics: deduplicate dimensions when serialising (#1780) (8181b48)</li> </ul>"
        },
        {
            "location": "changelog/#1141-2023-10-31",
            "title": "1.14.1 (2023-10-31)",
            "text": "<p>Note: Version bump only for package aws-lambda-powertools-typescript</p>"
        },
        {
            "location": "changelog/#1140-2023-09-29",
            "title": "1.14.0 (2023-09-29)",
            "text": ""
        },
        {
            "location": "changelog/#features_22",
            "title": "Features",
            "text": "<ul> <li>idempotency: add idempotency decorator (#1723) (d138673)</li> <li>layers: add <code>arm64</code> to integration test matrix (#1720) (61ad5ac)</li> <li>tracer: add try/catch logic to decorator and middleware close (#1716) (be16b59)</li> </ul>"
        },
        {
            "location": "changelog/#1131-2023-09-21",
            "title": "1.13.1 (2023-09-21)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_19",
            "title": "Bug Fixes",
            "text": "<ul> <li>maintenance: remove upper peer dependency Middy (#1705) (df21ec8)</li> </ul>"
        },
        {
            "location": "changelog/#1130-2023-09-18",
            "title": "1.13.0 (2023-09-18)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_20",
            "title": "Bug Fixes",
            "text": "<ul> <li>batch: Update processor to pass only context to handler (#1637) (6fa09b2)</li> <li>docs: update versions.json jq query (4e6f662)</li> <li>parameters: return type when options without transform is used (#1671) (b2fe341)</li> </ul>"
        },
        {
            "location": "changelog/#features_23",
            "title": "Features",
            "text": "<ul> <li>batch: rename AsyncBatchProcessor to default BatchProcessor (#1683) (e253755)</li> </ul>"
        },
        {
            "location": "changelog/#1121-2023-07-25",
            "title": "1.12.1 (2023-07-25)",
            "text": "<p>Note: Version bump only for package aws-lambda-powertools-typescript</p>"
        },
        {
            "location": "changelog/#1120-2023-07-25",
            "title": "1.12.0 (2023-07-25)",
            "text": ""
        },
        {
            "location": "changelog/#features_24",
            "title": "Features",
            "text": "<ul> <li>batch: add batch processing utility (#1625) (c4e6b19), closes #1588 #1591 #1593 #1592 #1594</li> <li>logger: add cause to formatted error (#1617) (6a14595)</li> </ul>"
        },
        {
            "location": "changelog/#1111-2023-07-11",
            "title": "1.11.1 (2023-07-11)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_21",
            "title": "Bug Fixes",
            "text": "<ul> <li>docs: fix alias in versions.json (#1576) (7198cbc)</li> <li>idempotency: types, docs, and <code>makeIdempotent</code> function wrapper (#1579) (bba1c01)</li> </ul>"
        },
        {
            "location": "changelog/#1110-2023-06-29",
            "title": "1.11.0 (2023-06-29)",
            "text": ""
        },
        {
            "location": "changelog/#features_25",
            "title": "Features",
            "text": "<ul> <li>idempotency: preserve original error when wrapping into <code>IdempotencyPersistenceLayerError</code> (#1552) (866837d)</li> </ul>"
        },
        {
            "location": "changelog/#1100-2023-06-23",
            "title": "1.10.0 (2023-06-23)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_22",
            "title": "Bug Fixes",
            "text": "<ul> <li>ci: change how versions and aliases are inserted into versions.json (#1549) (9e1d19a)</li> <li>idempotency: pass lambda context remaining time to save inprogress (#1540) (d47c3ec)</li> <li>idempotency: record validation not using hash (#1502) (f475bd0)</li> <li>idempotency: skip persistence for optional idempotency key (#1507) (b9fcef6)</li> <li>metrics: flush metrics when data points array reaches max size (#1548) (24c247c)</li> <li>missing quotes (67f5f14)</li> <li>missing quotes (349e612)</li> <li>update reference in workflow (#1518) (9c75f9a)</li> </ul>"
        },
        {
            "location": "changelog/#features_26",
            "title": "Features",
            "text": "<ul> <li>logger: clear state when other middlewares return early (#1544) (d5f3f13)</li> <li>metrics: publish metrics when other middlewares return early (#1546) (58b0877)</li> <li>parameters: review types and exports (#1528) (6f96711)</li> <li>tracer: close &amp; restore segments when other middlewares return (#1545) (74ddb09)</li> </ul>"
        },
        {
            "location": "changelog/#190-2023-06-09",
            "title": "1.9.0 (2023-06-09)",
            "text": ""
        },
        {
            "location": "changelog/#features_27",
            "title": "Features",
            "text": "<ul> <li>commons: add <code>cleanupPowertools</code> function (#1473) (5bd0166)</li> <li>idempotency: <code>makeHandlerIdempotent</code> middy middleware (#1474) (a558f10)</li> <li>idempotency: add package exports (#1483) (faa9307)</li> <li>idempotency: idempotency middleware &amp; types exports (#1487) (d947db9)</li> <li>idempotency: implement IdempotencyHandler (#1416) (f2ebf08)</li> <li>logger: enhance log level handling (#1476) (0021536)</li> <li>parameters: add adaptive types to SecretsProvider (#1411) (5c6d527)</li> <li>tracer: add isTraceSampled method (#1435) (194bbd3)</li> </ul>"
        },
        {
            "location": "changelog/#180-2023-04-07",
            "title": "1.8.0 (2023-04-07)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_23",
            "title": "Bug Fixes",
            "text": "<ul> <li>parameters: type import path in AppConfigProvider (#1388) (40a1a24)</li> </ul>"
        },
        {
            "location": "changelog/#features_28",
            "title": "Features",
            "text": "<ul> <li>idempotency: add local cache to <code>BasePersistenceLayer</code> (#1396) (2013ff2)</li> <li>idempotency: BasePersistenceLayer, DynamoDBPersistenceLayer and configs (#1376) (f05cba8)</li> <li>logger: add <code>CRITICAL</code> log level (#1399) (a248ff0)</li> <li>metrics: log warning on empty metrics (#1397) (31ae936)</li> <li>parameters: ability to set <code>maxAge</code> and <code>decrypt</code> via environment variables (#1384) (dcf6620)</li> <li>parameters: add <code>clearCaches</code> function (#1382) (ec49023)</li> <li>parameters: stronger types for SSM getParameter (#1387) (9d53942)</li> </ul>"
        },
        {
            "location": "changelog/#170-2023-03-20",
            "title": "1.7.0 (2023-03-20)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_24",
            "title": "Bug Fixes",
            "text": "<ul> <li>docs: typo in layer arn (bc5f7c9)</li> </ul>"
        },
        {
            "location": "changelog/#features_29",
            "title": "Features",
            "text": "<ul> <li>logger: add silent log level to suppress the emission of all logs (#1347) (c82939e)</li> <li>metrics: support high resolution metrics (#1369) (79a321b)</li> <li>parameters: AppConfigProvider to return the last valid value when the API returns empty value on subsequent calls (#1365) (97339d9)</li> </ul>"
        },
        {
            "location": "changelog/#160-2023-03-02",
            "title": "1.6.0 (2023-03-02)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_25",
            "title": "Bug Fixes",
            "text": "<ul> <li>docs: logger bringYourOwnFormatter snippet #1253 (#1254) (fdbba32)</li> <li>hardcoded cdk version in <code>publish_layer.yaml</code> (#1232) (63a3909)</li> <li>logger: createChild not passing all parent's attributes (#1267) (84ab4b9)</li> <li>logger: middleware stores initial persistent attributes correctly (#1329) (6b32304)</li> <li>parameters: handle base64/binaries in transformer (#1326) (bb50c04)</li> <li>parameters: Tokenize attribute names in <code>DynamoDBProvider</code> (#1239) (f3e5ed7)</li> </ul>"
        },
        {
            "location": "changelog/#features_30",
            "title": "Features",
            "text": "<ul> <li>idempotency: Add function wrapper and decorator (#1262) (eacb1d9)</li> <li>layers: add new regions (#1322) (618613b)</li> <li>logger: make loglevel types stricter (#1313) (5af51d3)</li> <li>parameters: add support for custom AWS SDK v3 clients for providers (#1260) (3a8cfa0)</li> </ul>"
        },
        {
            "location": "changelog/#151-2023-01-13",
            "title": "1.5.1 (2023-01-13)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_26",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: logger throws TypeError when log item has BigInt value (#1201) (a09e4df)</li> <li>parameters: types in BaseProvider + added getMultiple alias to SecretsProvider (#1214) (32bd7e8)</li> </ul>"
        },
        {
            "location": "changelog/#features_31",
            "title": "Features",
            "text": "<ul> <li>parameters: AppConfigProvider (#1200) (fecedb9)</li> <li>parameters: DynamoDBProvider support (#1202) (db94850)</li> <li>parameters: SecretsProvider support (#1206) (02516b7)</li> <li>parameters: SSMProvider support (#1187) (2e4bb76)</li> </ul>"
        },
        {
            "location": "changelog/#150-2022-11-25",
            "title": "1.5.0 (2022-11-25)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_27",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: merge child logger options correctly (#1178) (cb91374)</li> </ul>"
        },
        {
            "location": "changelog/#features_32",
            "title": "Features",
            "text": "<ul> <li>idempotency: Add persistence layer and DynamoDB implementation (#1110) (0a6676a)</li> <li>logger: disable logs while testing with <code>jest --silent</code> in dev env (#1165) (6f0c307)</li> <li>logger: pretty printing logs in local and non-prod environment (#1141) (8d52660)</li> <li>parameters: added <code>BaseProvider</code> class (#1168) (d717a26)</li> </ul>"
        },
        {
            "location": "changelog/#141-2022-11-09",
            "title": "1.4.1 (2022-11-09)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_28",
            "title": "Bug Fixes",
            "text": "<ul> <li>metrics: store service name in defaultDimensions to avoid clearing it (#1146) (a979202)</li> </ul>"
        },
        {
            "location": "changelog/#140-2022-10-27",
            "title": "1.4.0 (2022-10-27)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_29",
            "title": "Bug Fixes",
            "text": "<ul> <li>metrics: metadata and dimensions not cleared on publish (#1129) (b209c30)</li> </ul>"
        },
        {
            "location": "changelog/#features_33",
            "title": "Features",
            "text": "<ul> <li>all: moved EnvService to commons + exposed getXrayTraceId in tracer (#1123) (c8e3c15)</li> </ul>"
        },
        {
            "location": "changelog/#130-2022-10-17",
            "title": "1.3.0 (2022-10-17)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_30",
            "title": "Bug Fixes",
            "text": "<ul> <li>all: update version command to use lint-fix (#1119) (6f14fb3)</li> <li>captureColdStartMetric and throwOnEmptyMetrics when set to false was interpreted as true (#1090) (127aad4)</li> <li>captureMethod correctly detect method name when used with external decorators (#1109) (a574406)</li> <li>logger: wait for decorated method return before clearing out state (#1087) (133ed3c)</li> <li>ts-node version for layer-publisher (#1112) (ee243de)</li> </ul>"
        },
        {
            "location": "changelog/#features_34",
            "title": "Features",
            "text": "<ul> <li>idempotency: create initial class structure for function idempotency (#1086) (06fbaae)</li> <li>publish lib as Lambda Layer (#1095) (83f6efb)</li> <li>tracer: specify subsegment name when capturing class method (#1092) (d4174eb)</li> </ul>"
        },
        {
            "location": "changelog/#reverts",
            "title": "Reverts",
            "text": "<ul> <li>Revert \"chore(release): v1.3.0 [skip ci]\" (237b99f)</li> </ul>"
        },
        {
            "location": "changelog/#121-2022-08-25",
            "title": "1.2.1 (2022-08-25)",
            "text": "<p>Note: Version bump only for package aws-lambda-powertools-typescript</p>"
        },
        {
            "location": "changelog/#120-2022-08-23",
            "title": "1.2.0 (2022-08-23)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_31",
            "title": "Bug Fixes",
            "text": "<ul> <li>docs: docs published with incorrect version number + api docs missing after release (#1066) (8b8b25c)</li> </ul>"
        },
        {
            "location": "changelog/#features_35",
            "title": "Features",
            "text": "<ul> <li>metrics: increase maximum dimensions to 29 (#1072) (7b9a027)</li> <li>tracer: allow disabling result capture for decorators and middleware (#1065) (c3b9a37)</li> </ul>"
        },
        {
            "location": "changelog/#111-2022-08-18",
            "title": "1.1.1 (2022-08-18)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_32",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: decorated class methods cannot access <code>this</code> (#1060) (73990bb)</li> <li>tracer: decorated class methods cannot access <code>this</code> (#1055) (107fa04)</li> <li>workflow concurrency + leftover needs (#1054) (9ce180a)</li> </ul>"
        },
        {
            "location": "changelog/#110-2022-08-12",
            "title": "1.1.0 (2022-08-12)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_33",
            "title": "Bug Fixes",
            "text": "<ul> <li>layers: release process + remove duplicate code (#1052) (f653c06)</li> <li>logger: fix clearstate bug when lambda handler throws (#1045) (5ebd1cf)</li> <li>wrong scope in captureMethod (#1026) (1a06fed)</li> </ul>"
        },
        {
            "location": "changelog/#features_36",
            "title": "Features",
            "text": "<ul> <li>build: publish lib as a Lambda Layer (#884) (c3a20c6), closes #1031</li> </ul>"
        },
        {
            "location": "changelog/#102-2022-07-19",
            "title": "1.0.2 (2022-07-19)",
            "text": "<p>Note: Version bump only for package aws-lambda-powertools-typescript</p>"
        },
        {
            "location": "changelog/#101-2022-07-14",
            "title": "1.0.1 (2022-07-14)",
            "text": "<p>Note: Version bump only for package aws-lambda-powertools-typescript</p>"
        },
        {
            "location": "changelog/#0120-rc1-2022-07-14",
            "title": "0.12.0-rc.1 (2022-07-14)",
            "text": ""
        },
        {
            "location": "changelog/#reverts_1",
            "title": "Reverts",
            "text": "<ul> <li>Revert \"build: bump lerna (#1014)\" (#1018) (623e12d), closes #1014 #1018</li> </ul>"
        },
        {
            "location": "changelog/#0120-rc0-2022-07-14",
            "title": "0.12.0-rc.0 (2022-07-14)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_34",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: POWERTOOLS_LOGGER_LOG_EVENT precedence is respected (#1015) (1cbb4db)</li> <li>tracer: capture method throws errors correctly (#1016) (fb85238)</li> </ul>"
        },
        {
            "location": "changelog/#features_37",
            "title": "Features",
            "text": "<ul> <li>tracer: auto disable when running inside amplify mock (#1010) (024d628)</li> </ul>"
        },
        {
            "location": "changelog/#reverts_2",
            "title": "Reverts",
            "text": "<ul> <li>Revert \"chore(release): v0.12.0-rc.0 [skip ci]\" (9397f1d)</li> <li>Revert \"chore(release): v0.12.0-rc.0 [skip ci]\" (#1017) (51c18da), closes #1017</li> </ul>"
        },
        {
            "location": "changelog/#0111-rc0-2022-06-24",
            "title": "0.11.1-rc.0 (2022-06-24)",
            "text": "<p>Note: Version bump only for package aws-lambda-powertools-typescript</p>"
        },
        {
            "location": "changelog/#0110-2022-06-23",
            "title": "0.11.0 (2022-06-23)",
            "text": ""
        },
        {
            "location": "changelog/#features_38",
            "title": "Features",
            "text": "<ul> <li>logger: add clear state functionality (#902) (fa1dacb)</li> </ul>"
        },
        {
            "location": "changelog/#0100-2022-06-02",
            "title": "0.10.0 (2022-06-02)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_35",
            "title": "Bug Fixes",
            "text": "<ul> <li>commons: rename tests subfolder to samples to avoid being deleted by tools such as node-prune (#882) (74ef816)</li> </ul>"
        },
        {
            "location": "changelog/#features_39",
            "title": "Features",
            "text": "<ul> <li>all: nodejs16x support (#877) (d2b13c9)</li> <li>logger: add removeKeys functionality (#901) (a0f72c2)</li> </ul>"
        },
        {
            "location": "changelog/#091-2022-05-24",
            "title": "0.9.1 (2022-05-24)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_36",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: enable logging of arbitrary objects (#883) (5d34854)</li> </ul>"
        },
        {
            "location": "changelog/#090-2022-05-16",
            "title": "0.9.0 (2022-05-16)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_37",
            "title": "Bug Fixes",
            "text": "<ul> <li>added back fetch-depth: 0 (#812) (494c742)</li> <li>logger: add xray_trace_id to every log (#776) (11af21a)</li> <li>reintroduce token while checking out (#848) (cabef3e)</li> <li>removed token from remaining actions (#805) (4fd9ecb)</li> </ul>"
        },
        {
            "location": "changelog/#features_40",
            "title": "Features",
            "text": "<ul> <li>examples: added sam example to workflows (#849) (93f1c7b)</li> </ul>"
        },
        {
            "location": "changelog/#081-2022-04-14",
            "title": "0.8.1 (2022-04-14)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_38",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: change logging to use stdout (#748) (0781a47)</li> </ul>"
        },
        {
            "location": "changelog/#080-2022-04-08",
            "title": "0.8.0 (2022-04-08)",
            "text": ""
        },
        {
            "location": "changelog/#features_41",
            "title": "Features",
            "text": "<ul> <li>added captureHTTPsRequest feature (#677) (5a36723)</li> </ul>"
        },
        {
            "location": "changelog/#072-2022-04-01",
            "title": "0.7.2 (2022-04-01)",
            "text": "<p>Note: Version bump only for package aws-lambda-powertools-typescript</p>"
        },
        {
            "location": "changelog/#071-2022-03-17",
            "title": "0.7.1 (2022-03-17)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_39",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: enable sequential invocation in e2e test (#658) (800424b)</li> <li>logger: fix handling of additional log keys (#614) (8aab299)</li> <li>tracer, metrics: use polling instead of fixed wait in e2e tests (#654) (6d4ab75)</li> </ul>"
        },
        {
            "location": "changelog/#070-2022-03-08",
            "title": "0.7.0 (2022-03-08)",
            "text": ""
        },
        {
            "location": "changelog/#features_42",
            "title": "Features",
            "text": "<ul> <li>logger: adopted Utility class &amp; updated unit tests (#550) (48f3487)</li> <li>metrics: adopted Utility class (#548) (672e6a8)</li> <li>tracer: adopted Utility class &amp; updated unit tests (#549) (3769a69)</li> </ul>"
        },
        {
            "location": "changelog/#060-2022-02-17",
            "title": "0.6.0 (2022-02-17)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_40",
            "title": "Bug Fixes",
            "text": "<ul> <li>logger: fix logger attribute merging (#535) (8180be1)</li> </ul>"
        },
        {
            "location": "changelog/#features_43",
            "title": "Features",
            "text": "<ul> <li>commons: centralize cold start heuristic (#547) (4e4091f)</li> <li>logger: add e2e tests for logger (#529) (e736b65)</li> </ul>"
        },
        {
            "location": "changelog/#051-2022-02-09",
            "title": "0.5.1 (2022-02-09)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_41",
            "title": "Bug Fixes",
            "text": "<ul> <li>tracer: properly return DynamoDB.DocumentClient (#528) (3559e7b)</li> </ul>"
        },
        {
            "location": "changelog/#reverts_3",
            "title": "Reverts",
            "text": "<ul> <li>Revert \"build(deps-dev): bump aws-cdk from 1.139.0 to 1.143.0 (#532)\" (#544) (e96c9ba), closes #532 #544</li> <li>Revert \"build(deps-dev): bump @aws-cdk/aws-lambda-nodejs from 1.139.0 to 1.143.0 (#531)\" (#545) (7dffbd8), closes #531 #545</li> </ul>"
        },
        {
            "location": "changelog/#050-2022-01-26",
            "title": "0.5.0 (2022-01-26)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_42",
            "title": "Bug Fixes",
            "text": "<ul> <li>examples: fix errors in logger and metrics examples (#509) (c19b47c)</li> <li>logger|metrics: properly return decorated class (#489) (014c5bd)</li> </ul>"
        },
        {
            "location": "changelog/#features_44",
            "title": "Features",
            "text": "<ul> <li>Add codespaces/gitpod support (#485) (ed6f258)</li> <li>all: make <code>@middy/core</code> optional (#511) (1107f96)</li> <li>tracer: add support for capturing DynamoDB DocumentClient (#450) (621ae50)</li> </ul>"
        },
        {
            "location": "changelog/#040-2022-01-20",
            "title": "0.4.0 (2022-01-20)",
            "text": ""
        },
        {
            "location": "changelog/#features_45",
            "title": "Features",
            "text": "<ul> <li>logger: JSDOCS support (#491) (cd2c2d9)</li> </ul>"
        },
        {
            "location": "changelog/#033-2022-01-17",
            "title": "0.3.3 (2022-01-17)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_43",
            "title": "Bug Fixes",
            "text": "<ul> <li>lerna version not publishing all packages (#480) (0cabc3f)</li> </ul>"
        },
        {
            "location": "changelog/#032-2022-01-17",
            "title": "0.3.2 (2022-01-17)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_44",
            "title": "Bug Fixes",
            "text": "<ul> <li>export LogFormatter + update docs (#479) (7f91566)</li> <li>updated CDK examples to remove old references &amp; improve comments (#439) (4cdaaea)</li> </ul>"
        },
        {
            "location": "changelog/#031-2022-01-14",
            "title": "0.3.1 (2022-01-14)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_45",
            "title": "Bug Fixes",
            "text": "<ul> <li>all: fix latest release broken by change of npm pack result on common (#470) (2c3df93), closes #417</li> </ul>"
        },
        {
            "location": "changelog/#030-2022-01-14",
            "title": "0.3.0 (2022-01-14)",
            "text": ""
        },
        {
            "location": "changelog/#bug-fixes_46",
            "title": "Bug Fixes",
            "text": "<ul> <li>build: Fix linting issue and add linting to the pre-push hook (#440) (e7bc53c)</li> <li>build: Update contributing.md and fix npm ci (#417) (279ad98), closes #415 #415</li> <li>metrics: Rename purgeStoredMetrics() function usage in CDK example (#424) (02f0eae)</li> <li>tracer: avoid throwing errors in manual instrumentation when running outside of AWS Lambda (#442) (fd02acb)</li> </ul>"
        },
        {
            "location": "changelog/#features_46",
            "title": "Features",
            "text": "<ul> <li>all: Update to examples use released version (0.2.0) (#405) (d5e0620)</li> </ul>"
        },
        {
            "location": "changelog/#020-2022-01-05",
            "title": "0.2.0 (2022-01-05)",
            "text": ""
        },
        {
            "location": "changelog/#features_47",
            "title": "Features",
            "text": "<ul> <li>tracer: beta release (#91 (https://github.com/aws-powertools/powertools-lambda-python/issues/91))</li> <li>logger: beta release (#24 (https://github.com/aws-powertools/powertools-lambda-python/issues/24))</li> <li>metrics: beta release (#25 (https://github.com/aws-powertools/powertools-lambda-python/issues/25))</li> </ul>"
        },
        {
            "location": "changelog/#contributions",
            "title": "Contributions",
            "text": "<ul> <li>chore(ci): auto-label PR on semantic title (#403) by @heitorlessa</li> <li>fix: documentation generation on on-release.yml workflow (#368) by @ijemmy</li> <li>fix: Remove publishing doc on develop version and fix missing leading 0 in version (#356) by @ijemmy</li> <li>feat: generate new version of doc for each release (#355) by @ijemmy</li> <li>chore(cicd): cdk examples and e2e tests for metrics (#326) by @flochaz</li> <li>fix(cicd): skip ci on bump commit (#339) by @flochaz</li> <li>chore(cicd): fix publish (#336) by @flochaz</li> <li>chore(cicd): Add release workflow (#260) by @flochaz</li> <li>chore(commons): Create a common package (#314) by @flochaz</li> <li>feat: Auto publish docs to version \"develop\" (#269) by @ijemmy</li> <li>fix(metrics): publish metrics even if handler throw (#249) by @flochaz</li> <li>chore: fix linting (#247) by @flochaz</li> <li>chore(all): npm libraries bump and breaking changes fixes (#215) by @saragerion</li> <li>chore: Enable auto-merge for dependabot PRs (#169) by @dreamorosi</li> <li>feat: add metrics (#102) by @alan-churley</li> <li>chore: Add commit hooks for testing and linting (#149) by @bahrmichael</li> <li>chore: Removed assignees from issue templates (#146) by @dreamorosi</li> <li>chore: Disabled auto-assign-issues integration (#144) by @dreamorosi</li> <li>feat: Adding sample automation for PR (#121) by @alan-churley</li> <li>test(logger): add unit tests with most important scenarios and features (#52) by @saragerion</li> <li>chore: increase version of WS dependancy (#71) by @alan-churley</li> <li>chore: dependancies upgrade (#70) by @alan-churley</li> <li>build(github-actions): fix YAML of closed issues message (#23) by @saragerion</li> <li>improv: repository documentation, metadata, github actions, dot files (#17) by @saragerion</li> <li>refactor(logger): overall improvements - DX, examples, business logic (#16) by @saragerion</li> <li>chore: updating path for coverage (#12) by @alan-churley</li> <li>feat(logger): add context decorator functionality (#13) by @saragerion</li> <li>test(all): add mock Lambda events payloads generated by other AWS services (#10) by @saragerion</li> <li>feat(logger): basic logger logic (#9) by @saragerion</li> <li>revert: Remove CodeQL analysis (#2) by @alan-churley</li> <li> <p>feat(metrics): rename method purgeStoredMetrics to publishStoredMetrics (#377) by @flochaz</p> </li> <li> <p>fix(metrics): use same naming for serviceName (#401) by @flochaz</p> </li> <li>feat(commons): update types to have optional callback (#394) by @flochaz</li> <li>feat(metrics): logMetrics middleware (#338) by @saragerion</li> <li>chore(tracer): quality of life improvements (#337) by @dreamorosi</li> <li>feat(tracer): middy middleware (#324) by @dreamorosi</li> <li>feat(logger): middy middleware (#313) by @saragerion</li> <li>chore(ALL): fix packaging (#316) by @flochaz</li> <li>feat: add tracer (#107) by @dreamorosi</li> <li>feat(logger): documentation, examples, business logic changes (#293) by @saragerion</li> <li>feat(metric): bring feature parity between decorator and utility function (#291) by @flochaz</li> <li>docs(all): make docs more coherent (#387) by @dreamorosi</li> <li>docs(logger): improve mkdocs and examples of sample rate feature (#389) by @saragerion</li> <li>docs(all): clarifications &amp; fixes (#370) by @dreamorosi</li> <li>chore(tracer): cdk examples + e2e tests (#347) by @dreamorosi</li> <li>docs(all): getting started section, beta release warning (#351) by @saragerion</li> <li>chore(docs): Tracer docs (#274) by @dreamorosi</li> <li>chore(docs): Add credits section to README (#305) by @dreamorosi</li> <li>chore(metrics): Add typeDoc (#285) by @flochaz</li> <li>feat(logger): documentation, examples, business logic changes (#293) by @saragerion</li> <li>chore(metrics): github page doc (#284) by @flochaz</li> <li>feat: generate api docs (#277) by @ijemmy</li> <li>docs: base documentation (#250) by @dreamorosi</li> <li>docs: updating readme and package.json to work with lerna (#11) by @alan-churley</li> <li>fix(metrics): Support multiple addMetric() call with the same metric name (#390) by @ijemmy</li> <li>fix(logger): display correct log level in cloudwatch (#386) by @saragerion</li> <li>fix(metrics): expose logMetrics middleware (#380) by @flochaz</li> <li>chore: change license (#117) by @dreamorosi</li> <li>chore: don't bump version for merge to main (#404) by @flochaz</li> <li>feat(ALL): Use optional callback LambdaInterface for decorator (#397) by @flochaz</li> <li>chore(ci): add release drafter workflow (#382) by @heitorlessa</li> <li>build(deps): bump e2e dependencies metrics (#371) by @dreamorosi</li> <li>build(deps-dev): bump @aws-cdk/aws-lambda from 1.136.0 to 1.137.0 (#340) by @dependabot</li> <li>chore(commons): Remove eslint from commons pkg (#352) by @dreamorosi</li> <li>build(deps-dev): bump @types/lodash from 4.14.177 to 4.14.178 (#335) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.11.11 to 17.0.0 (#325) by @dependabot</li> <li>build(deps-dev): bump @types/lodash from 4.14.177 to 4.14.178 (#318) by @dependabot</li> <li>build(deps-dev): bump ts-jest from 27.0.7 to 27.1.1 (#317) by @dependabot</li> <li>build(deps-dev): bump jest from 27.4.3 to 27.4.5 (#310) by @dependabot</li> <li>build(deps): bump @types/aws-lambda from 8.10.85 to 8.10.88 (#312) by @dependabot</li> <li>build(deps-dev): bump typescript from 4.5.2 to 4.5.4 (#311) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 5.5.0 to 5.7.0 (#308) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 5.5.0 to 5.7.0 (#309) by @dependabot</li> <li>build(deps): bump aws-xray-sdk-core from 3.3.3 to 3.3.4 (#307) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 5.5.0 to 5.6.0 (#297) by @dependabot</li> <li>build(deps): bump @types/aws-lambda from 8.10.85 to 8.10.87 (#299) by @dependabot</li> <li>build(deps-dev): bump jest from 27.4.3 to 27.4.4 (#300) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 5.5.0 to 5.6.0 (#298) by @dependabot</li> <li>build(deps-dev): bump ts-jest from 27.0.7 to 27.1.1 (#296) by @dependabot</li> <li>build(deps-dev): bump typescript from 4.5.2 to 4.5.3 (#287) by @dependabot</li> <li>build(deps-dev): bump jest from 27.4.3 to 27.4.4 (#288) by @dependabot</li> <li>build(deps-dev): bump @types/lodash from 4.14.177 to 4.14.178 (#283) by @dependabot</li> <li>build(deps): bump @types/aws-lambda from 8.10.85 to 8.10.86 (#272) by @dependabot</li> <li>build(deps-dev): bump ts-jest from 27.0.7 to 27.1.1 (#271) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.11.11 to 16.11.12 (#270) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 5.5.0 to 5.6.0 (#273) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 5.5.0 to 5.6.0 (#268) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.11.11 to 16.11.12 (#267) by @dependabot</li> <li>build(deps-dev): bump eslint from 8.3.0 to 8.4.1 (#266) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 5.5.0 to 5.6.0 (#265) by @dependabot</li> <li>build(deps-dev): bump ts-jest from 27.0.7 to 27.1.0 (#264) by @dependabot</li> <li>build(deps): bump @types/aws-lambda from 8.10.85 to 8.10.86 (#263) by @dependabot</li> <li>build(deps): bump romeovs/lcov-reporter-action from 0.2.21 to 0.3.1 (#261) by @dependabot</li> <li>build(deps-dev): bump @types/jest from 27.0.2 to 27.0.3 (#258) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.11.6 to 16.11.11 (#257) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.33.0 to 5.5.0 (#256) by @dependabot</li> <li>build(deps-dev): bump @types/lodash from 4.14.175 to 4.14.177 (#255) by @dependabot</li> <li>build(deps): bump @types/aws-lambda from 8.10.84 to 8.10.85 (#252) by @dependabot</li> <li>build(deps-dev): bump jest from 27.3.1 to 27.4.3 (#251) by @dependabot</li> <li>build(deps-dev): bump husky from 7.0.2 to 7.0.4 (#243) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.33.0 to 5.5.0 (#253) by @dependabot</li> <li>build(deps-dev): bump eslint from 8.1.0 to 8.3.0 (#254) by @dependabot</li> <li>build(deps-dev): bump typescript from 4.4.3 to 4.5.2 (#245) by @dependabot</li> <li>build(deps-dev): bump ts-node from 10.3.0 to 10.4.0 (#242) by @dependabot</li> <li>build(deps-dev): bump ts-jest from 27.0.5 to 27.0.7 (#234) by @dependabot</li> <li>build(deps-dev): bump @commitlint/cli from 13.2.1 to 15.0.0 (#244) by @dependabot</li> <li>build(deps-dev): bump jest from 27.2.5 to 27.3.1 (#235) by @dependabot</li> <li>build(deps-dev): bump eslint from 7.32.0 to 8.1.0 (#239) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.10.3 to 16.11.6 (#240) by @dependabot</li> <li>build(deps-dev): bump ts-node from 10.2.1 to 10.3.0 (#226) by @dependabot</li> <li>build(deps-dev): bump jest from 27.2.4 to 27.2.5 (#225) by @dependabot</li> <li>build(deps-dev): bump @types/aws-lambda from 8.10.83 to 8.10.84 (#223) by @dependabot</li> <li>build(deps-dev): bump @commitlint/cli from 13.2.0 to 13.2.1 (#222) by @dependabot</li> <li>build(deps-dev): bump jest from 27.2.2 to 27.2.4 (#217) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.32.0 to 4.33.0 (#219) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.32.0 to 4.33.0 (#220) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.10.1 to 16.10.3 (#221) by @dependabot</li> <li>build(deps-dev): bump jest from 27.0.6 to 27.2.2 (#212) by @dependabot</li> <li>build(deps-dev): bump ts-jest from 27.0.4 to 27.0.5 (#181) by @dependabot</li> <li>build(deps): bump actions/github-script from 4.1 to 5 (#211) by @dependabot</li> <li>build(deps-dev): bump typescript from 4.3.5 to 4.4.3 (#199) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.9.6 to 16.10.1 (#213) by @dependabot</li> <li>build(deps-dev): bump @types/lodash from 4.14.173 to 4.14.174 (#214) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.9.4 to 16.9.6 (#210) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.30.0 to 4.31.2 (#209) by @dependabot</li> <li>build(deps-dev): bump @types/jest from 27.0.1 to 27.0.2 (#208) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.9.2 to 16.9.4 (#205) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.31.1 to 4.31.2 (#206) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.9.1 to 16.9.2 (#204) by @dependabot</li> <li>build(deps-dev): bump @types/lodash from 4.14.172 to 4.14.173 (#203) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.7.2 to 16.9.1 (#202) by @dependabot</li> <li>build(deps-dev): bump husky from 7.0.1 to 7.0.2 (#191) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.29.2 to 4.31.1 (#200) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.29.2 to 4.30.0 (#194) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.6.2 to 16.7.2 (#190) by @dependabot</li> <li>build(deps): bump actions/github-script from 4.0.2 to 4.1 (#187) by @dependabot</li> <li>build(deps-dev): bump @types/aws-lambda from 8.10.82 to 8.10.83 (#186) by @dependabot</li> <li>build(deps): bump actions/github-script from 3.1.0 to 4.0.2 (#179) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.29.1 to 4.29.2 (#180) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.6.1 to 16.6.2 (#184) by @dependabot</li> <li>build(deps-dev): bump ts-node from 10.2.0 to 10.2.1 (#183) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.29.1 to 4.29.2 (#182) by @dependabot</li> <li>build(deps-dev): bump @types/jest from 27.0.0 to 27.0.1 (#177) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.6.0 to 16.6.1 (#176) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.4.13 to 16.6.0 (#174) by @dependabot</li> <li>build(deps-dev): bump @commitlint/cli from 12.1.4 to 13.1.0 (#172) by @dependabot</li> <li>build(deps-dev): bump @types/jest from 26.0.24 to 27.0.0 (#171) by @dependabot</li> <li>build(deps-dev): bump @types/aws-lambda from 8.10.81 to 8.10.82 (#170) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.29.0 to 4.29.1 (#167) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.29.0 to 4.29.1 (#166) by @dependabot</li> <li>improv: Use lodash.merge &amp; lodash.clonedeed instead of full lodash in Logger (#159) by @dreamorosi</li> <li>build(deps-dev): bump ts-node from 10.1.0 to 10.2.0 (#164) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.4.10 to 16.4.13 (#162) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.28.5 to 4.29.0 (#156) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.28.5 to 4.29.0 (#157) by @dependabot</li> <li>build(deps-dev): bump @types/lodash from 4.14.171 to 4.14.172 (#158) by @dependabot</li> <li>build(deps-dev): bump eslint from 7.31.0 to 7.32.0 (#155) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.4.7 to 16.4.10 (#154) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.4.6 to 16.4.7 (#150) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.4.5 to 16.4.6 (#148) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.4.3 to 16.4.5 (#145) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.28.4 to 4.28.5 (#138) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.28.4 to 4.28.5 (#137) by @dependabot</li> <li>build(deps-dev): bump @types/aws-lambda from 8.10.80 to 8.10.81 (#135) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.4.1 to 16.4.3 (#134) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.4.0 to 16.4.1 (#132) by @dependabot</li> <li>build(deps-dev): bump @types/aws-lambda from 8.10.79 to 8.10.80 (#128) by @dependabot</li> <li>build(deps-dev): bump ts-jest from 27.0.3 to 27.0.4 (#127) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.3.3 to 16.4.0 (#124) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.28.3 to 4.28.4 (#122) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.28.3 to 4.28.4 (#123) by @dependabot</li> <li>build(deps-dev): bump eslint from 7.30.0 to 7.31.0 (#118) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.3.2 to 16.3.3 (#119) by @dependabot</li> <li>build(deps-dev): bump @types/aws-lambda from 8.10.78 to 8.10.79 (#114) by @dependabot</li> <li>build(deps-dev): bump @types/node from 16.0.0 to 16.3.2 (#113) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.28.2 to 4.28.3 (#112) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.28.2 to 4.28.3 (#111) by @dependabot</li> <li>build(deps-dev): bump ts-node from 10.0.0 to 10.1.0 (#110) by @dependabot</li> <li>build(deps-dev): bump @types/lodash from 4.14.170 to 4.14.171 (#105) by @dependabot</li> <li>build(deps-dev): bump @types/jest from 26.0.23 to 26.0.24 (#104) by @dependabot</li> <li>build(deps-dev): bump @types/aws-lambda from 8.10.77 to 8.10.78 (#103) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.28.1 to 4.28.2 (#100) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.28.1 to 4.28.2 (#101) by @dependabot</li> <li>build(deps-dev): bump @types/node from 15.14.0 to 16.0.0 (#98) by @dependabot</li> <li>build(deps-dev): bump eslint from 7.29.0 to 7.30.0 (#99) by @dependabot</li> <li>build(deps-dev): bump typescript from 4.3.4 to 4.3.5 (#97) by @dependabot</li> <li>build(deps-dev): bump @types/node from 15.12.3 to 15.14.0 (#96) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.27.0 to 4.28.1 (#94) by @dependabot</li> <li>build(deps-dev): bump eslint from 7.28.0 to 7.29.0 (#86) by @dependabot</li> <li>build(deps-dev): bump @types/node from 15.12.3 to 15.12.5 (#92) by @dependabot</li> <li>build(deps-dev): bump jest from 27.0.4 to 27.0.6 (#93) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.27.0 to 4.28.1 (#95) by @dependabot</li> <li>build(deps-dev): bump typescript from 4.3.2 to 4.3.4 (#84) by @dependabot</li> <li>build(deps-dev): bump @types/node from 15.12.2 to 15.12.3 (#85) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.26.1 to 4.27.0 (#81) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.26.1 to 4.27.0 (#82) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.26.0 to 4.26.1 (#80) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.26.0 to 4.26.1 (#78) by @dependabot</li> <li>build(deps-dev): bump @types/node from 15.12.1 to 15.12.2 (#79) by @dependabot</li> <li>build(deps-dev): bump jest from 26.6.3 to 27.0.4 (#73) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.25.0 to 4.26.0 (#69) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.25.0 to 4.26.0 (#68) by @dependabot</li> <li>build(deps-dev): bump typescript from 4.2.4 to 4.3.2 (#66) by @dependabot</li> <li>build(deps-dev): bump @types/node from 15.3.1 to 15.6.1 (#61) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.24.0 to 4.25.0 (#62) by @dependabot</li> <li>build(deps-dev): bump @types/lodash from 4.14.169 to 4.14.170 (#60) by @dependabot</li> <li>build(deps-dev): bump ts-node from 9.1.1 to 10.0.0 (#58) by @dependabot</li> <li>build(deps-dev): bump eslint from 7.26.0 to 7.27.0 (#57) by @dependabot</li> <li>build(deps-dev): bump @types/node from 15.3.0 to 15.3.1 (#56) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.23.0 to 4.24.0 (#55) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.23.0 to 4.24.0 (#54) by @dependabot</li> <li>build(deps-dev): bump @types/node from 15.0.3 to 15.3.0 (#53) by @dependabot</li> <li>build(deps-dev): bump @types/node from 14.14.37 to 15.0.3 (#50) by @dependabot</li> <li>build(deps-dev): bump lerna from 3.22.1 to 4.0.0 (#29) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.21.0 to 4.22.0 (#37) by @dependabot</li> <li>build(deps-dev): bump eslint from 7.23.0 to 7.24.0 (#35) by @dependabot</li> <li>build(deps): bump romeovs/lcov-reporter-action from v0.2.11 to v0.2.21 (#34) by @dependabot</li> <li>build(deps-dev): bump @commitlint/cli from 11.0.0 to 12.1.1 (#33) by @dependabot</li> <li>build(deps-dev): bump @types/aws-lambda from 8.10.72 to 8.10.75 (#32) by @dependabot</li> <li>build(deps-dev): bump @types/node from 14.14.20 to 14.14.37 (#31) by @dependabot</li> <li>build(deps-dev): bump husky from 4.3.7 to 6.0.0 (#30) by @dependabot</li> <li>build(deps-dev): bump typescript from 4.1.3 to 4.2.4 (#28) by @dependabot</li> <li>build(deps-dev): bump ts-jest from 26.4.4 to 26.5.4 (#27) by @dependabot</li> <li>build(deps-dev): bump eslint from 7.17.0 to 7.23.0 (#21) by @dependabot</li> <li>build(deps-dev): bump @types/jest from 26.0.20 to 26.0.22 (#22) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/parser from 4.13.0 to 4.21.0 (#20) by @dependabot</li> <li>build(deps-dev): bump @typescript-eslint/eslint-plugin from 4.13.0 to 4.21.0 (#18) by @dependabot</li> <li>build(deps-dev): bump @commitlint/config-conventional from 11.0.0 to 12.1.1 (#19) by @dependabot</li> <li>docs: updating readme and package.json to work with lerna (#11) by @alan-churley</li> <li>chore: lerna downstream dependancy security issues (#15) by @alan-churley</li> <li>build(deps): bump ini from 1.3.5 to 1.3.8 (#5) by @dependabot</li> <li>build(deps): bump ini from 1.3.5 to 1.3.8 in /packages/logging (#4) by @dependabot</li> <li>build(deps): bump ini from 1.3.5 to 1.3.8 in /docs (#3) by @dependabot</li> </ul>"
        },
        {
            "location": "changelog/#contributor-list",
            "title": "Contributor List:",
            "text": "<p>@alan-churley, @bahrmichael, @dreamorosi, @flochaz, @heitorlessa, @ijemmy and @saragerion</p>"
        },
        {
            "location": "maintainers/",
            "title": "Maintainers playbook",
            "text": ""
        },
        {
            "location": "maintainers/#overview",
            "title": "Overview",
            "text": "<p>Please treat this content as a living document.</p> <p>This is document explains who the maintainers are, their responsibilities, and how they should be doing it. If you're interested in contributing, see Contributing document.</p>"
        },
        {
            "location": "maintainers/#current-maintainers",
            "title": "Current Maintainers",
            "text": "Maintainer GitHub ID Affiliation Andrea Amorosi dreamorosi Amazon Alexander Schueren am29d Amazon Simon Thulbourn sthulb Amazon"
        },
        {
            "location": "maintainers/#emeritus",
            "title": "Emeritus",
            "text": "<p>Previous active maintainers who contributed to this project.</p> Maintainer GitHub ID Affiliation Sara Gerion saragerion Amazon Florian Chazal flochaz Amazon Chadchapol Vittavutkarnvej ijemmy Booking.com Alan Churley alan-churley CloudCall Michael Bahr bahrmichael Stedi"
        },
        {
            "location": "maintainers/#labels",
            "title": "Labels",
            "text": "<p>These are the most common labels used by maintainers to triage issues, pull requests (PR), and for project management:</p> Label Usage Notes triage New issues that require maintainers review Issue template documentation Improvements or additions to documentation Examples/Readme files; Doc additions, fixes, etc.; logger Items related to the Logger Utility PR automation metrics Items related to the Metrics Utility PR automation tracer Items related to the Tracer Utility PR automation idempotency Items related to the Idempotency Utility PR automation parameters Items related to the Parameters Utility PR automation commons Items related to the Commons Utility PR automation jmespath Items related to the JMESPath Utility PR automation validation Items related to the Validation Utility PR automation batch Items related to the Batch Processing Utility PR automation parser Items related to the Parser Utility PR automation event-handler Items related to the Event Handler Utility PR automation automation Items related to automation like GitHub workflows or CI/CD PR automation layers Items related to the Lambda Layers pipeline PR automation size/XS PRs between 0-9 LOC PR automation size/S PRs between 10-29 LOC PR automation size/M PRs between 30-99 LOC PR automation size/L PRs between 100-499 LOC PR automation size/XL PRs between 500-999 LOC, often PRs that grown with feedback PR automation size/XXL PRs with 1K+ LOC, largely documentation related PR automation customer-reference Authorization to use company name in our documentation Public Relations community-content Suggested content to feature in our documentation Public Relations do-not-merge PRs that are blocked for varying reasons Timeline is uncertain bug Unexpected, reproducible and unintended software behavior PR/Release automation; Doc snippets are excluded; bug-upstream Bug caused by upstream dependency not-a-bug New and existing bug reports incorrectly submitted as bug Analytics deprecation This item contains code deprecation duplicate This issue is a duplicate of an existing one Analytics feature-request Issue requesting new or enhancements to existing features Issue template feature PRs that introduce new features PR automation enhancement PRs that introduce minor changes, usually to existing features PR automation RFC Technical design documents related to a feature request internal PRs that introduce changes in governance, tech debt and chores (linting setup, baseline, etc.) PR automation tests PRs that add or change tests PR automation dependencies Changes that touch dependencies, e.g. Dependabot, etc. Issues/PR automation breaking-change Changes that will cause customer impact and need careful triage blocked Items which progress is blocked by external dependency or reason confirmed Items with clear scope and that are ready for implementation discussing Items that need to be discussed, elaborated, or refined on-hold Items that are on hold and will be revisited in the future pending-release Merged changes that will be available soon Release automation auto-closes/notifies it completed Items that are complete and have been merged and/or shipped rejected This is something we will not be working on. At least, not in the measurable future pending-close-response-required This issue will be closed soon unless the discussion moves forward Stale Automation revisit-in-3-months Blocked issues/PRs that need to be revisited Often related to <code>need-customer-feedback</code>, prioritization, etc. good-first-issue Something that is suitable for those who want to start contributing help-wanted Tasks you want help from anyone to move forward Bandwidth, complex topics, etc. need-customer-feedback Tasks that need more feedback before proceeding 80/20% rule, uncertain, etc. need-more-information Missing information before making any calls Signal that investigation or answers are needed need-response Requires a response from a customer and might be automatically closed if none is received Marked as stale after 2 weeks, and closed after 3 need-issue PR is missing a related issue for tracking change"
        },
        {
            "location": "maintainers/#maintainer-responsibilities",
            "title": "Maintainer Responsibilities",
            "text": "<p>Maintainers are active and visible members of the community, and have maintain-level permissions on a repository. Use those privileges to serve the community and evolve code as follows.</p> <p>Be aware of recurring ambiguous situations and document them to help your fellow maintainers.</p>"
        },
        {
            "location": "maintainers/#uphold-code-of-conduct",
            "title": "Uphold Code of Conduct",
            "text": "<p>Model the behavior set forward by the Code of Conduct and raise any violations to other maintainers and admins. There could be unusual circumstances where inappropriate behavior does not immediately fall within the Code of Conduct.</p> <p>These might be nuanced and should be handled with extra care - when in doubt, do not engage and reach out to other maintainers and admins.</p>"
        },
        {
            "location": "maintainers/#prioritize-security",
            "title": "Prioritize Security",
            "text": "<p>Security is your number one priority. Maintainer's Github keys must be password protected securely and any reported security vulnerabilities are addressed before features or bugs.</p> <p>Note that this repository is monitored and supported 24/7 by Amazon Security, see Reporting a Vulnerability for details.</p>"
        },
        {
            "location": "maintainers/#review-pull-requests",
            "title": "Review Pull Requests",
            "text": "<p>Review pull requests regularly, comment, suggest, reject, merge and close. Accept only high quality pull-requests. Provide code reviews and guidance on incoming pull requests.</p> <p>PRs are labeled based on file changes and semantic title. Pay attention to whether labels reflect the current state of the PR and correct accordingly.</p> <p>Use and enforce semantic versioning pull request titles, as these will be used for CHANGELOG and Release notes - make sure they communicate their intent at the human level.</p> <p>For issues linked to a PR, make sure <code>pending-release</code> label is applied to them when merging. Upon release, these issues will be notified which release version contains their change.</p> <p>See Common scenarios section for additional guidance.</p>"
        },
        {
            "location": "maintainers/#triage-new-issues",
            "title": "Triage New Issues",
            "text": "<p>Manage labels, review issues regularly, and create new labels as needed by the project. Remove <code>triage</code> label when you're able to confirm the validity of a request, a bug can be reproduced, etc. Give priority to the original author for implementation, unless it is a sensitive task that is best handled by maintainers.</p> <p>Make sure issues are assigned to our board of activities and have the right status.</p> <p>Use our labels to signal good first issues to new community members, and to set expectation that this might need additional feedback from the author, other customers, experienced community members and/or maintainers.</p> <p>Be aware of casual contributors and recurring contributors. Provide the experience and attention you wish you had if you were starting in open source.</p> <p>See Common scenarios section for additional guidance.</p>"
        },
        {
            "location": "maintainers/#triage-bug-reports",
            "title": "Triage Bug Reports",
            "text": "<p>Be familiar with our definition of bug. If it's not a bug, you can close it or adjust its title and labels - always communicate the reason accordingly.</p> <p>For bugs caused by upstream dependencies, replace <code>bug</code> with <code>bug-upstream</code> label. Ask the author whether they'd like to raise the issue upstream or if they prefer us to do so.</p> <p>Assess the impact and make the call on whether we need an emergency release. Contact other maintainers when in doubt.</p> <p>See Common scenarios section for additional guidance.</p>"
        },
        {
            "location": "maintainers/#triage-rfcs",
            "title": "Triage RFCs",
            "text": "<p>RFC is a collaborative process to help us get to the most optimal solution given the context. Their purpose is to ensure everyone understands what this context is, their trade-offs, and alternative solutions that were part of the research before implementation begins.</p> <p>Make sure you ask these questions in mind when reviewing:</p> <ul> <li>Does it use our RFC template?</li> <li>Does the match our Tenets?</li> <li>Does the proposal address the use case? If so, is the recommended usage explicit?</li> <li>Does it focus on the mechanics to solve the use case over fine-grained implementation details?</li> <li>Can anyone familiar with the code base implement it?</li> <li>If approved, are they interested in contributing? Do they need any guidance?</li> <li>Does this significantly increase the overall project maintenance? Do we have the skills to maintain it?</li> <li>If we can't take this use case, are there alternative projects we could recommend? Or does it call for a new project altogether?</li> </ul> <p>When necessary, be upfront that the time to review, approve, and implement a RFC can vary - see Contribution is stuck. Some RFCs may be further updated after implementation, as certain areas become clearer.</p> <p>Some examples using our initial and new RFC templates: #447</p>"
        },
        {
            "location": "maintainers/#releasing-a-new-version",
            "title": "Releasing a new version",
            "text": "<p>Firstly, make sure all the PRs that you want to include in the release are merged into the <code>main</code> branch.</p> <p>Next, run the integration tests one last time to make sure everything is working as expected. See Run end to end tests for more details.</p> <p>Looks good, what's next?</p> <p>Kickoff the <code>Make Release</code> workflow with the intended version - this might take around 20m-25m to complete.</p> <p>Once complete, you can start drafting the release notes to let customers know what changed and what's in it for them (a.k.a why they should care). We have guidelines in the release notes section so you know what good looks like.</p> <p>NOTE: Documentation might take a few minutes to reflect the latest version due to caching and CDN invalidations.</p>"
        },
        {
            "location": "maintainers/#release-process-visualized",
            "title": "Release process visualized",
            "text": "<p>Every release makes dozens of checks, linting, canaries and deployments - all of these are automated through a number of distinct workflows that together make up the release process.</p> <p>This is a close visual representation of the main steps (GitHub Actions UI should be the source of truth), along with the approximate time it takes for each key step to complete.</p> <pre><code>gantt\n\ntitle      Release process\ndateFormat HH:mm\naxisFormat %H:%M\n\nRelease start   : milestone, m1, 10:00, 8s\n\nsection Version\n    Bump package version              : active, 8s\n    Create commit (version bump)      : active, 8s\n    Open version PR                   : active, 8s\n\nReview and merge version PR : milestone, m2\n\nsection QA\n    Quality checks                    : active, 2.4m\n\nsection Build\n    Bundle release artifact (CJS+ESM) : active, 39s\n\nsection Git release\n    Git Tag                           : active, 8s\n    Push Tag                          : active, 8s\n\nsection Release\n    Attest build                      : active, 8s\n    Sign attestation                  : active, attestation, 10:04, 8s\n    Publish npm.js                    : active, npm, after attestation, 40s\n\nnpmjs.com release : milestone, m3\n\nsection Layer release\n    Build                             : active, layer_build, 10:05, 2.5m\n    Deploy Beta                       : active, layer_beta, after layer_build, 4m\n    Run Canary Test                   : active, layer_canary, after layer_beta, 2m\n    Deploy Prod                       : active, layer_prod, after layer_canary, 4m\n\nLayer release : milestone, m4\n\nsection Docs\n    Create commit (Layer ARN)         : active, 10:18, 8s\n    Open docs PR                      : active, 8s\n\nReview andmerge docs PR : milestone, m5\n\n    Publish updated docs              : active, 2m\n\nDocumentation release : milestone, m6\n\nRelease complete : milestone, m7</code></pre>"
        },
        {
            "location": "maintainers/#drafting-release-notes",
            "title": "Drafting release notes",
            "text": "<p>Visit the Releases page and choose the edit pencil button.</p> <p>Make sure the <code>tag</code> field reflects the new version you're releasing, the target branch field is set to <code>main</code>, and <code>release title</code> matches your tag e.g., <code>v1.14.1</code>.</p> <p>You'll notice we group all changes based on their labels like <code>feature</code>, <code>bug</code>, <code>documentation</code>, etc.</p> <p>I spotted a typo or incorrect grouping - how do I fix it?</p> <p>Edit the respective PR title and update their labels. Then run the Release Drafter workflow to update the Draft release.</p> <p>Note</p> <p>This won't change the CHANGELOG as the merge commit is immutable. Don't worry about it. We'd only rewrite git history only if this can lead to confusion and we'd pair with another maintainer.</p> <p>All looking good, what's next?</p> <p>The best part comes now. Replace the placeholder <code>[Human readable summary of changes]</code> with what you'd like to communicate to customers what this release is all about. Rule of thumb: always put yourself in the customers shoes.</p> <p>These are some questions to keep in mind when drafting your first or future release notes:</p> <ul> <li>Can customers understand at a high level what changed in this release?</li> <li>Is there a link to the documentation where they can read more about each main change?</li> <li>Are there any graphics or code snippets that can enhance readability?</li> <li>Are we calling out any key contributor(s) to this release?<ul> <li>All contributors are automatically credited, use this as an exceptional case to feature them</li> </ul> </li> </ul> <p>Once you're happy, hit <code>Publish release</code> 🎉🎉🎉.</p> <p>This will kick off the Post Release workflow and within a few minutes you should see all issues labeled as <code>pending-release</code>  notified of the new release and labeled as <code>completed</code>.</p>"
        },
        {
            "location": "maintainers/#run-end-to-end-tests",
            "title": "Run end to end tests",
            "text": "<p>Note</p> <p>We are planning to automate this process in the future so that tests are run automatically when a PR is merged, see #1149</p> <p>E2E tests should be ran before every merge to <code>main</code> or manually via Run e2e Tests workflow before making a release.</p> <p>To run locally, you need AWS CDK CLI and an account bootstrapped (<code>cdk bootstrap</code>). With a default AWS CLI profile configured, or <code>AWS_PROFILE</code> environment variable set, run <code>make e2e tests</code>.</p> <p>For more information on how the tests are structured and how they can be run locally, see Integration Tests.</p>"
        },
        {
            "location": "maintainers/#releasing-a-documentation-hotfix",
            "title": "Releasing a documentation hotfix",
            "text": "<p>You can rebuild the latest documentation without a full release via this GitHub Actions Workflow. Choose <code>Run workflow</code>, keep <code>main</code> as the branch, and input the latest Powertools for AWS Lambda (TypeScript) version available.</p> <p>This workflow will update both user guide and API documentation.</p>"
        },
        {
            "location": "maintainers/#maintain-overall-health-of-the-repo",
            "title": "Maintain Overall Health of the Repo",
            "text": "<p>Keep the <code>main</code> branch at production quality at all times. Backport features as needed. Cut release branches and tags to enable future patches.</p>"
        },
        {
            "location": "maintainers/#manage-roadmap",
            "title": "Manage Roadmap",
            "text": "<p>See Roadmap section</p> <p>Ensure the repo highlights features that should be elevated to the project roadmap. Be clear about the feature’s status, priority, target version, and whether or not it should be elevated to the roadmap.</p>"
        },
        {
            "location": "maintainers/#add-continuous-integration-checks",
            "title": "Add Continuous Integration Checks",
            "text": "<p>Add integration checks that validate pull requests and pushes to ease the burden on Pull Request reviewers. Continuously revisit areas of improvement to reduce operational burden in all parties involved.</p>"
        },
        {
            "location": "maintainers/#publish-lambda-layers-to-new-aws-regions",
            "title": "Publish Lambda Layers to new AWS Regions",
            "text": "<p>When a new AWS region is available, make the Lambda Layers available in that region. Before doing so, ensure that the region supports AWS Lambda and that the Lambda Layers are compatible with the region.</p> <p>Then bootstrap the region both in the beta and prod accounts by running <code>npm run cdk bootstrap aws://&lt;account-id&gt;/&lt;region&gt;</code> for each account while in the <code>layers</code> directory. Next, run the <code>layer-balancer</code> script to align the layer version in the new region with the existing regions.</p> <p>Finally, add the new region to the <code>region</code> matrix in the <code>reusable_deploy_layer_stack.yml</code> workflow file, and add the corresponding ARN to the Lambda Layer ARN table in the documentation.</p>"
        },
        {
            "location": "maintainers/#negative-impact-on-the-project",
            "title": "Negative Impact on the Project",
            "text": "<p>Actions that negatively impact the project will be handled by the admins, in coordination with other maintainers, in balance with the urgency of the issue. Examples would be Code of Conduct violations, deliberate harmful or malicious actions, spam, monopolization, and security risks.</p>"
        },
        {
            "location": "maintainers/#becoming-a-maintainer",
            "title": "Becoming a maintainer",
            "text": "<p>We need to improve our understanding of how other projects are doing, their mechanisms to promote key contributors, and how they interact daily.</p> <p>We suspect this process might look similar to the OpenSearch project and will revisit this in late 2024.</p>"
        },
        {
            "location": "maintainers/#common-scenarios",
            "title": "Common scenarios",
            "text": "<p>These are recurring ambiguous situations that new and existing maintainers may encounter. They serve as guidance. It is up to each maintainer to follow, adjust, or handle in a different manner as long as our conduct is consistent</p>"
        },
        {
            "location": "maintainers/#contribution-is-stuck",
            "title": "Contribution is stuck",
            "text": "<p>A contribution can get stuck often due to lack of bandwidth and language barrier. For bandwidth issues, check whether the author needs help. Make sure you get their permission before pushing code into their existing PR - do not create a new PR unless strictly necessary.</p> <p>For language barrier and others, offer a 1:1 chat to get them unblocked. Often times, English might not be their primary language, and writing in public might put them off, or come across not the way they intended to be.</p> <p>In other cases, you may have constrained capacity. Use <code>help-wanted</code> label when you want to signal other maintainers and external contributors that you could use a hand to move it forward.</p>"
        },
        {
            "location": "maintainers/#insufficient-feedback-or-information",
            "title": "Insufficient feedback or information",
            "text": "<p>When in doubt, use <code>need-more-information</code> or <code>need-customer-feedback</code> labels to signal more context and feedback are necessary before proceeding. You can also use <code>revisit-in-3-months</code> label when you expect it might take a while to gather enough information before you can decide.</p> <p>Note that issues marked as <code>need-response</code> will be automatically closed after 3 weeks of inactivity.</p>"
        },
        {
            "location": "maintainers/#crediting-contributions",
            "title": "Crediting contributions",
            "text": "<p>We credit all contributions as part of each release note as an automated process. If you find  contributors are missing from the release note you're producing, please add them manually.</p>"
        },
        {
            "location": "maintainers/#is-that-a-bug",
            "title": "Is that a bug?",
            "text": "<p>A bug produces incorrect or unexpected results at runtime that differ from its intended behavior. Bugs must be reproducible. They directly affect customers experience at runtime despite following its recommended usage.</p> <p>Documentation snippets, use of internal components, or unadvertised functionalities are not considered bugs.</p>"
        },
        {
            "location": "maintainers/#mentoring-contributions",
            "title": "Mentoring contributions",
            "text": "<p>Always favor mentoring issue authors to contribute, unless they're not interested or the implementation is sensitive (e.g., complexity, time to release, etc.).</p> <p>Make use of <code>help-wanted</code> and <code>good-first-issue</code> to signal additional contributions the community can help.</p>"
        },
        {
            "location": "maintainers/#long-running-issues-or-prs",
            "title": "Long running issues or PRs",
            "text": "<p>Try offering a 1:1 call in the attempt to get to a mutual understanding and clarify areas that maintainers could help.</p> <p>In the rare cases where both parties don't have the bandwidth or expertise to continue, it's best to use the <code>on-hold</code> or <code>revisit-in-3-months</code> labels. After some time has passed, see if it's possible to break the PR or issue in smaller chunks, and eventually close if there is no progress.</p>"
        },
        {
            "location": "roadmap/",
            "title": "Roadmap",
            "text": ""
        },
        {
            "location": "roadmap/#overview",
            "title": "Overview",
            "text": "<p>Our public roadmap outlines the high level direction we are working towards. We update this document when our priorities change: security and stability are our top priority.</p> <p>For most up-to-date information, see our board of activities.</p>"
        },
        {
            "location": "roadmap/#key-areas",
            "title": "Key areas",
            "text": "<p>Security and operational excellence take precedence above all else. This means bug fixing, stability, customer's support, and internal compliance may delay one or more key areas below.</p> <p>We may choose to reprioritize or defer items based on customer feedback, security, and operational impacts, and business value.</p>"
        },
        {
            "location": "roadmap/#event-handler-rest-p0",
            "title": "Event Handler REST (p0)",
            "text": "<p>This is a roadmap item that we carry forward from 2024 and involves the creation of a new utility for customers to work with REST APIs built on AWS Lambda, and Amazon API Gateway REST and HTTP APIs, Application Load Balancer (ALB), Lambda Function URLs, and VPC Lattice. It's one of the most requested features in terms of feature parity from our customers.</p> <p>You can follow the progress of this feature in the Event Handler REST milestone. Below are some of the key macro tasks that we will be working on:</p> <ul> <li> Explore pros &amp; cons of whether to build atop lean frameworks (e.g., Hono) or from scratch</li> <li> RFC to discuss initial thoughts and feasibility for TS/JS ecosystem</li> <li> Support for API Gateway REST API resolver</li> <li> Support for API Gateway HTTP API resolver</li> <li> Support for Lambda Function URL resolver</li> <li> Support for Application Load Balancer resolver</li> <li> Support for VPC Lattice resolver</li> <li> Support for Data Validation (e.g., <code>Zod</code>)</li> <li> Support for OpenAPI generation</li> <li> Support for Middlewares</li> <li> Support for Compression</li> <li> Support for Binary responses</li> <li> Support for custom serializer</li> <li> Support for injecting request details (consider not doing globals like Python legacy)</li> <li> Support for Router (multi-file routes)</li> </ul>"
        },
        {
            "location": "roadmap/#feature-parity-p1",
            "title": "Feature parity (p1)",
            "text": "<p>To close the gap between Powertools for AWS Lambda (Python) and Powertools for AWS Lambda (TypeScript), we will focus our efforts on adding targeted features that are currently missing from the TypeScript version. These include (but are not limited to):</p>"
        },
        {
            "location": "roadmap/#logger",
            "title": "Logger",
            "text": "<ul> <li> Ability to add a correlation ID to logs via decorator/middleware</li> <li> Ability to pretty print stack traces</li> <li> Ability to buffer logs</li> <li> Ability to refresh debug log sampling rate via decorator/middleware</li> </ul>"
        },
        {
            "location": "roadmap/#event-handler",
            "title": "Event Handler",
            "text": "<p>In addition to the Event Handler REST feature mentioned above, we will also be working on the following:</p> <ul> <li> Implement resolver for Amazon Bedrock Agents Functions</li> <li> Implement resolver for Amazon Bedrock Agents OpenAPI</li> <li> Create RFC for AppSync GraphQL resolver</li> </ul>"
        },
        {
            "location": "roadmap/#validation",
            "title": "Validation",
            "text": "<p>For the Validation utility, we'll experiment with a community-driven approach to building a new Powertools for AWS Lambda utility.</p> <ul> <li> Standalone validation utility</li> <li> Class method decorator validation</li> <li> Middy.js middleware validation</li> <li> Documentation</li> </ul>"
        },
        {
            "location": "roadmap/#governance-advanced-use-cases-p2",
            "title": "Governance &amp; Advanced Use Cases (p2)",
            "text": "<p>To streghten our offering for more advanced customers as well as enterprises, we will be working on a set of activities that will help us better support their needs and practices. These include:</p> <ul> <li> Publish Lambda layers to GovCloud</li> <li> Publish Lambda layers to China regions</li> <li> Improve OSS supply chain posture (Q2) by making sure we're auditing our dependencies for compatible licenses and include NOTICE files in our Lambda layers</li> <li> Create a new \"Advanced Use Cases\" section in the docs - to help customers with more complex use cases, such as running Powertools for AWS Lambda in container environments</li> <li> Set up CI/CD for performance testing</li> <li> Improve performance of our core utilities</li> <li> Improve performance overhead of Lambda layers</li> <li> Publish SSM Parameters to lookup Lambda layers ARNs</li> </ul>"
        },
        {
            "location": "roadmap/#community-engagement-new-customers-p3",
            "title": "Community engagement &amp; new customers (p3)",
            "text": "<p>To ensure we are attracting tomorrow's customers as well as new contributors to the project, we will be working on a set of activities that will help us better engage with the community and new customers. These include:</p> <ul> <li> Create a new \"Getting Started\" guide in the docs</li> <li> Further improve the \"Contributing\" &amp; \"How to find contributions\" pages</li> <li> Surface contribution opportunities in Discord &amp; other community channels</li> <li> Improve release notes announcements in Discord &amp; other community channels</li> <li> We will also attempt to create a community-developed new utility (see Validation above)</li> </ul>"
        },
        {
            "location": "roadmap/#missing-something",
            "title": "Missing something?",
            "text": "<p>You can help us prioritize by upvoting existing feature requests, leaving a comment on what use cases it could unblock for you, and by joining our discussions on Discord.</p> <p></p>"
        },
        {
            "location": "roadmap/#roadmap-status-definition",
            "title": "Roadmap status definition",
            "text": "<p> <pre><code>graph LR\n    Ideas --&gt; Backlog --&gt; Work[\"Working on it\"] --&gt; Merged[\"Coming soon\"] --&gt; Shipped</code></pre> Visual representation </p> <p>Within our public board, you'll see the following values in the <code>Status</code> column:</p> <ul> <li>Ideas. Incoming and existing feature requests that are not being actively considered yet. These will be reviewed when bandwidth permits.</li> <li>Backlog. Accepted feature requests or enhancements that we want to work on.</li> <li>Working on it. Features or enhancements we're currently either researching or implementing it.</li> <li>Coming soon. Any feature, enhancement, or bug fixes that have been merged and are coming in the next release.</li> <li>Shipped. Features or enhancements that are now available in the most recent release.</li> </ul> <p>Tasks or issues with empty <code>Status</code> will be categorized in upcoming review cycles.</p>"
        },
        {
            "location": "roadmap/#process",
            "title": "Process",
            "text": "<p> <pre><code>graph LR\n    PFR[Feature request] --&gt; Triage{Need RFC?}\n    Triage --&gt; |Complex/major change or new utility?| RFC[Ask or write RFC] --&gt; Approval{Approved?}\n    Triage --&gt; |Minor feature or enhancement?| NoRFC[No RFC required] --&gt; Approval\n    Approval --&gt; |Yes| Backlog\n    Approval --&gt; |No | Reject[\"Inform next steps\"]\n    Backlog --&gt; |Prioritized| Implementation\n    Backlog --&gt; |Defer| WelcomeContributions[\"help-wanted label\"]</code></pre> Visual representation </p> <p>Our end-to-end mechanism follows four major steps:</p> <ul> <li>Feature Request. Ideas start with a feature request to outline their use case at a high level. For complex use cases, maintainers might ask for/write a RFC.<ul> <li>Maintainers review requests based on project tenets, customers reaction (👍), and use cases.</li> </ul> </li> <li>Request-for-comments (RFC). Design proposals use our RFC template to describe its implementation, challenges, developer experience, dependencies, and alternative solutions.<ul> <li>This helps refine the initial idea with community feedback before a decision is made.</li> </ul> </li> <li>Decision. After carefully reviewing and discussing them, maintainers make a final decision on whether to start implementation, defer or reject it, and update everyone with the next steps.</li> <li>Implementation. For approved features, maintainers give priority to the original authors for implementation unless it is a sensitive task that is best handled by maintainers.</li> </ul> See Maintainers document to understand how we triage issues and pull requests, labels and governance."
        },
        {
            "location": "roadmap/#disclaimer",
            "title": "Disclaimer",
            "text": "<p>The Powertools for AWS Lambda (TypeScript) team values feedback and guidance from its community of users, although final decisions on inclusion into the project will be made by AWS.</p> <p>We determine the high-level direction for our open roadmap based on customer feedback and popularity (👍🏽 and comments), security and operational impacts, and business value. Where features don’t meet our goals and longer-term strategy, we will communicate that clearly and openly as quickly as possible with an explanation of why the decision was made.</p>"
        },
        {
            "location": "roadmap/#faqs",
            "title": "FAQs",
            "text": "<p>Q: Why did you build this?</p> <p>A: We know that our customers are making decisions and plans based on what we are developing, and we want to provide our customers the insights they need to plan.</p> <p>Q: Why are there no dates on your roadmap?</p> <p>A: Because job zero is security and operational stability, we can't provide specific target dates for features. The roadmap is subject to change at any time, and roadmap issues in this repository do not guarantee a feature will be launched as proposed.</p> <p>Q: How can I provide feedback or ask for more information?</p> <p>A: For existing features, you can directly comment on issues. For anything else, please open an issue.</p>"
        },
        {
            "location": "upgrade/",
            "title": "Upgrade guide",
            "text": ""
        },
        {
            "location": "upgrade/#end-of-support-v1",
            "title": "End of support v1",
            "text": "<p>On March 13th, 2024, Powertools for AWS Lambda (TypeScript) v1 entered maintenance mode, and has reached End-of-Life on September 1st, 2024. If you are still using v1, we strongly recommend you to upgrade to the latest version.</p> <p>Given our commitment to all of our customers using Powertools for AWS Lambda (TypeScript), we will keep npm v1 releases and documentation 1.x versions to prevent any disruption.</p>"
        },
        {
            "location": "upgrade/#migrate-from-v1-to-v2",
            "title": "Migrate from v1 to v2",
            "text": "<p>V2 is focused on official support for ESM (ECMAScript modules). We've made other minimal breaking changes to make your transition to v2 as smooth as possible.</p>"
        },
        {
            "location": "upgrade/#quick-summary",
            "title": "Quick summary",
            "text": "Area Change Code change required ESM support Added ESM support via dual CommonJS and ESM bundling, enabling top-level <code>await</code> and tree-shaking. - Middy.js Updated import path for Middy.js middlewares to leverage subpath exports - i.e. <code>@aws-lambda-powertools/tracer/middleware</code>. Yes Types imports Updated import path for TypeScript types to leverage subpath exports - i.e. <code>@aws-lambda-powertools/logger/types</code>. Yes Logger Changed log sampling to dynamically switch log level to <code>DEBUG</code> on a percentage of requests. - Logger Updated custom log formatter to include standard as well as persistent keys. Yes Logger Removed <code>ContextExamples</code> from <code>@aws-lambda-powertools/commons</code> package. Yes Logger and Tracer Removed deprecated <code>createLogger</code> and <code>createTracer</code> helper functions in favor of direct instantiation. Yes"
        },
        {
            "location": "upgrade/#first-steps",
            "title": "First steps",
            "text": "<p>Before you start, we suggest making a copy of your current working project or create a new git branch.</p> <ol> <li>Upgrade Node.js to v18 or higher, Node.js v20 is recommended.</li> <li>Ensure that you have the latest Powertools for AWS Lambda (TypeScript) version via Lambda Layer or npm.</li> <li>Review the following sections to confirm whether they apply to your codebase.</li> </ol>"
        },
        {
            "location": "upgrade/#esm-support",
            "title": "ESM support",
            "text": "<p>With support for ES Modules in v2, you can now use <code>import</code> instead of <code>require</code> syntax.</p> <p>This is especially useful when you want to run asynchronous code during the initialization phase by using top-level <code>await</code>.</p> top-level await example in v2<pre><code>import { getSecret } from '@aws-lambda-powertools/parameters/secrets';\n\n// This code will run during the initialization phase of your Lambda function\nconst myApiKey = await getSecret('my-api-key', { transform: 'json' });\n\nexport const handler = async (_event: unknown, _context: unknown) =&gt; {\n    // ...\n};\n</code></pre> <p>In v2, we improved tree-shaking support to help you reduce your function bundle size. We would love to hear your feedback on further improvements we could make.</p>"
        },
        {
            "location": "upgrade/#unable-to-use-esm",
            "title": "Unable to use ESM?",
            "text": "<p>We recommend using ESM for the best experience (top-level await, smaller bundle size etc.).</p> <p>If you're unable to use ESM, you can still use the <code>require</code> syntax to import the package. We will continue to support it by shipping CommonJS modules alongside ESM.</p> <p>You might still need the <code>require</code> syntax when using a dependency or a transitive dependency that doesn't support ESM. For example, Tracer (<code>@aws-lambda-powertools/tracer</code>) relies on the AWS X-Ray SDK for Node.js which uses <code>require</code>.</p> <p>When that happens, you can instruct your bundler to use the <code>require</code> syntax for specific dependencies while using ESM for everything else. This is commonly known as polyfill. Here is an example using <code>esbuild</code> bundler.</p> With AWS CDKWith AWS SAM <pre><code>import { Stack, type StackProps } from 'aws-cdk-lib';\nimport { Construct } from 'constructs';\nimport { NodejsFunction, OutputFormat } from 'aws-cdk-lib/aws-lambda-nodejs';\nimport { Runtime } from 'aws-cdk-lib/aws-lambda';\n\nexport class MyStack extends Stack {\n  public constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const handler = new NodejsFunction(this, 'helloWorldFunction', {\n      runtime: Runtime.NODEJS_22_X,\n      handler: 'handler',\n      entry: 'src/index.ts',\n      bundling: {\n        format: OutputFormat.ESM,\n        minify: true,\n        esbuildArgs: {\n          \"--tree-shaking\": \"true\",\n        },\n        banner: \n          \"import { createRequire } from 'module';const require = createRequire(import.meta.url);\", // (1)!\n      },\n    });\n  }\n}\n</code></pre> <ol> <li><code>esbuild</code> will include this arbitrary code at the top of your bundle to maximize CommonJS compatibility (<code>require</code> keyword).</li> </ol> <pre><code>Transform: AWS::Serverless-2016-10-31\nResources:\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Runtime: nodejs22.x\n      Handler: src/index.handler\n    Metadata:\n      BuildMethod: esbuild\n      BuildProperties:\n        Minify: true\n        Target: 'ES2020'\n        Sourcemap: true\n        Format: esm\n        EntryPoints:\n          - src/index.ts\n        Banner:\n          js: \"import { createRequire } from 'module';const require = createRequire(import.meta.url);\"  # (1)!\n</code></pre> <ol> <li><code>esbuild</code> will include this arbitrary code at the top of your bundle to maximize CommonJS compatibility (<code>require</code> keyword).</li> </ol>"
        },
        {
            "location": "upgrade/#scoped-imports",
            "title": "Scoped imports",
            "text": ""
        },
        {
            "location": "upgrade/#middyjs-middleware-imports",
            "title": "Middy.js middleware imports",
            "text": "Disregard if you are not using Middy.js middlewares. <p>In v2, we've added support for subpath exports. This means if you don't import Middy.js middlewares, you will benefit from a smaller bundle size.</p> <p>In v1, you could import Middy.js middlewares from the default export of a package (e.g., <code>logger</code>). For example, you'd import <code>injectLambdaContext</code> Logger middleware from <code>@aws-lambda-powertools/logger</code>.</p> <p>In v2, you can now import only the Middy.js middlewares you want to use from a subpath export, e.g., <code>@aws-lambda-powertools/logger/middleware</code>, leading to a smaller bundle size.</p> BeforeAfter <pre><code>import { Logger, injectLambdaContext } from '@aws-lambda-powertools/logger';\nimport { Tracer, captureLambdaHandler } from '@aws-lambda-powertools/tracer';\nimport { Metrics, logMetrics } from '@aws-lambda-powertools/metrics';\n</code></pre> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { injectLambdaContext } from '@aws-lambda-powertools/logger/middleware';\n\nimport { Tracer } from '@aws-lambda-powertools/tracer';\nimport { captureLambdaHandler } from '@aws-lambda-powertools/tracer/middleware';\n\nimport { Metrics } from '@aws-lambda-powertools/metrics';\nimport { logMetrics } from '@aws-lambda-powertools/metrics/middleware';\n</code></pre>"
        },
        {
            "location": "upgrade/#types-imports",
            "title": "Types imports",
            "text": "<p>In v1, you could import package types from each package under <code>/lib</code>, for example <code>@aws-lambda-powertools/logger/lib/types</code>.</p> <p>In v2, you can now directly import from the <code>types</code> subpath export, e.g., <code>@aws-lambda-powertools/logger/types</code>. This will optimize your bundle size, standardize types import across packages, future-proofing growth.</p> BeforeAfter <pre><code>import { LogAttributes, UnformattedAttributes } from '@aws-lambda-powertools/logger/lib/types';\n</code></pre> <pre><code>import { LogAttributes, UnformattedAttributes } from '@aws-lambda-powertools/logger/types';\n</code></pre>"
        },
        {
            "location": "upgrade/#using-eslint",
            "title": "Using eslint?",
            "text": "<p>When using <code>eslint</code>, you might need to use <code>@typescript-eslint/parser</code> and <code>eslint-plugin-import</code> to resolve the new subpath imports.</p> <p>Below is an example of how to configure your <code>.eslintrc.json</code> file:</p> <pre><code>{\n  \"parser\": \"@typescript-eslint/parser\",\n  \"settings\": {\n    \"import/resolver\": {\n      \"node\": {},\n      \"typescript\": {\n        \"project\": \"./tsconfig.json\",\n        \"alwaysTryTypes\": true,\n      },\n    },\n  },\n}\n</code></pre>"
        },
        {
            "location": "upgrade/#logger",
            "title": "Logger",
            "text": ""
        },
        {
            "location": "upgrade/#log-sampling",
            "title": "Log sampling",
            "text": "<p>Disregard if you are not using the log sampling feature.</p> <p>In v1, log sampling implementation was inconsistent from other Powertools for AWS Lambda languages (Python, .NET, and Java).</p> <p>In v2, we changed these behaviors for consistency across languages:</p> Behavior v1 v2 Log Level Log level remains unchanged but any log statement is printed Log level changes to <code>DEBUG</code> Log sampling indication No indication Debug message indicates sampling is in effect <p>Logger <code>sampleRateValue</code> continues to determine the percentage of concurrent/cold start invocations that logs will be sampled, e.g., log level set to <code>DEBUG</code>.</p>"
        },
        {
            "location": "upgrade/#custom-log-formatter",
            "title": "Custom log formatter",
            "text": "<p>Disregard if you are not customizing log output with a custom log formatter.</p> <p>In v1, <code>Logger</code> exposed the standard as a single argument, e.g., <code>formatAttributes(attributes: UnformattedAttributes)</code>. It expected a plain object with keys and values you wanted in the final log output.</p> <p>In v2, you have more control over standard (<code>attributes</code>) and custom keys (<code>additionalLogAttributes</code>) in the <code>formatAttributes</code> method. Also, you now return a <code>LogItem</code> object to increase type safety when defining the final log output.</p> BeforeAfter <pre><code>import { LogFormatter } from '@aws-lambda-powertools/logger';\nimport {\n  LogAttributes,\n  UnformattedAttributes,\n} from '@aws-lambda-powertools/logger/lib/types';\n\nclass MyCompanyLogFormatter extends LogFormatter {\n  public formatAttributes(attributes: UnformattedAttributes): LogAttributes {\n    return {\n      message: attributes.message,\n      service: attributes.serviceName,\n      environment: attributes.environment,\n      awsRegion: attributes.awsRegion,\n      correlationIds: {\n        awsRequestId: attributes.lambdaContext?.awsRequestId,\n        xRayTraceId: attributes.xRayTraceId,\n      },\n      lambdaFunction: {\n        name: attributes.lambdaContext?.functionName,\n        arn: attributes.lambdaContext?.invokedFunctionArn,\n        memoryLimitInMB: attributes.lambdaContext?.memoryLimitInMB,\n        version: attributes.lambdaContext?.functionVersion,\n        coldStart: attributes.lambdaContext?.coldStart,\n      },\n      logLevel: attributes.logLevel,\n      timestamp: this.formatTimestamp(attributes.timestamp),\n      logger: {\n        sampleRateValue: attributes.sampleRateValue,\n      },\n    };\n  }\n}\n\nexport { MyCompanyLogFormatter };\n</code></pre> <pre><code>import { LogFormatter, LogItem } from '@aws-lambda-powertools/logger';\nimport type { LogAttributes, UnformattedAttributes } from '@aws-lambda-powertools/logger/types';\n\nclass MyCompanyLogFormatter extends LogFormatter {\n  public formatAttributes(\n    attributes: UnformattedAttributes,\n    additionalLogAttributes: LogAttributes  // (1)!\n  ): LogItem {  // (2)!\n    const baseAttributes = {\n        message: attributes.message,\n        service: attributes.serviceName,\n        environment: attributes.environment,\n        awsRegion: attributes.awsRegion,\n        correlationIds: {\n            awsRequestId: attributes.lambdaContext?.awsRequestId,\n            xRayTraceId: attributes.xRayTraceId,\n        },\n        lambdaFunction: {\n            name: attributes.lambdaContext?.functionName,\n            arn: attributes.lambdaContext?.invokedFunctionArn,\n            memoryLimitInMB: attributes.lambdaContext?.memoryLimitInMB,\n            version: attributes.lambdaContext?.functionVersion,\n            coldStart: attributes.lambdaContext?.coldStart,\n        },\n        logLevel: attributes.logLevel,\n        timestamp: this.formatTimestamp(attributes.timestamp),\n        logger: {\n            sampleRateValue: attributes.sampleRateValue,\n        },\n    };\n\n    // Create a new LogItem with the base attributes\n    const logItem = new LogItem({ attributes: baseAttributes });\n\n    // Merge additional attributes\n    logItem.addAttributes(additionalLogAttributes); // (3)!\n\n    return logItem;\n  }\n}\n\nexport { MyCompanyLogFormatter };\n</code></pre> <ol> <li>This new argument contains all your custom keys.</li> <li><code>LogItem</code> is the new return object instead of a plain object.</li> <li>If you prefer adding at the initialization, use:  <code>LogItem({persistentAttributes: additionalLogAttributes, attributes: baseAttributes})</code></li> </ol>"
        },
        {
            "location": "upgrade/#contextexamples-for-testing",
            "title": "ContextExamples for testing",
            "text": "<p>In v1, we have provided a <code>ContextExamples</code> object to help you with testing.</p> <p>In v2, we have removed the <code>ContextExamples</code> from the <code>@aws-lambda-powertools/commons</code> package, so you need to create it in your tests:</p> BeforeAfter <pre><code>import { ContextExamples as dummyContext } from '@aws-lambda-powertools/commons';\n\ndescribe('MyUnitTest', () =&gt; {\n  test('Lambda invoked successfully', async () =&gt; {\n    const testEvent = { test: 'test' };\n    await handler(testEvent, dummyContext);\n  });\n});\n</code></pre> <pre><code>declare const handler: (event: unknown, context: unknown) =&gt; Promise&lt;void&gt;;\n\nconst context = {\n  callbackWaitsForEmptyEventLoop: true,\n  functionVersion: '$LATEST',\n  functionName: 'foo-bar-function',\n  memoryLimitInMB: '128',\n  logGroupName: '/aws/lambda/foo-bar-function-123456abcdef',\n  logStreamName: '2021/03/09/[$LATEST]abcdef123456abcdef123456abcdef123456',\n  invokedFunctionArn:\n  'arn:aws:lambda:eu-west-1:123456789012:function:foo-bar-function',\n  awsRequestId: 'c6af9ac6-7b61-11e6-9a41-93e812345678',\n  getRemainingTimeInMillis: () =&gt; 1234,\n  done: () =&gt; console.log('Done!'),\n  fail: () =&gt; console.log('Failed!'),\n  succeed: () =&gt; console.log('Succeeded!'),\n};\n\ndescribe('MyUnitTest', () =&gt; {\n  test('Lambda invoked successfully', async () =&gt; {\n    const testEvent = { test: 'test' };\n    await handler(testEvent, context);\n  });\n});\n</code></pre>"
        },
        {
            "location": "upgrade/#helper-functions",
            "title": "Helper functions",
            "text": "<p>We removed the deprecated <code>createLogger</code> and <code>createTracer</code> helper functions.</p> <pre><code>import { createLogger } from '@aws-lambda-powertools/logger';\nimport { createTracer } from '@aws-lambda-powertools/tracer';\n\nconst logger = createLogger({ logLevel: 'info' });\nconst tracer = createTracer({ serviceName: 'my-service' });\n</code></pre> <p>You can migrate to instantiating the <code>Logger</code> and <code>Tracer</code> classes directly with no additional changes.</p> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { Tracer } from '@aws-lambda-powertools/tracer';\n\nconst logger = new Logger({ logLevel: 'info' });\nconst tracer = new Tracer({ serviceName: 'my-service' });\n</code></pre>"
        },
        {
            "location": "versioning/",
            "title": "Versioning and maintenance policy",
            "text": ""
        },
        {
            "location": "versioning/#overview",
            "title": "Overview",
            "text": "<p>This document outlines the maintenance policy for Powertools for AWS Lambda and their underlying dependencies. AWS regularly provides Powertools for AWS Lambda with updates that may contain new features, enhancements, bug fixes, security patches, or documentation updates. Updates may also address changes with dependencies, language runtimes, and operating systems. Powertools for AWS Lambda is published to package managers (e.g. PyPi, NPM, Maven, NuGet), and are available as source code on GitHub.</p> <p>We recommend users to stay up-to-date with Powertools for AWS Lambda releases to keep up with the latest features, security updates, and underlying dependencies. Continued use of an unsupported Powertools for AWS Lambda version is not recommended and is done at the user’s discretion.</p> <p>For brevity, we will interchangeably refer to Powertools for AWS Lambda (TypeScript) as \"SDK\" (Software Development Toolkit).</p>"
        },
        {
            "location": "versioning/#versioning",
            "title": "Versioning",
            "text": "<p>Powertools for AWS Lambda release versions are in the form of X.Y.Z where X represents the major version. Increasing the major version of an SDK indicates that this SDK underwent significant and substantial changes to support new idioms and patterns in the language. Major versions are introduced when public interfaces (e.g. classes, methods, types, etc.), behaviors, or semantics have changed. Applications need to be updated in order for them to work with the newest SDK version. It is important to update major versions carefully and in accordance with the upgrade guidelines provided by AWS.</p>"
        },
        {
            "location": "versioning/#sdk-major-version-lifecycle",
            "title": "SDK major version lifecycle",
            "text": "<p>The lifecycle for major Powertools for AWS Lambda versions consists of 5 phases, which are outlined below.</p> <ul> <li>Developer Preview (Phase 0) - During this phase, SDKs are not supported, should not be used in production environments, and are meant for early access and feedback purposes only. It is possible for future releases to introduce breaking changes. Once AWS identifies a release to be a stable product, it may mark it as a Release Candidate. Release Candidates are ready for GA release unless significant bugs emerge, and will receive full AWS support.</li> <li>General Availability (GA) (Phase 1) - During this phase, SDKs are fully supported. AWS will provide regular SDK releases that include support for new features, enhancements, as well as bug and security fixes. AWS will support the GA version of an SDK for at least 12 months, unless otherwise specified.</li> <li>Maintenance Announcement (Phase 2) - AWS will make a public announcement at least 6 months before an SDK enters maintenance mode. During this period, the SDK will continue to be fully supported. Typically, maintenance mode is announced at the same time as the next major version is transitioned to GA.</li> <li>Maintenance (Phase 3) - During the maintenance mode, AWS limits SDK releases to address critical bug fixes and security issues only. An SDK will not receive API updates for new or existing services, or be updated to support new regions. Maintenance mode has a default duration of 6 months, unless otherwise specified.</li> <li>End-of-Support (Phase 4) - When an SDK reaches end-of support, it will no longer receive updates or releases. Previously published releases will continue to be available via public package managers and the code will remain on GitHub. The GitHub repository may be archived. Use of an SDK which has reached end-of-support is done at the user’s discretion. We recommend users upgrade to the new major version.</li> </ul> <p>Please note that the timelines shown below are illustrative and not binding</p> <p></p>"
        },
        {
            "location": "versioning/#dependency-lifecycle",
            "title": "Dependency lifecycle",
            "text": "<p>Most AWS SDKs have underlying dependencies, such as language runtimes, AWS Lambda runtime, or third party libraries and frameworks. These dependencies are typically tied to the language community or the vendor who owns that particular component. Each community or vendor publishes their own end-of-support schedule for their product.</p> <p>The following terms are used to classify underlying third party dependencies:</p> <ul> <li>AWS Lambda Runtime: Examples include <code>nodejs20.x</code>, <code>python3.12</code>, etc.</li> <li>Language Runtime: Examples include Python 3.12, NodeJS 20, Java 17, .NET Core, etc.</li> <li>Third party Library: Examples include Pydantic, AWS X-Ray SDK, AWS Encryption SDK, Middy.js, etc.</li> </ul> <p>Powertools for AWS Lambda follows the AWS Lambda Runtime deprecation policy cycle, when it comes to Language Runtime. This means we will stop supporting their respective deprecated Language Runtime (e.g., <code>nodejs20.x</code>) without increasing the major SDK version.</p> <p>AWS reserves the right to stop support for an underlying dependency without increasing the major SDK version</p>"
        },
        {
            "location": "versioning/#lambda-layer-lifecycle",
            "title": "Lambda layer lifecycle",
            "text": "<p>Powertools for AWS Lambda provides public Lambda layers as an alternative method for including the Powertools SDK into your Lambda functions.</p> <p>Unlike package indexers such as PyPi and NPMJS, which use semantic versioning (e.g., v1.2.3, v1.3.0), Lambda layers employs incrementing sequential versions (e.g., 1, 2, 3, 4). With each new release of the SDK, Powertools for AWS Lambda publishes an updated layer, including the SDK version in the layer description.</p> <p>Powertools for AWS Lambda layers are immutable and remain available beyond their end-of-life dates.</p> <p>Each Powertools for AWS Lambda layer adheres to the versioning policy outlined above.</p>"
        },
        {
            "location": "versioning/#communication-methods",
            "title": "Communication methods",
            "text": "<p>Maintenance announcements are communicated in several ways:</p> <ul> <li>A pinned GitHub Request For Comments (RFC) issue indicating the campaign for the next major version. The RFC will outline the path to end-of-support, specify campaign timelines, and upgrade guidance.</li> <li>AWS SDK documentation, such as API reference documentation, user guides, SDK product marketing pages, and GitHub readme(s) are updated to indicate the campaign timeline and provide guidance on upgrading affected applications.</li> <li>Deprecation warnings are added to the SDKs, outlining the path to end-of-support and linking to the upgrade guide.</li> </ul> <p>To see the list of available major versions of Powertools for AWS Lambda and where they are in their maintenance lifecycle, see version support matrix</p>"
        },
        {
            "location": "versioning/#version-support-matrix",
            "title": "Version support matrix",
            "text": "SDK Major version Current Phase General Availability Date Notes Powertools for AWS Lambda TypeScript 1.x End-of-life 09/01/2024 See announcement Powertools for AWS Lambda TypeScript 1.x Maintenance Announcement 03/13/2024 See announcement Powertools for AWS Lambda TypeScript 2.x General Availability 03/05/2024 See Release Notes Powertools for AWS Lambda TypeScript 1.x General Availability 07/15/2022 See Release Notes"
        },
        {
            "location": "we_made_this/",
            "title": "We Made This (Community)",
            "text": "<p>This space is dedicated to highlight our awesome community content featuring Powertools 🙏!</p> <p>Get your content featured here!</p>"
        },
        {
            "location": "we_made_this/#connect",
            "title": "Connect",
            "text": "<p>Join us on Discord to connect with the Powertools community 👋. Ask questions, learn from each other, contribute, hang out with key contributors, and more!</p>"
        },
        {
            "location": "we_made_this/#blog-posts",
            "title": "Blog posts",
            "text": ""
        },
        {
            "location": "we_made_this/#lambda-powertools-great-defaults-for-batteries-that-arent-quite-but-should-be-included",
            "title": "Lambda Powertools - great defaults for batteries that aren't quite (but should be) included",
            "text": "<p>Author: Mike Roberts </p> <p>This article discusses why you should consider using Powertools in your Lambda functions.</p> <ul> <li>https://blog.symphonia.io/posts/2022-10-24_lambda-powertools</li> </ul>"
        },
        {
            "location": "we_made_this/#test-drive-aws-lambda-powertools-for-typescript",
            "title": "Test Drive AWS Lambda Powertools for Typescript",
            "text": "<p>Author: Matt Lewis </p> <p>This article gives an overview Powertools' core utilities: Logger, Metrics, and Tracer.</p> <ul> <li>https://dev.to/aws-heroes/test-drive-aws-lambda-powertools-for-typescript-h3p</li> </ul>"
        },
        {
            "location": "we_made_this/#power-up-lambda-functions-with-aws-lambda-powertools-for-typescript",
            "title": "Power-up Lambda functions with AWS Lambda Powertools for TypeScript",
            "text": "<p>Author: Ryan Toler </p> <p>Discover how easy it is to quickly “power-up” your Node.js Lambda functions with utilities from AWS Lambda Powertools for TypeScript.</p> <ul> <li>https://www.trek10.com/blog/power-up-lambda-functions-with-aws-lambda-powertools-for-typescript</li> </ul>"
        },
        {
            "location": "we_made_this/#getting-to-well-architected-faster-with-aws-lambda-powertools",
            "title": "Getting to Well Architected Faster with AWS Lambda Powertools",
            "text": "<p>Author: Eoin Shanaghy </p> <p>This post shows how to use Powertools for AWS Lambda to quickly build Well-Architected Serverless applications.</p> <ul> <li>https://fourtheorem.com/aws-lambda-powertools/</li> </ul>"
        },
        {
            "location": "we_made_this/#aws-lambda-powertools-typescript",
            "title": "AWS Lambda Powertools TypeScript",
            "text": "<p>Author: Matt Morgan </p> <p>A two parts series that gives an overview of Powertools and its features starting from the beta phase to the General Availability release.</p> <ul> <li> <p>First Look at Lambda Powertools TypeScript</p> </li> <li> <p>Lambda Powertools TypeScript is Generally Available</p> </li> </ul>"
        },
        {
            "location": "we_made_this/#eventbridge-working-around-api-destination-5s-maximum-client-timeout-constraint-using-powertools-for-aws-lambda-idempotency",
            "title": "EventBridge: working around API Destination 5s maximum client timeout constraint, using Powertools for AWS Lambda Idempotency",
            "text": "<p>Author: Paul Santus </p> <p>This article discusses how to use the Idempotency feature to work around EventBridge API Destinations' built-in maximum client execution timeout (5s) and allow long-running queries, while still benefitting from automated retry and DLQ, and preventing concurrent calls.</p> <ul> <li>https://dev.to/aws-builders/eventbridge-working-around-api-destination-5s-maximum-client-timeout-constraint-using-lambda-powertools-idempotency-1cb3</li> </ul>"
        },
        {
            "location": "we_made_this/#videos",
            "title": "Videos",
            "text": ""
        },
        {
            "location": "we_made_this/#supercharge-lambda-functions-with-powertools-for-aws-lambda",
            "title": "Supercharge Lambda functions with Powertools for AWS Lambda",
            "text": "<p>Author: Raphael Manke </p> <p>An overview of all the Powertools for AWS Lambda features put into a real world example.</p>"
        },
        {
            "location": "we_made_this/#aws-reinvent-2024-gain-expert-level-knowledge-about-powertools-for-aws-lambda-opn402",
            "title": "AWS re:Invent 2024 - Gain expert-level knowledge about Powertools for AWS Lambda (OPN402)",
            "text": "<p>Author: Andrea Amorosi </p> <p>Did you learn serverless best practices but are unsure about implementation? Have you used Powertools for AWS Lambda but felt you barely scratched the surface? This session dives deep into observability practices, safe retries with idempotency, mono- and multi-function APIs, and more. Learn about each practice in depth, achieve expert-level knowledge, and hear from maintainers about what’s next.</p>"
        },
        {
            "location": "contributing/conventions/",
            "title": "Conventions",
            "text": ""
        },
        {
            "location": "contributing/conventions/#general-terminology-and-practices",
            "title": "General terminology and practices",
            "text": "<p>These are common conventions we keep on building as the project gains new contributors and grows in complexity.</p> <p>As we gather more concrete examples, this page will have one section for each category to demonstrate a before and after.</p> Category Convention Docstring We use TypeDoc annotations to help generate more readable API references. For public APIs, we always include at least one Example to ease everyone's experience when using an IDE. Style guide We use Biome for linting and formatting to enforce beyond good practices. We use TypeScript types, function return types, and access modifiers to convey intent. Core utilities Core utilities always accept <code>serviceName</code> as a constructor parameter, can work in isolation, and are also available in other languages implementation. Utilities Utilities are not as strict as core and focus on community needs: development productivity, industry leading practices, etc. Both core and general utilities follow our Tenets. Errors Specific errors thrown by Powertools live within utilities themselves and use <code>Error</code> suffix e.g. <code>IdempotencyKeyError</code>. Git commits We follow conventional commits. We do not enforce conventional commits on contributors to lower the entry bar. Instead, we enforce a conventional PR title so our label automation and changelog are generated correctly. API documentation API reference docs are generated from docstrings which should have Examples section to allow developers to have what they need within their own IDE. Documentation website covers the wider usage, tips, and strive to be concise. Documentation We treat it like a product. We sub-divide content aimed at getting started (80% of customers) vs advanced usage (20%). We also ensure customers know how to unit test their code when using our features."
        },
        {
            "location": "contributing/conventions/#repository-structure",
            "title": "Repository structure",
            "text": "<p>The repository uses a monorepo structure managed using npm workspaces. This allows us to keep all code in one place and share common dependencies.</p> <p>The Powertools for AWS Lambda (TypeScript) repository utilities live under the <code>packages/</code> directory. Each utility is a separate package and has its own <code>package.json</code> file. For example, the <code>@aws-lambda-powertools/logger</code> source code can be found under the <code>packages/logger/src</code> directory.</p> <p>Whenever possible, we use the same directory structure for all utilities. This makes it easier for contributors to navigate the repository and find what they need.</p> <p>Additionally, we try to share common runtime code between utilities to reduce maintenance overhead and runtime footprint. The shared runtime code lives under the <code>packages/commons/src</code> directory and is published to npm as the <code>@aws-lambda-powertools/commons</code> package.</p> <p>There are also a few other workspaces that are not utilities published to npm, but that still share dependencies and/or runtime code with the utilities. These workspaces are:</p> <ul> <li><code>examples/snippets</code>: contains the documentation code snippets</li> <li><code>examples/app</code>: contains an example project that can be deployed via AWS CDK or AWS SAM</li> <li><code>layers</code>: contains the code used to build and publish the Lambda layers</li> </ul>"
        },
        {
            "location": "contributing/conventions/#testing-definition",
            "title": "Testing definition",
            "text": "<p>We group tests in different categories</p> Test When to write Notes Speed Unit tests Verify the smallest possible unit works. Networking access is prohibited. Keep mocks and spies at minimum. Fast (ms to few seconds at worst) End-to-end tests Gain confidence that a Lambda function with our code operates as expected. Also referred to as integration tests. It simulates how customers configure, deploy, and run their Lambda function - Event Source configuration, IAM permissions, etc. Slow (minutes) Performance tests Ensure critical operations won't increase latency and costs to customers. CI arbitrary hardware can make it flaky. We'll resume writing perf test after we revamp our unit/functional tests with internal utilities. Fast to moderate (a few seconds to a few minutes)"
        },
        {
            "location": "contributing/getting_started/",
            "title": "Your first contribution",
            "text": "<p>Thank you for your interest in contributing to our project - we couldn't be more excited!</p> <p> <pre><code>graph LR\n    Learn[\"Learn about contributions\"] --&gt; Find[\"Find areas to work / get mentoring\"] --&gt; Work[\"Prepare pull request\"] --&gt; Closing[\"Take learnings with you\"]</code></pre> End-to-end process </p>"
        },
        {
            "location": "contributing/getting_started/#types-of-contributions",
            "title": "Types of contributions",
            "text": "<p>We consider any contribution that help this project improve everyone's experience to be valid, as long as you agree with our tenets, licensing, and Code of Conduct.</p> <p>Whether you're new contributor or a pro, we compiled a list of the common contributions to help you choose your first:</p> <p>Please check existing open, or recently closed issues before creating a new one.</p> <p>Each type link goes to their respective template, or Discord invite.</p> Type Description Documentation Ideas to make user guide or API guide clearer. This includes typos, diagrams, tutorials, the lack of documentation, etc. Feature request New functionalities or enhancements that could help you, your team, or existing and future customers. Check out our process to understand how we prioritize it. Design proposals Request for Comments (RFC) including user experience (UX) based on a feature request to gather the community feedback, and demonstrate the art of the possible. Bug report A runtime error that is reproducible whether you have an idea how to solve it or not. Advocacy Share what you did with Powertools for AWS Lambda. Blog posts, workshops, presentation, sample applications, podcasts, etc. Public reference Become a public reference to share how you're using Powertools for AWS Lambda at your organization. Discussions Kick off a discussion on Discord, introduce yourself, and help respond to existing questions from the community. Maintenance Suggest areas to address technical debt, governance, and anything internal. Generally used by maintainers and contributors."
        },
        {
            "location": "contributing/getting_started/#finding-contributions-to-work-on",
            "title": "Finding contributions to work on",
            "text": "<p>Besides suggesting ideas you think it'll improve everyone's experience, these are the most common places to find work:</p> Area Description Help wanted issues These are triaged areas that we'd appreciate any level of contribution - from opinions to actual implementation. Missing customer feedback issues These are items we'd like to hear from more customers before making any decision. Sharing your thoughts, use case, or asking additional questions are great help. Pending design proposals These are feature requests that initially look good but need a RFC to enrich the discussion by validating user-experience, tradeoffs, and highlight use cases. Backlog items We use GitHub projects to surface what we're working on, needs triage, etc. This view shows items we already triaged but don't have the bandwidth to tackle them just yet. Documentation Documentation can always be improved. Look for areas that a better example, or a diagram, or more context helps everyone - keep in mind a diverse audience and English as a second language folks. Participate in discussions There's always a discussion that could benefit others in the form of documentation, blog post, etc. Roadmap Some roadmap items need a RFC to discuss design options, or gather customers use case before we can prioritize it. Build a sample application Using Powertools for AWS Lambda in different contexts will give you insights on what could be made easier, which documentation could be enriched, and more. <p>Still couldn't find anything that match your skill set?</p> <p>Please reach out on Discord, specially if you'd like to get mentoring for a task you'd like to take but you don't feel ready yet </p> <p>Contributions are meant to be bi-directional. There's always something we can learn from each other.</p>"
        },
        {
            "location": "contributing/getting_started/#sending-a-pull-request",
            "title": "Sending a pull request",
            "text": "<p>First time creating a Pull Request? Keep this document handy.</p> <p>Before sending us a pull request, please ensure that:</p> <ul> <li>You are working against the latest source on the main branch, unless instructed otherwise.</li> <li>You check existing open, and recently merged pull requests to make sure someone else hasn't addressed the problem already.</li> <li>You discuss and agree the proposed changes under an existing issue or a new one before you begin any implementation. We value your time and bandwidth. As such, any pull requests created on non-triaged issues might not be successful.</li> <li>Create a new branch named after the change you are contributing e.g. <code>feat/logger-debug-sampling</code></li> </ul> <p>Ready?</p> <p>These are the steps to send a pull request:</p> <ol> <li>Make sure that all formatting, linting, and tests tasks run as git pre-commit &amp; pre-push hooks are passing.</li> <li>Commit to your fork using clear commit messages. Don't worry about typos or format, we squash all commits during merge.</li> <li>Send us a pull request with a conventional semantic title - see full list of scopes and actions here.</li> <li>Fill in the areas pre-defined in the pull request body to help expedite reviewing your work.</li> <li>Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation.</li> </ol>"
        },
        {
            "location": "contributing/getting_started/#code-of-conduct",
            "title": "Code of Conduct",
            "text": "<p>This project has adopted the Amazon Open Source Code of Conduct</p> <p>For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.</p>"
        },
        {
            "location": "contributing/getting_started/#security-issue-notifications",
            "title": "Security issue notifications",
            "text": "<p>If you discover a potential security issue in this project, we kindly ask you to notify AWS/Amazon Security via our vulnerability reporting page. Please do not create a public github issue.</p>"
        },
        {
            "location": "contributing/setup/",
            "title": "Development environment",
            "text": "<p>This page describes how to setup your development environment (Cloud or locally) to contribute to Powertools for AWS Lambda (TypeScript).</p> <p> <pre><code>graph LR\n    Dev[\"Development environment\"] --&gt; Quality[\"Run quality checks locally\"] --&gt; PR[\"Prepare pull request\"] --&gt; Collaborate</code></pre> End-to-end process </p>"
        },
        {
            "location": "contributing/setup/#requirements",
            "title": "Requirements",
            "text": "<p>First time contributing to an open-source project ever?</p> <p>Read this introduction on how to fork and clone a project on GitHub.</p> <p>Unless you're using the pre-configured Cloud environment, you'll need the following installed:</p> <ul> <li>GitHub account. You'll need to be able to fork, clone, and contribute via pull request.</li> <li>Node.js 22.x. The repository contains an <code>.nvmrc</code> file, so if you use tools like nvm, fnm you can switch version quickly.</li> <li>npm 10.x. We use it to install dependencies and manage the workspaces.</li> <li>Docker. We use it to run documentation, and non-JavaScript tooling.</li> <li>Fork the repository. You'll work against your fork of this repository.</li> </ul> Additional requirements if running end-to-end tests <ul> <li>AWS Account bootstrapped with CDK</li> <li>AWS CLI installed and configured</li> </ul>"
        },
        {
            "location": "contributing/setup/#cloud-environment",
            "title": "Cloud environment",
            "text": "<p>A word of caution</p> <p>Before using one of the services below check out their pricing. You can find more information about each service pricing respectively on Gitpod and GitHub Codespaces pages.</p> <p>Once provisioned, each Cloud environment will come with all development dependencies and tools you'll need to contribute already installed.</p>"
        },
        {
            "location": "contributing/setup/#gitpod",
            "title": "Gitpod",
            "text": "<p>To use a pre-configured Gitpod environment, create or login to a Gitpod account, then replace <code>YOUR_USERNAME</code> with your GitHub username or organization.</p> <pre><code>https://gitpod.io/#https://github.com/YOUR_USERNAME/powertools-lambda-typescript  #(1)!\n</code></pre> <ol> <li>For example, if your username is <code>octocat</code>, then the final URL should be <code>https://gitpod.io/#https://github.com/octocat/powertools-lambda-typescript</code></li> </ol>"
        },
        {
            "location": "contributing/setup/#github-codespaces",
            "title": "GitHub Codespaces",
            "text": "<p>To use a pre-configured GitHub Codespaces environment, navigate to your fork of the repository, then click on the green <code>Code</code> button, and select <code>Create codespace on &lt;branch_name&gt;</code> under the <code>Codespaces</code> tab (where <code>&lt;branch_name&gt;</code> is the branch you want to work on).</p>"
        },
        {
            "location": "contributing/setup/#local-environment",
            "title": "Local environment",
            "text": "<p>Assuming you've got all requirements.</p> <p>You can use <code>npm run setup-local</code> to install all dependencies locally and setup pre-commit hooks.</p> <p>Curious about what <code>setup-local</code> does under the hood?</p> <p>We use npm scripts to automate common tasks locally and in Continuous Integration environments.</p>"
        },
        {
            "location": "contributing/setup/#local-documentation",
            "title": "Local documentation",
            "text": "<p>You might find useful to run both the documentation website and the API reference locally while contributing:</p>"
        },
        {
            "location": "contributing/setup/#using-docker-recommended",
            "title": "Using Docker (recommended)",
            "text": "<ol> <li>Build the Docker image (only needed the first time):</li> </ol> <pre><code>npm run docs:docker:build\n</code></pre> <ol> <li>Run the documentation website:</li> </ol> <pre><code>npm run docs:docker:run\n</code></pre>"
        },
        {
            "location": "contributing/setup/#using-python-directly",
            "title": "Using Python directly",
            "text": "<p>If you have Python installed, you can run the documentation website and API reference locally without Docker:</p> <ol> <li>Create a virtual environment and install dependencies:</li> </ol> <pre><code>npm run docs:local:setup\n</code></pre> <ol> <li>Run the documentation website:</li> </ol> <pre><code>npm run docs:local:run\n</code></pre>"
        },
        {
            "location": "contributing/testing/",
            "title": "Testing",
            "text": ""
        },
        {
            "location": "contributing/testing/#general-practices",
            "title": "General practices",
            "text": "<p>As discussed in the conventions page, we have different types of tests that aim to verify different aspects of the code.</p> <p>Tests are defined alongside the code they test, and can be found under the <code>tests</code> folder of each module. For example, the tests for the <code>@aws-lambda-powertools/logger</code> module can be found under <code>packages/logger/tests</code>.</p> <p>Each test type has its own folder, and each test file is named after the feature it tests. For example, the tests for the <code>@aws-lambda-powertools/logger</code> module can be found under <code>packages/logger/tests/unit</code> and <code>packages/logger/tests/e2e</code>.</p> <p>Tests use Vitest as test runner and are grouped by packages and type. You can run each group separately or all together by passing extra arguments to the test command.</p> <p>The test file should contain one or more tests organized using the <code>describe</code> and <code>it</code> functions. Each test should be named after the feature it tests, and should be as descriptive as possible. For example, the test for the <code>Logger</code> class <code>info</code> method is named <code>should log info message</code>.</p> <pre><code>describe('Class: Logger', () =&gt; {\n  describe('Method: info', () =&gt; {\n    it('should log info message', () =&gt; {\n      // ...\n    })\n  })\n})\n</code></pre> <p>Single tests should be as simple as possible, and should follow the Prepare, Act, Assess pattern. For example, the test from the previous example should look like this:</p> <pre><code>describe('Class: Logger', () =&gt; {\n  describe('Method: info', () =&gt; {\n    it('should log info message', () =&gt; {\n      // Prepare\n      const logger = new Logger()\n\n      // Act\n      logger.info('test')\n\n      // Assess\n      expect(logger.info).toHaveBeenCalledWith('test')\n    })\n  })\n})\n</code></pre>"
        },
        {
            "location": "contributing/testing/#unit-tests",
            "title": "Unit tests",
            "text": "<p>Unit tests are used to verify the smallest possible unit of code works as expected. They are fast to run and should be used to test the core logic of the code. They should not test external dependencies, such as network calls, and should use mocks and spies as needed to verify the code behaves as expected.</p> <p>When writing unit tests, you should follow the same conventions we use for the code. For example, each test file should correspond to a single discrete feature such as a single high-level function, class, or middleware. For example, the <code>Logger</code> class for the <code>@aws-lambda-powertools/logger</code> module has a single test file named <code>logger.test.ts</code>.</p> <p>To run unit tests, you can use of the following commands from the root folder:</p> <ul> <li><code>npm test -ws</code> to run all the unit tests for all the modules sequentially</li> <li><code>npm run test:parallel</code> to run all the unit tests for all the modules in parallel</li> <li><code>npm test -w packages/metrics</code> to run all the unit tests for the <code>metrics</code> module</li> </ul> <p>We enforce 100% code coverage for unit tests. The test command will fail if the coverage is not 100% both on your local machine and in CI.</p>"
        },
        {
            "location": "contributing/testing/#integration-tests",
            "title": "Integration tests",
            "text": "<p>Integration tests are used to verify that the code works as expected when deployed to AWS. They are slower than unit tests, and should be used to test the code in a real environment. They should test the code as a whole, including external dependencies such as network calls, and should not use mocks and spies.</p> <p>When writing integration tests, you should follow the same conventions used for existing tests. For example, each test file should correspond to an utility and a specific usage type. For example, the test for the middleware usage for the <code>@aws-lambda-powertools/logger</code> module has a single test file named <code>basicFeatures.middy.test.ts</code>.</p> <p>A word of caution</p> <p>Running integration tests will deploy AWS resources in your AWS account, which might incur costs. The cost from some services are covered by the AWS Free Tier but not all of them. We recommend you to use a dedicated AWS account for testing purposes, and when in doubt, let the CI on our repository run the tests for you.</p> <p>To run integration tests you'll need to set up an AWS account and obtain credentials as described in the prerequisites. Once ready, you can use of the following commands from the root folder:</p> <ul> <li><code>npm test:e2e -ws</code> to run all the integration tests for all the modules sequentially</li> <li><code>test:e2e:parallel</code> to run all the integration tests for all the modules in parallel</li> <li><code>npm test:e2e -w packages/metrics</code> to run all the integration tests for the <code>metrics</code> module</li> <li><code>npm run test:e2e:nodejs22x -w packages/metrics</code> to run all the integration tests for the <code>metrics</code> module using the <code>nodejs22x</code> runtime</li> </ul> <p>The tests will deploy the necessary AWS resources using AWS CDK, and will run the Lambda functions using the AWS SDK. After that, the tests will verify the Lambda functions behave as expected by checking logs, metrics, traces, and other resources as needed. Finally, the tests will destroy all the AWS resources created at the beginning.</p> <p>Below is a diagram that shows the flow of the integration tests:</p> <pre><code>sequenceDiagram\n    Dev Environment / CI-&gt;&gt;+Vitest: npm run test:e2e\n    Vitest--&gt;Vitest: Synthetize CloudFormation Stack\n    Vitest-&gt;&gt;+AWS: Deploy Stack\n    Vitest-&gt;&gt;+AWS: Invoke Lambda function\n    AWS-&gt;&gt;Vitest: Report logs / results\n    Vitest--&gt;Vitest: Assert logs/result\n    Vitest-&gt;&gt;+AWS: Destroy Stack\n    Vitest-&gt;&gt;+Dev Environment / CI: show test results</code></pre>"
        },
        {
            "location": "core/logger/",
            "title": "Logger",
            "text": "<p>Logger provides an opinionated logger with output structured as JSON.</p>"
        },
        {
            "location": "core/logger/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Capturing key fields from the Lambda context, cold starts, and structure logging output as JSON.</li> <li>Logging Lambda invocation events when instructed (disabled by default).</li> <li>Switch log level to <code>DEBUG</code> for a percentage of invocations (sampling).</li> <li>Buffering logs for a specific request or invocation, and flushing them automatically on error or manually as needed.</li> <li>Appending additional keys to structured logs at any point in time.</li> <li>Providing a custom log formatter (Bring Your Own Formatter) to output logs in a structure compatible with your organization’s Logging RFC.</li> </ul> Logger showcase - Log attributes"
        },
        {
            "location": "core/logger/#getting-started",
            "title": "Getting started",
            "text": ""
        },
        {
            "location": "core/logger/#installation",
            "title": "Installation",
            "text": "<p>Install the library in your project:</p> <pre><code>npm install @aws-lambda-powertools/logger\n</code></pre>"
        },
        {
            "location": "core/logger/#usage",
            "title": "Usage",
            "text": "<p>The <code>Logger</code> utility must always be instantiated outside the Lambda handler. By doing this, subsequent invocations processed by the same instance of your function can reuse these resources. This saves cost by reducing function run time. In addition, <code>Logger</code> can keep track of a cold start and inject the appropriate fields into logs.</p> handler.ts <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger({ serviceName: 'serverlessAirline' });\n\nexport const handler = async (_event, _context): Promise&lt;void&gt; =&gt; {\n  logger.info('Hello World');\n};\n</code></pre>"
        },
        {
            "location": "core/logger/#utility-settings",
            "title": "Utility settings",
            "text": "<p>The library has three optional settings, which can be set via environment variables or passed in the constructor.</p> <p>These settings will be used across all logs emitted:</p> Setting Description Environment variable Default Value Allowed Values Example Value Constructor parameter Service name Sets the name of service of which the Lambda function is part of, that will be present across all log statements <code>POWERTOOLS_SERVICE_NAME</code> <code>service_undefined</code> Any string <code>serverlessAirline</code> <code>serviceName</code> Logging level Sets how verbose Logger should be, from the most verbose to the least verbose (no logs) <code>POWERTOOLS_LOG_LEVEL</code> <code>INFO</code> <code>DEBUG</code>, <code>INFO</code>, <code>WARN</code>, <code>ERROR</code>, <code>CRITICAL</code>, <code>SILENT</code> <code>ERROR</code> <code>logLevel</code> Sample rate Probability that a Lambda invocation will print all the log items regardless of the log level setting <code>POWERTOOLS_LOGGER_SAMPLE_RATE</code> <code>0</code> <code>0.0</code> to <code>1.0</code> <code>0.1</code> <code>sampleRateValue</code> Info <p>When <code>POWERTOOLS_DEV</code> environment variable is present and set to <code>\"true\"</code> or <code>\"1\"</code>, Logger will pretty-print log messages for easier readability. We recommend to use this setting only when debugging on local environments.</p> <p>See all environment variables in the Environment variables section. Check API docs to learn more about Logger constructor options.</p>"
        },
        {
            "location": "core/logger/#example-using-aws-serverless-application-model-sam",
            "title": "Example using AWS Serverless Application Model (SAM)",
            "text": "handler.tstemplate.yaml <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\n// Logger parameters fetched from the environment variables (see template.yaml tab)\nconst logger = new Logger();\nlogger.info('Hello World');\n\n// You can also pass the parameters in the constructor\n// const logger = new Logger({\n//     logLevel: 'WARN',\n//     serviceName: 'serverlessAirline'\n// });\n</code></pre> <pre><code>Resources:\n  ShoppingCartApiFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Runtime: nodejs22.x\n      Environment:\n        Variables:\n          POWERTOOLS_LOG_LEVEL: WARN\n          POWERTOOLS_SERVICE_NAME: serverlessAirline\n</code></pre>"
        },
        {
            "location": "core/logger/#standard-structured-keys",
            "title": "Standard structured keys",
            "text": "<p>Your Logger will include the following keys to your structured logging (default log formatter):</p> Key Example Note level: <code>string</code> <code>INFO</code> Logging level set for the Lambda function's invocation message: <code>string</code> <code>Query performed to DynamoDB</code> A descriptive, human-readable representation of this log item sampling_rate: <code>float</code> <code>0.1</code> When enabled, it prints all the logs of a percentage of invocations, e.g. 10% service: <code>string</code> <code>serverlessAirline</code> A unique name identifier of the service this Lambda function belongs to, by default <code>service_undefined</code> timestamp: <code>string</code> <code>2011-10-05T14:48:00.000Z</code> Timestamp string in simplified extended ISO format (ISO 8601) xray_trace_id: <code>string</code> <code>1-5759e988-bd862e3fe1be46a994272793</code> X-Ray Trace ID. This value is always presented in Lambda environment, whether tracing is enabled or not. Logger will always log this value. error: <code>Object</code> <code>{ name: \"Error\", location: \"/my-project/handler.ts:18\", message: \"Unexpected error #1\", stack: \"[stacktrace]\"}</code> Optional - An object containing information about the Error passed to the logger Note <p>If you emit a log message with a key that matches one of <code>level</code>, <code>message</code>, <code>sampling_rate</code>, <code>service</code>, or <code>timestamp</code>, the Logger will log a warning message and ignore the key.</p>"
        },
        {
            "location": "core/logger/#capturing-lambda-context-info",
            "title": "Capturing Lambda context info",
            "text": "<p>You can enrich your structured logs with key Lambda context information in multiple ways.</p> <p>This functionality will include the following keys in your structured logs:</p> Key Example cold_start: <code>bool</code> <code>false</code> function_name <code>string</code> <code>shopping-cart-api-lambda-prod-eu-west-1</code> function_memory_size: <code>number</code> <code>128</code> function_arn: <code>string</code> <code>arn:aws:lambda:eu-west-1:123456789012:function:shopping-cart-api-lambda-prod-eu-west-1</code> function_request_id: <code>string</code> <code>c6af9ac6-7b61-11e6-9a41-93e812345678</code> Middy MiddlewareDecoratorManual <p>A note about Middy</p> <p>We guarantee support for Middy.js <code>v4.x</code> through <code>v6.x</code> versions. Check their docs to learn more about Middy and its middleware stack as well as best practices when working with Powertools.</p> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { injectLambdaContext } from '@aws-lambda-powertools/logger/middleware';\nimport middy from '@middy/core';\n\nconst logger = new Logger();\n\nconst lambdaHandler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  logger.info('This is an INFO log with some context');\n};\n\nexport const handler = middy(lambdaHandler).use(injectLambdaContext(logger));\n</code></pre> <p>Note</p> <p>The class method decorators in this project follow the experimental implementation enabled via the <code>experimentalDecorators</code> compiler option in TypeScript.</p> <p>Additionally, they are implemented to decorate async methods. When decorating a synchronous one, the decorator replaces its implementation with an async one causing the caller to have to <code>await</code> the now decorated method.</p> <p>If this is not the desired behavior, you can call the <code>logger.injectLambdaContext()</code> method directly in your handler.</p> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger();\n\nclass Lambda implements LambdaInterface {\n  // Decorate your handler class method\n  @logger.injectLambdaContext()\n  public async handler(_event: unknown, _context: unknown): Promise&lt;void&gt; {\n    logger.info('This is an INFO log with some context');\n  }\n}\n\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction); // (1)\n</code></pre> <ol> <li>Binding your handler method allows your handler to access <code>this</code> within the class methods.</li> </ol> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport type { Context } from 'aws-lambda';\n\nconst logger = new Logger();\n\nexport const handler = async (\n  _event: unknown,\n  context: Context\n): Promise&lt;void&gt; =&gt; {\n  logger.addContext(context);\n\n  logger.info('This is an INFO log with some context');\n};\n</code></pre> <p>In each case, the printed log will look like this:</p> Example CloudWatch Logs excerpt <pre><code>{\n    \"level\": \"INFO\",\n    \"message\": \"This is an INFO log with some context\",\n    \"timestamp\": \"2021-12-12T21:21:08.921Z\",\n    \"service\": \"serverlessAirline\",\n    \"cold_start\": true,\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:123456789012:function:shopping-cart-api-lambda-prod-eu-west-1\",\n    \"function_memory_size\": 128,\n    \"function_request_id\": \"c6af9ac6-7b61-11e6-9a41-93e812345678\",\n    \"function_name\": \"shopping-cart-api-lambda-prod-eu-west-1\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#log-incoming-event",
            "title": "Log incoming event",
            "text": "<p>When debugging in non-production environments, you can log the incoming event using the <code>logEventIfEnabled()</code> method or by setting the <code>logEvent</code> option in the <code>injectLambdaContext()</code> Middy.js middleware or class method decorator.</p> Warning <p>This is disabled by default to prevent sensitive info being logged</p> <code>logEventIfEnabled()</code>Middy.js MiddlewareDecoratorpayload.jsonCloudWatch output <pre><code>process.env.POWERTOOLS_LOGGER_LOG_EVENT = 'true';\n\nimport { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger();\n\nexport const handler = async (event: unknown) =&gt; {\n  logger.logEventIfEnabled(event); // (1)\n  // ... your logic here\n};\n</code></pre> <ol> <li>You can control the event logging via the <code>POWERTOOLS_LOGGER_LOG_EVENT</code> environment variable.</li> </ol> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { injectLambdaContext } from '@aws-lambda-powertools/logger/middleware';\nimport middy from '@middy/core';\n\nconst logger = new Logger();\n\nexport const handler = middy(async () =&gt; {\n  // ... your logic here\n}).use(\n  injectLambdaContext(logger, { logEvent: true }) // (1)\n);\n</code></pre> <ol> <li>The <code>logEvent</code> option takes precedence over the <code>POWERTOOLS_LOGGER_LOG_EVENT</code> environment variable.</li> </ol> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger();\n\nclass Lambda implements LambdaInterface {\n  @logger.injectLambdaContext({ logEvent: true }) // (1)\n  public async handler(_event: unknown, _context: unknown): Promise&lt;void&gt; {\n    // ... your logic here\n  }\n}\n\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\n</code></pre> <ol> <li>The <code>logEvent</code> option takes precedence over the <code>POWERTOOLS_LOGGER_LOG_EVENT</code> environment variable.</li> </ol> <pre><code>{\n  \"foo\": \"bar\"\n}\n</code></pre> <pre><code>{\n  \"cold_start\": true,\n  \"function_arn\": \"arn:aws:lambda:eu-west-1:123456789012:function:LogEventFn\",\n  \"function_memory_size\": \"128\",\n  \"function_name\": \"LogEventFn\",\n  \"function_request_id\": \"0a9df60d-e2de-447d-ba3e-45f149eae6c9\",\n  \"level\": \"INFO\",\n  \"message\": \"Lambda invocation event\",\n  \"sampling_rate\": 0,\n  \"service\": \"service_undefined\",\n  \"timestamp\": \"2024-08-14T10:08:06.199Z\",\n  \"xray_trace_id\": \"1-66bc8205-21f8b5190da519d22b2b0533\",\n  \"event\": {\n    \"foo\": \"bar\"\n  }\n}\n</code></pre> <p>Use <code>POWERTOOLS_LOGGER_LOG_EVENT</code> environment variable to enable or disable (<code>true</code>/<code>false</code>) this feature. When using Middy.js middleware or class method decorator, the <code>logEvent</code> option will take precedence over the environment variable.</p>"
        },
        {
            "location": "core/logger/#setting-a-correlation-id",
            "title": "Setting a Correlation ID",
            "text": "<p>To get started, install the <code>@aws-lambda-powertools/jmespath</code> package, and pass the search function using the <code>correlationIdSearchFn</code> constructor parameter:</p> Setup the Logger to use JMESPath search <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { search } from '@aws-lambda-powertools/logger/correlationId';\n\nconst logger = new Logger({\n  correlationIdSearchFn: search,\n});\n</code></pre> Tip <p>You can retrieve correlation IDs via <code>getCorrelationId</code> method.</p> <p>You can set a correlation ID using <code>correlationIdPath</code> parameter by passing a JMESPath expression, including our custom JMESPath functions or set it manually by calling <code>setCorrelationId</code> function.</p> Setting correlation ID manuallyMiddy.jsDecoratorpayload.jsonlog-output.json <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport type { APIGatewayProxyEvent } from 'aws-lambda';\n\nconst logger = new Logger();\n\nexport const handler = async (event: APIGatewayProxyEvent) =&gt; {\n  logger.setCorrelationId(event.requestContext.requestId); // (1)!\n\n  logger.info('log with correlation_id');\n};\n</code></pre> <ol> <li>Alternatively, if the payload is more complex you can use a JMESPath expression as second parameter when prividing a search function in the constructor.</li> </ol> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { search } from '@aws-lambda-powertools/logger/correlationId';\nimport { injectLambdaContext } from '@aws-lambda-powertools/logger/middleware';\nimport middy from '@middy/core';\n\nconst logger = new Logger({\n  correlationIdSearchFn: search,\n});\n\nexport const handler = middy()\n  .use(\n    injectLambdaContext(logger, {\n      correlationIdPath: 'headers.my_request_id_header',\n    })\n  )\n  .handler(async () =&gt; {\n    logger.info('log with correlation_id');\n  });\n</code></pre> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport { search } from '@aws-lambda-powertools/logger/correlationId';\n\nconst logger = new Logger({\n  correlationIdSearchFn: search,\n});\n\nclass Lambda implements LambdaInterface {\n  @logger.injectLambdaContext({\n    correlationIdPath: 'headers.my_request_id_header',\n  })\n  public async handler(_event: unknown, _context: unknown): Promise&lt;void&gt; {\n    logger.info('This is an INFO log with some context');\n  }\n}\n\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\n</code></pre> <pre><code>{\n  \"headers\": {\n    \"my_request_id_header\": \"correlation_id_value\"\n  }\n}\n</code></pre> <pre><code>{\n  \"level\": \"INFO\",\n  \"message\": \"This is an INFO log with some context\",\n  \"timestamp\": \"2021-05-03 11:47:12,494+0000\",\n  \"service\": \"payment\",\n  \"correlation_id\": \"correlation_id_value\"\n}\n</code></pre> <p>To ease routine tasks like extracting correlation ID from popular event sources, we provide built-in JMESPath expressions.</p> Decorator <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport {\n  correlationPaths,\n  search,\n} from '@aws-lambda-powertools/logger/correlationId';\n\nconst logger = new Logger({\n  correlationIdSearchFn: search,\n});\n\nclass Lambda implements LambdaInterface {\n  @logger.injectLambdaContext({\n    correlationIdPath: correlationPaths.API_GATEWAY_REST,\n  })\n  public async handler(_event: unknown, _context: unknown): Promise&lt;void&gt; {\n    logger.info('This is an INFO log with some context');\n  }\n}\n\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\n</code></pre> Note: Any object key named with <code>-</code> must be escaped <p>For example, <code>request.headers.\"x-amzn-trace-id\"</code>.</p> Name Expression Description API_GATEWAY_REST <code>'requestContext.requestId'</code> API Gateway REST API request ID API_GATEWAY_HTTP <code>'requestContext.requestId'</code> API Gateway HTTP API request ID APPSYNC_AUTHORIZER <code>'requestContext.requestId'</code> AppSync resolver request ID APPSYNC_RESOLVER <code>'request.headers.\"x-amzn-trace-id\"'</code> AppSync X-Ray Trace ID APPLICATION_LOAD_BALANCER <code>'headers.\"x-amzn-trace-id\"'</code> ALB X-Ray Trace ID EVENT_BRIDGE <code>'id'</code> EventBridge Event ID LAMBDA_FUNCTION_URL <code>'requestContext.requestId'</code> Lambda Function URL request ID S3_OBJECT_LAMBDA <code>'xAmzRequestId'</code> S3 Object trigger request ID VPC_LATTICE <code>'headers.\"x-amzn-trace-id'</code> VPC Lattice X-Ray Trace ID"
        },
        {
            "location": "core/logger/#appending-additional-keys",
            "title": "Appending additional keys",
            "text": "<p>You can append additional keys using either mechanism:</p> <ul> <li>Add extra keys to a single log message by passing them to the log method directly</li> <li>Append temporary keys to all future log messages via the <code>appendKeys()</code> method until <code>resetKeys()</code> is called</li> <li>Set Persistent keys for the logger instance via the <code>persistentKeys</code> constructor option or the <code>appendPersistentKeys()</code> method</li> </ul> <p>To prevent you from accidentally overwriting some of the standard keys, we will log a warning message and ignore the key if you try to overwrite them.</p>"
        },
        {
            "location": "core/logger/#extra-keys",
            "title": "Extra keys",
            "text": "<p>You can append additional data to a single log item by passing objects as additional parameters.</p> <ul> <li>Pass a simple string for logging it with default key name <code>extra</code></li> <li>Pass one or multiple objects containing arbitrary data to be logged. Each data object should be placed in an enclosing object as a single property value, you can name this property as you need: <code>{ myData: arbitraryObjectToLog }</code></li> <li>If you already have an object containing a <code>message</code> key and an additional property, you can pass this object directly</li> </ul> handler.tsExample CloudWatch Logs excerpt <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger();\n\nexport const handler = async (\n  event: unknown,\n  _context: unknown\n): Promise&lt;unknown&gt; =&gt; {\n  const myImportantVariable = {\n    foo: 'bar',\n  };\n\n  // Log additional data in single log items\n\n  // As second parameter\n  logger.info('This is a log with an extra variable', {\n    data: myImportantVariable,\n  });\n\n  // You can also pass multiple parameters containing arbitrary objects\n  logger.info(\n    'This is a log with 3 extra objects',\n    { data: myImportantVariable },\n    { correlationIds: { myCustomCorrelationId: 'foo-bar-baz' } },\n    { lambdaEvent: event }\n  );\n\n  // Simply pass a string for logging additional data\n  logger.info('This is a log with additional string value', 'string value');\n\n  // Directly passing an object containing both the message and the additional info\n  const logObject = {\n    message: 'This is a log message',\n    additionalValue: 42,\n  };\n\n  logger.info(logObject);\n\n  return {\n    foo: 'bar',\n  };\n};\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"message\": \"This is a log with an extra variable\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:06:17.463Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\",\n    \"data\": { \"foo\": \"bar\" }\n}\n{\n    \"level\": \"INFO\",\n    \"message\": \"This is a log with 3 extra objects\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:06:17.466Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\",\n    \"data\": { \"foo\": \"bar\" },\n    \"correlationIds\": { \"myCustomCorrelationId\": \"foo-bar-baz\" },\n    \"lambdaEvent\": { \n        \"exampleEventData\": {\n            \"eventValue\": 42\n        }\n    }\n}\n{\n    \"level\": \"INFO\",\n    \"message\": \"This is a log with additional string value\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:06:17.463Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\",\n    \"extra\": \"string value\"\n}\n{\n    \"level\": \"INFO\",\n    \"message\": \"This is a log message\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:06:17.463Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\",\n    \"additionalValue\": 42\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#temporary-keys",
            "title": "Temporary keys",
            "text": "<p>You can append additional keys to all future log messages by using the <code>appendKeys()</code> method.</p> When is this useful? <p>This is helpful to contextualize log messages emitted during a specific function.</p> handler.tsExample CloudWatch Logs excerpt <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger({\n  serviceName: 'serverlessAirline',\n});\n\nconst processTransaction = async (customerId: string): Promise&lt;void&gt; =&gt; {\n  try {\n    logger.appendKeys({\n      customerId,\n    });\n\n    // ... your business logic\n\n    logger.info('transaction processed');\n  } finally {\n    logger.resetKeys(); // (1)!\n  }\n};\n\nexport const handler = async (\n  event: { customerId: string },\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  await processTransaction(event.customerId);\n\n  // .. other business logic\n\n  logger.info('other business logic processed');\n};\n</code></pre> <ol> <li>You can also remove specific keys by calling the <code>removeKeys()</code> method.</li> </ol> <pre><code>{\n    \"level\": \"INFO\",\n    \"message\": \"transaction processed\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T21:49:58.084Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\",\n    \"customerId\": \"123456789012\"\n}\n{\n    \"level\": \"INFO\",\n    \"message\": \"other business logic processed\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T21:49:58.088Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#persistent-keys",
            "title": "Persistent keys",
            "text": "<p>You can persist keys across Lambda invocations by using the <code>persistentKeys</code> constructor option or the <code>appendPersistentKeys()</code> method. These keys will persist even if you call the <code>resetKeys()</code> method.</p> <p>A common use case is to set keys about your environment or application version, so that you can easily filter logs in CloudWatch Logs.</p> As constructor optionsVia dynamic methodExample CloudWatch Logs excerpt <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger({\n  serviceName: 'serverlessAirline',\n  persistentKeys: {\n    environment: 'prod',\n    version: process.env.BUILD_VERSION,\n  },\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  logger.info('processing transaction');\n\n  // ... your business logic\n};\n</code></pre> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger({\n  serviceName: 'serverlessAirline',\n});\n\ndeclare const getRemoteConfig: (env: string) =&gt; {\n  environment: string;\n  version: string;\n};\nconst { environment, version } = getRemoteConfig('prod');\n\nlogger.appendPersistentKeys({ environment, version });\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  logger.info('processing transaction');\n\n  // .. your business logic\n};\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"message\": \"processing transaction\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T21:49:58.084Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\",\n    \"environment\": \"prod\",\n    \"version\": \"1.2.0\",\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#removing-additional-keys",
            "title": "Removing additional keys",
            "text": "<p>You can remove additional keys from the logger instance at any time:</p> <ul> <li>Remove temporary keys added via the <code>appendKeys()</code> method by using the <code>removeKeys()</code> method</li> <li>Remove persistent keys added via the <code>persistentKeys</code> constructor option or the <code>appendPersistentKeys()</code> method by using the <code>removePersistentKeys()</code> method</li> </ul> Remove temporary keysRemove persistent keys <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger({\n  serviceName: 'serverlessAirline',\n});\n\nconst processTransaction = async (customerId: string): Promise&lt;void&gt; =&gt; {\n  try {\n    logger.appendKeys({\n      customerId,\n    });\n\n    // ... your business logic\n\n    logger.info('transaction processed');\n  } finally {\n    logger.removeKeys(['customerId']);\n  }\n};\n\nexport const handler = async (\n  event: { customerId: string },\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  await processTransaction(event.customerId);\n\n  // .. other business logic\n\n  logger.info('other business logic processed');\n};\n</code></pre> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger({\n  serviceName: 'serverlessAirline',\n  persistentKeys: {\n    foo: true,\n  },\n});\n\ndeclare const getRemoteConfig: (env: string) =&gt; {\n  isFoo: boolean;\n};\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  const { isFoo } = getRemoteConfig('prod');\n  if (isFoo) logger.removePersistentKeys(['foo']);\n\n  logger.info('processing transaction');\n\n  // ... your business logic\n};\n</code></pre>"
        },
        {
            "location": "core/logger/#resetting-keys",
            "title": "Resetting keys",
            "text": "<p>Logger is commonly initialized in the global scope. Due to Lambda Execution Context reuse, this means that custom keys can be persisted across invocations.</p> <p>Resetting the state allows you to clear all the temporary keys you have added.</p> Tip: When is this useful? <p>This is useful when you add multiple custom keys conditionally or when you use canonical or wide logs.</p> Clearing state manuallyMiddy MiddlewareDecoratorFirst invocationSecond invocation <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\n// Persistent attributes will be cached across invocations\nconst logger = new Logger({\n  logLevel: 'info',\n  persistentKeys: {\n    environment: 'prod',\n  },\n});\n\n// Enable the clear state flag\nexport const handler = async (\n  event: { userId: string },\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  try {\n    // This temporary key will be included in the log &amp; cleared after the invocation\n    logger.appendKeys({\n      details: { userId: event.userId },\n    });\n\n    // ... your business logic\n  } finally {\n    logger.info('WIDE');\n    logger.resetKeys();\n  }\n};\n</code></pre> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { injectLambdaContext } from '@aws-lambda-powertools/logger/middleware';\nimport middy from '@middy/core';\n\n// Persistent attributes will be cached across invocations\nconst logger = new Logger({\n  logLevel: 'info',\n  persistentKeys: {\n    environment: 'prod',\n  },\n});\n\nexport const handler = middy(\n  async (event: { userId: string }, _context: unknown): Promise&lt;void&gt; =&gt; {\n    // This temporary key will be included in the log &amp; cleared after the invocation\n    logger.appendKeys({\n      details: { userId: event.userId },\n    });\n\n    // ... your business logic\n\n    logger.info('WIDE');\n  }\n).use(injectLambdaContext(logger, { resetKeys: true }));\n</code></pre> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Logger } from '@aws-lambda-powertools/logger';\n\n// Persistent attributes will be cached across invocations\nconst logger = new Logger({\n  logLevel: 'info',\n  persistentKeys: {\n    environment: 'prod',\n  },\n});\n\nclass Lambda implements LambdaInterface {\n  @logger.injectLambdaContext({ resetKeys: true })\n  public async handler(\n    event: { userId: string },\n    _context: unknown\n  ): Promise&lt;void&gt; {\n    // This temporary key will be included in the log &amp; cleared after the invocation\n    logger.appendKeys({\n      details: { userId: event.userId },\n    });\n\n    // ... your business logic\n\n    logger.info('WIDE');\n  }\n}\n\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction); // (1)!\n</code></pre> <ol> <li>Binding your handler method allows your handler to access <code>this</code> within the class methods.</li> </ol> <pre><code>{\n    \"environment\": \"prod\",\n    \"cold_start\": true,\n    \"userId\": \"123456789012\",\n    \"foo\": \"bar\",\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:123456789012:function:foo-bar-function\",\n    \"function_memory_size\": 128,\n    \"function_name\": \"foo-bar-function\",\n    \"function_request_id\": \"abcdef123456abcdef123456\",\n    \"level\": \"INFO\",\n    \"message\": \"WIDE\",\n    \"service\": \"hello-world\",\n    \"timestamp\": \"2021-12-12T22:32:54.670Z\",\n    \"xray_trace_id\": \"1-5759e988-bd862e3fe1be46a994272793\"\n}\n</code></pre> <pre><code>{\n    \"environment\": \"prod\",\n    \"cold_start\": false,\n    \"userId\": \"210987654321\",\n    \"function_arn\": \"arn:aws:lambda:eu-west-1:123456789012:function:foo-bar-function\",\n    \"function_memory_size\": 128,\n    \"function_name\": \"foo-bar-function\",\n    \"function_request_id\": \"abcdef123456abcdef123456\",\n    \"level\": \"INFO\",\n    \"message\": \"WIDE\",\n    \"service\": \"hello-world\",\n    \"timestamp\": \"2021-12-12T22:40:23.120Z\",\n    \"xray_trace_id\": \"1-5759e988-bd862e3fe1be46a994272793\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#logging-errors",
            "title": "Logging errors",
            "text": "<p>You can log errors by using the <code>error</code> method and pass the error object as parameter. The error will be logged with default key name <code>error</code>, but you can also pass your own custom key name.</p> handler.tsExample CloudWatch Logs excerpt <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger();\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  try {\n    throw new Error('Unexpected error #1');\n  } catch (error) {\n    // Log information about the error using the default \"error\" key\n    logger.error('This is the first error', error as Error);\n  }\n\n  try {\n    throw new Error('Unexpected error #2');\n  } catch (error) {\n    // Log information about the error using a custom \"myCustomErrorKey\" key\n    logger.error('This is the second error', {\n      myCustomErrorKey: error as Error,\n    });\n  }\n};\n</code></pre> <p> <pre><code>{\n    \"level\": \"ERROR\",\n    \"message\": \"This is the first error\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:12:39.345Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\",\n    \"error\": {\n        \"name\": \"Error\",\n        \"location\": \"/path/to/my/source-code/my-service/handler.ts:18\",\n        \"message\": \"Unexpected error #1\",\n        \"stack\": \"Error: Unexpected error #1    at lambdaHandler (/path/to/my/source-code/my-service/handler.ts:18:11)    at Object.&lt;anonymous&gt; (/path/to/my/source-code/my-service/handler.ts:35:1)    at Module._compile (node:internal/modules/cjs/loader:1108:14)    at Module.m._compile (/path/to/my/source-code/node_modules/ts-node/src/index.ts:1371:23)    at Module._extensions..js (node:internal/modules/cjs/loader:1137:10)    at Object.require.extensions.&lt;computed&gt; [as .ts] (/path/to/my/source-code/node_modules/ts-node/src/index.ts:1374:12)    at Module.load (node:internal/modules/cjs/loader:973:32)    at Function.Module._load (node:internal/modules/cjs/loader:813:14)    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:76:12)    at main (/path/to/my/source-code/node_modules/ts-node/src/bin.ts:331:12)\"\n    }\n}\n{\n    \"level\": \"ERROR\",\n    \"message\": \"This is the second error\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:12:39.377Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\",\n    \"myCustomErrorKey\": {\n        \"name\": \"Error\",\n        \"location\": \"/path/to/my/source-code/my-service/handler.ts:24\",\n        \"message\": \"Unexpected error #2\",\n        \"stack\": \"Error: Unexpected error #2    at lambdaHandler (/path/to/my/source-code/my-service/handler.ts:24:11)    at Object.&lt;anonymous&gt; (/path/to/my/source-code/my-service/handler.ts:35:1)    at Module._compile (node:internal/modules/cjs/loader:1108:14)    at Module.m._compile (/path/to/my/source-code/node_modules/ts-node/src/index.ts:1371:23)    at Module._extensions..js (node:internal/modules/cjs/loader:1137:10)    at Object.require.extensions.&lt;computed&gt; [as .ts] (/path/to/my/source-code/node_modules/ts-node/src/index.ts:1374:12)    at Module.load (node:internal/modules/cjs/loader:973:32)    at Function.Module._load (node:internal/modules/cjs/loader:813:14)    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:76:12)    at main (/path/to/my/source-code/node_modules/ts-node/src/bin.ts:331:12)\"\n    }\n}\n</code></pre> </p> <p>Logging errors and log level</p> <p>You can also log errors using the <code>warn</code>, <code>info</code>, and <code>debug</code> methods. Be aware of the log level though, you might miss those  errors when analyzing the log later depending on the log level configuration.</p>"
        },
        {
            "location": "core/logger/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/logger/#log-levels",
            "title": "Log levels",
            "text": "<p>The default log level is <code>INFO</code> and can be set using the <code>logLevel</code> constructor option or by using the <code>POWERTOOLS_LOG_LEVEL</code> environment variable.</p> <p>We support the following log levels:</p> Level Numeric value <code>TRACE</code> 6 <code>DEBUG</code> 8 <code>INFO</code> 12 <code>WARN</code> 16 <code>ERROR</code> 20 <code>CRITICAL</code> 24 <code>SILENT</code> 28 <p>You can access the current log level by using the <code>getLevelName()</code> method. This method returns the name of the current log level as a string. If you want to change the log level at runtime, you can use the <code>setLogLevel()</code> method. This method accepts a string value that represents the log level you want to set, both lower and upper case values are supported.</p> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger();\n\nlogger.getLevelName(); // returns \"INFO\"\nlogger.setLogLevel('DEBUG');\n</code></pre> <p>If you want to access the numeric value of the current log level, you can use the <code>level</code> property. For example, if the current log level is <code>INFO</code>, <code>logger.level</code> property will return <code>12</code>.</p>"
        },
        {
            "location": "core/logger/#silencing-logs",
            "title": "Silencing logs",
            "text": "<p>The <code>SILENT</code> log level provides a simple and efficient way to suppress all log messages without the need to modify your code. When you set this log level, all log messages, regardless of their severity, will be silenced.</p> <p>This feature is useful when you want to have your code instrumented to produce logs, but due to some requirement or business decision, you prefer to not emit them.</p> <p>By setting the log level to <code>SILENT</code>, which can be done either through the <code>logLevel</code> constructor option or by using the <code>POWERTOOLS_LOG_LEVEL</code> environment variable, you can easily suppress all logs as needed.</p> <p>Note</p> <p>Use the <code>SILENT</code> log level with care, as it can make it more challenging to monitor and debug your application. Therefore, we advise using this log level judiciously.</p>"
        },
        {
            "location": "core/logger/#aws-lambda-advanced-logging-controls-alc",
            "title": "AWS Lambda Advanced Logging Controls (ALC)",
            "text": "<p>With AWS Lambda Advanced Logging Controls (ALC), you can control the output format of your logs as either <code>TEXT</code> or <code>JSON</code> and specify the minimum accepted log level for your application.</p> <p>Regardless of the output format setting in Lambda, we will always output JSON formatted logging messages.</p> <p>When you have this feature enabled, log messages that don’t meet the configured log level are discarded by Lambda. For example, if you set the minimum log level to <code>WARN</code>, you will only receive <code>WARN</code> and <code>ERROR</code> messages in your AWS CloudWatch Logs, all other log levels will be discarded by Lambda.</p> <pre><code>sequenceDiagram\n    title Lambda ALC allows WARN logs only\n    participant Lambda service\n    participant Lambda function\n    participant Application Logger\n\n    Note over Lambda service: AWS_LAMBDA_LOG_LEVEL=\"WARN\"\n    Lambda service-&gt;&gt;Lambda function: Invoke (event)\n    Lambda function-&gt;&gt;Lambda function: Calls handler\n    Lambda function-&gt;&gt;Application Logger: logger.warn(\"Something happened\")\n    Lambda function--&gt;&gt;Application Logger: logger.debug(\"Something happened\")\n    Lambda function--&gt;&gt;Application Logger: logger.info(\"Something happened\")\n\n    Lambda service-&gt;&gt;Lambda service: DROP INFO and DEBUG logs\n\n    Lambda service-&gt;&gt;CloudWatch Logs: Ingest error logs</code></pre> <p>Priority of log level settings in Powertools for AWS Lambda</p> <p>When the Advanced Logging Controls feature is enabled, we are unable to increase the minimum log level below the <code>AWS_LAMBDA_LOG_LEVEL</code> environment variable value, see AWS Lambda service documentation for more details.</p> <p>We prioritise log level settings in this order:</p> <ol> <li><code>AWS_LAMBDA_LOG_LEVEL</code> environment variable</li> <li>Setting the log level in code using the <code>logLevel</code> constructor option, or by calling the <code>logger.setLogLevel()</code> method</li> <li><code>POWERTOOLS_LOG_LEVEL</code> environment variable</li> </ol> <p>In the event you have set a log level in Powertools to a level that is lower than the ACL setting, we will output a warning log message informing you that your messages will be discarded by Lambda.</p>"
        },
        {
            "location": "core/logger/#buffering-logs",
            "title": "Buffering logs",
            "text": "<p>Log buffering enables you to buffer logs for a specific request or invocation. Enable log buffering by passing <code>logBufferOptions</code> when initializing a Logger instance. You can buffer logs at the <code>WARNING</code>, <code>INFO</code>,  <code>DEBUG</code>, or <code>TRACE</code> level, and flush them automatically on error or manually as needed.</p> <p>This is useful when you want to reduce the number of log messages emitted while still having detailed logs when needed, such as when troubleshooting issues.</p> logBufferingGettingStarted.ts <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger({\n  logBufferOptions: {\n    maxBytes: 20480,\n    flushOnErrorLog: true,\n  },\n});\n\nlogger.debug('This is a debug message'); // This is NOT buffered\n\nexport const handler = async () =&gt; {\n  logger.debug('This is a debug message'); // This is buffered\n  logger.info('This is an info message');\n\n  // your business logic here\n\n  logger.error('This is an error message'); // This also flushes the buffer\n  // or logger.flushBuffer(); // to flush the buffer manually\n};\n</code></pre>"
        },
        {
            "location": "core/logger/#configuring-the-buffer",
            "title": "Configuring the buffer",
            "text": "<p>When configuring the buffer, you can set the following options to fine-tune how logs are captured, stored, and emitted. You can configure the following options in the <code>logBufferOptions</code> constructor parameter:</p> Parameter Description Configuration Default <code>enabled</code> Enable or disable log buffering <code>true</code>, <code>false</code> <code>false</code> <code>maxBytes</code> Maximum size of the log buffer in bytes <code>number</code> <code>20480</code> <code>bufferAtVerbosity</code> Minimum log level to buffer <code>TRACE</code>, <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code> <code>DEBUG</code> <code>flushOnErrorLog</code> Automatically flush buffer when logging an error <code>true</code>, <code>false</code> <code>true</code> logBufferingBufferAtVerbosity.tslogBufferingflushOnErrorLog.ts <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger({\n  logBufferOptions: {\n    bufferAtVerbosity: 'warn', // (1)!\n  },\n});\n\nexport const handler = async () =&gt; {\n  // All logs below are buffered\n  logger.debug('This is a debug message');\n  logger.info('This is an info message');\n  logger.warn('This is a warn message');\n\n  logger.clearBuffer(); // (2)!\n};\n</code></pre> <ol> <li>Setting <code>bufferAtVerbosity: 'warn'</code> configures log buffering for <code>WARNING</code> and all lower severity levels like <code>INFO</code>, <code>DEBUG</code>, and <code>TRACE</code>.</li> <li>Calling <code>logger.clearBuffer()</code> will clear the buffer without emitting the logs.</li> </ol> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger({\n  logBufferOptions: {\n    maxBytes: 20480,\n    flushOnErrorLog: false, // (1)!\n  },\n});\n\nexport const handler = async () =&gt; {\n  logger.debug('This is a debug message'); // This is buffered\n\n  try {\n    throw new Error('a non fatal error');\n  } catch (error) {\n    logger.error('A non fatal error occurred', { error }); // This does NOT flush the buffer\n  }\n\n  logger.debug('This is another debug message'); // This is buffered\n\n  try {\n    throw new Error('a fatal error');\n  } catch (error) {\n    logger.error('A fatal error occurred', { error }); // This does NOT flush the buffer\n    logger.flushBuffer();\n  }\n};\n</code></pre> <ol> <li>Disabling <code>flushOnErrorLog</code> will not flush the buffer when logging an error. This is useful when you want to control when the buffer is flushed by calling the <code>logger.flushBuffer()</code> method.</li> </ol>"
        },
        {
            "location": "core/logger/#flushing-on-errors",
            "title": "Flushing on errors",
            "text": "<p>When using the <code>logger.injectLambdaContext()</code> class method decorator or the <code>injectLambdaContext()</code> middleware, you can configure the logger to automatically flush the buffer when an error occurs. This is done by setting the <code>flushBufferOnUncaughtError</code> option to <code>true</code> in the decorator or middleware options.</p> logBufferingFlushOnErrorDecorator.tslogBufferingFlushOnErrorMiddy.ts <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport type { Context } from 'aws-lambda';\n\nconst logger = new Logger({\n  logLevel: 'DEBUG',\n  logBufferOptions: { enabled: true },\n});\n\nclass Lambda {\n  @logger.injectLambdaContext({\n    flushBufferOnUncaughtError: true,\n  })\n  async handler(_event: unknown, _context: Context) {\n    // Both logs below are buffered\n    logger.debug('a debug log');\n    logger.debug('another debug log');\n\n    throw new Error('an error log'); // This causes the buffer to flush\n  }\n}\n\nconst lambda = new Lambda();\nexport const handler = lambda.handler.bind(lambda);\n</code></pre> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { injectLambdaContext } from '@aws-lambda-powertools/logger/middleware';\nimport middy from '@middy/core';\n\nconst logger = new Logger({\n  logLevel: 'DEBUG',\n  logBufferOptions: { enabled: true },\n});\n\nexport const handler = middy()\n  .use(injectLambdaContext(logger, { flushBufferOnUncaughtError: true }))\n  .handler(async (event: unknown) =&gt; {\n    // Both logs below are buffered\n    logger.debug('a debug log');\n    logger.debug('another debug log');\n\n    throw new Error('an error log'); // This causes the buffer to flush\n  });\n</code></pre>"
        },
        {
            "location": "core/logger/#buffering-workflows",
            "title": "Buffering workflows",
            "text": ""
        },
        {
            "location": "core/logger/#manual-flush",
            "title": "Manual flush",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Logger\n    participant CloudWatch\n    Client-&gt;&gt;Lambda: Invoke Lambda\n    Lambda-&gt;&gt;Logger: Initialize with DEBUG level buffering\n    Logger--&gt;&gt;Lambda: Logger buffer ready\n    Lambda-&gt;&gt;Logger: logger.debug(\"First debug log\")\n    Logger--&gt;&gt;Logger: Buffer first debug log\n    Lambda-&gt;&gt;Logger: logger.info(\"Info log\")\n    Logger-&gt;&gt;CloudWatch: Directly log info message\n    Lambda-&gt;&gt;Logger: logger.debug(\"Second debug log\")\n    Logger--&gt;&gt;Logger: Buffer second debug log\n    Lambda-&gt;&gt;Logger: logger.flush_buffer()\n    Logger-&gt;&gt;CloudWatch: Emit buffered logs to stdout\n    Lambda-&gt;&gt;Client: Return execution result</code></pre> Flushing buffer manually </p>"
        },
        {
            "location": "core/logger/#flushing-when-logging-an-error",
            "title": "Flushing when logging an error",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Logger\n    participant CloudWatch\n    Client-&gt;&gt;Lambda: Invoke Lambda\n    Lambda-&gt;&gt;Logger: Initialize with DEBUG level buffering\n    Logger--&gt;&gt;Lambda: Logger buffer ready\n    Lambda-&gt;&gt;Logger: logger.debug(\"First log\")\n    Logger--&gt;&gt;Logger: Buffer first debug log\n    Lambda-&gt;&gt;Logger: logger.debug(\"Second log\")\n    Logger--&gt;&gt;Logger: Buffer second debug log\n    Lambda-&gt;&gt;Logger: logger.debug(\"Third log\")\n    Logger--&gt;&gt;Logger: Buffer third debug log\n    Lambda-&gt;&gt;Lambda: Exception occurs\n    Lambda-&gt;&gt;Logger: logger.error(\"Error details\")\n    Logger-&gt;&gt;CloudWatch: Emit buffered debug logs\n    Logger-&gt;&gt;CloudWatch: Emit error log\n    Lambda-&gt;&gt;Client: Raise exception</code></pre> Flushing buffer when an error happens </p>"
        },
        {
            "location": "core/logger/#flushing-on-error",
            "title": "Flushing on error",
            "text": "<p>This works only when using the <code>logger.injectLambdaContext()</code> class method decorator or the <code>injectLambdaContext()</code> middleware. You can configure the logger to automatically flush the buffer when an error occurs by setting the <code>flushBufferOnUncaughtError</code> option to <code>true</code> in the decorator or middleware options.</p> <p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Logger\n    participant CloudWatch\n    Client-&gt;&gt;Lambda: Invoke Lambda\n    Lambda-&gt;&gt;Logger: Using decorator\n    Logger--&gt;&gt;Lambda: Logger context injected\n    Lambda-&gt;&gt;Logger: logger.debug(\"First log\")\n    Logger--&gt;&gt;Logger: Buffer first debug log\n    Lambda-&gt;&gt;Logger: logger.debug(\"Second log\")\n    Logger--&gt;&gt;Logger: Buffer second debug log\n    Lambda-&gt;&gt;Lambda: Uncaught Exception\n    Lambda-&gt;&gt;CloudWatch: Automatically emit buffered debug logs\n    Lambda-&gt;&gt;Client: Raise uncaught exception</code></pre> Flushing buffer when an uncaught exception happens </p>"
        },
        {
            "location": "core/logger/#buffering-faqs",
            "title": "Buffering FAQs",
            "text": "<ol> <li> <p>Does the buffer persist across Lambda invocations?    No, each Lambda invocation has its own buffer. The buffer is initialized when the Lambda function is invoked and is cleared after the function execution completes or when flushed manually.</p> </li> <li> <p>Are my logs buffered during cold starts?    No, we never buffer logs during cold starts. This is because we want to ensure that logs emitted during this phase are always available for debugging and monitoring purposes. The buffer is only used during the execution of the Lambda function.</p> </li> <li> <p>How can I prevent log buffering from consuming excessive memory?    You can limit the size of the buffer by setting the <code>maxBytes</code> option in the <code>logBufferOptions</code> constructor parameter. This will ensure that the buffer does not grow indefinitely and consume excessive memory.</p> </li> <li> <p>What happens if the log buffer reaches its maximum size?    Older logs are removed from the buffer to make room for new logs. This means that if the buffer is full, you may lose some logs if they are not flushed before the buffer reaches its maximum size. When this happens, we emit a warning when flushing the buffer to indicate that some logs have been dropped.</p> </li> <li> <p>How is the log size of a log line calculated?    The log size is calculated based on the size of the stringified log line in bytes. This includes the size of the log message, the size of any additional keys, and the size of the timestamp.</p> </li> <li> <p>What timestamp is used when I flush the logs?    The timestamp preserves the original time when the log record was created. If you create a log record at 11:00:10 and flush it at 11:00:25, the log line will retain its original timestamp of 11:00:10.</p> </li> <li> <p>What happens if I try to add a log line that is bigger than max buffer size?    The log will be emitted directly to standard output and not buffered. When this happens, we emit a warning to indicate that the log line was too big to be buffered.</p> </li> <li> <p>What happens if Lambda times out without flushing the buffer?    Logs that are still in the buffer will be lost. If you are using the log buffer to log asynchronously, you should ensure that the buffer is flushed before the Lambda function times out. You can do this by calling the <code>logger.flushBuffer()</code> method at the end of your Lambda function.</p> </li> <li> <p>Do child loggers inherit the buffer?    No, child loggers do not inherit the buffer from their parent logger but only the buffer configuration. This means that if you create a child logger, it will have its own buffer and will not share the buffer with the parent logger.</p> </li> </ol>"
        },
        {
            "location": "core/logger/#reordering-log-keys-position",
            "title": "Reordering log keys position",
            "text": "<p>You can change the order of standard Logger keys or any keys that will be appended later at runtime via the <code>logRecordOrder</code> parameter.</p> <p>Note</p> <p>This feature is available only in the default log formatter and not with custom log formatters.</p> reorderLogKeys.tsreorderLogKeysOutput.json <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger({\n  serviceName: 'serverlessAirline',\n  logRecordOrder: ['timestamp', 'additionalKey'],\n});\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  logger.info('Hello, World!', {\n    additionalKey: 'additionalValue',\n  });\n};\n</code></pre> <pre><code>{\n  \"level\": \"INFO\",\n  \"message\": \"Hello, World!\",\n  \"timestamp\": \"2024-09-03T02:59:06.603Z\",\n  \"service\": \"serverlessAirline\",\n  \"additionalKey\": \"additionalValue\",\n  \"sampling_rate\": 0,\n  \"xray_trace_id\": \"1-66d67b7a-79bc7b2346b32af01b437cf8\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#setting-timestamp-to-custom-timezone",
            "title": "Setting timestamp to custom timezone",
            "text": "<p>By default, Logger emits records with the default Lambda timestamp in UTC, i.e. <code>2016-06-20T12:08:10.000Z</code></p> <p>If you prefer to log in a specific timezone, you can configure it by setting the <code>TZ</code> environment variable. You can do this either as an environment variable or directly within your Lambda function settings.</p> <p>Click here for a comprehensive list of available Lambda environment variables.</p> customTimezone.tscustomTimezoneOutput.json <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger({ serviceName: 'serverlessAirline' });\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  logger.info('Hello, World!');\n\n  process.env.TZ = 'Europe/Rome';\n\n  const childLogger = logger.createChild();\n\n  childLogger.info('Ciao, Mondo!');\n};\n</code></pre> <pre><code>[\n  {\n    \"level\": \"INFO\",\n    \"message\": \"Hello, World!\",\n    \"timestamp\": \"2024-07-01T11:00:37.886Z\",\n    \"service\": \"serverlessAirline\",\n    \"sampling_rate\": 0,\n    \"xray_trace_id\": \"1-66828c55-2bb635c65eb609c820ebe7bc\"\n  },\n  {\n    \"level\": \"INFO\",\n    \"message\": \"Ciao, Mondo!\",\n    \"timestamp\": \"2024-07-01T13:00:37.934+02:00\",\n    \"service\": \"serverlessAirline\",\n    \"sampling_rate\": 0,\n    \"xray_trace_id\": \"1-66828c55-2bb635c65eb609c820ebe7bc\"\n  }\n]\n</code></pre>"
        },
        {
            "location": "core/logger/#creating-child-loggers",
            "title": "Creating child loggers",
            "text": "<p>The <code>createChild</code> method allows you to create a child instance of the Logger, which inherits all of the attributes from its parent. You have the option to override any of the settings and attributes from the parent logger, including its settings, any extra keys, and the log formatter.</p> <p>Once a child logger is created, the logger and its parent will act as separate instances of the Logger class, and as such any change to one won't be applied to the other.</p> <p>The following example shows how to create multiple Loggers that share service name and persistent attributes while specifying different logging levels within a single Lambda invocation. As the result, only ERROR logs with all the inherited attributes will be displayed in CloudWatch Logs from the child logger, but all logs emitted will have the same service name and persistent attributes.</p> handler.tsExample CloudWatch Logs excerpt <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\n// This logger has a service name, some persistent attributes\n// and log level set to INFO\nconst logger = new Logger({\n  serviceName: 'serverlessAirline',\n  logLevel: 'INFO',\n  persistentLogAttributes: {\n    aws_account_id: '123456789012',\n    aws_region: 'eu-west-1',\n  },\n});\n\n// This other logger inherits all the parent's attributes\n// but the log level, which is now set to ERROR\nconst childLogger = logger.createChild({\n  logLevel: 'ERROR',\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  logger.info('This is an INFO log, from the parent logger');\n  logger.error('This is an ERROR log, from the parent logger');\n\n  childLogger.info('This is an INFO log, from the child logger');\n  childLogger.error('This is an ERROR log, from the child logger');\n};\n</code></pre> <pre><code>{\n    \"level\": \"INFO\",\n    \"message\": \"This is an INFO log, from the parent logger\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:32:54.667Z\",\n    \"aws_account_id\":\"123456789012\",\n    \"aws_region\":\"eu-west-1\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n}\n{\n    \"level\": \"ERROR\",\n    \"message\": \"This is an ERROR log, from the parent logger\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:32:54.670Z\",\n    \"aws_account_id\":\"123456789012\",\n    \"aws_region\":\"eu-west-1\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n}\n{\n    \"level\": \"ERROR\",\n    \"message\": \"This is an ERROR log, from the child logger\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:32:54.670Z\",\n    \"aws_account_id\":\"123456789012\",\n    \"aws_region\":\"eu-west-1\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#sampling-debug-logs",
            "title": "Sampling debug logs",
            "text": "<p>Use sampling when you want to dynamically change your log level to DEBUG based on a percentage of your invocations.</p> <p>You can use values ranging from <code>0</code> to <code>1</code> (100%) when setting the <code>sampleRateValue</code> constructor option or <code>POWERTOOLS_LOGGER_SAMPLE_RATE</code> env var.</p> <p>When is this useful?</p> <p>Let's imagine a sudden spike increase in concurrency triggered a transient issue downstream. When looking into the logs you might not have enough information, and while you can adjust log levels it might not happen again.</p> <p>This feature takes into account transient issues where additional debugging information can be useful.</p> <p>Sampling decision happens at the Logger initialization. When using the <code>injectLambdaContext</code> method either as a decorator or Middy.js middleware, the sampling decision is refreshed at the beginning of each Lambda invocation for you, except for cold starts.</p> <p>If you're not using either of these, you'll need to manually call the <code>refreshSamplingRate()</code> function at the start of your handler to refresh the sampling decision for each invocation.</p> handler.tsExample Logs Request #1 (not sampled)Example Logs Request #2 (sampled)Example Logs Request #3 (sampled)Example Logs Request #4 (not sampled) <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger({\n  logLevel: 'ERROR', // (1)!\n  sampleRateValue: 0.5,\n});\n\nexport const handler = async () =&gt; {\n  logger.refreshSampleRateCalculation(); // (2)!\n\n  logger.error('This log is always emitted');\n\n  logger.debug('This log has ~50% chance of being emitted');\n  logger.info('This log has ~50% chance of being emitted');\n  logger.warn('This log has ~50% chance of being emitted');\n};\n</code></pre> <ol> <li>The log level must be set to a more verbose level than <code>DEBUG</code> for log sampling to kick in.</li> <li>You need to call <code>logger.refreshSamplingRate()</code> at the start of your handler only if you're not using the <code>injectLambdaContext()</code> class method decorator or Middy.js middleware.</li> </ol> <pre><code>{\n  \"level\": \"ERROR\",\n  \"message\": \"This log is always emitted\",\n  \"sampling_rate\": \"0.5\",\n  \"service\": \"serverlessAirline\",\n  \"timestamp\": \"2021-12-12T22:59:06.334Z\",\n  \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n}\n</code></pre> <pre><code>[\n  {\n    \"level\": \"ERROR\",\n    \"message\": \"This log is always emitted\",\n    \"sampling_rate\": \"0.5\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:59:06.334Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n  },\n  {\n    \"level\": \"DEBUG\",\n    \"message\": \"This log has ~50% chance of being emitted\",\n    \"sampling_rate\": \"0.5\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:59:06.337Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n  },\n  {\n    \"level\": \"INFO\",\n    \"message\": \"This log has ~50% chance of being emitted\",\n    \"sampling_rate\": \"0.5\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:59:06.338Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n  },\n  {\n    \"level\": \"WARN\",\n    \"message\": \"This log has ~50% chance of being emitted\",\n    \"sampling_rate\": \"0.5\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:59:06.338Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n  }\n]\n</code></pre> <pre><code>[\n  {\n    \"level\": \"ERROR\",\n    \"message\": \"This log is always emitted\",\n    \"sampling_rate\": \"0.5\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:59:06.334Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n  },\n  {\n    \"level\": \"DEBUG\",\n    \"message\": \"This log has ~50% chance of being emitted\",\n    \"sampling_rate\": \"0.5\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:59:06.337Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n  },\n  {\n    \"level\": \"INFO\",\n    \"message\": \"This log has ~50% chance of being emitted\",\n    \"sampling_rate\": \"0.5\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:59:06.338Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n  },\n  {\n    \"level\": \"WARN\",\n    \"message\": \"This log has ~50% chance of being emitted\",\n    \"sampling_rate\": \"0.5\",\n    \"service\": \"serverlessAirline\",\n    \"timestamp\": \"2021-12-12T22:59:06.338Z\",\n    \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n  }\n]\n</code></pre> <pre><code>{\n  \"level\": \"ERROR\",\n  \"message\": \"This log is always emitted\",\n  \"sampling_rate\": \"0.5\",\n  \"service\": \"serverlessAirline\",\n  \"timestamp\": \"2021-12-12T22:59:06.334Z\",\n  \"xray_trace_id\": \"abcdef123456abcdef123456abcdef123456\"\n}\n</code></pre>"
        },
        {
            "location": "core/logger/#custom-log-formatter",
            "title": "Custom Log formatter",
            "text": "<p>You can customize the structure (keys and values) of your logs by passing a custom log formatter, a class that implements the <code>LogFormatter</code> interface, to the <code>Logger</code> constructor.</p> <p>When working with custom log formatters, you take full control over the structure of your logs. This allows you to optionally drop or transform keys, add new ones, or change the format to suit your company's logging standards or use Logger with a third-party logging service.</p> handler.tsutils/formatters/MyCompanyLogFormatter.tsExample CloudWatch Logs excerpt <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport type { Context } from 'aws-lambda';\nimport { MyCompanyLogFormatter } from './bringYourOwnFormatterClass';\n\nconst logger = new Logger({\n  logFormatter: new MyCompanyLogFormatter(),\n  logLevel: 'DEBUG',\n  serviceName: 'serverlessAirline',\n  sampleRateValue: 0.5,\n  persistentLogAttributes: {\n    awsAccountId: process.env.AWS_ACCOUNT_ID,\n    logger: {\n      name: '@aws-lambda-powertools/logger',\n      version: '0.0.1',\n    },\n  },\n});\n\nexport const handler = async (\n  _event: unknown,\n  context: Context\n): Promise&lt;void&gt; =&gt; {\n  logger.addContext(context);\n\n  logger.info('This is an INFO log', {\n    correlationIds: { myCustomCorrelationId: 'foo-bar-baz' },\n  });\n};\n</code></pre> <pre><code>import { LogFormatter, LogItem } from '@aws-lambda-powertools/logger';\nimport type {\n  LogAttributes,\n  UnformattedAttributes,\n} from '@aws-lambda-powertools/logger/types';\n\n// Replace this line with your own type\ntype MyCompanyLog = LogAttributes;\n\nclass MyCompanyLogFormatter extends LogFormatter {\n  public formatAttributes(\n    attributes: UnformattedAttributes,\n    additionalLogAttributes: LogAttributes\n  ): LogItem {\n    const baseAttributes: MyCompanyLog = {\n      message: attributes.message,\n      service: attributes.serviceName,\n      environment: attributes.environment,\n      awsRegion: attributes.awsRegion,\n      correlationIds: {\n        awsRequestId: attributes.lambdaContext?.awsRequestId,\n        xRayTraceId: attributes.xRayTraceId,\n      },\n      lambdaFunction: {\n        name: attributes.lambdaContext?.functionName,\n        arn: attributes.lambdaContext?.invokedFunctionArn,\n        memoryLimitInMB: attributes.lambdaContext?.memoryLimitInMB,\n        version: attributes.lambdaContext?.functionVersion,\n        coldStart: attributes.lambdaContext?.coldStart,\n      },\n      logLevel: attributes.logLevel,\n      timestamp: this.formatTimestamp(attributes.timestamp), // You can extend this function\n      logger: {\n        sampleRateValue: attributes.sampleRateValue,\n      },\n    };\n\n    const logItem = new LogItem({ attributes: baseAttributes });\n    logItem.addAttributes(additionalLogAttributes); // add any attributes not explicitly defined\n\n    return logItem;\n  }\n}\n\nexport { MyCompanyLogFormatter };\n</code></pre> <pre><code>{\n    \"message\": \"This is an INFO log\",\n    \"service\": \"serverlessAirline\",\n    \"awsRegion\": \"eu-west-1\",\n    \"correlationIds\": {\n        \"awsRequestId\": \"c6af9ac6-7b61-11e6-9a41-93e812345678\",\n        \"xRayTraceId\": \"abcdef123456abcdef123456abcdef123456\",\n        \"myCustomCorrelationId\": \"foo-bar-baz\"\n    },\n    \"lambdaFunction\": {\n        \"name\": \"shopping-cart-api-lambda-prod-eu-west-1\",\n        \"arn\": \"arn:aws:lambda:eu-west-1:123456789012:function:shopping-cart-api-lambda-prod-eu-west-1\",\n        \"memoryLimitInMB\": 128,\n        \"version\": \"$LATEST\",\n        \"coldStart\": true\n    },\n    \"logLevel\": \"INFO\",\n    \"timestamp\": \"2021-12-12T23:13:53.404Z\",\n    \"logger\": {\n        \"sampleRateValue\": \"0.5\",\n        \"name\": \"aws-lambda-powertools-typescript\",\n        \"version\": \"0.0.1\"\n    },\n    \"awsAccountId\": \"123456789012\"\n}\n</code></pre> <p>Note that when implementing this method, you should avoid mutating the <code>attributes</code> and <code>additionalLogAttributes</code> objects directly. Instead, create a new object with the desired structure and return it. If mutation is necessary, you can create a <code>structuredClone</code> of the object to avoid side effects.</p>"
        },
        {
            "location": "core/logger/#extend-json-replacer-function",
            "title": "Extend JSON replacer function",
            "text": "<p>You can extend the default JSON serializer by passing a custom serializer function to the <code>Logger</code> constructor, using the <code>jsonReplacerFn</code> option. This is useful when you want to customize the serialization of specific values.</p> unserializableValues.tsunserializableValues.json <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport type { CustomReplacerFn } from '@aws-lambda-powertools/logger/types';\n\nconst jsonReplacerFn: CustomReplacerFn = (_: string, value: unknown) =&gt;\n  value instanceof Set ? [...value] : value;\n\nconst logger = new Logger({ serviceName: 'serverlessAirline', jsonReplacerFn });\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  logger.info('Serialize with custom serializer', {\n    serializedValue: new Set([1, 2, 3]),\n  });\n};\n</code></pre> <pre><code>{\n  \"level\": \"INFO\",\n  \"message\": \"Serialize with custom serializer\",\n  \"timestamp\": \"2024-07-07T09:52:14.212Z\",\n  \"service\": \"serverlessAirline\",\n  \"sampling_rate\": 0,\n  \"xray_trace_id\": \"1-668a654d-396c646b760ee7d067f32f18\",\n  \"serializedValue\": [\n    1,\n    2,\n    3\n  ]\n}\n</code></pre> <p>By default, Logger uses <code>JSON.stringify()</code> to serialize log items and a custom replacer function to serialize common unserializable values such as <code>BigInt</code>, circular references, and <code>Error</code> objects.</p> <p>When you extend the default JSON serializer, we will call your custom serializer function before the default one. This allows you to customize the serialization while still benefiting from the default behavior.</p>"
        },
        {
            "location": "core/logger/#testing-your-code",
            "title": "Testing your code",
            "text": ""
        },
        {
            "location": "core/logger/#inject-lambda-context",
            "title": "Inject Lambda Context",
            "text": "<p>When unit testing your code that makes use of <code>logger.addContext()</code> or <code>injectLambdaContext</code> middleware and decorator, you can optionally pass a dummy Lambda Context if you want your logs to contain this information.</p> <p>This is a sample that provides the minimum information necessary for Logger to inject context data:</p> handler.test.ts <pre><code>import type { Context } from 'aws-lambda';\nimport { describe, expect, it } from 'vitest';\ndeclare const handler: (event: unknown, context: Context) =&gt; Promise&lt;true&gt;;\n\nconst context = {\n  callbackWaitsForEmptyEventLoop: true,\n  functionVersion: '$LATEST',\n  functionName: 'foo-bar-function',\n  memoryLimitInMB: '128',\n  logGroupName: '/aws/lambda/foo-bar-function-123456abcdef',\n  logStreamName: '2021/03/09/[$LATEST]abcdef123456abcdef123456abcdef123456',\n  invokedFunctionArn:\n    'arn:aws:lambda:eu-west-1:123456789012:function:foo-bar-function',\n  awsRequestId: 'c6af9ac6-7b61-11e6-9a41-93e812345678',\n  getRemainingTimeInMillis: () =&gt; 1234,\n  done: () =&gt; console.log('Done!'),\n  fail: () =&gt; console.log('Failed!'),\n  succeed: () =&gt; console.log('Succeeded!'),\n} satisfies Context;\n\ndescribe('MyUnitTest', () =&gt; {\n  it('invokes the handler successfully', async () =&gt; {\n    // Prepare\n    const testEvent = { test: 'test' };\n\n    // Act\n    const result = await handler(testEvent, context);\n\n    // Assert\n    expect(result).toBe(true);\n  });\n});\n</code></pre>"
        },
        {
            "location": "core/logger/#suppress-logs",
            "title": "Suppress logs",
            "text": "<p>When unit testing your code with Jest or Vitest you can use the <code>POWERTOOLS_DEV</code> environment variable in conjunction with the <code>--silent</code> CLI option to suppress logs from Logger.</p> Disabling logs while testing with Vitest<pre><code>export POWERTOOLS_DEV=true &amp;&amp; npx vitest --silent\n</code></pre> <p>Alternatively, you can also set the <code>POWERTOOLS_DEV</code> environment variable to <code>true</code> in your test setup file, or in a hoisted block at the top of your test file.</p>"
        },
        {
            "location": "core/metrics/",
            "title": "Metrics",
            "text": "<p>Metrics creates custom metrics asynchronously by logging metrics to standard output following Amazon CloudWatch Embedded Metric Format (EMF).</p> <p>These metrics can be visualized through Amazon CloudWatch Console.</p>"
        },
        {
            "location": "core/metrics/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Aggregating up to 100 metrics using a single CloudWatch EMF object (large JSON blob).</li> <li>Validating your metrics against common metric definitions mistakes (for example, metric unit, values, max dimensions, max metrics).</li> <li>Metrics are created asynchronously by the CloudWatch service. You do not need any custom stacks, and there is no impact to Lambda function latency.</li> <li>Creating a one-off metric with different dimensions.</li> </ul> Metrics showcase - Metrics Explorer"
        },
        {
            "location": "core/metrics/#terminologies",
            "title": "Terminologies",
            "text": "<p>If you're new to Amazon CloudWatch, there are two terminologies you must be aware of before using this utility:</p> <ul> <li>Namespace. It's the highest level container that will group multiple metrics from multiple services for a given application, for example <code>ServerlessEcommerce</code>.</li> <li>Dimensions. Metrics metadata in key-value format. They help you slice and dice metrics visualization, for example <code>ColdStart</code> metric by Payment <code>service</code>.</li> <li>Metric. It's the name of the metric, for example: SuccessfulBooking or UpdatedBooking.</li> <li>Unit. It's a value representing the unit of measure for the corresponding metric, for example: Count or Seconds.</li> <li>Resolution. It's a value representing the storage resolution for the corresponding metric. Metrics can be either Standard or High resolution. Read more here.</li> </ul> Metric terminology, visually explained"
        },
        {
            "location": "core/metrics/#getting-started",
            "title": "Getting started",
            "text": ""
        },
        {
            "location": "core/metrics/#installation",
            "title": "Installation",
            "text": "<p>Install the library in your project:</p> <pre><code>npm install @aws-lambda-powertools/metrics\n</code></pre> <p>Caution</p> <p>When using the Lambda Advanced Logging Controls feature you must install version of Powertools for AWS Lambda (TypeScript) v1.15.0 or newer.</p>"
        },
        {
            "location": "core/metrics/#usage",
            "title": "Usage",
            "text": "<p>The <code>Metrics</code> utility must always be instantiated outside of the Lambda handler. In doing this, subsequent invocations processed by the same instance of your function can reuse these resources. This saves cost by reducing function run time. In addition, <code>Metrics</code> can track cold start and emit the appropriate metrics.</p> handler.ts <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n};\n</code></pre>"
        },
        {
            "location": "core/metrics/#utility-settings",
            "title": "Utility settings",
            "text": "<p>The library requires two settings. You can set them as environment variables, or pass them in the constructor.  </p> <p>These settings will be used across all metrics emitted:</p> Setting Description Environment variable Default Allowed Values Example Constructor parameter Service Optionally, sets service metric dimension across all metrics <code>POWERTOOLS_SERVICE_NAME</code> <code>service_undefined</code> Any string <code>serverlessAirline</code> <code>serviceName</code> Metric namespace Logical container where all metrics will be placed <code>POWERTOOLS_METRICS_NAMESPACE</code> <code>default_namespace</code> Any string <code>serverlessAirline</code> <code>default_namespace</code> Function Name Function name used as dimension for the <code>ColdStart</code> metric <code>POWERTOOLS_METRICS_FUNCTION_NAME</code> See docs Any string <code>my-function-name</code> <code>functionName</code> Enabled Whether to emit metrics to standard output or not <code>POWERTOOLS_METRICS_ENABLED</code> <code>true</code> Boolean <code>false</code> <p>Tip</p> <p>Use your application name or main service as the metric namespace to easily group all metrics</p>"
        },
        {
            "location": "core/metrics/#example-using-aws-serverless-application-model-sam",
            "title": "Example using AWS Serverless Application Model (SAM)",
            "text": "<p>The <code>Metrics</code> utility is instantiated outside of the Lambda handler. In doing this, the same instance can be used across multiple invocations inside the same execution environment. This allows <code>Metrics</code> to be aware of things like whether or not a given invocation had a cold start or not.</p> handler.tstemplate.yml <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\n// Metrics parameters fetched from the environment variables (see template.yaml tab)\nconst metrics = new Metrics();\nmetrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n\n// You can also pass the parameters in the constructor\n// const metrics = new Metrics({\n//   namespace: 'serverlessAirline',\n//   serviceName: 'orders'\n// });\n</code></pre> <pre><code>Resources:\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Runtime: nodejs22.x\n      Environment:\n      Variables:\n        POWERTOOLS_SERVICE_NAME: orders\n        POWERTOOLS_METRICS_NAMESPACE: serverlessAirline\n        POWERTOOLS_METRICS_FUNCTION_NAME: my-function-name\n</code></pre> <p>You can initialize Metrics anywhere in your code - It'll keep track of your aggregate metrics in memory.</p>"
        },
        {
            "location": "core/metrics/#creating-metrics",
            "title": "Creating metrics",
            "text": "<p>You can create metrics using the <code>addMetric</code> method, and you can create dimensions for all your aggregate metrics using the <code>addDimension</code> method.</p> MetricsMetrics with custom dimensions <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n  metrics.publishStoredMetrics();\n};\n</code></pre> <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addDimension('environment', 'prod');\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n  metrics.publishStoredMetrics();\n};\n</code></pre> <p>Autocomplete Metric Units</p> <p>Use the <code>MetricUnit</code> enum to easily find a supported metric unit by CloudWatch. Alternatively, you can pass the value as a string if you already know them e.g. \"Count\".</p> <p>Metrics overflow</p> <p>CloudWatch EMF supports a max of 100 metrics per batch. Metrics will automatically propagate all the metrics when adding the 100th metric. Subsequent metrics, e.g. 101th, will be aggregated into a new EMF object, for your convenience.</p> <p>Do not create metrics or dimensions outside the handler</p> <p>Metrics or dimensions added in the global scope will only be added during cold start. Disregard if that's the intended behavior.</p>"
        },
        {
            "location": "core/metrics/#adding-high-resolution-metrics",
            "title": "Adding high-resolution metrics",
            "text": "<p>You can create high-resolution metrics passing <code>resolution</code> as parameter to <code>addMetric</code>.</p> <p>When is it useful?</p> <p>High-resolution metrics are data with a granularity of one second and are very useful in several situations such as telemetry, time series, real-time incident management, and others.</p> Metrics with high resolution <pre><code>import {\n  MetricResolution,\n  MetricUnit,\n  Metrics,\n} from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addMetric(\n    'successfulBooking',\n    MetricUnit.Count,\n    1,\n    MetricResolution.High\n  );\n};\n</code></pre> <p>Autocomplete Metric Resolutions</p> <p>Use the <code>MetricResolution</code> type to easily find a supported metric resolution by CloudWatch. Alternatively, you can pass the allowed values of 1 or 60 as an integer.</p>"
        },
        {
            "location": "core/metrics/#adding-multi-value-metrics",
            "title": "Adding multi-value metrics",
            "text": "<p>You can call <code>addMetric()</code> with the same name multiple times. The values will be grouped together in an array.</p> addMetric() with the same nameExample CloudWatch Logs excerpt <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addMetric('performedActionA', MetricUnit.Count, 2);\n  // do something else...\n  metrics.addMetric('performedActionA', MetricUnit.Count, 1);\n};\n</code></pre> <pre><code>{\n    \"performedActionA\": [\n        2,\n        1\n    ],\n    \"_aws\": {\n        \"Timestamp\": 1592234975665,\n        \"CloudWatchMetrics\": [\n            {\n            \"Namespace\": \"serverlessAirline\",\n            \"Dimensions\": [\n                [\n                \"service\"\n                ]\n            ],\n            \"Metrics\": [\n                {\n                \"Name\": \"performedActionA\",\n                \"Unit\": \"Count\"\n                }\n            ]\n            }\n        ]\n    },\n    \"service\": \"orders\"\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#adding-default-dimensions",
            "title": "Adding default dimensions",
            "text": "<p>You can add default dimensions to your metrics by passing them as parameters in 4 ways:</p> <ul> <li>in the constructor</li> <li>in the Middy-compatible middleware</li> <li>using the <code>setDefaultDimensions</code> method</li> <li>in the decorator</li> </ul> constructorMiddy middlewaresetDefaultDimensions methodwith logMetrics decorator <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n  defaultDimensions: { environment: 'prod', foo: 'bar' },\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n};\n</code></pre> <p>A note about Middy</p> <p>We guarantee support for Middy.js <code>v4.x</code> through <code>v6.x</code> versions. Check their docs to learn more about Middy and its middleware stack as well as best practices when working with Powertools.</p> <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\nimport { logMetrics } from '@aws-lambda-powertools/metrics/middleware';\nimport middy from '@middy/core';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nconst lambdaHandler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n};\n\n// Wrap the handler with middy\nexport const handler = middy(lambdaHandler)\n  // Use the middleware by passing the Metrics instance as a parameter\n  .use(\n    logMetrics(metrics, {\n      defaultDimensions: { environment: 'prod', foo: 'bar' },\n    })\n  );\n</code></pre> <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\nmetrics.setDefaultDimensions({ environment: 'prod', foo: 'bar' });\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n};\n</code></pre> <p>Note</p> <p>The class method decorators in this project follow the experimental implementation enabled via the <code>experimentalDecorators</code> compiler option in TypeScript.</p> <p>Additionally, they are implemented to decorate async methods. When decorating a synchronous one, the decorator replaces its implementation with an async one causing the caller to have to <code>await</code> the now decorated method.</p> <p>If this is not the desired behavior, you can use the <code>logMetrics</code> middleware instead.</p> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\nconst DEFAULT_DIMENSIONS = { environment: 'prod', foo: 'bar' };\n\nexport class Lambda implements LambdaInterface {\n  // Decorate your handler class method\n  @metrics.logMetrics({ defaultDimensions: DEFAULT_DIMENSIONS })\n  public async handler(_event: unknown, _context: unknown): Promise&lt;void&gt; {\n    metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n  }\n}\n\nconst handlerClass = new Lambda();\nexport const handler = handlerClass.handler.bind(handlerClass); // (1)\n</code></pre> <ol> <li>Binding your handler method allows your handler to access <code>this</code> within the class methods.</li> </ol> <p>If you'd like to remove them at some point, you can use the <code>clearDefaultDimensions</code> method.</p>"
        },
        {
            "location": "core/metrics/#changing-default-timestamp",
            "title": "Changing default timestamp",
            "text": "<p>When creating metrics, we use the current timestamp. If you want to change the timestamp of all the metrics you create, utilize the <code>setTimestamp</code> function. You can specify a datetime object or an integer representing an epoch timestamp in milliseconds.</p> <p>Note that when specifying the timestamp using an integer, it must adhere to the epoch timezone format in milliseconds.</p> setTimestamp method <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  const metricTimestamp = new Date(Date.now() - 24 * 60 * 60 * 1000); // 24 hours ago\n  metrics.setTimestamp(metricTimestamp);\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n};\n</code></pre>"
        },
        {
            "location": "core/metrics/#flushing-metrics",
            "title": "Flushing metrics",
            "text": "<p>As you finish adding all your metrics, you need to serialize and \"flush them\" by calling <code>publishStoredMetrics()</code>. This will print the metrics to standard output.</p> <p>You can flush metrics automatically using one of the following methods:  </p> <ul> <li>manually</li> <li>Middy-compatible middleware</li> <li>class decorator</li> </ul> <p>Using the Middy middleware or decorator will automatically validate, serialize, and flush all your metrics. During metrics validation, if no metrics are provided then a warning will be logged, but no exception will be thrown. If you do not use the middleware or decorator, you have to flush your metrics manually.</p> <p>Metric validation</p> <p>If metrics are provided, and any of the following criteria are not met, a <code>RangeError</code> error will be thrown:</p> <ul> <li>Maximum of 29 dimensions</li> <li>Namespace is set only once (or none)</li> <li>Metric units must be supported by CloudWatch</li> </ul>"
        },
        {
            "location": "core/metrics/#middy-middleware",
            "title": "Middy middleware",
            "text": "<p>See below an example of how to automatically flush metrics with the Middy-compatible <code>logMetrics</code> middleware.</p> handler.tsExample CloudWatch Logs excerpt <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\nimport { logMetrics } from '@aws-lambda-powertools/metrics/middleware';\nimport middy from '@middy/core';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nconst lambdaHandler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n};\n\nexport const handler = middy(lambdaHandler).use(logMetrics(metrics));\n</code></pre> <pre><code>{\n    \"successfulBooking\": 1.0,\n    \"_aws\": {\n        \"Timestamp\": 1592234975665,\n        \"CloudWatchMetrics\": [{\n            \"Namespace\": \"serverlessAirline\",\n            \"Dimensions\": [\n                [ \"service\" ]\n            ],\n            \"Metrics\": [{\n                \"Name\": \"successfulBooking\",\n                \"Unit\": \"Count\"\n            }]\n        }]\n    },\n    \"service\": \"orders\"\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#using-the-class-decorator",
            "title": "Using the class decorator",
            "text": "<p>Note</p> <p>The class method decorators in this project follow the experimental implementation enabled via the <code>experimentalDecorators</code> compiler option in TypeScript.</p> <p>Additionally, they are implemented to decorate async methods. When decorating a synchronous one, the decorator replaces its implementation with an async one causing the caller to have to <code>await</code> the now decorated method.</p> <p>If this is not the desired behavior, you can use the <code>logMetrics</code> middleware instead.</p> <p>The <code>logMetrics</code> decorator of the metrics utility can be used when your Lambda handler function is implemented as method of a Class.</p> handler.tsExample CloudWatch Logs excerpt <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nclass Lambda implements LambdaInterface {\n  @metrics.logMetrics()\n  public async handler(_event: unknown, _context: unknown): Promise&lt;void&gt; {\n    metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n  }\n}\n\nconst handlerClass = new Lambda();\nexport const handler = handlerClass.handler.bind(handlerClass); // (1)\n</code></pre> <ol> <li>Binding your handler method allows your handler to access <code>this</code> within the class methods.</li> </ol> <pre><code>{\n    \"successfulBooking\": 1.0,\n    \"_aws\": {\n        \"Timestamp\": 1592234975665,\n        \"CloudWatchMetrics\": [{\n            \"Namespace\": \"successfulBooking\",\n            \"Dimensions\": [\n                [ \"service\" ]\n            ],\n            \"Metrics\": [{\n                \"Name\": \"successfulBooking\",\n                \"Unit\": \"Count\"\n            }]\n        }]\n    },\n    \"service\": \"orders\"\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#manually",
            "title": "Manually",
            "text": "<p>You can manually flush the metrics with <code>publishStoredMetrics</code> as follows:</p> <p>Warning</p> <p>Metrics, dimensions and namespace validation still applies.</p> handler.tsExample CloudWatch Logs excerpt <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 10);\n  metrics.publishStoredMetrics();\n};\n</code></pre> <pre><code>{\n    \"successfulBooking\": 1.0,\n    \"_aws\": {\n        \"Timestamp\": 1592234975665,\n        \"CloudWatchMetrics\": [{\n            \"Namespace\": \"successfulBooking\",\n            \"Dimensions\": [\n                [ \"service\" ]\n            ],\n            \"Metrics\": [{\n                \"Name\": \"successfulBooking\",\n                \"Unit\": \"Count\"\n            }]\n        }]\n    },\n    \"service\": \"orders\"\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#throwing-a-rangeerror-when-no-metrics-are-emitted",
            "title": "Throwing a RangeError when no metrics are emitted",
            "text": "<p>If you want to ensure that at least one metric is emitted before you flush them, you can use the <code>throwOnEmptyMetrics</code> parameter and pass it to the middleware or decorator:</p> handler.ts <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\nimport { logMetrics } from '@aws-lambda-powertools/metrics/middleware';\nimport middy from '@middy/core';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nconst lambdaHandler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n};\n\nexport const handler = middy(lambdaHandler).use(\n  logMetrics(metrics, { throwOnEmptyMetrics: true })\n);\n</code></pre>"
        },
        {
            "location": "core/metrics/#capturing-a-cold-start-invocation-as-metric",
            "title": "Capturing a cold start invocation as metric",
            "text": "<p>You can optionally capture cold start metrics with the <code>logMetrics</code> middleware or decorator via the <code>captureColdStartMetric</code> param.</p> Middy MiddlewarelogMetrics decorator <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\nimport { logMetrics } from '@aws-lambda-powertools/metrics/middleware';\nimport middy from '@middy/core';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nconst lambdaHandler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n};\n\nexport const handler = middy(lambdaHandler).use(\n  logMetrics(metrics, { captureColdStartMetric: true })\n);\n</code></pre> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nexport class MyFunction implements LambdaInterface {\n  @metrics.logMetrics({ captureColdStartMetric: true })\n  public async handler(_event: unknown, _context: unknown): Promise&lt;void&gt; {\n    metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n  }\n}\n</code></pre> <p>If it's a cold start invocation, this feature will:</p> <ul> <li>Create a separate EMF blob solely containing a metric named <code>ColdStart</code></li> <li>Add the <code>function_name</code>, <code>service</code> and default dimensions</li> </ul> <p>This has the advantage of keeping cold start metric separate from your application metrics, where you might have unrelated dimensions.</p> <p>We do not emit 0 as a value for the ColdStart metric for cost-efficiency reasons. Let us know if you'd prefer a flag to override it.</p>"
        },
        {
            "location": "core/metrics/#setting-function-name",
            "title": "Setting function name",
            "text": "<p>When emitting cold start metrics, the <code>function_name</code> dimension defaults to <code>context.functionName</code>. If you want to change the value you can set the <code>functionName</code> parameter in the metrics constructor, define the environment variable <code>POWERTOOLS_METRICS_FUNCTION_NAME</code>, or pass a value to <code>captureColdStartMetric</code>.</p> <p>The priority of the <code>function_name</code> dimension value is defined as:</p> <ol> <li><code>functionName</code> constructor option</li> <li><code>POWERTOOLS_METRICS_FUNCTION_NAME</code> environment variable</li> <li>The value passed in the <code>captureColdStartMetric</code> call, or <code>context.functionName</code> if using logMetrics decorator or Middy middleware</li> </ol> constructorcaptureColdStartMetric method <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n  functionName: 'my-function-name',\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.captureColdStartMetric();\n\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n\n  metrics.publishStoredMetrics();\n};\n</code></pre> <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.captureColdStartMetric('my-function-name');\n\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n\n  metrics.publishStoredMetrics();\n};\n</code></pre>"
        },
        {
            "location": "core/metrics/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/metrics/#adding-metadata",
            "title": "Adding metadata",
            "text": "<p>You can add high-cardinality data as part of your Metrics log with the <code>addMetadata</code> method. This is useful when you want to search highly contextual information along with your metrics in your logs.</p> <p>Info</p> <p>This will not be available during metrics visualization - Use dimensions for this purpose</p> handler.tsExample CloudWatch Logs excerpt <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\nimport { logMetrics } from '@aws-lambda-powertools/metrics/middleware';\nimport middy from '@middy/core';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nconst lambdaHandler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  metrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n  metrics.addMetadata('bookingId', '7051cd10-6283-11ec-90d6-0242ac120003');\n};\n\nexport const handler = middy(lambdaHandler).use(logMetrics(metrics));\n</code></pre> <pre><code>{\n    \"successfulBooking\": 1.0,\n    \"_aws\": {\n        \"Timestamp\": 1592234975665,\n        \"CloudWatchMetrics\": [{\n            \"Namespace\": \"serverlessAirline\",\n            \"Dimensions\": [\n                [ \"service\" ]\n            ],\n            \"Metrics\": [{\n                \"Namespace\": \"exampleApplication\",\n                \"Dimensions\": [\n                    [ \"service\" ]\n                ],\n                \"Metrics\": [{\n                    \"Name\": \"successfulBooking\",\n                    \"Unit\": \"Count\"\n                }]\n            }]\n        }]\n    },\n    \"service\": \"orders\",\n    \"bookingId\": \"7051cd10-6283-11ec-90d6-0242ac120003\"\n}\n</code></pre>"
        },
        {
            "location": "core/metrics/#single-metric-with-different-dimensions",
            "title": "Single metric with different dimensions",
            "text": "<p>CloudWatch EMF uses the same dimensions across all your metrics. Use <code>singleMetric</code> if you have a metric that should have different dimensions.</p> <p>Generally, using different dimensions would be an edge case since you pay for unique metric.</p> <p>Keep the following formula in mind: <code>unique metric = (metric_name + dimension_name + dimension_value)</code>.</p> Single Metric <pre><code>import { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst metrics = new Metrics({\n  namespace: 'serverlessAirline',\n  serviceName: 'orders',\n});\n\nexport const handler = async (event: { orderId: string }) =&gt; {\n  const singleMetric = metrics.singleMetric();\n  singleMetric.addDimension('metricType', 'business');\n  singleMetric.addMetadata('orderId', event.orderId); // (1)!\n  singleMetric.addMetric('successfulBooking', MetricUnit.Count, 1); // (2)!\n};\n</code></pre> <ol> <li>Metadata should be added before calling <code>addMetric()</code> to ensure it's included in the same EMF blob.</li> <li>Single metrics are emitted as soon as <code>addMetric()</code> is called, so you don't need to call <code>publishStoredMetrics()</code>.</li> </ol>"
        },
        {
            "location": "core/metrics/#customizing-the-logger",
            "title": "Customizing the logger",
            "text": "<p>You can customize how Metrics logs warnings and debug messages to standard output by passing a custom logger as a constructor parameter. This is useful when you want to silence warnings or debug messages, or when you want to log them to a different output.</p> Custom logger <pre><code>import { LogLevel, Logger } from '@aws-lambda-powertools/logger';\nimport { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\n\nconst logger = new Logger({ logLevel: LogLevel.CRITICAL });\nconst metrics = new Metrics({\n  serviceName: 'serverless-airline',\n  namespace: 'orders',\n  singleMetric: true,\n  logger,\n});\n\nmetrics.addMetric('successfulBooking', MetricUnit.Count, 1);\n</code></pre>"
        },
        {
            "location": "core/metrics/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>When unit testing your code that uses the Metrics utility, you may want to silence the logs emitted by the utility. To do so, you can set the <code>POWERTOOLS_DEV</code> environment variable to <code>true</code>. This instructs the utility to not emit any logs to standard output.</p> <p>If instead you want to spy on the logs emitted by the utility, you must set the <code>POWERTOOLS_DEV</code> environment variable to <code>true</code> in conjunction with the <code>POWERTOOLS_METRICS_ENABLED</code> environment variable also set to <code>true</code>.</p> <p>When <code>POWERTOOLS_DEV</code> is enabled, Metrics uses the global <code>console</code> to emit metrics to standard out. This allows you to easily spy on the logs emitted and make assertions on them.</p> Spying on emitted metrics <pre><code>import { describe, expect, it, vi } from 'vitest';\n\nvi.hoisted(() =&gt; {\n  process.env.POWERTOOLS_DEV = 'true';\n  process.env.POWERTOOLS_METRICS_ENABLED = 'true';\n});\n\ndescribe('Metrics tests', () =&gt; {\n  it('emits metrics properly', async () =&gt; {\n    // Prepare\n    const metricsEmittedSpy = vi\n      .spyOn(console, 'log')\n      .mockImplementation(() =&gt; {});\n\n    // Act\n    // ...\n\n    // Assess\n    expect(metricsEmittedSpy).toHaveBeenCalledOnce();\n  });\n});\n</code></pre>"
        },
        {
            "location": "core/tracer/",
            "title": "Tracer",
            "text": "<p>Tracer is an opinionated thin wrapper for AWS X-Ray SDK for Node.js.</p>"
        },
        {
            "location": "core/tracer/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Auto-capturing cold start and service name as annotations, and responses or full exceptions as metadata.</li> <li>Automatically tracing HTTP(S) clients including <code>fetch</code> and generating segments for each request.</li> <li>Supporting tracing functions via decorators, middleware, and manual instrumentation.</li> <li>Supporting tracing AWS SDK v2 and v3 via AWS X-Ray SDK for Node.js.</li> <li>Auto-disable tracing when not running in the Lambda environment.</li> </ul> Tracer showcase - Handler Annotations"
        },
        {
            "location": "core/tracer/#getting-started",
            "title": "Getting started",
            "text": "<p>Tracer relies on AWS X-Ray SDK over OpenTelemetry Distro (ADOT) for optimal cold start (lower latency).</p>"
        },
        {
            "location": "core/tracer/#installation",
            "title": "Installation",
            "text": "<p>Install the library in your project:</p> <pre><code>npm install @aws-lambda-powertools/tracer\n</code></pre>"
        },
        {
            "location": "core/tracer/#usage",
            "title": "Usage",
            "text": "<p>The <code>Tracer</code> utility must always be instantiated outside of the Lambda handler. In doing this, subsequent invocations processed by the same instance of your function can reuse these resources. This saves cost by reducing function run time. In addition, <code>Tracer</code> can track cold start and annotate the traces accordingly.</p> handler.ts <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nexport const handler = async (_event, _context): Promise&lt;void&gt; =&gt; {\n  tracer.getSegment();\n};\n</code></pre>"
        },
        {
            "location": "core/tracer/#using-with-esm",
            "title": "Using with ESM?",
            "text": "<p>Tracer relies on the AWS X-Ray SDK for Node.js, which is distributed as a CommonJS module and uses <code>require</code>.</p> <p>To use it in an ESM project, you can instruct your bundler to use the <code>require</code> syntax for specific dependencies while using ESM for everything else. This is commonly known as polyfill.</p> Code snippets for AWS CDK and AWS SAM CLI with <code>esbuild</code> With AWS CDKWith AWS SAM <pre><code>import { Stack, type StackProps } from 'aws-cdk-lib';\nimport { Construct } from 'constructs';\nimport { NodejsFunction, OutputFormat } from 'aws-cdk-lib/aws-lambda-nodejs';\nimport { Runtime } from 'aws-cdk-lib/aws-lambda';\n\nexport class MyStack extends Stack {\npublic constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const handler = new NodejsFunction(this, 'helloWorldFunction', {\n    runtime: Runtime.NODEJS_22_X,\n    handler: 'handler',\n    entry: 'src/index.ts',\n    bundling: {\n        format: OutputFormat.ESM,\n        minify: true,\n        esbuildArgs: {\n        \"--tree-shaking\": \"true\",\n        },\n        banner: \n        \"import { createRequire } from 'module';const require = createRequire(import.meta.url);\", // (1)!\n    },\n    });\n}\n}\n</code></pre> <ol> <li><code>esbuild</code> will include this arbitrary code at the top of your bundle to maximize CommonJS compatibility (<code>require</code> keyword).</li> </ol> <pre><code>Transform: AWS::Serverless-2016-10-31\nResources:\nHelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n    Runtime: nodejs22.x\n    Handler: src/index.handler\n    Metadata:\n    BuildMethod: esbuild\n    BuildProperties:\n        Minify: true\n        Target: 'ES2020'\n        Sourcemap: true\n        Format: esm\n        EntryPoints:\n        - src/index.ts\n        Banner:\n        js: \"import { createRequire } from 'module';const require = createRequire(import.meta.url);\"  # (1)!\n</code></pre> <ol> <li><code>esbuild</code> will include this arbitrary code at the top of your bundle to maximize CommonJS compatibility (<code>require</code> keyword).</li> </ol>"
        },
        {
            "location": "core/tracer/#utility-settings",
            "title": "Utility settings",
            "text": "<p>The library has three optional settings. You can set them as environment variables, or pass them in the constructor:</p> Setting Description Environment variable Default Allowed Values Example Constructor parameter Service name Sets an annotation with the name of the service across all traces <code>POWERTOOLS_SERVICE_NAME</code> <code>service_undefined</code> Any string <code>serverlessAirline</code> <code>serviceName</code> Tracing enabled Enables or disables tracing. <code>POWERTOOLS_TRACE_ENABLED</code> <code>true</code> <code>true</code> or <code>false</code> <code>false</code> <code>enabled</code> Capture HTTPs Requests Defines whether HTTPs requests will be traced or not <code>POWERTOOLS_TRACER_CAPTURE_HTTPS_REQUESTS</code> <code>true</code> <code>true</code> or <code>false</code> <code>false</code> <code>captureHTTPsRequests</code> Capture Response Defines whether functions responses are serialized as metadata <code>POWERTOOLS_TRACER_CAPTURE_RESPONSE</code> <code>true</code> <code>true</code> or <code>false</code> <code>false</code> <code>captureResult</code> Capture Errors Defines whether functions errors are serialized as metadata <code>POWERTOOLS_TRACER_CAPTURE_ERROR</code> <code>true</code> <code>true</code> or <code>false</code> <code>false</code> N/A <p>Note</p> <p>Before you use this utility, your AWS Lambda function must have Active Tracing enabled as well as have permissions to send traces to AWS X-Ray</p>"
        },
        {
            "location": "core/tracer/#example-using-aws-serverless-application-model-sam",
            "title": "Example using AWS Serverless Application Model (SAM)",
            "text": "<p>The <code>Tracer</code> utility is instantiated outside of the Lambda handler. In doing this, the same instance can be used across multiple invocations inside the same execution environment. This allows <code>Tracer</code> to be aware of things like whether or not a given invocation had a cold start or not.</p> handler.tstemplate.yml <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\n\n// Tracer parameter fetched from the environment variables (see template.yaml tab)\nconst tracer = new Tracer();\ntracer.getSegment();\n\n// You can also pass the parameter in the constructor\n// const tracer = new Tracer({\n//     serviceName: 'serverlessAirline'\n// });\n</code></pre> <pre><code>Resources:\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Runtime: nodejs22.x\n      Tracing: Active\n      Environment:\n        Variables:\n          POWERTOOLS_SERVICE_NAME: serverlessAirline\n</code></pre>"
        },
        {
            "location": "core/tracer/#lambda-handler",
            "title": "Lambda handler",
            "text": "<p>You can quickly start by importing the <code>Tracer</code> class, initialize it outside the Lambda handler, and instrument your function.</p> Middy MiddlewareDecoratorManual <p>A note about Middy</p> <p>We guarantee support for Middy.js <code>v4.x</code> through <code>v6.x</code> versions. Check their docs to learn more about Middy and its middleware stack as well as best practices when working with Powertools.</p> <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\nimport { captureLambdaHandler } from '@aws-lambda-powertools/tracer/middleware';\nimport middy from '@middy/core';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nconst lambdaHandler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  tracer.putAnnotation('successfulBooking', true);\n};\n\n// Wrap the handler with middy\nexport const handler = middy(lambdaHandler)\n  // Use the middleware by passing the Tracer instance as a parameter\n  .use(captureLambdaHandler(tracer));\n</code></pre> <p>Note</p> <p>The class method decorators in this project follow the experimental implementation enabled via the <code>experimentalDecorators</code> compiler option in TypeScript.</p> <p>Additionally, they are implemented to decorate async methods. When decorating a synchronous one, the decorator replaces its implementation with an async one causing the caller to have to <code>await</code> the now decorated method.</p> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Tracer } from '@aws-lambda-powertools/tracer';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nclass Lambda implements LambdaInterface {\n  // Decorate your handler class method\n  @tracer.captureLambdaHandler()\n  public async handler(_event: unknown, _context: unknown): Promise&lt;void&gt; {\n    tracer.getSegment();\n  }\n}\n\nconst handlerClass = new Lambda();\nexport const handler = handlerClass.handler.bind(handlerClass); // (1)\n</code></pre> <ol> <li>Binding your handler method allows your handler to access <code>this</code>.</li> </ol> <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\nimport type { Subsegment } from 'aws-xray-sdk-core';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;unknown&gt; =&gt; {\n  const segment = tracer.getSegment(); // This is the facade segment (the one that is created by AWS Lambda)\n  let subsegment: Subsegment | undefined;\n  if (segment) {\n    // Create subsegment for the function &amp; set it as active\n    subsegment = segment.addNewSubsegment(`## ${process.env._HANDLER}`);\n    tracer.setSegment(subsegment);\n  }\n\n  // Annotate the subsegment with the cold start &amp; serviceName\n  tracer.annotateColdStart();\n  tracer.addServiceNameAnnotation();\n\n  try {\n    // Add the response as metadata\n    tracer.addResponseAsMetadata({}, process.env._HANDLER);\n  } catch (err) {\n    // Add the error as metadata\n    tracer.addErrorAsMetadata(err as Error);\n    throw err;\n  } finally {\n    if (segment &amp;&amp; subsegment) {\n      // Close subsegment (the AWS Lambda one is closed automatically)\n      subsegment.close();\n      // Set back the facade segment as active again\n      tracer.setSegment(segment);\n    }\n  }\n\n  return {};\n};\n</code></pre> <p>When using the <code>captureLambdaHandler</code> decorator or middleware, Tracer performs these additional tasks to ease operations:</p> <ul> <li>Handles the lifecycle of the subsegment</li> <li>Creates a <code>ColdStart</code> annotation to easily filter traces that have had an initialization overhead</li> <li>Creates a <code>Service</code> annotation to easily filter traces that have a specific service name</li> <li>Captures any response, or full exceptions generated by the handler, and include them as tracing metadata</li> </ul>"
        },
        {
            "location": "core/tracer/#annotations-metadata",
            "title": "Annotations &amp; Metadata",
            "text": "<p>Annotations are key-values associated with traces and indexed by AWS X-Ray. You can use them to filter traces and to create Trace Groups to slice and dice your transactions.</p> <p>Metadata are key-values also associated with traces but not indexed by AWS X-Ray. You can use them to add additional context for an operation using any native object.</p> AnnotationsMetadata <p>You can add annotations using <code>putAnnotation</code> method.</p> <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  const handlerSegment = tracer.getSegment()?.addNewSubsegment('### handler');\n  handlerSegment &amp;&amp; tracer.setSegment(handlerSegment); // (1)!\n\n  tracer.putAnnotation('successfulBooking', true);\n\n  handlerSegment?.close();\n  handlerSegment &amp;&amp; tracer.setSegment(handlerSegment?.parent); // (2)!\n};\n</code></pre> <ol> <li>When Lambda starts an invocation the X-Ray SDk creates a segment called <code>facade</code>. This segment cannot be annotated or modified by your code, so you need to create a new subsegment. This is done automatically by Tracer when using the decorator or middleware patterns</li> <li>To correctly trace the current and subsequent invocations you need to restore the original segment, this is done automatically by Tracer when using the decorator or middleware patterns.</li> </ol> <p>You can add metadata using <code>putMetadata</code> method.</p> <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  const handlerSegment = tracer.getSegment()?.addNewSubsegment('### handler');\n  handlerSegment &amp;&amp; tracer.setSegment(handlerSegment); // (1)!\n\n  tracer.putMetadata('paymentResponse', {\n    foo: 'bar',\n  });\n\n  handlerSegment?.close();\n  handlerSegment &amp;&amp; tracer.setSegment(handlerSegment?.parent); // (2)!\n};\n</code></pre> <ol> <li>When Lambda starts an invocation the X-Ray SDk creates a segment called <code>facade</code>. This segment cannot be modified by your code, so you need to create a new subsegment. This is done automatically by Tracer when using the decorator or middleware patterns</li> <li>To correctly trace the current and subsequent invocations you need to restore the original segment, this is done automatically by Tracer when using the decorator or middleware patterns.</li> </ol> Tracer showcase - Handler Metadata"
        },
        {
            "location": "core/tracer/#methods",
            "title": "Methods",
            "text": "<p>You can trace other class methods using the <code>captureMethod</code> decorator or any arbitrary asynchronous function using manual instrumentation.</p> DecoratorManual <p>Note</p> <p>The class method decorators in this project follow the experimental implementation enabled via the <code>experimentalDecorators</code> compiler option in TypeScript.</p> <p>Additionally, they are implemented to decorate async methods. When decorating a synchronous one, the decorator replaces its implementation with an async one causing the caller to have to <code>await</code> the now decorated method.</p> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Tracer } from '@aws-lambda-powertools/tracer';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nclass Lambda implements LambdaInterface {\n  // Decorate your class method\n  @tracer.captureMethod() // (1)\n  public async getChargeId(): Promise&lt;string&gt; {\n    /* ... */\n    return 'foo bar';\n  }\n\n  public async handler(_event: unknown, _context: unknown): Promise&lt;void&gt; {\n    await this.getChargeId();\n  }\n}\n\nconst handlerClass = new Lambda();\nexport const handler = handlerClass.handler.bind(handlerClass); // (2)\n</code></pre> <ol> <li>You can set a custom name for the subsegment by passing <code>subSegmentName</code> to the decorator, like: <code>@tracer.captureMethod({ subSegmentName: '### myCustomMethod' })</code>.</li> <li>Binding your handler method allows your handler to access <code>this</code>.</li> </ol> <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\nimport type { Subsegment } from 'aws-xray-sdk-core';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nconst getChargeId = async (): Promise&lt;unknown&gt; =&gt; {\n  const parentSubsegment = tracer.getSegment(); // This is the subsegment currently active\n  let subsegment: Subsegment | undefined;\n  if (parentSubsegment) {\n    // Create subsegment for the function &amp; set it as active\n    subsegment = parentSubsegment.addNewSubsegment('### chargeId');\n    tracer.setSegment(subsegment);\n  }\n\n  let res: unknown;\n  try {\n    /* ... */\n    // Add the response as metadata\n    tracer.addResponseAsMetadata(res, 'chargeId');\n  } catch (err) {\n    // Add the error as metadata\n    tracer.addErrorAsMetadata(err as Error);\n    throw err;\n  }\n\n  if (parentSubsegment &amp;&amp; subsegment) {\n    // Close subsegment (the AWS Lambda one is closed automatically)\n    subsegment.close();\n    // Set the facade segment as active again\n    tracer.setSegment(parentSubsegment);\n  }\n\n  return res;\n};\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  await getChargeId();\n};\n</code></pre>"
        },
        {
            "location": "core/tracer/#patching-aws-sdk-clients",
            "title": "Patching AWS SDK clients",
            "text": "<p>Tracer can patch any AWS SDK clients and create traces when your application makes calls to AWS services.</p> <p>Info</p> <p>The following snippet assumes you are using the AWS SDK v3 for JavaScript</p> <p>You can patch any AWS SDK clients by calling the <code>captureAWSv3Client</code> method:</p> index.ts <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\nimport { SecretsManagerClient } from '@aws-sdk/client-secrets-manager';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n// Instrument the AWS SDK client\nconst client = tracer.captureAWSv3Client(new SecretsManagerClient({}));\n\nexport default client;\n</code></pre> <p>Info</p> <p>The following two snippets assume you are using the AWS SDK v2 for JavaScript</p> <p>You can patch all AWS SDK v2 clients by calling the <code>captureAWS</code> method:</p> index.ts <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\nimport AWS from 'aws-sdk';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\n// Instrument all AWS SDK clients created from this point onwards\ntracer.captureAWS(AWS);\n\n// Create a new client which will be automatically instrumented\nconst client = new AWS.SecretsManager();\nexport default client;\n</code></pre> <p>If you're looking to shave a few microseconds, or milliseconds depending on your function memory configuration, you can patch only specific AWS SDK v2 clients using <code>captureAWSClient</code>:</p> index.ts <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\nimport { S3 } from 'aws-sdk';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n// Instrument the AWS SDK client\nconst client = tracer.captureAWSClient(new S3());\n\nexport default client;\n</code></pre>"
        },
        {
            "location": "core/tracer/#tracing-http-requests",
            "title": "Tracing HTTP requests",
            "text": "<p>When your function makes outgoing requests to APIs, Tracer automatically traces those calls and adds the API to the service graph as a downstream service.</p> <p>You can opt-out from this feature by setting the <code>POWERTOOLS_TRACER_CAPTURE_HTTPS_REQUESTS=false</code> environment variable or by passing the <code>captureHTTPsRequests: false</code> option to the <code>Tracer</code> constructor.</p> <p>Info</p> <p>The following snippet shows how to trace <code>fetch</code> requests, but you can use any HTTP client library built on top it, or on http, and https. Support to 3rd party HTTP clients is provided on a best effort basis.</p> index.ts <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\nimport { captureLambdaHandler } from '@aws-lambda-powertools/tracer/middleware';\nimport middy from '@middy/core';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nexport const handler = middy(\n  async (_event: unknown, _context: unknown): Promise&lt;void&gt; =&gt; {\n    await fetch('https://httpbin.org/status/200');\n  }\n).use(captureLambdaHandler(tracer));\n</code></pre> <pre><code>{\n    \"id\": \"22883fbc730e3a0b\",\n    \"name\": \"## index.handler\",\n    \"start_time\": 1647956168.22749,\n    \"end_time\": 1647956169.0679862,\n    \"subsegments\": [\n        {\n            \"id\": \"ab82ab2b7d525d8f\",\n            \"name\": \"httpbin.org\",\n            \"start_time\": 1647956168.407,\n            \"end_time\": 1647956168.945,\n            \"http\": {\n                \"request\": {\n                    \"url\": \"https://httpbin.org/status/200\",\n                    \"method\": \"GET\"\n                },\n                \"response\": {\n                    \"status\": 200,\n                    \"content_length\": 0\n                }\n            },\n            \"namespace\": \"remote\"\n        }\n    ]\n}\n</code></pre>"
        },
        {
            "location": "core/tracer/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "core/tracer/#disabling-response-auto-capture",
            "title": "Disabling response auto-capture",
            "text": "<p>Use <code>POWERTOOLS_TRACER_CAPTURE_RESPONSE=false</code> environment variable to instruct Tracer not to serialize function responses as metadata.</p> <p>This is commonly useful in three scenarios</p> <ol> <li>You might return sensitive information you don't want it to be added to your traces</li> <li>You might manipulate streaming objects that can be read only once; this prevents subsequent calls from being empty</li> <li>You might return more than 64K of data e.g., <code>message too long</code> error</li> </ol> <p>Alternatively, use the <code>captureResponse: false</code> option in both <code>tracer.captureLambdaHandler()</code> and <code>tracer.captureMethod()</code> decorators, or use the same option in the Middy <code>captureLambdaHandler</code> middleware to instruct Tracer not to serialize function responses as metadata.</p> method.tshandler.tsmiddy.ts <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Tracer } from '@aws-lambda-powertools/tracer';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nclass Lambda implements LambdaInterface {\n  @tracer.captureMethod({ captureResponse: false })\n  public async getChargeId(): Promise&lt;string&gt; {\n    /* ... */\n    return 'foo bar';\n  }\n\n  public async handler(_event: unknown, _context: unknown): Promise&lt;void&gt; {\n    /* ... */\n  }\n}\n\nconst handlerClass = new Lambda();\nexport const handler = handlerClass.handler.bind(handlerClass);\n</code></pre> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Tracer } from '@aws-lambda-powertools/tracer';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nclass Lambda implements LambdaInterface {\n  @tracer.captureLambdaHandler({ captureResponse: false })\n  public async handler(_event: unknown, _context: unknown): Promise&lt;void&gt; {\n    tracer.getSegment();\n  }\n}\n\nconst handlerClass = new Lambda();\nexport const handler = handlerClass.handler.bind(handlerClass);\n</code></pre> <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\nimport { captureLambdaHandler } from '@aws-lambda-powertools/tracer/middleware';\nimport middy from '@middy/core';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nconst lambdaHandler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;void&gt; =&gt; {\n  /* ... */\n};\n\n// Wrap the handler with middy\nexport const handler = middy(lambdaHandler)\n  // Use the middleware by passing the Tracer instance as a parameter,\n  // but specify the captureResponse option as false.\n  .use(captureLambdaHandler(tracer, { captureResponse: false }));\n</code></pre>"
        },
        {
            "location": "core/tracer/#disabling-errors-auto-capture",
            "title": "Disabling errors auto-capture",
            "text": "<p>Use <code>POWERTOOLS_TRACER_CAPTURE_ERROR=false</code> environment variable to instruct Tracer not to serialize errors as metadata.</p> <p>Commonly useful in one scenario</p> <ol> <li>You might return sensitive information from errors, stack traces you might not control</li> </ol>"
        },
        {
            "location": "core/tracer/#access-aws-x-ray-root-trace-id",
            "title": "Access AWS X-Ray Root Trace ID",
            "text": "<p>Tracer exposes a <code>getRootXrayTraceId()</code> method that allows you to retrieve the AWS X-Ray Root Trace ID corresponds to the current function execution.</p> <p>This is commonly useful in two scenarios</p> <ol> <li>By including the root trace id in your response, consumers can use it to correlate requests</li> <li>You might want to surface the root trace id to your end users so that they can reference it while contacting customer service</li> </ol> index.ts <pre><code>import { Tracer } from '@aws-lambda-powertools/tracer';\n\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nexport const handler = async (): Promise&lt;unknown&gt; =&gt; {\n  try {\n    throw new Error('Something went wrong');\n  } catch (err) {\n    const rootTraceId = tracer.getRootXrayTraceId();\n\n    // Example of returning an error response\n    return {\n      statusCode: 500,\n      body: `Internal Error - Please contact support and quote the following id: ${rootTraceId}`,\n      headers: { _X_AMZN_TRACE_ID: rootTraceId },\n    };\n  }\n};\n</code></pre>"
        },
        {
            "location": "core/tracer/#escape-hatch-mechanism",
            "title": "Escape hatch mechanism",
            "text": "<p>You can use <code>tracer.provider</code> attribute to access a subset of the methods provided by the AWS X-Ray SDK.</p> <p>This is useful when you need a feature available in X-Ray that is not available in the Tracer utility, for example SQL queries tracing, or a custom logger.</p> index.ts <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { Tracer } from '@aws-lambda-powertools/tracer';\n\nconst serviceName = 'serverlessAirline';\nconst logger = new Logger({ serviceName: serviceName });\nconst tracer = new Tracer({ serviceName: serviceName });\ntracer.provider.setLogger(logger);\n</code></pre> <p>If you need to access a method that is not available you can import it directly from the AWS X-Ray SDK for Node.js. Compatibility with the Tracer utility is not guaranteed.</p>"
        },
        {
            "location": "core/tracer/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>Tracer is disabled by default when not running in the AWS Lambda environment - This means no code changes or environment variables to be set.</p>"
        },
        {
            "location": "core/tracer/#tips",
            "title": "Tips",
            "text": "<ul> <li>Use annotations on key operations to slice and dice traces, create unique views, and create metrics from it via Trace Groups</li> <li>Use a namespace when adding metadata to group data more easily</li> <li>Annotations and metadata are added to the currently open subsegment. If you want them in a specific subsegment, create one via the escape hatch mechanism</li> </ul>"
        },
        {
            "location": "core/event-handler/api-gateway/",
            "title": "REST API",
            "text": "Don't use in production (yet) <p>This feature is currently under development. As such it's considered not stable and we might make significant breaking changes before going before its release. You are welcome to provide feedback and contribute to the project.</p> <p>Event handler for Amazon API Gateway REST and HTTP APIs, Application Loader Balancer (ALB), Lambda Function URLs, and VPC Lattice.</p>"
        },
        {
            "location": "core/event-handler/api-gateway/#key-features",
            "title": "Key Features",
            "text": "<ul> <li>Lightweight routing to reduce boilerplate for API Gateway REST/HTTP API, ALB and Lambda Function URLs.</li> <li>Support for CORS, binary and Gzip compression, Decimals JSON encoding and bring your own JSON serializer</li> <li>Built-in integration with Parser for easy payload validation and parsing</li> <li>Works with micro function (one or a few routes) and monolithic functions (all routes)</li> </ul>"
        },
        {
            "location": "core/event-handler/api-gateway/#getting-started",
            "title": "Getting started",
            "text": "Tip <p>All examples shared in this documentation are available within the project repository.</p>"
        },
        {
            "location": "core/event-handler/api-gateway/#install",
            "title": "Install",
            "text": "<pre><code>npm install @aws-lambda-powertools/event-handler\n</code></pre>"
        },
        {
            "location": "core/event-handler/api-gateway/#required-resources",
            "title": "Required resources",
            "text": "<p>If you're using any API Gateway integration, you must have an existing API Gateway Proxy integration or ALB configured to invoke your Lambda function.</p> <p>In case of using VPC Lattice, you must have a service network configured to invoke your Lambda function.</p> <p>This is the sample infrastructure for API Gateway and Lambda Function URLs we are using for the examples in this documentation.</p> There is no additional permissions or dependencies required to use this utility. API Gateway SAM TemplateLambda Function URL SAM Template <p>```yaml title=\"AWS Serverless Application Model (SAM) example\"</p> <p>```</p> <p>```yaml title=\"AWS Serverless Application Model (SAM) example\"</p> <p>```</p>"
        },
        {
            "location": "utilities/batch/",
            "title": "Batch Processing",
            "text": "<p>The batch processing utility handles partial failures when processing batches from Amazon SQS, Amazon Kinesis Data Streams, and Amazon DynamoDB Streams.</p> <pre><code>stateDiagram-v2\n    direction LR\n    BatchSource: Amazon SQS &lt;br/&gt;&lt;br/&gt; Amazon Kinesis Data Streams &lt;br/&gt;&lt;br/&gt; Amazon DynamoDB Streams &lt;br/&gt;&lt;br/&gt;\n    LambdaInit: Lambda invocation\n    BatchProcessor: Batch Processor\n    RecordHandler: Record Handler function\n    YourLogic: Your logic to process each batch item\n    LambdaResponse: Lambda response\n\n    BatchSource --&gt; LambdaInit\n\n    LambdaInit --&gt; BatchProcessor\n    BatchProcessor --&gt; RecordHandler\n\n    state BatchProcessor {\n        [*] --&gt; RecordHandler: Your function\n        RecordHandler --&gt; YourLogic\n    }\n\n    RecordHandler --&gt; BatchProcessor: Collect results\n    BatchProcessor --&gt; LambdaResponse: Report items that failed processing</code></pre>"
        },
        {
            "location": "utilities/batch/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Reports batch item failures to reduce number of retries for a record upon errors</li> <li>Simple interface to process each batch record</li> <li>Build your own batch processor by extending primitives</li> </ul>"
        },
        {
            "location": "utilities/batch/#background",
            "title": "Background",
            "text": "<p>When using SQS, Kinesis Data Streams, or DynamoDB Streams as a Lambda event source, your Lambda functions are triggered with a batch of messages.</p> <p>If your function fails to process any message from the batch, the entire batch returns to your queue or stream. This same batch is then retried until either condition happens first: a) your Lambda function returns a successful response, b) record reaches maximum retry attempts, or c) when records expire.</p> <pre><code>journey\n  section Conditions\n    Successful response: 5: Success\n    Maximum retries: 3: Failure\n    Records expired: 1: Failure</code></pre> <p>This behavior changes when you enable ReportBatchItemFailures feature in your Lambda function event source configuration:</p> <ul> <li>SQS queues. Only messages reported as failure will return to the queue for a retry, while successful ones will be deleted.</li> <li>Kinesis data streams and DynamoDB streams. Single reported failure will use its sequence number as the stream checkpoint. Multiple  reported failures will use the lowest sequence number as checkpoint.</li> </ul> Warning: This utility lowers the chance of processing records more than once; it does not guarantee it <p>We recommend implementing processing logic in an idempotent manner wherever possible.</p> <p>You can find more details on how Lambda works with either SQS, Kinesis, or DynamoDB in the AWS Documentation.</p>"
        },
        {
            "location": "utilities/batch/#getting-started",
            "title": "Getting started",
            "text": ""
        },
        {
            "location": "utilities/batch/#installation",
            "title": "Installation",
            "text": "<p>Install the library in your project</p> <pre><code>npm i @aws-lambda-powertools/batch\n</code></pre> <p>For this feature to work, you need to (1) configure your Lambda function event source to use <code>ReportBatchItemFailures</code>, and (2) return a specific response to report which records failed to be processed.</p> <p>Use your preferred deployment framework to set the correct configuration while this utility handles the correct response to be returned.</p>"
        },
        {
            "location": "utilities/batch/#required-resources",
            "title": "Required resources",
            "text": "<p>The remaining sections of the documentation will rely on these samples. For completeness, this demonstrates IAM permissions and Dead Letter Queue where batch records will be sent after 2 retries.</p> <p>You do not need any additional IAM permissions to use this utility, except for what each event source requires.</p> SQSKinesis Data StreamsDynamoDB Streams template.yaml<pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: partial batch response sample\n\nGlobals:\n  Function:\n    Timeout: 5\n    MemorySize: 256\n    Runtime: nodejs22.x\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_LOG_LEVEL: INFO\n        POWERTOOLS_SERVICE_NAME: hello\n\nResources:\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: index.handler\n      CodeUri: hello_world\n      Policies:\n        - SQSPollerPolicy:\n            QueueName: !GetAtt SampleQueue.QueueName\n      Events:\n        Batch:\n          Type: SQS\n          Properties:\n            Queue: !GetAtt SampleQueue.Arn\n            FunctionResponseTypes:\n              - ReportBatchItemFailures\n\n  SampleDLQ:\n    Type: AWS::SQS::Queue\n\n  SampleQueue:\n    Type: AWS::SQS::Queue\n    Properties:\n      VisibilityTimeout: 30 # Fn timeout * 6\n      SqsManagedSseEnabled: true\n      RedrivePolicy:\n        maxReceiveCount: 2\n        deadLetterTargetArn: !GetAtt SampleDLQ.Arn\n</code></pre> template.yaml<pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: partial batch response sample\n\nGlobals:\n  Function:\n    Timeout: 5\n    MemorySize: 256\n    Runtime: nodejs22.x\n    Tracing: Active\n    Environment:\n      Variables:\n        LOG_LEVEL: INFO\n        POWERTOOLS_SERVICE_NAME: hello\n\nResources:\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: index.handler\n      CodeUri: hello_world\n      Policies:\n        # Lambda Destinations require additional permissions\n        # to send failure records to DLQ from Kinesis/DynamoDB\n        - Version: '2012-10-17'\n          Statement:\n            Effect: 'Allow'\n            Action:\n              - sqs:GetQueueAttributes\n              - sqs:GetQueueUrl\n              - sqs:SendMessage\n            Resource: !GetAtt SampleDLQ.Arn\n      Events:\n        KinesisStream:\n          Type: Kinesis\n          Properties:\n            Stream: !GetAtt SampleStream.Arn\n            BatchSize: 100\n            StartingPosition: LATEST\n            MaximumRetryAttempts: 2\n            DestinationConfig:\n              OnFailure:\n                Destination: !GetAtt SampleDLQ.Arn\n            FunctionResponseTypes:\n              - ReportBatchItemFailures\n\n  SampleDLQ:\n    Type: AWS::SQS::Queue\n\n  SampleStream:\n    Type: AWS::Kinesis::Stream\n    Properties:\n      ShardCount: 1\n      StreamEncryption:\n        EncryptionType: KMS\n        KeyId: alias/aws/kinesis\n</code></pre> template.yaml<pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: partial batch response sample\n\nGlobals:\n  Function:\n    Timeout: 5\n    MemorySize: 256\n    Runtime: nodejs22.x\n    Tracing: Active\n    Environment:\n      Variables:\n        POWERTOOLS_LOG_LEVEL: INFO\n        POWERTOOLS_SERVICE_NAME: hello\n\nResources:\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: index.handler\n      CodeUri: hello_world\n      Policies:\n        # Lambda Destinations require additional permissions\n        # to send failure records from Kinesis/DynamoDB\n        - Version: '2012-10-17'\n          Statement:\n            Effect: 'Allow'\n            Action:\n              - sqs:GetQueueAttributes\n              - sqs:GetQueueUrl\n              - sqs:SendMessage\n            Resource: !GetAtt SampleDLQ.Arn\n      Events:\n        DynamoDBStream:\n          Type: DynamoDB\n          Properties:\n            Stream: !GetAtt SampleTable.StreamArn\n            StartingPosition: LATEST\n            MaximumRetryAttempts: 2\n            DestinationConfig:\n              OnFailure:\n                Destination: !GetAtt SampleDLQ.Arn\n            FunctionResponseTypes:\n              - ReportBatchItemFailures\n\n  SampleDLQ:\n    Type: AWS::SQS::Queue\n\n  SampleTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      BillingMode: PAY_PER_REQUEST\n      AttributeDefinitions:\n        - AttributeName: pk\n          AttributeType: S\n        - AttributeName: sk\n          AttributeType: S\n      KeySchema:\n        - AttributeName: pk\n          KeyType: HASH\n        - AttributeName: sk\n          KeyType: RANGE\n      SSESpecification:\n        SSEEnabled: true\n      StreamSpecification:\n        StreamViewType: NEW_AND_OLD_IMAGES\n</code></pre>"
        },
        {
            "location": "utilities/batch/#processing-messages-from-sqs",
            "title": "Processing messages from SQS",
            "text": "<p>Processing batches from SQS works in three stages:</p> <ol> <li>Instantiate <code>BatchProcessor</code> and choose <code>EventType.SQS</code> for the event type</li> <li>Define your function to handle each batch record, and use the <code>SQSRecord</code> type annotation for autocompletion</li> <li>Use <code>processPartialResponse</code> to kick off processing</li> </ol> Info <p>This code example optionally uses Logger for completion.</p> index.tsSample responseSample event <pre><code> import {\n   BatchProcessor,\n   EventType,\n   processPartialResponse,\n } from '@aws-lambda-powertools/batch';\n import { Logger } from '@aws-lambda-powertools/logger';\n import type { SQSHandler, SQSRecord } from 'aws-lambda';\n\n const processor = new BatchProcessor(EventType.SQS); // (1)!\n const logger = new Logger();\n\n const recordHandler = async (record: SQSRecord): Promise&lt;void&gt; =&gt; { // (2)!\n   const payload = record.body;\n   if (payload) {\n     const item = JSON.parse(payload);\n     logger.info('Processed item', { item });\n   }\n };\n\n export const handler: SQSHandler = async (event, context) =&gt;\n   processPartialResponse(event, recordHandler, processor, { // (3)!\n     context,\n   });\n</code></pre> <ol> <li>Step 1. Creates a partial failure batch processor for SQS queues. See partial failure mechanics for details</li> <li>Step 2. Defines a function to receive one record at a time from the batch</li> <li>Step 3. Kicks off processing   </li> </ol> <p>The second record failed to be processed, therefore the processor added its message ID in the response.</p> <pre><code>{\n  \"batchItemFailures\": [\n    {\n      \"itemIdentifier\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\"\n    }\n  ]\n}\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n      \"body\": \"{\\\"Message\\\": \\\"success\\\"}\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082649183\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n      \"awsRegion\": \"us-east-1\"\n    },\n    {\n      \"messageId\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n      \"body\": \"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082649183\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n      \"awsRegion\": \"us-east-1\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch/#fifo-queues",
            "title": "FIFO queues",
            "text": "<p>When using SQS FIFO queues, a batch may include messages from different group IDs.</p> <p>By default, we will stop processing at the first failure and mark unprocessed messages as failed to preserve ordering. However, this behavior may not be optimal for customers who wish to proceed with processing messages from a different group ID.</p> <p>Enable the <code>skipGroupOnError</code> option for seamless processing of messages from various group IDs. This setup ensures that messages from a failed group ID are sent back to SQS, enabling uninterrupted processing of messages from the subsequent group ID.</p> RecommendedAsync processingEnabling skipGroupOnError flag <pre><code>import {\n  SqsFifoPartialProcessor,\n  processPartialResponseSync,\n} from '@aws-lambda-powertools/batch';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport type { SQSHandler, SQSRecord } from 'aws-lambda';\n\nconst processor = new SqsFifoPartialProcessor(); // (1)!\nconst logger = new Logger();\n\nconst recordHandler = (record: SQSRecord): void =&gt; {\n  const payload = record.body;\n  if (payload) {\n    const item = JSON.parse(payload);\n    logger.info('Processed item', { item });\n  }\n};\n\nexport const handler: SQSHandler = async (event, context) =&gt;\n  processPartialResponseSync(event, recordHandler, processor, {\n    context,\n  });\n</code></pre> <ol> <li>Step 1. Creates a partial failure batch processor for SQS FIFO queues. See partial failure mechanics for details</li> </ol> <pre><code>import {\n  SqsFifoPartialProcessorAsync,\n  processPartialResponse,\n} from '@aws-lambda-powertools/batch';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport type { SQSHandler, SQSRecord } from 'aws-lambda';\n\nconst processor = new SqsFifoPartialProcessorAsync();\nconst logger = new Logger();\n\nconst recordHandler = async (record: SQSRecord): Promise&lt;void&gt; =&gt; {\n  const payload = record.body;\n  if (payload) {\n    const item = JSON.parse(payload);\n    logger.info('Processed item', { item });\n  }\n};\n\nexport const handler: SQSHandler = async (event, context) =&gt;\n  processPartialResponse(event, recordHandler, processor, {\n    context,\n  });\n</code></pre> <pre><code>import {\n  SqsFifoPartialProcessor,\n  processPartialResponseSync,\n} from '@aws-lambda-powertools/batch';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport type {\n  Context,\n  SQSBatchResponse,\n  SQSEvent,\n  SQSRecord,\n} from 'aws-lambda';\n\nconst processor = new SqsFifoPartialProcessor();\nconst logger = new Logger();\n\nconst recordHandler = (record: SQSRecord): void =&gt; {\n  const payload = record.body;\n  if (payload) {\n    const item = JSON.parse(payload);\n    logger.info('Processed item', { item });\n  }\n};\n\nexport const handler = async (\n  event: SQSEvent,\n  context: Context\n): Promise&lt;SQSBatchResponse&gt; =&gt; {\n  return processPartialResponseSync(event, recordHandler, processor, {\n    context,\n    skipGroupOnError: true,\n  });\n};\n</code></pre> <p>Note</p> <p>Note that <code>SqsFifoPartialProcessor</code> is synchronous using <code>processPartialResponseSync</code>. If you need asynchronous processing while preserving the order of messages in the queue, use <code>SqsFifoPartialProcessorAsync</code> with <code>processPartialResponse</code>.</p>"
        },
        {
            "location": "utilities/batch/#processing-messages-from-kinesis",
            "title": "Processing messages from Kinesis",
            "text": "<p>Processing batches from Kinesis works in three stages:</p> <ol> <li>Instantiate <code>BatchProcessor</code> and choose <code>EventType.KinesisDataStreams</code> for the event type</li> <li>Define your function to handle each batch record, and use the <code>KinesisStreamRecord</code> type annotation for autocompletion</li> <li>Use <code>processPartialResponse</code> to kick off processing</li> </ol> Info <p>This code example optionally uses Logger for completion.</p> index.tsSample responseSample event <pre><code>import {\n  BatchProcessor,\n  EventType,\n  processPartialResponse,\n} from '@aws-lambda-powertools/batch';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport type { KinesisStreamHandler, KinesisStreamRecord } from 'aws-lambda';\n\nconst processor = new BatchProcessor(EventType.KinesisDataStreams); // (1)!\nconst logger = new Logger();\n\nconst recordHandler = async (record: KinesisStreamRecord): Promise&lt;void&gt; =&gt; {\n  logger.info('Processing record', { record: record.kinesis.data });\n  const payload = JSON.parse(record.kinesis.data);\n  logger.info('Processed item', { item: payload });\n};\n\nexport const handler: KinesisStreamHandler = async (event, context) =&gt;\n  processPartialResponse(event, recordHandler, processor, {\n    context,\n  });\n</code></pre> <ol> <li>Creates a partial failure batch processor for Kinesis Data Streams. See partial failure mechanics for details</li> </ol> <p>The second record failed to be processed, therefore the processor added its sequence number in the response.</p> <pre><code>{\n  \"Records\": [\n    {\n      \"kinesis\": {\n        \"kinesisSchemaVersion\": \"1.0\",\n        \"partitionKey\": \"1\",\n        \"sequenceNumber\": \"4107859083838847772757075850904226111829882106684065\",\n        \"data\": \"eyJNZXNzYWdlIjogInN1Y2Nlc3MifQ==\",\n        \"approximateArrivalTimestamp\": 1545084650.987\n      },\n      \"eventSource\": \"aws:kinesis\",\n      \"eventVersion\": \"1.0\",\n      \"eventID\": \"shardId-000000000006:4107859083838847772757075850904226111829882106684065\",\n      \"eventName\": \"aws:kinesis:record\",\n      \"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n      \"awsRegion\": \"us-east-2\",\n      \"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n    },\n    {\n      \"kinesis\": {\n        \"kinesisSchemaVersion\": \"1.0\",\n        \"partitionKey\": \"1\",\n        \"sequenceNumber\": \"6006958808509702859251049540584488075644979031228738\",\n        \"data\": \"c3VjY2Vzcw==\",\n        \"approximateArrivalTimestamp\": 1545084650.987\n      },\n      \"eventSource\": \"aws:kinesis\",\n      \"eventVersion\": \"1.0\",\n      \"eventID\": \"shardId-000000000006:6006958808509702859251049540584488075644979031228738\",\n      \"eventName\": \"aws:kinesis:record\",\n      \"invokeIdentityArn\": \"arn:aws:iam::123456789012:role/lambda-role\",\n      \"awsRegion\": \"us-east-2\",\n      \"eventSourceARN\": \"arn:aws:kinesis:us-east-2:123456789012:stream/lambda-stream\"\n    }\n  ]\n}\n</code></pre> <pre><code>{\n  \"batchItemFailures\": [\n    {\n      \"itemIdentifier\": \"6006958808509702859251049540584488075644979031228738\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch/#processing-messages-from-dynamodb",
            "title": "Processing messages from DynamoDB",
            "text": "<p>Processing batches from DynamoDB Streams works in three stages:</p> <ol> <li>Instantiate <code>BatchProcessor</code> and choose <code>EventType.DynamoDBStreams</code> for the event type</li> <li>Define your function to handle each batch record, and use the <code>DynamoDBRecord</code> type annotation for autocompletion</li> <li>Use <code>processPartialResponse</code> to kick off processing</li> </ol> Info <p>This code example optionally uses Logger for completion.</p> index.tsSample responseSample event <pre><code>import {\n  BatchProcessor,\n  EventType,\n  processPartialResponse,\n} from '@aws-lambda-powertools/batch';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport type { DynamoDBRecord, DynamoDBStreamHandler } from 'aws-lambda';\n\nconst processor = new BatchProcessor(EventType.DynamoDBStreams); // (1)!\nconst logger = new Logger();\n\nconst recordHandler = async (record: DynamoDBRecord): Promise&lt;void&gt; =&gt; {\n  if (record.dynamodb?.NewImage) {\n    logger.info('Processing record', { record: record.dynamodb.NewImage });\n    const message = record.dynamodb.NewImage.Message.S;\n    if (message) {\n      const payload = JSON.parse(message);\n      logger.info('Processed item', { item: payload });\n    }\n  }\n};\n\nexport const handler: DynamoDBStreamHandler = async (event, context) =&gt;\n  processPartialResponse(event, recordHandler, processor, {\n    context,\n  });\n</code></pre> <ol> <li>Creates a partial failure batch processor for DynamoDB Streams. See partial failure mechanics for details</li> </ol> <p>The second record failed to be processed, therefore the processor added its sequence number in the response.</p> <pre><code>{\n  \"batchItemFailures\": [\n    {\n      \"itemIdentifier\": \"8640712661\"\n    }\n  ]\n}\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"eventID\": \"1\",\n      \"eventVersion\": \"1.0\",\n      \"dynamodb\": {\n        \"Keys\": {\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"NewImage\": {\n          \"Message\": {\n            \"S\": \"failure\"\n          }\n        },\n        \"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n        \"SequenceNumber\": \"3275880929\",\n        \"SizeBytes\": 26\n      },\n      \"awsRegion\": \"us-west-2\",\n      \"eventName\": \"INSERT\",\n      \"eventSourceARN\": \"eventsource_arn\",\n      \"eventSource\": \"aws:dynamodb\"\n    },\n    {\n      \"eventID\": \"1\",\n      \"eventVersion\": \"1.0\",\n      \"dynamodb\": {\n        \"Keys\": {\n          \"Id\": {\n            \"N\": \"101\"\n          }\n        },\n        \"NewImage\": {\n          \"SomethingElse\": {\n            \"S\": \"success\"\n          }\n        },\n        \"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n        \"SequenceNumber\": \"8640712661\",\n        \"SizeBytes\": 26\n      },\n      \"awsRegion\": \"us-west-2\",\n      \"eventName\": \"INSERT\",\n      \"eventSourceARN\": \"eventsource_arn\",\n      \"eventSource\": \"aws:dynamodb\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch/#error-handling",
            "title": "Error handling",
            "text": "<p>By default, we catch any exception raised by your record handler function. This allows us to (1) continue processing the batch, (2) collect each batch item that failed processing, and (3) return the appropriate  response correctly without failing your Lambda function execution.</p> Sample error handling with custom exceptionSample response <pre><code> import {\n   BatchProcessor,\n   EventType,\n   processPartialResponse,\n } from '@aws-lambda-powertools/batch';\n import { Logger } from '@aws-lambda-powertools/logger';\n import type { SQSHandler, SQSRecord } from 'aws-lambda';\n\n const processor = new BatchProcessor(EventType.SQS);\n const logger = new Logger();\n\n class InvalidPayload extends Error {\n   public constructor(message: string) {\n     super(message);\n     this.name = 'InvalidPayload';\n   }\n }\n\n const recordHandler = async (record: SQSRecord): Promise&lt;void&gt; =&gt; {\n   const payload = record.body;\n   if (payload) {\n     const item = JSON.parse(payload);\n     logger.info('Processed item', { item });\n   } else {\n     throw new InvalidPayload('Payload does not contain minimum required fields'); // (1)!\n   }\n };\n\n export const handler: SQSHandler = async (event, context) =&gt;\n   processPartialResponse(event, recordHandler, processor, { // (2)!\n     context,\n   });\n</code></pre> <ol> <li> <p>Any exception works here. See extending BatchProcessorSync section, if you want to override this behavior.</p> </li> <li> <p>Exceptions raised in <code>recordHandler</code> will propagate to <code>process_partial_response</code>.  We catch them and include each failed batch item identifier in the response dictionary (see <code>Sample response</code> tab).</p> </li> </ol> <pre><code>{\n  \"batchItemFailures\": [\n    {\n      \"itemIdentifier\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/batch/#partial-failure-mechanics",
            "title": "Partial failure mechanics",
            "text": "<p>All records in the batch will be passed to this handler for processing, even if exceptions are thrown - Here's the behaviour after completing the batch:</p> <ul> <li>All records successfully processed. We will return an empty list of item failures <code>{'batchItemFailures': []}</code></li> <li>Partial success with some exceptions. We will return a list of all item IDs/sequence numbers that failed processing</li> <li>All records failed to be processed. We will throw a <code>FullBatchFailureError</code> error with a list of all the errors thrown while processing unless <code>throwOnFullBatchFailure</code> is disabled.</li> </ul> <p>The following sequence diagrams explain how each Batch processor behaves under different scenarios.</p>"
        },
        {
            "location": "utilities/batch/#sqs-standard",
            "title": "SQS Standard",
            "text": "<p>Read more about Batch Failure Reporting feature in AWS Lambda.</p> <p>Sequence diagram to explain how <code>BatchProcessor</code> works with SQS Standard queues.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant SQS queue\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;SQS queue: Poll\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    Lambda function-&gt;&gt;Lambda service: Report some failed messages\n    activate SQS queue\n    Lambda service-&gt;&gt;SQS queue: Delete successful messages\n    SQS queue--&gt;&gt;SQS queue: Failed messages return\n    Note over SQS queue,Lambda service: Process repeat\n    deactivate SQS queue</code></pre> SQS mechanism with Batch Item Failures </p>"
        },
        {
            "location": "utilities/batch/#sqs-fifo",
            "title": "SQS FIFO",
            "text": "<p>Read more about Batch Failure Reporting feature in AWS Lambda.</p> <p>Sequence diagram to explain how <code>SqsFifoPartialProcessor</code> works with SQS FIFO queues without <code>skipGroupOnError</code> flag.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant SQS queue\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;SQS queue: Poll\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    activate Lambda function\n    Lambda function--&gt;Lambda function: Process 2 out of 10 batch items\n    Lambda function--xLambda function: Fail on 3rd batch item\n    Lambda function-&gt;&gt;Lambda service: Report 3rd batch item and unprocessed messages as failure\n    deactivate Lambda function\n    activate SQS queue\n    Lambda service-&gt;&gt;SQS queue: Delete successful messages (1-2)\n    SQS queue--&gt;&gt;SQS queue: Failed messages return (3-10)\n    deactivate SQS queue</code></pre> SQS FIFO mechanism with Batch Item Failures </p> <p>Sequence diagram to explain how <code>SqsFifoPartialProcessor</code> works with SQS FIFO queues with <code>skipGroupOnError</code> flag.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant SQS queue\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;SQS queue: Poll\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    activate Lambda function\n    Lambda function--&gt;Lambda function: Process 2 out of 10 batch items\n    Lambda function--xLambda function: Fail on 3rd batch item\n    Lambda function--&gt;Lambda function: Process messages from another MessageGroupID\n    Lambda function-&gt;&gt;Lambda service: Report 3rd batch item and all messages within the same MessageGroupID as failure\n    deactivate Lambda function\n    activate SQS queue\n    Lambda service-&gt;&gt;SQS queue: Delete successful messages processed\n    SQS queue--&gt;&gt;SQS queue: Failed messages return\n    deactivate SQS queue</code></pre> SQS FIFO mechanism with Batch Item Failures </p>"
        },
        {
            "location": "utilities/batch/#kinesis-and-dynamodb-streams",
            "title": "Kinesis and DynamoDB Streams",
            "text": "<p>Read more about Batch Failure Reporting feature.</p> <p>Sequence diagram to explain how <code>BatchProcessor</code> works with both Kinesis Data Streams and DynamoDB Streams.</p> <p>For brevity, we will use <code>Streams</code> to refer to either services. For theory on stream checkpoints, see this blog post</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Streams\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;Streams: Poll latest records\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    activate Lambda function\n    Lambda function--&gt;Lambda function: Process 2 out of 10 batch items\n    Lambda function--xLambda function: Fail on 3rd batch item\n    Lambda function--&gt;Lambda function: Continue processing batch items (4-10)\n    Lambda function-&gt;&gt;Lambda service: Report batch item as failure (3)\n    deactivate Lambda function\n    activate Streams\n    Lambda service-&gt;&gt;Streams: Checkpoints to sequence number from 3rd batch item\n    Lambda service-&gt;&gt;Streams: Poll records starting from updated checkpoint\n    deactivate Streams</code></pre> Kinesis and DynamoDB streams mechanism with single batch item failure </p> <p>The behavior changes slightly when there are multiple item failures. Stream checkpoint is updated to the lowest sequence number reported.</p> <p>Note that the batch item sequence number could be different from batch item number in the illustration.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Streams\n    participant Lambda service\n    participant Lambda function\n    Lambda service-&gt;&gt;Streams: Poll latest records\n    Lambda service-&gt;&gt;Lambda function: Invoke (batch event)\n    activate Lambda function\n    Lambda function--&gt;Lambda function: Process 2 out of 10 batch items\n    Lambda function--xLambda function: Fail on 3-5 batch items\n    Lambda function--&gt;Lambda function: Continue processing batch items (6-10)\n    Lambda function-&gt;&gt;Lambda service: Report batch items as failure (3-5)\n    deactivate Lambda function\n    activate Streams\n    Lambda service-&gt;&gt;Streams: Checkpoints to lowest sequence number\n    Lambda service-&gt;&gt;Streams: Poll records starting from updated checkpoint\n    deactivate Streams</code></pre> Kinesis and DynamoDB streams mechanism with multiple batch item failures </p>"
        },
        {
            "location": "utilities/batch/#async-or-sync-processing",
            "title": "Async or sync processing",
            "text": "<p>There are two processors you can use with this utility:</p> <ul> <li><code>BatchProcessor</code> and <code>processPartialResponse</code> – Processes messages asynchronously</li> <li><code>BatchProcessorSync</code> and <code>processPartialResponseSync</code> – Processes messages synchronously</li> </ul> <p>In most cases your function will be <code>async</code> returning a <code>Promise</code>. Therefore, the <code>BatchProcessor</code> is the default processor handling your batch records asynchronously. There are use cases where you need to process the batch records synchronously. For example, when you need to process multiple records at the same time without conflicting with one another. For such cases we recommend to use the <code>BatchProcessorSync</code> and <code>processPartialResponseSync</code> functions.</p> <p>Note that you need match your processing function with the right batch processor</p> <p>*If your function is <code>async</code> returning a <code>Promise</code>, use <code>BatchProcessor</code> and <code>processPartialResponse</code> * If your function is not <code>async</code>, use <code>BatchProcessorSync</code> and <code>processPartialResponseSync</code></p> <p>The difference between the two processors is in how they handle record processing:</p> <ul> <li><code>BatchProcessor</code>: By default, it processes records in parallel using <code>Promise.all()</code>. However, it also offers an option to process records sequentially, preserving the order.</li> <li><code>BatchProcessorSync</code>: Always processes records sequentially, ensuring the order is preserved by looping through each record one by one.</li> </ul> When is this useful? <p>For example, imagine you need to process multiple loyalty points and incrementally save in a database. While you await the database to confirm your records are saved, you could start processing another request concurrently.</p> <p>The reason this is not the default behaviour is that not all use cases can handle concurrency safely (e.g., loyalty points must be updated in order).</p>"
        },
        {
            "location": "utilities/batch/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/batch/#accessing-processed-messages",
            "title": "Accessing processed messages",
            "text": "<p>Use the <code>BatchProcessor</code> directly in your function to access a list of all returned values from your <code>recordHandler</code> function.</p> <ul> <li>When successful. We will include a tuple with <code>success</code>, the result of <code>recordHandler</code>, and the batch record</li> <li>When failed. We will include a tuple with <code>fail</code>, exception as a string, and the batch record</li> </ul> Accessing processed messages<pre><code>import { BatchProcessor, EventType } from '@aws-lambda-powertools/batch';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport type { SQSHandler, SQSRecord } from 'aws-lambda';\n\nconst processor = new BatchProcessor(EventType.SQS);\nconst logger = new Logger();\n\nconst recordHandler = (record: SQSRecord): void =&gt; {\n  const payload = record.body;\n  if (payload) {\n    const item = JSON.parse(payload);\n    logger.info('Processed item', { item });\n  }\n};\n\nexport const handler: SQSHandler = async (event, context) =&gt; {\n  const batch = event.Records; // (1)!\n\n  processor.register(batch, recordHandler, { context }); // (2)!\n  const processedMessages = await processor.process();\n\n  for (const message of processedMessages) {\n    const [status, error, record] = message;\n\n    logger.info('Processed record', { status, record, error });\n  }\n\n  return processor.response();\n};\n</code></pre> <ol> <li>The processor requires the records array. This is typically handled by <code>processPartialResponse</code>.</li> <li>You need to register the <code>batch</code>, the <code>recordHandler</code> function, and optionally the <code>context</code> to access the Lambda context.</li> </ol>"
        },
        {
            "location": "utilities/batch/#accessing-lambda-context",
            "title": "Accessing Lambda Context",
            "text": "<p>Within your <code>recordHandler</code> function, you might need access to the Lambda context to determine how much time you have left before your function times out.</p> <p>We can automatically inject the Lambda context into your <code>recordHandler</code> as optional second argument if you register it when using <code>BatchProcessorSync</code> or the <code>processPartialResponseSync</code> function.</p> <pre><code>import {\n  BatchProcessor,\n  EventType,\n  processPartialResponse,\n} from '@aws-lambda-powertools/batch';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport type { Context, SQSHandler, SQSRecord } from 'aws-lambda';\n\nconst processor = new BatchProcessor(EventType.SQS);\nconst logger = new Logger();\n\nconst recordHandler = (record: SQSRecord, lambdaContext?: Context): void =&gt; {\n  const payload = record.body;\n  if (payload) {\n    const item = JSON.parse(payload);\n    logger.info('Processed item', { item });\n  }\n  if (lambdaContext) {\n    logger.info('Remaining time', {\n      time: lambdaContext.getRemainingTimeInMillis(),\n    });\n  }\n};\n\nexport const handler: SQSHandler = async (event, context) =&gt;\n  processPartialResponse(event, recordHandler, processor, {\n    context,\n  });\n</code></pre>"
        },
        {
            "location": "utilities/batch/#working-with-full-batch-failures",
            "title": "Working with full batch failures",
            "text": "<p>By default, the <code>BatchProcessor</code> will throw a <code>FullBatchFailureError</code> if all records in the batch fail to process, we do this to reflect the failure in your operational metrics.</p> <p>When working with functions that handle batches with a small number of records, or when you use errors as a flow control mechanism, this behavior might not be desirable as your function might generate an unnaturally high number of errors. When this happens, the Lambda service will scale down the concurrency of your function, potentially impacting performance.</p> <p>For these scenarios, you can set the <code>throwOnFullBatchFailure</code> option to <code>false</code> when calling.</p> <pre><code>import {\n  BatchProcessor,\n  EventType,\n  processPartialResponse,\n} from '@aws-lambda-powertools/batch';\nimport type { SQSHandler, SQSRecord } from 'aws-lambda';\n\nconst processor = new BatchProcessor(EventType.SQS);\n\nconst recordHandler = async (_record: SQSRecord): Promise&lt;void&gt; =&gt; {\n  // Process the record\n};\n\nexport const handler: SQSHandler = async (event, context) =&gt;\n  processPartialResponse(event, recordHandler, processor, {\n    context,\n    throwOnFullBatchFailure: false,\n  });\n</code></pre>"
        },
        {
            "location": "utilities/batch/#extending-batchprocessor",
            "title": "Extending BatchProcessor",
            "text": "<p>You might want to bring custom logic to the existing <code>BatchProcessor</code> to slightly override how we handle successes and failures.</p> <p>For these scenarios, you can subclass <code>BatchProcessor</code> and quickly override <code>successHandler</code> and <code>failureHandler</code> methods:</p> <ul> <li><code>successHandler()</code> – Keeps track of successful batch records</li> <li><code>failureHandler()</code> – Keeps track of failed batch records</li> </ul> <p>Let's suppose you'd like to add a metric named <code>BatchRecordFailures</code> for each batch record that failed processing</p> Extending failure handling mechanism in BatchProcessor<pre><code>import {\n  BatchProcessor,\n  EventType,\n  processPartialResponse,\n} from '@aws-lambda-powertools/batch';\nimport type {\n  EventSourceDataClassTypes,\n  FailureResponse,\n} from '@aws-lambda-powertools/batch/types';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport { MetricUnit, Metrics } from '@aws-lambda-powertools/metrics';\nimport type { SQSHandler, SQSRecord } from 'aws-lambda';\n\nclass MyProcessor extends BatchProcessor {\n  #metrics: Metrics;\n\n  public constructor(eventType: keyof typeof EventType) {\n    super(eventType);\n    this.#metrics = new Metrics({ namespace: 'test' });\n  }\n\n  public failureHandler(\n    record: EventSourceDataClassTypes,\n    error: Error\n  ): FailureResponse {\n    this.#metrics.addMetric('BatchRecordFailures', MetricUnit.Count, 1);\n\n    return super.failureHandler(record, error);\n  }\n}\n\nconst processor = new MyProcessor(EventType.SQS);\nconst logger = new Logger();\n\nconst recordHandler = (record: SQSRecord): void =&gt; {\n  const payload = record.body;\n  if (payload) {\n    const item = JSON.parse(payload);\n    logger.info('Processed item', { item });\n  }\n};\n\nexport const handler: SQSHandler = async (event, context) =&gt;\n  processPartialResponse(event, recordHandler, processor, {\n    context,\n  });\n</code></pre>"
        },
        {
            "location": "utilities/batch/#sequential-async-processing",
            "title": "Sequential async processing",
            "text": "<p>By default, the <code>BatchProcessor</code> processes records in parallel using <code>Promise.all()</code>. However, if you need to preserve the order of records, you can set the <code>processInParallel</code> option to <code>false</code> to process records sequentially.</p> <p>If the <code>processInParallel</code> option is not provided, the <code>BatchProcessor</code> will process records in parallel.</p> Sequential async processing<pre><code>import {\n  BatchProcessor,\n  EventType,\n  processPartialResponse,\n} from '@aws-lambda-powertools/batch';\nimport type { SQSHandler, SQSRecord } from 'aws-lambda';\n\nconst processor = new BatchProcessor(EventType.SQS);\n\nconst recordHandler = async (_record: SQSRecord): Promise&lt;void&gt; =&gt; {\n  // Process the record\n};\n\nexport const handler: SQSHandler = async (event, context) =&gt;\n  processPartialResponse(event, recordHandler, processor, {\n    context,\n    processInParallel: false,\n  });\n</code></pre>"
        },
        {
            "location": "utilities/batch/#create-your-own-partial-processor",
            "title": "Create your own partial processor",
            "text": "<p>You can create your own partial batch processor from scratch by inheriting the <code>BasePartialProcessor</code> class, and implementing the <code>prepare()</code>, <code>clean()</code>, <code>processRecord()</code> and <code>processRecordSync()</code> abstract methods.</p> <p> <pre><code>classDiagram\n    direction LR\n    class BasePartialProcessor {\n        &lt;&lt;interface&gt;&gt;\n        +prepare()\n        +clean()\n        +processRecord(record: BaseRecord)\n        +processRecordSync(record: BaseRecord)\n    }\n    class YourCustomProcessor {\n        +prepare()\n        +clean()\n        +processRecord(record: BaseRecord)\n        +processRecordSyc(record: BaseRecord)\n    }\n    BasePartialProcessor &lt;|-- YourCustomProcessor : extends</code></pre> Visual representation to bring your own processor </p> <ul> <li><code>prepare()</code> – called once as part of the processor initialization</li> <li><code>clean()</code> – teardown logic called once after <code>processRecord</code> completes</li> <li><code>processRecord()</code> – If you need to implement asynchronous logic, use this method, otherwise define it in your class with empty logic</li> <li><code>processRecordSync()</code> – handles all processing logic for each individual message of a batch, including calling the <code>recordHandler</code> (<code>this.handler</code>)</li> </ul> <p>You can then use this class as a context manager, or pass it to <code>processPartialResponseSync</code> to process the records in your Lambda handler function.</p> Creating a custom batch processor<pre><code>import { randomInt } from 'node:crypto';\nimport {\n  BasePartialBatchProcessor,\n  EventType,\n  processPartialResponse,\n} from '@aws-lambda-powertools/batch';\nimport type {\n  BaseRecord,\n  FailureResponse,\n  SuccessResponse,\n} from '@aws-lambda-powertools/batch/types';\nimport {\n  BatchWriteItemCommand,\n  DynamoDBClient,\n} from '@aws-sdk/client-dynamodb';\nimport { marshall } from '@aws-sdk/util-dynamodb';\nimport type { SQSHandler } from 'aws-lambda';\n\nconst tableName = process.env.TABLE_NAME || 'table-not-found';\n\nclass MyPartialProcessor extends BasePartialBatchProcessor {\n  #tableName: string;\n  #client?: DynamoDBClient;\n\n  public constructor(tableName: string) {\n    super(EventType.SQS);\n    this.#tableName = tableName;\n  }\n\n  /**\n   * It's called once, **after** processing the batch.\n   *\n   * Here we are writing all the processed messages to DynamoDB.\n   */\n  public clean(): void {\n    // biome-ignore lint/style/noNonNullAssertion: We know that the client is defined because clean() is called after prepare()\n    this.#client!.send(\n      new BatchWriteItemCommand({\n        RequestItems: {\n          [this.#tableName]: this.successMessages.map((message) =&gt; ({\n            PutRequest: {\n              Item: marshall(message),\n            },\n          })),\n        },\n      })\n    );\n  }\n\n  /**\n   * It's called once, **before** processing the batch.\n   *\n   * It initializes a new client and cleans up any existing data.\n   */\n  public prepare(): void {\n    this.#client = new DynamoDBClient({});\n    this.successMessages = [];\n  }\n\n  public async processRecord(\n    _record: BaseRecord\n  ): Promise&lt;SuccessResponse | FailureResponse&gt; {\n    throw new Error('Not implemented');\n  }\n\n  /**\n   * It handles how your record is processed.\n   *\n   * Here we are keeping the status of each run, `this.handler` is\n   * the function that is passed when calling `processor.register()`.\n   */\n  public processRecordSync(\n    record: BaseRecord\n  ): SuccessResponse | FailureResponse {\n    try {\n      const result = this.handler(record);\n\n      return this.successHandler(record, result);\n    } catch (error) {\n      return this.failureHandler(record, error as Error);\n    }\n  }\n}\n\nconst processor = new MyPartialProcessor(tableName);\n\nconst recordHandler = (): number =&gt; {\n  return Math.floor(randomInt(1, 10));\n};\n\nexport const handler: SQSHandler = async (event, context) =&gt;\n  processPartialResponse(event, recordHandler, processor, {\n    context,\n  });\n</code></pre>"
        },
        {
            "location": "utilities/batch/#tracing-with-aws-x-ray",
            "title": "Tracing with AWS X-Ray",
            "text": "<p>You can use Tracer to create subsegments for each batch record processed. To do so, you can open a new subsegment for each record, and close it when you're done processing it. When adding annotations and metadata to the subsegment, you can do so directly without calling <code>tracer.setSegment(subsegment)</code>. This allows you to work with the subsegment directly and avoid having to either pass the parent subsegment around or have to restore the parent subsegment at the end of the record processing.</p> <pre><code>import {\n  BatchProcessor,\n  EventType,\n  processPartialResponse,\n} from '@aws-lambda-powertools/batch';\nimport { Tracer } from '@aws-lambda-powertools/tracer';\nimport { captureLambdaHandler } from '@aws-lambda-powertools/tracer/middleware';\nimport middy from '@middy/core';\nimport type { SQSEvent, SQSHandler, SQSRecord } from 'aws-lambda';\n\nconst processor = new BatchProcessor(EventType.SQS);\nconst tracer = new Tracer({ serviceName: 'serverlessAirline' });\n\nconst recordHandler = async (record: SQSRecord): Promise&lt;void&gt; =&gt; {\n  const subsegment = tracer.getSegment()?.addNewSubsegment('### recordHandler'); // (1)!\n  subsegment?.addAnnotation('messageId', record.messageId); // (2)!\n\n  const payload = record.body;\n  if (payload) {\n    try {\n      const item = JSON.parse(payload);\n      // do something with the item\n      subsegment?.addMetadata('item', item);\n    } catch (error) {\n      subsegment?.addError(error);\n      throw error;\n    }\n  }\n\n  subsegment?.close(); // (3)!\n};\n\nexport const handler: SQSHandler = middy(async (event: SQSEvent, context) =&gt;\n  processPartialResponse(event, recordHandler, processor, {\n    context,\n  })\n).use(captureLambdaHandler(tracer));\n</code></pre> <ol> <li>Retrieve the current segment, then create a subsegment for the record being processed</li> <li>You can add annotations and metadata to the subsegment directly without calling <code>tracer.setSegment(subsegment)</code></li> <li>Close the subsegment when you're done processing the record</li> </ol>"
        },
        {
            "location": "utilities/batch/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>As there is no external calls, you can unit test your code with <code>BatchProcessorSync</code> quite easily.</p> <p>Example:</p> <p>Given a SQS batch where the first batch record succeeds and the second fails processing, we should have a single item reported in the function response.</p> index.test.tsindex.tsSample SQS event <pre><code>import { readFileSync } from 'node:fs';\nimport { describe, expect, it } from 'vitest';\nimport { handler, processor } from './gettingStartedSQS.js';\n\nconst context = {\n  callbackWaitsForEmptyEventLoop: true,\n  functionVersion: '$LATEST',\n  functionName: 'foo-bar-function',\n  memoryLimitInMB: '128',\n  logGroupName: '/aws/lambda/foo-bar-function-123456abcdef',\n  logStreamName: '2021/03/09/[$LATEST]abcdef123456abcdef123456abcdef123456',\n  invokedFunctionArn:\n    'arn:aws:lambda:eu-west-1:123456789012:function:foo-bar-function',\n  awsRequestId: 'c6af9ac6-7b61-11e6-9a41-93e812345678',\n  getRemainingTimeInMillis: () =&gt; 1234,\n  done: () =&gt; console.log('Done!'),\n  fail: () =&gt; console.log('Failed!'),\n  succeed: () =&gt; console.log('Succeeded!'),\n};\n\ndescribe('Function tests', () =&gt; {\n  it('returns one failed message', async () =&gt; {\n    // Prepare\n    const event = JSON.parse(\n      readFileSync('./samples/sampleSQSEvent.json', 'utf8')\n    );\n    const processorResult = processor; // access processor for additional assertions\n    const successfulRecord = event.Records[0];\n    const failedRecord = event.Records[1];\n    const expectedResponse = {\n      batchItemFailures: [\n        {\n          itemIdentifier: failedRecord.messageId,\n        },\n      ],\n    };\n\n    // Act\n    const response = await handler(event, context, () =&gt; {});\n\n    // Assess\n    expect(response).toEqual(expectedResponse);\n    expect(processorResult.failureMessages).toHaveLength(1);\n    expect(processorResult.successMessages[0]).toEqual(successfulRecord);\n  });\n});\n</code></pre> <pre><code>import {\n  BatchProcessor,\n  EventType,\n  processPartialResponse,\n} from '@aws-lambda-powertools/batch';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport type { SQSHandler, SQSRecord } from 'aws-lambda';\n\nconst processor = new BatchProcessor(EventType.SQS); // (1)!\nconst logger = new Logger();\n\n// biome-ignore format: we need the comment in the next line to stay there to annotate the code snippet in the docs\nconst recordHandler = async (record: SQSRecord): Promise&lt;void&gt; =&gt; { // (2)!\n  const payload = record.body;\n  if (payload) {\n    const item = JSON.parse(payload);\n    logger.info('Processed item', { item });\n  }\n};\n\nexport const handler: SQSHandler = async (event, context) =&gt;\n  // biome-ignore format: we need the comment in the next line to stay there to annotate the code snippet in the docs\n  processPartialResponse(event, recordHandler, processor, { // (3)!\n    context,\n  });\n\nexport { processor };\n</code></pre> events/sqs_event.json<pre><code>{\n  \"Records\": [\n    {\n      \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n      \"body\": \"{\\\"Message\\\": \\\"success\\\"}\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082649183\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n      \"awsRegion\": \"us-east-1\"\n    },\n    {\n      \"messageId\": \"244fc6b4-87a3-44ab-83d2-361172410c3a\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a\",\n      \"body\": \"SGVsbG8sIHRoaXMgaXMgYSB0ZXN0Lg==\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082649183\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2: 123456789012:my-queue\",\n      \"awsRegion\": \"us-east-1\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/",
            "title": "Idempotency",
            "text": "<p>The idempotency utility provides a simple solution to convert your Lambda functions into idempotent operations which are safe to retry.</p>"
        },
        {
            "location": "utilities/idempotency/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Prevent Lambda handler from executing more than once on the same event payload during a time window</li> <li>Ensure Lambda handler returns the same result when called with the same payload</li> <li>Select a subset of the event as the idempotency key using JMESPath expressions</li> <li>Set a time window in which records with the same payload should be considered duplicates</li> <li>Expires in-progress executions if the Lambda function times out halfway through</li> </ul>"
        },
        {
            "location": "utilities/idempotency/#terminology",
            "title": "Terminology",
            "text": "<p>The property of idempotency means that an operation does not cause additional side effects if it is called more than once with the same input parameters.</p> <p>Idempotent operations will return the same result when they are called multiple times with the same parameters. This makes idempotent operations safe to retry.</p> <p>Idempotency key is a hash representation of either the entire event or a specific configured subset of the event, and invocation results are JSON serialized and stored in your persistence storage layer.</p> <p>Idempotency record is the data representation of an idempotent request saved in your preferred  storage layer. We use it to coordinate whether a request is idempotent, whether it's still valid or expired based on timestamps, etc.</p> <p> <pre><code>classDiagram\n    direction LR\n    class IdempotencyRecord {\n        idempotencyKey string\n        status Status\n        expiryTimestamp number\n        inProgressExpiryTimestamp number\n        responseData Json~string~\n        payloadHash string\n    }\n    class Status {\n        &lt;&lt;Enumeration&gt;&gt;\n        INPROGRESS\n        COMPLETE\n        EXPIRED internal_only\n    }\n    IdempotencyRecord -- Status</code></pre> <p>Idempotency record representation </p>"
        },
        {
            "location": "utilities/idempotency/#getting-started",
            "title": "Getting started",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#installation",
            "title": "Installation",
            "text": "<p>Install the library in your project</p> <pre><code>npm i @aws-lambda-powertools/idempotency @aws-sdk/client-dynamodb @aws-sdk/lib-dynamodb\n</code></pre> <p>While we support Amazon DynamoDB as a persistence layer out of the box, you need to bring your own AWS SDK for JavaScript v3 DynamoDB client.</p> Note <p>This utility supports AWS SDK for JavaScript v3 only. If you are using the <code>nodejs18.x</code> runtime or newer, the AWS SDK for JavaScript v3 is already installed and you can install only the utility.</p>"
        },
        {
            "location": "utilities/idempotency/#iam-permissions",
            "title": "IAM Permissions",
            "text": "<p>Your Lambda function IAM Role must have <code>dynamodb:GetItem</code>, <code>dynamodb:PutItem</code>, <code>dynamodb:UpdateItem</code> and <code>dynamodb:DeleteItem</code> IAM permissions before using this feature. If you're using one of our examples: AWS Serverless Application Model (SAM) or Terraform the required permissions are already included.</p>"
        },
        {
            "location": "utilities/idempotency/#required-resources",
            "title": "Required resources",
            "text": "<p>Before getting started, you need to create a persistent storage layer where the idempotency utility can store its state - your lambda functions will need read and write access to it.</p> <p>As of now, Amazon DynamoDB is the only supported persistent storage layer, so you'll need to create a table first.</p> <p>Default table configuration</p> <p>If you're not changing the default configuration for the DynamoDB persistence layer, this is the expected default configuration:</p> Configuration Default value Notes Partition key <code>id</code> The id of each idempotency record which a combination of <code>functionName#hashOfPayload</code>. TTL attribute name <code>expiration</code> This can only be configured after your table is created if you're using AWS Console. Tip: You can share a single state table for all functions <p>You can reuse the same DynamoDB table to store idempotency state. We add the Lambda function name in addition to the idempotency key as a hash key.</p> AWS Cloud Development Kit (CDK) exampleAWS Serverless Application Model (SAM) exampleTerraform example template.ts<pre><code>import { Stack, type StackProps } from 'aws-cdk-lib';\nimport { AttributeType, BillingMode, Table } from 'aws-cdk-lib/aws-dynamodb';\nimport { Runtime } from 'aws-cdk-lib/aws-lambda';\nimport { NodejsFunction } from 'aws-cdk-lib/aws-lambda-nodejs';\nimport type { Construct } from 'constructs';\n\nexport class IdempotencyStack extends Stack {\n  public constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    const table = new Table(this, 'idempotencyTable', {\n      partitionKey: {\n        name: 'id',\n        type: AttributeType.STRING,\n      },\n      timeToLiveAttribute: 'expiration',\n      billingMode: BillingMode.PAY_PER_REQUEST,\n    });\n\n    const fnHandler = new NodejsFunction(this, 'helloWorldFunction', {\n      runtime: Runtime.NODEJS_20_X,\n      handler: 'handler',\n      entry: 'src/index.ts',\n      environment: {\n        IDEMPOTENCY_TABLE_NAME: table.tableName,\n      },\n    });\n    table.grantReadWriteData(fnHandler);\n  }\n}\n</code></pre> template.yaml<pre><code>Transform: AWS::Serverless-2016-10-31\nResources:\n  IdempotencyTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      AttributeDefinitions:\n        - AttributeName: id\n          AttributeType: S\n      KeySchema:\n        - AttributeName: id\n          KeyType: HASH\n      TimeToLiveSpecification:\n        AttributeName: expiration\n        Enabled: true\n      BillingMode: PAY_PER_REQUEST\n\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Runtime: nodejs22.x\n      Handler: app.py\n      Policies:\n        - Statement:\n            - Sid: AllowDynamodbReadWrite\n              Effect: Allow\n              Action:\n                - dynamodb:PutItem\n                - dynamodb:GetItem\n                - dynamodb:UpdateItem\n                - dynamodb:DeleteItem\n              Resource: !GetAtt IdempotencyTable.Arn\n</code></pre> template.tf<pre><code>terraform {\n    required_providers {\n        aws = {\n        source  = \"hashicorp/aws\"\n        version = \"~&gt; 4.0\"\n        }\n    }\n}\n\nprovider \"aws\" {\n    region = \"us-east-1\" # Replace with your desired AWS region\n}\n\nresource \"aws_dynamodb_table\" \"IdempotencyTable\" {\n    name         = \"IdempotencyTable\"\n    billing_mode = \"PAY_PER_REQUEST\"\n    hash_key     = \"id\"\n    attribute {\n        name = \"id\"\n        type = \"S\"\n    }\n    ttl {\n        attribute_name = \"expiration\"\n        enabled        = true\n    }\n}\n\nresource \"aws_lambda_function\" \"IdempotencyFunction\" {\n    function_name = \"IdempotencyFunction\"\n    role          = aws_iam_role.IdempotencyFunctionRole.arn\n    runtime       = \"nodejs20.x\"\n    handler       = \"index.handler\"\n    filename      = \"lambda.zip\"\n}\n\nresource \"aws_iam_role\" \"IdempotencyFunctionRole\" {\n    name = \"IdempotencyFunctionRole\"\n\n    assume_role_policy = jsonencode({\n        Version = \"2012-10-17\"\n        Statement = [\n        {\n            Sid    = \"\"\n            Effect = \"Allow\"\n            Principal = {\n            Service = \"lambda.amazonaws.com\"\n            }\n            Action = \"sts:AssumeRole\"\n        },\n        ]\n    })\n}\n\nresource \"aws_iam_policy\" \"LambdaDynamoDBPolicy\" {\n    name        = \"LambdaDynamoDBPolicy\"\n    description = \"IAM policy for Lambda function to access DynamoDB\"\n    policy = jsonencode({\n        Version = \"2012-10-17\"\n        Statement = [\n        {\n            Sid    = \"AllowDynamodbReadWrite\"\n            Effect = \"Allow\"\n            Action = [\n            \"dynamodb:PutItem\",\n            \"dynamodb:GetItem\",\n            \"dynamodb:UpdateItem\",\n            \"dynamodb:DeleteItem\",\n            ]\n            Resource = aws_dynamodb_table.IdempotencyTable.arn\n        },\n        ]\n    })\n}\n\nresource \"aws_iam_role_policy_attachment\" \"IdempotencyFunctionRoleAttachment\" {\n    role       = aws_iam_role.IdempotencyFunctionRole.name\n    policy_arn = aws_iam_policy.LambdaDynamoDBPolicy.arn\n}\n</code></pre> Warning: Large responses with DynamoDB persistence layer <p>When using this utility with DynamoDB, your function's responses must be smaller than 400KB.</p> <p>Larger items cannot be written to DynamoDB and will cause exceptions.</p> Info: DynamoDB <p>Each function invocation will make only 1 request to DynamoDB by using DynamoDB's conditional expressions to ensure that we don't overwrite existing records, and ReturnValuesOnConditionCheckFailure to return the record if it exists. See AWS Blog post on handling conditional write errors for more details. For retried invocations, you will see 1WCU and 1RCU. Review the DynamoDB pricing documentation to estimate the cost.</p>"
        },
        {
            "location": "utilities/idempotency/#makeidempotent-function-wrapper",
            "title": "MakeIdempotent function wrapper",
            "text": "<p>You can quickly start by initializing the <code>DynamoDBPersistenceLayer</code> class and using it with the <code>makeIdempotent</code> function wrapper on your Lambda handler.</p> index.tstypes.ts <pre><code>import { randomUUID } from 'node:crypto';\nimport { makeIdempotent } from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response, SubscriptionResult } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\n\nconst createSubscriptionPayment = async (\n  event: Request\n): Promise&lt;SubscriptionResult&gt; =&gt; {\n  // ... create payment\n  return {\n    id: randomUUID(),\n    productId: event.productId,\n  };\n};\n\nexport const handler = makeIdempotent(\n  async (event: Request, _context: Context): Promise&lt;Response&gt; =&gt; {\n    try {\n      const payment = await createSubscriptionPayment(event);\n\n      return {\n        paymentId: payment.id,\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  },\n  {\n    persistenceStore,\n  }\n);\n</code></pre> <pre><code>export type Request = {\n  user: string;\n  productId: string;\n};\n\nexport type Response = {\n  [key: string]: unknown;\n};\n\nexport type SubscriptionResult = {\n  id: string;\n  productId: string;\n};\n</code></pre> <p>After processing this request successfully, a second request containing the exact same payload above will now return the same response, ensuring our customer isn't charged twice.</p> Note <p>In this example, the entire Lambda handler is treated as a single idempotent operation. If your Lambda handler can cause multiple side effects, or you're only interested in making a specific logic idempotent, use the <code>makeIdempotent</code> high-order function only on the function that needs to be idempotent.</p> <p>See Choosing a payload subset for idempotency for more elaborate use cases.</p> <p>You can also use the <code>makeIdempotent</code> function wrapper on any method that returns a response to make it idempotent. This is useful when you want to make a specific logic idempotent, for example when your Lambda handler performs multiple side effects and you only want to make a specific one idempotent.</p> Limitation <p>Make sure to return a JSON serializable response from your function, otherwise you'll get an error.</p> <p>When using <code>makeIdempotent</code> on arbitrary functions, you can tell us which argument in your function signature has the data we should use via <code>dataIndexArgument</code>. If you don't specify this argument, we'll use the first argument in the function signature.</p> index.tstypes.ts <pre><code>import { randomUUID } from 'node:crypto';\nimport {\n  IdempotencyConfig,\n  makeIdempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response, SubscriptionResult } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\nconst config = new IdempotencyConfig({});\n\nconst reportSubscriptionMetrics = async (\n  _transactionId: string,\n  _user: string\n): Promise&lt;void&gt; =&gt; {\n  // ... send notification\n};\n\nconst createSubscriptionPayment = makeIdempotent(\n  async (\n    transactionId: string,\n    event: Request\n  ): Promise&lt;SubscriptionResult&gt; =&gt; {\n    // ... create payment\n    return {\n      id: transactionId,\n      productId: event.productId,\n    };\n  },\n  {\n    persistenceStore,\n    dataIndexArgument: 1,\n    config,\n  }\n);\n\nexport const handler = async (\n  event: Request,\n  context: Context\n): Promise&lt;Response&gt; =&gt; {\n  config.registerLambdaContext(context);\n  try {\n    const transactionId = randomUUID();\n    const payment = await createSubscriptionPayment(transactionId, event);\n\n    await reportSubscriptionMetrics(transactionId, event.user);\n\n    return {\n      paymentId: payment.id,\n      message: 'success',\n      statusCode: 200,\n    };\n  } catch (error) {\n    throw new Error('Error creating payment');\n  }\n};\n</code></pre> <pre><code>export type Request = {\n  user: string;\n  productId: string;\n};\n\nexport type Response = {\n  [key: string]: unknown;\n};\n\nexport type SubscriptionResult = {\n  id: string;\n  productId: string;\n};\n</code></pre> <p>The function this example has two arguments, note that while wrapping it with the <code>makeIdempotent</code> high-order function, we specify the <code>dataIndexArgument</code> as <code>1</code> to tell the decorator that the second argument is the one with the data we should use to make the function idempotent. Remember that arguments are zero-indexed, so the first argument is <code>0</code>, the second is <code>1</code>, etc.</p>"
        },
        {
            "location": "utilities/idempotency/#idempotent-decorator",
            "title": "Idempotent Decorator",
            "text": "<p>You can also use the <code>@idempotent</code> decorator to make your Lambda handler idempotent, similar to the <code>makeIdempotent</code> function wrapper.</p> <p>Info</p> <p>The class method decorators in this project follow the experimental implementation enabled via the <code>experimentalDecorators</code> compiler option in TypeScript.</p> <p>Additionally, they are implemented to decorate async methods. When decorating a synchronous one, the decorator replaces its implementation with an async one causing the caller to have to <code>await</code> the now decorated method.</p> <p>If this is not the desired behavior, you can use one of the other patterns to make your logic idempotent.</p> index.tstypes.ts <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport {\n  IdempotencyConfig,\n  idempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response } from './types.js';\n\nconst dynamoDBPersistenceLayer = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\n\nconst config = new IdempotencyConfig({});\n\nclass MyLambda implements LambdaInterface {\n  @idempotent({ persistenceStore: dynamoDBPersistenceLayer, config: config })\n  public async handler(_event: Request, _context: Context): Promise&lt;Response&gt; {\n    // ... process your event\n    return {\n      message: 'success',\n      statusCode: 200,\n    };\n  }\n}\n\nconst defaultLambda = new MyLambda();\nexport const handler = defaultLambda.handler.bind(defaultLambda);\n</code></pre> <pre><code>import type { IdempotencyRecordStatusValue } from '@aws-lambda-powertools/idempotency/types';\n\nexport type Request = {\n  user: string;\n  productId: string;\n};\n\nexport type Response = {\n  [key: string]: unknown;\n};\n\nexport type SubscriptionResult = {\n  id: string;\n  productId: string;\n};\n\nexport type ApiSecret = {\n  apiKey: string;\n  refreshToken: string;\n  validUntil: number;\n  restEndpoint: string;\n};\n\nexport type ProviderItem = {\n  validation?: string;\n  in_progress_expiration?: number;\n  status: IdempotencyRecordStatusValue;\n  data: string;\n};\n</code></pre> <p>You can use the decorator on your Lambda handler or on any function that returns a response to make it idempotent. This is useful when you want to make a specific logic idempotent, for example when your Lambda handler performs multiple side effects and you only want to make a specific one idempotent. The configuration options for the <code>@idempotent</code> decorator are the same as the ones for the <code>makeIdempotent</code> function wrapper.</p>"
        },
        {
            "location": "utilities/idempotency/#makehandleridempotent-middy-middleware",
            "title": "MakeHandlerIdempotent Middy middleware",
            "text": "<p>A note about Middy</p> <p>We guarantee support for Middy.js <code>v4.x</code> through <code>v6.x</code> versions. Check their docs to learn more about Middy and its middleware stack as well as best practices when working with Powertools.</p> <p>If you are using Middy.js as your middleware engine, you can use the <code>makeHandlerIdempotent</code> middleware to make your Lambda handler idempotent.</p> <p>Similar to the <code>makeIdempotent</code> function wrapper, you can quickly make your Lambda handler idempotent by initializing the <code>DynamoDBPersistenceLayer</code> class and using it with the <code>makeHandlerIdempotent</code> middleware.</p> index.tstypes.ts <pre><code>import { randomUUID } from 'node:crypto';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport { makeHandlerIdempotent } from '@aws-lambda-powertools/idempotency/middleware';\nimport middy from '@middy/core';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response, SubscriptionResult } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\n\nconst createSubscriptionPayment = async (\n  event: Request\n): Promise&lt;SubscriptionResult&gt; =&gt; {\n  // ... create payment\n  return {\n    id: randomUUID(),\n    productId: event.productId,\n  };\n};\n\nexport const handler = middy(\n  async (event: Request, _context: Context): Promise&lt;Response&gt; =&gt; {\n    try {\n      const payment = await createSubscriptionPayment(event);\n\n      return {\n        paymentId: payment.id,\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  }\n).use(\n  makeHandlerIdempotent({\n    persistenceStore,\n  })\n);\n</code></pre> <pre><code>export type Request = {\n  user: string;\n  productId: string;\n};\n\nexport type Response = {\n  [key: string]: unknown;\n};\n\nexport type SubscriptionResult = {\n  id: string;\n  productId: string;\n};\n</code></pre> <p>For the middleware to work, your Lambda function handler must return a value different from <code>undefined</code>. This is a known limitation of the early return feature in Middy.js. If your use case requires early returns, you can use the <code>makeIdempotent</code> function wrapper instead.</p>"
        },
        {
            "location": "utilities/idempotency/#choosing-a-payload-subset-for-idempotency",
            "title": "Choosing a payload subset for idempotency",
            "text": "<p>Use <code>IdempotencyConfig</code> to instruct the idempotent decorator to only use a portion of your payload to verify whether a request is idempotent, and therefore it should not be retried. When dealing with a more elaborate payload, where parts of the payload always change, you should use the <code>eventKeyJmesPath</code> parameter.</p> <p>Payment scenario</p> <p>In this example, we have a Lambda handler that creates a payment for a user subscribing to a product. We want to ensure that we don't accidentally charge our customer by subscribing them more than once.</p> <p>Imagine the function executes successfully, but the client never receives the response due to a connection issue. It is safe to retry in this instance, as the idempotent decorator will return a previously saved response.</p> <p>What we want here is to instruct Idempotency to use the <code>user</code> and <code>productId</code> fields from our incoming payload as our idempotency key. If we were to treat the entire request as our idempotency key, a simple HTTP header or timestamp change would cause our customer to be charged twice.</p> Deserializing JSON strings in payloads for increased accuracy. <p>The payload extracted by the <code>eventKeyJmesPath</code> is treated as a string by default. This means there could be differences in whitespace even when the JSON payload itself is identical.</p> <p>To alter this behaviour, we can use the JMESPath built-in function <code>powertools_json()</code> to treat the payload as a JSON object rather than a string.</p> index.tsExample eventtypes.ts <pre><code>import { randomUUID } from 'node:crypto';\nimport {\n  IdempotencyConfig,\n  makeIdempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response, SubscriptionResult } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\n\nconst createSubscriptionPayment = async (\n  _user: string,\n  productId: string\n): Promise&lt;SubscriptionResult&gt; =&gt; {\n  // ... create payment\n  return {\n    id: randomUUID(),\n    productId: productId,\n  };\n};\n\n// Deserialize JSON string under the \"body\" key, then extract the \"user\" and \"productId\" keys\nconst config = new IdempotencyConfig({\n  eventKeyJmesPath: 'powertools_json(body).[\"user\", \"productId\"]',\n});\n\nexport const handler = makeIdempotent(\n  async (event: Request, _context: Context): Promise&lt;Response&gt; =&gt; {\n    try {\n      const payment = await createSubscriptionPayment(\n        event.user,\n        event.productId\n      );\n\n      return {\n        paymentId: payment.id,\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  },\n  {\n    persistenceStore,\n    config,\n  }\n);\n</code></pre> <pre><code>{\n  \"version\": \"2.0\",\n  \"routeKey\": \"ANY /createpayment\",\n  \"rawPath\": \"/createpayment\",\n  \"rawQueryString\": \"\",\n  \"headers\": {\n    \"Header1\": \"value1\",\n    \"X-Idempotency-Key\": \"abcdefg\"\n  },\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"apiId\": \"api-id\",\n    \"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n    \"domainPrefix\": \"id\",\n    \"http\": {\n      \"method\": \"POST\",\n      \"path\": \"/createpayment\",\n      \"protocol\": \"HTTP/1.1\",\n      \"sourceIp\": \"ip\",\n      \"userAgent\": \"agent\"\n    },\n    \"requestId\": \"id\",\n    \"routeKey\": \"ANY /createpayment\",\n    \"stage\": \"$default\",\n    \"time\": \"10/Feb/2021:13:40:43 +0000\",\n    \"timeEpoch\": 1612964443723\n  },\n  \"body\": \"{\\\"user\\\":\\\"xyz\\\",\\\"productId\\\":\\\"123456789\\\"}\",\n  \"isBase64Encoded\": false\n}\n</code></pre> <pre><code>export type Request = {\n  user: string;\n  productId: string;\n};\n\nexport type Response = {\n  [key: string]: unknown;\n};\n\nexport type SubscriptionResult = {\n  id: string;\n  productId: string;\n};\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#lambda-timeouts",
            "title": "Lambda timeouts",
            "text": "<p>To prevent against extended failed retries when a Lambda function times out, Powertools for AWS Lambda calculates and includes the remaining invocation available time as part of the idempotency record. This is automatically done when you wrap your Lambda handler with the makeIdempotent function wrapper, or use the <code>makeHandlerIdempotent</code> Middy middleware.</p> Example <p>If a second invocation happens after this timestamp, and the record is marked as <code>INPROGRESS</code>, we will execute the invocation again as if it was in the <code>EXPIRED</code> state (e.g, <code>expire_seconds</code> field elapsed).</p> <p>This means that if an invocation expired during execution, it will be quickly executed again on the next retry.</p> Important <p>If you are only using the makeIdempotent function wrapper to guard isolated parts of your code outside of your handler, you must use <code>registerLambdaContext</code> available in the idempotency config object to benefit from this protection.</p> <p>Here is an example on how you register the Lambda context in your handler:</p> Registering Lambda Context <pre><code>import { randomUUID } from 'node:crypto';\nimport {\n  IdempotencyConfig,\n  makeIdempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response, SubscriptionResult } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\nconst config = new IdempotencyConfig({});\n\nconst createSubscriptionPayment = makeIdempotent(\n  async (\n    transactionId: string,\n    event: Request\n  ): Promise&lt;SubscriptionResult&gt; =&gt; {\n    // ... create payment\n    return {\n      id: transactionId,\n      productId: event.productId,\n    };\n  },\n  {\n    persistenceStore,\n    dataIndexArgument: 1,\n    config,\n  }\n);\n\nexport const handler = async (\n  event: Request,\n  context: Context\n): Promise&lt;Response&gt; =&gt; {\n  // Register the Lambda context to the IdempotencyConfig instance\n  config.registerLambdaContext(context);\n  try {\n    const transactionId = randomUUID();\n    const payment = await createSubscriptionPayment(transactionId, event);\n\n    return {\n      paymentId: payment.id,\n      message: 'success',\n      statusCode: 200,\n    };\n  } catch (error) {\n    throw new Error('Error creating payment');\n  }\n};\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#handling-exceptions",
            "title": "Handling exceptions",
            "text": "<p>If you are making on your entire Lambda handler idempotent, any unhandled exceptions that are raised during the code execution will cause the record in the persistence layer to be deleted. This means that new invocations will execute your code again despite having the same payload. If you don't want the record to be deleted, you need to catch exceptions within the idempotent function and return a successful response.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;Persistence Layer: Get or set (id=event.search(payload))\n    activate Persistence Layer\n    Note right of Persistence Layer: Locked during this time. Prevents multiple&lt;br/&gt;Lambda invocations with the same&lt;br/&gt;payload running concurrently.\n    Lambda--xLambda: Call handler (event).&lt;br/&gt;Raises exception\n    Lambda-&gt;&gt;Persistence Layer: Delete record (id=event.search(payload))\n    deactivate Persistence Layer\n    Lambda--&gt;&gt;Client: Return error response</code></pre> Idempotent sequence exception </p> <p>If you are using <code>makeIdempotent</code> on any other function, any unhandled exceptions that are thrown inside the wrapped function will cause the record in the persistence layer to be deleted, and allow the function to be executed again if retried.</p> <p>If an error is thrown outside the scope of the decorated function and after your function has been called, the persistent record will not be affected. In this case, idempotency will be maintained for your decorated function. Example:</p> Handling exceptions <pre><code>import { randomUUID } from 'node:crypto';\nimport {\n  IdempotencyConfig,\n  makeIdempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response, SubscriptionResult } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\nconst config = new IdempotencyConfig({});\n\nconst createSubscriptionPayment = makeIdempotent(\n  async (\n    transactionId: string,\n    event: Request\n  ): Promise&lt;SubscriptionResult&gt; =&gt; {\n    // ... create payment\n    return {\n      id: transactionId,\n      productId: event.productId,\n    };\n  },\n  {\n    persistenceStore,\n    dataIndexArgument: 1,\n    config,\n  }\n);\n\nexport const handler = async (\n  event: Request,\n  context: Context\n): Promise&lt;Response&gt; =&gt; {\n  config.registerLambdaContext(context);\n  /**\n   * If an exception is thrown before the wrapped function is called,\n   * no idempotency record is created.\n   */\n  try {\n    const transactionId = randomUUID();\n    const payment = await createSubscriptionPayment(transactionId, event);\n\n    /**\n     * If an exception is thrown after the wrapped function is called,\n     * the idempotency record won't be affected so it's safe to retry.\n     */\n\n    return {\n      paymentId: payment.id,\n      message: 'success',\n      statusCode: 200,\n    };\n  } catch (error) {\n    throw new Error('Error creating payment');\n  }\n};\n</code></pre> Warning <p>We will throw <code>IdempotencyPersistenceLayerError</code> if any of the calls to the persistence layer fail unexpectedly.</p> <p>As this happens outside the scope of your decorated function, you are not able to catch it when making your Lambda handler idempotent.</p>"
        },
        {
            "location": "utilities/idempotency/#idempotency-request-flow",
            "title": "Idempotency request flow",
            "text": "<p>The following sequence diagrams explain how the Idempotency feature behaves under different scenarios.</p>"
        },
        {
            "location": "utilities/idempotency/#successful-request",
            "title": "Successful request",
            "text": "<p> <pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Persistence Layer--&gt;&gt;Lambda: Already exists in persistence layer.\n        deactivate Persistence Layer\n        Note over Lambda,Persistence Layer: Record status is COMPLETE and not expired\n        Lambda--&gt;&gt;Client: Same response sent to client\n    end</code></pre> Idempotent successful request </p>"
        },
        {
            "location": "utilities/idempotency/#successful-request-with-cache-enabled",
            "title": "Successful request with cache enabled",
            "text": "<p>In-memory cache is disabled by default.</p> <p> <pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n      Client-&gt;&gt;Lambda: Invoke (event)\n      Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n      activate Persistence Layer\n      Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n      Lambda--&gt;&gt;Lambda: Call your function\n      Lambda-&gt;&gt;Persistence Layer: Update record with result\n      deactivate Persistence Layer\n      Persistence Layer--&gt;&gt;Persistence Layer: Update record\n      Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n      Lambda--&gt;&gt;Lambda: Save record and result in memory\n      Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n      Client-&gt;&gt;Lambda: Invoke (event)\n      Lambda--&gt;&gt;Lambda: Get idempotency_key=hash(payload)\n      Note over Lambda,Persistence Layer: Record status is COMPLETE and not expired\n      Lambda--&gt;&gt;Client: Same response sent to client\n    end</code></pre> Idempotent successful request cached </p>"
        },
        {
            "location": "utilities/idempotency/#successful-request-with-responsehook-configured",
            "title": "Successful request with responseHook configured",
            "text": "<p> <pre><code>sequenceDiagram\n    participant Client\n    participant Lambda\n    participant Response hook\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Persistence Layer--&gt;&gt;Response hook: Already exists in persistence layer.\n        deactivate Persistence Layer\n        Note over Response hook,Persistence Layer: Record status is COMPLETE and not expired\n        Response hook-&gt;&gt;Lambda: Response hook invoked\n        Lambda--&gt;&gt;Client: Manipulated idempotent response sent to client\n    end</code></pre> Successful idempotent request with a response hook </p>"
        },
        {
            "location": "utilities/idempotency/#expired-idempotency-records",
            "title": "Expired idempotency records",
            "text": "<p> <pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else retried request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Persistence Layer--&gt;&gt;Lambda: Already exists in persistence layer.\n        deactivate Persistence Layer\n        Note over Lambda,Persistence Layer: Record status is COMPLETE but expired hours ago\n        loop Repeat initial request process\n            Note over Lambda,Persistence Layer: 1. Set record to INPROGRESS, &lt;br&gt; 2. Call your function, &lt;br&gt; 3. Set record to COMPLETE\n        end\n        Lambda--&gt;&gt;Client: Same response sent to client\n    end</code></pre> Previous Idempotent request expired </p>"
        },
        {
            "location": "utilities/idempotency/#concurrent-identical-in-flight-requests",
            "title": "Concurrent identical in-flight requests",
            "text": "<p> <pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    Client-&gt;&gt;Lambda: Invoke (event)\n    Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n    activate Persistence Layer\n    Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n      par Second request\n          Client-&gt;&gt;Lambda: Invoke (event)\n          Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n          Lambda--xLambda: IdempotencyAlreadyInProgressError\n          Lambda-&gt;&gt;Client: Error sent to client if unhandled\n      end\n    Lambda--&gt;&gt;Lambda: Call your function\n    Lambda-&gt;&gt;Persistence Layer: Update record with result\n    deactivate Persistence Layer\n    Persistence Layer--&gt;&gt;Persistence Layer: Update record\n    Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n    Lambda--&gt;&gt;Client: Response sent to client</code></pre> Concurrent identical in-flight requests </p>"
        },
        {
            "location": "utilities/idempotency/#lambda-request-timeout",
            "title": "Lambda request timeout",
            "text": "<p> <pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt initial request\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Note right of Lambda: Time out\n        Lambda--xLambda: Time out error\n        Lambda--&gt;&gt;Client: Return error response\n        deactivate Persistence Layer\n    else retry after Lambda timeout elapses\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Reset in_progress_expiry attribute\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Lambda--&gt;&gt;Client: Response sent to client\n    end</code></pre> Idempotent request during and after Lambda timeouts </p>"
        },
        {
            "location": "utilities/idempotency/#optional-idempotency-key",
            "title": "Optional idempotency key",
            "text": "<p> <pre><code>sequenceDiagram\n    autonumber\n    participant Client\n    participant Lambda\n    participant Persistence Layer\n    alt request with idempotency key\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Lambda-&gt;&gt;Persistence Layer: Get or set idempotency_key=hash(payload)\n        activate Persistence Layer\n        Note over Lambda,Persistence Layer: Set record status to INPROGRESS. &lt;br&gt; Prevents concurrent invocations &lt;br&gt; with the same payload\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda-&gt;&gt;Persistence Layer: Update record with result\n        deactivate Persistence Layer\n        Persistence Layer--&gt;&gt;Persistence Layer: Update record\n        Note over Lambda,Persistence Layer: Set record status to COMPLETE. &lt;br&gt; New invocations with the same payload &lt;br&gt; now return the same result\n        Lambda--&gt;&gt;Client: Response sent to client\n    else request(s) without idempotency key\n        Client-&gt;&gt;Lambda: Invoke (event)\n        Note over Lambda: Idempotency key is missing\n        Note over Persistence Layer: Skips any operation to fetch, update, and delete\n        Lambda--&gt;&gt;Lambda: Call your function\n        Lambda--&gt;&gt;Client: Response sent to client\n    end</code></pre> Optional idempotency key </p>"
        },
        {
            "location": "utilities/idempotency/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#persistence-layers",
            "title": "Persistence layers",
            "text": ""
        },
        {
            "location": "utilities/idempotency/#dynamodbpersistencelayer",
            "title": "DynamoDBPersistenceLayer",
            "text": "<p>This persistence layer is built-in, and you can either use an existing DynamoDB table or create a new one dedicated for idempotency state (recommended).</p> Customizing DynamoDBPersistenceLayer to suit your table structure <pre><code>import { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport { makeHandlerIdempotent } from '@aws-lambda-powertools/idempotency/middleware';\nimport middy from '@middy/core';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n  keyAttr: 'idempotencyKey',\n  expiryAttr: 'expiresAt',\n  inProgressExpiryAttr: 'inProgressExpiresAt',\n  statusAttr: 'currentStatus',\n  dataAttr: 'resultData',\n  validationKeyAttr: 'validationKey',\n});\n\nexport const handler = middy(\n  async (_event: Request, _context: Context): Promise&lt;Response&gt; =&gt; {\n    try {\n      // ... create payment\n\n      return {\n        paymentId: '1234567890',\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  }\n).use(\n  makeHandlerIdempotent({\n    persistenceStore,\n  })\n);\n</code></pre> <p>When using DynamoDB as a persistence layer, you can alter the attribute names by passing these parameters when initializing the persistence layer:</p> Parameter Required Default Description tableName Table name to store state keyAttr <code>id</code> Partition key of the table. Hashed representation of the payload (unless sort_key_attr is specified) expiryAttr <code>expiration</code> Unix timestamp of when record expires inProgressExpiryAttr <code>in_progress_expiration</code> Unix timestamp of when record expires while in progress (in case of the invocation times out) statusAttr <code>status</code> Stores status of the lambda execution during and after invocation dataAttr <code>data</code> Stores results of successfully executed Lambda handlers validationKeyAttr <code>validation</code> Hashed representation of the parts of the event used for validation sortKeyAttr Sort key of the table (if table is configured with a sort key). staticPkValue <code>idempotency#{LAMBDA_FUNCTION_NAME}</code> Static value to use as the partition key. Only used when sort_key_attr is set."
        },
        {
            "location": "utilities/idempotency/#customizing-the-default-behavior",
            "title": "Customizing the default behavior",
            "text": "<p>Idempotent decorator can be further configured with <code>IdempotencyConfig</code> as seen in the previous examples. These are the available options for further configuration</p> Parameter Default Description eventKeyJmespath <code>''</code> JMESPath expression to extract the idempotency key from the event record using built-in functions payloadValidationJmespath <code>''</code> JMESPath expression to validate that the specified fields haven't changed across requests for the same idempotency key e.g., payload tampering. jmesPathOptions <code>undefined</code> Custom JMESPath functions to use when parsing the JMESPath expressions. See Custom JMESPath Functions throwOnNoIdempotencyKey <code>false</code> Throw an error if no idempotency key was found in the request expiresAfterSeconds 3600 The number of seconds to wait before a record is expired, allowing a new transaction with the same idempotency key useLocalCache <code>false</code> Whether to cache idempotency results in-memory to save on persistence storage latency and costs localCacheMaxItems 256 Max number of items to store in local cache hashFunction <code>md5</code> Function to use for calculating hashes, as provided by the crypto module in the standard library. responseHook <code>undefined</code> Function to use for processing the stored Idempotent response. This function hook is called when an existing idempotent response is found. See Manipulating The Idempotent Response"
        },
        {
            "location": "utilities/idempotency/#handling-concurrent-executions-with-the-same-payload",
            "title": "Handling concurrent executions with the same payload",
            "text": "<p>This utility will throw an <code>IdempotencyAlreadyInProgressError</code> error if you receive multiple invocations with the same payload while the first invocation hasn't completed yet.</p> Info <p>If you receive <code>IdempotencyAlreadyInProgressError</code>, you can safely retry the operation.</p> <p>This is a locking mechanism for correctness. Since we don't know the result from the first invocation yet, we can't safely allow another concurrent execution.</p>"
        },
        {
            "location": "utilities/idempotency/#using-in-memory-cache",
            "title": "Using in-memory cache",
            "text": "<p>By default, in-memory local caching is disabled, since we don't know how much memory you consume per invocation compared to the maximum configured in your Lambda function.</p> Note: This in-memory cache is local to each Lambda execution environment <p>This means it will be effective in cases where your function's concurrency is low in comparison to the number of \"retry\" invocations with the same payload, because cache might be empty.</p> <p>You can enable in-memory caching with the <code>useLocalCache</code> parameter:</p> Caching idempotent transactions in-memory to prevent multiple calls to storage <pre><code>import { IdempotencyConfig } from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport { makeHandlerIdempotent } from '@aws-lambda-powertools/idempotency/middleware';\nimport middy from '@middy/core';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\nconst config = new IdempotencyConfig({\n  useLocalCache: true,\n  maxLocalCacheSize: 512,\n});\n\nexport const handler = middy(\n  async (_event: Request, _context: Context): Promise&lt;Response&gt; =&gt; {\n    try {\n      // ... create payment\n\n      return {\n        paymentId: '1234567890',\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  }\n).use(\n  makeHandlerIdempotent({\n    persistenceStore,\n    config,\n  })\n);\n</code></pre> <p>When enabled, the default is to cache a maximum of 256 records in each Lambda execution environment - You can change it with the <code>maxLocalCacheSize</code> parameter.</p>"
        },
        {
            "location": "utilities/idempotency/#expiring-idempotency-records",
            "title": "Expiring idempotency records",
            "text": "<p>By default, we expire idempotency records after an hour (3600 seconds).</p> <p>In most cases, it is not desirable to store the idempotency records forever. Rather, you want to guarantee that the same payload won't be executed within a period of time.</p> <p>You can change this window with the <code>expiresAfterSeconds</code> parameter:</p> Adjusting idempotency record expiration <pre><code>import {\n  IdempotencyConfig,\n  makeIdempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\n\nconst config = new IdempotencyConfig({\n  expiresAfterSeconds: 300,\n});\n\nexport const handler = makeIdempotent(\n  async (_event: Request, _context: Context): Promise&lt;Response&gt; =&gt; {\n    try {\n      // ... create payment\n\n      return {\n        paymentId: '12345',\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  },\n  {\n    persistenceStore,\n    config,\n  }\n);\n</code></pre> <p>This will mark any records older than 5 minutes as expired, and your function will be executed as normal if it is invoked with a matching payload.</p> Idempotency record expiration vs DynamoDB time-to-live (TTL) <p>DynamoDB TTL is a feature to remove items after a certain period of time, it may occur within 48 hours of expiration.</p> <p>We don't rely on DynamoDB or any persistence storage layer to determine whether a record is expired to avoid eventual inconsistency states.</p> <p>Instead, Idempotency records saved in the storage layer contain timestamps that can be verified upon retrieval and double checked within Idempotency feature.</p> <p>Why?</p> <p>A record might still be valid (<code>COMPLETE</code>) when we retrieved, but in some rare cases it might expire a second later. A record could also be cached in memory. You might also want to have idempotent transactions that should expire in seconds.</p>"
        },
        {
            "location": "utilities/idempotency/#payload-validation",
            "title": "Payload validation",
            "text": "Question: What if your function is invoked with the same payload except some outer parameters have changed? <p>Example: A payment transaction for a given productID was requested twice for the same customer, however the amount to be paid has changed in the second transaction.</p> <p>By default, we will return the same result as it returned before, however in this instance it may be misleading; we provide a fail fast payload validation to address this edge case.</p> <p>With <code>payloadValidationJmesPath</code>, you can provide an additional JMESPath expression to specify which part of the event body should be validated against previous idempotent invocations</p> Payload validation <pre><code>import { randomUUID } from 'node:crypto';\nimport {\n  IdempotencyConfig,\n  makeIdempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response, SubscriptionResult } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\nconst config = new IdempotencyConfig({\n  eventKeyJmesPath: '[\"userId\", \"productId\"]',\n  payloadValidationJmesPath: 'amount',\n});\n\nconst fetchProductAmount = async (_transactionId: string): Promise&lt;number&gt; =&gt; {\n  // ... fetch product amount\n  return 42;\n};\n\nconst createSubscriptionPayment = makeIdempotent(\n  async (event: Request &amp; { amount: number }): Promise&lt;SubscriptionResult&gt; =&gt; {\n    // ... create payment\n    return {\n      id: randomUUID(),\n      productId: event.productId,\n    };\n  },\n  {\n    persistenceStore,\n    dataIndexArgument: 1,\n    config,\n  }\n);\n\nexport const handler = async (\n  event: Request,\n  context: Context\n): Promise&lt;Response&gt; =&gt; {\n  config.registerLambdaContext(context);\n  try {\n    const productAmount = await fetchProductAmount(event.productId);\n    const payment = await createSubscriptionPayment({\n      ...event,\n      amount: productAmount,\n    });\n\n    return {\n      paymentId: payment.id,\n      message: 'success',\n      statusCode: 200,\n    };\n  } catch (error) {\n    throw new Error('Error creating payment');\n  }\n};\n</code></pre> <p>In this example, the <code>userId</code> and <code>productId</code> keys are used as the payload to generate the idempotency key, as per <code>eventKeyJmespath</code> parameter.</p> Note <p>If we try to send the same request but with a different amount, we will raise <code>IdempotencyValidationError</code>.</p> <p>Without payload validation, we would have returned the same result as we did for the initial request. Since we're also returning an amount in the response, this could be quite confusing for the client.</p> <p>By using <code>payloadValidationJmesPath=\"amount\"</code>, we prevent this potentially confusing behavior and instead throw an error.</p>"
        },
        {
            "location": "utilities/idempotency/#custom-jmespath-functions",
            "title": "Custom JMESPath Functions",
            "text": "<p>You can provide custom JMESPath functions for evaluating JMESPath expressions by passing them through the <code>jmesPathOptions</code> parameter. In this example, we use a custom function, <code>my_fancy_function</code>, to parse the payload as a JSON object instead of a string.</p> Custom JMESPath functions <pre><code>import type { JSONValue } from '@aws-lambda-powertools/commons/types';\nimport {\n  IdempotencyConfig,\n  makeIdempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport {\n  Functions,\n  PowertoolsFunctions,\n} from '@aws-lambda-powertools/jmespath/functions';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\n\nclass MyFancyFunctions extends PowertoolsFunctions {\n  @Functions.signature({\n    argumentsSpecs: [['string']],\n  })\n  public funcMyFancyFunction(value: string): JSONValue {\n    return JSON.parse(value);\n  }\n}\n\nexport const handler = makeIdempotent(async () =&gt; true, {\n  persistenceStore,\n  config: new IdempotencyConfig({\n    eventKeyJmesPath: 'my_fancy_function(body).[\"user\", \"productId\"]',\n    jmesPathOptions: new MyFancyFunctions(),\n  }),\n});\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#making-idempotency-key-required",
            "title": "Making idempotency key required",
            "text": "<p>If you want to enforce that an idempotency key is required, you can set <code>throwOnNoIdempotencyKey</code> to <code>true</code>.</p> <p>This means that we will raise <code>IdempotencyKeyError</code> if the evaluation of <code>eventKeyJmesPath</code> results in an empty subset.</p> Warning <p>To prevent errors, transactions will not be treated as idempotent if <code>throwOnNoIdempotencyKey</code> is set to <code>false</code> and the evaluation of <code>eventKeyJmesPath</code> is an empty result. Therefore, no data will be fetched, stored, or deleted in the idempotency storage layer.</p> Idempotency key requiredSuccess EventFailure Event <pre><code>import {\n  IdempotencyConfig,\n  makeIdempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\n\nconst config = new IdempotencyConfig({\n  throwOnNoIdempotencyKey: true,\n  eventKeyJmesPath: '[\"user.uid\", \"productId\"]',\n});\n\nexport const handler = makeIdempotent(\n  async (_event: Request, _context: Context): Promise&lt;Response&gt; =&gt; {\n    try {\n      // ... create payment\n\n      return {\n        paymentId: '12345',\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  },\n  {\n    persistenceStore,\n    config,\n  }\n);\n</code></pre> <pre><code>{\n  \"user\": {\n    \"uid\": \"BB0D045C-8878-40C8-889E-38B3CB0A61B1\",\n    \"name\": \"Foo\"\n  },\n  \"productId\": 10000\n}\n</code></pre> <pre><code>{\n  \"user\": {\n    \"uid\": \"BB0D045C-8878-40C8-889E-38B3CB0A61B1\",\n    \"name\": \"foo\",\n    \"productId\": 10000\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#customizing-the-idempotency-key-prefix",
            "title": "Customizing the idempotency key prefix",
            "text": "<p>Warning</p> <p>Changing the idempotency key generation will invalidate existing idempotency records</p> <p>You can use the <code>keyPrefix</code> parameter in any of the idempotency configurations to define a custom prefix for your idempotency key. This allows you to decouple the idempotency key from the function name, which is especially useful during application refactorings.</p> Using a custom prefix with function wrapperUsing a custom prefix with decoratorUsing a custom prefix with Middy.js middleware <pre><code>import { randomUUID } from 'node:crypto';\nimport { makeIdempotent } from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\n\nexport const handler = makeIdempotent(\n  async () =&gt; {\n    try {\n      // ... create payment\n\n      return {\n        paymentId: randomUUID(),\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  },\n  {\n    persistenceStore,\n    keyPrefix: 'createSubscriptionPayment',\n  }\n);\n</code></pre> <pre><code>import { randomUUID } from 'node:crypto';\nimport { idempotent } from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\n\nclass Lambda {\n  @idempotent({\n    persistenceStore,\n    keyPrefix: 'createSubscriptionPayment',\n  })\n  async handler(event: unknown, context: Context) {\n    try {\n      // ... create payment\n\n      return {\n        paymentId: randomUUID(),\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  }\n}\n\nconst lambda = new Lambda();\nexport const handler = lambda.handler.bind(lambda);\n</code></pre> <pre><code>import { randomUUID } from 'node:crypto';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport { makeHandlerIdempotent } from '@aws-lambda-powertools/idempotency/middleware';\nimport middy from '@middy/core';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\n\nexport const handler = middy()\n  .use(\n    makeHandlerIdempotent({\n      persistenceStore,\n      keyPrefix: 'createSubscriptionPayment',\n    })\n  )\n  .handler(async () =&gt; {\n    try {\n      // ... create payment\n\n      return {\n        paymentId: randomUUID(),\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  });\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#batch-integration",
            "title": "Batch integration",
            "text": "<p>You can easily integrate with Batch utility by using idempotency wrapper around your processing function. This ensures that you process each record in an idempotent manner, and guard against a Lambda timeout idempotent situation.</p> Choosing a unique batch record attribute <p>In this example, we choose <code>messageId</code> as our idempotency key since we know it'll be unique. Depending on your use case, it might be more accurate to choose another field your producer intentionally set to define uniqueness.</p> Integration with batch processorSample event <pre><code>import {\n  BatchProcessor,\n  EventType,\n  processPartialResponse,\n} from '@aws-lambda-powertools/batch';\nimport {\n  IdempotencyConfig,\n  makeIdempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type {\n  Context,\n  SQSBatchResponse,\n  SQSEvent,\n  SQSRecord,\n} from 'aws-lambda';\n\nconst processor = new BatchProcessor(EventType.SQS);\n\nconst dynamoDBPersistence = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTable',\n});\nconst idempotencyConfig = new IdempotencyConfig({\n  eventKeyJmesPath: 'messageId',\n});\n\nconst processIdempotently = makeIdempotent(\n  async (_record: SQSRecord) =&gt; {\n    // process your event\n  },\n  {\n    persistenceStore: dynamoDBPersistence,\n    config: idempotencyConfig,\n  }\n);\n\nexport const handler = async (\n  event: SQSEvent,\n  context: Context\n): Promise&lt;SQSBatchResponse&gt; =&gt; {\n  idempotencyConfig.registerLambdaContext(context);\n\n  return processPartialResponse(event, processIdempotently, processor, {\n    context,\n  });\n};\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n      \"body\": \"Test message.\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082649183\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n      },\n      \"messageAttributes\": {\n        \"testAttr\": {\n          \"stringValue\": \"100\",\n          \"binaryValue\": \"base64Str\",\n          \"dataType\": \"Number\"\n        }\n      },\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:my-queue\",\n      \"awsRegion\": \"us-east-2\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#customizing-aws-sdk-configuration",
            "title": "Customizing AWS SDK configuration",
            "text": "<p>The <code>clientConfig</code> and <code>awsSdkV3Client</code> parameters enable you to pass in custom configurations or your own DynamoDBClient when constructing the persistence store.</p> Passing specific configurationPassing custom DynamoDBClient <pre><code>import { makeIdempotent } from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n  clientConfig: {\n    region: 'us-east-1',\n  },\n});\n\nexport const handler = makeIdempotent(\n  async (_event: Request, _context: Context): Promise&lt;Response&gt; =&gt; {\n    try {\n      // ... create payment\n\n      return {\n        paymentId: '12345',\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  },\n  {\n    persistenceStore,\n  }\n);\n</code></pre> <pre><code>import { makeIdempotent } from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport { DynamoDBClient } from '@aws-sdk/client-dynamodb';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response } from './types.js';\n\nconst customDynamoDBClient = new DynamoDBClient({\n  endpoint: 'http://localhost:8000',\n});\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n  awsSdkV3Client: customDynamoDBClient,\n});\n\nexport const handler = makeIdempotent(\n  async (_event: Request, _context: Context): Promise&lt;Response&gt; =&gt; {\n    try {\n      // ... create payment\n\n      return {\n        paymentId: '12345',\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  },\n  {\n    persistenceStore,\n  }\n);\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#using-a-dynamodb-table-with-a-composite-primary-key",
            "title": "Using a DynamoDB table with a composite primary key",
            "text": "<p>When using a composite primary key table (hash+range key), use <code>sortKeyAttr</code> parameter when initializing your persistence layer.</p> <p>With this setting, we will save the idempotency key in the sort key instead of the primary key. By default, the primary key will now be set to <code>idempotency#{LAMBDA_FUNCTION_NAME}</code>.</p> <p>You can optionally set a static value for the partition key using the <code>staticPkValue</code> parameter.</p> Reusing a DynamoDB table that uses a composite primary key <pre><code>import { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport { makeHandlerIdempotent } from '@aws-lambda-powertools/idempotency/middleware';\nimport middy from '@middy/core';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n  sortKeyAttr: 'sort_key',\n});\n\nexport const handler = middy(\n  async (_event: Request, _context: Context): Promise&lt;Response&gt; =&gt; {\n    try {\n      // ... create payment\n\n      return {\n        paymentId: '12345',\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  }\n).use(\n  makeHandlerIdempotent({\n    persistenceStore,\n  })\n);\n</code></pre> <p>The example function above would cause data to be stored in DynamoDB like this:</p> id sort_key expiration status data idempotency#MyLambdaFunction 1e956ef7da78d0cb890be999aecc0c9e 1636549553 COMPLETED {\"paymentId\": \"12345, \"message\": \"success\", \"statusCode\": 200} idempotency#MyLambdaFunction 2b2cdb5f86361e97b4383087c1ffdf27 1636549571 COMPLETED {\"paymentId\": \"527212\", \"message\": \"success\", \"statusCode\": 200} idempotency#MyLambdaFunction f091d2527ad1c78f05d54cc3f363be80 1636549585 IN_PROGRESS"
        },
        {
            "location": "utilities/idempotency/#bring-your-own-persistent-store",
            "title": "Bring your own persistent store",
            "text": "<p>This utility provides an abstract base class (ABC), so that you can implement your choice of persistent storage layer.</p> <p>You can create your own persistent store from scratch by inheriting the <code>BasePersistenceLayer</code> class, and implementing <code>_getRecord()</code>, <code>_putRecord()</code>, <code>_updateRecord()</code> and <code>_deleteRecord()</code>.</p> <ul> <li><code>_getRecord()</code> – Retrieves an item from the persistence store using an idempotency key and returns it as a <code>IdempotencyRecord</code> instance.</li> <li><code>_putRecord()</code> – Adds a <code>IdempotencyRecord</code> to the persistence store if it doesn't already exist with that key. Throws an <code>IdempotencyItemAlreadyExistsError</code> error if a non-expired entry already exists.</li> <li><code>_updateRecord()</code> – Updates an item in the persistence store.</li> <li><code>_deleteRecord()</code> – Removes an item from the persistence store.</li> </ul> <p>Below an example implementation of a custom persistence layer backed by a generic key-value store.</p> CustomPersistenceLayerindex.tstypes.ts <pre><code>import {\n  IdempotencyItemAlreadyExistsError,\n  IdempotencyItemNotFoundError,\n  IdempotencyRecordStatus,\n} from '@aws-lambda-powertools/idempotency';\nimport {\n  BasePersistenceLayer,\n  IdempotencyRecord,\n} from '@aws-lambda-powertools/idempotency/persistence';\nimport type { IdempotencyRecordOptions } from '@aws-lambda-powertools/idempotency/types';\nimport { Transform } from '@aws-lambda-powertools/parameters';\nimport { getSecret } from '@aws-lambda-powertools/parameters/secrets';\nimport {\n  ProviderClient,\n  ProviderItemAlreadyExists,\n} from './advancedBringYourOwnPersistenceLayerProvider';\nimport type { ApiSecret, ProviderItem } from './types';\n\nclass CustomPersistenceLayer extends BasePersistenceLayer {\n  #collectionName: string;\n  #client?: ProviderClient;\n\n  public constructor(config: { collectionName: string }) {\n    super();\n    this.#collectionName = config.collectionName;\n  }\n\n  protected async _deleteRecord(record: IdempotencyRecord): Promise&lt;void&gt; {\n    await (await this.#getClient()).delete(\n      this.#collectionName,\n      record.idempotencyKey\n    );\n  }\n\n  protected async _getRecord(\n    idempotencyKey: string\n  ): Promise&lt;IdempotencyRecord&gt; {\n    try {\n      const item = await (await this.#getClient()).get(\n        this.#collectionName,\n        idempotencyKey\n      );\n\n      return new IdempotencyRecord({\n        ...(item as unknown as IdempotencyRecordOptions),\n      });\n    } catch (error) {\n      throw new IdempotencyItemNotFoundError();\n    }\n  }\n\n  protected async _putRecord(record: IdempotencyRecord): Promise&lt;void&gt; {\n    const item: Partial&lt;ProviderItem&gt; = {\n      status: record.getStatus(),\n    };\n\n    if (record.inProgressExpiryTimestamp !== undefined) {\n      item.in_progress_expiration = record.inProgressExpiryTimestamp;\n    }\n\n    if (this.isPayloadValidationEnabled() &amp;&amp; record.payloadHash !== undefined) {\n      item.validation = record.payloadHash;\n    }\n\n    const ttl = record.expiryTimestamp\n      ? Math.floor(new Date(record.expiryTimestamp * 1000).getTime() / 1000) -\n        Math.floor(new Date().getTime() / 1000)\n      : this.getExpiresAfterSeconds();\n\n    let existingItem: ProviderItem | undefined;\n    try {\n      existingItem = await (await this.#getClient()).put(\n        this.#collectionName,\n        record.idempotencyKey,\n        item,\n        {\n          ttl,\n        }\n      );\n    } catch (error) {\n      if (error instanceof ProviderItemAlreadyExists) {\n        if (\n          existingItem &amp;&amp;\n          existingItem.status !== IdempotencyRecordStatus.INPROGRESS &amp;&amp;\n          (existingItem.in_progress_expiration || 0) &lt; Date.now()\n        ) {\n          throw new IdempotencyItemAlreadyExistsError(\n            `Failed to put record for already existing idempotency key: ${record.idempotencyKey}`\n          );\n        }\n      }\n    }\n  }\n\n  protected async _updateRecord(record: IdempotencyRecord): Promise&lt;void&gt; {\n    const value: Partial&lt;ProviderItem&gt; = {\n      data: JSON.stringify(record.responseData),\n      status: record.getStatus(),\n    };\n\n    if (this.isPayloadValidationEnabled()) {\n      value.validation = record.payloadHash;\n    }\n\n    await (await this.#getClient()).update(\n      this.#collectionName,\n      record.idempotencyKey,\n      value\n    );\n  }\n\n  async #getClient(): Promise&lt;ProviderClient&gt; {\n    if (this.#client) return this.#client;\n\n    const secretName = process.env.API_SECRET;\n    if (!secretName) {\n      throw new Error('API_SECRET environment variable is not set');\n    }\n\n    const apiSecret = await getSecret&lt;ApiSecret&gt;(secretName, {\n      transform: Transform.JSON,\n    });\n\n    if (!apiSecret) {\n      throw new Error(`Could not retrieve secret ${secretName}`);\n    }\n\n    this.#client = new ProviderClient({\n      apiKey: apiSecret.apiKey,\n      defaultTtlSeconds: this.getExpiresAfterSeconds(),\n    });\n\n    return this.#client;\n  }\n}\n\nexport { CustomPersistenceLayer };\n</code></pre> <pre><code>import { randomUUID } from 'node:crypto';\nimport {\n  IdempotencyConfig,\n  makeIdempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport type { Context } from 'aws-lambda';\nimport { CustomPersistenceLayer } from './advancedBringYourOwnPersistenceLayer';\nimport type { Request, Response, SubscriptionResult } from './types.js';\n\nconst persistenceStore = new CustomPersistenceLayer({\n  collectionName: 'powertools',\n});\nconst config = new IdempotencyConfig({\n  expiresAfterSeconds: 60,\n});\n\nconst createSubscriptionPayment = makeIdempotent(\n  async (\n    _transactionId: string,\n    event: Request\n  ): Promise&lt;SubscriptionResult&gt; =&gt; {\n    // ... create payment\n    return {\n      id: randomUUID(),\n      productId: event.productId,\n    };\n  },\n  {\n    persistenceStore,\n    dataIndexArgument: 1,\n    config,\n  }\n);\n\nexport const handler = async (\n  event: Request,\n  context: Context\n): Promise&lt;Response&gt; =&gt; {\n  config.registerLambdaContext(context);\n\n  try {\n    const transactionId = randomUUID();\n    const payment = await createSubscriptionPayment(transactionId, event);\n\n    return {\n      paymentId: payment.id,\n      message: 'success',\n      statusCode: 200,\n    };\n  } catch (error) {\n    throw new Error('Error creating payment');\n  }\n};\n</code></pre> <pre><code>import type { IdempotencyRecordStatusValue } from '@aws-lambda-powertools/idempotency/types';\n\nexport type Request = {\n  user: string;\n  productId: string;\n};\n\nexport type Response = {\n  [key: string]: unknown;\n};\n\nexport type SubscriptionResult = {\n  id: string;\n  productId: string;\n};\n\nexport type ApiSecret = {\n  apiKey: string;\n  refreshToken: string;\n  validUntil: number;\n  restEndpoint: string;\n};\n\nexport type ProviderItem = {\n  validation?: string;\n  in_progress_expiration?: number;\n  status: IdempotencyRecordStatusValue;\n  data: string;\n};\n</code></pre> Danger <p>Pay attention to the documentation for each - you may need to perform additional checks inside these methods to ensure the idempotency guarantees remain intact.</p> <p>For example, the <code>_putRecord()</code> method needs to throw an error if a non-expired record already exists in the data store with a matching key.</p>"
        },
        {
            "location": "utilities/idempotency/#manipulating-the-idempotent-response",
            "title": "Manipulating the Idempotent Response",
            "text": "<p>You can set up a <code>responseHook</code> in the <code>IdempotentConfig</code> class to manipulate the returned data when an operation is idempotent. The hook function will be called with the current deserialized response object and the Idempotency record.</p> Using an Idempotent Response HookSample eventSample Idempotent response <pre><code>import { randomUUID } from 'node:crypto';\nimport type { JSONValue } from '@aws-lambda-powertools/commons/types';\nimport {\n  IdempotencyConfig,\n  makeIdempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { IdempotencyRecord } from '@aws-lambda-powertools/idempotency/persistence';\nimport type { Context } from 'aws-lambda';\nimport type { Request, Response, SubscriptionResult } from './types.js';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'idempotencyTableName',\n});\n\nconst responseHook = (response: JSONValue, record: IdempotencyRecord) =&gt; {\n  // Return inserted Header data into the Idempotent Response\n  (response as Response).headers = {\n    'x-idempotency-key': record.idempotencyKey,\n  };\n\n  // Must return the response here\n  return response as JSONValue;\n};\n\nconst config = new IdempotencyConfig({\n  responseHook,\n});\n\nconst createSubscriptionPayment = async (\n  event: Request\n): Promise&lt;SubscriptionResult&gt; =&gt; {\n  // ... create payment\n  return {\n    id: randomUUID(),\n    productId: event.productId,\n  };\n};\n\nexport const handler = makeIdempotent(\n  async (event: Request, _context: Context): Promise&lt;Response&gt; =&gt; {\n    try {\n      const payment = await createSubscriptionPayment(event);\n\n      return {\n        paymentId: payment.id,\n        message: 'success',\n        statusCode: 200,\n      };\n    } catch (error) {\n      throw new Error('Error creating payment');\n    }\n  },\n  {\n    persistenceStore,\n    config,\n  }\n);\n</code></pre> <pre><code>{\n    \"user\": \"John Doe\",\n    \"productId\": \"123456\"\n}\n</code></pre> <pre><code>{\n    \"message\": \"success\",\n    \"paymentId\": \"31a964eb-7477-4fe1-99fe-7f8a6a351a7e\",\n    \"statusCode\": 200,\n    \"headers\": {\n      \"x-idempotency-key\": \"function-name#mHfGv2vJ8h+ZvLIr/qGBbQ==\"\n    }\n  }\n</code></pre> Info: Using custom de-serialization? <p>The responseHook is called after the custom de-serialization so the payload you process will be the de-serialized version.</p>"
        },
        {
            "location": "utilities/idempotency/#being-a-good-citizen",
            "title": "Being a good citizen",
            "text": "<p>When using response hooks to manipulate returned data from idempotent operations, it's important to follow best practices to avoid introducing complexity or issues. Keep these guidelines in mind:</p> <ol> <li> <p>Response hook works exclusively when operations are idempotent. The hook will not be called when an operation is not idempotent, or when the idempotent logic fails.</p> </li> <li> <p>Catch and Handle Exceptions. Your response hook code should catch and handle any exceptions that may arise from your logic. Unhandled exceptions will cause the Lambda function to fail unexpectedly.</p> </li> <li> <p>Keep Hook Logic Simple Response hooks should consist of minimal and straightforward logic for manipulating response data. Avoid complex conditional branching and aim for hooks that are easy to reason about.</p> </li> </ol>"
        },
        {
            "location": "utilities/idempotency/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>The idempotency utility provides several routes to test your code.</p>"
        },
        {
            "location": "utilities/idempotency/#disabling-the-idempotency-utility",
            "title": "Disabling the idempotency utility",
            "text": "<p>When testing your code, you may wish to disable the idempotency logic altogether and focus on testing your business logic. To do this, you can set the environment variable <code>POWERTOOLS_IDEMPOTENCY_DISABLED</code> with a truthy value.</p>"
        },
        {
            "location": "utilities/idempotency/#testing-with-local-dynamodb",
            "title": "Testing with local DynamoDB",
            "text": "<p>When testing your Lambda function locally, you can use a local DynamoDB instance to test the idempotency feature. You can use DynamoDB Local or LocalStack.</p> handler.test.tshandler.ts <pre><code>import { makeIdempotent } from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\nimport { describe, expect, it } from 'vitest';\nimport { handler } from './workingWithLocalDynamoDB.js';\n\nconst context = {\n  functionName: 'foo-bar-function',\n  memoryLimitInMB: '128',\n  invokedFunctionArn:\n    'arn:aws:lambda:eu-west-1:123456789012:function:foo-bar-function',\n  awsRequestId: 'c6af9ac6-7b61-11e6-9a41-93e812345678',\n  getRemainingTimeInMillis: () =&gt; 1234,\n} as Context;\n\nconst mockPersistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'IdempotencyTable',\n  clientConfig: { endpoint: 'http://localhost:8000' }, // 8000 for local DynamoDB and 4566 for LocalStack\n});\n\ndescribe('Idempotent handler', () =&gt; {\n  it('returns the same response', async () =&gt; {\n    // Prepare\n    const idempotentHandler = makeIdempotent(handler, {\n      persistenceStore: mockPersistenceStore,\n    });\n\n    // Act\n    const response = await idempotentHandler(\n      {\n        foo: 'bar',\n      },\n      context\n    );\n\n    // Assess\n    expect(response).toEqual({\n      statusCode: 200,\n      body: JSON.stringify({\n        paymentId: '123',\n        message: 'Payment created',\n      }),\n    });\n  });\n});\n</code></pre> <pre><code>import { makeIdempotent } from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { Context } from 'aws-lambda';\n\nconst ddbPersistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'IdempotencyTable',\n});\n\nconst handler = async (event: unknown, context: Context) =&gt; {\n  return {\n    statusCode: 200,\n    body: JSON.stringify({\n      paymentId: '123',\n      message: 'Payment created',\n    }),\n  };\n};\n\nconst idempotentHandler = makeIdempotent(handler, {\n  persistenceStore: ddbPersistenceStore,\n});\n\nexport { idempotentHandler, handler };\n</code></pre>"
        },
        {
            "location": "utilities/idempotency/#extra-resources",
            "title": "Extra resources",
            "text": "<p>If you're interested in a deep dive on how Amazon uses idempotency when building our APIs, check out this article.</p>"
        },
        {
            "location": "utilities/jmespath/",
            "title": "JMESPath Functions",
            "text": "<p>Built-in JMESPath functions to easily deserialize common encoded JSON payloads in Lambda functions.</p>"
        },
        {
            "location": "utilities/jmespath/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Deserialize JSON from JSON strings, base64, and compressed data</li> <li>Use JMESPath to extract and combine data recursively</li> <li>Provides commonly used JMESPath expressions with popular event sources</li> </ul>"
        },
        {
            "location": "utilities/jmespath/#getting-started",
            "title": "Getting started",
            "text": ""
        },
        {
            "location": "utilities/jmespath/#installation",
            "title": "Installation",
            "text": "<p>Install the utility in your project:</p> <pre><code>npm install @aws-lambda-powertools/jmespath\n</code></pre> <p>You might have events that contain encoded JSON payloads as string, base64, or even in compressed format. It is a common use case to decode and extract them partially or fully as part of your Lambda function invocation.</p> <p>Powertools for AWS Lambda (TypeScript) also have utilities like idempotency where you might need to extract a portion of your data before using them.</p> Terminology <p>Envelope is the terminology we use for the JMESPath expression to extract your JSON object from your data input. We might use those two terms interchangeably.</p>"
        },
        {
            "location": "utilities/jmespath/#extracting-data",
            "title": "Extracting data",
            "text": "<p>You can use the <code>extractDataFromEnvelope</code> function with any JMESPath expression.</p> Tip <p>Another common use case is to fetch deeply nested data, filter, flatten, and more.</p> extractDataFromBuiltinEnvelope.tsextractDataFromEnvelope.json <pre><code>import { extractDataFromEnvelope } from '@aws-lambda-powertools/jmespath/envelopes';\n\ntype MyEvent = {\n  body: string; // \"{\\\"customerId\\\":\\\"dd4649e6-2484-4993-acb8-0f9123103394\\\"}\"\n  deeplyNested: Array&lt;{ someData: number[] }&gt;;\n};\n\ntype MessageBody = {\n  customerId: string;\n};\n\nexport const handler = async (event: MyEvent): Promise&lt;unknown&gt; =&gt; {\n  const payload = extractDataFromEnvelope&lt;MessageBody&gt;(\n    event,\n    'powertools_json(body)'\n  );\n  const { customerId } = payload; // now deserialized\n\n  // also works for fetching and flattening deeply nested data\n  const someData = extractDataFromEnvelope&lt;number[]&gt;(\n    event,\n    'deeplyNested[*].someData[]'\n  );\n\n  return {\n    customerId,\n    message: 'success',\n    context: someData,\n    statusCode: 200,\n  };\n};\n</code></pre> <pre><code>{\n  \"body\": \"{\\\"customerId\\\":\\\"dd4649e6-2484-4993-acb8-0f9123103394\\\"}\",\n  \"deeplyNested\": [\n    {\n      \"someData\": [1, 2, 3]\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/jmespath/#built-in-envelopes",
            "title": "Built-in envelopes",
            "text": "<p>We provide built-in envelopes for popular AWS Lambda event sources to easily decode and/or deserialize JSON objects.</p> extractDataFromBuiltinEnvelope.tsextractDataFromBuiltinEnvelope.json <pre><code>import {\n  SQS,\n  extractDataFromEnvelope,\n} from '@aws-lambda-powertools/jmespath/envelopes';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport type { SQSEvent } from 'aws-lambda';\n\nconst logger = new Logger();\n\ntype MessageBody = {\n  customerId: string;\n};\n\nexport const handler = async (event: SQSEvent): Promise&lt;void&gt; =&gt; {\n  const records = extractDataFromEnvelope&lt;Array&lt;MessageBody&gt;&gt;(event, SQS);\n  for (const record of records) {\n    // records is now a list containing the deserialized body of each message\n    const { customerId } = record;\n    logger.appendKeys({ customerId });\n  }\n};\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"messageId\": \"19dd0b57-b21e-4ac1-bd88-01bbb068cb78\",\n      \"receiptHandle\": \"MessageReceiptHandle\",\n      \"body\": \"{\\\"customerId\\\":\\\"dd4649e6-2484-4993-acb8-0f9123103394\\\",\\\"booking\\\":{\\\"id\\\":\\\"5b2c4803-330b-42b7-811a-c68689425de1\\\",\\\"reference\\\":\\\"ySz7oA\\\",\\\"outboundFlightId\\\":\\\"20c0d2f2-56a3-4068-bf20-ff7703db552d\\\"},\\\"payment\\\":{\\\"receipt\\\":\\\"https://pay.stripe.com/receipts/acct_1Dvn7pF4aIiftV70/ch_3JTC14F4aIiftV700iFq2CHB/rcpt_K7QsrFln9FgFnzUuBIiNdkkRYGxUL0X\\\",\\\"amount\\\":100}}\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1523232000000\",\n        \"SenderId\": \"123456789012\",\n        \"ApproximateFirstReceiveTimestamp\": \"1523232000001\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"7b270e59b47ff90a553787216d55d91d\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-1:123456789012:MyQueue\",\n      \"awsRegion\": \"us-east-1\"\n    }\n  ]\n}\n</code></pre> <p>These are all built-in envelopes you can use along with their expression as a reference:</p> Envelope JMESPath expression <code>API_GATEWAY_HTTP</code> <code>powertools_json(body)</code> <code>API_GATEWAY_REST</code> <code>powertools_json(body)</code> <code>CLOUDWATCH_EVENTS_SCHEDULED</code> <code>detail</code> <code>CLOUDWATCH_LOGS</code> <code>awslogs.powertools_base64_gzip(data)                                                     | powertools_json(@).logEvents[*]</code> <code>EVENTBRIDGE</code> <code>detail</code> <code>KINESIS_DATA_STREAM</code> <code>Records[*].kinesis.powertools_json(powertools_base64(data))</code> <code>S3_EVENTBRIDGE_SQS</code> <code>Records[*].powertools_json(body).detail</code> <code>S3_KINESIS_FIREHOSE</code> <code>records[*].powertools_json(powertools_base64(data)).Records[0]</code> <code>S3_SNS_KINESIS_FIREHOSE</code> <code>records[*].powertools_json(powertools_base64(data)).powertools_json(Message).Records[0]</code> <code>S3_SNS_SQS</code> <code>Records[*].powertools_json(body).powertools_json(Message).Records[0]</code> <code>S3_SQS</code> <code>Records[*].powertools_json(body).Records[0]</code> <code>SNS</code> <code>Records[0].Sns.Message                                                                   | powertools_json(@)</code> <code>SQS</code> <code>Records[*].powertools_json(body)</code> Using SNS? <p>If you don't require SNS metadata, enable raw message delivery. It will reduce multiple payload layers and size, when using SNS in combination with other services (e.g., SQS, S3, etc).</p>"
        },
        {
            "location": "utilities/jmespath/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/jmespath/#built-in-jmespath-functions",
            "title": "Built-in JMESPath functions",
            "text": "<p>You can use our built-in JMESPath functions within your envelope expression. They handle deserialization for common data formats found in AWS Lambda event sources such as JSON strings, base64, and uncompress gzip data.</p>"
        },
        {
            "location": "utilities/jmespath/#powertools_json-function",
            "title": "<code>powertools_json</code> function",
            "text": "<p>Use <code>powertools_json</code> function to decode any JSON string anywhere a JMESPath expression is allowed.</p> <p>Idempotency scenario</p> <p>This sample will deserialize the JSON string within the <code>body</code> key before Idempotency processes it.</p> powertoolsJsonIdempotencyJmespath.tspowertoolsJsonIdempotencyJmespath.json <pre><code>import { randomUUID } from 'node:crypto';\nimport {\n  IdempotencyConfig,\n  makeIdempotent,\n} from '@aws-lambda-powertools/idempotency';\nimport { DynamoDBPersistenceLayer } from '@aws-lambda-powertools/idempotency/dynamodb';\nimport type { APIGatewayEvent } from 'aws-lambda';\n\nconst persistenceStore = new DynamoDBPersistenceLayer({\n  tableName: 'IdempotencyTable',\n});\n\nexport const handler = makeIdempotent(\n  async (event: APIGatewayEvent) =&gt; {\n    const body = JSON.parse(event.body || '{}');\n    const { user, productId } = body;\n\n    const result = await createSubscriptionPayment(user, productId);\n\n    return {\n      statusCode: 200,\n      body: JSON.stringify({\n        paymentId: result.id,\n        message: 'success',\n      }),\n    };\n  },\n  {\n    persistenceStore,\n    config: new IdempotencyConfig({\n      eventKeyJmesPath: 'powertools_json(body)',\n    }),\n  }\n);\n\nconst createSubscriptionPayment = async (\n  user: string,\n  productId: string\n): Promise&lt;{ id: string; message: string }&gt; =&gt; {\n  const payload = { user, productId };\n  const response = await fetch('https://httpbin.org/anything', {\n    method: 'POST',\n    body: JSON.stringify(payload),\n  });\n\n  if (!response.ok) {\n    throw new Error('Failed to create subscription payment');\n  }\n\n  return { id: randomUUID(), message: 'paid' };\n};\n</code></pre> <pre><code>{\n  \"version\": \"2.0\",\n  \"routeKey\": \"ANY /createpayment\",\n  \"rawPath\": \"/createpayment\",\n  \"rawQueryString\": \"\",\n  \"headers\": {\n    \"Header1\": \"value1\",\n    \"Header2\": \"value2\"\n  },\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"apiId\": \"api-id\",\n    \"domainName\": \"id.execute-api.us-east-1.amazonaws.com\",\n    \"domainPrefix\": \"id\",\n    \"http\": {\n      \"method\": \"POST\",\n      \"path\": \"/createpayment\",\n      \"protocol\": \"HTTP/1.1\",\n      \"sourceIp\": \"ip\",\n      \"userAgent\": \"agent\"\n    },\n    \"requestId\": \"id\",\n    \"routeKey\": \"ANY /createpayment\",\n    \"stage\": \"$default\",\n    \"time\": \"10/Feb/2021:13:40:43 +0000\",\n    \"timeEpoch\": 1612964443723\n  },\n  \"body\": \"{\\\"user\\\":\\\"xyz\\\",\\\"product_id\\\":\\\"123456789\\\"}\",\n  \"isBase64Encoded\": false\n}\n</code></pre>"
        },
        {
            "location": "utilities/jmespath/#powertools_base64-function",
            "title": "<code>powertools_base64</code> function",
            "text": "<p>Use <code>powertools_base64</code> function to decode any base64 data.</p> <p>This sample will decode the base64 value within the <code>data</code> key, and deserialize the JSON string before processing.</p> powertoolsBase64Jmespath.tspowertoolsBase64JmespathPayload.json <pre><code>import { extractDataFromEnvelope } from '@aws-lambda-powertools/jmespath/envelopes';\nimport { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger();\n\nexport const handler = async (event: { payload: string }): Promise&lt;void&gt; =&gt; {\n  const data = extractDataFromEnvelope&lt;string&gt;(\n    event,\n    'powertools_json(powertools_base64(payload))'\n  );\n\n  logger.info('Decoded payload', { data }); // (1)!\n};\n</code></pre> <ol> <li>The <code>data</code> variable contains the decoded object that looks like this: <pre><code>{\n    user_id: 123,\n    product_id: 1,\n    quantity: 2,\n    price: 10.4,\n    currency: 'USD',\n}\n</code></pre></li> </ol> <pre><code>{\n  \"payload\": \"eyJ1c2VyX2lkIjogMTIzLCAicHJvZHVjdF9pZCI6IDEsICJxdWFudGl0eSI6IDIsICJwcmljZSI6IDEwLjQwLCAiY3VycmVuY3kiOiAiVVNEIn0=\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/jmespath/#powertools_base64_gzip-function",
            "title": "<code>powertools_base64_gzip</code> function",
            "text": "<p>Use <code>powertools_base64_gzip</code> function to decompress and decode base64 data.</p> <p>This sample will decompress and decode base64 data from Cloudwatch Logs, then use JMESPath pipeline expression to pass the result for decoding its JSON string.</p> powertoolsBase64GzipJmespath.tspowertoolsBase64GzipJmespathPayload.json <pre><code>import { extractDataFromEnvelope } from '@aws-lambda-powertools/jmespath/envelopes';\nimport { Logger } from '@aws-lambda-powertools/logger';\n\nconst logger = new Logger();\n\nexport const handler = async (event: { payload: string }): Promise&lt;void&gt; =&gt; {\n  const logGroup = extractDataFromEnvelope&lt;string&gt;(\n    event, // (1)!\n    'powertools_base64_gzip(payload) | powertools_json(@).logGroup'\n  );\n\n  logger.info('Log group name', { logGroup }); // (2)!\n};\n</code></pre> <ol> <li>The <code>payload</code> key contains a JSON object that once decompressed and decoded looks like this: <pre><code>{\n    \"owner\": \"123456789012\",\n    \"logGroup\": \"/aws/lambda/powertools-example\",\n    \"logStream\": \"2020/09/02/[$LATEST]d3a8dcaffc7f4de2b8db132e3e106660\",\n    \"subscriptionFilters\": [\"Destination\"],\n    \"messageType\": \"DATA_MESSAGE\",\n    \"logEvents\": [\n        {\n            \"id\": \"eventId1\",\n            \"message\": {\n                \"username\": \"lessa\",\n                \"message\": \"hello world\"\n            },\n            \"timestamp\": 1440442987000\n        },\n        {\n            \"id\": \"eventId2\",\n            \"message\": {\n                \"username\": \"dummy\",\n                \"message\": \"hello world\"\n            },\n            \"timestamp\": 1440442987001\n        }\n    ]\n}\n</code></pre></li> <li>The <code>logGroup</code> variable contains the string <code>\"/aws/lambda/powertools-example\"</code>.</li> </ol> <pre><code>{\n  \"payload\": \"H4sIACZAXl8C/52PzUrEMBhFX2UILpX8tPbHXWHqIOiq3Q1F0ubrWEiakqTWofTdTYYB0YWL2d5zvnuTFellBIOedoiyKH5M0iwnlKH7HZL6dDB6ngLDfLFYctUKjie9gHFaS/sAX1xNEq525QxwFXRGGMEkx4Th491rUZdV3YiIZ6Ljfd+lfSyAtZloacQgAkqSJCGhxM6t7cwwuUGPz4N0YKyvO6I9WDeMPMSo8Z4Ca/kJ6vMEYW5f1MX7W1lVxaG8vqX8hNFdjlc0iCBBSF4ERT/3Pl7RbMGMXF2KZMh/C+gDpNS7RRsp0OaRGzx0/t8e0jgmcczyLCWEePhni/23JWalzjdu0a3ZvgEaNLXeugEAAA==\"\n}\n</code></pre>"
        },
        {
            "location": "utilities/jmespath/#bring-your-own-jmespath-function",
            "title": "Bring your own JMESPath function",
            "text": "Warning <p>This should only be used for advanced use cases where you have special formats not covered by the built-in functions.</p> <p>For special binary formats that you want to decode before processing, you can bring your own JMESPath function by extending the <code>PowertoolsFunctions</code> class.</p> <p>Here is an example of how to decompress messages compressed using the Brotli compression algorithm:</p> PowertoolsCustomFunction.tspowertoolsCustomFunction.json <pre><code> import { brotliDecompressSync } from 'node:zlib';\n import { fromBase64 } from '@aws-lambda-powertools/commons/utils/base64';\n import { extractDataFromEnvelope } from '@aws-lambda-powertools/jmespath/envelopes';\n import { PowertoolsFunctions } from '@aws-lambda-powertools/jmespath/functions';\n import { Logger } from '@aws-lambda-powertools/logger';\n\n const logger = new Logger();\n\n class CustomFunctions extends PowertoolsFunctions {\n   @PowertoolsFunctions.signature({ // (1)!\n     argumentsSpecs: [['string']],\n     variadic: false,\n   })\n   public funcDecodeBrotliCompression(value: string): string { // (2)!\n     const encoded = fromBase64(value, 'base64');\n     const uncompressed = brotliDecompressSync(encoded);\n\n     return uncompressed.toString();\n   }\n }\n\n export const handler = async (event: { payload: string }): Promise&lt;void&gt; =&gt; {\n   const message = extractDataFromEnvelope&lt;string&gt;(\n     event,\n     'Records[*].decode_brotli_compression(notification) | [*].powertools_json(@).message',\n     { customFunctions: new CustomFunctions() }\n   );\n\n   logger.info('Decoded message', { message });\n };\n</code></pre> <ol> <li>The function signature can be enforced at runtime by using the <code>@Functions.signature</code> decorator.</li> <li>The name of the function must start with the <code>func</code> prefix.</li> </ol> <pre><code>{\n  \"Records\": [\n    {\n      \"application\": \"app\",\n      \"datetime\": \"2022-01-01T00:00:00.000Z\",\n      \"notification\": \"GyYA+AXhZKk/K5DkanoQSTYpSKMwwxXh8DRWVo9A1hLqAQ==\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/parameters/",
            "title": "Parameters",
            "text": "<p>The Parameters utility provides high-level functions to retrieve one or multiple parameter values from AWS Systems Manager Parameter Store, AWS Secrets Manager, AWS AppConfig, Amazon DynamoDB, or your own parameter store.</p>"
        },
        {
            "location": "utilities/parameters/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Retrieve one or multiple parameters from the underlying provider</li> <li>Cache parameter values for a given amount of time (defaults to 5 seconds)</li> <li>Transform parameter values from JSON or base64 encoded strings</li> <li>Bring Your Own Parameter Store Provider</li> </ul>"
        },
        {
            "location": "utilities/parameters/#getting-started",
            "title": "Getting started",
            "text": "<p>The Parameters Utility helps to retrieve parameters from the System Manager Parameter Store (SSM), secrets from the Secrets Manager, and application configuration from AppConfig. Additionally, the utility also offers support for a DynamoDB provider, enabling the retrieval of arbitrary parameters from specified tables.</p>"
        },
        {
            "location": "utilities/parameters/#installation",
            "title": "Installation",
            "text": "Note <p>This utility supports AWS SDK for JavaScript v3 only. This allows the utility to be modular, and you to install only the SDK packages you need and keep your bundle size small.</p> <p>Depending on the provider you want to use, install the library and the corresponding AWS SDK package:</p> SSMProviderSecretsProviderAppConfigProviderDynamoDBProvider <pre><code>npm install @aws-lambda-powertools/parameters @aws-sdk/client-ssm\n</code></pre> <pre><code>npm install @aws-lambda-powertools/parameters @aws-sdk/client-secrets-manager\n</code></pre> <pre><code>npm install @aws-lambda-powertools/parameters @aws-sdk/client-appconfigdata\n</code></pre> <pre><code>npm install @aws-lambda-powertools/parameters @aws-sdk/client-dynamodb @aws-sdk/util-dynamodb\n</code></pre> Tip <p>If you are using the <code>nodejs18.x</code> runtime or newer, the AWS SDK for JavaScript v3 is already installed and you can install the utility only.</p>"
        },
        {
            "location": "utilities/parameters/#iam-permissions",
            "title": "IAM Permissions",
            "text": "<p>This utility requires additional permissions to work as expected.</p> Note <p>Different parameter providers require different permissions.</p> Provider Function/Method IAM Permission SSM <code>getParameter</code>, <code>SSMProvider.get</code> <code>ssm:GetParameter</code> SSM <code>getParameters</code>, <code>SSMProvider.getMultiple</code> <code>ssm:GetParametersByPath</code> SSM <code>getParametersByName</code>, <code>SSMProvider.getParametersByName</code> <code>ssm:GetParameter</code> and <code>ssm:GetParameters</code> SSM If using <code>decrypt: true</code> You must add an additional permission <code>kms:Decrypt</code> SSM <code>setParameter</code>, <code>SSMProvider.set</code> <code>ssm:PutParameter</code> Secrets <code>getSecret</code>, <code>SecretsProvider.get</code> <code>secretsmanager:GetSecretValue</code> DynamoDB <code>DynamoDBProvider.get</code> <code>dynamodb:GetItem</code> DynamoDB <code>DynamoDBProvider.getMultiple</code> <code>dynamodb:Query</code> AppConfig <code>getAppConfig</code>, <code>AppConfigProvider.getAppConfig</code> <code>appconfig:GetLatestConfiguration</code> and <code>appconfig:StartConfigurationSession</code>"
        },
        {
            "location": "utilities/parameters/#fetching-parameters",
            "title": "Fetching parameters",
            "text": "<p>You can retrieve a single parameter using the <code>getParameter</code> high-level function.</p> Fetching a single parameter from SSM<pre><code>import { getParameter } from '@aws-lambda-powertools/parameters/ssm';\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a single parameter\n  const parameter = await getParameter('/my/parameter');\n  console.log(parameter);\n};\n</code></pre> <p>For multiple parameters, you can use either:</p> <ul> <li><code>getParameters</code> to recursively fetch all parameters by path.</li> <li><code>getParametersByName</code> to fetch distinct parameters by their full name. It also accepts custom caching, transform, decrypt per parameter.</li> </ul> getParametersgetParametersByName Fetching multiple parameters by path from SSM<pre><code>import { getParameters } from '@aws-lambda-powertools/parameters/ssm';\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  /**\n   * Retrieve multiple parameters from a path prefix recursively.\n   * This returns an object with the parameter name as key\n   */\n  const parameters = await getParameters('/my/path/prefix');\n  for (const [key, value] of Object.entries(parameters || {})) {\n    console.log(`${key}: ${value}`);\n  }\n};\n</code></pre> Fetching multiple parameters by names from SSM<pre><code>import { Transform } from '@aws-lambda-powertools/parameters';\nimport { getParametersByName } from '@aws-lambda-powertools/parameters/ssm';\nimport type { SSMGetParametersByNameOptions } from '@aws-lambda-powertools/parameters/ssm/types';\n\nconst props: Record&lt;string, SSMGetParametersByNameOptions&gt; = {\n  '/develop/service/commons/telemetry/config': {\n    maxAge: 300,\n    transform: Transform.JSON,\n  },\n  '/no_cache_param': { maxAge: 0 },\n  '/develop/service/payment/api/capture/url': {}, // When empty or undefined, it uses default values\n};\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // This returns an object with the parameter name as key\n  const parameters = await getParametersByName(props, { maxAge: 60 });\n  for (const [key, value] of Object.entries(parameters)) {\n    console.log(`${key}: ${value}`);\n  }\n};\n</code></pre> <code>getParametersByName</code> supports graceful error handling <p>By default, the provider will throw a <code>GetParameterError</code> when any parameter fails to be fetched. You can override it by setting <code>throwOnError: false</code>.</p> <p>When disabled, instead the provider will take the following actions:</p> <ul> <li>Add failed parameter name in the <code>_errors</code> key, e.g., <code>{ _errors: [ '/param1', '/param2' ] }</code></li> <li>Keep only successful parameter names and their values in the response</li> <li>Throw <code>GetParameterError</code> if any of your parameters is named <code>_errors</code></li> </ul> <pre><code>import { getParametersByName } from '@aws-lambda-powertools/parameters/ssm';\nimport type { SSMGetParametersByNameOptions } from '@aws-lambda-powertools/parameters/ssm/types';\n\nconst props: Record&lt;string, SSMGetParametersByNameOptions&gt; = {\n  '/develop/service/commons/telemetry/config': {\n    maxAge: 300,\n    transform: 'json',\n  },\n  '/this/param/does/not/exist': {}, // &lt;- Example of non-existent parameter\n};\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  const { _errors: errors, ...parameters } = await getParametersByName(props, {\n    throwOnError: false,\n  });\n\n  // Handle gracefully, since `/this/param/does/not/exist` will only be available in `_errors`\n  if (errors?.length) {\n    console.error(`Unable to retrieve parameters: ${errors.join(',')}`);\n  }\n\n  for (const [key, value] of Object.entries(parameters)) {\n    console.log(`${key}: ${value}`);\n  }\n};\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#storing-parameters",
            "title": "Storing parameters",
            "text": "<p>You can store parameters in the System Manager Parameter Store using <code>setParameter</code>.</p> Storing a parameter in SSM<pre><code>import { setParameter } from '@aws-lambda-powertools/parameters/ssm';\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Store a string parameter\n  const parameter = await setParameter('/my/parameter', { value: 'my-value' });\n  console.log(parameter);\n};\n</code></pre> <p>If the parameter is already existent, it needs to have the <code>overwrite</code> parameter set to <code>true</code> to update the value.</p> Overwriting an existing parameter in SSM<pre><code>import { setParameter } from '@aws-lambda-powertools/parameters/ssm';\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Overwrite a string parameter\n  const parameter = await setParameter('/my/parameter', {\n    value: 'my-value',\n    overwrite: true,\n  });\n  console.log(parameter);\n};\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#fetching-secrets",
            "title": "Fetching secrets",
            "text": "<p>You can fetch secrets stored in Secrets Manager using <code>getSecret</code>.</p> Fetching secrets<pre><code>import { getSecret } from '@aws-lambda-powertools/parameters/secrets';\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a single secret\n  const secret = await getSecret('my-secret');\n  console.log(secret);\n};\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#fetching-app-configurations",
            "title": "Fetching app configurations",
            "text": "<p>You can fetch application configurations in AWS AppConfig using <code>getAppConfig</code>.</p> <p>The following will retrieve the latest version and store it in the cache.</p> Fetching latest config from AppConfig<pre><code>import { getAppConfig } from '@aws-lambda-powertools/parameters/appconfig';\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a configuration, latest version\n  const config = await getAppConfig('my-configuration', {\n    environment: 'my-env',\n    application: 'my-app',\n  });\n  console.log(config);\n};\n</code></pre> <p>When using <code>getAppConfig</code>, the underlying provider is cached. To fetch from different applications or environments, create separate <code>AppConfigProvider</code> instances for each application/environment combination.</p>"
        },
        {
            "location": "utilities/parameters/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/parameters/#adjusting-cache-ttl",
            "title": "Adjusting cache TTL",
            "text": "<p>By default, the provider will cache parameters retrieved in-memory for 5 seconds.</p> <p>You can adjust how long values should be kept in cache by using the param <code>maxAge</code>, when using  <code>get()</code> or <code>getMultiple()</code> methods across all providers.</p> Tip <p>If you want to set the same TTL for all parameters, you can set the <code>POWERTOOLS_PARAMETERS_MAX_AGE</code> environment variable. This will override the default TTL of 5 seconds but can be overridden by the <code>maxAge</code> parameter.</p> Caching parameters values in memory for longer than 5 seconds<pre><code>import { SSMProvider } from '@aws-lambda-powertools/parameters/ssm';\n\nconst parametersProvider = new SSMProvider();\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a single parameter and cache it for 1 minute\n  const parameter = await parametersProvider.get('/my/parameter', {\n    maxAge: 60,\n  }); // (1)\n  console.log(parameter);\n\n  // Retrieve multiple parameters from a path prefix and cache them for 2 minutes\n  const parameters = await parametersProvider.getMultiple('/my/path/prefix', {\n    maxAge: 120,\n  });\n  for (const [key, value] of Object.entries(parameters || {})) {\n    console.log(`${key}: ${value}`);\n  }\n};\n</code></pre> <ol> <li>Options passed to <code>get()</code>, <code>getMultiple()</code>, and <code>getParametersByName()</code> will override the values set in <code>POWERTOOLS_PARAMETERS_MAX_AGE</code> environment variable.</li> </ol> Info <p>The <code>maxAge</code> parameter is also available in high level functions like <code>getParameter</code>, <code>getSecret</code>, etc.</p>"
        },
        {
            "location": "utilities/parameters/#always-fetching-the-latest",
            "title": "Always fetching the latest",
            "text": "<p>If you'd like to always ensure you fetch the latest parameter from the store regardless if already available in cache, use the <code>forceFetch</code> parameter.</p> Forcefully fetching the latest parameter whether TTL has expired or not<pre><code>import { getParameter } from '@aws-lambda-powertools/parameters/ssm';\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a single parameter\n  const parameter = await getParameter('/my/parameter', { forceFetch: true });\n  console.log(parameter);\n};\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#built-in-provider-class",
            "title": "Built-in provider class",
            "text": "<p>For greater flexibility such as configuring the underlying SDK client used by built-in providers, you can use their respective Provider Classes directly.</p> Tip <p>This can be used to retrieve values from other regions, change the retry behavior, etc.</p>"
        },
        {
            "location": "utilities/parameters/#ssmprovider",
            "title": "SSMProvider",
            "text": "Example with SSMProvider for further extensibility<pre><code>import { SSMProvider } from '@aws-lambda-powertools/parameters/ssm';\nimport type { SSMClientConfig } from '@aws-sdk/client-ssm';\n\nconst clientConfig: SSMClientConfig = { region: 'us-east-1' };\nconst parametersProvider = new SSMProvider({ clientConfig });\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a single parameter\n  const parameter = await parametersProvider.get('/my/parameter');\n  console.log(parameter);\n\n  // Retrieve multiple parameters from a path prefix\n  const parameters = await parametersProvider.getMultiple('/my/path/prefix');\n  for (const [key, value] of Object.entries(parameters || {})) {\n    console.log(`${key}: ${value}`);\n  }\n};\n</code></pre> <p>The AWS Systems Manager Parameter Store provider supports two additional arguments for the <code>get()</code> and <code>getMultiple()</code> methods:</p> Parameter Default Description decrypt <code>false</code> Will automatically decrypt the parameter (see required IAM Permissions). recursive <code>true</code> For <code>getMultiple()</code> only, will fetch all parameter values recursively based on a path prefix. Tip <p>If you want to always decrypt parameters, you can set the <code>POWERTOOLS_PARAMETERS_SSM_DECRYPT=true</code> environment variable. This will override the default value of <code>false</code> but can be overridden by the <code>decrypt</code> parameter.</p> Example with get() and getMultiple()<pre><code>import { SSMProvider } from '@aws-lambda-powertools/parameters/ssm';\n\nconst parametersProvider = new SSMProvider();\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  const decryptedValue = await parametersProvider.get(\n    '/my/encrypted/parameter',\n    { decrypt: true }\n  ); // (1)\n  console.log(decryptedValue);\n\n  const noRecursiveValues = await parametersProvider.getMultiple(\n    '/my/path/prefix',\n    { recursive: false }\n  );\n  for (const [key, value] of Object.entries(noRecursiveValues || {})) {\n    console.log(`${key}: ${value}`);\n  }\n};\n</code></pre> <ol> <li>Options passed to <code>get()</code>, <code>getMultiple()</code>, and <code>getParametersByName()</code> will override the values set in <code>POWERTOOLS_PARAMETERS_SSM_DECRYPT</code> environment variable.</li> </ol>"
        },
        {
            "location": "utilities/parameters/#secretsprovider",
            "title": "SecretsProvider",
            "text": "Example with SecretsProvider for further extensibility<pre><code>import { SecretsProvider } from '@aws-lambda-powertools/parameters/secrets';\nimport type { SecretsManagerClientConfig } from '@aws-sdk/client-secrets-manager';\n\nconst clientConfig: SecretsManagerClientConfig = { region: 'us-east-1' };\nconst secretsProvider = new SecretsProvider({ clientConfig });\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a single secret\n  const secret = await secretsProvider.get('my-secret');\n  console.log(secret);\n};\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#appconfigprovider",
            "title": "AppConfigProvider",
            "text": "<p>The AWS AppConfig provider requires two arguments when initialized:</p> Parameter Mandatory in constructor Alternative Description application No <code>POWERTOOLS_SERVICE_NAME</code> env variable The application in which your config resides. environment Yes (N/A) The environment that corresponds to your current config. Example with AppConfigProvider for further extensibility<pre><code>import { AppConfigProvider } from '@aws-lambda-powertools/parameters/appconfig';\nimport type { AppConfigDataClientConfig } from '@aws-sdk/client-appconfigdata';\n\nconst clientConfig: AppConfigDataClientConfig = { region: 'us-east-1' };\nconst configsProvider = new AppConfigProvider({\n  application: 'my-app',\n  environment: 'my-env',\n  clientConfig,\n});\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a config\n  const config = await configsProvider.get('my-config');\n  console.log(config);\n};\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#dynamodbprovider",
            "title": "DynamoDBProvider",
            "text": "<p>The DynamoDB Provider does not have any high-level functions and needs to know the name of the DynamoDB table containing the parameters.</p> <p>DynamoDB table structure for single parameters</p> <p>For single parameters, you must use <code>id</code> as the partition key for that table.</p> Example <p>DynamoDB table with <code>id</code> partition key and <code>value</code> as attribute</p> id value my-parameter my-value <p>With this table, <code>await dynamoDBProvider.get('my-param')</code> will return <code>my-value</code>.</p> handler.tsDynamoDB Local example <pre><code>import { DynamoDBProvider } from '@aws-lambda-powertools/parameters/dynamodb';\n\nconst dynamoDBProvider = new DynamoDBProvider({ tableName: 'my-table' });\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a value from DynamoDB\n  const value = await dynamoDBProvider.get('my-parameter');\n  console.log(value);\n};\n</code></pre> <p>You can initialize the DynamoDB provider pointing to DynamoDB Local using the <code>endpoint</code> field in the <code>clientConfig</code> parameter:</p> <pre><code>import { DynamoDBProvider } from '@aws-lambda-powertools/parameters/dynamodb';\n\nconst dynamoDBProvider = new DynamoDBProvider({\n  tableName: 'my-table',\n  clientConfig: {\n    endpoint: 'http://localhost:8000',\n  },\n});\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a value from DynamoDB\n  const value = await dynamoDBProvider.get('my-parameter');\n  console.log(value);\n};\n</code></pre> <p>DynamoDB table structure for multiple values parameters</p> <p>You can retrieve multiple parameters sharing the same <code>id</code> by having a sort key named <code>sk</code>.</p> Example <p>DynamoDB table with <code>id</code> primary key, <code>sk</code> as sort key and <code>value</code> as attribute</p> id sk value my-hash-key param-a my-value-a my-hash-key param-b my-value-b my-hash-key param-c my-value-c <p>With this table, <code>await dynamoDBProvider.getMultiple('my-hash-key')</code> will return a dictionary response in the shape of <code>sk:value</code>.</p> handler.tsvalues response object <pre><code>import { DynamoDBProvider } from '@aws-lambda-powertools/parameters/dynamodb';\n\nconst dynamoDBProvider = new DynamoDBProvider({ tableName: 'my-table' });\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  /**\n   * Retrieve multiple values by performing a Query on the DynamoDB table.\n   * This returns a dict with the sort key attribute as dict key.\n   */\n  const values = await dynamoDBProvider.getMultiple('my-hash-key');\n  for (const [key, value] of Object.entries(values || {})) {\n    // key: param-a\n    // value: my-value-a\n    console.log(`${key}: ${value}`);\n  }\n};\n</code></pre> <pre><code>{\n  \"param-a\": \"my-value-a\",\n  \"param-b\": \"my-value-b\",\n  \"param-c\": \"my-value-c\"\n}\n</code></pre> <p>Customizing DynamoDBProvider</p> <p>DynamoDB provider can be customized at initialization to match your table structure:</p> Parameter Mandatory Default Description tableName Yes (N/A) Name of the DynamoDB table containing the parameter values. keyAttr No <code>id</code> Hash key for the DynamoDB table. sortAttr No <code>sk</code> Range key for the DynamoDB table. You don't need to set this if you don't use the <code>getMultiple()</code> method. valueAttr No <code>value</code> Name of the attribute containing the parameter value. Customizing DynamoDBProvider to suit your table design<pre><code>import { DynamoDBProvider } from '@aws-lambda-powertools/parameters/dynamodb';\n\nconst dynamoDBProvider = new DynamoDBProvider({\n  tableName: 'my-table',\n  keyAttr: 'key',\n  sortAttr: 'sort',\n  valueAttr: 'val',\n});\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  const value = await dynamoDBProvider.get('my-parameter');\n  console.log(value);\n};\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#create-your-own-provider",
            "title": "Create your own provider",
            "text": "<p>You can create your own custom parameter store provider by extending the <code>BaseProvider</code> class, and implementing the <code>get()</code> and <code>getMultiple()</code> methods, as well as its respective <code>_get()</code> and <code>_getMultiple()</code> private methods to retrieve a single, or multiple parameters from your custom store.</p> <p>All caching logic is handled by the <code>BaseProvider</code>, and provided that the return types of your store are compatible with the ones used in the <code>BaseProvider</code>, all transformations will also work as expected.</p> <p>Here's an example of implementing a custom parameter store using an external service like HashiCorp Vault, a widely popular key-value secret storage.</p> Provider usageProvider implementationProvider types <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { HashiCorpVaultProvider } from './customProviderVault.js';\n\nconst logger = new Logger({ serviceName: 'serverless-airline' });\nconst secretsProvider = new HashiCorpVaultProvider({\n  url: 'https://vault.example.com:8200/v1',\n  token: process.env.ROOT_TOKEN ?? '',\n  rootPath: 'kv',\n});\n\n// Retrieve a secret from HashiCorp Vault\nconst secret = await secretsProvider.get&lt;{ foo: 'string' }&gt;('my-secret');\n\nconst res = await fetch('https://example.com/api', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n    Authorization: `Bearer ${secret?.foo}`,\n  },\n  body: JSON.stringify({ data: 'example' }),\n});\nlogger.debug('res status', { status: res.status });\n</code></pre> <pre><code>import { BaseProvider } from '@aws-lambda-powertools/parameters/base';\nimport { GetParameterError } from '@aws-lambda-powertools/parameters/errors';\nimport type {\n  HashiCorpVaultGetOptions,\n  HashiCorpVaultProviderOptions,\n} from './customProviderVaultTypes.js';\n\nclass HashiCorpVaultProvider extends BaseProvider {\n  readonly #baseUrl: string;\n  readonly #token: string;\n  readonly #rootPath?: string;\n  readonly #timeout: number;\n  readonly #abortController: AbortController;\n\n  /**\n   * It initializes the HashiCorpVaultProvider class.\n   *\n   * @param config - The configuration object.\n   */\n  public constructor(config: HashiCorpVaultProviderOptions) {\n    super({});\n\n    const { url, token, rootPath, timeout } = config;\n    this.#baseUrl = url;\n    this.#rootPath = rootPath ?? 'secret';\n    this.#timeout = timeout ?? 5000;\n    this.#token = token;\n    this.#abortController = new AbortController();\n  }\n\n  /**\n   * Retrieve a secret from HashiCorp Vault.\n   *\n   * You can customize the retrieval of the secret by passing options to the function:\n   * * `maxAge` - The maximum age of the value in cache before fetching a new one (in seconds) (default: 5)\n   * * `forceFetch` - Whether to always fetch a new value from the store regardless if already available in cache\n   * * `sdkOptions` - Extra options to pass to the HashiCorp Vault SDK, e.g. `mount` or `version`\n   *\n   * @param name - The name of the secret\n   * @param options - Options to customize the retrieval of the secret\n   */\n  public async get&lt;T extends Record&lt;string, unknown&gt;&gt;(\n    name: string,\n    options?: HashiCorpVaultGetOptions\n  ): Promise&lt;T | undefined&gt; {\n    return super.get(name, options) as Promise&lt;\n      Record&lt;string, unknown&gt; | undefined\n    &gt; as Promise&lt;T | undefined&gt;;\n  }\n\n  /**\n   * Retrieving multiple parameter values is not supported with HashiCorp Vault.\n   */\n  public async getMultiple(path: string, _options?: unknown): Promise&lt;void&gt; {\n    await super.getMultiple(path);\n  }\n\n  /**\n   * Retrieve a secret from HashiCorp Vault.\n   *\n   * @param name - The name of the secret\n   * @param options - Options to customize the retrieval of the secret\n   */\n  protected async _get(\n    name: string,\n    options?: HashiCorpVaultGetOptions\n  ): Promise&lt;Record&lt;string, unknown&gt;&gt; {\n    const { sdkOptions } = options ?? {};\n    const mount = sdkOptions?.mount ?? this.#rootPath;\n    const version = sdkOptions?.version\n      ? `?version=${sdkOptions?.version}`\n      : '';\n\n    setTimeout(() =&gt; {\n      this.#abortController.abort();\n    }, this.#timeout);\n\n    const res = await fetch(\n      `${this.#baseUrl}/${mount}/data/${name}${version}`,\n      {\n        headers: { 'X-Vault-Token': this.#token },\n        method: 'GET',\n        signal: this.#abortController.signal,\n      }\n    );\n    if (!res.ok) {\n      throw new GetParameterError(`Failed to fetch secret ${res.statusText}`);\n    }\n    const response = await res.json();\n    return response.data.data;\n  }\n\n  /**\n   * Retrieving multiple parameter values from HashiCorp Vault is not supported.\n   *\n   * @throws Not Implemented Error.\n   */\n  protected async _getMultiple(\n    _path: string,\n    _options?: unknown\n  ): Promise&lt;Record&lt;string, unknown&gt; | undefined&gt; {\n    throw new GetParameterError('Method not implemented.');\n  }\n}\n\nexport { HashiCorpVaultProvider };\n</code></pre> <pre><code>import type { GetOptionsInterface } from '@aws-lambda-powertools/parameters/base/types';\n\n/**\n * Options for the HashiCorpVaultProvider class constructor.\n *\n * @param {string} url - Indicate the server name/IP, port and API version for the Vault instance, all paths are relative to this one.\n * @param {string} token - The Vault token to use for authentication.\n *\n */\ninterface HashiCorpVaultProviderOptions {\n  /**\n   * Indicate the server name/IP, port and API version for the Vault instance, all paths are relative to this one.\n   * @example 'https://vault.example.com:8200/v1'\n   */\n  url: string;\n  /**\n   * The Vault token to use for authentication.\n   */\n  token: string;\n  /**\n   * The root path to use for the secret engine. Defaults to `secret`.\n   */\n  rootPath?: string;\n  /**\n   * The timeout in milliseconds for the HTTP requests. Defaults to `5000`.\n   * @example 10000\n   * @default 5000\n   */\n  timeout?: number;\n}\n\ntype HashiCorpVaultReadKVSecretOptions = {\n  /**\n   * The mount point of the secret engine to use. Defaults to `secret`.\n   * @example 'kv'\n   */\n  mount?: string;\n  /**\n   * The version of the secret to retrieve. Defaults to `undefined`.\n   * @example 1\n   */\n  version?: number;\n};\n\ninterface HashiCorpVaultGetOptions extends GetOptionsInterface {\n  /**\n   * The Parameters utility does not support transforming `Record&lt;string, unknown&gt;` values as returned by the HashiCorp Vault SDK.\n   */\n  transform?: never;\n  sdkOptions?: HashiCorpVaultReadKVSecretOptions;\n}\n\nexport type { HashiCorpVaultProviderOptions, HashiCorpVaultGetOptions };\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#deserializing-values-with-transform-parameter",
            "title": "Deserializing values with transform parameter",
            "text": "<p>For parameters stored in JSON or Base64 format, you can use the <code>transform</code> argument for deserialization.</p> Info <p>The <code>transform</code> argument is available across all providers, including the high level functions.</p> High level functionsProviders <pre><code>import { getParameter } from '@aws-lambda-powertools/parameters/ssm';\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  const valueFromJson = await getParameter('/my/json/parameter', {\n    transform: 'json',\n  });\n  console.log(valueFromJson);\n};\n</code></pre> <pre><code>import { SecretsProvider } from '@aws-lambda-powertools/parameters/secrets';\n\nconst secretsProvider = new SecretsProvider();\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Transform a JSON string\n  const json = await secretsProvider.get('my-secret-json', {\n    transform: 'json',\n  });\n  console.log(json);\n\n  // Transform a Base64 encoded string (e.g. binary)\n  const binary = await secretsProvider.getMultiple('my-secret-binary', {\n    transform: 'binary',\n  });\n  console.log(binary);\n};\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#partial-transform-failures-with-getmultiple",
            "title": "Partial transform failures with <code>getMultiple()</code>",
            "text": "<p>If you use <code>transform</code> with <code>getMultiple()</code>, you can have a single malformed parameter value. To prevent failing the entire request, the method will return an <code>undefined</code> value for the parameters that failed to transform.</p> <p>You can override this by setting the <code>throwOnTransformError</code> argument to <code>true</code>. If you do so, a single transform error will throw a <code>TransformParameterError</code> error.</p> <p>For example, if you have three parameters, /param/a, /param/b and /param/c, but /param/c is malformed:</p> Throwing TransformParameterError at first malformed parameter<pre><code>import { SSMProvider } from '@aws-lambda-powertools/parameters/ssm';\n\nconst parametersProvider = new SSMProvider();\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  /**\n   * This will display:\n   * /param/a: [some value]\n   * /param/b: [some value]\n   * /param/c: undefined\n   */\n  const parameters = await parametersProvider.getMultiple('/param', {\n    transform: 'json',\n  });\n  for (const [key, value] of Object.entries(parameters || {})) {\n    console.log(`${key}: ${value}`);\n  }\n\n  try {\n    // This will throw a TransformParameterError\n    const parameters2 = await parametersProvider.getMultiple('/param', {\n      transform: 'json',\n      throwOnTransformError: true,\n    });\n    for (const [key, value] of Object.entries(parameters2 || {})) {\n      console.log(`${key}: ${value}`);\n    }\n  } catch (err) {\n    console.error(err);\n  }\n};\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#auto-transform-values-on-suffix",
            "title": "Auto-transform values on suffix",
            "text": "<p>If you use <code>transform</code> with <code>getMultiple()</code>, you might want to retrieve and transform parameters encoded in different formats.</p> <p>You can do this with a single request by using <code>transform: 'auto'</code>. This will instruct any provider to infer its type based on the suffix and transform it accordingly.</p> Info <p><code>transform: 'auto'</code> feature is available across all providers, including the high level functions.</p> Deserializing parameter values based on their suffix<pre><code>import { SSMProvider } from '@aws-lambda-powertools/parameters/ssm';\n\nconst parametersProvider = new SSMProvider();\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  const values = await parametersProvider.getMultiple('/param', {\n    transform: 'auto',\n  });\n  for (const [key, value] of Object.entries(values || {})) {\n    console.log(`${key}: ${value}`);\n  }\n};\n</code></pre> <p>For example, if you have three parameters: two with the following suffixes <code>.json</code> and <code>.binary</code> and one without any suffix:</p> Parameter name Parameter value /param/a [some encoded value] /param/a.json [some encoded value] /param/a.binary [some encoded value] <p>The return of <code>await parametersProvider.getMultiple('/param', transform: 'auto');</code> call will be an object like:</p> <pre><code>{\n  \"a\": [some encoded value],\n  \"a.json\": [some decoded value],\n  \"b.binary\": [some decoded value]\n}\n</code></pre> <p>The two parameters with a suffix will be decoded, while the one without a suffix will be returned as is.</p>"
        },
        {
            "location": "utilities/parameters/#passing-additional-sdk-arguments",
            "title": "Passing additional SDK arguments",
            "text": "<p>You can use a special <code>sdkOptions</code> object argument to pass any supported option directly to the underlying SDK method.</p> Specify a VersionId for a secret<pre><code>import { SecretsProvider } from '@aws-lambda-powertools/parameters/secrets';\nimport type { GetSecretValueCommandInput } from '@aws-sdk/client-secrets-manager';\n\nconst secretsProvider = new SecretsProvider();\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  const sdkOptions: Partial&lt;GetSecretValueCommandInput&gt; = {\n    VersionId: 'e62ec170-6b01-48c7-94f3-d7497851a8d2',\n  };\n  /**\n   * The 'VersionId' argument will be passed to the underlying\n   * `GetSecretValueCommand` call.\n   */\n  const secret = await secretsProvider.get('my-secret', { sdkOptions });\n  console.log(secret);\n};\n</code></pre> <p>Here is the mapping between this utility's functions and methods and the underlying SDK:</p> Provider Function/Method Client name Function name SSM Parameter Store <code>getParameter</code> <code>@aws-sdk/client-ssm</code> GetParameterCommand SSM Parameter Store <code>getParameters</code> <code>@aws-sdk/client-ssm</code> GetParametersByPathCommand SSM Parameter Store <code>SSMProvider.get</code> <code>@aws-sdk/client-ssm</code> GetParameterCommand SSM Parameter Store <code>SSMProvider.getMultiple</code> <code>@aws-sdk/client-ssm</code> GetParametersByPathCommand SSM Parameter Store <code>setParameter</code> <code>@aws-sdk/client-ssm</code> PutParameterCommand SSM Parameter Store <code>SSMProvider.set</code> <code>@aws-sdk/client-ssm</code> PutParameterCommand Secrets Manager <code>getSecret</code> <code>@aws-sdk/client-secrets-manager</code> GetSecretValueCommand Secrets Manager <code>SecretsProvider.get</code> <code>@aws-sdk/client-secrets-manager</code> GetSecretValueCommand AppConfig <code>AppConfigProvider.get</code> <code>@aws-sdk/client-appconfigdata</code> StartConfigurationSessionCommand &amp; GetLatestConfigurationCommand AppConfig <code>getAppConfig</code> <code>@aws-sdk/client-appconfigdata</code> StartConfigurationSessionCommand &amp; GetLatestConfigurationCommand DynamoDB <code>DynamoDBProvider.get</code> <code>@aws-sdk/client-dynamodb</code> GetItemCommand DynamoDB <code>DynamoDBProvider.getMultiple</code> <code>@aws-sdk/client-dynamodb</code> QueryCommand"
        },
        {
            "location": "utilities/parameters/#bring-your-own-aws-sdk-v3-client",
            "title": "Bring your own AWS SDK v3 client",
            "text": "<p>You can use the <code>awsSdkV3Client</code> parameter via any of the available Provider Classes.</p> Provider Client SSMProvider <code>new SSMClient();</code> SecretsProvider <code>new SecretsManagerClient();</code> AppConfigProvider <code>new AppConfigDataClient();</code> DynamoDBProvider <code>new DynamoDBClient();</code> When is this useful? <p>Injecting a custom AWS SDK v3 client allows you to apply tracing or make unit/snapshot testing easier, including SDK customizations.</p> SSMProviderSecretsProviderAppConfigProviderDynamoDBProvider <pre><code>import { SSMProvider } from '@aws-lambda-powertools/parameters/ssm';\nimport { SSMClient } from '@aws-sdk/client-ssm';\n\n// construct your clients with any custom configuration\nconst ssmClient = new SSMClient({ region: 'us-east-1' });\n// pass the client to the provider\nconst parametersProvider = new SSMProvider({ awsSdkV3Client: ssmClient });\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a single parameter\n  const parameter = await parametersProvider.get('/my/parameter');\n  console.log(parameter);\n};\n</code></pre> <pre><code>import { SecretsProvider } from '@aws-lambda-powertools/parameters/secrets';\nimport { SecretsManagerClient } from '@aws-sdk/client-secrets-manager';\n\n// construct your clients with any custom configuration\nconst secretsManagerClient = new SecretsManagerClient({ region: 'us-east-1' });\n// pass the client to the provider\nconst secretsProvider = new SecretsProvider({\n  awsSdkV3Client: secretsManagerClient,\n});\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a single secret\n  const secret = await secretsProvider.get('my-secret');\n  console.log(secret);\n};\n</code></pre> <pre><code>import { AppConfigProvider } from '@aws-lambda-powertools/parameters/appconfig';\nimport { AppConfigDataClient } from '@aws-sdk/client-appconfigdata';\n\n// construct your clients with any custom configuration\nconst appConfigClient = new AppConfigDataClient({ region: 'us-east-1' });\n// pass the client to the provider\nconst configsProvider = new AppConfigProvider({\n  application: 'my-app',\n  environment: 'my-env',\n  awsSdkV3Client: appConfigClient,\n});\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  const config = await configsProvider.get('my-config');\n  console.log(config);\n};\n</code></pre> <pre><code>import { DynamoDBProvider } from '@aws-lambda-powertools/parameters/dynamodb';\nimport { DynamoDBClient } from '@aws-sdk/client-dynamodb';\n\n// construct your clients with any custom configuration\nconst dynamoDBClient = new DynamoDBClient({ region: 'us-east-1' });\n// pass the client to the provider\nconst valuesProvider = new DynamoDBProvider({\n  tableName: 'my-table',\n  awsSdkV3Client: dynamoDBClient,\n});\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a single value\n  const value = await valuesProvider.get('my-value');\n  console.log(value);\n};\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#customizing-aws-sdk-v3-configuration",
            "title": "Customizing AWS SDK v3 configuration",
            "text": "<p>The <code>clientConfig</code> parameter enables you to pass in a custom config object when constructing any of the built-in provider classes.</p> Tip <p>You can use a custom session for retrieving parameters cross-account/region and for snapshot testing.</p> <p>When using VPC private endpoints, you can pass a custom client altogether. It's also useful for testing when injecting fake instances.</p> <pre><code>import { SSMProvider } from '@aws-lambda-powertools/parameters/ssm';\nimport type { SSMClientConfig } from '@aws-sdk/client-ssm';\n\nconst clientConfig: SSMClientConfig = { region: 'us-east-1' };\nconst parametersProvider = new SSMProvider({ clientConfig });\n\nexport const handler = async (): Promise&lt;void&gt; =&gt; {\n  // Retrieve a single parameter\n  const value = await parametersProvider.get('/my/parameter');\n  console.log(value);\n};\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#testing-your-code",
            "title": "Testing your code",
            "text": ""
        },
        {
            "location": "utilities/parameters/#mocking-parameter-values",
            "title": "Mocking parameter values",
            "text": "<p>For unit testing your applications, you can mock the calls to the parameters utility to avoid calling AWS APIs. This can be achieved in a number of ways - in this example, we mock the module import to patch the <code>getParameters</code> function.</p> handler.test.tshandler.ts <pre><code>import { afterEach, describe, expect, it, vi } from 'vitest';\nimport { handler } from './testingYourCodeFunctionsHandler.js';\n\nconst mocks = vi.hoisted(() =&gt; ({\n  getParameter: vi.fn(),\n}));\n\nvi.mock('@aws-lambda-powertools/parameters/ssm', async (importOriginal) =&gt; ({\n  ...(await importOriginal&lt;\n    typeof import('@aws-lambda-powertools/parameters/ssm')\n  &gt;()),\n  getParameter: mocks.getParameter,\n}));\n\ndescribe('Function tests', () =&gt; {\n  afterEach(() =&gt; {\n    vi.clearAllMocks();\n  });\n\n  it('returns the correct response', async () =&gt; {\n    // Prepare\n    mocks.getParameter.mockResolvedValueOnce('my/param');\n\n    // Act\n    const result = await handler({}, {});\n\n    // Assess\n    expect(result).toEqual({\n      value: 'my/param',\n    });\n  });\n});\n</code></pre> <pre><code>import { getParameter } from '@aws-lambda-powertools/parameters/ssm';\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;Record&lt;string, unknown&gt;&gt; =&gt; {\n  const parameter = await getParameter('my/param');\n\n  return {\n    value: parameter,\n  };\n};\n</code></pre> <p>With this pattern in place, you can customize the return values of the mocked function to test different scenarios without calling AWS APIs.</p> <p>A similar pattern can be applied also to any of the built-in provider classes - in this other example, we use spies to patch the <code>get</code> function of the <code>AppConfigProvider</code> class. This is useful also when you want to test that the correct arguments are being passed to the Parameters utility.</p> handler.test.tshandler.ts <pre><code>import { AppConfigProvider } from '@aws-lambda-powertools/parameters/appconfig';\nimport { Uint8ArrayBlobAdapter } from '@smithy/util-stream';\nimport { afterEach, describe, expect, it, vi } from 'vitest';\nimport { handler } from './testingYourCodeFunctionsHandler.js';\n\ndescribe('Function tests', () =&gt; {\n  const providerSpy = vi.spyOn(AppConfigProvider.prototype, 'get');\n\n  afterEach(() =&gt; {\n    vi.clearAllMocks();\n  });\n\n  it('retrieves the config once and uses the correct name', async () =&gt; {\n    // Prepare\n    const expectedConfig = {\n      feature: {\n        enabled: true,\n        name: 'paywall',\n      },\n    };\n    providerSpy.mockResolvedValueOnce(\n      Uint8ArrayBlobAdapter.fromString(JSON.stringify(expectedConfig))\n    );\n\n    // Act\n    const result = await handler({}, {});\n\n    // Assess\n    expect(result).toStrictEqual({ value: expectedConfig });\n    expect(providerSpy).toHaveBeenCalledTimes(1);\n    expect(providerSpy).toHaveBeenCalledWith('my-config');\n  });\n});\n</code></pre> <pre><code>import { AppConfigProvider } from '@aws-lambda-powertools/parameters/appconfig';\n\nconst provider = new AppConfigProvider({\n  environment: 'dev',\n  application: 'my-app',\n});\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;Record&lt;string, unknown&gt;&gt; =&gt; {\n  const config = await provider.get('my-config');\n\n  return {\n    value: config,\n  };\n};\n</code></pre> <p>For when you want to mock the AWS SDK v3 client directly, we recommend using the <code>aws-sdk-client-mock</code> and <code>aws-sdk-client-mock-vitest</code> libraries. This is useful when you want to test how your code behaves when the AWS SDK v3 client throws an error or a specific response.</p> handler.test.tshandler.ts <pre><code>import {\n  GetSecretValueCommand,\n  ResourceNotFoundException,\n  SecretsManagerClient,\n} from '@aws-sdk/client-secrets-manager';\nimport { mockClient } from 'aws-sdk-client-mock';\nimport { afterEach, describe, expect, it, vi } from 'vitest';\nimport { handler } from './testingYourCodeFunctionsHandler.js';\nimport 'aws-sdk-client-mock-vitest';\n\ndescribe('Function tests', () =&gt; {\n  const client = mockClient(SecretsManagerClient);\n\n  afterEach(() =&gt; {\n    vi.clearAllMocks();\n    client.reset();\n  });\n\n  it('returns the correct error message', async () =&gt; {\n    // Prepare\n    client.on(GetSecretValueCommand).rejectsOnce(\n      new ResourceNotFoundException({\n        $metadata: {\n          httpStatusCode: 404,\n        },\n        message: 'Unable to retrieve secret',\n      })\n    );\n\n    // Act\n    const result = await handler({}, {});\n\n    // Assess\n    expect(result).toStrictEqual({ message: 'Unable to retrieve secret' });\n  });\n});\n</code></pre> <pre><code>import { getSecret } from '@aws-lambda-powertools/parameters/secrets';\n\nexport const handler = async (\n  _event: unknown,\n  _context: unknown\n): Promise&lt;Record&lt;string, unknown&gt;&gt; =&gt; {\n  try {\n    const parameter = await getSecret('my-secret');\n\n    return {\n      value: parameter,\n    };\n  } catch (error) {\n    return {\n      message: 'Unable to retrieve secret',\n    };\n  }\n};\n</code></pre>"
        },
        {
            "location": "utilities/parameters/#clearing-cache",
            "title": "Clearing cache",
            "text": "<p>Parameters utility caches all parameter values for performance and cost reasons. However, this can have unintended interference in tests using the same parameter name.</p> <p>Within your tests, you can use <code>clearCache</code> method available in every provider. When using multiple providers or higher level functions like <code>getParameter</code>, use the <code>clearCaches</code> standalone function to clear cache globally.</p> handler.test.ts <pre><code>import { clearCaches } from '@aws-lambda-powertools/parameters';\nimport { afterEach, describe } from 'vitest';\n\ndescribe('Function tests', () =&gt; {\n  afterEach(() =&gt; {\n    clearCaches();\n  });\n\n  // ...\n});\n</code></pre>"
        },
        {
            "location": "utilities/parser/",
            "title": "Parser (Zod)",
            "text": "<p>This utility provides data validation and parsing using Zod, a TypeScript-first schema declaration and validation library.  </p>"
        },
        {
            "location": "utilities/parser/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Define data schema as Zod schema, then parse, validate and extract only what you want</li> <li>Built-in envelopes to unwrap and validate popular AWS event sources payloads</li> <li>Extend and customize envelopes to fit your needs</li> <li>Safe parsing option to avoid throwing errors and custom error handling</li> <li>Available for Middy.js middleware and TypeScript method decorators</li> </ul>"
        },
        {
            "location": "utilities/parser/#getting-started",
            "title": "Getting started",
            "text": "<pre><code>npm install @aws-lambda-powertools/parser zod@~3\n</code></pre> <p>This utility supports Zod v3.x and above.</p>"
        },
        {
            "location": "utilities/parser/#define-schema",
            "title": "Define schema",
            "text": "<p>You can define your schema using Zod:</p> schema.ts<pre><code>import { z } from 'zod';\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\n\ntype Order = z.infer&lt;typeof orderSchema&gt;;\n\nexport { orderSchema, type Order };\n</code></pre> <p>This is a schema for <code>Order</code> object using Zod. You can create complex schemas by using nested objects, arrays, unions, and other types, see Zod documentation for more details.</p>"
        },
        {
            "location": "utilities/parser/#parse-events",
            "title": "Parse events",
            "text": "<p>You can parse inbound events using <code>parser</code> decorator, Middy.js middleware, or manually using built-in envelopes and schemas. Both are also able to parse either an object or JSON string as an input.</p> Warning <p>The decorator and middleware will replace the event object with the parsed schema if successful. Be cautious when using multiple decorators that expect event to have a specific structure, the order of evaluation for decorators is from bottom to top.</p> Middy middlewareDecorator <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { parser } from '@aws-lambda-powertools/parser/middleware';\nimport middy from '@middy/core';\nimport { z } from 'zod';\n\nconst logger = new Logger();\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\n\nexport const handler = middy()\n  .use(parser({ schema: orderSchema }))\n  .handler(async (event): Promise&lt;void&gt; =&gt; {\n    for (const item of event.items) {\n      // item is parsed as OrderItem\n      logger.info('Processing item', { item });\n    }\n  });\n</code></pre> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport { parser } from '@aws-lambda-powertools/parser';\nimport type { Context } from 'aws-lambda';\nimport { z } from 'zod';\n\nconst logger = new Logger();\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\n\ntype Order = z.infer&lt;typeof orderSchema&gt;;\n\nclass Lambda implements LambdaInterface {\n  @parser({ schema: orderSchema })\n  public async handler(event: Order, _context: Context): Promise&lt;void&gt; {\n    // event is now typed as Order\n    for (const item of event.items) {\n      logger.info('Processing item', { item });\n    }\n  }\n}\n\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\n</code></pre>"
        },
        {
            "location": "utilities/parser/#built-in-schemas",
            "title": "Built-in schemas",
            "text": "<p>Parser comes with the following built-in schemas:</p> Model name Description AlbSchema Lambda Event Source payload for Amazon Application Load Balancer APIGatewayProxyEventSchema Lambda Event Source payload for Amazon API Gateway APIGatewayRequestAuthorizerEventSchema Lambda Event Source payload for Amazon API Gateway Request Authorizer APIGatewayTokenAuthorizerEventSchema Lambda Event Source payload for Amazon API Gateway Token Authorizer APIGatewayProxyEventV2Schema Lambda Event Source payload for Amazon API Gateway v2 payload APIGatewayProxyWebsocketEventSchema Lambda Event Source payload for Amazon API Gateway WebSocket events APIGatewayRequestAuthorizerEventV2Schema Lambda Event Source payload for Amazon API Gateway v2 Authorizer CloudFormationCustomResourceCreateSchema Lambda Event Source payload for AWS CloudFormation <code>CREATE</code> operation CloudFormationCustomResourceUpdateSchema Lambda Event Source payload for AWS CloudFormation <code>UPDATE</code> operation CloudFormationCustomResourceDeleteSchema Lambda Event Source payload for AWS CloudFormation <code>DELETE</code> operation CloudwatchLogsSchema Lambda Event Source payload for Amazon CloudWatch Logs PreSignupTriggerSchema Lambda Event Source payload for Amazon Cognito Pre Sign-up trigger PostConfirmationTriggerSchema Lambda Event Source payload for Amazon Cognito Post Confirmation trigger PreTokenGenerationTriggerSchema Lambda Event Source payload for Amazon Cognito Pre Token Generation trigger CustomMessageTriggerSchema Lambda Event Source payload for Amazon Cognito Custom Message trigger MigrateUserTriggerSchema Lambda Event Source payload for Amazon Cognito User Migration trigger CustomSMSTriggerSchema Lambda Event Source payload for Amazon Cognito Custom SMS trigger CustomEmailTriggerSchema Lambda Event Source payload for Amazon Cognito Custom Email trigger DefineAuthChallengeTriggerSchema Lambda Event Source payload for Amazon Cognito Define Auth Challenge trigger CreateAuthChallengeTriggerSchema Lambda Event Source payload for Amazon Cognito Create Auth Challenge trigger VerifyAuthChallengeResponseTriggerSchema Lambda Event Source payload for Amazon Cognito Verify Auth Challenge Response trigger PreTokenGenerationTriggerSchemaV1 Lambda Event Source payload for Amazon Cognito Pre Token Generation trigger v1 PreTokenGenerationTriggerSchemaV2AndV3 Lambda Event Source payload for Amazon Cognito Pre Token Generation trigger v2 and v3 DynamoDBStreamSchema Lambda Event Source payload for Amazon DynamoDB Streams EventBridgeSchema Lambda Event Source payload for Amazon EventBridge KafkaMskEventSchema Lambda Event Source payload for AWS MSK payload KafkaSelfManagedEventSchema Lambda Event Source payload for self managed Kafka payload KinesisDataStreamSchema Lambda Event Source payload for Amazon Kinesis Data Streams KinesisFirehoseSchema Lambda Event Source payload for Amazon Kinesis Firehose KinesisDynamoDBStreamSchema Lambda Event Source payload for DynamodbStream record wrapped in Kinesis Data stream KinesisFirehoseSqsSchema Lambda Event Source payload for SQS messages wrapped in Kinesis Firehose records LambdaFunctionUrlSchema Lambda Event Source payload for Lambda Function URL payload S3EventNotificationEventBridgeSchema Lambda Event Source payload for Amazon S3 Event Notification to EventBridge. S3Schema Lambda Event Source payload for Amazon S3 S3ObjectLambdaEvent Lambda Event Source payload for Amazon S3 Object Lambda S3SqsEventNotificationSchema Lambda Event Source payload for S3 event notifications wrapped in SQS event (S3-&gt;SQS) SesSchema Lambda Event Source payload for Amazon Simple Email Service SnsSchema Lambda Event Source payload for Amazon Simple Notification Service SqsSchema Lambda Event Source payload for Amazon SQS TransferFamilySchema Lambda Event Source payload for AWS Transfer Family events VpcLatticeSchema Lambda Event Source payload for Amazon VPC Lattice VpcLatticeV2Schema Lambda Event Source payload for Amazon VPC Lattice v2 payload"
        },
        {
            "location": "utilities/parser/#extend-built-in-schemas",
            "title": "Extend built-in schemas",
            "text": "<p>You can extend every built-in schema to include your own schema, and yet have all other known fields parsed along the way.</p> handler.tsExample payload <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport { parser } from '@aws-lambda-powertools/parser';\nimport { EventBridgeSchema } from '@aws-lambda-powertools/parser/schemas/eventbridge';\nimport type { Context } from 'aws-lambda';\nimport { z } from 'zod';\n\nconst logger = new Logger();\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\n\nconst orderEventSchema = EventBridgeSchema.extend({\n  detail: orderSchema, // (1)!\n});\n\ntype OrderEvent = z.infer&lt;typeof orderEventSchema&gt;;\n\nclass Lambda implements LambdaInterface {\n  @parser({ schema: orderEventSchema }) // (2)!\n  public async handler(event: OrderEvent, _context: Context): Promise&lt;void&gt; {\n    for (const item of event.detail.items) {\n      // process OrderItem\n      logger.info('Processing item', { item }); // (3)!\n    }\n  }\n}\n\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\n</code></pre> <ol> <li>Extend built-in <code>EventBridgeSchema</code> with your own detail schema</li> <li>Pass the extended schema to <code>parser</code> decorator or middy middleware</li> <li><code>event</code> is validated including your custom schema and now available in your handler</li> </ol> <pre><code>{\n  \"version\": \"0\",\n  \"id\": \"6a7e8feb-b491-4cf7-a9f1-bf3703467718\",\n  \"detail-type\": \"OrderPurchased\",\n  \"source\": \"OrderService\",\n  \"account\": \"111122223333\",\n  \"time\": \"2020-10-22T18:43:48Z\",\n  \"region\": \"us-west-1\",\n  \"resources\": [\"some_additional\"],\n  \"detail\": {\n    \"id\": 10876546789,\n    \"description\": \"My order\",\n    \"items\": [\n      {\n        \"id\": 1015938732,\n        \"quantity\": 1,\n        \"description\": \"item xpto\"\n      }\n    ]\n  }\n}\n</code></pre>"
        },
        {
            "location": "utilities/parser/#json-stringified-payloads",
            "title": "JSON stringified payloads",
            "text": "<p>If you want to extend a schema and transform a JSON stringified payload to an object, you can use helper function <code>JSONStringified</code>:</p> AlbSchema with JSONStringifiedALB example payloadAPIGatewayProxyEventV2Schema with JSONStringifiedAPI Gateway HTTP API example payloadSQS Schema with JSONStringifiedSQS example payload <pre><code>import { JSONStringified } from '@aws-lambda-powertools/parser/helpers';\nimport { AlbSchema } from '@aws-lambda-powertools/parser/schemas/alb';\nimport { z } from 'zod';\n\nconst customSchema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n\nconst extendedSchema = AlbSchema.extend({\n  body: JSONStringified(customSchema),\n});\n\ntype ExtendedAlbEvent = z.infer&lt;typeof extendedSchema&gt;;\n</code></pre> <ol> <li>Extend built-in <code>AlbSchema</code> using JSONStringified function to transform your payload</li> </ol> <pre><code>{\n  \"requestContext\": {\n    \"elb\": {\n      \"targetGroupArn\": \"arn:aws:elasticloadbalancing:us-east-2:123456789012:targetgroup/lambda-279XGJDqGZ5rsrHC2Fjr/49e9d65c45c6791a\"\n    }\n  },\n  \"httpMethod\": \"GET\",\n  \"path\": \"/lambda\",\n  \"queryStringParameters\": {\n    \"query\": \"1234ABCD\"\n  },\n  \"headers\": {\n    \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n    \"accept-encoding\": \"gzip\",\n    \"accept-language\": \"en-US,en;q=0.9\",\n    \"connection\": \"keep-alive\",\n    \"host\": \"lambda-alb-123578498.us-east-2.elb.amazonaws.com\",\n    \"upgrade-insecure-requests\": \"1\",\n    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36\",\n    \"x-amzn-trace-id\": \"Root=1-5c536348-3d683b8b04734faae651f476\",\n    \"x-forwarded-for\": \"72.12.164.125\",\n    \"x-forwarded-port\": \"80\",\n    \"x-forwarded-proto\": \"http\",\n    \"x-imforwards\": \"20\"\n  },\n  \"body\": \"{\\\"name\\\":\\\"Walter\\\", \\\"age\\\": 50}\",\n  \"isBase64Encoded\": false\n}\n</code></pre> <pre><code> import { JSONStringified } from '@aws-lambda-powertools/parser/helpers';\n import { APIGatewayProxyEventV2Schema } from '@aws-lambda-powertools/parser/schemas/api-gatewayv2';\n import { z } from 'zod';\n\n const extendedSchema = APIGatewayProxyEventV2Schema.extend({ // (1)!\n   body: JSONStringified(\n     z.object({\n       name: z.string(),\n       age: z.number(),\n     })\n   ),\n });\n type ExtendedAPIGatewayEvent = z.infer&lt;typeof extendedSchema&gt;;\n</code></pre> <ol> <li>This is compatible also with API Gateway REST API schemas</li> </ol> <pre><code>{\n  \"version\": \"2.0\",\n  \"routeKey\": \"POST /lambda\",\n  \"rawPath\": \"/lambda\",\n  \"rawQueryString\": \"\",\n  \"headers\": {\n    \"accept\": \"*/*\",\n    \"accept-encoding\": \"gzip, deflate\",\n    \"authorization\": \"Bearer foo\",\n    \"content-length\": \"0\",\n    \"host\": \"lsw1ro4ipb.execute-api.eu-west-1.amazonaws.com\",\n    \"user-agent\": \"HTTPie/3.2.2\",\n    \"x-amzn-trace-id\": \"Root=1-66705bc7-2b4257df30cbee696ef2cf28\",\n    \"x-forwarded-for\": \"15.248.3.126\",\n    \"x-forwarded-port\": \"443\",\n    \"x-forwarded-proto\": \"https\"\n  },\n  \"requestContext\": {\n    \"accountId\": \"123456789012\",\n    \"apiId\": \"lsw1ro4ipb\",\n    \"authorizer\": {\n      \"lambda\": null\n    },\n    \"domainName\": \"lsw1ro4ipb.execute-api.eu-west-1.amazonaws.com\",\n    \"domainPrefix\": \"lsw1ro4ipb\",\n    \"http\": {\n      \"method\": \"POST\",\n      \"path\": \"/lambda\",\n      \"protocol\": \"HTTP/1.1\",\n      \"sourceIp\": \"15.248.3.126\",\n      \"userAgent\": \"HTTPie/3.2.2\"\n    },\n    \"requestId\": \"ZhNHJhhLjoEEPiw=\",\n    \"routeKey\": \"POST /lambda\",\n    \"stage\": \"$default\",\n    \"time\": \"17/Jun/2024:15:52:39 +0000\",\n    \"timeEpoch\": 1718639559080\n  },\n  \"body\": \"{\\\"name\\\":\\\"John\\\",\\\"age\\\":42}\",\n  \"isBase64Encoded\": false\n}\n</code></pre> <pre><code>import { JSONStringified } from '@aws-lambda-powertools/parser/helpers';\nimport {\n  SqsRecordSchema,\n  SqsSchema,\n} from '@aws-lambda-powertools/parser/schemas/sqs';\nimport { z } from 'zod';\n\nconst customSchema = z.object({\n  name: z.string(),\n  age: z.number(),\n});\n\nconst extendedSchema = SqsSchema.extend({\n  Records: z.array(\n    SqsRecordSchema.extend({\n      body: JSONStringified(customSchema), // (1)!\n    })\n  ),\n});\n\ntype ExtendedSqsEvent = z.infer&lt;typeof extendedSchema&gt;;\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"messageId\": \"059f36b4-87a3-44ab-83d2-661975830a7d\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n      \"body\": \"{\\\"name\\\": \\\"John Doe\\\", \\\"age\\\": 30}\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082649183\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082649185\"\n      },\n      \"messageAttributes\": {\n        \"testAttr\": {\n          \"stringValue\": \"100\",\n          \"binaryValue\": \"base64Str\",\n          \"dataType\": \"Number\"\n        }\n      },\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:my-queue\",\n      \"awsRegion\": \"us-east-2\"\n    },\n    {\n      \"messageId\": \"2e1424d4-f796-459a-8184-9c92662be6da\",\n      \"receiptHandle\": \"AQEBzWwaftRI0KuVm4tP+/7q1rGgNqicHq...\",\n      \"body\": \"{\\\"name\\\": \\\"foo\\\", \\\"age\\\": 10}\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1545082650636\",\n        \"SenderId\": \"AIDAIENQZJOLO23YVJ4VO\",\n        \"ApproximateFirstReceiveTimestamp\": \"1545082650649\",\n        \"DeadLetterQueueSourceArn\": \"arn:aws:sqs:us-east-2:123456789012:my-queue-dead\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"e4e68fb7bd0e697a0ae8f1bb342846b3\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-2:123456789012:my-queue\",\n      \"awsRegion\": \"us-east-2\"\n    }\n  ]\n}\n</code></pre>"
        },
        {
            "location": "utilities/parser/#dynamodb-stream-event-parsing",
            "title": "DynamoDB Stream event parsing",
            "text": "<p>If you want to parse a DynamoDB stream event with unmarshalling, you can use the helper function <code>DynamoDBMarshalled</code>:</p> DynamoDBStreamSchema with DynamoDBMarshalledDynamoDBStream event payload <pre><code>import { DynamoDBMarshalled } from '@aws-lambda-powertools/parser/helpers/dynamodb';\nimport {\n  DynamoDBStreamChangeRecordBase,\n  DynamoDBStreamRecord,\n  DynamoDBStreamSchema,\n} from '@aws-lambda-powertools/parser/schemas/dynamodb';\nimport { z } from 'zod';\n\nconst customSchema = z.object({\n  id: z.string(),\n  message: z.string(),\n});\n\nconst extendedSchema = DynamoDBStreamSchema.extend({\n  Records: z.array(\n    DynamoDBStreamRecord.extend({\n      dynamodb: DynamoDBStreamChangeRecordBase.extend({\n        NewImage: DynamoDBMarshalled(customSchema).optional(),\n      }),\n    })\n  ),\n});\n\ntype ExtendedDynamoDBStreamEvent = z.infer&lt;typeof extendedSchema&gt;;\n</code></pre> <pre><code>{\n    \"Records\": [\n      {\n        \"eventID\": \"1\",\n        \"eventVersion\": \"1.0\",\n        \"dynamodb\": {\n          \"ApproximateCreationDateTime\": 1693997155.0,\n          \"Keys\": {\n            \"Id\": {\n              \"N\": \"101\"\n            }\n          },\n          \"NewImage\": {\n            \"Message\": {\n              \"S\": \"New item!\"\n            },\n            \"Id\": {\n              \"N\": \"101\"\n            }\n          },\n          \"StreamViewType\": \"NEW_AND_OLD_IMAGES\",\n          \"SequenceNumber\": \"111\",\n          \"SizeBytes\": 26\n        },\n        \"awsRegion\": \"us-west-2\",\n        \"eventName\": \"INSERT\",\n        \"eventSourceARN\": \"eventsource_arn\",\n        \"eventSource\": \"aws:dynamodb\"\n      },\n      {\n        \"eventID\": \"2\",\n        \"eventVersion\": \"1.0\",\n        \"dynamodb\": {\n          \"OldImage\": {\n            \"Message\": {\n              \"S\": \"New item!\"\n            },\n            \"Id\": {\n              \"N\": \"101\"\n            }\n          },\n          \"SequenceNumber\": \"222\",\n          \"Keys\": {\n            \"Id\": {\n              \"N\": \"101\"\n            }\n          },\n          \"SizeBytes\": 59,\n          \"NewImage\": {\n            \"Message\": {\n              \"S\": \"This item has changed\"\n            },\n            \"Id\": {\n              \"N\": \"101\"\n            }\n          },\n          \"StreamViewType\": \"NEW_AND_OLD_IMAGES\"\n        },\n        \"awsRegion\": \"us-west-2\",\n        \"eventName\": \"MODIFY\",\n        \"eventSourceARN\": \"source_arn\",\n        \"eventSource\": \"aws:dynamodb\"\n      }\n    ]\n  }\n</code></pre>"
        },
        {
            "location": "utilities/parser/#envelopes",
            "title": "Envelopes",
            "text": "<p>When trying to parse your payload you might encounter the following situations:</p> <ul> <li>Your actual payload is wrapped around a known structure, for example Lambda Event Sources like EventBridge</li> <li>You're only interested in a portion of the payload, for example parsing the detail of custom events in EventBridge, or body of SQS records</li> <li>You can either solve these situations by creating a schema of these known structures, parsing them, then extracting and parsing a key where your payload is.</li> </ul> <p>This can become difficult quite quickly. Parser simplifies the development through a feature named Envelope. Envelopes can be used via envelope parameter available in middy and decorator. Here's an example of parsing a custom schema in an event coming from EventBridge, where all you want is what's inside the detail key.</p> Middy middlewareDecorator <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { EventBridgeEnvelope } from '@aws-lambda-powertools/parser/envelopes/eventbridge';\nimport { parser } from '@aws-lambda-powertools/parser/middleware';\nimport middy from '@middy/core';\nimport { z } from 'zod';\n\nconst logger = new Logger();\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\n\nexport const handler = middy()\n  .use(parser({ schema: orderSchema, envelope: EventBridgeEnvelope }))\n  .handler(async (event): Promise&lt;void&gt; =&gt; {\n    for (const item of event.items) {\n      // item is parsed as OrderItem\n      logger.info('Processing item', { item });\n    }\n  });\n</code></pre> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport { parser } from '@aws-lambda-powertools/parser';\nimport { EventBridgeEnvelope } from '@aws-lambda-powertools/parser/envelopes/eventbridge';\nimport type { Context } from 'aws-lambda';\nimport { z } from 'zod';\n\nconst logger = new Logger();\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\n\ntype Order = z.infer&lt;typeof orderSchema&gt;;\n\nclass Lambda implements LambdaInterface {\n  @parser({ schema: orderSchema, envelope: EventBridgeEnvelope }) // (1)!\n  public async handler(event: Order, _context: Context): Promise&lt;void&gt; {\n    // event is now typed as Order\n    for (const item of event.items) {\n      logger.info('Processing item', item); // (2)!\n    }\n  }\n}\n\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\n</code></pre> <ol> <li>Pass <code>eventBridgeEnvelope</code> to <code>parser</code> decorator</li> <li><code>event</code> is parsed and replaced as <code>Order</code> object</li> </ol> <p>The envelopes are functions that take an event and the schema to parse, and return the result of the inner schema. Depending on the envelope it can be something simple like extracting a key. We have also complex envelopes that parse the payload from a string, decode base64, uncompress gzip, etc.</p> <p>Envelopes vs schema extension</p> <p>Use envelopes if you want to extract only the inner part of an event payload and don't use the information from the Lambda event. Otherwise, extend built-in schema to parse the whole payload and use the metadata from the Lambda event.</p>"
        },
        {
            "location": "utilities/parser/#built-in-envelopes",
            "title": "Built-in envelopes",
            "text": "<p>Parser comes with the following built-in envelopes:</p> Envelope name Behaviour apiGatewayEnvelope 1. Parses data using <code>APIGatewayProxyEventSchema</code>.  2. Parses <code>body</code> key using your schema and returns it. apiGatewayV2Envelope 1. Parses data using <code>APIGatewayProxyEventV2Schema</code>.  2. Parses <code>body</code> key using your schema and returns it. cloudWatchEnvelope 1. Parses data using <code>CloudwatchLogsSchema</code> which will base64 decode and decompress it.  2. Parses records in <code>message</code> key using your schema and return them in a list. dynamoDBStreamEnvelope 1. Parses data using <code>DynamoDBStreamSchema</code>.  2. Parses records in <code>NewImage</code> and <code>OldImage</code> keys using your schema.  3. Returns a list with a dictionary containing <code>NewImage</code> and <code>OldImage</code> keys eventBridgeEnvelope 1. Parses data using <code>EventBridgeSchema</code>.  2. Parses <code>detail</code> key using your schema and returns it. kafkaEnvelope 1. Parses data using <code>KafkaRecordSchema</code>.  2. Parses <code>value</code> key using your schema and returns it. kinesisEnvelope 1. Parses data using <code>KinesisDataStreamSchema</code> which will base64 decode it.  2. Parses records in <code>Records</code> key using your schema and returns them in a list. kinesisFirehoseEnvelope 1. Parses data using <code>KinesisFirehoseSchema</code> which will base64 decode it.  2. Parses records in <code>Records</code> key using your schema and returns them in a list. lambdaFunctionUrlEnvelope 1. Parses data using <code>LambdaFunctionUrlSchema</code>.  2. Parses <code>body</code> key using your schema and returns it. snsEnvelope 1. Parses data using <code>SnsSchema</code>.  2. Parses records in <code>body</code> key using your schema and return them in a list. snsSqsEnvelope 1. Parses data using <code>SqsSchema</code>.  2. Parses SNS records in <code>body</code> key using <code>SnsNotificationSchema</code>.  3. Parses data in <code>Message</code> key using your schema and return them in a list. sqsEnvelope 1. Parses data using <code>SqsSchema</code>.  2. Parses records in <code>body</code> key using your schema and return them in a list. vpcLatticeEnvelope 1. Parses data using <code>VpcLatticeSchema</code>.  2. Parses <code>value</code> key using your schema and returns it. vpcLatticeV2Envelope 1. Parses data using <code>VpcLatticeSchema</code>.  2. Parses <code>value</code> key using your schema and returns it."
        },
        {
            "location": "utilities/parser/#safe-parsing",
            "title": "Safe parsing",
            "text": "<p>If you want to parse the event without throwing an error, use the <code>safeParse</code> option. The handler <code>event</code> object will be replaced with <code>ParsedResult&lt;Input?, Oputput?&gt;</code>, for example <code>ParsedResult&lt;SqsEvent, Order&gt;</code>, where <code>SqsEvent</code> is the original event and <code>Order</code> is the parsed schema.</p> <p>The <code>ParsedResult</code> object will have <code>success</code>, <code>data</code>,  or <code>error</code> and <code>originalEvent</code> fields, depending on the outcome. If the parsing is successful, the <code>data</code> field will contain the parsed event, otherwise you can access the <code>error</code> field and the <code>originalEvent</code> to handle the error and recover the original event.</p> Middy middlewareDecorator <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { parser } from '@aws-lambda-powertools/parser/middleware';\nimport middy from '@middy/core';\nimport { z } from 'zod';\n\nconst logger = new Logger();\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\n\nexport const handler = middy()\n  .use(\n    parser({ schema: orderSchema, safeParse: true }) // (1)!\n  )\n  .handler(async (event): Promise&lt;void&gt; =&gt; {\n    if (event.success) {\n      for (const item of event.data.items) {\n        logger.info('Processing item', { item }); // (2)!\n      }\n    } else {\n      logger.error('Error parsing event', { event: event.error }); // (3)!\n      logger.error('Original event', { event: event.originalEvent }); // (4)!\n    }\n  });\n</code></pre> <ol> <li>Use <code>safeParse</code> option to parse the event without throwing an error</li> <li>Use <code>data</code> to access the parsed event when successful</li> <li>Use <code>error</code> to handle the error message</li> <li>Use <code>originalEvent</code> to get the original event and recover</li> </ol> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport { parser } from '@aws-lambda-powertools/parser';\nimport { EventBridgeEnvelope } from '@aws-lambda-powertools/parser/envelopes/eventbridge';\nimport type {\n  EventBridgeEvent,\n  ParsedResult,\n} from '@aws-lambda-powertools/parser/types';\nimport type { Context } from 'aws-lambda';\nimport { z } from 'zod';\n\nconst logger = new Logger();\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\n\ntype Order = z.infer&lt;typeof orderSchema&gt;;\n\nclass Lambda implements LambdaInterface {\n  @parser({\n    schema: orderSchema,\n    envelope: EventBridgeEnvelope,\n    safeParse: true, // (1)!\n  })\n  public async handler(\n    event: ParsedResult&lt;EventBridgeEvent, Order&gt;,\n    _context: Context\n  ): Promise&lt;void&gt; {\n    if (event.success) {\n      for (const item of event.data.items) {\n        logger.info('Processing item', { item }); // (2)!\n      }\n    } else {\n      logger.error('Failed to parse event', { error: event.error }); // (3)!\n      logger.error('Original event is ', { original: event.originalEvent }); // (4)!\n    }\n  }\n}\n\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\n</code></pre> <ol> <li>Use <code>safeParse</code> option to parse the event without throwing an error</li> <li>Use <code>data</code> to access the parsed event when successful</li> <li>Use <code>error</code> to handle the error message</li> <li>Use <code>originalEvent</code> to get the original event and recover</li> </ol>"
        },
        {
            "location": "utilities/parser/#manual-parsing",
            "title": "Manual parsing",
            "text": "<p>You can use built-in envelopes and schemas to parse the incoming events manually, without using middy or decorator.</p> Manual parseManual safeParse <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { EventBridgeEnvelope } from '@aws-lambda-powertools/parser/envelopes/eventbridge';\nimport { EventBridgeSchema } from '@aws-lambda-powertools/parser/schemas/eventbridge';\nimport type { EventBridgeEvent } from '@aws-lambda-powertools/parser/types';\nimport type { Context } from 'aws-lambda';\nimport { z } from 'zod';\n\nconst logger = new Logger();\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\ntype Order = z.infer&lt;typeof orderSchema&gt;;\n\nexport const handler = async (\n  event: EventBridgeEvent,\n  _context: Context\n): Promise&lt;void&gt; =&gt; {\n  const parsedEvent = EventBridgeSchema.parse(event); // (1)!\n  logger.info('Parsed event', parsedEvent);\n\n  const orders: Order = EventBridgeEnvelope.parse(event, orderSchema); // (2)!\n  logger.info('Parsed orders', orders);\n};\n</code></pre> <ol> <li>Use <code>EventBridgeSchema</code> to parse the event, the <code>details</code> fields will be parsed as a generic record.</li> <li>Use <code>eventBridgeEnvelope</code> with a combination of <code>orderSchema</code> to get <code>Order</code> object from the <code>details</code> field.</li> </ol> <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { EventBridgeEnvelope } from '@aws-lambda-powertools/parser/envelopes/eventbridge';\nimport { EventBridgeSchema } from '@aws-lambda-powertools/parser/schemas/eventbridge';\nimport type { EventBridgeEvent } from '@aws-lambda-powertools/parser/types';\nimport type { Context } from 'aws-lambda';\nimport { z } from 'zod';\n\nconst logger = new Logger();\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\n\nexport const handler = async (\n  event: EventBridgeEvent,\n  _context: Context\n): Promise&lt;void&gt; =&gt; {\n  const parsedEvent = EventBridgeSchema.safeParse(event); // (1)!\n  parsedEvent.success\n    ? logger.info('Event parsed successfully', parsedEvent.data)\n    : logger.error('Event parsing failed', parsedEvent.error);\n  const parsedEvenlope = EventBridgeEnvelope.safeParse(event, orderSchema); // (2)!\n  parsedEvenlope.success\n    ? logger.info('Event envelope parsed successfully')\n    : logger.error('Event envelope parsing failed', parsedEvenlope.error);\n};\n</code></pre> <ol> <li>Use <code>safeParse</code> option to parse the event without throwing an error</li> <li><code>safeParse</code> is also available for envelopes</li> </ol>"
        },
        {
            "location": "utilities/parser/#custom-validation",
            "title": "Custom validation",
            "text": "<p>Because Parser uses Zod, you can use all the features of Zod to validate your data. For example, you can use <code>refine</code> to validate a field or a combination of fields:</p> Custom validation <pre><code>import { z } from 'zod';\n\nconst orderItemSchema = z.object({\n  id: z.number().positive(),\n  quantity: z.number(),\n  description: z.string(),\n});\n\nexport const orderSchema = z\n  .object({\n    id: z.number().positive(),\n    description: z.string(),\n    items: z.array(orderItemSchema).refine((items) =&gt; items.length &gt; 0, {\n      message: 'Order must have at least one item', // (1)!\n    }),\n    optionalField: z.string().optional(),\n  })\n  .refine((order) =&gt; order.id &gt; 100 &amp;&amp; order.items.length &gt; 100, {\n    message:\n      'All orders with more than 100 items must have an id greater than 100', // (2)!\n  });\n</code></pre> <ol> <li>validate a single field</li> <li>validate an object with multiple fields</li> </ol> <p>Zod provides a lot of other features and customization, see Zod documentation for more details.</p>"
        },
        {
            "location": "utilities/parser/#types",
            "title": "Types",
            "text": ""
        },
        {
            "location": "utilities/parser/#schema-and-type-inference",
            "title": "Schema and Type inference",
            "text": "<p>Use <code>z.infer</code> to extract the type of the schema, so you can use types during development and avoid type errors.</p> Types <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { parser } from '@aws-lambda-powertools/parser/middleware';\nimport middy from '@middy/core';\nimport type { Context } from 'aws-lambda';\nimport { z } from 'zod';\n\nconst logger = new Logger();\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\n\ntype Order = z.infer&lt;typeof orderSchema&gt;; // (1)!\n\nconst lambdaHandler = async (\n  event: Order, // (2)!\n  _context: Context\n): Promise&lt;void&gt; =&gt; {\n  for (const item of event.items) {\n    // item is parsed as OrderItem\n    logger.info('Processing item', { item }); // (3)!\n  }\n};\n\nexport const handler = middy(lambdaHandler).use(\n  parser({ schema: orderSchema })\n);\n</code></pre> <ol> <li>Use <code>z.infer</code> to extract the type of the schema, also works for nested schemas</li> <li><code>event</code> is of type <code>Order</code></li> <li>infer types from deeply nested schemas </li> </ol>"
        },
        {
            "location": "utilities/parser/#compatibility-with-typesaws-lambda",
            "title": "Compatibility with <code>@types/aws-lambda</code>",
            "text": "<p>The package <code>@types/aws-lambda</code> is a popular project that contains type definitions for many AWS service event invocations. Powertools parser utility also bring AWS Lambda event types based on the built-in schema definitions.</p> <p>We recommend to use the types provided by the parser utility. If you encounter any issues or have any feedback, please submit an issue.</p>"
        },
        {
            "location": "utilities/parser/#testing-your-code",
            "title": "Testing your code",
            "text": "<p>When testing your handler with parser decorator you need to use double assertion to bypass TypeScript type checking in your tests. This is useful when you want to test the handler for invalid payloads or when you want to test the error handling. If you are you use middy middleware, you don't need to do this.</p> handlerDecorator.test.tshandlerDecorator.tsschema.ts <pre><code>import type { Context } from 'aws-lambda';\nimport { describe, expect, it } from 'vitest';\nimport { handler } from './decorator.js';\nimport type { Order } from './schema.js';\n\ndescribe('Test handler', () =&gt; {\n  it('should parse event successfully', async () =&gt; {\n    const testEvent = {\n      id: 123,\n      description: 'test',\n      items: [\n        {\n          id: 1,\n          quantity: 1,\n          description: 'item1',\n        },\n      ],\n    };\n\n    await expect(handler(testEvent, {} as Context)).resolves.toEqual(123);\n  });\n\n  it('should throw error if event is invalid', async () =&gt; {\n    const testEvent = { foo: 'bar' };\n    await expect(\n      handler(\n        testEvent as unknown as Order, // (1)!\n        {} as Context\n      )\n    ).rejects.toThrow();\n  });\n});\n</code></pre> <ol> <li>Use double assertion <code>as unknown as X</code> to bypass TypeScript type checking in your tests</li> </ol> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport { parser } from '@aws-lambda-powertools/parser';\nimport type { Context } from 'aws-lambda';\nimport { type Order, orderSchema } from './schema.js';\n\nconst logger = new Logger();\n\nclass Lambda implements LambdaInterface {\n  @parser({ schema: orderSchema })\n  public async handler(event: Order, _context: Context): Promise&lt;number&gt; {\n    logger.info('Processing event', { event });\n\n    // ... business logic\n    return event.id;\n  }\n}\n\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\n</code></pre> <pre><code>import { z } from 'zod';\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\n\ntype Order = z.infer&lt;typeof orderSchema&gt;;\n\nexport { orderSchema, type Order };\n</code></pre> <p>This also works when using <code>safeParse</code> option.</p> handlerSafeParse.test.tshandlerSafeParse.tsschema.ts <pre><code>import type {\n  EventBridgeEvent,\n  ParsedResult,\n} from '@aws-lambda-powertools/parser/types';\nimport type { Context } from 'aws-lambda';\nimport { describe, expect, it } from 'vitest';\nimport { handler } from './safeParseDecorator.js';\nimport type { Order } from './schema.js';\n\ndescribe('Test handler', () =&gt; {\n  it('should parse event successfully', async () =&gt; {\n    const testEvent = {\n      version: '0',\n      id: '6a7e8feb-b491-4cf7-a9f1-bf3703467718',\n      'detail-type': 'OrderPurchased',\n      source: 'OrderService',\n      account: '111122223333',\n      time: '2020-10-22T18:43:48Z',\n      region: 'us-west-1',\n      resources: ['some_additional'],\n      detail: {\n        id: 10876546789,\n        description: 'My order',\n        items: [\n          {\n            id: 1015938732,\n            quantity: 1,\n            description: 'item xpto',\n          },\n        ],\n      },\n    };\n\n    await expect(\n      handler(\n        testEvent as unknown as ParsedResult&lt;EventBridgeEvent, Order&gt;, // (1)!\n        {} as Context\n      )\n    ).resolves.toEqual(10876546789);\n  });\n\n  it('should throw error if event is invalid', async () =&gt; {\n    const testEvent = { foo: 'bar' };\n    await expect(\n      handler(\n        testEvent as unknown as ParsedResult&lt;EventBridgeEvent, Order&gt;,\n        {} as Context\n      )\n    ).rejects.toThrow();\n  });\n});\n</code></pre> <ol> <li>Use double assertion to pass expected types to the handler</li> </ol> <pre><code>import type { LambdaInterface } from '@aws-lambda-powertools/commons/types';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport { parser } from '@aws-lambda-powertools/parser';\nimport { EventBridgeEnvelope } from '@aws-lambda-powertools/parser/envelopes/eventbridge';\nimport type {\n  EventBridgeEvent,\n  ParsedResult,\n} from '@aws-lambda-powertools/parser/types';\nimport type { Context } from 'aws-lambda';\nimport { type Order, orderSchema } from './schema.js';\n\nconst logger = new Logger();\n\nclass Lambda implements LambdaInterface {\n  @parser({\n    schema: orderSchema,\n    envelope: EventBridgeEnvelope,\n    safeParse: true,\n  })\n  public async handler(\n    event: ParsedResult&lt;EventBridgeEvent, Order&gt;,\n    _context: Context\n  ): Promise&lt;number&gt; {\n    logger.info('Processing event', { event });\n    if (event.success) {\n      // ... business logic\n      return event.data.id;\n    }\n    logger.error('Failed to parse event', { event });\n    throw new Error('Failed to parse event');\n  }\n}\n\nconst myFunction = new Lambda();\nexport const handler = myFunction.handler.bind(myFunction);\n</code></pre> <pre><code>import { z } from 'zod';\n\nconst orderSchema = z.object({\n  id: z.number().positive(),\n  description: z.string(),\n  items: z.array(\n    z.object({\n      id: z.number().positive(),\n      quantity: z.number(),\n      description: z.string(),\n    })\n  ),\n  optionalField: z.string().optional(),\n});\n\ntype Order = z.infer&lt;typeof orderSchema&gt;;\n\nexport { orderSchema, type Order };\n</code></pre>"
        },
        {
            "location": "utilities/validation/",
            "title": "Validation",
            "text": "<p>This utility provides JSON Schema validation for events and responses, including JMESPath support to unwrap events before validation.</p>"
        },
        {
            "location": "utilities/validation/#key-features",
            "title": "Key features",
            "text": "<ul> <li>Validate incoming event and response payloads</li> <li>JMESPath support to unwrap events before validation</li> <li>Built-in envelope to unwrap popular AWS service events</li> <li>TypeScript support with type-safe validation</li> </ul>"
        },
        {
            "location": "utilities/validation/#getting-started",
            "title": "Getting started",
            "text": "<pre><code>npm install @aws-lambda-powertools/validation\n</code></pre> <p>You can validate inbound and outbound payloads using the validator class method decorator or Middy.js middleware.</p> <p>You can also use the standalone <code>validate</code> function, if you want more control over the validation process such as handling a validation error.</p> <p>Using JSON Schemas for the first time?</p> <p>Check this step-by-step guide on how to create JSON Schemas. By default, we support JSON Schema draft-07.</p>"
        },
        {
            "location": "utilities/validation/#validator-decorator",
            "title": "Validator decorator",
            "text": "<p>The <code>@validator</code> decorator is a class method decorator that you can use to validate both the incoming event and the response payload.</p> <p>If the validation fails, we will throw a <code>SchemaValidationError</code>.</p> A note on class method decorators <p>The class method decorators in this project follow the experimental implementation enabled via the <code>experimentalDecorators</code> compiler option in TypeScript. We will add support for the newer Stage 3 decorators proposal in the next major release.</p> <p>All our decorators assume that the method they are decorating is an async method. This means that even when decorating a synchronous method, it will return a promise. If this is not the desired behavior, you can use one of the other patterns to validate your payloads.</p> gettingStartedDecorator.tsschemas.ts <pre><code>import { validator } from '@aws-lambda-powertools/validation/decorator';\nimport type { Context } from 'aws-lambda';\nimport {\n  type InboundSchema,\n  type OutboundSchema,\n  inboundSchema,\n  outboundSchema,\n} from './schemas.js';\n\nclass Lambda {\n  @validator({\n    inboundSchema,\n    outboundSchema,\n  })\n  async handler(\n    event: InboundSchema,\n    _context: Context\n  ): Promise&lt;OutboundSchema&gt; {\n    return {\n      statusCode: 200,\n      body: `Hello from ${event.userId}`,\n    };\n  }\n}\n\nconst lambda = new Lambda();\nexport const handler = lambda.handler.bind(lambda);\n</code></pre> <pre><code>const inboundSchema = {\n  type: 'object',\n  properties: {\n    userId: {\n      type: 'string',\n    },\n  },\n  required: ['userId'],\n} as const;\n\ntype InboundSchema = {\n  userId: string;\n};\n\nconst outboundSchema = {\n  type: 'object',\n  properties: {\n    body: {\n      type: 'string',\n    },\n    statusCode: {\n      type: 'number',\n    },\n  },\n  required: ['body', 'statusCode'],\n} as const;\n\ntype OutboundSchema = {\n  body: string;\n  statusCode: number;\n};\n\nexport {\n  inboundSchema,\n  outboundSchema,\n  type InboundSchema,\n  type OutboundSchema,\n};\n</code></pre> <p>It's not mandatory to validate both the inbound and outbound payloads. You can either use one, the other, or both.</p>"
        },
        {
            "location": "utilities/validation/#validator-middleware",
            "title": "Validator middleware",
            "text": "<p>If you are using Middy.js, you can use the <code>validator</code> middleware to validate the incoming event and response payload.</p> A note on Middy.js <p>We officially support versions of Middy.js <code>v4.x</code> through <code>v6.x</code></p> <p>Check their docs to learn more about Middy.js and its middleware stack as well as best practices when working with Powertools for AWS.</p> <p>Like the class method decorator, if the validation fails, we will throw a <code>SchemaValidationError</code>, and you don't need to use both the inbound and outbound schemas if you don't need to.</p> gettingStartedMiddy.tsschemas.ts <pre><code>import { validator } from '@aws-lambda-powertools/validation/middleware';\nimport middy from '@middy/core';\nimport {\n  type InboundSchema,\n  type OutboundSchema,\n  inboundSchema,\n  outboundSchema,\n} from './schemas.js';\n\nexport const handler = middy()\n  .use(\n    validator({\n      inboundSchema,\n      outboundSchema,\n    })\n  )\n  .handler(\n    async (event: InboundSchema): Promise&lt;OutboundSchema&gt; =&gt; ({\n      statusCode: 200,\n      body: `Hello from ${event.userId}`,\n    })\n  );\n</code></pre> <pre><code>const inboundSchema = {\n  type: 'object',\n  properties: {\n    userId: {\n      type: 'string',\n    },\n  },\n  required: ['userId'],\n} as const;\n\ntype InboundSchema = {\n  userId: string;\n};\n\nconst outboundSchema = {\n  type: 'object',\n  properties: {\n    body: {\n      type: 'string',\n    },\n    statusCode: {\n      type: 'number',\n    },\n  },\n  required: ['body', 'statusCode'],\n} as const;\n\ntype OutboundSchema = {\n  body: string;\n  statusCode: number;\n};\n\nexport {\n  inboundSchema,\n  outboundSchema,\n  type InboundSchema,\n  type OutboundSchema,\n};\n</code></pre>"
        },
        {
            "location": "utilities/validation/#standalone-validation",
            "title": "Standalone validation",
            "text": "<p>The <code>validate</code> function gives you more control over the validation process, and is typically used within the Lambda handler, or any other function that performs validation.</p> <p>You can also gracefully handle schema validation errors by catching <code>SchemaValidationError</code> errors.</p> gettingStartedStandalone.tsschemas.ts <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { validate } from '@aws-lambda-powertools/validation';\nimport { SchemaValidationError } from '@aws-lambda-powertools/validation/errors';\nimport { type InboundSchema, inboundSchema } from './schemas.js';\n\nconst logger = new Logger();\n\nexport const handler = async (event: InboundSchema) =&gt; {\n  try {\n    validate({\n      payload: event,\n      schema: inboundSchema,\n    });\n\n    return {\n      message: 'ok', // (1)!\n    };\n  } catch (error) {\n    if (error instanceof SchemaValidationError) {\n      logger.error('Schema validation failed', error);\n      throw new Error('Invalid event payload');\n    }\n\n    throw error;\n  }\n};\n</code></pre> <ol> <li>Since we are not validating the output, we can return anything</li> </ol> <pre><code>const inboundSchema = {\n  type: 'object',\n  properties: {\n    userId: {\n      type: 'string',\n    },\n  },\n  required: ['userId'],\n} as const;\n\ntype InboundSchema = {\n  userId: string;\n};\n\nconst outboundSchema = {\n  type: 'object',\n  properties: {\n    body: {\n      type: 'string',\n    },\n    statusCode: {\n      type: 'number',\n    },\n  },\n  required: ['body', 'statusCode'],\n} as const;\n\ntype OutboundSchema = {\n  body: string;\n  statusCode: number;\n};\n\nexport {\n  inboundSchema,\n  outboundSchema,\n  type InboundSchema,\n  type OutboundSchema,\n};\n</code></pre>"
        },
        {
            "location": "utilities/validation/#unwrapping-events-prior-to-validation",
            "title": "Unwrapping events prior to validation",
            "text": "<p>In some cases you might want to validate only a portion of the event payload - this is what the <code>envelope</code> option is for.</p> <p>Envelopes are JMESPath expressions to extract the part of the JSON you want before applying the JSON Schema validation.</p> <p>Here is a sample custom EventBridge event, where we only want to validate the <code>detail</code> part of the event:</p> gettingStartedEnvelope.tsschemas.tsgettingStartedEnvelopeEvent.json <pre><code>import { validator } from '@aws-lambda-powertools/validation/decorator';\nimport type { Context } from 'aws-lambda';\nimport { type InboundSchema, inboundSchema } from './schemas.js';\n\nclass Lambda {\n  @validator({\n    inboundSchema,\n    envelope: 'detail',\n  })\n  async handler(event: InboundSchema, context: Context) {\n    return {\n      message: `processed ${event.userId}`,\n      success: true,\n    };\n  }\n}\n\nconst lambda = new Lambda();\nexport const handler = lambda.handler.bind(lambda);\n</code></pre> <pre><code>const inboundSchema = {\n  type: 'object',\n  properties: {\n    userId: {\n      type: 'string',\n    },\n  },\n  required: ['userId'],\n} as const;\n\ntype InboundSchema = {\n  userId: string;\n};\n\nconst outboundSchema = {\n  type: 'object',\n  properties: {\n    body: {\n      type: 'string',\n    },\n    statusCode: {\n      type: 'number',\n    },\n  },\n  required: ['body', 'statusCode'],\n} as const;\n\ntype OutboundSchema = {\n  body: string;\n  statusCode: number;\n};\n\nexport {\n  inboundSchema,\n  outboundSchema,\n  type InboundSchema,\n  type OutboundSchema,\n};\n</code></pre> <pre><code>{\n  \"version\": \"0\",\n  \"id\": \"12345678-1234-1234-1234-123456789012\",\n  \"detail-type\": \"myDetailType\",\n  \"source\": \"myEventSource\",\n  \"account\": \"123456789012\",\n  \"time\": \"2017-12-22T18:43:48Z\",\n  \"region\": \"us-west-2\",\n  \"resources\": [],\n  \"detail\": {\n    \"userId\": \"123\"\n  }\n}\n</code></pre> <p>This is quite powerful as it allows you to validate only the part of the event that you are interested in, and thanks to JMESPath, you can extract records from arrays, combine pipe and filter expressions, and more.</p> <p>When combined, these features allow you to extract and validate the exact part of the event you actually care about.</p>"
        },
        {
            "location": "utilities/validation/#built-in-envelopes",
            "title": "Built-in envelopes",
            "text": "<p>We provide built-in envelopes to easily extract payloads from popular AWS event sources.</p> <p>Here is an example of how you can use the built-in envelope for SQS events:</p> gettingStartedEnvelopeBuiltin.tsschemas.tsgettingStartedSQSEnvelopeEvent.json <pre><code>import { SQS } from '@aws-lambda-powertools/jmespath/envelopes';\nimport { Logger } from '@aws-lambda-powertools/logger';\nimport { validator } from '@aws-lambda-powertools/validation/middleware';\nimport middy from '@middy/core';\nimport { type InboundSchema, inboundSchema } from './schemas.js';\n\nconst logger = new Logger();\n\nexport const handler = middy()\n  .use(\n    validator({\n      inboundSchema,\n      envelope: SQS,\n    })\n  )\n  .handler(async (event: Array&lt;InboundSchema&gt;) =&gt; {\n    for (const record of event) {\n      logger.info(`Processing message ${record.userId}`);\n    }\n  });\n</code></pre> <pre><code>const inboundSchema = {\n  type: 'object',\n  properties: {\n    userId: {\n      type: 'string',\n    },\n  },\n  required: ['userId'],\n} as const;\n\ntype InboundSchema = {\n  userId: string;\n};\n\nconst outboundSchema = {\n  type: 'object',\n  properties: {\n    body: {\n      type: 'string',\n    },\n    statusCode: {\n      type: 'number',\n    },\n  },\n  required: ['body', 'statusCode'],\n} as const;\n\ntype OutboundSchema = {\n  body: string;\n  statusCode: number;\n};\n\nexport {\n  inboundSchema,\n  outboundSchema,\n  type InboundSchema,\n  type OutboundSchema,\n};\n</code></pre> <pre><code>{\n  \"Records\": [\n    {\n      \"messageId\": \"c80e8021-a70a-42c7-a470-796e1186f753\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n      \"body\": \"{\\\"userId\\\":\\\"123\\\"}\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"3\",\n        \"SentTimestamp\": \"1529104986221\",\n        \"SenderId\": \"AIDAIC6K7FJUZ7Q\",\n        \"ApproximateFirstReceiveTimestamp\": \"1529104986230\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"098f6bcd4621d373cade4e832627b4f6\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-west-2:123456789012:my-queue\",\n      \"awsRegion\": \"us-west-2\"\n    },\n    {\n      \"messageId\": \"c80e8021-a70a-42c7-a470-796e1186f753\",\n      \"receiptHandle\": \"AQEBwJnKyrHigUMZj6rYigCgxlaS3SLy0a...\",\n      \"body\": \"{\\\"userId\\\":\\\"456\\\"}\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"3\",\n        \"SentTimestamp\": \"1529104986221\",\n        \"SenderId\": \"AIDAIC6K7FJUZ7Q\",\n        \"ApproximateFirstReceiveTimestamp\": \"1529104986230\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"098f6bcd4621d373cade4e832627b4f6\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-west-2:123456789012:my-queue\",\n      \"awsRegion\": \"us-west-2\"\n    }\n  ]\n}\n</code></pre> <p>For a complete list of built-in envelopes, check the built-in envelopes section here.</p>"
        },
        {
            "location": "utilities/validation/#advanced",
            "title": "Advanced",
            "text": ""
        },
        {
            "location": "utilities/validation/#validating-custom-formats",
            "title": "Validating custom formats",
            "text": "<p>While JSON Schema draft-07 has many new built-in formats such as date, time, and specifically a regex format which can be used in place of custom formats, you can also define your own custom formats.</p> <p>This is useful when you have a specific format that is not covered by the built-in formats or when you don't control the schema.</p> <p>JSON Schemas with custom formats like <code>awsaccountid</code> will fail validation if the format is not defined. You can define custom formats using the <code>formats</code> option to any of the validation methods.</p> schemaWithCustomFormat.json <pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"accountId\": {\n      \"type\": \"string\",\n      \"format\": \"awsaccountid\"\n    },\n    \"creditCard\": {\n      \"type\": \"string\",\n      \"format\": \"creditcard\"\n    }\n  },\n  \"required\": [\n    \"accountId\"\n  ]\n}\n</code></pre> <p>For each one of these custom formats, you need to tell us how to validate them. To do so, you can either pass a <code>RegExp</code> object or a function that receives the value and returns a boolean.</p> <p>For example, to validate using the schema above, you can define a custom format for <code>awsaccountid</code> like this:</p> advancedCustomFormats.ts <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { validate } from '@aws-lambda-powertools/validation';\nimport { SchemaValidationError } from '@aws-lambda-powertools/validation/errors';\nimport schemaWithCustomFormat from './samples/schemaWithCustomFormat.json';\n\nconst logger = new Logger();\n\nconst customFormats = {\n  awsaccountid: /^\\d{12}$/,\n  creditcard: (value: string) =&gt; {\n    // Luhn algorithm (for demonstration purposes only - do not use in production)\n    const sum = value\n      .split('')\n      .reverse()\n      .reduce((acc, digit, index) =&gt; {\n        const num = Number.parseInt(digit, 10);\n        return acc + (index % 2 === 0 ? num : num &lt; 5 ? num * 2 : num * 2 - 9);\n      }, 0);\n\n    return sum % 10 === 0;\n  },\n};\n\nexport const handler = async (event: unknown) =&gt; {\n  try {\n    await validate({\n      payload: event,\n      schema: schemaWithCustomFormat,\n      formats: customFormats,\n    });\n\n    return {\n      message: 'ok',\n    };\n  } catch (error) {\n    if (error instanceof SchemaValidationError) {\n      logger.error('Schema validation failed', error);\n      throw new Error('Invalid event payload');\n    }\n\n    throw error;\n  }\n};\n</code></pre>"
        },
        {
            "location": "utilities/validation/#built-in-jmespath-functions",
            "title": "Built-in JMESpath functions",
            "text": "<p>In some cases, your payloads might require some transformation before validation. For example, you might want to parse a JSON string or decode a base64 string before validating the payload.</p> <p>For this, you can use our buil-in JMESPath functions within your expressions. We have a few built-in functions that you can use:</p> <ul> <li><code>powertools_json()</code>: Parses a JSON string</li> <li><code>powertools_base64()</code>: Decodes a base64 string</li> <li><code>powertools_base64_gzip()</code>: Decodes a base64 string and unzips it</li> </ul> <p>We use these functions for built-in envelopes to easily decode and unwrap events from sources like Kinesis, SQS, S3, and more.</p>"
        },
        {
            "location": "utilities/validation/#validating-with-external-references",
            "title": "Validating with external references",
            "text": "<p>JSON Schema allows schemas to reference other schemas using the <code>$ref</code> keyword. This is useful when you have a common schema that you want to reuse across multiple schemas.</p> <p>You can use the <code>externalRefs</code> option to pass a list of schemas that you want to reference in your inbound and outbound schemas.</p> advancedExternalRefs.tsschemasWithExternalRefs.ts <pre><code>import { validator } from '@aws-lambda-powertools/validation/decorator';\nimport type { Context } from 'aws-lambda';\nimport {\n  type InboundSchema,\n  defsSchema,\n  inboundSchema,\n  outboundSchema,\n} from './schemasWithExternalRefs.js';\n\nclass Lambda {\n  @validator({\n    inboundSchema,\n    outboundSchema,\n    externalRefs: [defsSchema],\n  })\n  async handler(event: InboundSchema, _context: Context) {\n    return {\n      message: `processed ${event.userId}`,\n      success: true,\n    };\n  }\n}\n\nconst lambda = new Lambda();\nexport const handler = lambda.handler.bind(lambda);\n</code></pre> <pre><code>const defsSchema = {\n  $id: 'http://example.com/schemas/defs.json',\n  definitions: {\n    int: { type: 'integer' },\n    str: { type: 'string' },\n  },\n} as const;\n\nconst inboundSchema = {\n  $id: 'http://example.com/schemas/inbound.json',\n  type: 'object',\n  properties: {\n    userId: { $ref: 'defs.json#/definitions/str' },\n  },\n  required: ['userId'],\n} as const;\n\ntype InboundSchema = {\n  userId: string;\n};\n\nconst outboundSchema = {\n  $id: 'http://example.com/schemas/outbound.json',\n  type: 'object',\n  properties: {\n    body: { $ref: 'defs.json#/definitions/str' },\n    statusCode: { $ref: 'defs.json#/definitions/int' },\n  },\n  required: ['body', 'statusCode'],\n} as const;\n\ntype OutboundSchema = {\n  body: string;\n  statusCode: number;\n};\n\nexport {\n  defsSchema,\n  inboundSchema,\n  outboundSchema,\n  type InboundSchema,\n  type OutboundSchema,\n};\n</code></pre>"
        },
        {
            "location": "utilities/validation/#bringing-your-own-ajv-instance",
            "title": "Bringing your own <code>ajv</code> instance",
            "text": "<p>By default, we use JSON Schema draft-07. If you want to use a different draft, you can pass your own <code>ajv</code> instance to any of the validation methods.</p> <p>This is also useful if you want to configure <code>ajv</code> with custom options like keywords and more.</p> advancedBringAjvInstance.ts <pre><code>import { Logger } from '@aws-lambda-powertools/logger';\nimport { validate } from '@aws-lambda-powertools/validation';\nimport { SchemaValidationError } from '@aws-lambda-powertools/validation/errors';\nimport Ajv2019 from 'ajv/dist/2019';\nimport { inboundSchema } from './schemas.js';\n\nconst logger = new Logger();\n\nconst ajv = new Ajv2019();\n\nexport const handler = async (event: unknown) =&gt; {\n  try {\n    await validate({\n      payload: event,\n      schema: inboundSchema,\n      ajv, // (1)!\n    });\n\n    return {\n      message: 'ok',\n    };\n  } catch (error) {\n    if (error instanceof SchemaValidationError) {\n      logger.error('Schema validation failed', error);\n      throw new Error('Invalid event payload');\n    }\n\n    throw error;\n  }\n};\n</code></pre> <ol> <li>You can pass your own <code>ajv</code> instance to any of the validation methods. This is useful if you want to configure <code>ajv</code> with custom options like keywords and more.</li> </ol>"
        },
        {
            "location": "utilities/validation/#should-i-use-this-or-parser",
            "title": "Should I use this or Parser?",
            "text": "<p>One of Powertools for AWS Lambda tenets is to be progressive. This means that our utilities are designed to be incrementally adopted by customers at any stage of their serverless journey.</p> <p>For new projects, especially those using TypeScript, we recommend using the Parser utility. Thanks to its integration with Zod, it provides an expressive and type-safe way to validate and parse payloads.</p> <p>If instead you are already using JSON Schema, or simply feel more comfortable with it, the Validation utility is a great choice. It provides an opinionated thin layer on top of the popular ajv library, with built-in support for JMESPath and AWS service envelopes.</p> <p>When it comes to feature set, besides the type-safe parsing, the Parser utility also provides a rich collection of built-in schemas and envelopes for AWS services. The Validation utility, on the other hand, follows a more bring-your-own-schema approach, with built-in support for JMESPath and AWS service envelopes to help you unwrap events before validation.</p> <p>Additionally, while both utilities serve specific use cases, understanding your project requirements will help you choose the right tool for your validation needs.</p> <p>Finally, in terms of bundle size, the Validation utility is slightly heavier than the Parser utility primarily due to ajv not providing ESM builds. However, even with this, the Validation utility still clocks in at under ~100KB when minified and bundled.</p>"
        }
    ]
}